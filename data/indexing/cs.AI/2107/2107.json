[{"id": "2107.00001", "submitter": "Jan Philipp Portisch", "authors": "Jan Portisch, Michael Hladik, Heiko Paulheim", "title": "Background Knowledge in Schema Matching: Strategy vs. Data", "comments": "accepted at the International Semantic Web Conference '21 (ISWC 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of external background knowledge can be beneficial for the task of\nmatching schemas or ontologies automatically. In this paper, we exploit six\ngeneral-purpose knowledge graphs as sources of background knowledge for the\nmatching task. The background sources are evaluated by applying three different\nexploitation strategies. We find that explicit strategies still outperform\nlatent ones and that the choice of the strategy has a greater impact on the\nfinal alignment than the actual background dataset on which the strategy is\napplied. While we could not identify a universally superior resource, BabelNet\nachieved consistently good results. Our best matcher configuration with\nBabelNet performs very competitively when compared to other matching systems\neven though no dataset-specific optimizations were made.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 19:16:33 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Portisch", "Jan", ""], ["Hladik", "Michael", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2107.00048", "submitter": "Sankalp Gilda", "authors": "Sankalp Gilda and Stark C. Draper and Sebastien Fabbro and William\n  Mahoney and Simon Prunet and Kanoa Withington and Matthew Wilson and Yuan-Sen\n  Ting and Andrew Sheinis", "title": "Uncertainty-Aware Learning for Improvements in Image Quality of the\n  Canada-France-Hawaii Telescope", "comments": "25 pages, 1 appendix, 12 figures. To be submitted to MNRAS. Comments\n  and feedback welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We leverage state-of-the-art machine learning methods and a decade's worth of\narchival data from the Canada-France-Hawaii Telescope (CFHT) to predict\nobservatory image quality (IQ) from environmental conditions and observatory\noperating parameters. Specifically, we develop accurate and interpretable\nmodels of the complex dependence between data features and observed IQ for\nCFHT's wide field camera, MegaCam. Our contributions are several-fold. First,\nwe collect, collate and reprocess several disparate data sets gathered by CFHT\nscientists. Second, we predict probability distribution functions (PDFs) of IQ,\nand achieve a mean absolute error of $\\sim0.07''$ for the predicted medians.\nThird, we explore data-driven actuation of the 12 dome ``vents'', installed in\n2013-14 to accelerate the flushing of hot air from the dome. We leverage\nepistemic and aleatoric uncertainties in conjunction with probabilistic\ngenerative modeling to identify candidate vent adjustments that are\nin-distribution (ID) and, for the optimal configuration for each ID sample, we\npredict the reduction in required observing time to achieve a fixed SNR. On\naverage, the reduction is $\\sim15\\%$. Finally, we rank sensor data features by\nShapley values to identify the most predictive variables for each observation.\nOur long-term goal is to construct reliable and real-time models that can\nforecast optimal observatory operating parameters for optimization of IQ. Such\nforecasts can then be fed into scheduling protocols and predictive maintenance\nroutines. We anticipate that such approaches will become standard in automating\nobservatory operations and maintenance by the time CFHT's successor, the\nMaunakea Spectroscopic Explorer (MSE), is installed in the next decade.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 18:10:20 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Gilda", "Sankalp", ""], ["Draper", "Stark C.", ""], ["Fabbro", "Sebastien", ""], ["Mahoney", "William", ""], ["Prunet", "Simon", ""], ["Withington", "Kanoa", ""], ["Wilson", "Matthew", ""], ["Ting", "Yuan-Sen", ""], ["Sheinis", "Andrew", ""]]}, {"id": "2107.00051", "submitter": "Lichao Sun", "authors": "Wanning Pan, Lichao Sun", "title": "Global Knowledge Distillation in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation has caught a lot of attention in Federated Learning\n(FL) recently. It has the advantage for FL to train on heterogeneous clients\nwhich have different data size and data structure. However, data samples across\nall devices are usually not independent and identically distributed\n(non-i.i.d), posing additional challenges to the convergence and speed of\nfederated learning. As FL randomly asks the clients to join the training\nprocess and each client only learns from local non-i.i.d data, which makes\nlearning processing even slower. In order to solve this problem, an intuitive\nidea is using the global model to guide local training. In this paper, we\npropose a novel global knowledge distillation method, named FedGKD, which\nlearns the knowledge from past global models to tackle down the local bias\ntraining problem. By learning from global knowledge and consistent with current\nlocal models, FedGKD learns a global knowledge model in FL. To demonstrate the\neffectiveness of the proposed method, we conduct extensive experiments on\nvarious CV datasets (CIFAR-10/100) and settings (non-i.i.d data). The\nevaluation results show that FedGKD outperforms previous state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 18:14:24 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Pan", "Wanning", ""], ["Sun", "Lichao", ""]]}, {"id": "2107.00057", "submitter": "Xianzhi Du", "authors": "Xianzhi Du, Barret Zoph, Wei-Chih Hung, Tsung-Yi Lin", "title": "Simple Training Strategies and Model Scaling for Object Detection", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The speed-accuracy Pareto curve of object detection systems have advanced\nthrough a combination of better model architectures, training and inference\nmethods. In this paper, we methodically evaluate a variety of these techniques\nto understand where most of the improvements in modern detection systems come\nfrom. We benchmark these improvements on the vanilla ResNet-FPN backbone with\nRetinaNet and RCNN detectors. The vanilla detectors are improved by 7.7% in\naccuracy while being 30% faster in speed. We further provide simple scaling\nstrategies to generate family of models that form two Pareto curves, named\nRetinaNet-RS and Cascade RCNN-RS. These simple rescaled detectors explore the\nspeed-accuracy trade-off between the one-stage RetinaNet detectors and\ntwo-stage RCNN detectors. Our largest Cascade RCNN-RS models achieve 52.9% AP\nwith a ResNet152-FPN backbone and 53.6% with a SpineNet143L backbone. Finally,\nwe show the ResNet architecture, with three minor architectural changes,\noutperforms EfficientNet as the backbone for object detection and instance\nsegmentation systems.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 18:41:47 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Du", "Xianzhi", ""], ["Zoph", "Barret", ""], ["Hung", "Wei-Chih", ""], ["Lin", "Tsung-Yi", ""]]}, {"id": "2107.00082", "submitter": "Nuno Oliveira", "authors": "Nuno Oliveira, Norberto Sousa, Isabel Pra\\c{c}a", "title": "A Search Engine for Scientific Publications: a Cybersecurity Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cybersecurity is a very challenging topic of research nowadays, as\ndigitalization increases the interaction of people, software and services on\nthe Internet by means of technology devices and networks connected to it. The\nfield is broad and has a lot of unexplored ground under numerous disciplines\nsuch as management, psychology, and data science. Its large disciplinary\nspectrum and many significant research topics generate a considerable amount of\ninformation, making it hard for us to find what we are looking for when\nresearching a particular subject. This work proposes a new search engine for\nscientific publications which combines both information retrieval and reading\ncomprehension algorithms to extract answers from a collection of\ndomain-specific documents. The proposed solution although being applied to the\ncontext of cybersecurity exhibited great generalization capabilities and can be\neasily adapted to perform under other distinct knowledge domains.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 20:10:04 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Oliveira", "Nuno", ""], ["Sousa", "Norberto", ""], ["Pra\u00e7a", "Isabel", ""]]}, {"id": "2107.00100", "submitter": "Prateek Mishra", "authors": "Prateek Mishra, Kumar Divya Mani, Prashant Johri, Dikhsa Arya", "title": "FCMI: Feature Correlation based Missing Data Imputation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Processed data are insightful, and crude data are obtuse. A serious threat to\ndata reliability is missing values. Such data leads to inaccurate analysis and\nwrong predictions. We propose an efficient technique to impute the missing\nvalue in the dataset based on correlation called FCMI (Feature Correlation\nbased Missing Data Imputation). We have considered the correlation of the\nattributes of the dataset, and that is our central idea. Our proposed algorithm\npicks the highly correlated attributes of the dataset and uses these attributes\nto build a regression model whose parameters are optimized such that the\ncorrelation of the dataset is maintained. Experiments conducted on both\nclassification and regression datasets show that the proposed imputation\ntechnique outperforms existing imputation algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 13:35:33 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Mishra", "Prateek", ""], ["Mani", "Kumar Divya", ""], ["Johri", "Prashant", ""], ["Arya", "Dikhsa", ""]]}, {"id": "2107.00108", "submitter": "Murat Cubuktepe", "authors": "Murat Cubuktepe, Nils Jansen, Sebastian Junges, Joost-Pieter Katoen,\n  and Ufuk Topcu", "title": "Convex Optimization for Parameter Synthesis in MDPs", "comments": "Submitted to IEEE TAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic model checking aims to prove whether a Markov decision process\n(MDP) satisfies a temporal logic specification. The underlying methods rely on\nan often unrealistic assumption that the MDP is precisely known. Consequently,\nparametric MDPs (pMDPs) extend MDPs with transition probabilities that are\nfunctions over unspecified parameters. The parameter synthesis problem is to\ncompute an instantiation of these unspecified parameters such that the\nresulting MDP satisfies the temporal logic specification. We formulate the\nparameter synthesis problem as a quadratically constrained quadratic program\n(QCQP), which is nonconvex and is NP-hard to solve in general. We develop two\napproaches that iteratively obtain locally optimal solutions. The first\napproach exploits the so-called convex-concave procedure (CCP), and the second\napproach utilizes a sequential convex programming (SCP) method. The techniques\nimprove the runtime and scalability by multiple orders of magnitude compared to\nblack-box CCP and SCP by merging ideas from convex optimization and\nprobabilistic model checking. We demonstrate the approaches on a satellite\ncollision avoidance problem with hundreds of thousands of states and tens of\nthousands of parameters and their scalability on a wide range of commonly used\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 21:23:56 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Cubuktepe", "Murat", ""], ["Jansen", "Nils", ""], ["Junges", "Sebastian", ""], ["Katoen", "Joost-Pieter", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2107.00110", "submitter": "Masataro Asai", "authors": "Masataro Asai, Hiroshi Kajino, Alex Fukunaga, Christian Muise", "title": "Classical Planning in Deep Latent Space", "comments": "Under review at Journal of Artificial Intelligence Research (JAIR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current domain-independent, classical planners require symbolic models of the\nproblem domain and instance as input, resulting in a knowledge acquisition\nbottleneck. Meanwhile, although deep learning has achieved significant success\nin many fields, the knowledge is encoded in a subsymbolic representation which\nis incompatible with symbolic systems such as planners. We propose Latplan, an\nunsupervised architecture combining deep learning and classical planning. Given\nonly an unlabeled set of image pairs showing a subset of transitions allowed in\nthe environment (training inputs), Latplan learns a complete propositional PDDL\naction model of the environment. Later, when a pair of images representing the\ninitial and the goal states (planning inputs) is given, Latplan finds a plan to\nthe goal state in a symbolic latent space and returns a visualized plan\nexecution. We evaluate Latplan using image-based versions of 6 planning\ndomains: 8-puzzle, 15-Puzzle, Blocksworld, Sokoban and Two variations of\nLightsOut.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 21:31:21 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Asai", "Masataro", ""], ["Kajino", "Hiroshi", ""], ["Fukunaga", "Alex", ""], ["Muise", "Christian", ""]]}, {"id": "2107.00124", "submitter": "Ashwinkumar Ganesan", "authors": "Ashwinkumar Ganesan, Francis Ferraro, Tim Oates", "title": "Learning a Reversible Embedding Mapping using Bi-Directional Manifold\n  Alignment", "comments": null, "journal-ref": "Findings of the Association for Computational Linguistics: ACL\n  2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Bi-Directional Manifold Alignment (BDMA) that learns a\nnon-linear mapping between two manifolds by explicitly training it to be\nbijective. We demonstrate BDMA by training a model for a pair of languages\nrather than individual, directed source and target combinations, reducing the\nnumber of models by 50%. We show that models trained with BDMA in the \"forward\"\n(source to target) direction can successfully map words in the \"reverse\"\n(target to source) direction, yielding equivalent (or better) performance to\nstandard unidirectional translation models where the source and target language\nis flipped. We also show how BDMA reduces the overall size of the model.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 22:13:42 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Ganesan", "Ashwinkumar", ""], ["Ferraro", "Francis", ""], ["Oates", "Tim", ""]]}, {"id": "2107.00140", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge", "title": "Applications of the Free Energy Principle to Machine Learning and\n  Neuroscience", "comments": "30-06-21 initial upload", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this PhD thesis, we explore and apply methods inspired by the free energy\nprinciple to two important areas in machine learning and neuroscience. The free\nenergy principle is a general mathematical theory of the necessary\ninformation-theoretic behaviours of systems that maintain a separation from\ntheir environment. A core postulate of the theory is that complex systems can\nbe seen as performing variational Bayesian inference and minimizing an\ninformation-theoretic quantity called the variational free energy. The thesis\nis structured into three independent sections. Firstly, we focus on predictive\ncoding, a neurobiologically plausible process theory derived from the free\nenergy principle which argues that the primary function of the brain is to\nminimize prediction errors, showing how predictive coding can be scaled up and\nextended to be more biologically plausible, and elucidating its close links\nwith other methods such as Kalman Filtering. Secondly, we study active\ninference, a neurobiologically grounded account of action through variational\nmessage passing, and investigate how these methods can be scaled up to match\nthe performance of deep reinforcement learning methods. We additionally provide\na detailed mathematical understanding of the nature and origin of the\ninformation-theoretic objectives that underlie exploratory behaviour. Finally,\nwe investigate biologically plausible methods of credit assignment in the\nbrain. We first demonstrate a close link between predictive coding and the\nbackpropagation of error algorithm. We go on to propose novel and simpler\nalgorithms which allow for backprop to be implemented in purely local,\nbiologically plausible computations.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 22:53:03 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Millidge", "Beren", ""]]}, {"id": "2107.00156", "submitter": "Filip Ilievski", "authors": "Kartik Shenoy and Filip Ilievski and Daniel Garijo and Daniel Schwabe\n  and Pedro Szekely", "title": "A Study of the Quality of Wikidata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wikidata has been increasingly adopted by many communities for a wide variety\nof applications, which demand high-quality knowledge to deliver successful\nresults. In this paper, we develop a framework to detect and analyze\nlow-quality statements in Wikidata by shedding light on the current practices\nexercised by the community. We explore three indicators of data quality in\nWikidata, based on: 1) community consensus on the currently recorded knowledge,\nassuming that statements that have been removed and not added back are\nimplicitly agreed to be of low quality; 2) statements that have been\ndeprecated; and 3) constraint violations in the data. We combine these\nindicators to detect low-quality statements, revealing challenges with\nduplicate entities, missing triples, violated type rules, and taxonomic\ndistinctions. Our findings complement ongoing efforts by the Wikidata community\nto improve data quality, aiming to make it easier for users and editors to find\nand correct mistakes.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 00:19:02 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 15:50:35 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Shenoy", "Kartik", ""], ["Ilievski", "Filip", ""], ["Garijo", "Daniel", ""], ["Schwabe", "Daniel", ""], ["Szekely", "Pedro", ""]]}, {"id": "2107.00157", "submitter": "Bob Li", "authors": "Zhiming Li, Xiaofei Xie, Haoliang Li, Zhengzi Xu, Yi Li, Yang Liu", "title": "Cross-Lingual Adaptation for Type Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based techniques have been widely applied to the program\nanalysis tasks, in fields such as type inference, fault localization, and code\nsummarization. Hitherto deep learning-based software engineering systems rely\nthoroughly on supervised learning approaches, which require laborious manual\neffort to collect and label a prohibitively large amount of data. However, most\nTuring-complete imperative languages share similar control- and data-flow\nstructures, which make it possible to transfer knowledge learned from one\nlanguage to another. In this paper, we propose cross-lingual adaptation of\nprogram analysis, which allows us to leverage prior knowledge learned from the\nlabeled dataset of one language and transfer it to the others. Specifically, we\nimplemented a cross-lingual adaptation framework, PLATO, to transfer a deep\nlearning-based type inference procedure across weakly typed languages, e.g.,\nPython to JavaScript and vice versa. PLATO incorporates a novel joint graph\nkernelized attention based on abstract syntax tree and control flow graph, and\napplies anchor word augmentation across different languages. Besides, by\nleveraging data from strongly typed languages, PLATO improves the perplexity of\nthe backbone cross-programming-language model and the performance of downstream\ncross-lingual transfer for type inference. Experimental results illustrate that\nour framework significantly improves the transferability over the baseline\nmethod by a large margin.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 00:20:24 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Li", "Zhiming", ""], ["Xie", "Xiaofei", ""], ["Li", "Haoliang", ""], ["Xu", "Zhengzi", ""], ["Li", "Yi", ""], ["Liu", "Yang", ""]]}, {"id": "2107.00161", "submitter": "Qing Wang", "authors": "Qing Wang", "title": "The Use of Bandit Algorithms in Intelligent Interactive Recommender\n  Systems", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's business marketplace, many high-tech Internet enterprises\nconstantly explore innovative ways to provide optimal online user experiences\nfor gaining competitive advantages. The great needs of developing intelligent\ninteractive recommendation systems are indicated, which could sequentially\nsuggest users the most proper items by accurately predicting their preferences,\nwhile receiving the up-to-date feedback to refine the recommendation results,\ncontinuously. Multi-armed bandit algorithms, which have been widely applied\ninto various online systems, are quite capable of delivering such efficient\nrecommendation services. However, few existing bandit models are able to adapt\nto new changes introduced by the modern recommender systems.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 00:43:05 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Wang", "Qing", ""]]}, {"id": "2107.00166", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Geng Yuan, Xuan Shen, Tianlong Chen, Xuxi Chen, Xiaohan\n  Chen, Ning Liu, Minghai Qin, Sijia Liu, Zhangyang Wang, Yanzhi Wang", "title": "Sanity Checks for Lottery Tickets: Does Your Winning Ticket Really Win\n  the Jackpot?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There have been long-standing controversies and inconsistencies over the\nexperiment setup and criteria for identifying the \"winning ticket\" in\nliterature. To reconcile such, we revisit the definition of lottery ticket\nhypothesis, with comprehensive and more rigorous conditions. Under our new\ndefinition, we show concrete evidence to clarify whether the winning ticket\nexists across the major DNN architectures and/or applications. Through\nextensive experiments, we perform quantitative analysis on the correlations\nbetween winning tickets and various experimental factors, and empirically study\nthe patterns of our observations. We find that the key training\nhyperparameters, such as learning rate and training epochs, as well as the\narchitecture characteristics such as capacities and residual connections, are\nall highly correlated with whether and when the winning tickets can be\nidentified. Based on our analysis, we summarize a guideline for parameter\nsettings in regards of specific architecture characteristics, which we hope to\ncatalyze the research progress on the topic of lottery ticket hypothesis.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 01:27:07 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Ma", "Xiaolong", ""], ["Yuan", "Geng", ""], ["Shen", "Xuan", ""], ["Chen", "Tianlong", ""], ["Chen", "Xuxi", ""], ["Chen", "Xiaohan", ""], ["Liu", "Ning", ""], ["Qin", "Minghai", ""], ["Liu", "Sijia", ""], ["Wang", "Zhangyang", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2107.00181", "submitter": "Zhen Huang", "authors": "Zhen Huang, Xu Shen, Jun Xing, Tongliang Liu, Xinmei Tian, Houqiang\n  Li, Bing Deng, Jianqiang Huang and Xian-Sheng Hua", "title": "Revisiting Knowledge Distillation: An Inheritance and Exploration\n  Framework", "comments": "Accepted by CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge Distillation (KD) is a popular technique to transfer knowledge from\na teacher model or ensemble to a student model. Its success is generally\nattributed to the privileged information on similarities/consistency between\nthe class distributions or intermediate feature representations of the teacher\nmodel and the student model. However, directly pushing the student model to\nmimic the probabilities/features of the teacher model to a large extent limits\nthe student model in learning undiscovered knowledge/features. In this paper,\nwe propose a novel inheritance and exploration knowledge distillation framework\n(IE-KD), in which a student model is split into two parts - inheritance and\nexploration. The inheritance part is learned with a similarity loss to transfer\nthe existing learned knowledge from the teacher model to the student model,\nwhile the exploration part is encouraged to learn representations different\nfrom the inherited ones with a dis-similarity loss. Our IE-KD framework is\ngeneric and can be easily combined with existing distillation or mutual\nlearning methods for training deep neural networks. Extensive experiments\ndemonstrate that these two parts can jointly push the student model to learn\nmore diversified and effective representations, and our IE-KD can be a general\ntechnique to improve the student network to achieve SOTA performance.\nFurthermore, by applying our IE-KD to the training of two networks, the\nperformance of both can be improved w.r.t. deep mutual learning. The code and\nmodels of IE-KD will be make publicly available at\nhttps://github.com/yellowtownhz/IE-KD.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 02:20:56 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Huang", "Zhen", ""], ["Shen", "Xu", ""], ["Xing", "Jun", ""], ["Liu", "Tongliang", ""], ["Tian", "Xinmei", ""], ["Li", "Houqiang", ""], ["Deng", "Bing", ""], ["Huang", "Jianqiang", ""], ["Hua", "Xian-Sheng", ""]]}, {"id": "2107.00184", "submitter": "Yongqi Zhang", "authors": "Yongqi Zhang and Zhanke Zhou and Quanming Yao", "title": "AutoSF+: Towards Automatic Scoring Function Design for Knowledge Graph\n  Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scoring functions, which measure the plausibility of triples, have become the\ncrux of knowledge graph embedding (KGE). Plenty of scoring functions, targeting\nat capturing different kinds of relations in KGs, have been designed by experts\nin recent years. However, as relations can exhibit intricate patterns that are\nhard to infer before training, none of them can consistently perform the best\non existing benchmark tasks. AutoSF has shown the significance of using\nautomated machine learning (AutoML) to design KG- dependent scoring functions.\nIn this paper, we propose AutoSF+ as an extension of AutoSF. First, we improve\nthe search algorithm with the evolutionary search, which can better explore the\nsearch space. Second, we evaluate AutoSF+ on the recently developed benchmark\nOGB. Besides, we apply AutoSF+ to the new task, i.e., entity classification, to\nshow that it can improve the task beyond KG completion.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 02:28:23 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Zhang", "Yongqi", ""], ["Zhou", "Zhanke", ""], ["Yao", "Quanming", ""]]}, {"id": "2107.00187", "submitter": "Marco Netto", "authors": "Renato L. F. Cunha, Lucas V. Real, Renan Souza, Bruno Silva, Marco A.\n  S. Netto", "title": "Context-aware Execution Migration Tool for Data Science Jupyter\n  Notebooks on Hybrid Clouds", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive computing notebooks, such as Jupyter notebooks, have become a\npopular tool for developing and improving data-driven models. Such notebooks\ntend to be executed either in the user's own machine or in a cloud environment,\nhaving drawbacks and benefits in both approaches. This paper presents a\nsolution developed as a Jupyter extension that automatically selects which\ncells, as well as in which scenarios, such cells should be migrated to a more\nsuitable platform for execution. We describe how we reduce the execution state\nof the notebook to decrease migration time and we explore the knowledge of user\ninteractivity patterns with the notebook to determine which blocks of cells\nshould be migrated. Using notebooks from Earth science (remote sensing), image\nrecognition, and hand written digit identification (machine learning), our\nexperiments show notebook state reductions of up to 55x and migration decisions\nleading to performance gains of up to 3.25x when the user interactivity with\nthe notebook is taken into consideration.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 02:33:18 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Cunha", "Renato L. F.", ""], ["Real", "Lucas V.", ""], ["Souza", "Renan", ""], ["Silva", "Bruno", ""], ["Netto", "Marco A. S.", ""]]}, {"id": "2107.00197", "submitter": "Wei-Lun Chao", "authors": "Han-Jia Ye, Lu Ming, De-Chuan Zhan, Wei-Lun Chao", "title": "Few-Shot Learning with a Strong Teacher", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Few-shot learning (FSL) aims to train a strong classifier using limited\nlabeled examples. Many existing works take the meta-learning approach, sampling\nfew-shot tasks in turn and optimizing the few-shot learner's performance on\nclassifying the query examples. In this paper, we point out two potential\nweaknesses of this approach. First, the sampled query examples may not provide\nsufficient supervision for the few-shot learner. Second, the effectiveness of\nmeta-learning diminishes sharply with increasing shots (i.e., the number of\ntraining examples per class). To resolve these issues, we propose a novel\nobjective to directly train the few-shot learner to perform like a strong\nclassifier. Concretely, we associate each sampled few-shot task with a strong\nclassifier, which is learned with ample labeled examples. The strong classifier\nhas a better generalization ability and we use it to supervise the few-shot\nlearner. We present an efficient way to construct the strong classifier, making\nour proposed objective an easily plug-and-play term to existing meta-learning\nbased FSL methods. We validate our approach in combinations with many\nrepresentative meta-learning methods. On several benchmark datasets including\nminiImageNet and tiredImageNet, our approach leads to a notable improvement\nacross a variety of tasks. More importantly, with our approach, meta-learning\nbased FSL methods can consistently outperform non-meta-learning based ones,\neven in a many-shot setting, greatly strengthening their applicability.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 03:20:46 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Ye", "Han-Jia", ""], ["Ming", "Lu", ""], ["Zhan", "De-Chuan", ""], ["Chao", "Wei-Lun", ""]]}, {"id": "2107.00229", "submitter": "Yonghao Long", "authors": "Yonghao Long, Zhaoshuo Li, Chi Hang Yee, Chi Fai Ng, Russell H.\n  Taylor, Mathias Unberath, Qi Dou", "title": "E-DSSR: Efficient Dynamic Surgical Scene Reconstruction with\n  Transformer-based Stereoscopic Depth Perception", "comments": "Accepted to MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstructing the scene of robotic surgery from the stereo endoscopic video\nis an important and promising topic in surgical data science, which potentially\nsupports many applications such as surgical visual perception, robotic surgery\neducation and intra-operative context awareness. However, current methods are\nmostly restricted to reconstructing static anatomy assuming no tissue\ndeformation, tool occlusion and de-occlusion, and camera movement. However,\nthese assumptions are not always satisfied in minimal invasive robotic\nsurgeries. In this work, we present an efficient reconstruction pipeline for\nhighly dynamic surgical scenes that runs at 28 fps. Specifically, we design a\ntransformer-based stereoscopic depth perception for efficient depth estimation\nand a light-weight tool segmentor to handle tool occlusion. After that, a\ndynamic reconstruction algorithm which can estimate the tissue deformation and\ncamera movement, and aggregate the information over time is proposed for\nsurgical scene reconstruction. We evaluate the proposed pipeline on two\ndatasets, the public Hamlyn Centre Endoscopic Video Dataset and our in-house\nDaVinci robotic surgery dataset. The results demonstrate that our method can\nrecover the scene obstructed by the surgical tool and handle the movement of\ncamera in realistic surgical scenarios effectively at real-time speed.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 05:57:41 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Long", "Yonghao", ""], ["Li", "Zhaoshuo", ""], ["Yee", "Chi Hang", ""], ["Ng", "Chi Fai", ""], ["Taylor", "Russell H.", ""], ["Unberath", "Mathias", ""], ["Dou", "Qi", ""]]}, {"id": "2107.00233", "submitter": "Tehrim Yoon", "authors": "Tehrim Yoon, Sumin Shin, Sung Ju Hwang, Eunho Yang", "title": "FedMix: Approximation of Mixup under Mean Augmented Federated Learning", "comments": null, "journal-ref": "ICLR 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) allows edge devices to collectively learn a model\nwithout directly sharing data within each device, thus preserving privacy and\neliminating the need to store data globally. While there are promising results\nunder the assumption of independent and identically distributed (iid) local\ndata, current state-of-the-art algorithms suffer from performance degradation\nas the heterogeneity of local data across clients increases. To resolve this\nissue, we propose a simple framework, Mean Augmented Federated Learning (MAFL),\nwhere clients send and receive averaged local data, subject to the privacy\nrequirements of target applications. Under our framework, we propose a new\naugmentation algorithm, named FedMix, which is inspired by a phenomenal yet\nsimple data augmentation method, Mixup, but does not require local raw data to\nbe directly shared among devices. Our method shows greatly improved performance\nin the standard benchmark datasets of FL, under highly non-iid federated\nsettings, compared to conventional algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 06:14:51 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Yoon", "Tehrim", ""], ["Shin", "Sumin", ""], ["Hwang", "Sung Ju", ""], ["Yang", "Eunho", ""]]}, {"id": "2107.00238", "submitter": "Hieu Nguyen", "authors": "Nguyen Quang Hieu, Dinh Thai Hoang, Dusit Niyato, and Dong In Kim", "title": "Optimal Power Allocation for Rate Splitting Communications with Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.NI math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This letter introduces a novel framework to optimize the power allocation for\nusers in a Rate Splitting Multiple Access (RSMA) network. In the network,\nmessages intended for users are split into different parts that are a single\ncommon part and respective private parts. This mechanism enables RSMA to\nflexibly manage interference and thus enhance energy and spectral efficiency.\nAlthough possessing outstanding advantages, optimizing power allocation in RSMA\nis very challenging under the uncertainty of the communication channel and the\ntransmitter has limited knowledge of the channel information. To solve the\nproblem, we first develop a Markov Decision Process framework to model the\ndynamic of the communication channel. The deep reinforcement algorithm is then\nproposed to find the optimal power allocation policy for the transmitter\nwithout requiring any prior information of the channel. The simulation results\nshow that the proposed scheme can outperform baseline schemes in terms of\naverage sum-rate under different power and QoS requirements.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 06:32:49 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Hieu", "Nguyen Quang", ""], ["Hoang", "Dinh Thai", ""], ["Niyato", "Dusit", ""], ["Kim", "Dong In", ""]]}, {"id": "2107.00247", "submitter": "Mohammad Hossein Rohban", "authors": "Alireza Mousavi Hosseini, Amir Mohammad Abouei, Mohammad Hossein\n  Rohban", "title": "The Interplay between Distribution Parameters and the\n  Accuracy-Robustness Tradeoff in Classification", "comments": "Accepted for presentation in AML ICML workshop 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial training tends to result in models that are less accurate on\nnatural (unperturbed) examples compared to standard models. This can be\nattributed to either an algorithmic shortcoming or a fundamental property of\nthe training data distribution, which admits different solutions for optimal\nstandard and adversarial classifiers. In this work, we focus on the latter case\nunder a binary Gaussian mixture classification problem. Unlike earlier work, we\naim to derive the natural accuracy gap between the optimal Bayes and\nadversarial classifiers, and study the effect of different distributional\nparameters, namely separation between class centroids, class proportions, and\nthe covariance matrix, on the derived gap. We show that under certain\nconditions, the natural error of the optimal adversarial classifier, as well as\nthe gap, are locally minimized when classes are balanced, contradicting the\nperformance of the Bayes classifier where perfect balance induces the worst\naccuracy. Moreover, we show that with an $\\ell_\\infty$ bounded perturbation and\nan adversarial budget of $\\epsilon$, this gap is $\\Theta(\\epsilon^2)$ for the\nworst-case parameters, which for suitably small $\\epsilon$ indicates the\ntheoretical possibility of achieving robust classifiers with near-perfect\naccuracy, which is rarely reflected in practical algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 06:57:50 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Hosseini", "Alireza Mousavi", ""], ["Abouei", "Amir Mohammad", ""], ["Rohban", "Mohammad Hossein", ""]]}, {"id": "2107.00306", "submitter": "Rui Yang", "authors": "Rui Yang, Meng Fang, Lei Han, Yali Du, Feng Luo, Xiu Li", "title": "MHER: Model-based Hindsight Experience Replay", "comments": "18 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving multi-goal reinforcement learning (RL) problems with sparse rewards\nis generally challenging. Existing approaches have utilized goal relabeling on\ncollected experiences to alleviate issues raised from sparse rewards. However,\nthese methods are still limited in efficiency and cannot make full use of\nexperiences. In this paper, we propose Model-based Hindsight Experience Replay\n(MHER), which exploits experiences more efficiently by leveraging environmental\ndynamics to generate virtual achieved goals. Replacing original goals with\nvirtual goals generated from interaction with a trained dynamics model leads to\na novel relabeling method, \\emph{model-based relabeling} (MBR). Based on MBR,\nMHER performs both reinforcement learning and supervised learning for efficient\npolicy improvement. Theoretically, we also prove the supervised part in MHER,\ni.e., goal-conditioned supervised learning with MBR data, optimizes a lower\nbound on the multi-goal RL objective. Experimental results in several\npoint-based tasks and simulated robotics environments show that MHER achieves\nsignificantly higher sample efficiency than previous state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 08:52:45 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Yang", "Rui", ""], ["Fang", "Meng", ""], ["Han", "Lei", ""], ["Du", "Yali", ""], ["Luo", "Feng", ""], ["Li", "Xiu", ""]]}, {"id": "2107.00315", "submitter": "Neeraj Varshney", "authors": "Neeraj Varshney, Swaroop Mishra, Chitta Baral", "title": "Interviewer-Candidate Role Play: Towards Developing Real-World NLP\n  Systems", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard NLP tasks do not incorporate several common real-world scenarios\nsuch as seeking clarifications about the question, taking advantage of clues,\nabstaining in order to avoid incorrect answers, etc. This difference in task\nformulation hinders the adoption of NLP systems in real-world settings. In this\nwork, we take a step towards bridging this gap and present a multi-stage task\nthat simulates a typical human-human questioner-responder interaction such as\nan interview. Specifically, the system is provided with question\nsimplifications, knowledge statements, examples, etc. at various stages to\nimprove its prediction when it is not sufficiently confident. We instantiate\nthe proposed task in Natural Language Inference setting where a system is\nevaluated on both in-domain and out-of-domain (OOD) inputs. We conduct\ncomprehensive experiments and find that the multi-stage formulation of our task\nleads to OOD generalization performance improvement up to 2.29% in Stage 1,\n1.91% in Stage 2, 54.88% in Stage 3, and 72.02% in Stage 4 over the standard\nunguided prediction. However, our task leaves a significant challenge for NLP\nresearchers to further improve OOD performance at each stage.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 09:08:43 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Varshney", "Neeraj", ""], ["Mishra", "Swaroop", ""], ["Baral", "Chitta", ""]]}, {"id": "2107.00316", "submitter": "Danqing Zhu", "authors": "Qiwei Zhong, Guanxiong Zeng, Danqing Zhu, Yang Zhang, Wangli Lin, Ben\n  Chen, Jiayu Tang", "title": "Leveraging Domain Agnostic and Specific Knowledge for Acronym\n  Disambiguation", "comments": "Second Place Solution, Accepted to SDU@AAAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An obstacle to scientific document understanding is the extensive use of\nacronyms which are shortened forms of long technical phrases. Acronym\ndisambiguation aims to find the correct meaning of an ambiguous acronym in a\ngiven text. Recent efforts attempted to incorporate word embeddings and deep\nlearning architectures, and achieved significant effects in this task. In\ngeneral domains, kinds of fine-grained pretrained language models have sprung\nup, thanks to the largescale corpora which can usually be obtained through\ncrowdsourcing. However, these models based on domain agnostic knowledge might\nachieve insufficient performance when directly applied to the scientific\ndomain. Moreover, obtaining large-scale high-quality annotated data and\nrepresenting high-level semantics in the scientific domain is challenging and\nexpensive. In this paper, we consider both the domain agnostic and specific\nknowledge, and propose a Hierarchical Dual-path BERT method coined hdBERT to\ncapture the general fine-grained and high-level specific representations for\nacronym disambiguation. First, the context-based pretrained models, RoBERTa and\nSciBERT, are elaborately involved in encoding these two kinds of knowledge\nrespectively. Second, multiple layer perceptron is devised to integrate the\ndualpath representations simultaneously and outputs the prediction. With a\nwidely adopted SciAD dataset contained 62,441 sentences, we investigate the\neffectiveness of hdBERT. The experimental results exhibit that the proposed\napproach outperforms state-of-the-art methods among various evaluation metrics.\nSpecifically, its macro F1 achieves 93.73%.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 09:10:00 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Zhong", "Qiwei", ""], ["Zeng", "Guanxiong", ""], ["Zhu", "Danqing", ""], ["Zhang", "Yang", ""], ["Lin", "Wangli", ""], ["Chen", "Ben", ""], ["Tang", "Jiayu", ""]]}, {"id": "2107.00317", "submitter": "Fredrik Pr\\\"antare", "authors": "Fredrik Pr\\\"antare, Mattias Tiger, David Bergstr\\\"om, Herman\n  Appelgren, Fredrik Heintz", "title": "Towards Utilitarian Combinatorial Assignment with Deep Neural Networks\n  and Heuristic Algorithms", "comments": "7 pages, 4 figures, presented at the ECAI 2020 TAILOR workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents preliminary work on using deep neural networks to guide\ngeneral-purpose heuristic algorithms for performing utilitarian combinatorial\nassignment. In more detail, we use deep learning in an attempt to produce\nheuristics that can be used together with e.g., search algorithms to generate\nfeasible solutions of higher quality more quickly. Our results indicate that\nour approach could be a promising future method for constructing such\nheuristics.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 09:15:20 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Pr\u00e4ntare", "Fredrik", ""], ["Tiger", "Mattias", ""], ["Bergstr\u00f6m", "David", ""], ["Appelgren", "Herman", ""], ["Heintz", "Fredrik", ""]]}, {"id": "2107.00339", "submitter": "Grace Zhang", "authors": "Grace Zhang, Linghan Zhong, Youngwoon Lee, Joseph J. Lim", "title": "Policy Transfer across Visual and Dynamics Domain Gaps via Iterative\n  Grounding", "comments": "Robotics: Science and Systems (RSS), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to transfer a policy from one environment to another is a\npromising avenue for efficient robot learning in realistic settings where task\nsupervision is not available. This can allow us to take advantage of\nenvironments well suited for training, such as simulators or laboratories, to\nlearn a policy for a real robot in a home or office. To succeed, such policy\ntransfer must overcome both the visual domain gap (e.g. different illumination\nor background) and the dynamics domain gap (e.g. different robot calibration or\nmodelling error) between source and target environments. However, prior policy\ntransfer approaches either cannot handle a large domain gap or can only address\none type of domain gap at a time. In this paper, we propose a novel policy\ntransfer method with iterative \"environment grounding\", IDAPT, that alternates\nbetween (1) directly minimizing both visual and dynamics domain gaps by\ngrounding the source environment in the target environment domains, and (2)\ntraining a policy on the grounded source environment. This iterative training\nprogressively aligns the domains between the two environments and adapts the\npolicy to the target environment. Once trained, the policy can be directly\nexecuted on the target environment. The empirical results on locomotion and\nrobotic manipulation tasks demonstrate that our approach can effectively\ntransfer a policy across visual and dynamics domain gaps with minimal\nsupervision and interaction with the target environment. Videos and code are\navailable at https://clvrai.com/idapt .\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 10:09:59 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Zhang", "Grace", ""], ["Zhong", "Linghan", ""], ["Lee", "Youngwoon", ""], ["Lim", "Joseph J.", ""]]}, {"id": "2107.00359", "submitter": "Hadi Beik-Mohammadi", "authors": "Hadi Beik-Mohammadi, Matthias Kerzel, Benedikt Pleintinger, Thomas\n  Hulin, Philipp Reisich, Annika Schmidt, Aaron Pereira, Stefan Wermter, Neal\n  Y. Lii", "title": "Model Mediated Teleoperation with a Hand-Arm Exoskeleton in Long Time\n  Delays Using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Telerobotic systems must adapt to new environmental conditions and deal with\nhigh uncertainty caused by long-time delays. As one of the best alternatives to\nhuman-level intelligence, Reinforcement Learning (RL) may offer a solution to\ncope with these issues. This paper proposes to integrate RL with the Model\nMediated Teleoperation (MMT) concept. The teleoperator interacts with a\nsimulated virtual environment, which provides instant feedback. Whereas\nfeedback from the real environment is delayed, feedback from the model is\ninstantaneous, leading to high transparency. The MMT is realized in combination\nwith an intelligent system with two layers. The first layer utilizes Dynamic\nMovement Primitives (DMP) which accounts for certain changes in the avatar\nenvironment. And, the second layer addresses the problems caused by uncertainty\nin the model using RL methods. Augmented reality was also provided to fuse the\navatar device and virtual environment models for the teleoperator. Implemented\non DLR's Exodex Adam hand-arm haptic exoskeleton, the results show RL methods\nare able to find different solutions when changes are applied to the object\nposition after the demonstration. The results also show DMPs to be effective at\nadapting to new conditions where there is no uncertainty involved.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 10:49:55 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Beik-Mohammadi", "Hadi", ""], ["Kerzel", "Matthias", ""], ["Pleintinger", "Benedikt", ""], ["Hulin", "Thomas", ""], ["Reisich", "Philipp", ""], ["Schmidt", "Annika", ""], ["Pereira", "Aaron", ""], ["Wermter", "Stefan", ""], ["Lii", "Neal Y.", ""]]}, {"id": "2107.00369", "submitter": "Federico Igne", "authors": "Federico Igne, Stefano Germano, Ian Horrocks", "title": "Computing CQ lower-bounds over OWL 2 through approximation to RSA", "comments": "26 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conjunctive query (CQ) answering over knowledge bases is an important\nreasoning task. However, with expressive ontology languages such as OWL, query\nanswering is computationally very expensive. The PAGOdA system addresses this\nissue by using a tractable reasoner to compute lower and upper-bound\napproximations, falling back to a fully-fledged OWL reasoner only when these\nbounds don't coincide. The effectiveness of this approach critically depends on\nthe quality of the approximations, and in this paper we explore a technique for\ncomputing closer approximations via RSA, an ontology language that subsumes all\nthe OWL 2 profiles while still maintaining tractability. We present a novel\napproximation of OWL 2 ontologies into RSA, and an algorithm to compute a\ncloser (than PAGOdA) lower bound approximation using the RSA combined approach.\nWe have implemented these algorithms in a prototypical CQ answering system, and\nwe present a preliminary evaluation of our system that shows significant\nperformance improvements w.r.t. PAGOdA.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 11:13:00 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Igne", "Federico", ""], ["Germano", "Stefano", ""], ["Horrocks", "Ian", ""]]}, {"id": "2107.00376", "submitter": "Francisco Mart\\'in-Rico", "authors": "Francisco Mart\\'in, Jonatan Gin\\'es, Vicente Matell\\'an and Francisco\n  J. Rodr\\'iguez", "title": "PlanSys2: A Planning System Framework for ROS2", "comments": "Preprint of the accepted paper at 2021 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Autonomous robots need to plan the tasks they carry out to fulfill their\nmissions. The missions' increasing complexity does not let human designers\nanticipate all the possible situations, so traditional control systems based on\nstate machines are not enough. This paper contains a description of the ROS2\nPlanning System (PlanSys2 in short), a framework for symbolic planning that\nincorporates novel approaches for execution on robots working in demanding\nenvironments. PlanSys2 aims to be the reference task planning framework in\nROS2, the latest version of the {\\em de facto} standard in robotics software\ndevelopment. Among its main features, it can be highlighted the optimized\nexecution, based on Behavior Trees, of plans through a new actions auction\nprotocol and its multi-robot planning capabilities. It already has a small but\ngrowing community of users and developers, and this document is a summary of\nthe design and capabilities of this project.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 11:24:44 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Mart\u00edn", "Francisco", ""], ["Gin\u00e9s", "Jonatan", ""], ["Matell\u00e1n", "Vicente", ""], ["Rodr\u00edguez", "Francisco J.", ""]]}, {"id": "2107.00378", "submitter": "Jan-Hendrik Lorenz", "authors": "Florian W\\\"orz and Jan-Hendrik Lorenz", "title": "Evidence for Long-Tails in SLS Algorithms", "comments": "To appear at ESA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic local search (SLS) is a successful paradigm for solving the\nsatisfiability problem of propositional logic. A recent development in this\narea involves solving not the original instance, but a modified, yet logically\nequivalent one. Empirically, this technique was found to be promising as it\nimproves the performance of state-of-the-art SLS solvers.\n  Currently, there is only a shallow understanding of how this modification\ntechnique affects the runtimes of SLS solvers. Thus, we model this modification\nprocess and conduct an empirical analysis of the hardness of logically\nequivalent formulas. Our results are twofold. First, if the modification\nprocess is treated as a random process, a lognormal distribution perfectly\ncharacterizes the hardness; implying that the hardness is long-tailed. This\nmeans that the modification technique can be further improved by implementing\nan additional restart mechanism. Thus, as a second contribution, we\ntheoretically prove that all algorithms exhibiting this long-tail property can\nbe further improved by restarts. Consequently, all SAT solvers employing this\nmodification technique can be enhanced.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 11:31:39 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["W\u00f6rz", "Florian", ""], ["Lorenz", "Jan-Hendrik", ""]]}, {"id": "2107.00395", "submitter": "Baotian Hu", "authors": "Yunxin Li, Yu Zhao, Baotian Hu, Qingcai Chen, Yang Xiang, Xiaolong\n  Wang, Yuxin Ding, Lin Ma", "title": "GlyphCRM: Bidirectional Encoder Representation for Chinese Character\n  with its Glyph", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous works indicate that the glyph of Chinese characters contains rich\nsemantic information and has the potential to enhance the representation of\nChinese characters. The typical method to utilize the glyph features is by\nincorporating them into the character embedding space. Inspired by previous\nmethods, we innovatively propose a Chinese pre-trained representation model\nnamed as GlyphCRM, which abandons the ID-based character embedding method yet\nsolely based on sequential character images. We render each character into a\nbinary grayscale image and design two-channel position feature maps for it.\nFormally, we first design a two-layer residual convolutional neural network,\nnamely HanGlyph to generate the initial glyph representation of Chinese\ncharacters, and subsequently adopt multiple bidirectional encoder Transformer\nblocks as the superstructure to capture the context-sensitive information.\nMeanwhile, we feed the glyph features extracted from each layer of the HanGlyph\nmodule into the underlying Transformer blocks by skip-connection method to\nfully exploit the glyph features of Chinese characters. As the HanGlyph module\ncan obtain a sufficient glyph representation of any Chinese character, the\nlong-standing out-of-vocabulary problem could be effectively solved. Extensive\nexperimental results indicate that GlyphCRM substantially outperforms the\nprevious BERT-based state-of-the-art model on 9 fine-tuning tasks, and it has\nstrong transferability and generalization on specialized fields and\nlow-resource tasks. We hope this work could spark further research beyond the\nrealms of well-established representation of Chinese texts.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 12:14:05 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Li", "Yunxin", ""], ["Zhao", "Yu", ""], ["Hu", "Baotian", ""], ["Chen", "Qingcai", ""], ["Xiang", "Yang", ""], ["Wang", "Xiaolong", ""], ["Ding", "Yuxin", ""], ["Ma", "Lin", ""]]}, {"id": "2107.00425", "submitter": "Alejandro Morales-Hern\\'andez", "authors": "Alejandro Morales-Hern\\'andez, Gonzalo N\\'apoles, Agnieszka\n  Jastrzebska, Yamisleydi Salgueiro, Koen Vanhoof", "title": "Online learning of windmill time series using Long Short-term Cognitive\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Forecasting windmill time series is often the basis of other processes such\nas anomaly detection, health monitoring, or maintenance scheduling. The amount\nof data generated on windmill farms makes online learning the most viable\nstrategy to follow. Such settings require retraining the model each time a new\nbatch of data is available. However, update the model with the new information\nis often very expensive to perform using traditional Recurrent Neural Networks\n(RNNs). In this paper, we use Long Short-term Cognitive Networks (LSTCNs) to\nforecast windmill time series in online settings. These recently introduced\nneural systems consist of chained Short-term Cognitive Network blocks, each\nprocessing a temporal data chunk. The learning algorithm of these blocks is\nbased on a very fast, deterministic learning rule that makes LSTCNs suitable\nfor online learning tasks. The numerical simulations using a case study with\nfour windmills showed that our approach reported the lowest forecasting errors\nwith respect to a simple RNN, a Long Short-term Memory, a Gated Recurrent Unit,\nand a Hidden Markov Model. What is perhaps more important is that the LSTCN\napproach is significantly faster than these state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 13:13:24 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Morales-Hern\u00e1ndez", "Alejandro", ""], ["N\u00e1poles", "Gonzalo", ""], ["Jastrzebska", "Agnieszka", ""], ["Salgueiro", "Yamisleydi", ""], ["Vanhoof", "Koen", ""]]}, {"id": "2107.00436", "submitter": "Erik Larsen", "authors": "Erik Larsen, David Noever, Korey MacVittie and John Lilly", "title": "Overhead-MNIST: Machine Learning Baselines for Image Classification", "comments": "6 pages; 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Twenty-three machine learning algorithms were trained then scored to\nestablish baseline comparison metrics and to select an image classification\nalgorithm worthy of embedding into mission-critical satellite imaging systems.\nThe Overhead-MNIST dataset is a collection of satellite images similar in style\nto the ubiquitous MNIST hand-written digits found in the machine learning\nliterature. The CatBoost classifier, Light Gradient Boosting Machine, and\nExtreme Gradient Boosting models produced the highest accuracies, Areas Under\nthe Curve (AUC), and F1 scores in a PyCaret general comparison. Separate\nevaluations showed that a deep convolutional architecture was the most\npromising. We present results for the overall best performing algorithm as a\nbaseline for edge deployability and future performance improvement: a\nconvolutional neural network (CNN) scoring 0.965 categorical accuracy on unseen\ntest data.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 13:30:39 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Larsen", "Erik", ""], ["Noever", "David", ""], ["MacVittie", "Korey", ""], ["Lilly", "John", ""]]}, {"id": "2107.00440", "submitter": "Piji Li", "authors": "Dong Wang, Ning Ding, Piji Li, Hai-Tao Zheng", "title": "CLINE: Contrastive Learning with Semantic Negative Examples for Natural\n  Language Understanding", "comments": "ACL 2021, Main Conference, Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite pre-trained language models have proven useful for learning\nhigh-quality semantic representations, these models are still vulnerable to\nsimple perturbations. Recent works aimed to improve the robustness of\npre-trained models mainly focus on adversarial training from perturbed examples\nwith similar semantics, neglecting the utilization of different or even\nopposite semantics. Different from the image processing field, the text is\ndiscrete and few word substitutions can cause significant semantic changes. To\nstudy the impact of semantics caused by small perturbations, we conduct a\nseries of pilot experiments and surprisingly find that adversarial training is\nuseless or even harmful for the model to detect these semantic changes. To\naddress this problem, we propose Contrastive Learning with semantIc Negative\nExamples (CLINE), which constructs semantic negative examples unsupervised to\nimprove the robustness under semantically adversarial attacking. By comparing\nwith similar and opposite semantic examples, the model can effectively perceive\nthe semantic changes caused by small perturbations. Empirical results show that\nour approach yields substantial improvements on a range of sentiment analysis,\nreasoning, and reading comprehension tasks. And CLINE also ensures the\ncompactness within the same semantics and separability across different\nsemantics in sentence-level.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 13:34:12 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Wang", "Dong", ""], ["Ding", "Ning", ""], ["Li", "Piji", ""], ["Zheng", "Hai-Tao", ""]]}, {"id": "2107.00456", "submitter": "Xiaotian Lu", "authors": "Xiaotian Lu, Arseny Tolmachev, Tatsuya Yamamoto, Koh Takeuchi, Seiji\n  Okajima, Tomoyoshi Takebayashi, Koji Maruhashi, Hisashi Kashima", "title": "Crowdsourcing Evaluation of Saliency-based XAI Methods", "comments": "16 pages, 7 figures, 2 tables, Accepted for ECML-PKDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding the reasons behind the predictions made by deep neural networks\nis critical for gaining human trust in many important applications, which is\nreflected in the increasing demand for explainability in AI (XAI) in recent\nyears. Saliency-based feature attribution methods, which highlight important\nparts of images that contribute to decisions by classifiers, are often used as\nXAI methods, especially in the field of computer vision. In order to compare\nvarious saliency-based XAI methods quantitatively, several approaches for\nautomated evaluation schemes have been proposed; however, there is no guarantee\nthat such automated evaluation metrics correctly evaluate explainability, and a\nhigh rating by an automated evaluation scheme does not necessarily mean a high\nexplainability for humans. In this study, instead of the automated evaluation,\nwe propose a new human-based evaluation scheme using crowdsourcing to evaluate\nXAI methods. Our method is inspired by a human computation game, \"Peek-a-boom\",\nand can efficiently compare different XAI methods by exploiting the power of\ncrowds. We evaluate the saliency maps of various XAI methods on two datasets\nwith automated and crowd-based evaluation schemes. Our experiments show that\nthe result of our crowd-based evaluation scheme is different from those of\nautomated evaluation schemes. In addition, we regard the crowd-based evaluation\nresults as ground truths and provide a quantitative performance measure to\ncompare different automated evaluation schemes. We also discuss the impact of\ncrowd workers on the results and show that the varying ability of crowd workers\ndoes not significantly impact the results.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 17:37:53 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Lu", "Xiaotian", ""], ["Tolmachev", "Arseny", ""], ["Yamamoto", "Tatsuya", ""], ["Takeuchi", "Koh", ""], ["Okajima", "Seiji", ""], ["Takebayashi", "Tomoyoshi", ""], ["Maruhashi", "Koji", ""], ["Kashima", "Hisashi", ""]]}, {"id": "2107.00488", "submitter": "Xiongjie Chen", "authors": "Xiongjie Chen, Hao Wen, and Yunpeng Li", "title": "Differentiable Particle Filters through Conditional Normalizing Flow", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiable particle filters provide a flexible mechanism to adaptively\ntrain dynamic and measurement models by learning from observed data. However,\nmost existing differentiable particle filters are within the bootstrap particle\nfiltering framework and fail to incorporate the information from latest\nobservations to construct better proposals. In this paper, we utilize\nconditional normalizing flows to construct proposal distributions for\ndifferentiable particle filters, enriching the distribution families that the\nproposal distributions can represent. In addition, normalizing flows are\nincorporated in the construction of the dynamic model, resulting in a more\nexpressive dynamic model. We demonstrate the performance of the proposed\nconditional normalizing flow-based differentiable particle filters in a visual\ntracking task.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 14:31:27 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Chen", "Xiongjie", ""], ["Wen", "Hao", ""], ["Li", "Yunpeng", ""]]}, {"id": "2107.00528", "submitter": "Lars Malmqvist", "authors": "Lars Malmqvist, Tommy Yuan, Suresh Manandhar", "title": "Visualising Argumentation Graphs with Graph Embeddings and t-SNE", "comments": null, "journal-ref": "COMMA Workshop on Argument Visualization, 2020", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper applies t-SNE, a visualisation technique familiar from Deep Neural\nNetwork research to argumentation graphs by applying it to the output of graph\nembeddings generated using several different methods. It shows that such a\nvisualisation approach can work for argumentation and show interesting\nstructural properties of argumentation graphs, opening up paths for further\nresearch in the area.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 15:13:24 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Malmqvist", "Lars", ""], ["Yuan", "Tommy", ""], ["Manandhar", "Suresh", ""]]}, {"id": "2107.00567", "submitter": "Marcus Lewis", "authors": "Marcus Lewis", "title": "Hippocampal Spatial Mapping As Fast Graph Learning", "comments": "9 pages, 4 figures, writeup of poster for 30th Annual Computational\n  Neuroscience Meeting (CNS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The hippocampal formation is thought to learn spatial maps of environments,\nand in many models this learning process consists of forming a sensory\nassociation for each location in the environment. This is inefficient, akin to\nlearning a large lookup table for each environment. Spatial maps can be learned\nmuch more efficiently if the maps instead consist of arrangements of sparse\nenvironment parts. In this work, I approach spatial mapping as a problem of\nlearning graphs of environment parts. Each node in the learned graph,\nrepresented by hippocampal engram cells, is associated with feature information\nin lateral entorhinal cortex (LEC) and location information in medial\nentorhinal cortex (MEC) using empirically observed neuron types. Each edge in\nthe graph represents the relation between two parts, and it is associated with\ncoarse displacement information. This core idea of associating arbitrary\ninformation with nodes and edges is not inherently spatial, so this proposed\nfast-relation-graph-learning algorithm can expand to incorporate many spatial\nand non-spatial tasks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 16:05:42 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Lewis", "Marcus", ""]]}, {"id": "2107.00593", "submitter": "Lucius Bynum", "authors": "Lucius E.J. Bynum, Joshua R. Loftus, Julia Stoyanovich", "title": "Impact Remediation: Optimal Interventions to Reduce Inequality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A significant body of research in the data sciences considers unfair\ndiscrimination against social categories such as race or gender that could\noccur or be amplified as a result of algorithmic decisions. Simultaneously,\nreal-world disparities continue to exist, even before algorithmic decisions are\nmade. In this work, we draw on insights from the social sciences and humanistic\nstudies brought into the realm of causal modeling and constrained optimization,\nand develop a novel algorithmic framework for tackling pre-existing real-world\ndisparities. The purpose of our framework, which we call the \"impact\nremediation framework,\" is to measure real-world disparities and discover the\noptimal intervention policies that could help improve equity or access to\nopportunity for those who are underserved with respect to an outcome of\ninterest. We develop a disaggregated approach to tackling pre-existing\ndisparities that relaxes the typical set of assumptions required for the use of\nsocial categories in structural causal models. Our approach flexibly\nincorporates counterfactuals and is compatible with various ontological\nassumptions about the nature of social categories. We demonstrate impact\nremediation with a real-world case study and compare our disaggregated approach\nto an existing state-of-the-art approach, comparing its structure and resulting\npolicy recommendations. In contrast to most work on optimal policy learning, we\nexplore disparity reduction itself as an objective, explicitly focusing the\npower of algorithms on reducing inequality.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 16:35:12 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Bynum", "Lucius E. J.", ""], ["Loftus", "Joshua R.", ""], ["Stoyanovich", "Julia", ""]]}, {"id": "2107.00641", "submitter": "Jianwei Yang", "authors": "Jianwei Yang, Chunyuan Li, Pengchuan Zhang, Xiyang Dai, Bin Xiao, Lu\n  Yuan, Jianfeng Gao", "title": "Focal Self-attention for Local-Global Interactions in Vision\n  Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Vision Transformer and its variants have shown great promise on\nvarious computer vision tasks. The ability of capturing short- and long-range\nvisual dependencies through self-attention is arguably the main source for the\nsuccess. But it also brings challenges due to quadratic computational overhead,\nespecially for the high-resolution vision tasks (e.g., object detection). In\nthis paper, we present focal self-attention, a new mechanism that incorporates\nboth fine-grained local and coarse-grained global interactions. Using this new\nmechanism, each token attends the closest surrounding tokens at fine\ngranularity but the tokens far away at coarse granularity, and thus can capture\nboth short- and long-range visual dependencies efficiently and effectively.\nWith focal self-attention, we propose a new variant of Vision Transformer\nmodels, called Focal Transformer, which achieves superior performance over the\nstate-of-the-art vision Transformers on a range of public image classification\nand object detection benchmarks. In particular, our Focal Transformer models\nwith a moderate size of 51.1M and a larger size of 89.8M achieve 83.5 and 83.8\nTop-1 accuracy, respectively, on ImageNet classification at 224x224 resolution.\nUsing Focal Transformers as the backbones, we obtain consistent and substantial\nimprovements over the current state-of-the-art Swin Transformers for 6\ndifferent object detection methods trained with standard 1x and 3x schedules.\nOur largest Focal Transformer yields 58.7/58.9 box mAPs and 50.9/51.3 mask mAPs\non COCO mini-val/test-dev, and 55.4 mIoU on ADE20K for semantic segmentation,\ncreating new SoTA on three of the most challenging computer vision tasks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 17:56:09 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Yang", "Jianwei", ""], ["Li", "Chunyuan", ""], ["Zhang", "Pengchuan", ""], ["Dai", "Xiyang", ""], ["Xiao", "Bin", ""], ["Yuan", "Lu", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2107.00645", "submitter": "Yongming Rao", "authors": "Yongming Rao, Wenliang Zhao, Zheng Zhu, Jiwen Lu, Jie Zhou", "title": "Global Filter Networks for Image Classification", "comments": "Project page: https://gfnet.ivg-research.xyz/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in self-attention and pure multi-layer perceptrons (MLP)\nmodels for vision have shown great potential in achieving promising performance\nwith fewer inductive biases. These models are generally based on learning\ninteraction among spatial locations from raw data. The complexity of\nself-attention and MLP grows quadratically as the image size increases, which\nmakes these models hard to scale up when high-resolution features are required.\nIn this paper, we present the Global Filter Network (GFNet), a conceptually\nsimple yet computationally efficient architecture, that learns long-term\nspatial dependencies in the frequency domain with log-linear complexity. Our\narchitecture replaces the self-attention layer in vision transformers with\nthree key operations: a 2D discrete Fourier transform, an element-wise\nmultiplication between frequency-domain features and learnable global filters,\nand a 2D inverse Fourier transform. We exhibit favorable accuracy/complexity\ntrade-offs of our models on both ImageNet and downstream tasks. Our results\ndemonstrate that GFNet can be a very competitive alternative to\ntransformer-style models and CNNs in efficiency, generalization ability and\nrobustness. Code is available at https://github.com/raoyongming/GFNet\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 17:58:16 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Rao", "Yongming", ""], ["Zhao", "Wenliang", ""], ["Zhu", "Zheng", ""], ["Lu", "Jiwen", ""], ["Zhou", "Jie", ""]]}, {"id": "2107.00650", "submitter": "Medhini Narasimhan", "authors": "Medhini Narasimhan, Anna Rohrbach, Trevor Darrell", "title": "CLIP-It! Language-Guided Video Summarization", "comments": "Website at https://medhini.github.io/clip_it/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A generic video summary is an abridged version of a video that conveys the\nwhole story and features the most important scenes. Yet the importance of\nscenes in a video is often subjective, and users should have the option of\ncustomizing the summary by using natural language to specify what is important\nto them. Further, existing models for fully automatic generic summarization\nhave not exploited available language models, which can serve as an effective\nprior for saliency. This work introduces CLIP-It, a single framework for\naddressing both generic and query-focused video summarization, typically\napproached separately in the literature. We propose a language-guided\nmultimodal transformer that learns to score frames in a video based on their\nimportance relative to one another and their correlation with a user-defined\nquery (for query-focused summarization) or an automatically generated dense\nvideo caption (for generic video summarization). Our model can be extended to\nthe unsupervised setting by training without ground-truth supervision. We\noutperform baselines and prior work by a significant margin on both standard\nvideo summarization datasets (TVSum and SumMe) and a query-focused video\nsummarization dataset (QFVS). Particularly, we achieve large improvements in\nthe transfer setting, attesting to our method's strong generalization\ncapabilities.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 17:59:27 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Narasimhan", "Medhini", ""], ["Rohrbach", "Anna", ""], ["Darrell", "Trevor", ""]]}, {"id": "2107.00683", "submitter": "Sebastian Castro", "authors": "Michael Noseworthy, Caris Moses, Isaiah Brand, Sebastian Castro,\n  Leslie Kaelbling, Tom\\'as Lozano-P\\'erez, Nicholas Roy", "title": "Active Learning of Abstract Plan Feasibility", "comments": "To appear in Robotics: Science and Systems 2021", "journal-ref": null, "doi": "10.15607/rss.2021.xvii.043", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long horizon sequential manipulation tasks are effectively addressed\nhierarchically: at a high level of abstraction the planner searches over\nabstract action sequences, and when a plan is found, lower level motion plans\nare generated. Such a strategy hinges on the ability to reliably predict that a\nfeasible low level plan will be found which satisfies the abstract plan.\nHowever, computing Abstract Plan Feasibility (APF) is difficult because the\noutcome of a plan depends on real-world phenomena that are difficult to model,\nsuch as noise in estimation and execution. In this work, we present an active\nlearning approach to efficiently acquire an APF predictor through\ntask-independent, curious exploration on a robot. The robot identifies plans\nwhose outcomes would be informative about APF, executes those plans, and learns\nfrom their successes or failures. Critically, we leverage an infeasible\nsubsequence property to prune candidate plans in the active learning strategy,\nallowing our system to learn from less data. We evaluate our strategy in\nsimulation and on a real Franka Emika Panda robot with integrated perception,\nexperimentation, planning, and execution. In a stacking domain where objects\nhave non-uniform mass distributions, we show that our system permits real robot\nlearning of an APF model in four hundred self-supervised interactions, and that\nour learned model can be used effectively in multiple downstream tasks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 18:17:01 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Noseworthy", "Michael", ""], ["Moses", "Caris", ""], ["Brand", "Isaiah", ""], ["Castro", "Sebastian", ""], ["Kaelbling", "Leslie", ""], ["Lozano-P\u00e9rez", "Tom\u00e1s", ""], ["Roy", "Nicholas", ""]]}, {"id": "2107.00700", "submitter": "Vittorio Mazzia", "authors": "Diego Aghi, Simone Cerrato, Vittorio Mazzia, Marcello Chiaberge", "title": "Deep Semantic Segmentation at the Edge for Autonomous Navigation in\n  Vineyard Rows", "comments": "IEEE/RSJ International Conference on Intelligent Robots and Systems\n  (IROS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Precision agriculture is a fast-growing field that aims at introducing\naffordable and effective automation into agricultural processes. Nowadays,\nalgorithmic solutions for navigation in vineyards require expensive sensors and\nhigh computational workloads that preclude large-scale applicability of\nautonomous robotic platforms in real business case scenarios. From this\nperspective, our novel proposed control leverages the latest advancement in\nmachine perception and edge AI techniques to achieve highly affordable and\nreliable navigation inside vineyard rows with low computational and power\nconsumption. Indeed, using a custom-trained segmentation network and a\nlow-range RGB-D camera, we are able to take advantage of the semantic\ninformation of the environment to produce smooth trajectories and stable\ncontrol in different vineyards scenarios. Moreover, the segmentation maps\ngenerated by the control algorithm itself could be directly exploited as\nfilters for a vegetative assessment of the crop status. Extensive\nexperimentations and evaluations against real-world data and simulated\nenvironments demonstrated the effectiveness and intrinsic robustness of our\nmethodology.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 18:51:58 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Aghi", "Diego", ""], ["Cerrato", "Simone", ""], ["Mazzia", "Vittorio", ""], ["Chiaberge", "Marcello", ""]]}, {"id": "2107.00703", "submitter": "Anssi Kanervisto", "authors": "Anssi Kanervisto, Christian Scheller, Yanick Schraner, Ville\n  Hautam\\\"aki", "title": "Distilling Reinforcement Learning Tricks for Video Games", "comments": "To appear in IEEE Conference on Games 2021. Experiment code is\n  available at https://github.com/Miffyli/rl-human-prior-tricks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) research focuses on general solutions that can be\napplied across different domains. This results in methods that RL practitioners\ncan use in almost any domain. However, recent studies often lack the\nengineering steps (\"tricks\") which may be needed to effectively use RL, such as\nreward shaping, curriculum learning, and splitting a large task into smaller\nchunks. Such tricks are common, if not necessary, to achieve state-of-the-art\nresults and win RL competitions. To ease the engineering efforts, we distill\ndescriptions of tricks from state-of-the-art results and study how well these\ntricks can improve a standard deep Q-learning agent. The long-term goal of this\nwork is to enable combining proven RL methods with domain-specific tricks by\nproviding a unified software framework and accompanying insights in multiple\ndomains.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 19:02:38 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Kanervisto", "Anssi", ""], ["Scheller", "Christian", ""], ["Schraner", "Yanick", ""], ["Hautam\u00e4ki", "Ville", ""]]}, {"id": "2107.00710", "submitter": "Ulysse C\\^ot\\'e-Allard", "authors": "Ulysse C\\^ot\\'e-Allard, Petter Jakobsen, Andrea Stautland, Tine\n  Nordgreen, Ole Bernt Fasmer, Ketil Joachim Oedegaard, Jim Torresen", "title": "Long-Short Ensemble Network for Bipolar Manic-Euthymic State Recognition\n  Based on Wrist-worn Sensors", "comments": "Submitted for peer-review. 11 pages + 3. 2 Figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Manic episodes of bipolar disorder can lead to uncritical behaviour and\ndelusional psychosis, often with destructive consequences for those affected\nand their surroundings. Early detection and intervention of a manic episode are\ncrucial to prevent escalation, hospital admission and premature death. However,\npeople with bipolar disorder may not recognize that they are experiencing a\nmanic episode and symptoms such as euphoria and increased productivity can also\ndeter affected individuals from seeking help. This work proposes to perform\nuser-independent, automatic mood-state detection based on actigraphy and\nelectrodermal activity acquired from a wrist-worn device during mania and after\nrecovery (euthymia). This paper proposes a new deep learning-based ensemble\nmethod leveraging long (20h) and short (5 minutes) time-intervals to\ndiscriminate between the mood-states. When tested on 47 bipolar patients, the\nproposed classification scheme achieves an average accuracy of 91.59% in\neuthymic/manic mood-state recognition.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 19:35:54 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["C\u00f4t\u00e9-Allard", "Ulysse", ""], ["Jakobsen", "Petter", ""], ["Stautland", "Andrea", ""], ["Nordgreen", "Tine", ""], ["Fasmer", "Ole Bernt", ""], ["Oedegaard", "Ketil Joachim", ""], ["Torresen", "Jim", ""]]}, {"id": "2107.00722", "submitter": "Heriberto Cuay\\'ahuitl", "authors": "Abdalkarim Mohtasib, Amir Ghalamzan E., Nicola Bellotto, Heriberto\n  Cuay\\'ahuitl", "title": "Neural Task Success Classifiers for Robotic Manipulation from Few Real\n  Demonstrations", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots learning a new manipulation task from a small amount of demonstrations\nare increasingly demanded in different workspaces. A classifier model assessing\nthe quality of actions can predict the successful completion of a task, which\ncan be used by intelligent agents for action-selection. This paper presents a\nnovel classifier that learns to classify task completion only from a few\ndemonstrations. We carry out a comprehensive comparison of different neural\nclassifiers, e.g. fully connected-based, fully convolutional-based,\nsequence2sequence-based, and domain adaptation-based classification. We also\npresent a new dataset including five robot manipulation tasks, which is\npublicly available. We compared the performances of our novel classifier and\nthe existing models using our dataset and the MIME dataset. The results suggest\ndomain adaptation and timing-based features improve success prediction. Our\nnovel model, i.e. fully convolutional neural network with domain adaptation and\ntiming features, achieves an average classification accuracy of 97.3\\% and\n95.5\\% across tasks in both datasets whereas state-of-the-art classifiers\nwithout domain adaptation and timing-features only achieve 82.4\\% and 90.3\\%,\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 19:58:16 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Mohtasib", "Abdalkarim", ""], ["E.", "Amir Ghalamzan", ""], ["Bellotto", "Nicola", ""], ["Cuay\u00e1huitl", "Heriberto", ""]]}, {"id": "2107.00733", "submitter": "Reza Bagherian Azhiri", "authors": "Reza Bagherian Azhiri, Mohammad Esmaeili, Mehrdad Nourani", "title": "EMG-Based Feature Extraction and Classification for Prosthetic Hand\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, real-time control of prosthetic hands has gained a great\ndeal of attention. In particular, real-time analysis of Electromyography (EMG)\nsignals has several challenges to achieve an acceptable accuracy and execution\ndelay. In this paper, we address some of these challenges by improving the\naccuracy in a shorter signal length. We first introduce a set of new feature\nextraction functions applying on each level of wavelet decomposition. Then, we\npropose a postprocessing approach to process the neural network outputs. The\nexperimental results illustrate that the proposed method enhances the accuracy\nof real-time classification of EMG signals up to $95.5\\%$ for $800$ msec signal\nlength. The proposed postprocessing method achieves higher consistency compared\nwith conventional majority voting and Bayesian fusion methods.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 20:19:03 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Azhiri", "Reza Bagherian", ""], ["Esmaeili", "Mohammad", ""], ["Nourani", "Mehrdad", ""]]}, {"id": "2107.00745", "submitter": "Vaden Masrani", "authors": "Vaden Masrani, Rob Brekelmans, Thang Bui, Frank Nielsen, Aram\n  Galstyan, Greg Ver Steeg, Frank Wood", "title": "q-Paths: Generalizing the Geometric Annealing Path using Power Means", "comments": "arXiv admin note: text overlap with arXiv:2012.07823", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many common machine learning methods involve the geometric annealing path, a\nsequence of intermediate densities between two distributions of interest\nconstructed using the geometric average. While alternatives such as the\nmoment-averaging path have demonstrated performance gains in some settings,\ntheir practical applicability remains limited by exponential family endpoint\nassumptions and a lack of closed form energy function. In this work, we\nintroduce $q$-paths, a family of paths which is derived from a generalized\nnotion of the mean, includes the geometric and arithmetic mixtures as special\ncases, and admits a simple closed form involving the deformed logarithm\nfunction from nonextensive thermodynamics. Following previous analysis of the\ngeometric path, we interpret our $q$-paths as corresponding to a\n$q$-exponential family of distributions, and provide a variational\nrepresentation of intermediate densities as minimizing a mixture of\n$\\alpha$-divergences to the endpoints. We show that small deviations away from\nthe geometric path yield empirical gains for Bayesian inference using\nSequential Monte Carlo and generative model evaluation using Annealed\nImportance Sampling.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 21:09:06 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Masrani", "Vaden", ""], ["Brekelmans", "Rob", ""], ["Bui", "Thang", ""], ["Nielsen", "Frank", ""], ["Galstyan", "Aram", ""], ["Steeg", "Greg Ver", ""], ["Wood", "Frank", ""]]}, {"id": "2107.00749", "submitter": "Vaden Masrani", "authors": "Vaden Masrani", "title": "Proof of the impossibility of probabilistic induction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this short note I restate and simplify the proof of the impossibility of\nprobabilistic induction from Popper (1992). Other proofs are possible (cf.\nPopper (1985)).\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 21:30:46 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Masrani", "Vaden", ""]]}, {"id": "2107.00773", "submitter": "Zhongyu Li", "authors": "Scott Gilroy, Derek Lau, Lizhi Yang, Ed Izaguirre, Kristen Biermayer,\n  Anxing Xiao, Mengti Sun, Ayush Agrawal, Jun Zeng, Zhongyu Li, Koushil\n  Sreenath", "title": "Autonomous Navigation for Quadrupedal Robots with Optimized Jumping\n  through Constrained Obstacles", "comments": "Accepted to 2021 IEEE 17th International Conference on Automation\n  Science and Engineering (CASE 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quadrupeds are strong candidates for navigating challenging environments\nbecause of their agile and dynamic designs. This paper presents a methodology\nthat extends the range of exploration for quadrupedal robots by creating an\nend-to-end navigation framework that exploits walking and jumping modes. To\nobtain a dynamic jumping maneuver while avoiding obstacles,\ndynamically-feasible trajectories are optimized offline through\ncollocation-based optimization where safety constraints are imposed. Such\noptimization schematic allows the robot to jump through window-shaped obstacles\nby considering both obstacles in the air and on the ground. The resulted\njumping mode is utilized in an autonomous navigation pipeline that leverages a\nsearch-based global planner and a local planner to enable the robot to reach\nthe goal location by walking. A state machine together with a decision making\nstrategy allows the system to switch behaviors between walking around obstacles\nor jumping through them. The proposed framework is experimentally deployed and\nvalidated on a quadrupedal robot, a Mini Cheetah, to enable the robot to\nautonomously navigate through an environment while avoiding obstacles and\njumping over a maximum height of 13 cm to pass through a window-shaped opening\nin order to reach its goal.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 23:40:30 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Gilroy", "Scott", ""], ["Lau", "Derek", ""], ["Yang", "Lizhi", ""], ["Izaguirre", "Ed", ""], ["Biermayer", "Kristen", ""], ["Xiao", "Anxing", ""], ["Sun", "Mengti", ""], ["Agrawal", "Ayush", ""], ["Zeng", "Jun", ""], ["Li", "Zhongyu", ""], ["Sreenath", "Koushil", ""]]}, {"id": "2107.00778", "submitter": "Wei-Lun Chao", "authors": "Hong-You Chen, Wei-Lun Chao", "title": "On Bridging Generic and Personalized Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Federated learning is promising for its ability to collaboratively train\nmodels with multiple clients without accessing their data, but vulnerable when\nclients' data distributions diverge from each other. This divergence further\nleads to a dilemma: \"Should we prioritize the learned model's generic\nperformance (for future use at the server) or its personalized performance (for\neach client)?\" These two, seemingly competing goals have divided the community\nto focus on one or the other, yet in this paper we show that it is possible to\napproach both at the same time. Concretely, we propose a novel federated\nlearning framework that explicitly decouples a model's dual duties with two\nprediction tasks. On the one hand, we introduce a family of losses that are\nrobust to non-identical class distributions, enabling clients to train a\ngeneric predictor with a consistent objective across them. On the other hand,\nwe formulate the personalized predictor as a lightweight adaptive module that\nis learned to minimize each client's empirical risk on top of the generic\npredictor. With this two-loss, two-predictor framework which we name Federated\nRobust Decoupling Fed-RoD, the learned model can simultaneously achieve\nstate-of-the-art generic and personalized performance, essentially bridging the\ntwo tasks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 00:25:48 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Chen", "Hong-You", ""], ["Chao", "Wei-Lun", ""]]}, {"id": "2107.00793", "submitter": "Kevin Xia", "authors": "Kevin Xia, Kai-Zhan Lee, Yoshua Bengio, Elias Bareinboim", "title": "The Causal-Neural Connection: Expressiveness, Learnability, and\n  Inference", "comments": "10 pages main body (53 total pages with references and appendix), 5\n  figures in main body (20 total figures including appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the central elements of any causal inference is an object called\nstructural causal model (SCM), which represents a collection of mechanisms and\nexogenous sources of random variation of the system under investigation (Pearl,\n2000). An important property of many kinds of neural networks is universal\napproximability: the ability to approximate any function to arbitrary\nprecision. Given this property, one may be tempted to surmise that a collection\nof neural nets is capable of learning any SCM by training on data generated by\nthat SCM. In this paper, we show this is not the case by disentangling the\nnotions of expressivity and learnability. Specifically, we show that the causal\nhierarchy theorem (Thm. 1, Bareinboim et al., 2020), which describes the limits\nof what can be learned from data, still holds for neural models. For instance,\nan arbitrarily complex and expressive neural net is unable to predict the\neffects of interventions given observational data alone. Given this result, we\nintroduce a special type of SCM called a neural causal model (NCM), and\nformalize a new type of inductive bias to encode structural constraints\nnecessary for performing causal inferences. Building on this new class of\nmodels, we focus on solving two canonical tasks found in the literature known\nas causal identification and estimation. Leveraging the neural toolbox, we\ndevelop an algorithm that is both sufficient and necessary to determine whether\na causal effect can be learned from data (i.e., causal identifiability); it\nthen estimates the effect whenever identifiability holds (causal estimation).\nSimulations corroborate the proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 01:55:18 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 18:31:52 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Xia", "Kevin", ""], ["Lee", "Kai-Zhan", ""], ["Bengio", "Yoshua", ""], ["Bareinboim", "Elias", ""]]}, {"id": "2107.00821", "submitter": "George K. Thiruvathukal", "authors": "Vishnu Banna and Akhil Chinnakotla and Zhengxin Yan and Anirudh\n  Vegesana and Naveen Vivek and Kruthi Krishnappa and Wenxin Jiang and\n  Yung-Hsiang Lu and George K. Thiruvathukal and James C. Davis", "title": "An Experience Report on Machine Learning Reproducibility: Guidance for\n  Practitioners and TensorFlow Model Garden Contributors", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Machine learning techniques are becoming a fundamental tool for scientific\nand engineering progress. These techniques are applied in contexts as diverse\nas astronomy and spam filtering. However, correctly applying these techniques\nrequires careful engineering. Much attention has been paid to the technical\npotential; relatively little attention has been paid to the software\nengineering process required to bring research-based machine learning\ntechniques into practical utility. Technology companies have supported the\nengineering community through machine learning frameworks such as TensorFLow\nand PyTorch, but the details of how to engineer complex machine learning models\nin these frameworks have remained hidden.\n  To promote best practices within the engineering community, academic\ninstitutions and Google have partnered to launch a Special Interest Group on\nMachine Learning Models (SIGMODELS) whose goal is to develop exemplary\nimplementations of prominent machine learning models in community locations\nsuch as the TensorFlow Model Garden (TFMG). The purpose of this report is to\ndefine a process for reproducing a state-of-the-art machine learning model at a\nlevel of quality suitable for inclusion in the TFMG. We define the engineering\nprocess and elaborate on each step, from paper analysis to model release. We\nreport on our experiences implementing the YOLO model family with a team of 26\nstudent researchers, share the tools we developed, and describe the lessons we\nlearned along the way.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 04:32:18 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 16:44:14 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Banna", "Vishnu", ""], ["Chinnakotla", "Akhil", ""], ["Yan", "Zhengxin", ""], ["Vegesana", "Anirudh", ""], ["Vivek", "Naveen", ""], ["Krishnappa", "Kruthi", ""], ["Jiang", "Wenxin", ""], ["Lu", "Yung-Hsiang", ""], ["Thiruvathukal", "George K.", ""], ["Davis", "James C.", ""]]}, {"id": "2107.00862", "submitter": "Yuanbang Li", "authors": "Yuanbang Li", "title": "User Role Discovery and Optimization Method based on K-means +\n  Reinforcement learning in Mobile Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the widespread use of mobile phones, users can share their location and\nactivity anytime, anywhere, as a form of check in data. These data reflect user\nfeatures. Long term stable, and a set of user shared features can be abstracted\nas user roles. The role is closely related to the user's social background,\noccupation, and living habits. This study provides four main contributions.\nFirstly, user feature models from different views for each user are constructed\nfrom the analysis of check in data. Secondly, K Means algorithm is used to\ndiscover user roles from user features. Thirdly, a reinforcement learning\nalgorithm is proposed to strengthen the clustering effect of user roles and\nimprove the stability of the clustering result. Finally, experiments are used\nto verify the validity of the method, the results of which show the\neffectiveness of the method.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 06:40:12 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Li", "Yuanbang", ""]]}, {"id": "2107.00866", "submitter": "Yunzhuang Shen", "authors": "Yunzhuang Shen, Yuan Sun, Andrew Eberhard, Xiaodong Li", "title": "Learning Primal Heuristics for Mixed Integer Programs", "comments": "Accepted by IJCNN'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a novel primal heuristic for Mixed Integer Programs, by\nemploying machine learning techniques. Mixed Integer Programming is a general\ntechnique for formulating combinatorial optimization problems. Inside a solver,\nprimal heuristics play a critical role in finding good feasible solutions that\nenable one to tighten the duality gap from the outset of the Branch-and-Bound\nalgorithm (B&B), greatly improving its performance by pruning the B&B tree\naggressively. In this paper, we investigate whether effective primal heuristics\ncan be automatically learned via machine learning. We propose a new method to\nrepresent an optimization problem as a graph, and train a Graph Convolutional\nNetwork on solved problem instances with known optimal solutions. This in turn\ncan predict the values of decision variables in the optimal solution for an\nunseen problem instance of a similar type. The prediction of variable solutions\nis then leveraged by a novel configuration of the B&B method, Probabilistic\nBranching with guided Depth-first Search (PB-DFS) approach, aiming to find\n(near-)optimal solutions quickly. The experimental results show that this new\nheuristic can find better primal solutions at a much earlier stage of the\nsolving process, compared to other state-of-the-art primal heuristics.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 06:46:23 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Shen", "Yunzhuang", ""], ["Sun", "Yuan", ""], ["Eberhard", "Andrew", ""], ["Li", "Xiaodong", ""]]}, {"id": "2107.00873", "submitter": "Heiko Paulheim", "authors": "Malte Brockmeier, Yawen Liu, Sunita Pateer, Sven Hertling and Heiko\n  Paulheim", "title": "On-Demand and Lightweight Knowledge Graph Generation -- a Demonstration\n  with DBpedia", "comments": "Accepted at Semantics 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern large-scale knowledge graphs, such as DBpedia, are datasets which\nrequire large computational resources to serve and process. Moreover, they\noften have longer release cycles, which leads to outdated information in those\ngraphs. In this paper, we present DBpedia on Demand -- a system which serves\nDBpedia resources on demand without the need to materialize and store the\nentire graph, and which even provides limited querying functionality.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 07:15:27 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Brockmeier", "Malte", ""], ["Liu", "Yawen", ""], ["Pateer", "Sunita", ""], ["Hertling", "Sven", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2107.00894", "submitter": "Maosen Li", "authors": "Maosen Li, Siheng Chen, Yanning Shen, Genjia Liu, Ivor W. Tsang, Ya\n  Zhang", "title": "Online Multi-Agent Forecasting with Interpretable Collaborative Graph\n  Neural Network", "comments": "Submitted to IEEE-TNNLS SI-Deep Neural Networks for Graphs: Theory,\n  Models, Algorithms and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper considers predicting future statuses of multiple agents in an\nonline fashion by exploiting dynamic interactions in the system. We propose a\nnovel collaborative prediction unit (CoPU), which aggregates the predictions\nfrom multiple collaborative predictors according to a collaborative graph. Each\ncollaborative predictor is trained to predict the status of an agent by\nconsidering the impact of another agent. The edge weights of the collaborative\ngraph reflect the importance of each predictor. The collaborative graph is\nadjusted online by multiplicative update, which can be motivated by minimizing\nan explicit objective. With this objective, we also conduct regret analysis to\nindicate that, along with training, our CoPU achieves similar performance with\nthe best individual collaborative predictor in hindsight. This theoretical\ninterpretability distinguishes our method from many other graph networks. To\nprogressively refine predictions, multiple CoPUs are stacked to form a\ncollaborative graph neural network. Extensive experiments are conducted on\nthree tasks: online simulated trajectory prediction, online human motion\nprediction and online traffic speed prediction, and our methods outperform\nstate-of-the-art works on the three tasks by 28.6%, 17.4% and 21.0% on average,\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 08:20:06 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Li", "Maosen", ""], ["Chen", "Siheng", ""], ["Shen", "Yanning", ""], ["Liu", "Genjia", ""], ["Tsang", "Ivor W.", ""], ["Zhang", "Ya", ""]]}, {"id": "2107.00931", "submitter": "Zeynep Hilal Kilimci", "authors": "Anil Berk Altuner, Zeynep Hilal Kilimci", "title": "A Novel Deep Reinforcement Learning Based Stock Direction Prediction\n  using Knowledge Graph and Community Aware Sentiments", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Stock market prediction has been an important topic for investors,\nresearchers, and analysts. Because it is affected by too many factors, stock\nmarket prediction is a difficult task to handle. In this study, we propose a\nnovel method that is based on deep reinforcement learning methodologies for the\ndirection prediction of stocks using sentiments of community and knowledge\ngraph. For this purpose, we firstly construct a social knowledge graph of users\nby analyzing relations between connections. After that, time series analysis of\nrelated stock and sentiment analysis is blended with deep reinforcement\nmethodology. Turkish version of Bidirectional Encoder Representations from\nTransformers (BerTurk) is employed to analyze the sentiments of the users while\ndeep Q-learning methodology is used for the deep reinforcement learning side of\nthe proposed model to construct the deep Q network. In order to demonstrate the\neffectiveness of the proposed model, Garanti Bank (GARAN), Akbank (AKBNK),\nT\\\"urkiye \\.I\\c{s} Bankas{\\i} (ISCTR) stocks in Istanbul Stock Exchange are\nused as a case study. Experiment results show that the proposed novel model\nachieves remarkable results for stock market prediction task.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 09:39:41 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Altuner", "Anil Berk", ""], ["Kilimci", "Zeynep Hilal", ""]]}, {"id": "2107.00949", "submitter": "Christian Guckelsberger", "authors": "Christian Guckelsberger, Anna Kantosalo, Santiago Negrete-Yankelevich\n  and Tapio Takala", "title": "Embodiment and Computational Creativity", "comments": "10 pages, 1 Table, 1 Figure. Accepted as full paper at the\n  International Conference on Computational Creativity (ICCC) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We conjecture that creativity and the perception of creativity are, at least\nto some extent, shaped by embodiment. This makes embodiment highly relevant for\nComputational Creativity (CC) research, but existing research is scarce and the\nuse of the concept highly ambiguous. We overcome this situation by means of a\nsystematic review and a prescriptive analysis of publications at the\nInternational Conference on Computational Creativity. We adopt and extend an\nestablished typology of embodiment to resolve ambiguity through identifying and\ncomparing different usages of the concept. We collect, contextualise and\nhighlight opportunities and challenges in embracing embodiment in CC as a\nreference for research, and put forward important directions to further the\nembodied CC research programme.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 10:18:55 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Guckelsberger", "Christian", ""], ["Kantosalo", "Anna", ""], ["Negrete-Yankelevich", "Santiago", ""], ["Takala", "Tapio", ""]]}, {"id": "2107.00956", "submitter": "R\\'emy Portelas", "authors": "Grgur Kova\\v{c}, R\\'emy Portelas, Katja Hofmann, Pierre-Yves Oudeyer", "title": "SocialAI: Benchmarking Socio-Cognitive Abilities in Deep Reinforcement\n  Learning Agents", "comments": "under review. This paper extends and generalizes work in\n  arXiv:2104.13207", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building embodied autonomous agents capable of participating in social\ninteractions with humans is one of the main challenges in AI. Within the Deep\nReinforcement Learning (DRL) field, this objective motivated multiple works on\nembodied language use. However, current approaches focus on language as a\ncommunication tool in very simplified and non-diverse social situations: the\n\"naturalness\" of language is reduced to the concept of high vocabulary size and\nvariability. In this paper, we argue that aiming towards human-level AI\nrequires a broader set of key social skills: 1) language use in complex and\nvariable social contexts; 2) beyond language, complex embodied communication in\nmultimodal settings within constantly evolving social worlds. We explain how\nconcepts from cognitive sciences could help AI to draw a roadmap towards\nhuman-like intelligence, with a focus on its social dimensions. As a first\nstep, we propose to expand current research to a broader set of core social\nskills. To do this, we present SocialAI, a benchmark to assess the acquisition\nof social skills of DRL agents using multiple grid-world environments featuring\nother (scripted) social agents. We then study the limits of a recent SOTA DRL\napproach when tested on SocialAI and discuss important next steps towards\nproficient social agents. Videos and code are available at\nhttps://sites.google.com/view/socialai.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 10:39:18 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 06:42:34 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Kova\u010d", "Grgur", ""], ["Portelas", "R\u00e9my", ""], ["Hofmann", "Katja", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2107.00962", "submitter": "Antonella Bari\\v{s}i\\'c", "authors": "Antonella Bari\\v{s}i\\'c, Frano Petric, Stjepan Bogdan", "title": "Brain over Brawn -- Using a Stereo Camera to Detect, Track and Intercept\n  a Faster UAV by Reconstructing Its Trajectory", "comments": "To be published in Field Robotics. UAV-Eagle dataset available at:\n  https://github.com/larics/UAV-Eagle", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The work presented in this paper demonstrates our approach to intercepting a\nfaster intruder UAV, inspired by the MBZIRC2020 Challenge 1. By leveraging the\nknowledge of the shape of the intruder's trajectory we are able to calculate\nthe interception point. Target tracking is based on image processing by a\nYOLOv3 Tiny convolutional neural network, combined with depth calculation using\na gimbal-mounted ZED Mini stereo camera. We use RGB and depth data from ZED\nMini to extract the 3D position of the target, for which we devise a\nhistogram-of-depth based processing to reduce noise. Obtained 3D measurements\nof target's position are used to calculate the position, the orientation and\nthe size of a figure-eight shaped trajectory, which we approximate using\nlemniscate of Bernoulli. Once the approximation is deemed sufficiently precise,\nmeasured by Hausdorff distance between measurements and the approximation, an\ninterception point is calculated to position the intercepting UAV right on the\npath of the target. The proposed method, which has been significantly improved\nbased on the experience gathered during the MBZIRC competition, has been\nvalidated in simulation and through field experiments. The results confirmed\nthat an efficient visual perception module which extracts information related\nto the motion of the target UAV as a basis for the interception, has been\ndeveloped. The system is able to track and intercept the target which is 30%\nfaster than the interceptor in majority of simulation experiments. Tests in the\nunstructured environment yielded 9 out of 12 successful results.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 10:49:22 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Bari\u0161i\u0107", "Antonella", ""], ["Petric", "Frano", ""], ["Bogdan", "Stjepan", ""]]}, {"id": "2107.01001", "submitter": "Peng Yang", "authors": "Peng Yang, Tony Q. S. Quek, Jingxuan Chen, Chaoqun You, and Xianbin\n  Cao", "title": "Feeling of Presence Maximization: mmWave-Enabled Virtual Reality Meets\n  Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper investigates the problem of providing ultra-reliable and\nenergy-efficient virtual reality (VR) experiences for wireless mobile users. To\nensure reliable ultra-high-definition (UHD) video frame delivery to mobile\nusers and enhance their immersive visual experiences, a coordinated multipoint\n(CoMP) transmission technique and millimeter wave (mmWave) communications are\nexploited. Owing to user movement and time-varying wireless channels, the\nwireless VR experience enhancement problem is formulated as a\nsequence-dependent and mixed-integer problem with a goal of maximizing users'\nfeeling of presence (FoP) in the virtual world, subject to power consumption\nconstraints on access points (APs) and users' head-mounted displays (HMDs). The\nproblem, however, is hard to be directly solved due to the lack of users'\naccurate tracking information and the sequence-dependent and mixed-integer\ncharacteristics. To overcome this challenge, we develop a parallel echo state\nnetwork (ESN) learning method to predict users' tracking information by\ntraining fresh and historical tracking samples separately collected by APs.\nWith the learnt results, we propose a deep reinforcement learning (DRL) based\noptimization algorithm to solve the formulated problem. In this algorithm, we\nimplement deep neural networks (DNNs) as a scalable solution to produce integer\ndecision variables and solving a continuous power control problem to criticize\nthe integer decision variables. Finally, the performance of the proposed\nalgorithm is compared with various benchmark algorithms, and the impact of\ndifferent design parameters is also discussed. Simulation results demonstrate\nthat the proposed algorithm is more 4.14% energy-efficient than the benchmark\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 08:35:10 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 13:19:43 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Yang", "Peng", ""], ["Quek", "Tony Q. S.", ""], ["Chen", "Jingxuan", ""], ["You", "Chaoqun", ""], ["Cao", "Xianbin", ""]]}, {"id": "2107.01017", "submitter": "Angelo Menezes", "authors": "Angelo Garangau Menezes and Saulo Martiello Mastelini", "title": "MegazordNet: combining statistical and machine learning standpoints for\n  time series forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.AI cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Forecasting financial time series is considered to be a difficult task due to\nthe chaotic feature of the series. Statistical approaches have shown solid\nresults in some specific problems such as predicting market direction and\nsingle-price of stocks; however, with the recent advances in deep learning and\nbig data techniques, new promising options have arises to tackle financial time\nseries forecasting. Moreover, recent literature has shown that employing a\ncombination of statistics and machine learning may improve accuracy in the\nforecasts in comparison to single solutions. Taking into consideration the\nmentioned aspects, in this work, we proposed the MegazordNet, a framework that\nexplores statistical features within a financial series combined with a\nstructured deep learning model for time series forecasting. We evaluated our\napproach predicting the closing price of stocks in the S&P 500 using different\nmetrics, and we were able to beat single statistical and machine learning\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 15:06:54 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Menezes", "Angelo Garangau", ""], ["Mastelini", "Saulo Martiello", ""]]}, {"id": "2107.01035", "submitter": "Xiaohui Lin", "authors": "Xiaohui Lin, Yongquan Jiang, Yan Yang", "title": "Molecular structure prediction based on graph convolutional networks", "comments": "11 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the important application of molecular structure in many fields,\ncalculation by experimental means or traditional density functional theory is\noften time consuming. In view of this, a new Model Structure based on Graph\nConvolutional Neural network (MSGCN) is proposed, which can determine the\nmolecular structure by predicting the distance between two atoms. In order to\nverify the effect of MSGCN model, the model is compared with the method of\ncalculating molecular three-dimensional conformation in RDKit, and the result\nis better than it. In addition, the distance predicted by the MSGCN model and\nthe distance calculated by the QM9 dataset were used to predict the molecular\nproperties, thus proving the effectiveness of the distance predicted by the\nMSGCN model.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 08:34:51 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Lin", "Xiaohui", ""], ["Jiang", "Yongquan", ""], ["Yang", "Yan", ""]]}, {"id": "2107.01042", "submitter": "Daniel Halpern", "authors": "Manon Revel, Tao Lin, Daniel Halpern", "title": "The Optimal Size of an Epistemic Congress", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the optimal size of a congress in a representative democracy. We\ntake an epistemic view where voters decide on a binary issue with one ground\ntruth outcome, and each voter votes correctly according to their competence\nlevels in $[0, 1]$. Assuming that we can sample the best experts to form an\nepistemic congress, we find that the optimal congress size should be linear in\nthe population size. This result is striking because it holds even when\nallowing the top representatives to be accurate with arbitrarily high\nprobabilities. We then analyze real world data, finding that the actual sizes\nof congresses are much smaller than the optimal size our theoretical results\nsuggest. We conclude by analyzing under what conditions congresses of\nsub-optimal sizes would still outperform direct democracy, in which all voters\nvote.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 12:51:11 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Revel", "Manon", ""], ["Lin", "Tao", ""], ["Halpern", "Daniel", ""]]}, {"id": "2107.01057", "submitter": "Frederik Tr\\\"auble", "authors": "Frederik Tr\\\"auble, Julius von K\\\"ugelgen, Matth\\\"aus Kleindessner,\n  Francesco Locatello, Bernhard Sch\\\"olkopf, Peter Gehler", "title": "Backward-Compatible Prediction Updates: A Probabilistic Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When machine learning systems meet real world applications, accuracy is only\none of several requirements. In this paper, we assay a complementary\nperspective originating from the increasing availability of pre-trained and\nregularly improving state-of-the-art models. While new improved models develop\nat a fast pace, downstream tasks vary more slowly or stay constant. Assume that\nwe have a large unlabelled data set for which we want to maintain accurate\npredictions. Whenever a new and presumably better ML models becomes available,\nwe encounter two problems: (i) given a limited budget, which data points should\nbe re-evaluated using the new model?; and (ii) if the new predictions differ\nfrom the current ones, should we update? Problem (i) is about compute cost,\nwhich matters for very large data sets and models. Problem (ii) is about\nmaintaining consistency of the predictions, which can be highly relevant for\ndownstream applications; our demand is to avoid negative flips, i.e., changing\ncorrect to incorrect predictions. In this paper, we formalize the Prediction\nUpdate Problem and present an efficient probabilistic approach as answer to the\nabove questions. In extensive experiments on standard classification benchmark\ndata sets, we show that our method outperforms alternative strategies along key\nmetrics for backward-compatible prediction updates.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 13:05:31 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Tr\u00e4uble", "Frederik", ""], ["von K\u00fcgelgen", "Julius", ""], ["Kleindessner", "Matth\u00e4us", ""], ["Locatello", "Francesco", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Gehler", "Peter", ""]]}, {"id": "2107.01078", "submitter": "Eric Piette E.P.", "authors": "\\'Eric Piette, Matthew Stephenson, Dennis J.N.J. Soemers and Cameron\n  Browne", "title": "General Board Game Concepts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many games often share common ideas or aspects between them, such as their\nrules, controls, or playing area. However, in the context of General Game\nPlaying (GGP) for board games, this area remains under-explored. We propose to\nformalise the notion of \"game concept\", inspired by terms generally used by\ngame players and designers. Through the Ludii General Game System, we describe\nconcepts for several levels of abstraction, such as the game itself, the moves\nplayed, or the states reached. This new GGP feature associated with the ludeme\nrepresentation of games opens many new lines of research. The creation of a\nhyper-agent selector, the transfer of AI learning between games, or explaining\nAI techniques using game terms, can all be facilitated by the use of game\nconcepts. Other applications which can benefit from game concepts are also\ndiscussed, such as the generation of plausible reconstructed rules for\nincomplete ancient games, or the implementation of a board game recommender\nsystem.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 13:39:10 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Piette", "\u00c9ric", ""], ["Stephenson", "Matthew", ""], ["Soemers", "Dennis J. N. J.", ""], ["Browne", "Cameron", ""]]}, {"id": "2107.01079", "submitter": "Chen Chen", "authors": "Chen Chen, Kerstin Hammernik, Cheng Ouyang, Chen Qin, Wenjia Bai,\n  Daniel Rueckert", "title": "Cooperative Training and Latent Space Data Augmentation for Robust\n  Medical Image Segmentation", "comments": "MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based segmentation methods are vulnerable to unforeseen data\ndistribution shifts during deployment, e.g. change of image appearances or\ncontrasts caused by different scanners, unexpected imaging artifacts etc. In\nthis paper, we present a cooperative framework for training image segmentation\nmodels and a latent space augmentation method for generating hard examples.\nBoth contributions improve model generalization and robustness with limited\ndata. The cooperative training framework consists of a fast-thinking network\n(FTN) and a slow-thinking network (STN). The FTN learns decoupled image\nfeatures and shape features for image reconstruction and segmentation tasks.\nThe STN learns shape priors for segmentation correction and refinement. The two\nnetworks are trained in a cooperative manner. The latent space augmentation\ngenerates challenging examples for training by masking the decoupled latent\nspace in both channel-wise and spatial-wise manners. We performed extensive\nexperiments on public cardiac imaging datasets. Using only 10 subjects from a\nsingle site for training, we demonstrated improved cross-site segmentation\nperformance and increased robustness against various unforeseen imaging\nartifacts compared to strong baseline methods. Particularly, cooperative\ntraining with latent space data augmentation yields 15% improvement in terms of\naverage Dice score when compared to a standard training method.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 13:39:13 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Chen", "Chen", ""], ["Hammernik", "Kerstin", ""], ["Ouyang", "Cheng", ""], ["Qin", "Chen", ""], ["Bai", "Wenjia", ""], ["Rueckert", "Daniel", ""]]}, {"id": "2107.01110", "submitter": "Qi Liu", "authors": "Qi Liu, Xueyuan Li, Shihua Yuan, Zirui Li", "title": "Decision-Making Technology for Autonomous Vehicles Learning-Based\n  Methods, Applications and Future Outlook", "comments": "8 pages, 1 figure, 5 tables, ITSC2021(accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autonomous vehicles have a great potential in the application of both civil\nand military fields, and have become the focus of research with the rapid\ndevelopment of science and economy. This article proposes a brief review on\nlearning-based decision-making technology for autonomous vehicles since it is\nsignificant for safer and efficient performance of autonomous vehicles.\nFirstly, the basic outline of decision-making technology is provided. Secondly,\nrelated works about learning-based decision-making methods for autonomous\nvehicles are mainly reviewed with the comparison to classical decision-making\nmethods. In addition, applications of decision-making methods in existing\nautonomous vehicles are summarized. Finally, promising research topics in the\nfuture study of decision-making technology for autonomous vehicles are\nprospected.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 14:45:52 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Liu", "Qi", ""], ["Li", "Xueyuan", ""], ["Yuan", "Shihua", ""], ["Li", "Zirui", ""]]}, {"id": "2107.01130", "submitter": "Davood Zabihzadeh", "authors": "Davood Zabihzadeh", "title": "Ensemble of Loss Functions to Improve Generalizability of Deep Metric\n  Learning methods", "comments": "27 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Metric Learning (DML) learns a non-linear semantic embedding from input\ndata that brings similar pairs together while keeps dissimilar data away from\neach other. To this end, many different methods are proposed in the last decade\nwith promising results in various applications. The success of a DML algorithm\ngreatly depends on its loss function. However, no loss function is perfect, and\nit deals only with some aspects of an optimal similarity embedding. Besides,\nthe generalizability of the DML on unseen categories during the test stage is\nan important matter that is not considered by existing loss functions. To\naddress these challenges, we propose novel approaches to combine different\nlosses built on top of a shared deep feature extractor. The proposed ensemble\nof losses enforces the deep model to extract features that are consistent with\nall losses. Since the selected losses are diverse and each emphasizes different\naspects of an optimal semantic embedding, our effective combining methods yield\na considerable improvement over any individual loss and generalize well on\nunseen categories. Here, there is no limitation in choosing loss functions, and\nour methods can work with any set of existing ones. Besides, they can optimize\neach loss function as well as its weight in an end-to-end paradigm with no need\nto adjust any hyper-parameter. We evaluate our methods on some popular datasets\nfrom the machine vision domain in conventional Zero-Shot-Learning (ZSL)\nsettings. The results are very encouraging and show that our methods outperform\nall baseline losses by a large margin in all datasets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 15:19:46 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Zabihzadeh", "Davood", ""]]}, {"id": "2107.01131", "submitter": "Junya Chen", "authors": "Qing Guo, Junya Chen, Dong Wang, Yuewei Yang, Xinwei Deng, Lawrence\n  Carin, Fan Li, Chenyang Tao", "title": "Tight Mutual Information Estimation With Contrastive Fenchel-Legendre\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Successful applications of InfoNCE and its variants have popularized the use\nof contrastive variational mutual information (MI) estimators in machine\nlearning. While featuring superior stability, these estimators crucially depend\non costly large-batch training, and they sacrifice bound tightness for variance\nreduction. To overcome these limitations, we revisit the mathematics of popular\nvariational MI bounds from the lens of unnormalized statistical modeling and\nconvex optimization. Our investigation not only yields a new unified\ntheoretical framework encompassing popular variational MI bounds but also leads\nto a novel, simple, and powerful contrastive MI estimator named as FLO.\nTheoretically, we show that the FLO estimator is tight, and it provably\nconverges under stochastic gradient descent. Empirically, our FLO estimator\novercomes the limitations of its predecessors and learns more efficiently. The\nutility of FLO is verified using an extensive set of benchmarks, which also\nreveals the trade-offs in practical MI estimation.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 15:20:41 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Guo", "Qing", ""], ["Chen", "Junya", ""], ["Wang", "Dong", ""], ["Yang", "Yuewei", ""], ["Deng", "Xinwei", ""], ["Carin", "Lawrence", ""], ["Li", "Fan", ""], ["Tao", "Chenyang", ""]]}, {"id": "2107.01142", "submitter": "Liangkai Liu", "authors": "Liangkai Liu, Shaoshan Liu, and Weisong Shi", "title": "4C: A Computation, Communication, and Control Co-Design Framework for\n  CAVs", "comments": "7 pages, 4 figures, accepted by IEEE Wireless Communication Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.RO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Connected and autonomous vehicles (CAVs) are promising due to their potential\nsafety and efficiency benefits and have attracted massive investment and\ninterest from government agencies, industry, and academia. With more computing\nand communication resources are available, both vehicles and edge servers are\nequipped with a set of camera-based vision sensors, also known as Visual IoT\n(V-IoT) techniques, for sensing and perception. Tremendous efforts have been\nmade for achieving programmable communication, computation, and control.\nHowever, they are conducted mainly in the silo mode, limiting the\nresponsiveness and efficiency of handling challenging scenarios in the real\nworld. To improve the end-to-end performance, we envision that future CAVs\nrequire the co-design of communication, computation, and control. This paper\npresents our vision of the end-to-end design principle for CAVs, called 4C,\nwhich extends the V-IoT system by providing a unified communication,\ncomputation, and control co-design framework. With programmable communications,\nfine-grained heterogeneous computation, and efficient vehicle controls in 4C,\nCAVs can handle critical scenarios and achieve energy-efficient autonomous\ndriving. Finally, we present several challenges to achieving the vision of the\n4C framework.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 15:36:50 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Liu", "Liangkai", ""], ["Liu", "Shaoshan", ""], ["Shi", "Weisong", ""]]}, {"id": "2107.01151", "submitter": "Haiyang Wang", "authors": "Haiyang Wang, Wenguan Wang, Xizhou Zhu, Jifeng Dai, Liwei Wang", "title": "Collaborative Visual Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As a fundamental problem for Artificial Intelligence, multi-agent system\n(MAS) is making rapid progress, mainly driven by multi-agent reinforcement\nlearning (MARL) techniques. However, previous MARL methods largely focused on\ngrid-world like or game environments; MAS in visually rich environments has\nremained less explored. To narrow this gap and emphasize the crucial role of\nperception in MAS, we propose a large-scale 3D dataset, CollaVN, for\nmulti-agent visual navigation (MAVN). In CollaVN, multiple agents are entailed\nto cooperatively navigate across photo-realistic environments to reach target\nlocations. Diverse MAVN variants are explored to make our problem more general.\nMoreover, a memory-augmented communication framework is proposed. Each agent is\nequipped with a private, external memory to persistently store communication\ninformation. This allows agents to make better use of their past communication\ninformation, enabling more efficient collaboration and robust long-term\nplanning. In our experiments, several baselines and evaluation metrics are\ndesigned. We also empirically verify the efficacy of our proposed MARL approach\nacross different MAVN task settings.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 15:48:16 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 12:19:35 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Wang", "Haiyang", ""], ["Wang", "Wenguan", ""], ["Zhu", "Xizhou", ""], ["Dai", "Jifeng", ""], ["Wang", "Liwei", ""]]}, {"id": "2107.01152", "submitter": "Junya Chen", "authors": "Junya Chen, Zhe Gan, Xuan Li, Qing Guo, Liqun Chen, Shuyang Gao,\n  Tagyoung Chung, Yi Xu, Belinda Zeng, Wenlian Lu, Fan Li, Lawrence Carin,\n  Chenyang Tao", "title": "Simpler, Faster, Stronger: Breaking The log-K Curse On Contrastive\n  Learners With FlatNCE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  InfoNCE-based contrastive representation learners, such as SimCLR, have been\ntremendously successful in recent years. However, these contrastive schemes are\nnotoriously resource demanding, as their effectiveness breaks down with\nsmall-batch training (i.e., the log-K curse, whereas K is the batch-size). In\nthis work, we reveal mathematically why contrastive learners fail in the\nsmall-batch-size regime, and present a novel simple, non-trivial contrastive\nobjective named FlatNCE, which fixes this issue. Unlike InfoNCE, our FlatNCE no\nlonger explicitly appeals to a discriminative classification goal for\ncontrastive learning. Theoretically, we show FlatNCE is the mathematical dual\nformulation of InfoNCE, thus bridging the classical literature on energy\nmodeling; and empirically, we demonstrate that, with minimal modification of\ncode, FlatNCE enables immediate performance boost independent of the\nsubject-matter engineering efforts. The significance of this work is furthered\nby the powerful generalization of contrastive learning techniques, and the\nintroduction of new tools to monitor and diagnose contrastive training. We\nsubstantiate our claims with empirical evidence on CIFAR10, ImageNet, and other\ndatasets, where FlatNCE consistently outperforms InfoNCE.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 15:50:43 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Chen", "Junya", ""], ["Gan", "Zhe", ""], ["Li", "Xuan", ""], ["Guo", "Qing", ""], ["Chen", "Liqun", ""], ["Gao", "Shuyang", ""], ["Chung", "Tagyoung", ""], ["Xu", "Yi", ""], ["Zeng", "Belinda", ""], ["Lu", "Wenlian", ""], ["Li", "Fan", ""], ["Carin", "Lawrence", ""], ["Tao", "Chenyang", ""]]}, {"id": "2107.01170", "submitter": "Nidhika Yadav", "authors": "Nidhika Yadav", "title": "Computing Fuzzy Rough Set based Similarities with Fuzzy Inference and\n  Its Application to Sentence Similarity Computations", "comments": "5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several research initiatives have been proposed for computing similarity\nbetween two Fuzzy Sets in analysis through Fuzzy Rough Sets. These techniques\nyield two measures viz. lower similarity and upper similarity. While in most\napplications only one entity is useful to further analysis and for drawing\nconclusions. The aim of this paper is to propose novel technique to combine\nFuzzy Rough Set based lower similarity and upper similarity using Fuzzy\nInference Engine. Further, the proposed approach is applied to the problem\ncomputing sentence similarity and have been evaluated on SICK2014 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 16:21:25 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Yadav", "Nidhika", ""]]}, {"id": "2107.01181", "submitter": "Li Mi", "authors": "Li Mi, Yangjun Ou, Zhenzhong Chen", "title": "Visual Relationship Forecasting in Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world scenarios often require the anticipation of object interactions in\nunknown future, which would assist the decision-making process of both humans\nand agents. To meet this challenge, we present a new task named Visual\nRelationship Forecasting (VRF) in videos to explore the prediction of visual\nrelationships in a reasoning manner. Specifically, given a subject-object pair\nwith H existing frames, VRF aims to predict their future interactions for the\nnext T frames without visual evidence. To evaluate the VRF task, we introduce\ntwo video datasets named VRF-AG and VRF-VidOR, with a series of\nspatio-temporally localized visual relation annotations in a video. These two\ndatasets densely annotate 13 and 35 visual relationships in 1923 and 13447\nvideo clips, respectively. In addition, we present a novel Graph Convolutional\nTransformer (GCT) framework, which captures both object-level and frame-level\ndependencies by spatio-temporal Graph Convolution Network and Transformer.\nExperimental results on both VRF-AG and VRF-VidOR datasets demonstrate that GCT\noutperforms the state-of-the-art sequence modelling methods on visual\nrelationship forecasting.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 16:43:19 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Mi", "Li", ""], ["Ou", "Yangjun", ""], ["Chen", "Zhenzhong", ""]]}, {"id": "2107.01183", "submitter": "Saif M. Mohammad Dr.", "authors": "Saif M. Mohammad", "title": "Ethics Sheets for AI Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several high-profile events, such as the use of biased recidivism systems and\nmass testing of emotion recognition systems on vulnerable sub-populations, have\nhighlighted how technology will often lead to more adverse outcomes for those\nthat are already marginalized. In this paper, I will make a case for thinking\nabout ethical considerations not just at the level of individual models and\ndatasets, but also at the level of AI tasks. I will present a new form of such\nan effort, Ethics Sheets for AI Tasks, dedicated to fleshing out the\nassumptions and ethical considerations hidden in how a task is commonly framed\nand in the choices we make regarding the data, method, and evaluation. Finally,\nI will provide an example ethics sheet for automatic emotion recognition.\nTogether with Data Sheets for datasets and Model Cards for AI systems, Ethics\nSheets aid in the development and deployment of responsible AI systems.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 16:45:40 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 15:55:39 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Mohammad", "Saif M.", ""]]}, {"id": "2107.01188", "submitter": "Martin Schuetz", "authors": "Martin J. A. Schuetz, J. Kyle Brubaker, Helmut G. Katzgraber", "title": "Combinatorial Optimization with Physics-Inspired Graph Neural Networks", "comments": "Manuscript: 13 pages, 5 figures, 1 table. Supplemental Material: 1\n  page, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.AI math.OC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate how graph neural networks can be used to solve combinatorial\noptimization problems. Our approach is broadly applicable to canonical NP-hard\nproblems in the form of quadratic unconstrained binary optimization problems,\nsuch as maximum cut, minimum vertex cover, maximum independent set, as well as\nIsing spin glasses and higher-order generalizations thereof in the form of\npolynomial unconstrained binary optimization problems. We apply a relaxation\nstrategy to the problem Hamiltonian to generate a differentiable loss function\nwith which we train the graph neural network and apply a simple projection to\ninteger variables once the unsupervised training process has completed. We\nshowcase our approach with numerical results for the canonical maximum cut and\nmaximum independent set problems. We find that the graph neural network\noptimizer performs on par or outperforms existing solvers, with the ability to\nscale beyond the state of the art to problems with millions of variables.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 16:54:35 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Schuetz", "Martin J. A.", ""], ["Brubaker", "J. Kyle", ""], ["Katzgraber", "Helmut G.", ""]]}, {"id": "2107.01192", "submitter": "Sudeep Pasricha", "authors": "Liping Wang, Saideep Tiku, Sudeep Pasricha", "title": "CHISEL: Compression-Aware High-Accuracy Embedded Indoor Localization\n  with Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  GPS technology has revolutionized the way we localize and navigate outdoors.\nHowever, the poor reception of GPS signals in buildings makes it unsuitable for\nindoor localization. WiFi fingerprinting-based indoor localization is one of\nthe most promising ways to meet this demand. Unfortunately, most work in the\ndomain fails to resolve challenges associated with deployability on\nresource-limited embedded devices. In this work, we propose a compression-aware\nand high-accuracy deep learning framework called CHISEL that outperforms the\nbest-known works in the area while maintaining localization robustness on\nembedded devices.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 17:00:01 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Wang", "Liping", ""], ["Tiku", "Saideep", ""], ["Pasricha", "Sudeep", ""]]}, {"id": "2107.01194", "submitter": "Lin Zhang", "authors": "Lin Zhang, Qi She, Zhengyang Shen, Changhu Wang", "title": "How Incomplete is Contrastive Learning? An Inter-intra Variant Dual\n  Representation Method for Self-supervised Video Recognition", "comments": "10 pages with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contrastive learning applied to self-supervised representation learning has\nseen a resurgence in deep models. In this paper, we find that existing\ncontrastive learning based solutions for self-supervised video recognition\nfocus on inter-variance encoding but ignore the intra-variance existing in\nclips within the same video. We thus propose to learn dual representations for\neach clip which (\\romannumeral 1) encode intra-variance through a shuffle-rank\npretext task; (\\romannumeral 2) encode inter-variance through a temporal\ncoherent contrastive loss. Experiment results show that our method plays an\nessential role in balancing inter and intra variances and brings consistent\nperformance gains on multiple backbones and contrastive learning frameworks.\nIntegrated with SimCLR and pretrained on Kinetics-400, our method achieves\n$\\textbf{82.0\\%}$ and $\\textbf{51.2\\%}$ downstream classification accuracy on\nUCF101 and HMDB51 test sets respectively and $\\textbf{46.1\\%}$ video retrieval\naccuracy on UCF101, outperforming both pretext-task based and contrastive\nlearning based counterparts.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 17:03:04 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 02:07:19 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhang", "Lin", ""], ["She", "Qi", ""], ["Shen", "Zhengyang", ""], ["Wang", "Changhu", ""]]}, {"id": "2107.01248", "submitter": "Vinod Kumar Kurmi", "authors": "Indu Joshi and Ayush Utkarsh and Riya Kothari and Vinod K Kurmi and\n  Antitza Dantcheva and Sumantra Dutta Roy and Prem Kumar Kalra", "title": "Data Uncertainty Guided Noise-aware Preprocessing Of Fingerprints", "comments": "IJCNN 2021 (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The effectiveness of fingerprint-based authentication systems on good quality\nfingerprints is established long back. However, the performance of standard\nfingerprint matching systems on noisy and poor quality fingerprints is far from\nsatisfactory. Towards this, we propose a data uncertainty-based framework which\nenables the state-of-the-art fingerprint preprocessing models to quantify noise\npresent in the input image and identify fingerprint regions with background\nnoise and poor ridge clarity. Quantification of noise helps the model two\nfolds: firstly, it makes the objective function adaptive to the noise in a\nparticular input fingerprint and consequently, helps to achieve robust\nperformance on noisy and distorted fingerprint regions. Secondly, it provides a\nnoise variance map which indicates noisy pixels in the input fingerprint image.\nThe predicted noise variance map enables the end-users to understand erroneous\npredictions due to noise present in the input image. Extensive experimental\nevaluation on 13 publicly available fingerprint databases, across different\narchitectural choices and two fingerprint processing tasks demonstrate\neffectiveness of the proposed framework.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 19:47:58 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Joshi", "Indu", ""], ["Utkarsh", "Ayush", ""], ["Kothari", "Riya", ""], ["Kurmi", "Vinod K", ""], ["Dantcheva", "Antitza", ""], ["Roy", "Sumantra Dutta", ""], ["Kalra", "Prem Kumar", ""]]}, {"id": "2107.01253", "submitter": "Paulito Palmes", "authors": "Paulito P. Palmes, Akihiro Kishimoto, Radu Marinescu, Parikshit Ram,\n  Elizabeth Daly", "title": "Designing Machine Learning Pipeline Toolkit for AutoML Surrogate\n  Modeling Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The pipeline optimization problem in machine learning requires simultaneous\noptimization of pipeline structures and parameter adaptation of their elements.\nHaving an elegant way to express these structures can help lessen the\ncomplexity in the management and analysis of their performances together with\nthe different choices of optimization strategies. With these issues in mind, we\ncreated the AutoMLPipeline (AMLP) toolkit which facilitates the creation and\nevaluation of complex machine learning pipeline structures using simple\nexpressions. We use AMLP to find optimal pipeline signatures, datamine them,\nand use these datamined features to speed-up learning and prediction. We\nformulated a two-stage pipeline optimization with surrogate modeling in AMLP\nwhich outperforms other AutoML approaches with a 4-hour time budget in less\nthan 5 minutes of AMLP computation time.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 20:06:40 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 00:06:56 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Palmes", "Paulito P.", ""], ["Kishimoto", "Akihiro", ""], ["Marinescu", "Radu", ""], ["Ram", "Parikshit", ""], ["Daly", "Elizabeth", ""]]}, {"id": "2107.01277", "submitter": "Mukund Telukunta", "authors": "Mukund Telukunta, Venkata Sriram Siddhardh Nadendla", "title": "Non-Comparative Fairness for Human-Auditing and Its Relation to\n  Traditional Fairness Notions", "comments": "arXiv admin note: substantial text overlap with arXiv:2009.04383", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bias evaluation in machine-learning based services (MLS) based on traditional\nalgorithmic fairness notions that rely on comparative principles is practically\ndifficult, making it necessary to rely on human auditor feedback. However, in\nspite of taking rigorous training on various comparative fairness notions,\nhuman auditors are known to disagree on various aspects of fairness notions in\npractice, making it difficult to collect reliable feedback. This paper offers a\nparadigm shift to the domain of algorithmic fairness via proposing a new\nfairness notion based on the principle of non-comparative justice. In contrary\nto traditional fairness notions where the outcomes of two individuals/groups\nare compared, our proposed notion compares the MLS' outcome with a desired\noutcome for each input. This desired outcome naturally describes a human\nauditor's expectation, and can be easily used to evaluate MLS on crowd-auditing\nplatforms. We show that any MLS can be deemed fair from the perspective of\ncomparative fairness (be it in terms of individual fairness, statistical\nparity, equal opportunity or calibration) if it is non-comparatively fair with\nrespect to a fair auditor. We also show that the converse holds true in the\ncontext of individual fairness. Given that such an evaluation relies on the\ntrustworthiness of the auditor, we also present an approach to identify fair\nand reliable auditors by estimating their biases with respect to a given set of\nsensitive attributes, as well as quantify the uncertainty in the estimation of\nbiases within a given MLS. Furthermore, all of the above results are also\nvalidated on COMPAS, German credit and Adult Census Income datasets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 20:05:22 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Telukunta", "Mukund", ""], ["Nadendla", "Venkata Sriram Siddhardh", ""]]}, {"id": "2107.01325", "submitter": "Connor Lawless", "authors": "Connor Lawless, Oktay Gunluk", "title": "Fair Decision Rules for Binary Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning has begun automating decision making in\nfields as varied as college admissions, credit lending, and criminal\nsentencing. The socially sensitive nature of some of these applications\ntogether with increasing regulatory constraints has necessitated the need for\nalgorithms that are both fair and interpretable. In this paper we consider the\nproblem of building Boolean rule sets in disjunctive normal form (DNF), an\ninterpretable model for binary classification, subject to fairness constraints.\nWe formulate the problem as an integer program that maximizes classification\naccuracy with explicit constraints on two different measures of classification\nparity: equality of opportunity and equalized odds. Column generation\nframework, with a novel formulation, is used to efficiently search over\nexponentially many possible rules. When combined with faster heuristics, our\nmethod can deal with large data-sets. Compared to other fair and interpretable\nclassifiers, our method is able to find rule sets that meet stricter notions of\nfairness with a modest trade-off in accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 02:32:17 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Lawless", "Connor", ""], ["Gunluk", "Oktay", ""]]}, {"id": "2107.01326", "submitter": "Ken Li", "authors": "Hui Li, Xing Fu, Ruofan Wu, Jinyu Xu, Kai Xiao, Xiaofu Chang, Weiqiang\n  Wang, Shuai Chen, Leilei Shi, Tao Xiong, Yuan Qi", "title": "SHORING: Design Provable Conditional High-Order Interaction Network via\n  Symbolic Testing", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning provides a promising way to extract effective representations\nfrom raw data in an end-to-end fashion and has proven its effectiveness in\nvarious domains such as computer vision, natural language processing, etc.\nHowever, in domains such as content/product recommendation and risk management,\nwhere sequence of event data is the most used raw data form and experts derived\nfeatures are more commonly used, deep learning models struggle to dominate the\ngame. In this paper, we propose a symbolic testing framework that helps to\nanswer the question of what kinds of expert-derived features could be learned\nby a neural network. Inspired by this testing framework, we introduce an\nefficient architecture named SHORING, which contains two components:\n\\textit{event network} and \\textit{sequence network}. The \\textit{event}\nnetwork learns arbitrarily yet efficiently high-order \\textit{event-level}\nembeddings via a provable reparameterization trick, the \\textit{sequence}\nnetwork aggregates from sequence of \\textit{event-level} embeddings. We argue\nthat SHORING is capable of learning certain standard symbolic expressions which\nthe standard multi-head self-attention network fails to learn, and conduct\ncomprehensive experiments and ablation studies on four synthetic datasets and\nthree real-world datasets. The results show that SHORING empirically\noutperforms the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 02:33:32 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Li", "Hui", ""], ["Fu", "Xing", ""], ["Wu", "Ruofan", ""], ["Xu", "Jinyu", ""], ["Xiao", "Kai", ""], ["Chang", "Xiaofu", ""], ["Wang", "Weiqiang", ""], ["Chen", "Shuai", ""], ["Shi", "Leilei", ""], ["Xiong", "Tao", ""], ["Qi", "Yuan", ""]]}, {"id": "2107.01347", "submitter": "Paolo Fazzini", "authors": "Paolo Fazzini, Isaac Wheeler, Francesco Petracchini", "title": "Traffic Signal Control with Communicative Deep Reinforcement Learning\n  Agents: a Case Study", "comments": "41 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this work we theoretically and experimentally analyze Multi-Agent\nAdvantage Actor-Critic (MA2C) and Independent Advantage Actor-Critic (IA2C),\ntwo recently proposed multi-agent reinforcement learning methods that can be\napplied to control traffic signals in urban areas. The two methods differ in\ntheir use of a reward calculated locally or globally and in the management of\nagents' communication. We analyze the methods theoretically with the framework\nprovided by non-Markov decision processes, which provides useful insights in\nthe analysis of the algorithms. Moreover, we analyze the efficacy and the\nrobustness of the methods experimentally by testing them in two traffic areas\nin the Bologna (Italy) area, simulated by SUMO, a software tool. The\nexperimental results indicate that MA2C achieves the best performance in the\nmajority of cases, outperforms the alternative method considered, and displays\nsufficient stability during the learning process.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 05:12:03 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Fazzini", "Paolo", ""], ["Wheeler", "Isaac", ""], ["Petracchini", "Francesco", ""]]}, {"id": "2107.01348", "submitter": "Vektor Dewanto", "authors": "Vektor Dewanto, Marcus Gallagher", "title": "Examining average and discounted reward optimality criteria in\n  reinforcement learning", "comments": "14 pages, 3 figures, 10-page main content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In reinforcement learning (RL), the goal is to obtain an optimal policy, for\nwhich the optimality criterion is fundamentally important. Two major optimality\ncriteria are average and discounted rewards, where the later is typically\nconsidered as an approximation to the former. While the discounted reward is\nmore popular, it is problematic to apply in environments that have no natural\nnotion of discounting. This motivates us to revisit a) the progression of\noptimality criteria in dynamic programming, b) justification for and\ncomplication of an artificial discount factor, and c) benefits of directly\nmaximizing the average reward. Our contributions include a thorough examination\nof the relationship between average and discounted rewards, as well as a\ndiscussion of their pros and cons in RL. We emphasize that average-reward RL\nmethods possess the ingredient and mechanism for developing the general\ndiscounting-free optimality criterion (Veinott, 1969) in RL.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 05:28:56 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Dewanto", "Vektor", ""], ["Gallagher", "Marcus", ""]]}, {"id": "2107.01349", "submitter": "Dong-Wan Choi", "authors": "Jong-Yeong Kim and Dong-Wan Choi", "title": "Split-and-Bridge: Adaptable Class Incremental Learning within a Single\n  Neural Network", "comments": "In AAAI-2021", "journal-ref": "In Proceedings of the AAAI Conference on Artificial Intelligence\n  (Vol. 35, No. 9, pp. 8137-8145) 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning has been a major problem in the deep learning community,\nwhere the main challenge is how to effectively learn a series of newly arriving\ntasks without forgetting the knowledge of previous tasks. Initiated by Learning\nwithout Forgetting (LwF), many of the existing works report that knowledge\ndistillation is effective to preserve the previous knowledge, and hence they\ncommonly use a soft label for the old task, namely a knowledge distillation\n(KD) loss, together with a class label for the new task, namely a cross entropy\n(CE) loss, to form a composite loss for a single neural network. However, this\napproach suffers from learning the knowledge by a CE loss as a KD loss often\nmore strongly influences the objective function when they are in a competitive\nsituation within a single network. This could be a critical problem\nparticularly in a class incremental scenario, where the knowledge across tasks\nas well as within the new task, both of which can only be acquired by a CE\nloss, is essentially learned due to the existence of a unified classifier. In\nthis paper, we propose a novel continual learning method, called\nSplit-and-Bridge, which can successfully address the above problem by partially\nsplitting a neural network into two partitions for training the new task\nseparated from the old task and re-connecting them for learning the knowledge\nacross tasks. In our thorough experimental analysis, our Split-and-Bridge\nmethod outperforms the state-of-the-art competitors in KD-based continual\nlearning.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 05:51:53 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Kim", "Jong-Yeong", ""], ["Choi", "Dong-Wan", ""]]}, {"id": "2107.01353", "submitter": "Hao Peng", "authors": "Hao Peng, Pei Chen, Rui Liu, Luonan Chen", "title": "Spatiotemporal convolutional network for time-series prediction and\n  causal inference", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making predictions in a robust way is not easy for nonlinear systems. In this\nwork, a neural network computing framework, i.e., a spatiotemporal\nconvolutional network (STCN), was developed to efficiently and accurately\nrender a multistep-ahead prediction of a time series by employing a\nspatial-temporal information (STI) transformation. The STCN combines the\nadvantages of both the temporal convolutional network (TCN) and the STI\nequation, which maps the high-dimensional/spatial data to the future temporal\nvalues of a target variable, thus naturally providing the prediction of the\ntarget variable. From the observed variables, the STCN also infers the causal\nfactors of the target variable in the sense of Granger causality, which are in\nturn selected as effective spatial information to improve the prediction\nrobustness. The STCN was successfully applied to both benchmark systems and\nreal-world datasets, all of which show superior and robust performance in\nmultistep-ahead prediction, even when the data were perturbed by noise. From\nboth theoretical and computational viewpoints, the STCN has great potential in\npractical applications in artificial intelligence (AI) or machine learning\nfields as a model-free method based only on the observed data, and also opens a\nnew way to explore the observed high-dimensional data in a dynamical manner for\nmachine learning.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 06:20:43 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Peng", "Hao", ""], ["Chen", "Pei", ""], ["Liu", "Rui", ""], ["Chen", "Luonan", ""]]}, {"id": "2107.01354", "submitter": "Dong-Wan Choi", "authors": "Hakbin Kim and Dong-Wan Choi", "title": "Pool of Experts: Realtime Querying Specialized Knowledge in Massive\n  Neural Networks", "comments": "In SIGMOD/PODS 2021", "journal-ref": "SIGMOD Conference 2021: 2244-2252", "doi": "10.1145/3448016.3457326", "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the great success of deep learning technologies, training and\ndelivery of a practically serviceable model is still a highly time-consuming\nprocess. Furthermore, a resulting model is usually too generic and heavyweight,\nand hence essentially goes through another expensive model compression phase to\nfit in a resource-limited device like embedded systems. Inspired by the fact\nthat a machine learning task specifically requested by mobile users is often\nmuch simpler than it is supported by a massive generic model, this paper\nproposes a framework, called Pool of Experts (PoE), that instantly builds a\nlightweight and task-specific model without any training process. For a\nrealtime model querying service, PoE first extracts a pool of primitive\ncomponents, called experts, from a well-trained and sufficiently generic\nnetwork by exploiting a novel conditional knowledge distillation method, and\nthen performs our train-free knowledge consolidation to quickly combine\nnecessary experts into a lightweight network for a target task. Thanks to this\ntrain-free property, in our thorough empirical study, PoE can build a fairly\naccurate yet compact model in a realtime manner, whereas it takes a few minutes\nper query for the other training methods to achieve a similar level of the\naccuracy.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 06:31:54 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Kim", "Hakbin", ""], ["Choi", "Dong-Wan", ""]]}, {"id": "2107.01358", "submitter": "Girish Varma", "authors": "Sandeep Nagar, Marius Dufraisse, Girish Varma", "title": "CInC Flow: Characterizable Invertible 3x3 Convolution", "comments": "Accepted for the 4th Workshop on Tractable Probabilistic\n  Modeling,(UAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows are an essential alternative to GANs for generative\nmodelling, which can be optimized directly on the maximum likelihood of the\ndataset. They also allow computation of the exact latent vector corresponding\nto an image since they are composed of invertible transformations. However, the\nrequirement of invertibility of the transformation prevents standard and\nexpressive neural network models such as CNNs from being directly used.\nEmergent convolutions were proposed to construct an invertible 3$\\times$3 CNN\nlayer using a pair of masked CNN layers, making them inefficient. We study\nconditions such that 3$\\times$3 CNNs are invertible, allowing them to construct\nexpressive normalizing flows. We derive necessary and sufficient conditions on\na padded CNN for it to be invertible. Our conditions for invertibility are\nsimple, can easily be maintained during the training process. Since we require\nonly a single CNN layer for every effective invertible CNN layer, our approach\nis more efficient than emerging convolutions. We also proposed a coupling\nmethod, Quad-coupling. We benchmark our approach and show similar performance\nresults to emergent convolutions while improving the model's efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 06:55:24 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Nagar", "Sandeep", ""], ["Dufraisse", "Marius", ""], ["Varma", "Girish", ""]]}, {"id": "2107.01361", "submitter": "Vinod Kumar Kurmi", "authors": "Indu Joshi and Ayush Utkarsh and Riya Kothari and Vinod K Kurmi and\n  Antitza Dantcheva and Sumantra Dutta Roy and Prem Kumar Kalra", "title": "Sensor-invariant Fingerprint ROI Segmentation Using Recurrent\n  Adversarial Learning", "comments": "IJCNN 2021 (Accepted)", "journal-ref": "IJCNN 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A fingerprint region of interest (roi) segmentation algorithm is designed to\nseparate the foreground fingerprint from the background noise. All the learning\nbased state-of-the-art fingerprint roi segmentation algorithms proposed in the\nliterature are benchmarked on scenarios when both training and testing\ndatabases consist of fingerprint images acquired from the same sensors.\nHowever, when testing is conducted on a different sensor, the segmentation\nperformance obtained is often unsatisfactory. As a result, every time a new\nfingerprint sensor is used for testing, the fingerprint roi segmentation model\nneeds to be re-trained with the fingerprint image acquired from the new sensor\nand its corresponding manually marked ROI. Manually marking fingerprint ROI is\nexpensive because firstly, it is time consuming and more importantly, requires\ndomain expertise. In order to save the human effort in generating annotations\nrequired by state-of-the-art, we propose a fingerprint roi segmentation model\nwhich aligns the features of fingerprint images derived from the unseen sensor\nsuch that they are similar to the ones obtained from the fingerprints whose\nground truth roi masks are available for training. Specifically, we propose a\nrecurrent adversarial learning based feature alignment network that helps the\nfingerprint roi segmentation model to learn sensor-invariant features.\nConsequently, sensor-invariant features learnt by the proposed roi segmentation\nmodel help it to achieve improved segmentation performance on fingerprints\nacquired from the new sensor. Experiments on publicly available FVC databases\ndemonstrate the efficacy of the proposed work.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 07:16:39 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Joshi", "Indu", ""], ["Utkarsh", "Ayush", ""], ["Kothari", "Riya", ""], ["Kurmi", "Vinod K", ""], ["Dantcheva", "Antitza", ""], ["Roy", "Sumantra Dutta", ""], ["Kalra", "Prem Kumar", ""]]}, {"id": "2107.01366", "submitter": "Eugene Kharitonov", "authors": "Rahma Chaabouni, Roberto Dess\\`i, Eugene Kharitonov", "title": "Can Transformers Jump Around Right in Natural Language? Assessing\n  Performance Transfer from SCAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Despite their practical success, modern seq2seq architectures are unable to\ngeneralize systematically on several SCAN tasks. Hence, it is not clear if\nSCAN-style compositional generalization is useful in realistic NLP tasks. In\nthis work, we study the benefit that such compositionality brings about to\nseveral machine translation tasks. We present several focused modifications of\nTransformer that greatly improve generalization capabilities on SCAN and select\none that remains on par with a vanilla Transformer on a standard machine\ntranslation (MT) task. Next, we study its performance in low-resource settings\nand on a newly introduced distribution-shifted English-French translation task.\nOverall, we find that improvements of a SCAN-capable model do not directly\ntransfer to the resource-rich MT setup. In contrast, in the low-resource setup,\ngeneral modifications lead to an improvement of up to 13.1% BLEU score w.r.t. a\nvanilla Transformer. Similarly, an improvement of 14% in an accuracy-based\nmetric is achieved in the introduced compositional English-French translation\ntask. This provides experimental evidence that the compositional generalization\nassessed in SCAN is particularly useful in resource-starved and domain-shifted\nscenarios.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 07:45:41 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Chaabouni", "Rahma", ""], ["Dess\u00ec", "Roberto", ""], ["Kharitonov", "Eugene", ""]]}, {"id": "2107.01390", "submitter": "Thai Hung Le", "authors": "Hung Le", "title": "Memory and attention in deep learning", "comments": "PHD Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intelligence necessitates memory. Without memory, humans fail to perform\nvarious nontrivial tasks such as reading novels, playing games or solving\nmaths. As the ultimate goal of machine learning is to derive intelligent\nsystems that learn and act automatically just like human, memory construction\nfor machine is inevitable. Artificial neural networks model neurons and\nsynapses in the brain by interconnecting computational units via weights, which\nis a typical class of machine learning algorithms that resembles memory\nstructure. Their descendants with more complicated modeling techniques (a.k.a\ndeep learning) have been successfully applied to many practical problems and\ndemonstrated the importance of memory in the learning process of machinery\nsystems. Recent progresses on modeling memory in deep learning have revolved\naround external memory constructions, which are highly inspired by\ncomputational Turing models and biological neuronal systems. Attention\nmechanisms are derived to support acquisition and retention operations on the\nexternal memory. Despite the lack of theoretical foundations, these approaches\nhave shown promises to help machinery systems reach a higher level of\nintelligence. The aim of this thesis is to advance the understanding on memory\nand attention in deep learning. Its contributions include: (i) presenting a\ncollection of taxonomies for memory, (ii) constructing new memory-augmented\nneural networks (MANNs) that support multiple control and memory units, (iii)\nintroducing variability via memory in sequential generative models, (iv)\nsearching for optimal writing operations to maximise the memorisation capacity\nin slot-based memory networks, and (v) simulating the Universal Turing Machine\nvia Neural Stored-program Memory-a new kind of external memory for neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 09:21:13 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Le", "Hung", ""]]}, {"id": "2107.01392", "submitter": "Ayushe Gangal", "authors": "Peeyush Kumar, Ayushe Gangal and Sunita Kumari", "title": "WisdomNet: Prognosis of COVID-19 with Slender Prospect of False Negative\n  Cases and Vaticinating the Probability of Maturation to ARDS using\n  Posteroanterior Chest X-Rays", "comments": "10 pages, 4 figures, 1 table", "journal-ref": "J Pure Appl Microbiol. 2020;14(suppl 1):869-878, Article Number:\n  6236", "doi": "10.22207/JPAM.14.SPL1.24", "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Coronavirus is a large virus family consisting of diverse viruses, some of\nwhich disseminate among mammals and others cause sickness among humans.\nCOVID-19 is highly contagious and is rapidly spreading, rendering its early\ndiagnosis of preeminent status. Researchers, medical specialists and\norganizations all over the globe have been working tirelessly to combat this\nvirus and help in its containment. In this paper, a novel neural network called\nWisdomNet has been proposed, for the diagnosis of COVID-19 using chest X-rays.\nThe WisdomNet uses the concept of Wisdom of Crowds as its founding idea. It is\na two-layered convolutional Neural Network (CNN), which takes chest x-ray\nimages as input. Both layers of the proposed neural network consist of a number\nof neural networks each. The dataset used for this study consists of chest\nx-ray images of COVID-19 positive patients, compiled and shared by Dr. Cohen on\nGitHub, and the chest x-ray images of healthy lungs and lungs affected by viral\nand bacterial pneumonia were obtained from Kaggle. The network not only\npinpoints the presence of COVID-19, but also gives the probability of the\ndisease maturing into Acute Respiratory Distress Syndrome (ARDS). Thus,\npredicting the progression of the disease in the COVID-19 positive patients.\nThe network also slender the occurrences of false negative cases by employing a\nhigh threshold value, thus aids in curbing the spread of the disease and gives\nan accuracy of 100% for successfully predicting COVID-19 among the chest x-rays\nof patients affected with COVID-19, bacterial and viral pneumonia.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 09:55:28 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Kumar", "Peeyush", ""], ["Gangal", "Ayushe", ""], ["Kumari", "Sunita", ""]]}, {"id": "2107.01396", "submitter": "Yajie Wang", "authors": "Yajie Wang, Shangbo Wu, Wenyi Jiang, Shengang Hao, Yu-an Tan and\n  Quanxin Zhang", "title": "Demiguise Attack: Crafting Invisible Semantic Adversarial Perturbations\n  with Perceptual Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been found to be vulnerable to adversarial\nexamples. Adversarial examples are malicious images with visually imperceptible\nperturbations. While these carefully crafted perturbations restricted with\ntight $\\Lp$ norm bounds are small, they are still easily perceivable by humans.\nThese perturbations also have limited success rates when attacking black-box\nmodels or models with defenses like noise reduction filters. To solve these\nproblems, we propose Demiguise Attack, crafting ``unrestricted'' perturbations\nwith Perceptual Similarity. Specifically, we can create powerful and\nphotorealistic adversarial examples by manipulating semantic information based\non Perceptual Similarity. Adversarial examples we generate are friendly to the\nhuman visual system (HVS), although the perturbations are of large magnitudes.\nWe extend widely-used attacks with our approach, enhancing adversarial\neffectiveness impressively while contributing to imperceptibility. Extensive\nexperiments show that the proposed method not only outperforms various\nstate-of-the-art attacks in terms of fooling rate, transferability, and\nrobustness against defenses but can also improve attacks effectively. In\naddition, we also notice that our implementation can simulate illumination and\ncontrast changes that occur in real-world scenarios, which will contribute to\nexposing the blind spots of DNNs.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 10:14:01 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Wang", "Yajie", ""], ["Wu", "Shangbo", ""], ["Jiang", "Wenyi", ""], ["Hao", "Shengang", ""], ["Tan", "Yu-an", ""], ["Zhang", "Quanxin", ""]]}, {"id": "2107.01407", "submitter": "Lionel Blond\\'e", "authors": "Lionel Blond\\'e, Alexandros Kalousis", "title": "Where is the Grass Greener? Revisiting Generalized Policy Iteration for\n  Offline Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of state-of-the-art baselines in the offline RL regime varies\nwidely over the spectrum of dataset qualities, ranging from \"far-from-optimal\"\nrandom data to \"close-to-optimal\" expert demonstrations. We re-implement these\nunder a fair, unified, and highly factorized framework, and show that when a\ngiven baseline outperforms its competing counterparts on one end of the\nspectrum, it never does on the other end. This consistent trend prevents us\nfrom naming a victor that outperforms the rest across the board. We attribute\nthe asymmetry in performance between the two ends of the quality spectrum to\nthe amount of inductive bias injected into the agent to entice it to posit that\nthe behavior underlying the offline dataset is optimal for the task. The more\nbias is injected, the higher the agent performs, provided the dataset is\nclose-to-optimal. Otherwise, its effect is brutally detrimental. Adopting an\nadvantage-weighted regression template as base, we conduct an investigation\nwhich corroborates that injections of such optimality inductive bias, when not\ndone parsimoniously, makes the agent subpar in the datasets it was dominant as\nsoon as the offline policy is sub-optimal. In an effort to design methods that\nperform well across the whole spectrum, we revisit the generalized policy\niteration scheme for the offline regime, and study the impact of nine distinct\nnewly-introduced proposal distributions over actions, involved in proposed\ngeneralization of the policy evaluation and policy improvement update rules. We\nshow that certain orchestrations strike the right balance and can improve the\nperformance on one end of the spectrum without harming it on the other end.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 11:00:56 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Blond\u00e9", "Lionel", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "2107.01410", "submitter": "Amirhossein Nouranizadeh", "authors": "Amirhossein Nouranizadeh, Mohammadjavad Matinkia, Mohammad Rahmati,\n  Reza Safabakhsh", "title": "Maximum Entropy Weighted Independent Set Pooling for Graph Neural\n  Networks", "comments": "21 pages, 12 figures, under review in 35th Conference on Neural\n  Information Processing Systems (NeurIPS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel pooling layer for graph neural networks\nbased on maximizing the mutual information between the pooled graph and the\ninput graph. Since the maximum mutual information is difficult to compute, we\nemploy the Shannon capacity of a graph as an inductive bias to our pooling\nmethod. More precisely, we show that the input graph to the pooling layer can\nbe viewed as a representation of a noisy communication channel. For such a\nchannel, sending the symbols belonging to an independent set of the graph\nyields a reliable and error-free transmission of information. We show that\nreaching the maximum mutual information is equivalent to finding a maximum\nweight independent set of the graph where the weights convey entropy contents.\nThrough this communication theoretic standpoint, we provide a distinct\nperspective for posing the problem of graph pooling as maximizing the\ninformation transmission rate across a noisy communication channel, implemented\nby a graph neural network. We evaluate our method, referred to as Maximum\nEntropy Weighted Independent Set Pooling (MEWISPool), on graph classification\ntasks and the combinatorial optimization problem of the maximum independent\nset. Empirical results demonstrate that our method achieves the\nstate-of-the-art and competitive results on graph classification tasks and the\nmaximum independent set problem in several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 11:19:28 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Nouranizadeh", "Amirhossein", ""], ["Matinkia", "Mohammadjavad", ""], ["Rahmati", "Mohammad", ""], ["Safabakhsh", "Reza", ""]]}, {"id": "2107.01412", "submitter": "Sen Yan", "authors": "Wanyun Cui, Sen Yan", "title": "Isotonic Data Augmentation for Knowledge Distillation", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge distillation uses both real hard labels and soft labels predicted\nby teacher models as supervision. Intuitively, we expect the soft labels and\nhard labels to be concordant w.r.t. their orders of probabilities. However, we\nfound critical order violations between hard labels and soft labels in\naugmented samples. For example, for an augmented sample $x=0.7*panda+0.3*cat$,\nwe expect the order of meaningful soft labels to be\n$P_\\text{soft}(panda|x)>P_\\text{soft}(cat|x)>P_\\text{soft}(other|x)$. But real\nsoft labels usually violate the order, e.g.\n$P_\\text{soft}(tiger|x)>P_\\text{soft}(panda|x)>P_\\text{soft}(cat|x)$. We\nattribute this to the unsatisfactory generalization ability of the teacher,\nwhich leads to the prediction error of augmented samples. Empirically, we found\nthe violations are common and injure the knowledge transfer. In this paper, we\nintroduce order restrictions to data augmentation for knowledge distillation,\nwhich is denoted as isotonic data augmentation (IDA). We use isotonic\nregression (IR) -- a classic technique from statistics -- to eliminate the\norder violations. We show that IDA can be modeled as a tree-structured IR\nproblem. We thereby adapt the classical IRT-BIN algorithm for optimal solutions\nwith $O(c \\log c)$ time complexity, where $c$ is the number of labels. In order\nto further reduce the time complexity, we also propose a GPU-friendly\napproximation with linear time complexity. We have verified on variant datasets\nand data augmentation techniques that our proposed IDA algorithms effectively\nincreases the accuracy of knowledge distillation by eliminating the rank\nviolations.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 11:34:44 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 05:39:45 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Cui", "Wanyun", ""], ["Yan", "Sen", ""]]}, {"id": "2107.01428", "submitter": "Konrad Dabrowski", "authors": "Konrad K. Dabrowski and Peter Jonsson and Sebastian Ordyniak and\n  George Osipov", "title": "Solving Infinite-Domain CSPs Using the Patchwork Property", "comments": "34 pages, 2 figures. Parts of this article appeared in the\n  proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The constraint satisfaction problem (CSP) has important applications in\ncomputer science and AI. In particular, infinite-domain CSPs have been\nintensively used in subareas of AI such as spatio-temporal reasoning. Since\nconstraint satisfaction is a computationally hard problem, much work has been\ndevoted to identifying restricted problems that are efficiently solvable. One\nway of doing this is to restrict the interactions of variables and constraints,\nand a highly successful approach is to bound the treewidth of the underlying\nprimal graph. Bodirsky & Dalmau [J. Comput. System. Sci. 79(1), 2013] and Huang\net al. [Artif. Intell. 195, 2013] proved that CSP$(\\Gamma)$ can be solved in\n$n^{f(w)}$ time (where $n$ is the size of the instance, $w$ is the treewidth of\nthe primal graph and $f$ is a computable function) for certain classes of\nconstraint languages $\\Gamma$. We improve this bound to $f(w) \\cdot n^{O(1)}$,\nwhere the function $f$ only depends on the language $\\Gamma$, for CSPs whose\nbasic relations have the patchwork property. Hence, such problems are\nfixed-parameter tractable and our algorithm is asymptotically faster than the\nprevious ones. Additionally, our approach is not restricted to binary\nconstraints, so it is applicable to a strictly larger class of problems than\nthat of Huang et al. However, there exist natural problems that are covered by\nBodirsky & Dalmau's algorithm but not by ours, and we begin investigating ways\nof generalising our results to larger families of languages. We also analyse\nour algorithm with respect to its running time and show that it is optimal\n(under the Exponential Time Hypothesis) for certain languages such as Allen's\nInterval Algebra.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 13:04:41 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Dabrowski", "Konrad K.", ""], ["Jonsson", "Peter", ""], ["Ordyniak", "Sebastian", ""], ["Osipov", "George", ""]]}, {"id": "2107.01429", "submitter": "Aritra Sarkar", "authors": "Aritra Sarkar", "title": "QKSA: Quantum Knowledge Seeking Agent", "comments": "pre-print: motivation, core thesis and baseline framework", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this article we present the motivation and the core thesis towards the\nimplementation of a Quantum Knowledge Seeking Agent (QKSA). QKSA is a general\nreinforcement learning agent that can be used to model classical and quantum\ndynamics. It merges ideas from universal artificial general intelligence,\nconstructor theory and genetic programming to build a robust and general\nframework for testing the capabilities of the agent in a variety of\nenvironments. It takes the artificial life (or, animat) path to artificial\ngeneral intelligence where a population of intelligent agents are instantiated\nto explore valid ways of modelling the perceptions. The multiplicity and\nsurvivability of the agents are defined by the fitness, with respect to the\nexplainability and predictability, of a resource-bounded computational model of\nthe environment. This general learning approach is then employed to model the\nphysics of an environment based on subjective observer states of the agents. A\nspecific case of quantum process tomography as a general modelling principle is\npresented. The various background ideas and a baseline formalism are discussed\nin this article which sets the groundwork for the implementations of the QKSA\nthat are currently in active development.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 13:07:58 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Sarkar", "Aritra", ""]]}, {"id": "2107.01462", "submitter": "Sujay Rittikar", "authors": "Sujay Uday Rittikar", "title": "Development of a Conversation State Recognition System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the evolution of the concept of Speaker diarization using LSTM, it is\nrelatively easier to understand the speaker identities for specific segments of\ninput audio stream data than manually tagging the data. With such a concept, it\nis highly desirable to consider the possibility of using the identified speaker\nidentities to aid in recognizing the Speaker States in a conversation. In this\nstudy, the Markov Chains are used to identify and update the Speaker States for\nthe next conversations between the same set of speakers, to enable\nidentification of their states in the most natural and long conversations. The\nmodel is based on several audio samples from natural conversations of three or\ngreater than three speakers in two datasets with overall total error\npercentages for recognized states being lesser than or equal to 12%. The\nfindings imply that the proposed extension to the Speaker diarization is\neffective to predict the states for a conversation.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 16:33:23 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Rittikar", "Sujay Uday", ""]]}, {"id": "2107.01466", "submitter": "Zhenyu Yuan", "authors": "Zhenyu Yuan, Yuxin Jiang, Jingjing Li, Handong Huang", "title": "A convolutional neural network for prestack fracture detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fractures are widely developed in hydrocarbon reservoirs and constitute the\naccumulation spaces and transport channels of oil and gas. Fracture detection\nis a fundamental task for reservoir characterization. From prestack seismic\ngathers, anisotropic analysis and inversion were commonly applied to\ncharacterize the dominant orientations and relative intensities of fractures.\nHowever, the existing methods were mostly based on the vertical aligned facture\nhypothesis, it is impossible for them to recognize fracture dip. Furthermore,\nit is difficult or impractical for existing methods to attain the real fracture\ndensities. Based on data-driven deep learning, this paper designed a\nconvolutional neural network to perform prestack fracture detection.\nCapitalizing on the connections between seismic responses and fracture\nparameters, a suitable azimuth dataset was firstly generated through fracture\neffective medium modeling and anisotropic plane wave analyzing. Then a\nmulti-input and multi-output convolutional neural network was constructed to\nsimultaneously detect fracture density, dip and strike azimuth. The application\non a practical survey validated the effectiveness of the proposed CNN model.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 17:05:29 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Yuan", "Zhenyu", ""], ["Jiang", "Yuxin", ""], ["Li", "Jingjing", ""], ["Huang", "Handong", ""]]}, {"id": "2107.01495", "submitter": "Hejie Cui", "authors": "Hejie Cui, Zijie Lu, Pan Li, and Carl Yang", "title": "On Positional and Structural Node Features for Graph Neural Networks on\n  Non-attributed Graphs", "comments": "This paper has been accepted to the Sixth International Workshop on\n  Deep Learning on Graphs (DLG-KDD'21) (co-located with KDD'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have been widely used in various graph-related\nproblems such as node classification and graph classification, where the\nsuperior performance is mainly established when natural node features are\navailable. However, it is not well understood how GNNs work without natural\nnode features, especially regarding the various ways to construct artificial\nones. In this paper, we point out the two types of artificial node\nfeatures,i.e., positional and structural node features, and provide insights on\nwhy each of them is more appropriate for certain tasks,i.e., positional node\nclassification, structural node classification, and graph classification.\nExtensive experimental results on 10 benchmark datasets validate our insights,\nthus leading to a practical guideline on the choices between different\nartificial node features for GNNs on non-attributed graphs. The code is\navailable at https://github.com/zjzijielu/gnn-exp/.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 20:37:26 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Cui", "Hejie", ""], ["Lu", "Zijie", ""], ["Li", "Pan", ""], ["Yang", "Carl", ""]]}, {"id": "2107.01496", "submitter": "Ming Li", "authors": "Ming Li, Pradeep K.Murukannaiah, Catholijn M.Jonker", "title": "A Data-Driven Method for Recognizing Automated Negotiation Strategies", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Understanding an opponent agent helps in negotiating with it. Existing works\non understanding opponents focus on preference modeling (or estimating the\nopponent's utility function). An important but largely unexplored direction is\nrecognizing an opponent's negotiation strategy, which captures the opponent's\ntactics, e.g., to be tough at the beginning but to concede toward the deadline.\nRecognizing complex, state-of-the-art, negotiation strategies is extremely\nchallenging, and simple heuristics may not be adequate for this purpose. We\npropose a novel data-driven approach for recognizing an opponent's s\nnegotiation strategy. Our approach includes a data generation method for an\nagent to generate domain-independent sequences by negotiating with a variety of\nopponents across domains, a feature engineering method for representing\nnegotiation data as time series with time-step features and overall features,\nand a hybrid (recurrent neural network-based) deep learning method for\nrecognizing an opponent's strategy from the time series of bids. We perform\nextensive experiments, spanning four problem scenarios, to demonstrate the\neffectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 20:43:47 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Li", "Ming", ""], ["Murukannaiah", "Pradeep K.", ""], ["Jonker", "Catholijn M.", ""]]}, {"id": "2107.01525", "submitter": "Hongwei Zhang", "authors": "Hongwei Zhang and Weidong Zou and Hongbo Zhao and Qi Ming and Tijin\n  Yan and Yuanqing Xia and Weipeng Cao", "title": "AdaL: Adaptive Gradient Transformation Contributes to Convergences and\n  Generalizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive optimization methods have been widely used in deep learning. They\nscale the learning rates adaptively according to the past gradient, which has\nbeen shown to be effective to accelerate the convergence. However, they suffer\nfrom poor generalization performance compared with SGD. Recent studies point\nthat smoothing exponential gradient noise leads to generalization degeneration\nphenomenon. Inspired by this, we propose AdaL, with a transformation on the\noriginal gradient. AdaL accelerates the convergence by amplifying the gradient\nin the early stage, as well as dampens the oscillation and stabilizes the\noptimization by shrinking the gradient later. Such modification alleviates the\nsmoothness of gradient noise, which produces better generalization performance.\nWe have theoretically proved the convergence of AdaL and demonstrated its\neffectiveness on several benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 02:55:36 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhang", "Hongwei", ""], ["Zou", "Weidong", ""], ["Zhao", "Hongbo", ""], ["Ming", "Qi", ""], ["Yan", "Tijin", ""], ["Xia", "Yuanqing", ""], ["Cao", "Weipeng", ""]]}, {"id": "2107.01528", "submitter": "Jiexia Ye", "authors": "Jiexia Ye, Furong Zheng, Juanjuan Zhao, Kejiang Ye, Chengzhong Xu", "title": "Incorporating Reachability Knowledge into a Multi-Spatial Graph\n  Convolution Based Seq2Seq Model for Traffic Forecasting", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurate traffic state prediction is the foundation of transportation control\nand guidance. It is very challenging due to the complex spatiotemporal\ndependencies in traffic data. Existing works cannot perform well for multi-step\ntraffic prediction that involves long future time period. The spatiotemporal\ninformation dilution becomes serve when the time gap between input step and\npredicted step is large, especially when traffic data is not sufficient or\nnoisy. To address this issue, we propose a multi-spatial graph convolution\nbased Seq2Seq model. Our main novelties are three aspects: (1) We enrich the\nspatiotemporal information of model inputs by fusing multi-view features (time,\nlocation and traffic states) (2) We build multiple kinds of spatial\ncorrelations based on both prior knowledge and data-driven knowledge to improve\nmodel performance especially in insufficient or noisy data cases. (3) A\nspatiotemporal attention mechanism based on reachability knowledge is novelly\ndesigned to produce high-level features fed into decoder of Seq2Seq directly to\nease information dilution. Our model is evaluated on two real world traffic\ndatasets and achieves better performance than other competitors.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 03:23:30 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Ye", "Jiexia", ""], ["Zheng", "Furong", ""], ["Zhao", "Juanjuan", ""], ["Ye", "Kejiang", ""], ["Xu", "Chengzhong", ""]]}, {"id": "2107.01557", "submitter": "Sandeep Kumar Singh", "authors": "Sandeep Kumar Singh, Jaya Shradha Fowdur, Jakob Gawlikowski and Daniel\n  Medina", "title": "Leveraging Evidential Deep Learning Uncertainties with Graph-based\n  Clustering to Detect Anomalies", "comments": "Under submission in a Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding and representing traffic patterns are key to detecting\nanomalies in the maritime domain. To this end, we propose a novel graph-based\ntraffic representation and association scheme to cluster trajectories of\nvessels using automatic identification system (AIS) data. We utilize the\n(un)clustered data to train a recurrent neural network (RNN)-based evidential\nregression model, which can predict a vessel's trajectory at future timesteps\nwith its corresponding prediction uncertainty. This paper proposes the usage of\na deep learning (DL)-based uncertainty estimation in detecting maritime\nanomalies, such as unusual vessel maneuvering. Furthermore, we utilize the\nevidential deep learning classifiers to detect unusual turns of vessels and the\nloss of AIS signal using predicted class probabilities with associated\nuncertainties. Our experimental results suggest that using graph-based\nclustered data improves the ability of the DL models to learn the\ntemporal-spatial correlation of data and associated uncertainties. Using\ndifferent AIS datasets and experiments, we demonstrate that the estimated\nprediction uncertainty yields fundamental information for the detection of\ntraffic anomalies in the maritime and, possibly in other domains.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 06:31:59 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Singh", "Sandeep Kumar", ""], ["Fowdur", "Jaya Shradha", ""], ["Gawlikowski", "Jakob", ""], ["Medina", "Daniel", ""]]}, {"id": "2107.01615", "submitter": "Ralph Foorthuis", "authors": "Ralph Foorthuis", "title": "A Typology of Data Anomalies", "comments": "13 pages, 5 figures. Presented at the 17th International Conference\n  on Information Processing and Management of Uncertainty in Knowledge-Based\n  Systems (IPMU 2018). Note: for a fully developed and more detailed typology\n  of anomalies, see the follow-up publication 'On the Nature and Types of\n  Anomalies: A Review of Deviations in Data'. arXiv admin note: text overlap\n  with arXiv:2007.15634", "journal-ref": null, "doi": "10.1007/978-3-319-91476-3_3", "report-no": null, "categories": "cs.LG cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomalies are cases that are in some way unusual and do not appear to fit the\ngeneral patterns present in the dataset. Several conceptualizations exist to\ndistinguish between different types of anomalies. However, these are either too\nspecific to be generally applicable or so abstract that they neither provide\nconcrete insight into the nature of anomaly types nor facilitate the functional\nevaluation of anomaly detection algorithms. With the recent criticism on 'black\nbox' algorithms and analytics it has become clear that this is an undesirable\nsituation. This paper therefore introduces a general typology of anomalies that\noffers a clear and tangible definition of the different types of anomalies in\ndatasets. The typology also facilitates the evaluation of the functional\ncapabilities of anomaly detection algorithms and as a framework assists in\nanalyzing the conceptual levels of data, patterns and anomalies. Finally, it\nserves as an analytical tool for studying anomaly types from other typologies.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 13:12:24 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Foorthuis", "Ralph", ""]]}, {"id": "2107.01621", "submitter": "Sarah McDaid PhD", "authors": "Edward McDaid, Sarah McDaid", "title": "The Composability of Intermediate Values in Composable Inductive\n  Programming", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is believed that mechanisms including intermediate values enable\ncomposable inductive programming (CIP) to be used to produce software of any\nsize. We present the results of a study that investigated the relationships\nbetween program size, the number of intermediate values and the number of test\ncases used to specify programs using CIP. In the study 96,000 programs of\nvarious sizes were randomly generated, decomposed into fragments and\ntransformed into test cases. The test cases were then used to regenerate new\nversions of the original programs using Zoea. The results show linear\nrelationships between the number of intermediate values and regenerated program\nsize, and between the number of test cases and regenerated program size within\nthe size range studied. In addition, as program size increases there is\nincreasing scope for trading off the number of test cases against the number of\nintermediate values and vice versa.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 13:17:52 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["McDaid", "Edward", ""], ["McDaid", "Sarah", ""]]}, {"id": "2107.01654", "submitter": "Joao Marques-Silva", "authors": "Xuanxiang Huang and Yacine Izza and Alexey Ignatiev and Martin C.\n  Cooper and Nicholas Asher and Joao Marques-Silva", "title": "Efficient Explanations for Knowledge Compilation Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge compilation (KC) languages find a growing number of practical uses,\nincluding in Constraint Programming (CP) and in Machine Learning (ML). In most\napplications, one natural question is how to explain the decisions made by\nmodels represented by a KC language. This paper shows that for many of the best\nknown KC languages, well-known classes of explanations can be computed in\npolynomial time. These classes include deterministic decomposable negation\nnormal form (d-DNNF), and so any KC language that is strictly less succinct\nthan d-DNNF. Furthermore, the paper also investigates the conditions under\nwhich polynomial time computation of explanations can be extended to KC\nlanguages more succinct than d-DNNF.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 14:45:32 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 09:58:58 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Huang", "Xuanxiang", ""], ["Izza", "Yacine", ""], ["Ignatiev", "Alexey", ""], ["Cooper", "Martin C.", ""], ["Asher", "Nicholas", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "2107.01656", "submitter": "Baban Gain", "authors": "Baban Gain and Dibyanayan Bandyopadhyay and Asif Ekbal", "title": "IITP at WAT 2021: System description for English-Hindi Multimodal\n  Translation Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural Machine Translation (NMT) is a predominant machine translation\ntechnology nowadays because of its end-to-end trainable flexibility. However,\nNMT still struggles to translate properly in low-resource settings specifically\non distant language pairs. One way to overcome this is to use the information\nfrom other modalities if available. The idea is that despite differences in\nlanguages, both the source and target language speakers see the same thing and\nthe visual representation of both the source and target is the same, which can\npositively assist the system. Multimodal information can help the NMT system to\nimprove the translation by removing ambiguity on some phrases or words. We\nparticipate in the 8th Workshop on Asian Translation (WAT - 2021) for\nEnglish-Hindi multimodal translation task and achieve 42.47 and 37.50 BLEU\npoints for Evaluation and Challenge subset, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 14:56:28 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Gain", "Baban", ""], ["Bandyopadhyay", "Dibyanayan", ""], ["Ekbal", "Asif", ""]]}, {"id": "2107.01667", "submitter": "Nicol\\`o Botteghi", "authors": "Nicol\\`o Botteghi, Khaled Alaa, Mannes Poel, Beril Sirmacek, Christoph\n  Brune, Abeje Mersha, Stefano Stramigioli", "title": "Low Dimensional State Representation Learning with Robotics Priors in\n  Continuous Action Spaces", "comments": "Paper Accepted at IROS2021. This work has been submitted to the IEEE\n  for possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous robots require high degrees of cognitive and motoric intelligence\nto come into our everyday life. In non-structured environments and in the\npresence of uncertainties, such degrees of intelligence are not easy to obtain.\nReinforcement learning algorithms have proven to be capable of solving\ncomplicated robotics tasks in an end-to-end fashion without any need for\nhand-crafted features or policies. Especially in the context of robotics, in\nwhich the cost of real-world data is usually extremely high, reinforcement\nlearning solutions achieving high sample efficiency are needed. In this paper,\nwe propose a framework combining the learning of a low-dimensional state\nrepresentation, from high-dimensional observations coming from the robot's raw\nsensory readings, with the learning of the optimal policy, given the learned\nstate representation. We evaluate our framework in the context of mobile robot\nnavigation in the case of continuous state and action spaces. Moreover, we\nstudy the problem of transferring what learned in the simulated virtual\nenvironment to the real robot without further retraining using real-world data\nin the presence of visual and depth distractors, such as lighting changes and\nmoving obstacles.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 15:42:01 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Botteghi", "Nicol\u00f2", ""], ["Alaa", "Khaled", ""], ["Poel", "Mannes", ""], ["Sirmacek", "Beril", ""], ["Brune", "Christoph", ""], ["Mersha", "Abeje", ""], ["Stramigioli", "Stefano", ""]]}, {"id": "2107.01677", "submitter": "Nicol\\`o Botteghi", "authors": "Nicol\\`o Botteghi, Mannes Poel, Beril Sirmacek, Christoph Brune", "title": "Low-Dimensional State and Action Representation Learning with MDP\n  Homomorphism Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning has shown its ability in solving complicated\nproblems directly from high-dimensional observations. However, in end-to-end\nsettings, Reinforcement Learning algorithms are not sample-efficient and\nrequires long training times and quantities of data. In this work, we proposed\na framework for sample-efficient Reinforcement Learning that take advantage of\nstate and action representations to transform a high-dimensional problem into a\nlow-dimensional one. Moreover, we seek to find the optimal policy mapping\nlatent states to latent actions. Because now the policy is learned on abstract\nrepresentations, we enforce, using auxiliary loss functions, the lifting of\nsuch policy to the original problem domain. Results show that the novel\nframework can efficiently learn low-dimensional and interpretable state and\naction representations and the optimal latent policy.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 16:26:04 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Botteghi", "Nicol\u00f2", ""], ["Poel", "Mannes", ""], ["Sirmacek", "Beril", ""], ["Brune", "Christoph", ""]]}, {"id": "2107.01715", "submitter": "Gal Dalal", "authors": "Assaf Hallak and Gal Dalal, Steven Dalton, Iuri Frosio, Shie Mannor,\n  Gal Chechik", "title": "Improve Agents without Retraining: Parallel Tree Search with Off-Policy\n  Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree Search (TS) is crucial to some of the most influential successes in\nreinforcement learning. Here, we tackle two major challenges with TS that limit\nits usability: \\textit{distribution shift} and \\textit{scalability}. We first\ndiscover and analyze a counter-intuitive phenomenon: action selection through\nTS and a pre-trained value function often leads to lower performance compared\nto the original pre-trained agent, even when having access to the exact state\nand reward in future steps. We show this is due to a distribution shift to\nareas where value estimates are highly inaccurate and analyze this effect using\nExtreme Value theory. To overcome this problem, we introduce a novel off-policy\ncorrection term that accounts for the mismatch between the pre-trained value\nand its corresponding TS policy by penalizing under-sampled trajectories. We\nprove that our correction eliminates the above mismatch and bound the\nprobability of sub-optimal action selection. Our correction significantly\nimproves pre-trained Rainbow agents without any further training, often more\nthan doubling their scores on Atari games. Next, we address the scalability\nissue given by the computational complexity of exhaustive TS that scales\nexponentially with the tree depth. We introduce Batch-BFS: a GPU breadth-first\nsearch that advances all nodes in each depth of the tree simultaneously.\nBatch-BFS reduces runtime by two orders of magnitude and, beyond inference,\nenables also training with TS of depths that were not feasible before. We train\nDQN agents from scratch using TS and show improvement in several Atari games\ncompared to both the original DQN and the more advanced Rainbow.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 19:32:24 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Hallak", "Assaf", ""], ["Dalal", "Gal", ""], ["Dalton", "Steven", ""], ["Frosio", "Iuri", ""], ["Mannor", "Shie", ""], ["Chechik", "Gal", ""]]}, {"id": "2107.01759", "submitter": "Jibum Kim", "authors": "Jaeseung Lee, Woojin Choi, Jibum Kim", "title": "Learning Delaunay Triangulation using Self-attention and Domain\n  Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Delaunay triangulation is a well-known geometric combinatorial optimization\nproblem with various applications. Many algorithms can generate Delaunay\ntriangulation given an input point set, but most are nontrivial algorithms\nrequiring an understanding of geometry or the performance of additional\ngeometric operations, such as the edge flip. Deep learning has been used to\nsolve various combinatorial optimization problems; however, generating Delaunay\ntriangulation based on deep learning remains a difficult problem, and very few\nresearch has been conducted due to its complexity. In this paper, we propose a\nnovel deep-learning-based approach for learning Delaunay triangulation using a\nnew attention mechanism based on self-attention and domain knowledge. The\nproposed model is designed such that the model efficiently learns\npoint-to-point relationships using self-attention in the encoder. In the\ndecoder, a new attention score function using domain knowledge is proposed to\nprovide a high penalty when the geometric requirement is not satisfied. The\nstrength of the proposed attention score function lies in its ability to extend\nits application to solving other combinatorial optimization problems involving\ngeometry. When the proposed neural net model is well trained, it is simple and\nefficient because it automatically predicts the Delaunay triangulation for an\ninput point set without requiring any additional geometric operations. We\nconduct experiments to demonstrate the effectiveness of the proposed model and\nconclude that it exhibits better performance compared with other\ndeep-learning-based approaches.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 01:56:37 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Lee", "Jaeseung", ""], ["Choi", "Woojin", ""], ["Kim", "Jibum", ""]]}, {"id": "2107.01760", "submitter": "Taichi Murayama", "authors": "Taichi Murayama, Shoko Wakamiya, Eiji Aramaki", "title": "Single Model for Influenza Forecasting of Multiple Countries by\n  Multi-task Learning", "comments": "European Conference on Machine Learning and Principles and Practice\n  of Knowledge Discovery in Databases (ECML-PKDD), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accurate forecasting of infectious epidemic diseases such as influenza is\na crucial task undertaken by medical institutions. Although numerous flu\nforecasting methods and models based mainly on historical flu activity data and\nonline user-generated contents have been proposed in previous studies, no flu\nforecasting model targeting multiple countries using two types of data exists\nat present. Our paper leverages multi-task learning to tackle the challenge of\nbuilding one flu forecasting model targeting multiple countries; each country\nas each task. Also, to develop the flu prediction model with higher\nperformance, we solved two issues; finding suitable search queries, which are\npart of the user-generated contents, and how to leverage search queries\nefficiently in the model creation. For the first issue, we propose the transfer\napproaches from English to other languages. For the second issue, we propose a\nnovel flu forecasting model that takes advantage of search queries using an\nattention mechanism and extend the model to a multi-task model for multiple\ncountries' flu forecasts. Experiments on forecasting flu epidemics in five\ncountries demonstrate that our model significantly improved the performance by\nleveraging the search queries and multi-task learning compared to the\nbaselines.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 02:09:26 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 04:20:42 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Murayama", "Taichi", ""], ["Wakamiya", "Shoko", ""], ["Aramaki", "Eiji", ""]]}, {"id": "2107.01776", "submitter": "Zhiwei Lin", "authors": "Zhiwei Lin, Yongtao Wang and Hongxiang Lin", "title": "Continual Contrastive Self-supervised Learning for Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For artificial learning systems, continual learning over time from a stream\nof data is essential. The burgeoning studies on supervised continual learning\nhave achieved great progress, while the study of catastrophic forgetting in\nunsupervised learning is still blank. Among unsupervised learning methods,\nself-supervise learning method shows tremendous potential on visual\nrepresentation without any labeled data at scale. To improve the visual\nrepresentation of self-supervised learning, larger and more varied data is\nneeded. In the real world, unlabeled data is generated at all times. This\ncircumstance provides a huge advantage for the learning of the self-supervised\nmethod. However, in the current paradigm, packing previous data and current\ndata together and training it again is a waste of time and resources. Thus, a\ncontinual self-supervised learning method is badly needed. In this paper, we\nmake the first attempt to implement the continual contrastive self-supervised\nlearning by proposing a rehearsal method, which keeps a few exemplars from the\nprevious data. Instead of directly combining saved exemplars with the current\ndata set for training, we leverage self-supervised knowledge distillation to\ntransfer contrastive information among previous data to the current network by\nmimicking similarity score distribution inferred by the old network over a set\nof saved exemplars. Moreover, we build an extra sample queue to assist the\nnetwork to distinguish between previous and current data and prevent mutual\ninterference while learning their own feature representation. Experimental\nresults show that our method performs well on CIFAR100 and ImageNet-Sub.\nCompared with the baselines, which learning tasks without taking any technique,\nwe improve the image classification top-1 accuracy by 1.60% on CIFAR100, 2.86%\non ImageNet-Sub and 1.29% on ImageNet-Full under 10 incremental steps setting.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 03:53:42 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 03:00:14 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Lin", "Zhiwei", ""], ["Wang", "Yongtao", ""], ["Lin", "Hongxiang", ""]]}, {"id": "2107.01808", "submitter": "Sahib Singh", "authors": "Sahib Singh, Rosanne Liu", "title": "Why is Pruning at Initialization Immune to Reinitializing and Shuffling?", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent studies assessing the efficacy of pruning neural networks methods\nuncovered a surprising finding: when conducting ablation studies on existing\npruning-at-initialization methods, namely SNIP, GraSP, SynFlow, and magnitude\npruning, performances of these methods remain unchanged and sometimes even\nimprove when randomly shuffling the mask positions within each layer (Layerwise\nShuffling) or sampling new initial weight values (Reinit), while keeping\npruning masks the same. We attempt to understand the reason behind such network\nimmunity towards weight/mask modifications, by studying layer-wise statistics\nbefore and after randomization operations. We found that under each of the\npruning-at-initialization methods, the distribution of unpruned weights changed\nminimally with randomization operations.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 06:04:56 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Singh", "Sahib", ""], ["Liu", "Rosanne", ""]]}, {"id": "2107.01809", "submitter": "Xiao Yang", "authors": "Xiao Yang, Yinpeng Dong, Tianyu Pang, Hang Su, Jun Zhu", "title": "Boosting Transferability of Targeted Adversarial Examples via\n  Hierarchical Generative Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer-based adversarial attacks can effectively evaluate model robustness\nin the black-box setting. Though several methods have demonstrated impressive\ntransferability of untargeted adversarial examples, targeted adversarial\ntransferability is still challenging. The existing methods either have low\ntargeted transferability or sacrifice computational efficiency. In this paper,\nwe develop a simple yet practical framework to efficiently craft targeted\ntransfer-based adversarial examples. Specifically, we propose a conditional\ngenerative attacking model, which can generate the adversarial examples\ntargeted at different classes by simply altering the class embedding and share\na single backbone. Extensive experiments demonstrate that our method improves\nthe success rates of targeted black-box attacks by a significant margin over\nthe existing methods -- it reaches an average success rate of 29.6\\% against\nsix diverse models based only on one substitute white-box model in the standard\ntesting of NeurIPS 2017 competition, which outperforms the state-of-the-art\ngradient-based attack methods (with an average success rate of $<$2\\%) by a\nlarge margin. Moreover, the proposed method is also more efficient beyond an\norder of magnitude than gradient-based methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 06:17:47 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Yang", "Xiao", ""], ["Dong", "Yinpeng", ""], ["Pang", "Tianyu", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""]]}, {"id": "2107.01820", "submitter": "Michael Thrun PhD", "authors": "Alfred Ultsch, J\\\"org Hoffmann, Maximilian R\\\"ohnert, Malte Von Bonin,\n  Uta Oelschl\\\"agel, Cornelia Brendel, Michael C. Thrun", "title": "An Explainable AI System for the Diagnosis of High Dimensional\n  Biomedical Data", "comments": "22 pages, 1 figure, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical state of the art flow cytometry data samples consists of measures of\nmore than 100.000 cells in 10 or more features. AI systems are able to diagnose\nsuch data with almost the same accuracy as human experts. However, there is one\ncentral challenge in such systems: their decisions have far-reaching\nconsequences for the health and life of people, and therefore, the decisions of\nAI systems need to be understandable and justifiable by humans. In this work,\nwe present a novel explainable AI method, called ALPODS, which is able to\nclassify (diagnose) cases based on clusters, i.e., subpopulations, in the\nhigh-dimensional data. ALPODS is able to explain its decisions in a form that\nis understandable for human experts. For the identified subpopulations, fuzzy\nreasoning rules expressed in the typical language of domain experts are\ngenerated. A visualization method based on these rules allows human experts to\nunderstand the reasoning used by the AI system. A comparison to a selection of\nstate of the art explainable AI systems shows that ALPODS operates efficiently\non known benchmark data and also on everyday routine case data.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 07:00:29 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Ultsch", "Alfred", ""], ["Hoffmann", "J\u00f6rg", ""], ["R\u00f6hnert", "Maximilian", ""], ["Von Bonin", "Malte", ""], ["Oelschl\u00e4gel", "Uta", ""], ["Brendel", "Cornelia", ""], ["Thrun", "Michael C.", ""]]}, {"id": "2107.01825", "submitter": "Yao Yao", "authors": "Yao Yao, Li Xiao, Zhicheng An, Wanpeng Zhang, and Dijun Luo", "title": "Sample Efficient Reinforcement Learning via Model-Ensemble Exploration\n  and Exploitation", "comments": "7 pages, 5 figures, accepted by IEEE International Conference on\n  Robotics and Automation 2021 (IEEE ICRA 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based deep reinforcement learning has achieved success in various\ndomains that require high sample efficiencies, such as Go and robotics.\nHowever, there are some remaining issues, such as planning efficient\nexplorations to learn more accurate dynamic models, evaluating the uncertainty\nof the learned models, and more rational utilization of models. To mitigate\nthese issues, we present MEEE, a model-ensemble method that consists of\noptimistic exploration and weighted exploitation. During exploration, unlike\nprior methods directly selecting the optimal action that maximizes the expected\naccumulative return, our agent first generates a set of action candidates and\nthen seeks out the optimal action that takes both expected return and future\nobservation novelty into account. During exploitation, different discounted\nweights are assigned to imagined transition tuples according to their model\nuncertainty respectively, which will prevent model predictive error propagation\nin agent training. Experiments on several challenging continuous control\nbenchmark tasks demonstrated that our approach outperforms other model-free and\nmodel-based state-of-the-art methods, especially in sample complexity.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 07:18:20 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Yao", "Yao", ""], ["Xiao", "Li", ""], ["An", "Zhicheng", ""], ["Zhang", "Wanpeng", ""], ["Luo", "Dijun", ""]]}, {"id": "2107.01829", "submitter": "Jim Mainprice", "authors": "Yoojin Oh, Marc Toussaint, Jim Mainprice", "title": "A System for Traded Control Teleoperation of Manipulation Tasks using\n  Intent Prediction from Hand Gestures", "comments": "Accepted to IEEE-RoMAN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper presents a teleoperation system that includes robot perception and\nintent prediction from hand gestures. The perception module identifies the\nobjects present in the robot workspace and the intent prediction module which\nobject the user likely wants to grasp. This architecture allows the approach to\nrely on traded control instead of direct control: we use hand gestures to\nspecify the goal objects for a sequential manipulation task, the robot then\nautonomously generates a grasping or a retrieving motion using trajectory\noptimization. The perception module relies on the model-based tracker to\nprecisely track the 6D pose of the objects and makes use of a state of the art\nlearning-based object detection and segmentation method, to initialize the\ntracker by automatically detecting objects in the scene. Goal objects are\nidentified from user hand gestures using a trained a multi-layer perceptron\nclassifier. After presenting all the components of the system and their\nempirical evaluation, we present experimental results comparing our pipeline to\na direct traded control approach (i.e., one that does not use prediction) which\nshows that using intent prediction allows to bring down the overall task\nexecution time.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 07:37:17 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Oh", "Yoojin", ""], ["Toussaint", "Marc", ""], ["Mainprice", "Jim", ""]]}, {"id": "2107.01830", "submitter": "Cai Shaofeng", "authors": "Shaofeng Cai, Kaiping Zheng, Gang Chen, H. V. Jagadish, Beng Chin Ooi,\n  Meihui Zhang", "title": "ARM-Net: Adaptive Relation Modeling Network for Structured Data", "comments": "14 pages, 11 figures, 5 tables, published as a conference paper in\n  ACM SIGMOD 2020", "journal-ref": null, "doi": "10.1145/3448016.3457321", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational databases are the de facto standard for storing and querying\nstructured data, and extracting insights from structured data requires advanced\nanalytics. Deep neural networks (DNNs) have achieved super-human prediction\nperformance in particular data types, e.g., images. However, existing DNNs may\nnot produce meaningful results when applied to structured data. The reason is\nthat there are correlations and dependencies across combinations of attribute\nvalues in a table, and these do not follow simple additive patterns that can be\neasily mimicked by a DNN. The number of possible such cross features is\ncombinatorial, making them computationally prohibitive to model. Furthermore,\nthe deployment of learning models in real-world applications has also\nhighlighted the need for interpretability, especially for high-stakes\napplications, which remains another issue of concern to DNNs.\n  In this paper, we present ARM-Net, an adaptive relation modeling network\ntailored for structured data, and a lightweight framework ARMOR based on\nARM-Net for relational data analytics. The key idea is to model feature\ninteractions with cross features selectively and dynamically, by first\ntransforming the input features into exponential space, and then determining\nthe interaction order and interaction weights adaptively for each cross\nfeature. We propose a novel sparse attention mechanism to dynamically generate\nthe interaction weights given the input tuple, so that we can explicitly model\ncross features of arbitrary orders with noisy features filtered selectively.\nThen during model inference, ARM-Net can specify the cross features being used\nfor each prediction for higher accuracy and better interpretability. Our\nextensive experiments on real-world datasets demonstrate that ARM-Net\nconsistently outperforms existing models and provides more interpretable\npredictions for data-driven decision making.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 07:37:24 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Cai", "Shaofeng", ""], ["Zheng", "Kaiping", ""], ["Chen", "Gang", ""], ["Jagadish", "H. V.", ""], ["Ooi", "Beng Chin", ""], ["Zhang", "Meihui", ""]]}, {"id": "2107.01832", "submitter": "Wei Li", "authors": "Xin Liu and Zhisong Pan", "title": "Provable Convergence of Nesterov Accelerated Method for\n  Over-Parameterized Neural Networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the empirical success of deep learning, it still lacks theoretical\nunderstandings to explain why randomly initialized neural network trained by\nfirst-order optimization methods is able to achieve zero training loss, even\nthough its landscape is non-convex and non-smooth. Recently, there are some\nworks to demystifies this phenomenon under over-parameterized regime. In this\nwork, we make further progress on this area by considering a commonly used\nmomentum optimization algorithm: Nesterov accelerated method (NAG). We analyze\nthe convergence of NAG for two-layer fully connected neural network with ReLU\nactivation. Specifically, we prove that the error of NAG converges to zero at a\nlinear convergence rate $1-\\Theta(1/\\sqrt{\\kappa})$, where $\\kappa > 1$ is\ndetermined by the initialization and the architecture of neural network.\nComparing to the rate $1-\\Theta(1/\\kappa)$ of gradient descent, NAG achieves an\nacceleration. Besides, it also validates NAG and Heavy-ball method can achieve\na similar convergence rate.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 07:40:35 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Liu", "Xin", ""], ["Pan", "Zhisong", ""]]}, {"id": "2107.01836", "submitter": "Jim Mainprice", "authors": "Janik Hager, Ruben Bauer, Marc Toussaint, Jim Mainprice", "title": "GraspME -- Grasp Manifold Estimator", "comments": "Accepted to RoMan 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we introduce a Grasp Manifold Estimator (GraspME) to detect\ngrasp affordances for objects directly in 2D camera images. To perform\nmanipulation tasks autonomously it is crucial for robots to have such\ngraspability models of the surrounding objects. Grasp manifolds have the\nadvantage of providing continuously infinitely many grasps, which is not the\ncase when using other grasp representations such as predefined grasp points.\nFor instance, this property can be leveraged in motion optimization to define\ngoal sets as implicit surface constraints in the robot configuration space. In\nthis work, we restrict ourselves to the case of estimating possible\nend-effector positions directly from 2D camera images. To this extend, we\ndefine grasp manifolds via a set of key points and locate them in images using\na Mask R-CNN backbone. Using learned features allows generalizing to different\nview angles, with potentially noisy images, and objects that were not part of\nthe training set. We rely on simulation data only and perform experiments on\nsimple and complex objects, including unseen ones. Our framework achieves an\ninference speed of 11.5 fps on a GPU, an average precision for keypoint\nestimation of 94.5% and a mean pixel distance of only 1.29. This shows that we\ncan estimate the objects very well via bounding boxes and segmentation masks as\nwell as approximate the correct grasp manifold's keypoint coordinates.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 07:49:12 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Hager", "Janik", ""], ["Bauer", "Ruben", ""], ["Toussaint", "Marc", ""], ["Mainprice", "Jim", ""]]}, {"id": "2107.01854", "submitter": "Ke Ma", "authors": "Ke Ma and Qianqian Xu and Jinshan Zeng and Xiaochun Cao and Qingming\n  Huang", "title": "Poisoning Attack against Estimating from Pairwise Comparisons", "comments": "31 pages", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3087514", "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.GT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  As pairwise ranking becomes broadly employed for elections, sports\ncompetitions, recommendations, and so on, attackers have strong motivation and\nincentives to manipulate the ranking list. They could inject malicious\ncomparisons into the training data to fool the victim. Such a technique is\ncalled poisoning attack in regression and classification tasks. In this paper,\nto the best of our knowledge, we initiate the first systematic investigation of\ndata poisoning attacks on pairwise ranking algorithms, which can be formalized\nas the dynamic and static games between the ranker and the attacker and can be\nmodeled as certain kinds of integer programming problems. To break the\ncomputational hurdle of the underlying integer programming problems, we\nreformulate them into the distributionally robust optimization (DRO) problems,\nwhich are computationally tractable. Based on such DRO formulations, we propose\ntwo efficient poisoning attack algorithms and establish the associated\ntheoretical guarantees. The effectiveness of the suggested poisoning attack\nstrategies is demonstrated by a series of toy simulations and several real data\nexperiments. These experimental results show that the proposed methods can\nsignificantly reduce the performance of the ranker in the sense that the\ncorrelation between the true ranking list and the aggregated results can be\ndecreased dramatically.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 08:16:01 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Ma", "Ke", ""], ["Xu", "Qianqian", ""], ["Zeng", "Jinshan", ""], ["Cao", "Xiaochun", ""], ["Huang", "Qingming", ""]]}, {"id": "2107.01856", "submitter": "Michael Schlechtinger", "authors": "Michael Schlechtinger, Damaris Kosack, Heiko Paulheim, Thomas Fetzer", "title": "Winning at Any Cost -- Infringing the Cartel Prohibition With\n  Reinforcement Learning", "comments": "accepted at the 19th International Conference on Practical\n  Applications of Agents and Multi-Agent Systems (PAAMS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pricing decisions are increasingly made by AI. Thanks to their ability to\ntrain with live market data while making decisions on the fly, deep\nreinforcement learning algorithms are especially effective in taking such\npricing decisions. In e-commerce scenarios, multiple reinforcement learning\nagents can set prices based on their competitor's prices. Therefore, research\nstates that agents might end up in a state of collusion in the long run. To\nfurther analyze this issue, we build a scenario that is based on a modified\nversion of a prisoner's dilemma where three agents play the game of rock paper\nscissors. Our results indicate that the action selection can be dissected into\nspecific stages, establishing the possibility to develop collusion prevention\nsystems that are able to recognize situations which might lead to a collusion\nbetween competitors. We furthermore provide evidence for a situation where\nagents are capable of performing a tacit cooperation strategy without being\nexplicitly trained to do so.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 08:21:52 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Schlechtinger", "Michael", ""], ["Kosack", "Damaris", ""], ["Paulheim", "Heiko", ""], ["Fetzer", "Thomas", ""]]}, {"id": "2107.01867", "submitter": "Martin Servin", "authors": "Viktor Wiberg, Erik Wallin, Martin Servin, Tomas Nordfjell", "title": "Control of rough terrain vehicles using deep reinforcement learning", "comments": "16 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the potential to control terrain vehicles using deep reinforcement\nin scenarios where human operators and traditional control methods are\ninadequate. This letter presents a controller that perceives, plans, and\nsuccessfully controls a 16-tonne forestry vehicle with two frame articulation\njoints, six wheels, and their actively articulated suspensions to traverse\nrough terrain. The carefully shaped reward signal promotes safe, environmental,\nand efficient driving, which leads to the emergence of unprecedented driving\nskills. We test learned skills in a virtual environment, including terrains\nreconstructed from high-density laser scans of forest sites. The controller\ndisplays the ability to handle obstructing obstacles, slopes up to 27$^\\circ$,\nand a variety of natural terrains, all with limited wheel slip, smooth, and\nupright traversal with intelligent use of the active suspensions. The results\nconfirm that deep reinforcement learning has the potential to enhance control\nof vehicles with complex dynamics and high-dimensional observation data\ncompared to human operators or traditional control methods, especially in rough\nterrain.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 08:43:05 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Wiberg", "Viktor", ""], ["Wallin", "Erik", ""], ["Servin", "Martin", ""], ["Nordfjell", "Tomas", ""]]}, {"id": "2107.01873", "submitter": "Lucas Baier", "authors": "Lucas Baier, Tim Schl\\\"or, Jakob Sch\\\"offer, Niklas K\\\"uhl", "title": "Detecting Concept Drift With Neural Network Model Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deployed machine learning models are confronted with the problem of changing\ndata over time, a phenomenon also called concept drift. While existing\napproaches of concept drift detection already show convincing results, they\nrequire true labels as a prerequisite for successful drift detection.\nEspecially in many real-world application scenarios-like the ones covered in\nthis work-true labels are scarce, and their acquisition is expensive.\nTherefore, we introduce a new algorithm for drift detection, Uncertainty Drift\nDetection (UDD), which is able to detect drifts without access to true labels.\nOur approach is based on the uncertainty estimates provided by a deep neural\nnetwork in combination with Monte Carlo Dropout. Structural changes over time\nare detected by applying the ADWIN technique on the uncertainty estimates, and\ndetected drifts trigger a retraining of the prediction model. In contrast to\ninput data-based drift detection, our approach considers the effects of the\ncurrent input data on the properties of the prediction model rather than\ndetecting change on the input data only (which can lead to unnecessary\nretrainings). We show that UDD outperforms other state-of-the-art strategies on\ntwo synthetic as well as ten real-world data sets for both regression and\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 08:56:36 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Baier", "Lucas", ""], ["Schl\u00f6r", "Tim", ""], ["Sch\u00f6ffer", "Jakob", ""], ["K\u00fchl", "Niklas", ""]]}, {"id": "2107.01875", "submitter": "Lanqing Xue", "authors": "Lanqing Xue, Kaitao Song, Duocai Wu, Xu Tan, Nevin L. Zhang, Tao Qin,\n  Wei-Qiang Zhang, Tie-Yan Liu", "title": "DeepRapper: Neural Rap Generation with Rhyme and Rhythm Modeling", "comments": "Accepted by ACL 2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rap generation, which aims to produce lyrics and corresponding singing beats,\nneeds to model both rhymes and rhythms. Previous works for rap generation\nfocused on rhyming lyrics but ignored rhythmic beats, which are important for\nrap performance. In this paper, we develop DeepRapper, a Transformer-based rap\ngeneration system that can model both rhymes and rhythms. Since there is no\navailable rap dataset with rhythmic beats, we develop a data mining pipeline to\ncollect a large-scale rap dataset, which includes a large number of rap songs\nwith aligned lyrics and rhythmic beats. Second, we design a Transformer-based\nautoregressive language model which carefully models rhymes and rhythms.\nSpecifically, we generate lyrics in the reverse order with rhyme representation\nand constraint for rhyme enhancement and insert a beat symbol into lyrics for\nrhythm/beat modeling. To our knowledge, DeepRapper is the first system to\ngenerate rap with both rhymes and rhythms. Both objective and subjective\nevaluations demonstrate that DeepRapper generates creative and high-quality\nraps with rhymes and rhythms. Code will be released on GitHub.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:01:46 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Xue", "Lanqing", ""], ["Song", "Kaitao", ""], ["Wu", "Duocai", ""], ["Tan", "Xu", ""], ["Zhang", "Nevin L.", ""], ["Qin", "Tao", ""], ["Zhang", "Wei-Qiang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2107.01877", "submitter": "Lia Morra", "authors": "Francesco Manigrasso and Filomeno Davide Miro and Lia Morra and\n  Fabrizio Lamberti", "title": "Faster-LTN: a neuro-symbolic, end-to-end object detection architecture", "comments": "accepted for presentation at ICANN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of semantic relationships between objects represented in an\nimage is one of the fundamental challenges in image interpretation.\nNeural-Symbolic techniques, such as Logic Tensor Networks (LTNs), allow the\ncombination of semantic knowledge representation and reasoning with the ability\nto efficiently learn from examples typical of neural networks. We here propose\nFaster-LTN, an object detector composed of a convolutional backbone and an LTN.\nTo the best of our knowledge, this is the first attempt to combine both\nframeworks in an end-to-end training setting. This architecture is trained by\noptimizing a grounded theory which combines labelled examples with prior\nknowledge, in the form of logical axioms. Experimental comparisons show\ncompetitive performance with respect to the traditional Faster R-CNN\narchitecture.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:09:20 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Manigrasso", "Francesco", ""], ["Miro", "Filomeno Davide", ""], ["Morra", "Lia", ""], ["Lamberti", "Fabrizio", ""]]}, {"id": "2107.01903", "submitter": "Haocong Rao", "authors": "Haocong Rao, Xiping Hu, Jun Cheng, Bin Hu", "title": "SM-SGE: A Self-Supervised Multi-Scale Skeleton Graph Encoding Framework\n  for Person Re-Identification", "comments": "Accepted at ACMMM 2021 Main Track. Sole copyright holder is ACMMM.\n  Codes are available at https://github.com/Kali-Hac/SM-SGE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person re-identification via 3D skeletons is an emerging topic with great\npotential in security-critical applications. Existing methods typically learn\nbody and motion features from the body-joint trajectory, whereas they lack a\nsystematic way to model body structure and underlying relations of body\ncomponents beyond the scale of body joints. In this paper, we for the first\ntime propose a Self-supervised Multi-scale Skeleton Graph Encoding (SM-SGE)\nframework that comprehensively models human body, component relations, and\nskeleton dynamics from unlabeled skeleton graphs of various scales to learn an\neffective skeleton representation for person Re-ID. Specifically, we first\ndevise multi-scale skeleton graphs with coarse-to-fine human body partitions,\nwhich enables us to model body structure and skeleton dynamics at multiple\nlevels. Second, to mine inherent correlations between body components in\nskeletal motion, we propose a multi-scale graph relation network to learn\nstructural relations between adjacent body-component nodes and collaborative\nrelations among nodes of different scales, so as to capture more discriminative\nskeleton graph features. Last, we propose a novel multi-scale skeleton\nreconstruction mechanism to enable our framework to encode skeleton dynamics\nand high-level semantics from unlabeled skeleton graphs, which encourages\nlearning a discriminative skeleton representation for person Re-ID. Extensive\nexperiments show that SM-SGE outperforms most state-of-the-art skeleton-based\nmethods. We further demonstrate its effectiveness on 3D skeleton data estimated\nfrom large-scale RGB videos. Our codes are open at\nhttps://github.com/Kali-Hac/SM-SGE.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:53:08 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Rao", "Haocong", ""], ["Hu", "Xiping", ""], ["Cheng", "Jun", ""], ["Hu", "Bin", ""]]}, {"id": "2107.01904", "submitter": "Muhammad Rizki Maulana", "authors": "Muhammad Rizki Maulana and Wee Sun Lee", "title": "Ensemble and Auxiliary Tasks for Data-Efficient Deep Reinforcement\n  Learning", "comments": "ECML-PKDD 2021. Code: https://github.com/NUS-LID/RENAULT; appendix\n  theorem numbering fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble and auxiliary tasks are both well known to improve the performance\nof machine learning models when data is limited. However, the interaction\nbetween these two methods is not well studied, particularly in the context of\ndeep reinforcement learning. In this paper, we study the effects of ensemble\nand auxiliary tasks when combined with the deep Q-learning algorithm. We\nperform a case study on ATARI games under limited data constraint. Moreover, we\nderive a refined bias-variance-covariance decomposition to analyze the\ndifferent ways of learning ensembles and using auxiliary tasks, and use the\nanalysis to help provide some understanding of the case study. Our code is open\nsource and available at https://github.com/NUS-LID/RENAULT.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:54:07 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 03:50:32 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Maulana", "Muhammad Rizki", ""], ["Lee", "Wee Sun", ""]]}, {"id": "2107.01905", "submitter": "Hans Weytjens", "authors": "Hans Weytjens, Jochen De Weerdt", "title": "Creating Unbiased Public Benchmark Datasets with Data Leakage Prevention\n  for Predictive Process Monitoring", "comments": "Accepted for AI4BPM workshop at BMP2021 conferences", "journal-ref": null, "doi": "10.13140/RG.2.2.16036.19848", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Advances in AI, and especially machine learning, are increasingly drawing\nresearch interest and efforts towards predictive process monitoring, the\nsubfield of process mining (PM) that concerns predicting next events, process\noutcomes and remaining execution times. Unfortunately, researchers use a\nvariety of datasets and ways to split them into training and test sets. The\ndocumentation of these preprocessing steps is not always complete.\nConsequently, research results are hard or even impossible to reproduce and to\ncompare between papers. At times, the use of non-public domain knowledge\nfurther hampers the fair competition of ideas. Often the training and test sets\nare not completely separated, a data leakage problem particular to predictive\nprocess monitoring. Moreover, test sets usually suffer from bias in terms of\nboth the mix of case durations and the number of running cases. These obstacles\npose a challenge to the field's progress. The contribution of this paper is to\nidentify and demonstrate the importance of these obstacles and to propose\npreprocessing steps to arrive at unbiased benchmark datasets in a principled\nway, thus creating representative test sets without data leakage with the aim\nof levelling the playing field, promoting open science and contributing to more\nrapid progress in predictive process monitoring.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:54:34 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Weytjens", "Hans", ""], ["De Weerdt", "Jochen", ""]]}, {"id": "2107.01915", "submitter": "Dominik Sisejkovic", "authors": "Dominik Sisejkovic, Lennart M. Reimann, Elmira Moussavi, Farhad\n  Merchant, Rainer Leupers", "title": "Logic Locking at the Frontiers of Machine Learning: A Survey on\n  Developments and Opportunities", "comments": "6 pages, 3 figures, accepted at VLSI-SOC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the past decade, a lot of progress has been made in the design and\nevaluation of logic locking; a premier technique to safeguard the integrity of\nintegrated circuits throughout the electronics supply chain. However, the\nwidespread proliferation of machine learning has recently introduced a new\npathway to evaluating logic locking schemes. This paper summarizes the recent\ndevelopments in logic locking attacks and countermeasures at the frontiers of\ncontemporary machine learning models. Based on the presented work, the key\ntakeaways, opportunities, and challenges are highlighted to offer\nrecommendations for the design of next-generation logic locking.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 10:18:26 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 09:19:20 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 15:41:04 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Sisejkovic", "Dominik", ""], ["Reimann", "Lennart M.", ""], ["Moussavi", "Elmira", ""], ["Merchant", "Farhad", ""], ["Leupers", "Rainer", ""]]}, {"id": "2107.01927", "submitter": "Ahmed Hashem El Fiky", "authors": "Ahmed Hashem El Fiky, Ayman El Shenawy, Mohamed Ashraf Madkour", "title": "Android Malware Category and Family Detection and Identification using\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Android malware is one of the most dangerous threats on the internet, and\nit's been on the rise for several years. Despite significant efforts in\ndetecting and classifying android malware from innocuous android applications,\nthere is still a long way to go. As a result, there is a need to provide a\nbasic understanding of the behavior displayed by the most common Android\nmalware categories and families. Each Android malware family and category has a\ndistinct objective. As a result, it has impacted every corporate area,\nincluding healthcare, banking, transportation, government, and e-commerce. In\nthis paper, we presented two machine-learning approaches for Dynamic Analysis\nof Android Malware: one for detecting and identifying Android Malware\nCategories and the other for detecting and identifying Android Malware\nFamilies, which was accomplished by analyzing a massive malware dataset with 14\nprominent malware categories and 180 prominent malware families of\nCCCS-CIC-AndMal2020 dataset on Dynamic Layers. Our approach achieves in Android\nMalware Category detection more than 96 % accurate and achieves in Android\nMalware Family detection more than 99% accurate. Our approach provides a method\nfor high-accuracy Dynamic Analysis of Android Malware while also shortening the\ntime required to analyze smartphone malware.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 10:48:40 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Fiky", "Ahmed Hashem El", ""], ["Shenawy", "Ayman El", ""], ["Madkour", "Mohamed Ashraf", ""]]}, {"id": "2107.01969", "submitter": "Rohin Shah", "authors": "Rohin Shah, Cody Wild, Steven H. Wang, Neel Alex, Brandon Houghton,\n  William Guss, Sharada Mohanty, Anssi Kanervisto, Stephanie Milani, Nicholay\n  Topin, Pieter Abbeel, Stuart Russell, Anca Dragan", "title": "The MineRL BASALT Competition on Learning from Human Feedback", "comments": "NeurIPS 2021 Competition Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has seen a significant increase of interest in deep learning\nresearch, with many public successes that have demonstrated its potential. As\nsuch, these systems are now being incorporated into commercial products. With\nthis comes an additional challenge: how can we build AI systems that solve\ntasks where there is not a crisp, well-defined specification? While multiple\nsolutions have been proposed, in this competition we focus on one in\nparticular: learning from human feedback. Rather than training AI systems using\na predefined reward function or using a labeled dataset with a predefined set\nof categories, we instead train the AI system using a learning signal derived\nfrom some form of human feedback, which can evolve over time as the\nunderstanding of the task changes, or as the capabilities of the AI system\nimprove.\n  The MineRL BASALT competition aims to spur forward research on this important\nclass of techniques. We design a suite of four tasks in Minecraft for which we\nexpect it will be hard to write down hardcoded reward functions. These tasks\nare defined by a paragraph of natural language: for example, \"create a\nwaterfall and take a scenic picture of it\", with additional clarifying details.\nParticipants must train a separate agent for each task, using any method they\nwant. Agents are then evaluated by humans who have read the task description.\nTo help participants get started, we provide a dataset of human demonstrations\non each of the four tasks, as well as an imitation learning baseline that\nleverages these demonstrations.\n  Our hope is that this competition will improve our ability to build AI\nsystems that do what their designers intend them to do, even when the intent\ncannot be easily formalized. Besides allowing AI to solve more tasks, this can\nalso enable more effective regulation of AI systems, as well as making progress\non the value alignment problem.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 12:18:17 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Shah", "Rohin", ""], ["Wild", "Cody", ""], ["Wang", "Steven H.", ""], ["Alex", "Neel", ""], ["Houghton", "Brandon", ""], ["Guss", "William", ""], ["Mohanty", "Sharada", ""], ["Kanervisto", "Anssi", ""], ["Milani", "Stephanie", ""], ["Topin", "Nicholay", ""], ["Abbeel", "Pieter", ""], ["Russell", "Stuart", ""], ["Dragan", "Anca", ""]]}, {"id": "2107.01983", "submitter": "Qitong Gao", "authors": "Qitong Gao, Dong Wang, Joshua D. Amason, Siyang Yuan, Chenyang Tao,\n  Ricardo Henao, Majda Hadziahmetovic, Lawrence Carin, Miroslav Pajic", "title": "Imputation-Free Learning from Incomplete Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although recent works have developed methods that can generate estimations\n(or imputations) of the missing entries in a dataset to facilitate downstream\nanalysis, most depend on assumptions that may not align with real-world\napplications and could suffer from poor performance in subsequent tasks. This\nis particularly true if the data have large missingness rates or a small\npopulation. More importantly, the imputation error could be propagated into the\nprediction step that follows, causing the gradients used to train the\nprediction models to be biased. Consequently, in this work, we introduce the\nimportance guided stochastic gradient descent (IGSGD) method to train\nmultilayer perceptrons (MLPs) and long short-term memories (LSTMs) to directly\nperform inference from inputs containing missing values without imputation.\nSpecifically, we employ reinforcement learning (RL) to adjust the gradients\nused to train the models via back-propagation. This not only reduces bias but\nallows the model to exploit the underlying information behind missingness\npatterns. We test the proposed approach on real-world time-series (i.e.,\nMIMIC-III), tabular data obtained from an eye clinic, and a standard dataset\n(i.e., MNIST), where our imputation-free predictions outperform the traditional\ntwo-step imputation-based predictions using state-of-the-art imputation\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 12:44:39 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Gao", "Qitong", ""], ["Wang", "Dong", ""], ["Amason", "Joshua D.", ""], ["Yuan", "Siyang", ""], ["Tao", "Chenyang", ""], ["Henao", "Ricardo", ""], ["Hadziahmetovic", "Majda", ""], ["Carin", "Lawrence", ""], ["Pajic", "Miroslav", ""]]}, {"id": "2107.01988", "submitter": "Pietro Gori", "authors": "Robin Louiset and Pietro Gori and Benoit Dufumier and Josselin Houenou\n  and Antoine Grigis and Edouard Duchesnay", "title": "UCSL : A Machine Learning Expectation-Maximization framework for\n  Unsupervised Clustering driven by Supervised Learning", "comments": "ECML/PKDD 2021", "journal-ref": "ECML/PKDD 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subtype Discovery consists in finding interpretable and consistent sub-parts\nof a dataset, which are also relevant to a certain supervised task. From a\nmathematical point of view, this can be defined as a clustering task driven by\nsupervised learning in order to uncover subgroups in line with the supervised\nprediction. In this paper, we propose a general Expectation-Maximization\nensemble framework entitled UCSL (Unsupervised Clustering driven by Supervised\nLearning). Our method is generic, it can integrate any clustering method and\ncan be driven by both binary classification and regression. We propose to\nconstruct a non-linear model by merging multiple linear estimators, one per\ncluster. Each hyperplane is estimated so that it correctly discriminates - or\npredict - only one cluster. We use SVC or Logistic Regression for\nclassification and SVR for regression. Furthermore, to perform cluster analysis\nwithin a more suitable space, we also propose a dimension-reduction algorithm\nthat projects the data onto an orthonormal space relevant to the supervised\ntask. We analyze the robustness and generalization capability of our algorithm\nusing synthetic and experimental datasets. In particular, we validate its\nability to identify suitable consistent sub-types by conducting a\npsychiatric-diseases cluster analysis with known ground-truth labels. The gain\nof the proposed method over previous state-of-the-art techniques is about +1.9\npoints in terms of balanced accuracy. Finally, we make codes and examples\navailable in a scikit-learn-compatible Python package at\nhttps://github.com/neurospin-projects/2021_rlouiset_ucsl\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 12:55:13 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Louiset", "Robin", ""], ["Gori", "Pietro", ""], ["Dufumier", "Benoit", ""], ["Houenou", "Josselin", ""], ["Grigis", "Antoine", ""], ["Duchesnay", "Edouard", ""]]}, {"id": "2107.01996", "submitter": "Chao Wang Senior Scientist", "authors": "Chao Wang, Pengcheng An", "title": "Explainability via Interactivity? Supporting Nonexperts' Sensemaking of\n  Pretrained CNN by Interacting with Their Daily Surroundings", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current research on Explainable AI (XAI) heavily targets on expert users\n(data scientists or AI developers). However, increasing importance has been\nargued for making AI more understandable to nonexperts, who are expected to\nleverage AI techniques, but have limited knowledge about AI. We present a\nmobile application to support nonexperts to interactively make sense of\nConvolutional Neural Networks (CNN); it allows users to play with a pretrained\nCNN by taking pictures of their surrounding objects. We use an up-to-date XAI\ntechnique (Class Activation Map) to intuitively visualize the model's decision\n(the most important image regions that lead to a certain result). Deployed in a\nuniversity course, this playful learning tool was found to support design\nstudents to gain vivid understandings about the capabilities and limitations of\npretrained CNNs in real-world environments. Concrete examples of students'\nplayful explorations are reported to characterize their sensemaking processes\nreflecting different depths of thought.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 19:22:53 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Wang", "Chao", ""], ["An", "Pengcheng", ""]]}, {"id": "2107.02010", "submitter": "Pietro Gori", "authors": "Jean Feydy and Pierre Roussillon and Alain Trouv\\'e and Pietro Gori", "title": "Fast and Scalable Optimal Transport for Brain Tractograms", "comments": "MICCAI 2019", "journal-ref": "MICCAI 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new multiscale algorithm for solving regularized Optimal\nTransport problems on the GPU, with a linear memory footprint. Relying on\nSinkhorn divergences which are convex, smooth and positive definite loss\nfunctions, this method enables the computation of transport plans between\nmillions of points in a matter of minutes. We show the effectiveness of this\napproach on brain tractograms modeled either as bundles of fibers or as track\ndensity maps. We use the resulting smooth assignments to perform label transfer\nfor atlas-based segmentation of fiber tractograms. The parameters -- blur and\nreach -- of our method are meaningful, defining the minimum and maximum\ndistance at which two fibers are compared with each other. They can be set\naccording to anatomical knowledge. Furthermore, we also propose to estimate a\nprobabilistic atlas of a population of track density maps as a Wasserstein\nbarycenter. Our CUDA implementation is endowed with a user-friendly PyTorch\ninterface, freely available on the PyPi repository (pip install geomloss) and\nat www.kernel-operations.io/geomloss.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 13:28:41 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Feydy", "Jean", ""], ["Roussillon", "Pierre", ""], ["Trouv\u00e9", "Alain", ""], ["Gori", "Pietro", ""]]}, {"id": "2107.02024", "submitter": "Hadi Mansourifar", "authors": "Hadi Mansourifar, Dana Alsagheer, Weidong Shi, Lan Ni, Yan Huang", "title": "Statistical Analysis of Perspective Scores on Hate Speech Detection", "comments": "Accepted paper in International IJCAI Workshop on Artificial\n  Intelligence for Social Good 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hate speech detection has become a hot topic in recent years due to the\nexponential growth of offensive language in social media. It has proven that,\nstate-of-the-art hate speech classifiers are efficient only when tested on the\ndata with the same feature distribution as training data. As a consequence,\nmodel architecture plays the second role to improve the current results. In\nsuch a diverse data distribution relying on low level features is the main\ncause of deficiency due to natural bias in data. That's why we need to use high\nlevel features to avoid a biased judgement. In this paper, we statistically\nanalyze the Perspective Scores and their impact on hate speech detection. We\nshow that, different hate speech datasets are very similar when it comes to\nextract their Perspective Scores. Eventually, we prove that, over-sampling the\nPerspective Scores of a hate speech dataset can significantly improve the\ngeneralization performance when it comes to be tested on other hate speech\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 17:17:35 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Mansourifar", "Hadi", ""], ["Alsagheer", "Dana", ""], ["Shi", "Weidong", ""], ["Ni", "Lan", ""], ["Huang", "Yan", ""]]}, {"id": "2107.02033", "submitter": "Felix Biessmann", "authors": "Felix Biessmann and Dionysius Refiano", "title": "Quality Metrics for Transparent Machine Learning With and Without Humans\n  In the Loop Are Not Correlated", "comments": "Proceedings of the ICML Workshop on Theoretical Foundations,\n  Criticism, and Application Trends of Explainable AI held in conjunction with\n  the 38th International Conference on Machine Learning (ICML), a\n  non-peer-reviewed longer version was previously published as preprint here\n  arXiv:1912.05011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The field explainable artificial intelligence (XAI) has brought about an\narsenal of methods to render Machine Learning (ML) predictions more\ninterpretable. But how useful explanations provided by transparent ML methods\nare for humans remains difficult to assess. Here we investigate the quality of\ninterpretable computer vision algorithms using techniques from psychophysics.\nIn crowdsourced annotation tasks we study the impact of different\ninterpretability approaches on annotation accuracy and task time. We compare\nthese quality metrics with classical XAI, automated quality metrics. Our\nresults demonstrate that psychophysical experiments allow for robust quality\nassessment of transparency in machine learning. Interestingly the quality\nmetrics computed without humans in the loop did not provide a consistent\nranking of interpretability methods nor were they representative for how useful\nan explanation was for humans. These findings highlight the potential of\nmethods from classical psychophysics for modern machine learning applications.\nWe hope that our results provide convincing arguments for evaluating\ninterpretability in its natural habitat, human-ML interaction, if the goal is\nto obtain an authentic assessment of interpretability.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 12:30:51 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Biessmann", "Felix", ""], ["Refiano", "Dionysius", ""]]}, {"id": "2107.02039", "submitter": "Burc Gokden", "authors": "Burc Gokden", "title": "Power Law Graph Transformer for Machine Translation and Representation\n  Learning", "comments": "55 pages, 39 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the Power Law Graph Transformer, a transformer model with well\ndefined deductive and inductive tasks for prediction and representation\nlearning. The deductive task learns the dataset level (global) and instance\nlevel (local) graph structures in terms of learnable power law distribution\nparameters. The inductive task outputs the prediction probabilities using the\ndeductive task output, similar to a transductive model. We trained our model\nwith Turkish-English and Portuguese-English datasets from TED talk transcripts\nfor machine translation and compared the model performance and characteristics\nto a transformer model with scaled dot product attention trained on the same\nexperimental setup. We report BLEU scores of $17.79$ and $28.33$ on the\nTurkish-English and Portuguese-English translation tasks with our model,\nrespectively. We also show how a duality between a quantization set and\nN-dimensional manifold representation can be leveraged to transform between\nlocal and global deductive-inductive outputs using successive application of\nlinear and non-linear transformations end-to-end.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 15:59:37 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Gokden", "Burc", ""]]}, {"id": "2107.02040", "submitter": "Romina Etezadi", "authors": "Romina Etezadi, Mehrnoush Shamsfard", "title": "A Knowledge-based Approach for Answering Complex Questions in Persian", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research on open-domain question answering (QA) has a long tradition. A\nchallenge in this domain is answering complex questions (CQA) that require\ncomplex inference methods and large amounts of knowledge. In low resource\nlanguages, such as Persian, there are not many datasets for open-domain complex\nquestions and also the language processing toolkits are not very accurate. In\nthis paper, we propose a knowledge-based approach for answering Persian complex\nquestions using Farsbase; the Persian knowledge graph, exploiting PeCoQ; the\nnewly created complex Persian question dataset. In this work, we handle\nmulti-constraint and multi-hop questions by building their set of possible\ncorresponding logical forms. Then Multilingual-BERT is used to select the\nlogical form that best describes the input complex question syntactically and\nsemantically. The answer to the question is built from the answer to the\nlogical form, extracted from the knowledge graph. Experiments show that our\napproach outperforms other approaches in Persian CQA.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 14:01:43 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Etezadi", "Romina", ""], ["Shamsfard", "Mehrnoush", ""]]}, {"id": "2107.02052", "submitter": "Mathias L\\\"owe", "authors": "Mathias L\\\"owe, Jennifer Villareale, Evan Freed, Aleksanteri Sladek,\n  Jichen Zhu, Sebastian Risi", "title": "Dealing with Adversarial Player Strategies in the Neural Network Game\n  iNNk through Ensemble Learning", "comments": "10 pages, 4 Figures. Accepted for publishing at the 16th\n  International Conference on the Foundations of Digital Games (FDG) 2021", "journal-ref": null, "doi": "10.1145/3472538.3472540", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying neural network (NN) methods in games can lead to various new and\nexciting game dynamics not previously possible. However, they also lead to new\nchallenges such as the lack of large, clean datasets, varying player skill\nlevels, and changing gameplay strategies. In this paper, we focus on the\nadversarial player strategy aspect in the game iNNk, in which players try to\ncommunicate secret code words through drawings with the goal of not being\ndeciphered by a NN. Some strategies exploit weaknesses in the NN that\nconsistently trick it into making incorrect classifications, leading to\nunbalanced gameplay. We present a method that combines transfer learning and\nensemble methods to obtain a data-efficient adaptation to these strategies.\nThis combination significantly outperforms the baseline NN across all\nadversarial player strategies despite only being trained on a limited set of\nadversarial examples. We expect the methods developed in this paper to be\nuseful for the rapidly growing field of NN-based games, which will require new\napproaches to deal with unforeseen player creativity.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 14:25:44 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["L\u00f6we", "Mathias", ""], ["Villareale", "Jennifer", ""], ["Freed", "Evan", ""], ["Sladek", "Aleksanteri", ""], ["Zhu", "Jichen", ""], ["Risi", "Sebastian", ""]]}, {"id": "2107.02053", "submitter": "Kaiyang Zhou", "authors": "Kaiyang Zhou, Yongxin Yang, Yu Qiao, Tao Xiang", "title": "MixStyle Neural Networks for Domain Generalization and Adaptation", "comments": "Extension of https://openreview.net/forum?id=6xHJ37MVxxp. Code\n  available at https://github.com/KaiyangZhou/mixstyle-release", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) often have poor generalization\nperformance under domain shift. One way to improve domain generalization is to\ncollect diverse source data from multiple relevant domains so that a CNN model\nis allowed to learn more domain-invariant, and hence generalizable\nrepresentations. In this work, we address domain generalization with MixStyle,\na plug-and-play, parameter-free module that is simply inserted to shallow CNN\nlayers and requires no modification to training objectives. Specifically,\nMixStyle probabilistically mixes feature statistics between instances. This\nidea is inspired by the observation that visual domains can often be\ncharacterized by image styles which are in turn encapsulated within\ninstance-level feature statistics in shallow CNN layers. Therefore, inserting\nMixStyle modules in effect synthesizes novel domains albeit in an implicit way.\nMixStyle is not only simple and flexible, but also versatile -- it can be used\nfor problems whereby unlabeled images are available, such as semi-supervised\ndomain generalization and unsupervised domain adaptation, with a simple\nextension to mix feature statistics between labeled and pseudo-labeled\ninstances. We demonstrate through extensive experiments that MixStyle can\nsignificantly boost the out-of-distribution generalization performance across a\nwide range of tasks including object recognition, instance retrieval, and\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 14:29:19 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhou", "Kaiyang", ""], ["Yang", "Yongxin", ""], ["Qiao", "Yu", ""], ["Xiang", "Tao", ""]]}, {"id": "2107.02083", "submitter": "Fatema Tuj Johora MSc", "authors": "Fatema T. Johora and J\\\"org P. M\\\"uller", "title": "Modeling Interactions of Multimodal Road Users in Shared Spaces", "comments": null, "journal-ref": "IEEE, 2018, https://ieeexplore.ieee.org/document/8569687", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In shared spaces, motorized and non-motorized road users share the same space\nwith equal priority. Their movements are not regulated by traffic rules, hence\nthey interact more frequently to negotiate priority over the shared space. To\nestimate the safeness and efficiency of shared spaces, reproducing the traffic\nbehavior in such traffic places is important. In this paper, we consider and\ncombine different levels of interaction between pedestrians and cars in shared\nspace environments. Our proposed model consists of three layers: a layer to\nplan trajectories of road users; a force-based modeling layer to reproduce free\nflow movement and simple interactions; and a game-theoretic decision layer to\nhandle complex situations where road users need to make a decision over\ndifferent alternatives. We validate our model by simulating scenarios involving\nvarious interactions between pedestrians and cars and also car-to-car\ninteraction. The results indicate that simulated behaviors match observed\nbehaviors well.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 15:25:08 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Johora", "Fatema T.", ""], ["M\u00fcller", "J\u00f6rg P.", ""]]}, {"id": "2107.02086", "submitter": "Nathan Hubens", "authors": "Nathan Hubens and Matei Mancas and Bernard Gosselin and Marius Preda\n  and Titus Zaharia", "title": "One-Cycle Pruning: Pruning ConvNets Under a Tight Training Budget", "comments": "Accepted at Sparsity in Neural Networks (SNN 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Introducing sparsity in a neural network has been an efficient way to reduce\nits complexity while keeping its performance almost intact. Most of the time,\nsparsity is introduced using a three-stage pipeline: 1) train the model to\nconvergence, 2) prune the model according to some criterion, 3) fine-tune the\npruned model to recover performance. The last two steps are often performed\niteratively, leading to reasonable results but also to a time-consuming and\ncomplex process. In our work, we propose to get rid of the first step of the\npipeline and to combine the two other steps in a single pruning-training cycle,\nallowing the model to jointly learn for the optimal weights while being pruned.\nWe do this by introducing a novel pruning schedule, named One-Cycle Pruning,\nwhich starts pruning from the beginning of the training, and until its very\nend. Adopting such a schedule not only leads to better performing pruned models\nbut also drastically reduces the training budget required to prune a model.\nExperiments are conducted on a variety of architectures (VGG-16 and ResNet-18)\nand datasets (CIFAR-10, CIFAR-100 and Caltech-101), and for relatively high\nsparsity values (80%, 90%, 95% of weights removed). Our results show that\nOne-Cycle Pruning consistently outperforms commonly used pruning schedules such\nas One-Shot Pruning, Iterative Pruning and Automated Gradual Pruning, on a\nfixed training budget.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 15:27:07 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Hubens", "Nathan", ""], ["Mancas", "Matei", ""], ["Gosselin", "Bernard", ""], ["Preda", "Marius", ""], ["Zaharia", "Titus", ""]]}, {"id": "2107.02102", "submitter": "Yuxiang Wu", "authors": "Yuxiang Wu, Pasquale Minervini, Pontus Stenetorp, Sebastian Riedel", "title": "Training Adaptive Computation for Open-Domain Question Answering with\n  Computational Constraints", "comments": "7 pages, 1 figure, to be published in ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Adaptive Computation (AC) has been shown to be effective in improving the\nefficiency of Open-Domain Question Answering (ODQA) systems. However, current\nAC approaches require tuning of all model parameters, and training\nstate-of-the-art ODQA models requires significant computational resources that\nmay not be available for most researchers. We propose Adaptive Passage Encoder,\nan AC method that can be applied to an existing ODQA model and can be trained\nefficiently on a single GPU. It keeps the parameters of the base ODQA model\nfixed, but it overrides the default layer-by-layer computation of the encoder\nwith an AC policy that is trained to optimise the computational efficiency of\nthe model. Our experimental results show that our method improves upon a\nstate-of-the-art model on two datasets, and is also more accurate than previous\nAC methods due to the stronger base ODQA model. All source code and datasets\nare available at https://github.com/uclnlp/APE.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 15:48:14 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Wu", "Yuxiang", ""], ["Minervini", "Pasquale", ""], ["Stenetorp", "Pontus", ""], ["Riedel", "Sebastian", ""]]}, {"id": "2107.02139", "submitter": "Lin Chen", "authors": "Lin Chen, Hossein Esfandiari, Gang Fu, Vahab S. Mirrokni, Qian Yu", "title": "Feature Cross Search via Submodular Optimization", "comments": "Accepted to ESA 2021. Authors are ordered alphabetically", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study feature cross search as a fundamental primitive in\nfeature engineering. The importance of feature cross search especially for the\nlinear model has been known for a while, with well-known textbook examples. In\nthis problem, the goal is to select a small subset of features, combine them to\nform a new feature (called the crossed feature) by considering their Cartesian\nproduct, and find feature crosses to learn an \\emph{accurate} model. In\nparticular, we study the problem of maximizing a normalized Area Under the\nCurve (AUC) of the linear model trained on the crossed feature column.\n  First, we show that it is not possible to provide an $n^{1/\\log\\log\nn}$-approximation algorithm for this problem unless the exponential time\nhypothesis fails. This result also rules out the possibility of solving this\nproblem in polynomial time unless $\\mathsf{P}=\\mathsf{NP}$. On the positive\nside, by assuming the \\naive\\ assumption, we show that there exists a simple\ngreedy $(1-1/e)$-approximation algorithm for this problem. This result is\nestablished by relating the AUC to the total variation of the commutator of two\nprobability measures and showing that the total variation of the commutator is\nmonotone and submodular. To show this, we relate the submodularity of this\nfunction to the positive semi-definiteness of a corresponding kernel matrix.\nThen, we use Bochner's theorem to prove the positive semi-definiteness by\nshowing that its inverse Fourier transform is non-negative everywhere. Our\ntechniques and structural results might be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 16:58:31 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Chen", "Lin", ""], ["Esfandiari", "Hossein", ""], ["Fu", "Gang", ""], ["Mirrokni", "Vahab S.", ""], ["Yu", "Qian", ""]]}, {"id": "2107.02153", "submitter": "Sewon Min", "authors": "Jungsoo Park, Sewon Min, Jaewoo Kang, Luke Zettlemoyer, Hannaneh\n  Hajishirzi", "title": "FaVIQ: FAct Verification from Information-seeking Questions", "comments": "12 pages, 3 figures; Data & Code available at https://faviq.github.io", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite significant interest in developing general purpose fact checking\nmodels, it is challenging to construct a large-scale fact verification dataset\nwith realistic claims that would occur in the real world. Existing claims are\neither authored by crowdworkers, thereby introducing subtle biases that are\ndifficult to control for, or manually verified by professional fact checkers,\ncausing them to be expensive and limited in scale. In this paper, we construct\na challenging, realistic, and large-scale fact verification dataset called\nFaVIQ, using information-seeking questions posed by real users who do not know\nhow to answer. The ambiguity in information-seeking questions enables\nautomatically constructing true and false claims that reflect confusions arisen\nfrom users (e.g., the year of the movie being filmed vs. being released). Our\nclaims are verified to be natural, contain little lexical bias, and require a\ncomplete understanding of the evidence for verification. Our experiments show\nthat the state-of-the-art models are far from solving our new task. Moreover,\ntraining on our data helps in professional fact-checking, outperforming models\ntrained on the most widely used dataset FEVER or in-domain data by up to 17%\nabsolute. Altogether, our data will serve as a challenging benchmark for\nnatural language understanding and support future progress in professional fact\nchecking.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 17:31:44 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Park", "Jungsoo", ""], ["Min", "Sewon", ""], ["Kang", "Jaewoo", ""], ["Zettlemoyer", "Luke", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "2107.02156", "submitter": "Zhongdao Wang", "authors": "Zhongdao Wang, Hengshuang Zhao, Ya-Li Li, Shengjin Wang, Philip H.S.\n  Torr, Luca Bertinetto", "title": "Do Different Tracking Tasks Require Different Appearance Models?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Tracking objects of interest in a video is one of the most popular and widely\napplicable problems in computer vision. However, with the years, a Cambrian\nexplosion of use cases and benchmarks has fragmented the problem in a multitude\nof different experimental setups. As a consequence, the literature has\nfragmented too, and now the novel approaches proposed by the community are\nusually specialised to fit only one specific setup. To understand to what\nextent this specialisation is actually necessary, in this work we present\nUniTrack, a unified tracking solution to address five different tasks within\nthe same framework. UniTrack consists of a single and task-agnostic appearance\nmodel, which can be learned in a supervised or self-supervised fashion, and\nmultiple \"heads\" to address individual tasks and that do not require training.\nWe show how most tracking tasks can be solved within this framework, and that\nthe same appearance model can be used to obtain performance that is competitive\nagainst specialised methods for all the five tasks considered. The framework\nalso allows us to analyse appearance models obtained with the most recent\nself-supervised methods, thus significantly extending their evaluation and\ncomparison to a larger variety of important problems. Code available at\nhttps://github.com/Zhongdao/UniTrack.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 17:40:17 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Wang", "Zhongdao", ""], ["Zhao", "Hengshuang", ""], ["Li", "Ya-Li", ""], ["Wang", "Shengjin", ""], ["Torr", "Philip H. S.", ""], ["Bertinetto", "Luca", ""]]}, {"id": "2107.02170", "submitter": "Wei-Lun Chao", "authors": "Tai-Yu Pan, Cheng Zhang, Yandong Li, Hexiang Hu, Dong Xuan, Soravit\n  Changpinyo, Boqing Gong, Wei-Lun Chao", "title": "On Model Calibration for Long-Tailed Object Detection and Instance\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Vanilla models for object detection and instance segmentation suffer from the\nheavy bias toward detecting frequent objects in the long-tailed setting.\nExisting methods address this issue mostly during training, e.g., by\nre-sampling or re-weighting. In this paper, we investigate a largely overlooked\napproach -- post-processing calibration of confidence scores. We propose\nNorCal, Normalized Calibration for long-tailed object detection and instance\nsegmentation, a simple and straightforward recipe that reweighs the predicted\nscores of each class by its training sample size. We show that separately\nhandling the background class and normalizing the scores over classes for each\nproposal are keys to achieving superior performance. On the LVIS dataset,\nNorCal can effectively improve nearly all the baseline models not only on rare\nclasses but also on common and frequent classes. Finally, we conduct extensive\nanalysis and ablation studies to offer insights into various modeling choices\nand mechanisms of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 17:57:20 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Pan", "Tai-Yu", ""], ["Zhang", "Cheng", ""], ["Li", "Yandong", ""], ["Hu", "Hexiang", ""], ["Xuan", "Dong", ""], ["Changpinyo", "Soravit", ""], ["Gong", "Boqing", ""], ["Chao", "Wei-Lun", ""]]}, {"id": "2107.02174", "submitter": "Yuxin Fang", "authors": "Yuxin Fang, Xinggang Wang, Rui Wu, Jianwei Niu, Wenyu Liu", "title": "What Makes for Hierarchical Vision Transformer?", "comments": "Preprint. Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies show that hierarchical Vision Transformer with interleaved\nnon-overlapped intra window self-attention \\& shifted window self-attention is\nable to achieve state-of-the-art performance in various visual recognition\ntasks and challenges CNN's dense sliding window paradigm. Most follow-up works\ntry to replace shifted window operation with other kinds of cross window\ncommunication while treating self-attention as the de-facto standard for intra\nwindow information aggregation. In this short preprint, we question whether\nself-attention is the only choice for hierarchical Vision Transformer to attain\nstrong performance, and what makes for hierarchical Vision Transformer? We\nreplace self-attention layers in Swin Transformer and Shuffle Transformer with\nsimple linear mapping and keep other components unchanged. The resulting\narchitecture with 25.4M parameters and 4.2G FLOPs achieves 80.5\\% Top-1\naccuracy, compared to 81.3\\% for Swin Transformer with 28.3M parameters and\n4.5G FLOPs. We also experiment with other alternatives to self-attention for\ncontext aggregation inside each non-overlapped window, which all give similar\ncompetitive results under the same architecture. Our study reveals that the\n\\textbf{macro architecture} of Swin model families (i.e., interleaved intra\nwindow \\& cross window communications), other than specific aggregation layers\nor specific means of cross window communication, may be more responsible for\nits strong performance and is the real challenger to CNN's dense sliding window\nparadigm.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 17:59:35 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Fang", "Yuxin", ""], ["Wang", "Xinggang", ""], ["Wu", "Rui", ""], ["Niu", "Jianwei", ""], ["Liu", "Wenyu", ""]]}, {"id": "2107.02175", "submitter": "Junaid Baber", "authors": "Mohammad Aimal, Maheen Bakhtyar, Junaid Baber, Sadia Lakho, Umar\n  Mohammad, Warda Ahmed, Jahanvash Karim", "title": "Identifying negativity factors from social media text corpus using\n  sentiment analysis method", "comments": "Paper is accepted in the SOFA 2020 conference", "journal-ref": "SOFA 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic sentiment analysis play vital role in decision making. Many\norganizations spend a lot of budget to understand their customer satisfaction\nby manually going over their feedback/comments or tweets. Automatic sentiment\nanalysis can give overall picture of the comments received against any event,\nproduct, or activity. Usually, the comments/tweets are classified into two main\nclasses that are negative or positive. However, the negative comments are too\nabstract to understand the basic reason or the context. organizations are\ninterested to identify the exact reason for the negativity. In this research\nstudy, we hierarchically goes down into negative comments, and link them with\nmore classes. Tweets are extracted from social media sites such as Twitter and\nFacebook. If the sentiment analysis classifies any tweet into negative class,\nthen we further try to associates that negative comments with more possible\nnegative classes. Based on expert opinions, the negative comments/tweets are\nfurther classified into 8 classes. Different machine learning algorithms are\nevaluated and their accuracy are reported.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 10:15:31 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Aimal", "Mohammad", ""], ["Bakhtyar", "Maheen", ""], ["Baber", "Junaid", ""], ["Lakho", "Sadia", ""], ["Mohammad", "Umar", ""], ["Ahmed", "Warda", ""], ["Karim", "Jahanvash", ""]]}, {"id": "2107.02195", "submitter": "Anssi Kanervisto", "authors": "Shashank Hegde, Anssi Kanervisto, Aleksei Petrenko", "title": "Agents that Listen: High-Throughput Reinforcement Learning with Multiple\n  Sensory Systems", "comments": "To appear in IEEE Conference on Games 2021. Video demonstrations and\n  experiment can be found at https://sites.google.com/view/sound-rl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans and other intelligent animals evolved highly sophisticated perception\nsystems that combine multiple sensory modalities. On the other hand,\nstate-of-the-art artificial agents rely mostly on visual inputs or structured\nlow-dimensional observations provided by instrumented environments. Learning to\nact based on combined visual and auditory inputs is still a new topic of\nresearch that has not been explored beyond simple scenarios. To facilitate\nprogress in this area we introduce a new version of VizDoom simulator to create\na highly efficient learning environment that provides raw audio observations.\nWe study the performance of different model architectures in a series of tasks\nthat require the agent to recognize sounds and execute instructions given in\nnatural language. Finally, we train our agent to play the full game of Doom and\nfind that it can consistently defeat a traditional vision-based adversary. We\nare currently in the process of merging the augmented simulator with the main\nViZDoom code repository. Video demonstrations and experiment code can be found\nat https://sites.google.com/view/sound-rl.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 18:00:50 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Hegde", "Shashank", ""], ["Kanervisto", "Anssi", ""], ["Petrenko", "Aleksei", ""]]}, {"id": "2107.02202", "submitter": "Raz Saremi", "authors": "Razieh Saremi, Hardik Yagnik, Julian Togelius, Ye Yang, and Guenther\n  Ruhe", "title": "An Evolutionary Algorithm for Task Scheduling in Crowdsourced Software\n  Development", "comments": "16 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of software tasks and the uncertainty of crowd developer\nbehaviors make it challenging to plan crowdsourced software development (CSD)\nprojects. In a competitive crowdsourcing marketplace, competition for shared\nworker resources from multiple simultaneously open tasks adds another layer of\nuncertainty to the potential outcomes of software crowdsourcing. These factors\nlead to the need for supporting CSD managers with automated scheduling to\nimprove the visibility and predictability of crowdsourcing processes and\noutcomes. To that end, this paper proposes an evolutionary algorithm-based task\nscheduling method for crowdsourced software development. The proposed\nevolutionary scheduling method uses a multiobjective genetic algorithm to\nrecommend an optimal task start date. The method uses three fitness functions,\nbased on project duration, task similarity, and task failure prediction,\nrespectively. The task failure fitness function uses a neural network to\npredict the probability of task failure with respect to a specific task start\ndate. The proposed method then recommends the best tasks start dates for the\nproject as a whole and each individual task so as to achieve the lowest project\nfailure ratio. Experimental results on 4 projects demonstrate that the proposed\nmethod has the potential to reduce project duration by a factor of 33-78%.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 18:07:26 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Saremi", "Razieh", ""], ["Yagnik", "Hardik", ""], ["Togelius", "Julian", ""], ["Yang", "Ye", ""], ["Ruhe", "Guenther", ""]]}, {"id": "2107.02228", "submitter": "Kyeong-Ryeol Go", "authors": "Kyeongryeol Go, Seyoung Yun", "title": "Meta-learning Amidst Heterogeneity and Ambiguity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning aims to learn a model that can handle multiple tasks generated\nfrom an unknown but shared distribution. However, typical meta-learning\nalgorithms have assumed the tasks to be similar such that a single meta-learner\nis sufficient to aggregate the variations in all aspects. In addition, there\nhas been less consideration on uncertainty when limited information is given as\ncontext. In this paper, we devise a novel meta-learning framework, called\nMeta-learning Amidst Heterogeneity and Ambiguity (MAHA), that outperforms\nprevious works in terms of prediction based on its ability on task\nidentification. By extensively conducting several experiments in regression and\nclassification, we demonstrate the validity of our model, which turns out to be\nrobust to both task heterogeneity and ambiguity.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 18:54:31 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Go", "Kyeongryeol", ""], ["Yun", "Seyoung", ""]]}, {"id": "2107.02233", "submitter": "Salva R\\\"uhling Cachay", "authors": "Salva R\\\"uhling Cachay, Benedikt Boecking, Artur Dubrawski", "title": "End-to-End Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Aggregating multiple sources of weak supervision (WS) can ease the\ndata-labeling bottleneck prevalent in many machine learning applications, by\nreplacing the tedious manual collection of ground truth labels. Current state\nof the art approaches that do not use any labeled training data, however,\nrequire two separate modeling steps: Learning a probabilistic latent variable\nmodel based on the WS sources -- making assumptions that rarely hold in\npractice -- followed by downstream model training. Importantly, the first step\nof modeling does not consider the performance of the downstream model. To\naddress these caveats we propose an end-to-end approach for directly learning\nthe downstream model by maximizing its agreement with probabilistic labels\ngenerated by reparameterizing previous probabilistic posteriors with a neural\nnetwork. Our results show improved performance over prior work in terms of end\nmodel performance on downstream test sets, as well as in terms of improved\nrobustness to dependencies among weak supervision sources.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 19:10:11 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Cachay", "Salva R\u00fchling", ""], ["Boecking", "Benedikt", ""], ["Dubrawski", "Artur", ""]]}, {"id": "2107.02239", "submitter": "Pranav Jeevan P", "authors": "Pranav Jeevan, Amit Sethi (Indian Institute of Technology Bombay)", "title": "Vision Xformers: Efficient Attention for Image Classification", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Linear attention mechanisms provide hope for overcoming the bottleneck of\nquadratic complexity which restricts application of transformer models in\nvision tasks. We modify the ViT architecture to work on longer sequence data by\nreplacing the quadratic attention with efficient transformers like Performer,\nLinformer and Nystr\\\"omformer of linear complexity creating Vision X-formers\n(ViX). We show that ViX performs better than ViT in image classification\nconsuming lesser computing resources. We further show that replacing the\nembedding linear layer by convolutional layers in ViX further increases their\nperformance. Our test on recent visions transformer models like LeViT and\nCompact Convolutional Transformer (CCT) show that replacing the attention with\nNystr\\\"omformer or Performer saves GPU usage and memory without deteriorating\nperformance. Incorporating these changes can democratize transformers by making\nthem accessible to those with limited data and computing resources.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 19:24:23 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Jeevan", "Pranav", "", "Indian Institute of Technology Bombay"], ["Sethi", "Amit", "", "Indian Institute of Technology Bombay"]]}, {"id": "2107.02259", "submitter": "Fabian Leinen Leinen", "authors": "Fabian Leinen, Vittorio Cozzolino, Torsten Sch\\\"on", "title": "VolNet: Estimating Human Body Part Volumes from a Single RGB Image", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human body volume estimation from a single RGB image is a challenging problem\ndespite minimal attention from the research community. However VolNet, an\narchitecture leveraging 2D and 3D pose estimation, body part segmentation and\nvolume regression extracted from a single 2D RGB image combined with the\nsubject's body height can be used to estimate the total body volume. VolNet is\ndesigned to predict the 2D and 3D pose as well as the body part segmentation in\nintermediate tasks. We generated a synthetic, large-scale dataset of\nphoto-realistic images of human bodies with a wide range of body shapes and\nrealistic poses called SURREALvols. By using Volnet and combining multiple\nstacked hourglass networks together with ResNeXt, our model correctly predicted\nthe volume in ~82% of cases with a 10% tolerance threshold. This is a\nconsiderable improvement compared to state-of-the-art solutions such as BodyNet\nwith only a ~38% success rate.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 20:38:44 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Leinen", "Fabian", ""], ["Cozzolino", "Vittorio", ""], ["Sch\u00f6n", "Torsten", ""]]}, {"id": "2107.02274", "submitter": "Aadirupa Saha", "authors": "Aadirupa Saha, Pierre Gaillard", "title": "Dueling Bandits with Adversarial Sleeping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce the problem of sleeping dueling bandits with stochastic\npreferences and adversarial availabilities (DB-SPAA). In almost all dueling\nbandit applications, the decision space often changes over time; eg, retail\nstore management, online shopping, restaurant recommendation, search engine\noptimization, etc. Surprisingly, this `sleeping aspect' of dueling bandits has\nnever been studied in the literature. Like dueling bandits, the goal is to\ncompete with the best arm by sequentially querying the preference feedback of\nitem pairs. The non-triviality however results due to the non-stationary item\nspaces that allow any arbitrary subsets items to go unavailable every round.\nThe goal is to find an optimal `no-regret' policy that can identify the best\navailable item at each round, as opposed to the standard `fixed best-arm regret\nobjective' of dueling bandits. We first derive an instance-specific lower bound\nfor DB-SPAA $\\Omega( \\sum_{i =1}^{K-1}\\sum_{j=i+1}^K \\frac{\\log\nT}{\\Delta(i,j)})$, where $K$ is the number of items and $\\Delta(i,j)$ is the\ngap between items $i$ and $j$. This indicates that the sleeping problem with\npreference feedback is inherently more difficult than that for classical\nmulti-armed bandits (MAB). We then propose two algorithms, with near optimal\nregret guarantees. Our results are corroborated empirically.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 21:14:04 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Saha", "Aadirupa", ""], ["Gaillard", "Pierre", ""]]}, {"id": "2107.02282", "submitter": "Jiacheng Li", "authors": "Jiacheng Li, Haibo Ding, Jingbo Shang, Julian McAuley, Zhe Feng", "title": "Weakly Supervised Named Entity Tagging with Learnable Logical Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of building entity tagging systems by using a few rules\nas weak supervision. Previous methods mostly focus on disambiguation entity\ntypes based on contexts and expert-provided rules, while assuming entity spans\nare given. In this work, we propose a novel method TALLOR that bootstraps\nhigh-quality logical rules to train a neural tagger in a fully automated\nmanner. Specifically, we introduce compound rules that are composed from simple\nrules to increase the precision of boundary detection and generate more diverse\npseudo labels. We further design a dynamic label selection strategy to ensure\npseudo label quality and therefore avoid overfitting the neural tagger.\nExperiments on three datasets demonstrate that our method outperforms other\nweakly supervised methods and even rivals a state-of-the-art distantly\nsupervised tagger with a lexicon of over 2,000 terms when starting from only 20\nsimple rules. Our method can serve as a tool for rapidly building taggers in\nemerging domains and tasks. Case studies show that learned rules can\npotentially explain the predicted entities.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 21:32:19 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Li", "Jiacheng", ""], ["Ding", "Haibo", ""], ["Shang", "Jingbo", ""], ["McAuley", "Julian", ""], ["Feng", "Zhe", ""]]}, {"id": "2107.02295", "submitter": "Jo\\v{z}e Ro\\v{z}anec", "authors": "Georgios Sofianidis, Jo\\v{z}e M. Ro\\v{z}anec, Dunja Mladeni\\'c,\n  Dimosthenis Kyriazis", "title": "A Review of Explainable Artificial Intelligence in Manufacturing", "comments": "arXiv admin note: text overlap with arXiv:2102.13076 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The implementation of Artificial Intelligence (AI) systems in the\nmanufacturing domain enables higher production efficiency, outstanding\nperformance, and safer operations, leveraging powerful tools such as deep\nlearning and reinforcement learning techniques. Despite the high accuracy of\nthese models, they are mostly considered black boxes: they are unintelligible\nto the human. Opaqueness affects trust in the system, a factor that is critical\nin the context of decision-making. We present an overview of Explainable\nArtificial Intelligence (XAI) techniques as a means of boosting the\ntransparency of models. We analyze different metrics to evaluate these\ntechniques and describe several application scenarios in the manufacturing\ndomain.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 21:59:55 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Sofianidis", "Georgios", ""], ["Ro\u017eanec", "Jo\u017ee M.", ""], ["Mladeni\u0107", "Dunja", ""], ["Kyriazis", "Dimosthenis", ""]]}, {"id": "2107.02298", "submitter": "Jo\\v{z}e Ro\\v{z}anec", "authors": "Jo\\v{z}e M. Ro\\v{z}anec, Inna Novalija, d Patrik Zajec, Klemen Kenda,\n  Dunja Mladeni\\'c", "title": "Knowledge Modelling and Active Learning in Manufacturing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing digitalization of the manufacturing domain requires adequate\nknowledge modeling to capture relevant information. Ontologies and Knowledge\nGraphs provide means to model and relate a wide range of concepts, problems,\nand configurations. Both can be used to generate new knowledge through\ndeductive inference and identify missing knowledge. While digitalization\nincreases the amount of data available, much data is not labeled and cannot be\ndirectly used to train supervised machine learning models. Active learning can\nbe used to identify the most informative data instances for which to obtain\nusers' feedback, reduce friction, and maximize knowledge acquisition. By\ncombining semantic technologies and active learning, multiple use cases in the\nmanufacturing domain can be addressed taking advantage of the available\nknowledge and data.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 22:07:21 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Ro\u017eanec", "Jo\u017ee M.", ""], ["Novalija", "Inna", ""], ["Zajec", "d Patrik", ""], ["Kenda", "Klemen", ""], ["Mladeni\u0107", "Dunja", ""]]}, {"id": "2107.02308", "submitter": "Joseph Ortiz", "authors": "Joseph Ortiz, Talfan Evans, Andrew J. Davison", "title": "A visual introduction to Gaussian Belief Propagation", "comments": "See online version of this article: https://gaussianbp.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article, we present a visual introduction to Gaussian Belief\nPropagation (GBP), an approximate probabilistic inference algorithm that\noperates by passing messages between the nodes of arbitrarily structured factor\ngraphs. A special case of loopy belief propagation, GBP updates rely only on\nlocal information and will converge independently of the message schedule. Our\nkey argument is that, given recent trends in computing hardware, GBP has the\nright computational properties to act as a scalable distributed probabilistic\ninference framework for future machine learning systems.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 22:43:27 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Ortiz", "Joseph", ""], ["Evans", "Talfan", ""], ["Davison", "Andrew J.", ""]]}, {"id": "2107.02326", "submitter": "Ibrahim Mert Koc", "authors": "Mert Koc, Ekim Yurtsever, Keith Redmill, Umit Ozguner", "title": "Pedestrian Emergence Estimation and Occlusion-Aware Risk Assessment for\n  Urban Autonomous Driving", "comments": "Accepted to ITSC2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Avoiding unseen or partially occluded vulnerable road users (VRUs) is a major\nchallenge for fully autonomous driving in urban scenes. However,\nocclusion-aware risk assessment systems have not been widely studied. Here, we\npropose a pedestrian emergence estimation and occlusion-aware risk assessment\nsystem for urban autonomous driving. First, the proposed system utilizes\navailable contextual information, such as visible cars and pedestrians, to\nestimate pedestrian emergence probabilities in occluded regions. These\nprobabilities are then used in a risk assessment framework, and incorporated\ninto a longitudinal motion controller. The proposed controller is tested\nagainst several baseline controllers that recapitulate some commonly observed\ndriving styles. The simulated test scenarios include randomly placed parked\ncars and pedestrians, most of whom are occluded from the ego vehicle's view and\nemerges randomly. The proposed controller outperformed the baselines in terms\nof safety and comfort measures.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 00:07:09 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Koc", "Mert", ""], ["Yurtsever", "Ekim", ""], ["Redmill", "Keith", ""], ["Ozguner", "Umit", ""]]}, {"id": "2107.02328", "submitter": "Huaju Liang", "authors": "Huaju Liang, Hongyang Bai, Ke Hu and Xinbo Lv", "title": "Polarized skylight orientation determination artificial neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an artificial neural network to determine orientation\nusing polarized skylight. This neural network has specific dilated convolution,\nwhich can extract light intensity information of different polarization\ndirections. Then, the degree of polarization (DOP) and angle of polarization\n(AOP) are directly extracted in the network. In addition, the exponential\nfunction encoding of orientation is designed as the network output, which can\nbetter reflect the insect's encoding of polarization information, and improve\nthe accuracy of orientation determination. Finally, training and testing were\nconducted on a public polarized skylight navigation dataset, and the\nexperimental results proved the stability and effectiveness of the network.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 00:19:22 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Liang", "Huaju", ""], ["Bai", "Hongyang", ""], ["Hu", "Ke", ""], ["Lv", "Xinbo", ""]]}, {"id": "2107.02331", "submitter": "Siddharth Karamcheti", "authors": "Siddharth Karamcheti, Ranjay Krishna, Li Fei-Fei, Christopher D.\n  Manning", "title": "Mind Your Outliers! Investigating the Negative Impact of Outliers on\n  Active Learning for Visual Question Answering", "comments": "Accepted at ACL-IJCNLP 2021. 17 pages, 16 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Active learning promises to alleviate the massive data needs of supervised\nmachine learning: it has successfully improved sample efficiency by an order of\nmagnitude on traditional tasks like topic classification and object\nrecognition. However, we uncover a striking contrast to this promise: across 5\nmodels and 4 datasets on the task of visual question answering, a wide variety\nof active learning approaches fail to outperform random selection. To\nunderstand this discrepancy, we profile 8 active learning methods on a\nper-example basis, and identify the problem as collective outliers -- groups of\nexamples that active learning methods prefer to acquire but models fail to\nlearn (e.g., questions that ask about text in images or require external\nknowledge). Through systematic ablation experiments and qualitative\nvisualizations, we verify that collective outliers are a general phenomenon\nresponsible for degrading pool-based active learning. Notably, we show that\nactive learning sample efficiency increases significantly as the number of\ncollective outliers in the active learning pool decreases. We conclude with a\ndiscussion and prescriptive recommendations for mitigating the effects of these\noutliers in future work.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 00:52:11 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Karamcheti", "Siddharth", ""], ["Krishna", "Ranjay", ""], ["Fei-Fei", "Li", ""], ["Manning", "Christopher D.", ""]]}, {"id": "2107.02339", "submitter": "Harold Soh", "authors": "Kaiqi Chen, Yong Lee, Harold Soh", "title": "Multi-Modal Mutual Information (MuMMI) Training for Robust\n  Self-Supervised Deep Reinforcement Learning", "comments": "10 pages, Published in ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work focuses on learning useful and robust deep world models using\nmultiple, possibly unreliable, sensors. We find that current methods do not\nsufficiently encourage a shared representation between modalities; this can\ncause poor performance on downstream tasks and over-reliance on specific\nsensors. As a solution, we contribute a new multi-modal deep latent state-space\nmodel, trained using a mutual information lower-bound. The key innovation is a\nspecially-designed density ratio estimator that encourages consistency between\nthe latent codes of each modality. We tasked our method to learn policies (in a\nself-supervised manner) on multi-modal Natural MuJoCo benchmarks and a\nchallenging Table Wiping task. Experiments show our method significantly\noutperforms state-of-the-art deep reinforcement learning methods, particularly\nin the presence of missing observations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 01:39:21 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Chen", "Kaiqi", ""], ["Lee", "Yong", ""], ["Soh", "Harold", ""]]}, {"id": "2107.02351", "submitter": "EPTCS", "authors": "Maria Paola Bonacina (Universit\\`a degli Studi di Verona, Italy)", "title": "Proof Generation in CDSAT", "comments": "In Proceedings PxTP 2021, arXiv:2107.01544", "journal-ref": "EPTCS 336, 2021, pp. 1-4", "doi": "10.4204/EPTCS.336.1", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The main ideas in the CDSAT (Conflict-Driven Satisfiability) framework for\nSMT are summarized, leading to approaches to proof generation in CDSAT.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:35:21 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Bonacina", "Maria Paola", "", "Universit\u00e0 degli Studi di Verona, Italy"]]}, {"id": "2107.02358", "submitter": "Sumit Mandal", "authors": "Gokul Krishnan, Sumit K. Mandal, Chaitali Chakrabarti, Jae-sun Seo,\n  Umit Y. Ogras, Yu Cao", "title": "Impact of On-Chip Interconnect on In-Memory Acceleration of Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3460233", "report-no": null, "categories": "cs.AR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the widespread use of Deep Neural Networks (DNNs), machine learning\nalgorithms have evolved in two diverse directions -- one with ever-increasing\nconnection density for better accuracy and the other with more compact sizing\nfor energy efficiency. The increase in connection density increases on-chip\ndata movement, which makes efficient on-chip communication a critical function\nof the DNN accelerator. The contribution of this work is threefold. First, we\nillustrate that the point-to-point (P2P)-based interconnect is incapable of\nhandling a high volume of on-chip data movement for DNNs. Second, we evaluate\nP2P and network-on-chip (NoC) interconnect (with a regular topology such as a\nmesh) for SRAM- and ReRAM-based in-memory computing (IMC) architectures for a\nrange of DNNs. This analysis shows the necessity for the optimal interconnect\nchoice for an IMC DNN accelerator. Finally, we perform an experimental\nevaluation for different DNNs to empirically obtain the performance of the IMC\narchitecture with both NoC-tree and NoC-mesh. We conclude that, at the tile\nlevel, NoC-tree is appropriate for compact DNNs employed at the edge, and\nNoC-mesh is necessary to accelerate DNNs with high connection density.\nFurthermore, we propose a technique to determine the optimal choice of\ninterconnect for any given DNN. In this technique, we use analytical models of\nNoC to evaluate end-to-end communication latency of any given DNN. We\ndemonstrate that the interconnect optimization in the IMC architecture results\nin up to 6$\\times$ improvement in energy-delay-area product for VGG-19\ninference compared to the state-of-the-art ReRAM-based IMC architectures.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:44:00 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Krishnan", "Gokul", ""], ["Mandal", "Sumit K.", ""], ["Chakrabarti", "Chaitali", ""], ["Seo", "Jae-sun", ""], ["Ogras", "Umit Y.", ""], ["Cao", "Yu", ""]]}, {"id": "2107.02359", "submitter": "Shruthi Chari", "authors": "Shruthi Chari, Prithwish Chakraborty, Mohamed Ghalwash, Oshani\n  Seneviratne, Elif K. Eyigoz, Daniel M. Gruen, Fernando Suarez Saiz, Ching-Hua\n  Chen, Pablo Meyer Rojas, Deborah L. McGuinness", "title": "Leveraging Clinical Context for User-Centered Explainability: A Diabetes\n  Use Case", "comments": "4 pages, 4 tables, 3 figures, 2.5 pages appendices To appear and\n  accepted at: KDD Workshop on Applied Data Science for Healthcare (DSHealth),\n  2021, Virtual", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Academic advances of AI models in high-precision domains, like healthcare,\nneed to be made explainable in order to enhance real-world adoption. Our past\nstudies and ongoing interactions indicate that medical experts can use AI\nsystems with greater trust if there are ways to connect the model inferences\nabout patients to explanations that are tied back to the context of use.\nSpecifically, risk prediction is a complex problem of diagnostic and\ninterventional importance to clinicians wherein they consult different sources\nto make decisions. To enable the adoption of the ever improving AI risk\nprediction models in practice, we have begun to explore techniques to\ncontextualize such models along three dimensions of interest: the patients'\nclinical state, AI predictions about their risk of complications, and\nalgorithmic explanations supporting the predictions. We validate the importance\nof these dimensions by implementing a proof-of-concept (POC) in type-2 diabetes\n(T2DM) use case where we assess the risk of chronic kidney disease (CKD) - a\ncommon T2DM comorbidity. Within the POC, we include risk prediction models for\nCKD, post-hoc explainers of the predictions, and other natural-language modules\nwhich operationalize domain knowledge and CPGs to provide context. With primary\ncare physicians (PCP) as our end-users, we present our initial results and\nclinician feedback in this paper. Our POC approach covers multiple knowledge\nsources and clinical scenarios, blends knowledge to explain data and\npredictions to PCPs, and received an enthusiastic response from our medical\nexpert.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:44:40 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 01:19:16 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 18:35:40 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Chari", "Shruthi", ""], ["Chakraborty", "Prithwish", ""], ["Ghalwash", "Mohamed", ""], ["Seneviratne", "Oshani", ""], ["Eyigoz", "Elif K.", ""], ["Gruen", "Daniel M.", ""], ["Saiz", "Fernando Suarez", ""], ["Chen", "Ching-Hua", ""], ["Rojas", "Pablo Meyer", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "2107.02361", "submitter": "Paolo Fazzini", "authors": "Paolo Fazzini, Marco Torre, Valeria Rizza and Francesco Petracchini", "title": "Effects of Smart Traffic Signal Control on Air Quality", "comments": "23 pages, 21 figures. arXiv admin note: substantial text overlap with\n  arXiv:2107.01347", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Adaptive traffic signal control (ATSC) in urban traffic networks poses a\nchallenging task due to the complicated dynamics arising in traffic systems. In\nrecent years, several approaches based on multi-agent deep reinforcement\nlearning (MARL) have been studied experimentally. These approaches propose\ndistributed techniques in which each signalized intersection is seen as an\nagent in a stochastic game whose purpose is to optimize the flow of vehicles in\nits vicinity. In this setting, the systems evolves towards an equilibrium among\nthe agents that shows beneficial for the whole traffic network. A recently\ndeveloped multi-agent variant of the well-established advantage actor-critic\n(A2C) algorithm, called MA2C (multi-agent A2C) exploits the promising idea of\nsome communication among the agents. In this view,the agents share their\nstrategies with other neighbor agents, thereby stabilizing the learning process\neven when the agents grow in number and variety. We experimented MA2C in two\ntraffic networks located in Bologna (Italy) and found that its action\ntranslates into a significant decrease of the amount of pollutants released\ninto the environment.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:48:42 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Fazzini", "Paolo", ""], ["Torre", "Marco", ""], ["Rizza", "Valeria", ""], ["Petracchini", "Francesco", ""]]}, {"id": "2107.02367", "submitter": "Dianbo Liu Dr", "authors": "Dianbo Liu, Alex Lamb, Kenji Kawaguchi, Anirudh Goyal, Chen Sun,\n  Michael Curtis Mozer, Yoshua Bengio", "title": "Discrete-Valued Neural Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning has advanced from fully connected architectures to structured\nmodels organized into components, e.g., the transformer composed of positional\nelements, modular architectures divided into slots, and graph neural nets made\nup of nodes. In structured models, an interesting question is how to conduct\ndynamic and possibly sparse communication among the separate components. Here,\nwe explore the hypothesis that restricting the transmitted information among\ncomponents to discrete representations is a beneficial bottleneck. The\nmotivating intuition is human language in which communication occurs through\ndiscrete symbols. Even though individuals have different understandings of what\na \"cat\" is based on their specific experiences, the shared discrete token makes\nit possible for communication among individuals to be unimpeded by individual\ndifferences in internal representation. To discretize the values of concepts\ndynamically communicated among specialist components, we extend the\nquantization mechanism from the Vector-Quantized Variational Autoencoder to\nmulti-headed discretization with shared codebooks and use it for\ndiscrete-valued neural communication (DVNC). Our experiments show that DVNC\nsubstantially improves systematic generalization in a variety of architectures\n-- transformers, modular architectures, and graph neural networks. We also show\nthat the DVNC is robust to the choice of hyperparameters, making the method\nvery useful in practice. Moreover, we establish a theoretical justification of\nour discretization process, proving that it has the ability to increase noise\nrobustness and reduce the underlying dimensionality of the model.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 03:09:25 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 01:05:59 GMT"}, {"version": "v3", "created": "Sat, 10 Jul 2021 18:06:52 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Liu", "Dianbo", ""], ["Lamb", "Alex", ""], ["Kawaguchi", "Kenji", ""], ["Goyal", "Anirudh", ""], ["Sun", "Chen", ""], ["Mozer", "Michael Curtis", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2107.02371", "submitter": "Yuntian Deng", "authors": "Yuntian Deng, Xingyu Zhou, Baekjin Kim, Ambuj Tewari, Abhishek Gupta,\n  Ness Shroff", "title": "Weighted Gaussian Process Bandits for Non-stationary Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the Gaussian process (GP) bandit optimization\nproblem in a non-stationary environment. To capture external changes, the\nblack-box function is allowed to be time-varying within a reproducing kernel\nHilbert space (RKHS). To this end, we develop WGP-UCB, a novel UCB-type\nalgorithm based on weighted Gaussian process regression. A key challenge is how\nto cope with infinite-dimensional feature maps. To that end, we leverage kernel\napproximation techniques to prove a sublinear regret bound, which is the first\n(frequentist) sublinear regret guarantee on weighted time-varying bandits with\ngeneral nonlinear rewards. This result generalizes both non-stationary linear\nbandits and standard GP-UCB algorithms. Further, a novel concentration\ninequality is achieved for weighted Gaussian process regression with general\nweights. We also provide universal upper bounds and weight-dependent upper\nbounds for weighted maximum information gains. These results are potentially of\nindependent interest for applications such as news ranking and adaptive\npricing, where weights can be adopted to capture the importance or quality of\ndata. Finally, we conduct experiments to highlight the favorable gains of the\nproposed algorithm in many cases when compared to existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 03:37:33 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Deng", "Yuntian", ""], ["Zhou", "Xingyu", ""], ["Kim", "Baekjin", ""], ["Tewari", "Ambuj", ""], ["Gupta", "Abhishek", ""], ["Shroff", "Ness", ""]]}, {"id": "2107.02377", "submitter": "Kaixuan Huang", "authors": "Kaixuan Huang, Sham M. Kakade, Jason D. Lee, Qi Lei", "title": "A Short Note on the Relationship of Information Gain and Eluder\n  Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eluder dimension and information gain are two widely used methods of\ncomplexity measures in bandit and reinforcement learning. Eluder dimension was\noriginally proposed as a general complexity measure of function classes, but\nthe common examples of where it is known to be small are function spaces\n(vector spaces). In these cases, the primary tool to upper bound the eluder\ndimension is the elliptic potential lemma. Interestingly, the elliptic\npotential lemma also features prominently in the analysis of linear\nbandits/reinforcement learning and their nonparametric generalization, the\ninformation gain. We show that this is not a coincidence -- eluder dimension\nand information gain are equivalent in a precise sense for reproducing kernel\nHilbert spaces.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 04:01:22 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Huang", "Kaixuan", ""], ["Kakade", "Sham M.", ""], ["Lee", "Jason D.", ""], ["Lei", "Qi", ""]]}, {"id": "2107.02385", "submitter": "Mark J. Nelson", "authors": "Mark J. Nelson", "title": "Estimates for the Branching Factors of Atari Games", "comments": "Accepted at IEEE Conference on Games (CoG) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The branching factor of a game is the average number of new states reachable\nfrom a given state. It is a widely used metric in AI research on board games,\nbut less often computed or discussed for videogames. This paper provides\nestimates for the branching factors of 103 Atari 2600 games, as implemented in\nthe Arcade Learning Environment (ALE). Depending on the game, ALE exposes\nbetween 3 and 18 available actions per frame of gameplay, which is an upper\nbound on branching factor. This paper shows, based on an enumeration of the\nfirst 1 million distinct states reachable in each game, that the average\nbranching factor is usually much lower, in many games barely above 1. In\naddition to reporting the branching factors, this paper aims to clarify what\nconstitutes a distinct state in ALE.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 04:45:24 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 05:59:10 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Nelson", "Mark J.", ""]]}, {"id": "2107.02389", "submitter": "Qingyong Hu", "authors": "Qingyong Hu, Bo Yang, Linhai Xie, Stefano Rosa, Yulan Guo, Zhihua\n  Wang, Niki Trigoni and Andrew Markham", "title": "Learning Semantic Segmentation of Large-Scale Point Clouds with Random\n  Sampling", "comments": "IEEE TPAMI 2021. arXiv admin note: substantial text overlap with\n  arXiv:1911.11236", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3083288", "report-no": null, "categories": "cs.CV cs.AI cs.RO eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the problem of efficient semantic segmentation of large-scale 3D\npoint clouds. By relying on expensive sampling techniques or computationally\nheavy pre/post-processing steps, most existing approaches are only able to be\ntrained and operate over small-scale point clouds. In this paper, we introduce\nRandLA-Net, an efficient and lightweight neural architecture to directly infer\nper-point semantics for large-scale point clouds. The key to our approach is to\nuse random point sampling instead of more complex point selection approaches.\nAlthough remarkably computation and memory efficient, random sampling can\ndiscard key features by chance. To overcome this, we introduce a novel local\nfeature aggregation module to progressively increase the receptive field for\neach 3D point, thereby effectively preserving geometric details. Comparative\nexperiments show that our RandLA-Net can process 1 million points in a single\npass up to 200x faster than existing approaches. Moreover, extensive\nexperiments on five large-scale point cloud datasets, including Semantic3D,\nSemanticKITTI, Toronto3D, NPM3D and S3DIS, demonstrate the state-of-the-art\nsemantic segmentation performance of our RandLA-Net.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 05:08:34 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Hu", "Qingyong", ""], ["Yang", "Bo", ""], ["Xie", "Linhai", ""], ["Rosa", "Stefano", ""], ["Guo", "Yulan", ""], ["Wang", "Zhihua", ""], ["Trigoni", "Niki", ""], ["Markham", "Andrew", ""]]}, {"id": "2107.02427", "submitter": "Erdem Akag\\\"und\\\"uz", "authors": "Erdem Akag\\\"und\\\"uz and Oguzhan Cifdaloz", "title": "Dynamical System Parameter Identification using Deep Recurrent Cell\n  Networks", "comments": "Final version published in Journal of Neural Computing and\n  Applications", "journal-ref": null, "doi": "10.1007/s00521-021-06271-5", "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the parameter identification problem in\ndynamical systems through a deep learning approach. Focusing mainly on\nsecond-order, linear time-invariant dynamical systems, the topic of damping\nfactor identification is studied. By utilizing a six-layer deep neural network\nwith different recurrent cells, namely GRUs, LSTMs or BiLSTMs; and by feeding\ninput-output sequence pairs captured from a dynamical system simulator, we\nsearch for an effective deep recurrent architecture in order to resolve damping\nfactor identification problem. Our study results show that, although previously\nnot utilized for this task in the literature, bidirectional gated recurrent\ncells (BiLSTMs) provide better parameter identification results when compared\nto unidirectional gated recurrent memory cells such as GRUs and LSTM. Thus,\nindicating that an input-output sequence pair of finite length, collected from\na dynamical system and when observed anachronistically, may carry information\nin both time directions for prediction of a dynamical systems parameter.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 07:04:36 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Akag\u00fcnd\u00fcz", "Erdem", ""], ["Cifdaloz", "Oguzhan", ""]]}, {"id": "2107.02451", "submitter": "Kun He Prof.", "authors": "Kun He, Chao Li, Yixiao Yang, Gao Huang, John E. Hopcroft", "title": "Integrating Circle Kernels into Convolutional Neural Networks", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The square kernel is a standard unit for contemporary Convolutional Neural\nNetworks (CNNs), as it fits well on the tensor computation for the convolution\noperation. However, the receptive field in the human visual system is actually\nisotropic like a circle. Motivated by this observation, we propose using circle\nkernels with isotropic receptive fields for the convolution, and our training\ntakes approximately equivalent amount of calculation when compared with the\ncorresponding CNN with square kernels. Our preliminary experiments demonstrate\nthe rationality of circle kernels. We then propose a kernel boosting strategy\nthat integrates the circle kernels with square kernels for the training and\ninference, and we further let the kernel size/radius be learnable during the\ntraining. Note that we reparameterize the circle kernels or integrated kernels\nbefore the inference, thus taking no extra computation as well as the number of\nparameter overhead for the testing. Extensive experiments on several standard\ndatasets, ImageNet, CIFAR-10 and CIFAR-100, using the circle kernels or\nintegrated kernels on typical existing CNNs, show that our approach exhibits\nhighly competitive performance. Specifically, on ImageNet with standard data\naugmentation, our approach dramatically boosts the performance of\nMobileNetV3-Small by 5.20% top-1 accuracy and 3.39% top-5 accuracy, and boosts\nthe performance of MobileNetV3-Large by 2.16% top-1 accuracy and 1.18% top-5\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 07:59:36 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 09:10:08 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["He", "Kun", ""], ["Li", "Chao", ""], ["Yang", "Yixiao", ""], ["Huang", "Gao", ""], ["Hopcroft", "John E.", ""]]}, {"id": "2107.02453", "submitter": "Dumindu Tissera", "authors": "Dumindu Tissera, Kasun Vithanage, Rukshan Wijesinghe, Alex Xavier,\n  Sanath Jayasena, Subha Fernando, Ranga Rodrigo", "title": "Neural Mixture Models with Expectation-Maximization for End-to-end Deep\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any clustering algorithm must synchronously learn to model the clusters and\nallocate data to those clusters in the absence of labels. Mixture model-based\nmethods model clusters with pre-defined statistical distributions and allocate\ndata to those clusters based on the cluster likelihoods. They iteratively\nrefine those distribution parameters and member assignments following the\nExpectation-Maximization (EM) algorithm. However, the cluster representability\nof such hand-designed distributions that employ a limited amount of parameters\nis not adequate for most real-world clustering tasks. In this paper, we realize\nmixture model-based clustering with a neural network where the final layer\nneurons, with the aid of an additional transformation, approximate cluster\ndistribution outputs. The network parameters pose as the parameters of those\ndistributions. The result is an elegant, much-generalized representation of\nclusters than a restricted mixture of hand-designed distributions. We train the\nnetwork end-to-end via batch-wise EM iterations where the forward pass acts as\nthe E-step and the backward pass acts as the M-step. In image clustering, the\nmixture-based EM objective can be used as the clustering objective along with\nexisting representation learning methods. In particular, we show that when\nmixture-EM optimization is fused with consistency optimization, it improves the\nsole consistency optimization performance in clustering. Our trained networks\noutperform single-stage deep clustering methods that still depend on k-means,\nwith unsupervised classification accuracy of 63.8% in STL10, 58% in CIFAR10,\n25.9% in CIFAR100, and 98.9% in MNIST.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 08:00:58 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Tissera", "Dumindu", ""], ["Vithanage", "Kasun", ""], ["Wijesinghe", "Rukshan", ""], ["Xavier", "Alex", ""], ["Jayasena", "Sanath", ""], ["Fernando", "Subha", ""], ["Rodrigo", "Ranga", ""]]}, {"id": "2107.02457", "submitter": "Jean-Baptiste Herv\\'e", "authors": "Jean-Baptiste Herv\\'e, Christoph Salge", "title": "Comparing PCG metrics with Human Evaluation in Minecraft Settlement\n  Generation", "comments": "Accepted to the FDG'21 workshop on PCG", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are a range of metrics that can be applied to the artifacts produced by\nprocedural content generation, and several of them come with qualitative\nclaims. In this paper, we adapt a range of existing PCG metrics to generated\nMinecraft settlements, develop a few new metrics inspired by PCG literature,\nand compare the resulting measurements to existing human evaluations. The aim\nis to analyze how those metrics capture human evaluation scores in different\ncategories, how the metrics generalize to another game domain, and how metrics\ndeal with more complex artifacts. We provide an exploratory look at a variety\nof metrics and provide an information gain and several correlation analyses. We\nfound some relationships between human scores and metrics counting specific\nelements, measuring the diversity of blocks and measuring the presence of\ncrafting materials for the present complex blocks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 08:07:24 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Herv\u00e9", "Jean-Baptiste", ""], ["Salge", "Christoph", ""]]}, {"id": "2107.02463", "submitter": "Florian Haselbeck", "authors": "Florian Haselbeck and Dominik G. Grimm", "title": "EVARS-GPR: EVent-triggered Augmented Refitting of Gaussian Process\n  Regression for Seasonal Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time series forecasting is a growing domain with diverse applications.\nHowever, changes of the system behavior over time due to internal or external\ninfluences are challenging. Therefore, predictions of a previously learned\nfore-casting model might not be useful anymore. In this paper, we present\nEVent-triggered Augmented Refitting of Gaussian Process Regression for Seasonal\nData (EVARS-GPR), a novel online algorithm that is able to handle sudden shifts\nin the target variable scale of seasonal data. For this purpose, EVARS-GPR\ncom-bines online change point detection with a refitting of the prediction\nmodel using data augmentation for samples prior to a change point. Our\nexperiments on sim-ulated data show that EVARS-GPR is applicable for a wide\nrange of output scale changes. EVARS-GPR has on average a 20.8 % lower RMSE on\ndifferent real-world datasets compared to methods with a similar computational\nresource con-sumption. Furthermore, we show that our algorithm leads to a\nsix-fold reduction of the averaged runtime in relation to all comparison\npartners with a periodical refitting strategy. In summary, we present a\ncomputationally efficient online fore-casting algorithm for seasonal time\nseries with changes of the target variable scale and demonstrate its\nfunctionality on simulated as well as real-world data. All code is publicly\navailable on GitHub: https://github.com/grimmlab/evars-gpr.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 08:20:28 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Haselbeck", "Florian", ""], ["Grimm", "Dominik G.", ""]]}, {"id": "2107.02466", "submitter": "Zimu Zheng Dr.", "authors": "Zimu Zheng, Qiong Chen, Chuang Hu, Dan Wang, Fangming Liu", "title": "On-edge Multi-task Transfer Learning: Model and Practice with\n  Data-driven Task Allocation", "comments": "15 pages, published in IEEE TRANSACTIONS ON Parallel and Distributed\n  Systems, VOL. 31, NO. 6, JUNE 2020", "journal-ref": "in IEEE Transactions on Parallel and Distributed Systems, vol. 31,\n  no. 6, pp. 1357-1371, 1 June 2020", "doi": "10.1109/TPDS.2019.2962435", "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On edge devices, data scarcity occurs as a common problem where transfer\nlearning serves as a widely-suggested remedy. Nevertheless, transfer learning\nimposes a heavy computation burden to resource-constrained edge devices.\nExisting task allocation works usually assume all submitted tasks are equally\nimportant, leading to inefficient resource allocation at a task level when\ndirectly applied in Multi-task Transfer Learning (MTL). To address these\nissues, we first reveal that it is crucial to measure the impact of tasks on\noverall decision performance improvement and quantify \\emph{task importance}.\nWe then show that task allocation with task importance for MTL (TATIM) is a\nvariant of the NP-complete Knapsack problem, where the complicated computation\nto solve this problem needs to be conducted repeatedly under varying contexts.\nTo solve TATIM with high computational efficiency, we propose a Data-driven\nCooperative Task Allocation (DCTA) approach. Finally, we evaluate the\nperformance of DCTA by not only a trace-driven simulation, but also a new\ncomprehensive real-world AIOps case study that bridges model and practice via a\nnew architecture and main components design within the AIOps system. Extensive\nexperiments show that our DCTA reduces 3.24 times of processing time, and saves\n48.4\\% energy consumption compared with the state-of-the-art when solving\nTATIM.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 08:24:25 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Zheng", "Zimu", ""], ["Chen", "Qiong", ""], ["Hu", "Chuang", ""], ["Wang", "Dan", ""], ["Liu", "Fangming", ""]]}, {"id": "2107.02472", "submitter": "Marco Guerini", "authors": "Yi-Ling Chung, Serra Sinem Tekiroglu, Sara Tonelli, Marco Guerini", "title": "Empowering NGOs in Countering Online Hate Messages", "comments": "Preprint of the paper published in Online Social Networks and Media\n  Journal (OSNEM)", "journal-ref": null, "doi": "10.1016/j.osnem.2021.100150", "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies on online hate speech have mostly focused on the automated detection\nof harmful messages. Little attention has been devoted so far to the\ndevelopment of effective strategies to fight hate speech, in particular through\nthe creation of counter-messages. While existing manual scrutiny and\nintervention strategies are time-consuming and not scalable, advances in\nnatural language processing have the potential to provide a systematic approach\nto hatred management. In this paper, we introduce a novel ICT platform that NGO\noperators can use to monitor and analyze social media data, along with a\ncounter-narrative suggestion tool. Our platform aims at increasing the\nefficiency and effectiveness of operators' activities against islamophobia. We\ntest the platform with more than one hundred NGO operators in three countries\nthrough qualitative and quantitative evaluation. Results show that NGOs favor\nthe platform solution with the suggestion tool, and that the time required to\nproduce counter-narratives significantly decreases.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 08:36:24 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Chung", "Yi-Ling", ""], ["Tekiroglu", "Serra Sinem", ""], ["Tonelli", "Sara", ""], ["Guerini", "Marco", ""]]}, {"id": "2107.02517", "submitter": "Weiwei Jiang", "authors": "Weiwei Jiang, Jiayun Luo", "title": "An Evaluation of Machine Learning and Deep Learning Models for Drought\n  Prediction using Weather Data", "comments": "Github link:\n  https://github.com/jwwthu/DL4Climate/tree/main/DroughtPrediction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drought is a serious natural disaster that has a long duration and a wide\nrange of influence. To decrease the drought-caused losses, drought prediction\nis the basis of making the corresponding drought prevention and disaster\nreduction measures. While this problem has been studied in the literature, it\nremains unknown whether drought can be precisely predicted or not with machine\nlearning models using weather data. To answer this question, a real-world\npublic dataset is leveraged in this study and different drought levels are\npredicted using the last 90 days of 18 meteorological indicators as the\npredictors. In a comprehensive approach, 16 machine learning models and 16 deep\nlearning models are evaluated and compared. The results show no single model\ncan achieve the best performance for all evaluation metrics simultaneously,\nwhich indicates the drought prediction problem is still challenging. As\nbenchmarks for further studies, the code and results are publicly available in\na Github repository.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 10:19:43 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Jiang", "Weiwei", ""], ["Luo", "Jiayun", ""]]}, {"id": "2107.02524", "submitter": "Lang Nie", "authors": "Lang Nie, Chunyu Lin, Kang Liao, Shuaicheng Liu, Yao Zhao", "title": "Depth-Aware Multi-Grid Deep Homography Estimation with Contextual\n  Correlation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homography estimation is an important task in computer vision, such as image\nstitching, video stabilization, and camera calibration. Traditional homography\nestimation methods heavily depend on the quantity and distribution of feature\npoints, leading to poor robustness in textureless scenes. The learning\nsolutions, on the contrary, try to learn robust deep features but demonstrate\nunsatisfying performance in the scenes of low overlap rates. In this paper, we\naddress the two problems simultaneously, by designing a contextual correlation\nlayer, which can capture the long-range correlation on feature maps and\nflexibly be bridged in a learning framework. In addition, considering that a\nsingle homography can not represent the complex spatial transformation in\ndepth-varying images with parallax, we propose to predict multi-grid homography\nfrom global to local. Moreover, we equip our network with depth perception\ncapability, by introducing a novel depth-aware shape-preserved loss. Extensive\nexperiments demonstrate the superiority of our method over other\nstate-of-the-art solutions in the synthetic benchmark dataset and real-world\ndataset. The codes and models will be available at\nhttps://github.com/nie-lang/Multi-Grid-Deep-Homogarphy.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 10:33:12 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Nie", "Lang", ""], ["Lin", "Chunyu", ""], ["Liao", "Kang", ""], ["Liu", "Shuaicheng", ""], ["Zhao", "Yao", ""]]}, {"id": "2107.02603", "submitter": "Ricardo Luna Gutierrez", "authors": "Ricardo Luna Gutierrez and Matteo Leonetti", "title": "Meta-Reinforcement Learning for Heuristic Planning", "comments": "ICAPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Meta-Reinforcement Learning (meta-RL) an agent is trained on a set of\ntasks to prepare for and learn faster in new, unseen, but related tasks. The\ntraining tasks are usually hand-crafted to be representative of the expected\ndistribution of test tasks and hence all used in training. We show that given a\nset of training tasks, learning can be both faster and more effective (leading\nto better performance in the test tasks), if the training tasks are\nappropriately selected. We propose a task selection algorithm,\nInformation-Theoretic Task Selection (ITTS), based on information theory, which\noptimizes the set of tasks used for training in meta-RL, irrespectively of how\nthey are generated. The algorithm establishes which training tasks are both\nsufficiently relevant for the test tasks, and different enough from one\nanother. We reproduce different meta-RL experiments from the literature and\nshow that ITTS improves the final performance in all of them.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 13:25:52 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Gutierrez", "Ricardo Luna", ""], ["Leonetti", "Matteo", ""]]}, {"id": "2107.02609", "submitter": "Golsa Heidari", "authors": "Golsa Heidari, Kamran Zamanifar, Naser Nematbakhsh, Farhad Mardookhi", "title": "How to Discover a Semantic Web Service by Knowing Its Functionality\n  Parameters", "comments": "5 pages, 1 figure, 2 tables, ICSTE 2010", "journal-ref": null, "doi": "10.1109/icste.2010.5608824", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we show how to discover a semantic web service among a\nrepository of web services. A new approach for web service discovery based on\ncalculating the functions similarity. We define the Web service functions with\nOntology Web Language (OWL). We wrote some rules for comparing two web\nservices` parameters. Our algorithm compares the parameters of two web\nservices` inputs/outputs by making a bipartite graph. We compute the similarity\nrate by using the Ford-Fulkerson algorithm. The higher the similarity, the less\nare the differences between their functions. At last, our algorithm chooses the\nservice which has the highest similarity. As a consequence, our method is\nuseful when we need to find a web service suitable to replace an existing one\nthat has failed. Especially in autonomic systems, this situation is very common\nand important since we need to ensure the availability of the application which\nis based on the failed web service. We use Universal Description, Discovery and\nIntegration (UDDI) compliant web service registry.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 13:29:59 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Heidari", "Golsa", ""], ["Zamanifar", "Kamran", ""], ["Nematbakhsh", "Naser", ""], ["Mardookhi", "Farhad", ""]]}, {"id": "2107.02629", "submitter": "Yufei Wang", "authors": "Yufei Wang, Haoliang Li, Lap-pui Chau, Alex C. Kot", "title": "Embracing the Dark Knowledge: Domain Generalization Using Regularized\n  Knowledge Distillation", "comments": "Accepted by ACM MM, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though convolutional neural networks are widely used in different tasks, lack\nof generalization capability in the absence of sufficient and representative\ndata is one of the challenges that hinder their practical application. In this\npaper, we propose a simple, effective, and plug-and-play training strategy\nnamed Knowledge Distillation for Domain Generalization (KDDG) which is built\nupon a knowledge distillation framework with the gradient filter as a novel\nregularization term. We find that both the ``richer dark knowledge\" from the\nteacher network, as well as the gradient filter we proposed, can reduce the\ndifficulty of learning the mapping which further improves the generalization\nability of the model. We also conduct experiments extensively to show that our\nframework can significantly improve the generalization capability of deep\nneural networks in different tasks including image classification,\nsegmentation, reinforcement learning by comparing our method with existing\nstate-of-the-art domain generalization techniques. Last but not the least, we\npropose to adopt two metrics to analyze our proposed method in order to better\nunderstand how our proposed method benefits the generalization capability of\ndeep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 14:08:54 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Wang", "Yufei", ""], ["Li", "Haoliang", ""], ["Chau", "Lap-pui", ""], ["Kot", "Alex C.", ""]]}, {"id": "2107.02639", "submitter": "Pengpeng Shao", "authors": "Pengpeng Shao, Tong Liu, Dawei Zhang, Jianhua Tao, Feihu Che, Guohua\n  Yang", "title": "Multi-Level Graph Contrastive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning has attracted a surge of interest recently,\nwhose target at learning discriminant embedding for each node in the graph.\nMost of these representation methods focus on supervised learning and heavily\ndepend on label information. However, annotating graphs are expensive to obtain\nin the real world, especially in specialized domains (i.e. biology), as it\nneeds the annotator to have the domain knowledge to label the graph. To\napproach this problem, self-supervised learning provides a feasible solution\nfor graph representation learning. In this paper, we propose a Multi-Level\nGraph Contrastive Learning (MLGCL) framework for learning robust representation\nof graph data by contrasting space views of graphs. Specifically, we introduce\na novel contrastive view - topological and feature space views. The original\ngraph is first-order approximation structure and contains uncertainty or error,\nwhile the $k$NN graph generated by encoding features preserves high-order\nproximity. Thus $k$NN graph generated by encoding features not only provide a\ncomplementary view, but is more suitable to GNN encoder to extract discriminant\nrepresentation. Furthermore, we develop a multi-level contrastive mode to\npreserve the local similarity and semantic similarity of graph-structured data\nsimultaneously. Extensive experiments indicate MLGCL achieves promising results\ncompared with the existing state-of-the-art graph representation learning\nmethods on seven datasets.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 14:24:43 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Shao", "Pengpeng", ""], ["Liu", "Tong", ""], ["Zhang", "Dawei", ""], ["Tao", "Jianhua", ""], ["Che", "Feihu", ""], ["Yang", "Guohua", ""]]}, {"id": "2107.02655", "submitter": "Pietro Gori", "authors": "Giammarco La Barbera and Pietro Gori and Haithem Boussaid and Bruno\n  Belucci and Alessandro Delmonte and Jeanne Goulin and Sabine Sarnacki and\n  Laurence Rouet and Isabelle Bloch", "title": "Automatic size and pose homogenization with spatial transformer network\n  to improve and accelerate pediatric segmentation", "comments": "ISBI 2021", "journal-ref": "ISBI 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to a high heterogeneity in pose and size and to a limited number of\navailable data, segmentation of pediatric images is challenging for deep\nlearning methods. In this work, we propose a new CNN architecture that is pose\nand scale invariant thanks to the use of Spatial Transformer Network (STN). Our\narchitecture is composed of three sequential modules that are estimated\ntogether during training: (i) a regression module to estimate a similarity\nmatrix to normalize the input image to a reference one; (ii) a differentiable\nmodule to find the region of interest to segment; (iii) a segmentation module,\nbased on the popular UNet architecture, to delineate the object. Unlike the\noriginal UNet, which strives to learn a complex mapping, including pose and\nscale variations, from a finite training dataset, our segmentation module\nlearns a simpler mapping focusing on images with normalized pose and size.\nFurthermore, the use of an automatic bounding box detection through STN allows\nsaving time and especially memory, while keeping similar performance. We test\nthe proposed method in kidney and renal tumor segmentation on abdominal\npediatric CT scanners. Results indicate that the estimated STN homogenization\nof size and pose accelerates the segmentation (25h), compared to standard\ndata-augmentation (33h), while obtaining a similar quality for the kidney\n(88.01\\% of Dice score) and improving the renal tumor delineation (from 85.52\\%\nto 87.12\\%).\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 14:50:03 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["La Barbera", "Giammarco", ""], ["Gori", "Pietro", ""], ["Boussaid", "Haithem", ""], ["Belucci", "Bruno", ""], ["Delmonte", "Alessandro", ""], ["Goulin", "Jeanne", ""], ["Sarnacki", "Sabine", ""], ["Rouet", "Laurence", ""], ["Bloch", "Isabelle", ""]]}, {"id": "2107.02661", "submitter": "Jos\\'e Ribeiro MSc.", "authors": "Jos\\'e Ribeiro, Ra\\'issa Silva, Ronnie Alves", "title": "Does Dataset Complexity Matters for Model Explainers?", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Strategies based on Explainable Artificial Intelligence - XAI have emerged in\ncomputing to promote a better understanding of predictions made by black box\nmodels. Most XAI-based tools used today explain these types of models,\ngenerating attribute rankings aimed at explaining the same, that is, the\nanalysis of Attribute Importance. There is no consensus on which XAI tool\ngenerates a general rank of explainability, for this reason, several proposals\nfor tools have emerged (Ciu, Dalex, Eli5, Lofo, Shap and Skater). Here, we\npresent an experimental benchmark of explainable AI techniques capable of\nproducing model-agnostic global explainability ranks based on tabular data\nrelated to different problems. Seeking to answer questions such as \"Are the\nexplanations generated by the different tools the same, similar or different?\"\nand \"How does data complexity play along model explainability?\". The results\nfrom the construction of 82 computational models and 592 ranks give us some\nlight on the other side of the problem of explainability: dataset complexity!\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 15:01:04 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Ribeiro", "Jos\u00e9", ""], ["Silva", "Ra\u00edssa", ""], ["Alves", "Ronnie", ""]]}, {"id": "2107.02681", "submitter": "Jaemin Cho", "authors": "Zineng Tang, Jaemin Cho, Hao Tan, Mohit Bansal", "title": "VidLanKD: Improving Language Understanding via Video-Distilled Knowledge\n  Transfer", "comments": "18 pages (5 figures, 10 tables)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since visual perception can give rich information beyond text descriptions\nfor world understanding, there has been increasing interest in leveraging\nvisual grounding for language learning. Recently, vokenization has attracted\nattention by using the predictions of a text-to-image retrieval model as labels\nfor language model supervision. Despite its success, the method suffers from\napproximation error of using finite image labels and the lack of vocabulary\ndiversity of a small image-text dataset. To overcome these limitations, we\npresent VidLanKD, a video-language knowledge distillation method for improving\nlanguage understanding. We train a multi-modal teacher model on a video-text\ndataset, and then transfer its knowledge to a student language model with a\ntext dataset. To avoid approximation error, we propose to use different\nknowledge distillation objectives. In addition, the use of a large-scale\nvideo-text dataset helps learn diverse and richer vocabularies. In our\nexperiments, VidLanKD achieves consistent improvements over text-only language\nmodels and vokenization models, on several downstream language understanding\ntasks including GLUE, SQuAD, and SWAG. We also demonstrate the improved world\nknowledge, physical reasoning, and temporal reasoning capabilities of our model\nby evaluating on the GLUE-diagnostics, PIQA, and TRACIE datasets. Lastly, we\npresent comprehensive ablation studies as well as visualizations of the learned\ntext-to-video grounding results of our teacher and student language models. Our\ncode and models are available at: https://github.com/zinengtang/VidLanKD\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 15:41:32 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Tang", "Zineng", ""], ["Cho", "Jaemin", ""], ["Tan", "Hao", ""], ["Bansal", "Mohit", ""]]}, {"id": "2107.02689", "submitter": "Armin Moin", "authors": "Armin Moin, Atta Badii and Stephan G\\\"unnemann", "title": "A Model-Driven Engineering Approach to Machine Learning and Software\n  Modeling", "comments": "Preliminary version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Models are used in both the Software Engineering (SE) and the Artificial\nIntelligence (AI) communities. In the former case, models of software, which\nmay specify the software system architecture on different levels of abstraction\ncould be used in various stages of the Software Development Life-Cycle (SDLC),\nfrom early conceptualization and design, to verification, implementation,\ntesting and evolution. However, in the latter case, i.e., AI, models may\nprovide smart capabilities, such as prediction and decision making support. For\ninstance, in Machine Learning (ML), which is the most popular sub-discipline of\nAI at the present time, mathematical models may learn useful patterns in the\nobserved data instances and can become capable of making better predictions or\nrecommendations in the future. The goal of this work is to create synergy by\nbringing models in the said communities together and proposing a holistic\napproach. We illustrate how software models can become capable of producing or\ndealing with data analytics and ML models. The main focus is on the Internet of\nThings (IoT) and smart Cyber-Physical Systems (CPS) use cases, where both ML\nand model-driven (model-based) SE play a key role. In particular, we implement\nthe proposed approach in an open source prototype and validate it using two use\ncases from the IoT/CPS domain.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 15:50:50 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Moin", "Armin", ""], ["Badii", "Atta", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2107.02690", "submitter": "Armin Moin", "authors": "Armin Moin, Atta Badii and Stephan G\\\"unnemann", "title": "Enabling Un-/Semi-Supervised Machine Learning for MDSE of the Real-World\n  CPS/IoT Applications", "comments": "Preliminary version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a novel approach to support domain-specific\nModel-Driven Software Engineering (MDSE) for the real-world use-case scenarios\nof smart Cyber-Physical Systems (CPS) and the Internet of Things (IoT). We\nargue that the majority of available data in the nature for Artificial\nIntelligence (AI), specifically Machine Learning (ML) are unlabeled. Hence,\nunsupervised and/or semi-supervised ML approaches are the practical choices.\nHowever, prior work in the literature of MDSE has considered supervised ML\napproaches, which only work with labeled training data. Our proposed approach\nis fully implemented and integrated with an existing state-of-the-art MDSE tool\nto serve the CPS/IoT domain. Moreover, we validate the proposed approach using\na portion of the open data of the REFIT reference dataset for the smart energy\nsystems domain. Our model-to-code transformations (code generators) provide the\nfull source code of the desired IoT services out of the model instances in an\nautomated manner. Currently, we generate the source code in Java and Python.\nThe Python code is responsible for the ML functionalities and uses the APIs of\nseveral ML libraries and frameworks, namely Scikit-Learn, Keras and TensorFlow.\nFor unsupervised and semi-supervised learning, the APIs of Scikit-Learn are\ndeployed. In addition to the pure MDSE approach, where certain ML methods,\ne.g., K-Means, Mini-Batch K-Means, DB-SCAN, Spectral Clustering, Gaussian\nMixture Model, Self-Training, Label Propagation and Label Spreading are\nsupported, a more flexible, hybrid approach is also enabled to support the\npractitioner in deploying a pre-trained ML model with any arbitrary\narchitecture and learning algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 15:51:39 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Moin", "Armin", ""], ["Badii", "Atta", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2107.02692", "submitter": "Armin Moin", "authors": "Armin Moin, Andrei Mituca, Atta Badii and Stephan G\\\"unnemann", "title": "ML-Quadrat & DriotData: A Model-Driven Engineering Tool and a Low-Code\n  Platform for Smart IoT Services", "comments": "Preliminary version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present the novel early tool prototype of ML-Quadrat, which\nis an open source research prototype, based on the Eclipse Modeling Framework\n(EMF) and the state of the art in the literature of Model-Driven Software\nEngineering (MDSE) for smart Cyber-Physical Systems (CPS) and the Internet of\nThings (IoT). Its envisioned users are mostly software developers, who might\nnot have deep knowledge and skills in the heterogeneous IoT platforms and the\ndiverse Artificial Intelligence (AI) technologies, specifically regarding Data\nAnalytics and Machine Learning (DAML). ML-Quadrat is released under the terms\nof the Apache 2.0 license on Github: https://github.com/arminmoin/ML-Quadrat.\nAdditionally, the novel early tool prototype of DriotData, a Low-Code platform\ntargeting citizen data scientists and citizen/end-user software developers is\ndemonstrated. DriotData exploits and adopts ML-Quadrat and offers an extended\nversion of it as a web-based service to companies, especially Small- and\nMedium-Sized Enterprises (SME). A basic web-based demo of the Minimum Viable\nProduct (MVP) of DriotData is already available. Finally, a short video\ndemonstrating the tools is available on YouTube: https://youtu.be/YCNFfhmy_JY.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 15:52:09 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Moin", "Armin", ""], ["Mituca", "Andrei", ""], ["Badii", "Atta", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2107.02711", "submitter": "Tengyu Xu", "authors": "Tengyu Xu, Zhuoran Yang, Zhaoran Wang, Yingbin Liang", "title": "A Unified Off-Policy Evaluation Approach for General Value Function", "comments": "submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  General Value Function (GVF) is a powerful tool to represent both the {\\em\npredictive} and {\\em retrospective} knowledge in reinforcement learning (RL).\nIn practice, often multiple interrelated GVFs need to be evaluated jointly with\npre-collected off-policy samples. In the literature, the gradient temporal\ndifference (GTD) learning method has been adopted to evaluate GVFs in the\noff-policy setting, but such an approach may suffer from a large estimation\nerror even if the function approximation class is sufficiently expressive.\nMoreover, none of the previous work have formally established the convergence\nguarantee to the ground truth GVFs under the function approximation settings.\nIn this paper, we address both issues through the lens of a class of GVFs with\ncausal filtering, which cover a wide range of RL applications such as reward\nvariance, value gradient, cost in anomaly detection, stationary distribution\ngradient, etc. We propose a new algorithm called GenTD for off-policy GVFs\nevaluation and show that GenTD learns multiple interrelated multi-dimensional\nGVFs as efficiently as a single canonical scalar value function. We further\nshow that unlike GTD, the learned GVFs by GenTD are guaranteed to converge to\nthe ground truth GVFs as long as the function approximation power is\nsufficiently large. To our best knowledge, GenTD is the first off-policy GVF\nevaluation algorithm that has global optimality guarantee.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 16:20:34 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Xu", "Tengyu", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Liang", "Yingbin", ""]]}, {"id": "2107.02729", "submitter": "Sara Magliacane", "authors": "Biwei Huang, Fan Feng, Chaochao Lu, Sara Magliacane, Kun Zhang", "title": "AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Most approaches in reinforcement learning (RL) are data-hungry and specific\nto fixed environments. In this paper, we propose a principled framework for\nadaptive RL, called AdaRL, that adapts reliably to changes across domains.\nSpecifically, we construct a generative environment model for the structural\nrelationships among variables in the system and embed the changes in a compact\nway, which provides a clear and interpretable picture for locating what and\nwhere the changes are and how to adapt. Based on the environment model, we\ncharacterize a minimal set of representations, including both domain-specific\nfactors and domain-shared state representations, that suffice for reliable and\nlow-cost transfer. Moreover, we show that by explicitly leveraging a compact\nrepresentation to encode changes, we can adapt the policy with only a few\nsamples without further policy optimization in the target domain. We illustrate\nthe efficacy of AdaRL through a series of experiments that allow for changes in\ndifferent components of Cartpole and Atari games.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 16:56:25 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 07:21:38 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Huang", "Biwei", ""], ["Feng", "Fan", ""], ["Lu", "Chaochao", ""], ["Magliacane", "Sara", ""], ["Zhang", "Kun", ""]]}, {"id": "2107.02744", "submitter": "Ayushe Gangal", "authors": "Ayushe Gangal, Peeyush Kumar, Sunita Kumari and Aditya Kumar", "title": "Neural Computing", "comments": "Book chapter, 25 pages, 16 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This chapter aims to provide next-level understanding of the problems of the\nworld and the solutions available to those problems, which lie very well within\nthe domain of neural computing, and at the same time are intelligent in their\napproach, to invoke a sense of innovation among the educationalists,\nresearchers, academic professionals, students and people concerned, by\nhighlighting the work done by major researchers and innovators in this field\nand thus, encouraging the readers to develop newer and more advanced techniques\nfor the same. By means of this chapter, the societal problems are discussed and\nvarious solutions are also given by means of the theories presented and\nresearches done so far. Different types of neural networks discovered so far\nand applications of some of those neural networks are focused on, apart from\ntheir theoretical understanding, the working and core concepts involved in the\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:21:03 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Gangal", "Ayushe", ""], ["Kumar", "Peeyush", ""], ["Kumari", "Sunita", ""], ["Kumar", "Aditya", ""]]}, {"id": "2107.02748", "submitter": "Shyan Akmal", "authors": "Shyan Akmal and Ryan Williams", "title": "MAJORITY-3SAT (and Related Problems) in Polynomial Time", "comments": "Abstract shortened to fit arXiv requirements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Majority-SAT is the problem of determining whether an input $n$-variable\nformula in conjunctive normal form (CNF) has at least $2^{n-1}$ satisfying\nassignments. Majority-SAT and related problems have been studied extensively in\nvarious AI communities interested in the complexity of probabilistic planning\nand inference. Although Majority-SAT has been known to be PP-complete for over\n40 years, the complexity of a natural variant has remained open:\nMajority-$k$SAT, where the input CNF formula is restricted to have clause width\nat most $k$.\n  We prove that for every $k$, Majority-$k$SAT is in P. In fact, for any\npositive integer $k$ and rational $\\rho \\in (0,1)$ with bounded denominator, we\ngive an algorithm that can determine whether a given $k$-CNF has at least $\\rho\n\\cdot 2^n$ satisfying assignments, in deterministic linear time (whereas the\nprevious best-known algorithm ran in exponential time). Our algorithms have\ninteresting positive implications for counting complexity and the complexity of\ninference, significantly reducing the known complexities of related problems\nsuch as E-MAJ-$k$SAT and MAJ-MAJ-$k$SAT. At the heart of our approach is an\nefficient method for solving threshold counting problems by extracting\nsunflowers found in the corresponding set system of a $k$-CNF.\n  We also show that the tractability of Majority-$k$SAT is somewhat fragile.\nFor the closely related GtMajority-SAT problem (where we ask whether a given\nformula has greater than $2^{n-1}$ satisfying assignments) which is known to be\nPP-complete, we show that GtMajority-$k$SAT is in P for $k\\le 3$, but becomes\nNP-complete for $k\\geq 4$. These results are counterintuitive, because the\n``natural'' classifications of these problems would have been PP-completeness,\nand because there is a stark difference in the complexity of GtMajority-$k$SAT\nand Majority-$k$SAT for all $k\\ge 4$.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:24:04 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Akmal", "Shyan", ""], ["Williams", "Ryan", ""]]}, {"id": "2107.02772", "submitter": "Aurghya Maiti", "authors": "Aurghya Maiti, Vineet Nair, Gaurav Sinha", "title": "Causal Bandits on General Graphs", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the problem of determining the best intervention in a Causal\nBayesian Network (CBN) specified only by its causal graph. We model this as a\nstochastic multi-armed bandit (MAB) problem with side-information, where the\ninterventions correspond to the arms of the bandit instance. First, we propose\na simple regret minimization algorithm that takes as input a semi-Markovian\ncausal graph with atomic interventions and possibly unobservable variables, and\nachieves $\\tilde{O}(\\sqrt{M/T})$ expected simple regret, where $M$ is dependent\non the input CBN and could be very small compared to the number of arms. We\nalso show that this is almost optimal for CBNs described by causal graphs\nhaving an $n$-ary tree structure. Our simple regret minimization results, both\nupper and lower bound, subsume previous results in the literature, which\nassumed additional structural restrictions on the input causal graph. In\nparticular, our results indicate that the simple regret guarantee of our\nproposed algorithm can only be improved by considering more nuanced structural\nrestrictions on the causal graph. Next, we propose a cumulative regret\nminimization algorithm that takes as input a general causal graph with all\nobservable nodes and atomic interventions and performs better than the optimal\nMAB algorithm that does not take causal side-information into account. We also\nexperimentally compare both our algorithms with the best known algorithms in\nthe literature. To the best of our knowledge, this work gives the first simple\nand cumulative regret minimization algorithms for CBNs with general causal\ngraphs under atomic interventions and having unobserved confounders.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:29:45 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Maiti", "Aurghya", ""], ["Nair", "Vineet", ""], ["Sinha", "Gaurav", ""]]}, {"id": "2107.02792", "submitter": "Arun Narenthiran Sivakumar", "authors": "Arun Narenthiran Sivakumar and Sahil Modi and Mateus Valverde\n  Gasparino and Che Ellis and Andres Eduardo Baquero Velasquez and Girish\n  Chowdhary and Saurabh Gupta", "title": "Learned Visual Navigation for Under-Canopy Agricultural Robots", "comments": "RSS 2021. Project website with data and videos:\n  https://ansivakumar.github.io/learned-visual-navigation/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We describe a system for visually guided autonomous navigation of\nunder-canopy farm robots. Low-cost under-canopy robots can drive between crop\nrows under the plant canopy and accomplish tasks that are infeasible for\nover-the-canopy drones or larger agricultural equipment. However, autonomously\nnavigating them under the canopy presents a number of challenges: unreliable\nGPS and LiDAR, high cost of sensing, challenging farm terrain, clutter due to\nleaves and weeds, and large variability in appearance over the season and\nacross crop types. We address these challenges by building a modular system\nthat leverages machine learning for robust and generalizable perception from\nmonocular RGB images from low-cost cameras, and model predictive control for\naccurate control in challenging terrain. Our system, CropFollow, is able to\nautonomously drive 485 meters per intervention on average, outperforming a\nstate-of-the-art LiDAR based system (286 meters per intervention) in extensive\nfield testing spanning over 25 km.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:59:02 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Sivakumar", "Arun Narenthiran", ""], ["Modi", "Sahil", ""], ["Gasparino", "Mateus Valverde", ""], ["Ellis", "Che", ""], ["Velasquez", "Andres Eduardo Baquero", ""], ["Chowdhary", "Girish", ""], ["Gupta", "Saurabh", ""]]}, {"id": "2107.02794", "submitter": "Maxwell Nye", "authors": "Maxwell Nye, Michael Henry Tessler, Joshua B. Tenenbaum, Brenden M.\n  Lake", "title": "Improving Coherence and Consistency in Neural Sequence Models with\n  Dual-System, Neuro-Symbolic Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human reasoning can often be understood as an interplay between two systems:\nthe intuitive and associative (\"System 1\") and the deliberative and logical\n(\"System 2\"). Neural sequence models -- which have been increasingly successful\nat performing complex, structured tasks -- exhibit the advantages and failure\nmodes of System 1: they are fast and learn patterns from data, but are often\ninconsistent and incoherent. In this work, we seek a lightweight, training-free\nmeans of improving existing System 1-like sequence models by adding System\n2-inspired logical reasoning. We explore several variations on this theme in\nwhich candidate generations from a neural sequence model are examined for\nlogical consistency by a symbolic reasoning module, which can either accept or\nreject the generations. Our approach uses neural inference to mediate between\nthe neural System 1 and the logical System 2. Results in robust story\ngeneration and grounded instruction-following show that this approach can\nincrease the coherence and accuracy of neurally-based generations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:59:49 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Nye", "Maxwell", ""], ["Tessler", "Michael Henry", ""], ["Tenenbaum", "Joshua B.", ""], ["Lake", "Brenden M.", ""]]}, {"id": "2107.02842", "submitter": "Ren Wang", "authors": "Ren Wang, Tianqi Chen, Stephen Lindsly, Cooper Stansbury, Indika\n  Rajapakse, Alfred Hero", "title": "Immuno-mimetic Deep Neural Networks (Immuno-Net)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomimetics has played a key role in the evolution of artificial neural\nnetworks. Thus far, in silico metaphors have been dominated by concepts from\nneuroscience and cognitive psychology. In this paper we introduce a different\ntype of biomimetic model, one that borrows concepts from the immune system, for\ndesigning robust deep neural networks. This immuno-mimetic model leads to a new\ncomputational biology framework for robustification of deep neural networks\nagainst adversarial attacks. Within this Immuno-Net framework we define a\nrobust adaptive immune-inspired learning system (Immuno-Net RAILS) that\nemulates, in silico, the adaptive biological mechanisms of B-cells that are\nused to defend a mammalian host against pathogenic attacks. When applied to\nimage classification tasks on benchmark datasets, we demonstrate that\nImmuno-net RAILS results in improvement of as much as 12.5% in adversarial\naccuracy of a baseline method, the DkNN-robustified CNN, without appreciable\nloss of accuracy on clean data.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 16:45:23 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Wang", "Ren", ""], ["Chen", "Tianqi", ""], ["Lindsly", "Stephen", ""], ["Stansbury", "Cooper", ""], ["Rajapakse", "Indika", ""], ["Hero", "Alfred", ""]]}, {"id": "2107.02865", "submitter": "Aidan Hogan", "authors": "Daniel Diomedi, Aidan Hogan", "title": "Question Answering over Knowledge Graphs with Neural Machine Translation\n  and Entity Linking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of Question Answering over Knowledge Graphs (KGQA) is to find\nanswers for natural language questions over a knowledge graph. Recent KGQA\napproaches adopt a neural machine translation (NMT) approach, where the natural\nlanguage question is translated into a structured query language. However, NMT\nsuffers from the out-of-vocabulary problem, where terms in a question may not\nhave been seen during training, impeding their translation. This issue is\nparticularly problematic for the millions of entities that large knowledge\ngraphs describe. We rather propose a KGQA approach that delegates the\nprocessing of entities to entity linking (EL) systems. NMT is then used to\ncreate a query template with placeholders that are filled by entities\nidentified in an EL phase. Slot filling is used to decide which entity fills\nwhich placeholder. Experiments for QA over Wikidata show that our approach\noutperforms pure NMT: while there remains a strong dependence on having seen\nsimilar query templates during training, errors relating to entities are\ngreatly reduced.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 19:57:02 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Diomedi", "Daniel", ""], ["Hogan", "Aidan", ""]]}, {"id": "2107.02905", "submitter": "Meabh MacMahon", "authors": "M\\'eabh MacMahon, Woochang Hwang, Soorin Yim, Eoghan MacMahon,\n  Alexandre Abraham, Justin Barton, Mukunthan Tharmakulasingam, Paul Bilokon,\n  Vasanthi Priyadarshini Gaddi, Namshik Han", "title": "Identification and validation of Triamcinolone and Gallopamil as\n  treatments for early COVID-19 via an in silico repurposing pipeline", "comments": "32 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI q-bio.MN", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  SARS-CoV-2, the causative virus of COVID-19 continues to cause an ongoing\nglobal pandemic. Therapeutics are still needed to treat mild and severe\nCOVID-19. Drug repurposing provides an opportunity to deploy drugs for COVID-19\nmore rapidly than developing novel therapeutics. Some existing drugs have shown\npromise for treating COVID-19 in clinical trials. This in silico study uses\nstructural similarity to clinical trial drugs to identify two drugs with\npotential applications to treat early COVID-19. We apply in silico validation\nto suggest a possible mechanism of action for both. Triamcinolone is a\ncorticosteroid structurally similar to Dexamethasone. Gallopamil is a calcium\nchannel blocker structurally similar to Verapamil. We propose that both these\ndrugs could be useful to treat early COVID-19 infection due to the proximity of\ntheir targets within a SARS-CoV-2-induced protein-protein interaction network\nto kinases active in early infection, and the APOA1 protein which is linked to\nthe spread of COVID-19.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 13:08:24 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["MacMahon", "M\u00e9abh", ""], ["Hwang", "Woochang", ""], ["Yim", "Soorin", ""], ["MacMahon", "Eoghan", ""], ["Abraham", "Alexandre", ""], ["Barton", "Justin", ""], ["Tharmakulasingam", "Mukunthan", ""], ["Bilokon", "Paul", ""], ["Gaddi", "Vasanthi Priyadarshini", ""], ["Han", "Namshik", ""]]}, {"id": "2107.02912", "submitter": "Ankit Shah", "authors": "Ankit Shah, Pritish Kamath, Shen Li, Patrick Craven, Kevin Landers,\n  Kevin Oden, Julie Shah", "title": "Supervised Bayesian Specification Inference from Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When observing task demonstrations, human apprentices are able to identify\nwhether a given task is executed correctly long before they gain expertise in\nactually performing that task. Prior research into learning from demonstrations\n(LfD) has failed to capture this notion of the acceptability of a task's\nexecution; meanwhile, temporal logics provide a flexible language for\nexpressing task specifications. Inspired by this, we present Bayesian\nspecification inference, a probabilistic model for inferring task specification\nas a temporal logic formula. We incorporate methods from probabilistic\nprogramming to define our priors, along with a domain-independent likelihood\nfunction to enable sampling-based inference. We demonstrate the efficacy of our\nmodel for inferring specifications, with over 90% similarity observed between\nthe inferred specification and the ground truth, both within a synthetic domain\nand during a real-world table setting task.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 21:16:37 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Shah", "Ankit", ""], ["Kamath", "Pritish", ""], ["Li", "Shen", ""], ["Craven", "Patrick", ""], ["Landers", "Kevin", ""], ["Oden", "Kevin", ""], ["Shah", "Julie", ""]]}, {"id": "2107.02943", "submitter": "Mahardhika Pratama Dr", "authors": "Mahardhika Pratama, Choiru Za'in, Edwin Lughofer, Eric Pardede, Dwi A.\n  P. Rahayu", "title": "Scalable Teacher Forcing Network for Semi-Supervised Large Scale Data\n  Streams", "comments": "This paper has been accepted for publication in Information Sciences", "journal-ref": "Information Sciences, 2021", "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The large-scale data stream problem refers to high-speed information flow\nwhich cannot be processed in scalable manner under a traditional computing\nplatform. This problem also imposes expensive labelling cost making the\ndeployment of fully supervised algorithms unfeasible. On the other hand, the\nproblem of semi-supervised large-scale data streams is little explored in the\nliterature because most works are designed in the traditional single-node\ncomputing environments while also being fully supervised approaches. This paper\noffers Weakly Supervised Scalable Teacher Forcing Network (WeScatterNet) to\ncope with the scarcity of labelled samples and the large-scale data streams\nsimultaneously. WeScatterNet is crafted under distributed computing platform of\nApache Spark with a data-free model fusion strategy for model compression after\nparallel computing stage. It features an open network structure to address the\nglobal and local drift problems while integrating a data augmentation,\nannotation and auto-correction ($DA^3$) method for handling partially labelled\ndata streams. The performance of WeScatterNet is numerically evaluated in the\nsix large-scale data stream problems with only $25\\%$ label proportions. It\nshows highly competitive performance even if compared with fully supervised\nlearners with $100\\%$ label proportions.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 03:37:40 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Pratama", "Mahardhika", ""], ["Za'in", "Choiru", ""], ["Lughofer", "Edwin", ""], ["Pardede", "Eric", ""], ["Rahayu", "Dwi A. P.", ""]]}, {"id": "2107.02955", "submitter": "Taehei Kim", "authors": "Taehei Kim, Sung-Hee Lee", "title": "Quadruped Locomotion on Non-Rigid Terrain using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Legged robots need to be capable of walking on diverse terrain conditions. In\nthis paper, we present a novel reinforcement learning framework for learning\nlocomotion on non-rigid dynamic terrains. Specifically, our framework can\ngenerate quadruped locomotion on flat elastic terrain that consists of a matrix\nof tiles moving up and down passively when pushed by the robot's feet. A\ntrained robot with 55cm base length can walk on terrain that can sink up to\n5cm. We propose a set of observation and reward terms that enable this\nlocomotion; in which we found that it is crucial to include the end-effector\nhistory and end-effector velocity terms into observation. We show the\neffectiveness of our method by training the robot with various terrain\nconditions.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 00:34:23 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kim", "Taehei", ""], ["Lee", "Sung-Hee", ""]]}, {"id": "2107.02974", "submitter": "Iury Cleveston", "authors": "Iury Cleveston, Esther L. Colombini", "title": "RAM-VO: Less is more in Visual Odometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Building vehicles capable of operating without human supervision requires the\ndetermination of the agent's pose. Visual Odometry (VO) algorithms estimate the\negomotion using only visual changes from the input images. The most recent VO\nmethods implement deep-learning techniques using convolutional neural networks\n(CNN) extensively, which add a substantial cost when dealing with\nhigh-resolution images. Furthermore, in VO tasks, more input data does not mean\na better prediction; on the contrary, the architecture may filter out useless\ninformation. Therefore, the implementation of computationally efficient and\nlightweight architectures is essential. In this work, we propose the RAM-VO, an\nextension of the Recurrent Attention Model (RAM) for visual odometry tasks.\nRAM-VO improves the visual and temporal representation of information and\nimplements the Proximal Policy Optimization (PPO) algorithm to learn robust\npolicies. The results indicate that RAM-VO can perform regressions with six\ndegrees of freedom from monocular input images using approximately 3 million\nparameters. In addition, experiments on the KITTI dataset demonstrate that\nRAM-VO achieves competitive results using only 5.7% of the available visual\ninformation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 01:48:16 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Cleveston", "Iury", ""], ["Colombini", "Esther L.", ""]]}, {"id": "2107.02975", "submitter": "Irene Li", "authors": "Irene Li, Jessica Pan, Jeremy Goldwasser, Neha Verma, Wai Pan Wong,\n  Muhammed Yavuz Nuzumlal{\\i}, Benjamin Rosand, Yixin Li, Matthew Zhang, David\n  Chang, R. Andrew Taylor, Harlan M. Krumholz and Dragomir Radev", "title": "Neural Natural Language Processing for Unstructured Data in Electronic\n  Health Records: a Review", "comments": "33 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health records (EHRs), digital collections of patient healthcare\nevents and observations, are ubiquitous in medicine and critical to healthcare\ndelivery, operations, and research. Despite this central role, EHRs are\nnotoriously difficult to process automatically. Well over half of the\ninformation stored within EHRs is in the form of unstructured text (e.g.\nprovider notes, operation reports) and remains largely untapped for secondary\nuse. Recently, however, newer neural network and deep learning approaches to\nNatural Language Processing (NLP) have made considerable advances,\noutperforming traditional statistical and rule-based systems on a variety of\ntasks. In this survey paper, we summarize current neural NLP methods for EHR\napplications. We focus on a broad scope of tasks, namely, classification and\nprediction, word embeddings, extraction, generation, and other topics such as\nquestion answering, phenotyping, knowledge graphs, medical dialogue,\nmultilinguality, interpretability, etc.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 01:50:02 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Li", "Irene", ""], ["Pan", "Jessica", ""], ["Goldwasser", "Jeremy", ""], ["Verma", "Neha", ""], ["Wong", "Wai Pan", ""], ["Nuzumlal\u0131", "Muhammed Yavuz", ""], ["Rosand", "Benjamin", ""], ["Li", "Yixin", ""], ["Zhang", "Matthew", ""], ["Chang", "David", ""], ["Taylor", "R. Andrew", ""], ["Krumholz", "Harlan M.", ""], ["Radev", "Dragomir", ""]]}, {"id": "2107.02978", "submitter": "Cedric Buche", "authors": "Antoine Dizet and C\\'edric Le Bono and Am\\'elie Legeleux and Ma\\\"elic\n  neau and C\\'edric Buche", "title": "RoboCup@Home Education 2020 Best Performance: RoboBreizh, a modular\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Every year, the Robocup@Home competition challenges teams and robots'\nabilities. In 2020, the RoboCup@Home Education challenge was organized online,\naltering the usual competition rules. In this paper, we present the latest\ndevelopments that lead the RoboBreizh team to win the contest. These\ndevelopments include several modules linked to each other allowing the Pepper\nrobot to understand, act and adapt itself to a local environment. Up-to-date\navailable technologies have been used for navigation and dialogue. First\ncontribution includes combining object detection and pose estimation techniques\nto detect user's intention. Second contribution involves using Learning by\nDemonstrations to easily learn new movements that improve the Pepper robot's\nskills. This proposal won the best performance award of the 2020 RoboCup@Home\nEducation challenge.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 02:09:37 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Dizet", "Antoine", ""], ["Bono", "C\u00e9dric Le", ""], ["Legeleux", "Am\u00e9lie", ""], ["neau", "Ma\u00eblic", ""], ["Buche", "C\u00e9dric", ""]]}, {"id": "2107.02988", "submitter": "Danfeng Hong", "authors": "Danfeng Hong and Zhu Han and Jing Yao and Lianru Gao and Bing Zhang\n  and Antonio Plaza and Jocelyn Chanussot", "title": "SpectralFormer: Rethinking Hyperspectral Image Classification with\n  Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hyperspectral (HS) images are characterized by approximately contiguous\nspectral information, enabling the fine identification of materials by\ncapturing subtle spectral discrepancies. Owing to their excellent locally\ncontextual modeling ability, convolutional neural networks (CNNs) have been\nproven to be a powerful feature extractor in HS image classification. However,\nCNNs fail to mine and represent the sequence attributes of spectral signatures\nwell due to the limitations of their inherent network backbone. To solve this\nissue, we rethink HS image classification from a sequential perspective with\ntransformers, and propose a novel backbone network called \\ul{SpectralFormer}.\nBeyond band-wise representations in classic transformers, SpectralFormer is\ncapable of learning spectrally local sequence information from neighboring\nbands of HS images, yielding group-wise spectral embeddings. More\nsignificantly, to reduce the possibility of losing valuable information in the\nlayer-wise propagation process, we devise a cross-layer skip connection to\nconvey memory-like components from shallow to deep layers by adaptively\nlearning to fuse \"soft\" residuals across layers. It is worth noting that the\nproposed SpectralFormer is a highly flexible backbone network, which can be\napplicable to both pixel- and patch-wise inputs. We evaluate the classification\nperformance of the proposed SpectralFormer on three HS datasets by conducting\nextensive experiments, showing the superiority over classic transformers and\nachieving a significant improvement in comparison with state-of-the-art\nbackbone networks. The codes of this work will be available at\n\\url{https://sites.google.com/view/danfeng-hong} for the sake of\nreproducibility.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 02:59:21 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Hong", "Danfeng", ""], ["Han", "Zhu", ""], ["Yao", "Jing", ""], ["Gao", "Lianru", ""], ["Zhang", "Bing", ""], ["Plaza", "Antonio", ""], ["Chanussot", "Jocelyn", ""]]}, {"id": "2107.02991", "submitter": "Jialin Liu Ph.D", "authors": "Ziqi Wang, Jialin Liu, Georgios N. Yannakakis", "title": "Keiki: Towards Realistic Danmaku Generation via Sequential GANs", "comments": "This paper is accepted by the 2021 IEEE Conference on Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search-based procedural content generation methods have recently been\nintroduced for the autonomous creation of bullet hell games. Search-based\nmethods, however, can hardly model patterns of danmakus -- the bullet hell\nshooting entity -- explicitly and the resulting levels often look\nnon-realistic. In this paper, we present a novel bullet hell game platform\nnamed Keiki, which allows the representation of danmakus as a parametric\nsequence which, in turn, can model the sequential behaviours of danmakus. We\nemploy three types of generative adversarial networks (GANs) and test Keiki\nacross three metrics designed to quantify the quality of the generated\ndanmakus. The time-series GAN and periodic spatial GAN show different yet\ncompetitive performance in terms of the evaluation metrics adopted, their\ndeviation from human-designed danmakus, and the diversity of generated\ndanmakus. The preliminary experimental studies presented here showcase that\npotential of time-series GANs for sequential content generation in games.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 03:11:04 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Wang", "Ziqi", ""], ["Liu", "Jialin", ""], ["Yannakakis", "Georgios N.", ""]]}, {"id": "2107.03003", "submitter": "Kai Wang", "authors": "Kai Wang, Bryan Wilder, Sze-chuan Suen, Bistra Dilkina, Milind Tambe", "title": "Harnessing Heterogeneity: Learning from Decomposed Feedback in Bayesian\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is significant interest in learning and optimizing a complex system\ncomposed of multiple sub-components, where these components may be agents or\nautonomous sensors. Among the rich literature on this topic, agent-based and\ndomain-specific simulations can capture complex dynamics and subgroup\ninteraction, but optimizing over such simulations can be computationally and\nalgorithmically challenging. Bayesian approaches, such as Gaussian processes\n(GPs), can be used to learn a computationally tractable approximation to the\nunderlying dynamics but typically neglect the detailed information about\nsubgroups in the complicated system. We attempt to find the best of both worlds\nby proposing the idea of decomposed feedback, which captures group-based\nheterogeneity and dynamics. We introduce a novel decomposed GP regression to\nincorporate the subgroup decomposed feedback. Our modified regression has\nprovably lower variance -- and thus a more accurate posterior -- compared to\nprevious approaches; it also allows us to introduce a decomposed GP-UCB\noptimization algorithm that leverages subgroup feedback. The Bayesian nature of\nour method makes the optimization algorithm trackable with a theoretical\nguarantee on convergence and no-regret property. To demonstrate the wide\napplicability of this work, we execute our algorithm on two disparate social\nproblems: infectious disease control in a heterogeneous population and\nallocation of distributed weather sensors. Experimental results show that our\nnew method provides significant improvement compared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 03:57:22 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Wang", "Kai", ""], ["Wilder", "Bryan", ""], ["Suen", "Sze-chuan", ""], ["Dilkina", "Bistra", ""], ["Tambe", "Milind", ""]]}, {"id": "2107.03006", "submitter": "Jacob Austin", "authors": "Jacob Austin, Daniel D. Johnson, Jonathan Ho, Daniel Tarlow and Rianne\n  van den Berg", "title": "Structured Denoising Diffusion Models in Discrete State-Spaces", "comments": "10 pages plus references and appendices. First two authors\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Denoising diffusion probabilistic models (DDPMs) (Ho et al. 2020) have shown\nimpressive results on image and waveform generation in continuous state spaces.\nHere, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs),\ndiffusion-like generative models for discrete data that generalize the\nmultinomial diffusion model of Hoogeboom et al. 2021, by going beyond\ncorruption processes with uniform transition probabilities. This includes\ncorruption with transition matrices that mimic Gaussian kernels in continuous\nspace, matrices based on nearest neighbors in embedding space, and matrices\nthat introduce absorbing states. The third allows us to draw a connection\nbetween diffusion models and autoregressive and mask-based generative models.\nWe show that the choice of transition matrix is an important design decision\nthat leads to improved results in image and text domains. We also introduce a\nnew loss function that combines the variational lower bound with an auxiliary\ncross entropy loss. For text, this model class achieves strong results on\ncharacter-level text generation while scaling to large vocabularies on LM1B. On\nthe image dataset CIFAR-10, our models approach the sample quality and exceed\nthe log-likelihood of the continuous-space DDPM model.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 04:11:00 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 17:09:20 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Austin", "Jacob", ""], ["Johnson", "Daniel D.", ""], ["Ho", "Jonathan", ""], ["Tarlow", "Daniel", ""], ["Berg", "Rianne van den", ""]]}, {"id": "2107.03015", "submitter": "Juan Jose Garau-Luis", "authors": "Juan Jose Garau-Luis and Edward Crawley and Bruce Cameron", "title": "Evaluating the progress of Deep Reinforcement Learning in the real\n  world: aligning domain-agnostic and domain-specific research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep Reinforcement Learning (DRL) is considered a potential framework to\nimprove many real-world autonomous systems; it has attracted the attention of\nmultiple and diverse fields. Nevertheless, the successful deployment in the\nreal world is a test most of DRL models still need to pass. In this work we\nfocus on this issue by reviewing and evaluating the research efforts from both\ndomain-agnostic and domain-specific communities. On one hand, we offer a\ncomprehensive summary of DRL challenges and summarize the different proposals\nto mitigate them; this helps identifying five gaps of domain-agnostic research.\nOn the other hand, from the domain-specific perspective, we discuss different\nsuccess stories and argue why other models might fail to be deployed. Finally,\nwe take up on ways to move forward accounting for both perspectives.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 04:45:46 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Garau-Luis", "Juan Jose", ""], ["Crawley", "Edward", ""], ["Cameron", "Bruce", ""]]}, {"id": "2107.03018", "submitter": "Shouta Sugahara", "authors": "Shouta Sugahara and Maomi Ueno", "title": "Exact Learning Augmented Naive Bayes Classifier", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Earlier studies have shown that classification accuracies of Bayesian\nnetworks (BNs) obtained by maximizing the conditional log likelihood (CLL) of a\nclass variable, given the feature variables, were higher than those obtained by\nmaximizing the marginal likelihood (ML). However, differences between the\nperformances of the two scores in the earlier studies may be attributed to the\nfact that they used approximate learning algorithms, not exact ones. This paper\ncompares the classification accuracies of BNs with approximate learning using\nCLL to those with exact learning using ML. The results demonstrate that the\nclassification accuracies of BNs obtained by maximizing the ML are higher than\nthose obtained by maximizing the CLL for large data. However, the results also\ndemonstrate that the classification accuracies of exact learning BNs using the\nML are much worse than those of other methods when the sample size is small and\nthe class variable has numerous parents. To resolve the problem, we propose an\nexact learning augmented naive Bayes classifier (ANB), which ensures a class\nvariable with no parents. The proposed method is guaranteed to asymptotically\nestimate the identical class posterior to that of the exactly learned BN.\nComparison experiments demonstrated the superior performance of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 05:03:42 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Sugahara", "Shouta", ""], ["Ueno", "Maomi", ""]]}, {"id": "2107.03019", "submitter": "Xin Zhou", "authors": "Xin Zhou, Aixin Sun, Yong Liu, Jie Zhang, Chunyan Miao", "title": "SelfCF: A Simple Framework for Self-supervised Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Collaborative filtering (CF) is widely used to learn an informative latent\nrepresentation of a user or item from observed interactions. Existing CF-based\nmethods commonly adopt negative sampling to discriminate different items. That\nis, observed user-item pairs are treated as positive instances; unobserved\npairs are considered as negative instances and are sampled under a defined\ndistribution for training. Training with negative sampling on large datasets is\ncomputationally expensive. Further, negative items should be carefully sampled\nunder the defined distribution, in order to avoid selecting an observed\npositive item in the training dataset. Unavoidably, some negative items sampled\nfrom the training dataset could be positive in the test set. Recently,\nself-supervised learning (SSL) has emerged as a powerful tool to learn a model\nwithout negative samples. In this paper, we propose a self-supervised\ncollaborative filtering framework (SelfCF), that is specially designed for\nrecommender scenario with implicit feedback. The main idea of SelfCF is to\naugment the output embeddings generated by backbone networks, because it is\ninfeasible to augment raw input of user/item ids. We propose and study three\noutput perturbation techniques that can be applied to different types of\nbackbone networks including both traditional CF models and graph-based models.\nBy encapsulating two popular recommendation models into the framework, our\nexperiments on three datasets show that the best performance of our framework\nis comparable or better than the supervised counterpart. We also show that\nSelfCF can boost up the performance by up to 8.93\\% on average, compared with\nanother self-supervised framework as the baseline. Source codes are available\nat: https://github.com/enoche/SelfCF.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 05:21:12 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Zhou", "Xin", ""], ["Sun", "Aixin", ""], ["Liu", "Yong", ""], ["Zhang", "Jie", ""], ["Miao", "Chunyan", ""]]}, {"id": "2107.03030", "submitter": "Hu Chen Dr.", "authors": "Hu Chen, Hong Li, Bifu Hu, Kenan Ma, Yuchun Sun", "title": "A convolutional neural network for teeth margin detection on\n  3-dimensional dental meshes", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We proposed a convolutional neural network for vertex classification on\n3-dimensional dental meshes, and used it to detect teeth margins. An expanding\nlayer was constructed to collect statistic values of neighbor vertex features\nand compute new features for each vertex with convolutional neural networks. An\nend-to-end neural network was proposed to take vertex features, including\ncoordinates, curvatures and distance, as input and output each vertex\nclassification label. Several network structures with different parameters of\nexpanding layers and a base line network without expanding layers were designed\nand trained by 1156 dental meshes. The accuracy, recall and precision were\nvalidated on 145 dental meshes to rate the best network structures, which were\nfinally tested on another 144 dental meshes. All networks with our expanding\nlayers performed better than baseline, and the best one achieved an accuracy of\n0.877 both on validation dataset and test dataset.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 06:16:17 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Chen", "Hu", ""], ["Li", "Hong", ""], ["Hu", "Bifu", ""], ["Ma", "Kenan", ""], ["Sun", "Yuchun", ""]]}, {"id": "2107.03054", "submitter": "Xueyuan Lin", "authors": "Xueyuan Lin, Haihong E, Wenyu Song, Haoran Luo", "title": "EchoEA: Echo Information between Entities and Relations for Entity\n  Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity alignment (EA) is to discover entities referring to the same object in\nthe real world from different knowledge graphs (KGs). It plays an important\nrole in automatically integrating KGs from multiple sources.\n  Existing knowledge graph embedding (KGE) methods based on Graph Neural\nNetworks (GNNs) have achieved promising results, which enhance entity\nrepresentation with relation information unidirectionally. Besides, more and\nmore methods introduce semi-supervision to ask for more labeled training data.\n  However, two challenges still exist in these methods: (1) Insufficient\ninteraction: The interaction between entities and relations is insufficiently\nutilized. (2) Low-quality bootstrapping: The generated semi-supervised data is\nof low quality.\n  In this paper, we propose a novel framework, Echo Entity Alignment (EchoEA),\nwhich leverages self-attention mechanism to spread entity information to\nrelations and echo back to entities. The relation representation is dynamically\ncomputed from entity representation. Symmetrically, the next entity\nrepresentation is dynamically calculated from relation representation, which\nshows sufficient interaction.\n  Furthermore, we propose attribute-combined bi-directional global-filtered\nstrategy (ABGS) to improve bootstrapping, reduce false samples and generate\nhigh-quality training data.\n  The experimental results on three real-world cross-lingual datasets are\nstable at around 96\\% at hits@1 on average, showing that our approach not only\nsignificantly outperforms the state-of-the-art methods, but also is universal\nand transferable for existing KGE methods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 07:34:21 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Lin", "Xueyuan", ""], ["E", "Haihong", ""], ["Song", "Wenyu", ""], ["Luo", "Haoran", ""]]}, {"id": "2107.03072", "submitter": "Sevil Sen", "authors": "Sevil Sen and Burcu Can", "title": "Android Security using NLP Techniques: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android is among the most targeted platform by attackers. While attackers are\nimproving their techniques, traditional solutions based on static and dynamic\nanalysis have been also evolving. In addition to the application code, Android\napplications have some metadata that could be useful for security analysis of\napplications. Unlike traditional application distribution mechanisms, Android\napplications are distributed centrally in mobile markets. Therefore, beside\napplication packages, such markets contain app information provided by app\ndevelopers and app users. The availability of such useful textual data together\nwith the advancement in Natural Language Processing (NLP) that is used to\nprocess and understand textual data has encouraged researchers to investigate\nthe use of NLP techniques in Android security. Especially, security solutions\nbased on NLP have accelerated in the last 5 years and proven to be useful. This\nstudy reviews these proposals and aim to explore possible research directions\nfor future studies by presenting state-of-the-art in this domain. We mainly\nfocus on NLP-based solutions under four categories: description-to-behaviour\nfidelity, description generation, privacy and malware detection.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 08:33:00 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Sen", "Sevil", ""], ["Can", "Burcu", ""]]}, {"id": "2107.03088", "submitter": "Peidong Liu", "authors": "Peidong Liu, Zibin He, Xiyu Yan, Yong Jiang, Shutao Xia, Feng Zheng,\n  Maowei Hu", "title": "WeClick: Weakly-Supervised Video Semantic Segmentation with Click\n  Annotations", "comments": "Accepted by ACM MM2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared with tedious per-pixel mask annotating, it is much easier to\nannotate data by clicks, which costs only several seconds for an image.\nHowever, applying clicks to learn video semantic segmentation model has not\nbeen explored before. In this work, we propose an effective weakly-supervised\nvideo semantic segmentation pipeline with click annotations, called WeClick,\nfor saving laborious annotating effort by segmenting an instance of the\nsemantic class with only a single click. Since detailed semantic information is\nnot captured by clicks, directly training with click labels leads to poor\nsegmentation predictions. To mitigate this problem, we design a novel memory\nflow knowledge distillation strategy to exploit temporal information (named\nmemory flow) in abundant unlabeled video frames, by distilling the neighboring\npredictions to the target frame via estimated motion. Moreover, we adopt\nvanilla knowledge distillation for model compression. In this case, WeClick\nlearns compact video semantic segmentation models with the low-cost click\nannotations during the training phase yet achieves real-time and accurate\nmodels during the inference period. Experimental results on Cityscapes and\nCamvid show that WeClick outperforms the state-of-the-art methods, increases\nperformance by 10.24% mIoU than baseline, and achieves real-time execution.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 09:12:46 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Liu", "Peidong", ""], ["He", "Zibin", ""], ["Yan", "Xiyu", ""], ["Jiang", "Yong", ""], ["Xia", "Shutao", ""], ["Zheng", "Feng", ""], ["Hu", "Maowei", ""]]}, {"id": "2107.03090", "submitter": "Bhavya Kalra", "authors": "Bhavya Kalra, Kulin Shah and Naresh Manwani", "title": "RISAN: Robust Instance Specific Abstention Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose deep architectures for learning instance specific\nabstain (reject option) binary classifiers. The proposed approach uses double\nsigmoid loss function as described by Kulin Shah and Naresh Manwani in (\"Online\nActive Learning of Reject Option Classifiers\", AAAI, 2020), as a performance\nmeasure. We show that the double sigmoid loss is classification calibrated. We\nalso show that the excess risk of 0-d-1 loss is upper bounded by the excess\nrisk of double sigmoid loss. We derive the generalization error bounds for the\nproposed architecture for reject option classifiers. To show the effectiveness\nof the proposed approach, we experiment with several real world datasets. We\nobserve that the proposed approach not only performs comparable to the\nstate-of-the-art approaches, it is also robust against label noise. We also\nprovide visualizations to observe the important features learned by the network\ncorresponding to the abstaining decision.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 09:14:54 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kalra", "Bhavya", ""], ["Shah", "Kulin", ""], ["Manwani", "Naresh", ""]]}, {"id": "2107.03096", "submitter": "Cheng Liu", "authors": "Dawen Xu, Meng He, Cheng Liu, Ying Wang, Long Cheng, Huawei Li,\n  Xiaowei Li, Kwang-Ting Cheng", "title": "R2F: A Remote Retraining Framework for AIoT Processors with Computing\n  Errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AIoT processors fabricated with newer technology nodes suffer rising soft\nerrors due to the shrinking transistor sizes and lower power supply. Soft\nerrors on the AIoT processors particularly the deep learning accelerators\n(DLAs) with massive computing may cause substantial computing errors. These\ncomputing errors are difficult to be captured by the conventional training on\ngeneral purposed processors like CPUs and GPUs in a server. Applying the\noffline trained neural network models to the edge accelerators with errors\ndirectly may lead to considerable prediction accuracy loss.\n  To address the problem, we propose a remote retraining framework (R2F) for\nremote AIoT processors with computing errors. It takes the remote AIoT\nprocessor with soft errors in the training loop such that the on-site computing\nerrors can be learned with the application data on the server and the retrained\nmodels can be resilient to the soft errors. Meanwhile, we propose an optimized\npartial TMR strategy to enhance the retraining. According to our experiments,\nR2F enables elastic design trade-offs between the model accuracy and the\nperformance penalty. The top-5 model accuracy can be improved by 1.93%-13.73%\nwith 0%-200% performance penalty at high fault error rate. In addition, we\nnotice that the retraining requires massive data transmission and even\ndominates the training time, and propose a sparse increment compression\napproach for the data transmission optimization, which reduces the retraining\ntime by 38%-88% on average with negligible accuracy loss over a straightforward\nremote retraining.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 09:28:30 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Xu", "Dawen", ""], ["He", "Meng", ""], ["Liu", "Cheng", ""], ["Wang", "Ying", ""], ["Cheng", "Long", ""], ["Li", "Huawei", ""], ["Li", "Xiaowei", ""], ["Cheng", "Kwang-Ting", ""]]}, {"id": "2107.03144", "submitter": "Parnian Kassraie", "authors": "Parnian Kassraie, Andreas Krause", "title": "Neural Contextual Bandits without Regret", "comments": "37 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Contextual bandits are a rich model for sequential decision making given side\ninformation, with important applications, e.g., in recommender systems. We\npropose novel algorithms for contextual bandits harnessing neural networks to\napproximate the unknown reward function. We resolve the open problem of proving\nsublinear regret bounds in this setting for general context sequences,\nconsidering both fully-connected and convolutional networks. To this end, we\nfirst analyze NTK-UCB, a kernelized bandit optimization algorithm employing the\nNeural Tangent Kernel (NTK), and bound its regret in terms of the NTK maximum\ninformation gain $\\gamma_T$, a complexity parameter capturing the difficulty of\nlearning. Our bounds on $\\gamma_T$ for the NTK may be of independent interest.\nWe then introduce our neural network based algorithm NN-UCB, and show that its\nregret closely tracks that of NTK-UCB. Under broad non-parametric assumptions\nabout the reward function, our approach converges to the optimal policy at a\n$\\tilde{\\mathcal{O}}(T^{-1/2d})$ rate, where $d$ is the dimension of the\ncontext.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 11:11:34 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kassraie", "Parnian", ""], ["Krause", "Andreas", ""]]}, {"id": "2107.03158", "submitter": "Markus Bayer", "authors": "Markus Bayer, Marc-Andr\\'e Kaufhold, Christian Reuter", "title": "A Survey on Data Augmentation for Text Classification", "comments": "35 pages, 6 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation, the artificial creation of training data for machine\nlearning by transformations, is a widely studied research field across machine\nlearning disciplines. While it is useful for increasing the generalization\ncapabilities of a model, it can also address many other challenges and\nproblems, from overcoming a limited amount of training data over regularizing\nthe objective to limiting the amount data used to protect privacy. Based on a\nprecise description of the goals and applications of data augmentation (C1) and\na taxonomy for existing works (C2), this survey is concerned with data\naugmentation methods for textual classification and aims to achieve a concise\nand comprehensive overview for researchers and practitioners (C3). Derived from\nthe taxonomy, we divided more than 100 methods into 12 different groupings and\nprovide state-of-the-art references expounding which methods are highly\npromising (C4). Finally, research perspectives that may constitute a building\nblock for future work are given (C5).\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 11:37:03 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 12:46:29 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bayer", "Markus", ""], ["Kaufhold", "Marc-Andr\u00e9", ""], ["Reuter", "Christian", ""]]}, {"id": "2107.03178", "submitter": "Francisco Cruz", "authors": "Richard Dazeley, Peter Vamplew, Cameron Foale, Charlotte Young, Sunil\n  Aryal, Francisco Cruz", "title": "Levels of explainable artificial intelligence for human-aligned\n  conversational explanations", "comments": "35 pages, 13 figures", "journal-ref": "Artificial Intelligence, 299, 103525 (2021)", "doi": "10.1016/j.artint.2021.103525", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Over the last few years there has been rapid research growth into eXplainable\nArtificial Intelligence (XAI) and the closely aligned Interpretable Machine\nLearning (IML). Drivers for this growth include recent legislative changes and\nincreased investments by industry and governments, along with increased concern\nfrom the general public. People are affected by autonomous decisions every day\nand the public need to understand the decision-making process to accept the\noutcomes. However, the vast majority of the applications of XAI/IML are focused\non providing low-level `narrow' explanations of how an individual decision was\nreached based on a particular datum. While important, these explanations rarely\nprovide insights into an agent's: beliefs and motivations; hypotheses of other\n(human, animal or AI) agents' intentions; interpretation of external cultural\nexpectations; or, processes used to generate its own explanation. Yet all of\nthese factors, we propose, are essential to providing the explanatory depth\nthat people require to accept and trust the AI's decision-making. This paper\naims to define levels of explanation and describe how they can be integrated to\ncreate a human-aligned conversational explanation system. In so doing, this\npaper will survey current approaches and discuss the integration of different\ntechnologies to achieve these levels with Broad eXplainable Artificial\nIntelligence (Broad-XAI), and thereby move towards high-level `strong'\nexplanations.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 12:19:16 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Dazeley", "Richard", ""], ["Vamplew", "Peter", ""], ["Foale", "Cameron", ""], ["Young", "Charlotte", ""], ["Aryal", "Sunil", ""], ["Cruz", "Francisco", ""]]}, {"id": "2107.03182", "submitter": "Mahdi Maktabdar Oghaz", "authors": "Emily Waters, Mahdi Maktabdar Oghaz, Lakshmi Babu Saheer", "title": "Urban Tree Species Classification Using Aerial Imagery", "comments": "International Conference on Machine Learning (ICML 2021), Workshop on\n  Tackling Climate Change with Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Urban trees help regulate temperature, reduce energy consumption, improve\nurban air quality, reduce wind speeds, and mitigating the urban heat island\neffect. Urban trees also play a key role in climate change mitigation and\nglobal warming by capturing and storing atmospheric carbon-dioxide which is the\nlargest contributor to greenhouse gases. Automated tree detection and species\nclassification using aerial imagery can be a powerful tool for sustainable\nforest and urban tree management. Hence, This study first offers a pipeline for\ngenerating labelled dataset of urban trees using Google Map's aerial images and\nthen investigates how state of the art deep Convolutional Neural Network models\nsuch as VGG and ResNet handle the classification problem of urban tree aerial\nimages under different parameters. Experimental results show our best model\nachieves an average accuracy of 60% over 6 tree species.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 12:30:22 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Waters", "Emily", ""], ["Oghaz", "Mahdi Maktabdar", ""], ["Saheer", "Lakshmi Babu", ""]]}, {"id": "2107.03187", "submitter": "Koushik Biswas", "authors": "Koushik Biswas, Sandeep Kumar, Ashish Kumar Pandey", "title": "Intensity Prediction of Tropical Cyclones using Long Short-Term Memory\n  Network", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tropical cyclones can be of varied intensity and cause a huge loss of lives\nand property if the intensity is high enough. Therefore, the prediction of the\nintensity of tropical cyclones advance in time is of utmost importance. We\npropose a novel stacked bidirectional long short-term memory network (BiLSTM)\nbased model architecture to predict the intensity of a tropical cyclone in\nterms of Maximum surface sustained wind speed (MSWS). The proposed model can\npredict MSWS well advance in time (up to 72 h) with very high accuracy. We have\napplied the model on tropical cyclones in the North Indian Ocean from 1982 to\n2018 and checked its performance on two recent tropical cyclones, namely, Fani\nand Vayu. The model predicts MSWS (in knots) for the next 3, 12, 24, 36, 48,\n60, and 72 hours with a mean absolute error of 1.52, 3.66, 5.88, 7.42, 8.96,\n10.15, and 11.92, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 12:46:50 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Biswas", "Koushik", ""], ["Kumar", "Sandeep", ""], ["Pandey", "Ashish Kumar", ""]]}, {"id": "2107.03190", "submitter": "Juan Correa", "authors": "Juan D Correa, Sanghack Lee, Elias Bareinboim", "title": "Nested Counterfactual Identification from Arbitrary Surrogate\n  Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Ladder of Causation describes three qualitatively different types of\nactivities an agent may be interested in engaging in, namely, seeing\n(observational), doing (interventional), and imagining (counterfactual) (Pearl\nand Mackenzie, 2018). The inferential challenge imposed by the causal hierarchy\nis that data is collected by an agent observing or intervening in a system\n(layers 1 and 2), while its goal may be to understand what would have happened\nhad it taken a different course of action, contrary to what factually ended up\nhappening (layer 3). While there exists a solid understanding of the conditions\nunder which cross-layer inferences are allowed from observations to\ninterventions, the results are somewhat scarcer when targeting counterfactual\nquantities. In this paper, we study the identification of nested\ncounterfactuals from an arbitrary combination of observations and experiments.\nSpecifically, building on a more explicit definition of nested counterfactuals,\nwe prove the counterfactual unnesting theorem (CUT), which allows one to map\narbitrary nested counterfactuals to unnested ones. For instance, applications\nin mediation and fairness analysis usually evoke notions of direct, indirect,\nand spurious effects, which naturally require nesting. Second, we introduce a\nsufficient and necessary graphical condition for counterfactual identification\nfrom an arbitrary combination of observational and experimental distributions.\nLastly, we develop an efficient and complete algorithm for identifying nested\ncounterfactuals; failure of the algorithm returning an expression for a query\nimplies it is not identifiable.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 12:51:04 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Correa", "Juan D", ""], ["Lee", "Sanghack", ""], ["Bareinboim", "Elias", ""]]}, {"id": "2107.03212", "submitter": "Lu Yin", "authors": "Lu Yin, Vlado Menkovski, Shiwei Liu, Mykola Pechenizkiy", "title": "Hierarchical Semantic Segmentation using Psychometric Learning", "comments": "17 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assigning meaning to parts of image data is the goal of semantic image\nsegmentation. Machine learning methods, specifically supervised learning is\ncommonly used in a variety of tasks formulated as semantic segmentation. One of\nthe major challenges in the supervised learning approaches is expressing and\ncollecting the rich knowledge that experts have with respect to the meaning\npresent in the image data. Towards this, typically a fixed set of labels is\nspecified and experts are tasked with annotating the pixels, patches or\nsegments in the images with the given labels. In general, however, the set of\nclasses does not fully capture the rich semantic information present in the\nimages. For example, in medical imaging such as histology images, the different\nparts of cells could be grouped and sub-grouped based on the expertise of the\npathologist.\n  To achieve such a precise semantic representation of the concepts in the\nimage, we need access to the full depth of knowledge of the annotator. In this\nwork, we develop a novel approach to collect segmentation annotations from\nexperts based on psychometric testing. Our method consists of the psychometric\ntesting procedure, active query selection, query enhancement, and a deep metric\nlearning model to achieve a patch-level image embedding that allows for\nsemantic segmentation of images. We show the merits of our method with\nevaluation on the synthetically generated image, aerial image and histology\nimage.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 13:38:33 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Yin", "Lu", ""], ["Menkovski", "Vlado", ""], ["Liu", "Shiwei", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2107.03226", "submitter": "Andres Carvallo", "authors": "Iv\\'an Cantador, Andr\\'es Carvallo, Fernando Diez, Denis Parra", "title": "Graphing else matters: exploiting aspect opinions and ratings in\n  explainable graph-based recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG cs.SI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The success of neural network embeddings has entailed a renewed interest in\nusing knowledge graphs for a wide variety of machine learning and information\nretrieval tasks. In particular, current recommendation methods based on graph\nembeddings have shown state-of-the-art performance. These methods commonly\nencode latent rating patterns and content features. Different from previous\nwork, in this paper, we propose to exploit embeddings extracted from graphs\nthat combine information from ratings and aspect-based opinions expressed in\ntextual reviews. We then adapt and evaluate state-of-the-art graph embedding\ntechniques over graphs generated from Amazon and Yelp reviews on six domains,\noutperforming baseline recommenders. Our approach has the advantage of\nproviding explanations which leverage aspect-based opinions given by users\nabout recommended items. Furthermore, we also provide examples of the\napplicability of recommendations utilizing aspect opinions as explanations in a\nvisualization dashboard, which allows obtaining information about the most and\nleast liked aspects of similar users obtained from the embeddings of an input\ngraph.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 13:57:28 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Cantador", "Iv\u00e1n", ""], ["Carvallo", "Andr\u00e9s", ""], ["Diez", "Fernando", ""], ["Parra", "Denis", ""]]}, {"id": "2107.03227", "submitter": "Deep Patel", "authors": "Deep Patel, Erin Gao, Anirudh Koul, Siddha Ganju, Meher Anand Kasam", "title": "Scalable Data Balancing for Unlabeled Satellite Imagery", "comments": "Accepted to COSPAR 2021 Workshop on Machine Learning for Space\n  Sciences. 5 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data imbalance is a ubiquitous problem in machine learning. In large scale\ncollected and annotated datasets, data imbalance is either mitigated manually\nby undersampling frequent classes and oversampling rare classes, or planned for\nwith imputation and augmentation techniques. In both cases balancing data\nrequires labels. In other words, only annotated data can be balanced.\nCollecting fully annotated datasets is challenging, especially for large scale\nsatellite systems such as the unlabeled NASA's 35 PB Earth Imagery dataset.\nAlthough the NASA Earth Imagery dataset is unlabeled, there are implicit\nproperties of the data source that we can rely on to hypothesize about its\nimbalance, such as distribution of land and water in the case of the Earth's\nimagery. We present a new iterative method to balance unlabeled data. Our\nmethod utilizes image embeddings as a proxy for image labels that can be used\nto balance data, and ultimately when trained increases overall accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 13:58:15 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Patel", "Deep", ""], ["Gao", "Erin", ""], ["Koul", "Anirudh", ""], ["Ganju", "Siddha", ""], ["Kasam", "Meher Anand", ""]]}, {"id": "2107.03265", "submitter": "AnneMarie Borg", "authors": "AnneMarie Borg and Floris Bex", "title": "Contrastive Explanations for Argumentation-Based Conclusions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we discuss contrastive explanations for formal argumentation -\nthe question why a certain argument (the fact) can be accepted, whilst another\nargument (the foil) cannot be accepted under various extension-based semantics.\nThe recent work on explanations for argumentation-based conclusions has mostly\nfocused on providing minimal explanations for the (non-)acceptance of\narguments. What is still lacking, however, is a proper argumentation-based\ninterpretation of contrastive explanations. We show under which conditions\ncontrastive explanations in abstract and structured argumentation are\nmeaningful, and how argumentation allows us to make implicit foils explicit.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:00:47 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Borg", "AnneMarie", ""], ["Bex", "Floris", ""]]}, {"id": "2107.03279", "submitter": "Omar Vidal Pino", "authors": "Omar Vidal Pino, Erickson Rangel Nascimento, Mario Fernando Montenegro\n  Campos", "title": "Introducing the structural bases of typicality effects in deep learning", "comments": "14 pages (12 + 2 reference); 13 Figures and 2 Tables. arXiv admin\n  note: text overlap with arXiv:1906.03365", "journal-ref": null, "doi": "10.1016/j.imavis.2021.104249", "report-no": null, "categories": "cs.CV cs.AI math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we hypothesize that the effects of the degree of typicality in\nnatural semantic categories can be generated based on the structure of\nartificial categories learned with deep learning models. Motivated by the human\napproach to representing natural semantic categories and based on the Prototype\nTheory foundations, we propose a novel Computational Prototype Model (CPM) to\nrepresent the internal structure of semantic categories. Unlike other prototype\nlearning approaches, our mathematical framework proposes a first approach to\nprovide deep neural networks with the ability to model abstract semantic\nconcepts such as category central semantic meaning, typicality degree of an\nobject's image, and family resemblance relationship. We proposed several\nmethodologies based on the typicality's concept to evaluate our CPM-model in\nimage semantic processing tasks such as image classification, a global semantic\ndescription, and transfer learning. Our experiments on different image\ndatasets, such as ImageNet and Coco, showed that our approach might be an\nadmissible proposition in the effort to endow machines with greater power of\nabstraction for the semantic representation of objects' categories.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:15:43 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Pino", "Omar Vidal", ""], ["Nascimento", "Erickson Rangel", ""], ["Campos", "Mario Fernando Montenegro", ""]]}, {"id": "2107.03287", "submitter": "Richard Mayr", "authors": "Richard Mayr, Eric Munday", "title": "Strategy Complexity of Mean Payoff, Total Payoff and Point Payoff\n  Objectives in Countable MDPs", "comments": "Full version of a conference paper at CONCUR 2021. 41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study countably infinite Markov decision processes (MDPs) with real-valued\ntransition rewards. Every infinite run induces the following sequences of\npayoffs: 1. Point payoff (the sequence of directly seen transition rewards), 2.\nTotal payoff (the sequence of the sums of all rewards so far), and 3. Mean\npayoff. For each payoff type, the objective is to maximize the probability that\nthe $\\liminf$ is non-negative. We establish the complete picture of the\nstrategy complexity of these objectives, i.e., how much memory is necessary and\nsufficient for $\\varepsilon$-optimal (resp. optimal) strategies. Some cases can\nbe won with memoryless deterministic strategies, while others require a step\ncounter, a reward counter, or both.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 21:13:39 GMT"}, {"version": "v2", "created": "Sat, 10 Jul 2021 18:43:45 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Mayr", "Richard", ""], ["Munday", "Eric", ""]]}, {"id": "2107.03288", "submitter": "Qian Hu", "authors": "Qian Hu, Keyun Qin", "title": "Attribute reduction and rule acquisition of formal decision context\n  based on two new kinds of decision rules", "comments": "20 pages, 3figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper mainly studies the rule acquisition and attribute reduction for\nformal decision context based on two new kinds of decision rules, namely\nI-decision rules and II-decision rules. The premises of these rules are\nobject-oriented concepts, and the conclusions are formal concept and\nproperty-oriented concept respectively. The rule acquisition algorithms for\nI-decision rules and II-decision rules are presented. Some comparative analysis\nof these algorithms with the existing algorithms are examined which shows that\nthe algorithms presented in this study behave well. The attribute reduction\napproaches to preserve I-decision rules and II-decision rules are presented by\nusing discernibility matrix.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 02:55:24 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Hu", "Qian", ""], ["Qin", "Keyun", ""]]}, {"id": "2107.03297", "submitter": "Angelo Salatino Dr", "authors": "Mojtaba Nayyeri, Gokce Muge Cil, Sahar Vahdati, Francesco Osborne,\n  Mahfuzur Rahman, Simone Angioni, Angelo Salatino, Diego Reforgiato Recupero,\n  Nadezhda Vassilyeva, Enrico Motta, Jens Lehmann", "title": "Trans4E: Link Prediction on Scholarly Knowledge Graphs", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2021.02.100", "report-no": null, "categories": "cs.AI cs.CL cs.DL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The incompleteness of Knowledge Graphs (KGs) is a crucial issue affecting the\nquality of AI-based services. In the scholarly domain, KGs describing research\npublications typically lack important information, hindering our ability to\nanalyse and predict research dynamics. In recent years, link prediction\napproaches based on Knowledge Graph Embedding models became the first aid for\nthis issue. In this work, we present Trans4E, a novel embedding model that is\nparticularly fit for KGs which include N to M relations with N$\\gg$M. This is\ntypical for KGs that categorize a large number of entities (e.g., research\narticles, patents, persons) according to a relatively small set of categories.\nTrans4E was applied on two large-scale knowledge graphs, the Academia/Industry\nDynAmics (AIDA) and Microsoft Academic Graph (MAG), for completing the\ninformation about Fields of Study (e.g., 'neural networks', 'machine learning',\n'artificial intelligence'), and affiliation types (e.g., 'education',\n'company', 'government'), improving the scope and accuracy of the resulting\ndata. We evaluated our approach against alternative solutions on AIDA, MAG, and\nfour other benchmarks (FB15k, FB15k-237, WN18, and WN18RR). Trans4E outperforms\nthe other models when using low embedding dimensions and obtains competitive\nresults in high dimensions.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 09:34:44 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Nayyeri", "Mojtaba", ""], ["Cil", "Gokce Muge", ""], ["Vahdati", "Sahar", ""], ["Osborne", "Francesco", ""], ["Rahman", "Mahfuzur", ""], ["Angioni", "Simone", ""], ["Salatino", "Angelo", ""], ["Recupero", "Diego Reforgiato", ""], ["Vassilyeva", "Nadezhda", ""], ["Motta", "Enrico", ""], ["Lehmann", "Jens", ""]]}, {"id": "2107.03305", "submitter": "Jeppe Theiss Kristensen", "authors": "Jeppe Theiss Kristensen, Arturo Valdivia, Paolo Burelli", "title": "Statistical Modelling of Level Difficulty in Puzzle Games", "comments": "Conference on Games 2021 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Successful and accurate modelling of level difficulty is a fundamental\ncomponent of the operationalisation of player experience as difficulty is one\nof the most important and commonly used signals for content design and\nadaptation. In games that feature intermediate milestones, such as completable\nareas or levels, difficulty is often defined by the probability of completion\nor completion rate; however, this operationalisation is limited in that it does\nnot describe the behaviour of the player within the area.\n  In this research work, we formalise a model of level difficulty for puzzle\ngames that goes beyond the classical probability of success. We accomplish this\nby describing the distribution of actions performed within a game level using a\nparametric statistical model thus creating a richer descriptor of difficulty.\nThe model is fitted and evaluated on a dataset collected from the game Lily's\nGarden by Tactile Games, and the results of the evaluation show that the it is\nable to describe and explain difficulty in a vast majority of the levels.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 13:47:28 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 08:21:25 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Kristensen", "Jeppe Theiss", ""], ["Valdivia", "Arturo", ""], ["Burelli", "Paolo", ""]]}, {"id": "2107.03324", "submitter": "Timo M\\\"uller", "authors": "Timo M\\\"uller, Benjamin Lindemann, Tobias Jung, Nasser Jazdi, Michael\n  Weyrich", "title": "Enhancing an Intelligent Digital Twin with a Self-organized\n  Reconfiguration Management based on Adaptive Process Models", "comments": "6 pages, 2 figures. Submitted to 54th CIRP Conference on\n  Manufacturing Systems 2021", "journal-ref": null, "doi": "10.13140/RG.2.2.31646.87362", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Shorter product life cycles and increasing individualization of production\nleads to an increased reconfiguration demand in the domain of industrial\nautomation systems, which will be dominated by cyber-physical production\nsystems in the future. In constantly changing systems, however, not all\nconfiguration alternatives of the almost infinite state space are fully\nunderstood. Thus, certain configurations can lead to process instability, a\nreduction in quality or machine failures. Therefore, this paper presents an\napproach that enhances an intelligent Digital Twin with a self-organized\nreconfiguration management based on adaptive process models in order to find\noptimized configurations more comprehensively.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 16:02:53 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["M\u00fcller", "Timo", ""], ["Lindemann", "Benjamin", ""], ["Jung", "Tobias", ""], ["Jazdi", "Nasser", ""], ["Weyrich", "Michael", ""]]}, {"id": "2107.03336", "submitter": "Benjamin Maschler", "authors": "Benjamin Maschler, Sophia Tatiyosyan and Michael Weyrich", "title": "Regularization-based Continual Learning for Fault Prediction in\n  Lithium-Ion Batteries", "comments": "6 pages, 5 figures, 4 tables. Accepted at CIRP ICME 2021. arXiv admin\n  note: text overlap with arXiv:2101.00509", "journal-ref": null, "doi": "10.13140/RG.2.2.10151.06561", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, the use of lithium-ion batteries has greatly expanded into\nproducts from many industrial sectors, e.g. cars, power tools or medical\ndevices. An early prediction and robust understanding of battery faults could\ntherefore greatly increase product quality in those fields. While current\napproaches for data-driven fault prediction provide good results on the exact\nprocesses they were trained on, they often lack the ability to flexibly adapt\nto changes, e.g. in operational or environmental parameters. Continual learning\npromises such flexibility, allowing for an automatic adaption of previously\nlearnt knowledge to new tasks. Therefore, this article discusses different\ncontinual learning approaches from the group of regularization strategies,\nwhich are implemented, evaluated and compared based on a real battery wear\ndataset. Online elastic weight consolidation delivers the best results, but, as\nwith all examined approaches, its performance appears to be strongly dependent\non task characteristics and task sequence.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 16:24:18 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Maschler", "Benjamin", ""], ["Tatiyosyan", "Sophia", ""], ["Weyrich", "Michael", ""]]}, {"id": "2107.03354", "submitter": "Tianbo Li", "authors": "Tianbo Li, Tianze Luo, Yiping Ke, Sinno Jialin Pan", "title": "Mitigating Performance Saturation in Neural Marked Point Processes:\n  Architectures and Loss Functions", "comments": "9 pages, 4 figures, accepted by KDD-21 research track. The source\n  code is available at https://github.com/ltz0120/Graph-Convolutional-\n  Hawkes-Processes-GCHP", "journal-ref": null, "doi": "10.1145/3447548.3467436", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attributed event sequences are commonly encountered in practice. A recent\nresearch line focuses on incorporating neural networks with the statistical\nmodel -- marked point processes, which is the conventional tool for dealing\nwith attributed event sequences. Neural marked point processes possess good\ninterpretability of probabilistic models as well as the representational power\nof neural networks. However, we find that performance of neural marked point\nprocesses is not always increasing as the network architecture becomes more\ncomplicated and larger, which is what we call the performance saturation\nphenomenon. This is due to the fact that the generalization error of neural\nmarked point processes is determined by both the network representational\nability and the model specification at the same time. Therefore we can draw two\nmajor conclusions: first, simple network structures can perform no worse than\ncomplicated ones for some cases; second, using a proper probabilistic\nassumption is as equally, if not more, important as improving the complexity of\nthe network. Based on this observation, we propose a simple graph-based network\nstructure called GCHP, which utilizes only graph convolutional layers, thus it\ncan be easily accelerated by the parallel mechanism. We directly consider the\ndistribution of interarrival times instead of imposing a specific assumption on\nthe conditional intensity function, and propose to use a likelihood ratio loss\nwith a moment matching mechanism for optimization and model selection.\nExperimental results show that GCHP can significantly reduce training time and\nthe likelihood ratio loss with interarrival time probability assumptions can\ngreatly improve the model performance.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 16:59:14 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Li", "Tianbo", ""], ["Luo", "Tianze", ""], ["Ke", "Yiping", ""], ["Pan", "Sinno Jialin", ""]]}, {"id": "2107.03385", "submitter": "Andres Carvallo", "authors": "Iv\\'an Cantador, Andr\\'es Carvallo, Fernando Diez", "title": "Rating and aspect-based opinion graph embeddings for explainable\n  recommendations", "comments": "arXiv admin note: substantial text overlap with arXiv:2107.03226", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The success of neural network embeddings has entailed a renewed interest in\nusing knowledge graphs for a wide variety of machine learning and information\nretrieval tasks. In particular, recent recommendation methods based on graph\nembeddings have shown state-of-the-art performance. In general, these methods\nencode latent rating patterns and content features. Differently from previous\nwork, in this paper, we propose to exploit embeddings extracted from graphs\nthat combine information from ratings and aspect-based opinions expressed in\ntextual reviews. We then adapt and evaluate state-of-the-art graph embedding\ntechniques over graphs generated from Amazon and Yelp reviews on six domains,\noutperforming baseline recommenders. Additionally, our method has the advantage\nof providing explanations that involve the coverage of aspect-based opinions\ngiven by users about recommended items.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 14:07:07 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Cantador", "Iv\u00e1n", ""], ["Carvallo", "Andr\u00e9s", ""], ["Diez", "Fernando", ""]]}, {"id": "2107.03415", "submitter": "Masoud Mansoury", "authors": "Masoud Mansoury, Himan Abdollahpouri, Mykola Pechenizkiy, Bamshad\n  Mobasher, Robin Burke", "title": "A Graph-based Approach for Mitigating Multi-sided Exposure Bias in\n  Recommender Systems", "comments": "arXiv admin note: substantial text overlap with arXiv:2005.01148", "journal-ref": null, "doi": "10.1145/3470948", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness is a critical system-level objective in recommender systems that has\nbeen the subject of extensive recent research. A specific form of fairness is\nsupplier exposure fairness where the objective is to ensure equitable coverage\nof items across all suppliers in recommendations provided to users. This is\nespecially important in multistakeholder recommendation scenarios where it may\nbe important to optimize utilities not just for the end-user, but also for\nother stakeholders such as item sellers or producers who desire a fair\nrepresentation of their items. This type of supplier fairness is sometimes\naccomplished by attempting to increasing aggregate diversity in order to\nmitigate popularity bias and to improve the coverage of long-tail items in\nrecommendations. In this paper, we introduce FairMatch, a general graph-based\nalgorithm that works as a post processing approach after recommendation\ngeneration to improve exposure fairness for items and suppliers. The algorithm\niteratively adds high quality items that have low visibility or items from\nsuppliers with low exposure to the users' final recommendation lists. A\ncomprehensive set of experiments on two datasets and comparison with\nstate-of-the-art baselines show that FairMatch, while significantly improves\nexposure fairness and aggregate diversity, maintains an acceptable level of\nrelevance of the recommendations.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 18:01:26 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Mansoury", "Masoud", ""], ["Abdollahpouri", "Himan", ""], ["Pechenizkiy", "Mykola", ""], ["Mobasher", "Bamshad", ""], ["Burke", "Robin", ""]]}, {"id": "2107.03427", "submitter": "Sai Srivatsa Ravindranath", "authors": "Sai Srivatsa Ravindranath, Zhe Feng, Shira Li, Jonathan Ma, Scott D.\n  Kominers, David C. Parkes", "title": "Deep Learning for Two-Sided Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the use of a multi-layer neural network to model two-sided\nmatching and to explore the design space between strategy-proofness and\nstability. It is well known that both properties cannot be achieved\nsimultaneously but the efficient frontier in this design space is not\nunderstood. We show empirically that it is possible to achieve a good\ncompromise between stability and strategy-proofness-substantially better than\nthat achievable through a convex combination of deferred acceptance (stable and\nstrategy-proof for only one side of the market) and randomized serial\ndictatorship (strategy-proof but not stable).\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 18:22:11 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Ravindranath", "Sai Srivatsa", ""], ["Feng", "Zhe", ""], ["Li", "Shira", ""], ["Ma", "Jonathan", ""], ["Kominers", "Scott D.", ""], ["Parkes", "David C.", ""]]}, {"id": "2107.03451", "submitter": "Emily Dinan", "authors": "Emily Dinan, Gavin Abercrombie, A. Stevie Bergman, Shannon Spruit,\n  Dirk Hovy, Y-Lan Boureau, Verena Rieser", "title": "Anticipating Safety Issues in E2E Conversational AI: Framework and\n  Tooling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last several years, end-to-end neural conversational agents have\nvastly improved in their ability to carry a chit-chat conversation with humans.\nHowever, these models are often trained on large datasets from the internet,\nand as a result, may learn undesirable behaviors from this data, such as toxic\nor otherwise harmful language. Researchers must thus wrestle with the issue of\nhow and when to release these models. In this paper, we survey the problem\nlandscape for safety for end-to-end conversational AI and discuss recent and\nrelated work. We highlight tensions between values, potential positive impact\nand potential harms, and provide a framework for making decisions about whether\nand how to release these models, following the tenets of value-sensitive\ndesign. We additionally provide a suite of tools to enable researchers to make\nbetter-informed decisions about training and releasing end-to-end\nconversational AI models.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 19:25:57 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 15:37:52 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 15:05:22 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Dinan", "Emily", ""], ["Abercrombie", "Gavin", ""], ["Bergman", "A. Stevie", ""], ["Spruit", "Shannon", ""], ["Hovy", "Dirk", ""], ["Boureau", "Y-Lan", ""], ["Rieser", "Verena", ""]]}, {"id": "2107.03463", "submitter": "Seyed Mojtaba Marvasti-Zadeh", "authors": "Seyed Mojtaba Marvasti-Zadeh, Javad Khaghani, Li Cheng, Hossein\n  Ghanei-Yakhdan, Shohreh Kasaei", "title": "CHASE: Robust Visual Tracking via Cell-Level Differentiable Neural\n  Architecture Search", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A strong visual object tracker nowadays relies on its well-crafted modules,\nwhich typically consist of manually-designed network architectures to deliver\nhigh-quality tracking results. Not surprisingly, the manual design process\nbecomes a particularly challenging barrier, as it demands sufficient prior\nexperience, enormous effort, intuition and perhaps some good luck. Meanwhile,\nneural architecture search has gaining grounds in practical applications such\nas image segmentation, as a promising method in tackling the issue of automated\nsearch of feasible network structures. In this work, we propose a novel\ncell-level differentiable architecture search mechanism to automate the network\ndesign of the tracking module, aiming to adapt backbone features to the\nobjective of a tracking network during offline training. The proposed approach\nis simple, efficient, and with no need to stack a series of modules to\nconstruct a network. Our approach is easy to be incorporated into existing\ntrackers, which is empirically validated using different differentiable\narchitecture search-based methods and tracking objectives. Extensive\nexperimental evaluations demonstrate the superior performance of our approach\nover five commonly-used benchmarks. Meanwhile, our automated searching process\ntakes 41 (18) hours for the second (first) order DARTS method on the\nTrackingNet dataset.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 15:16:45 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Marvasti-Zadeh", "Seyed Mojtaba", ""], ["Khaghani", "Javad", ""], ["Cheng", "Li", ""], ["Ghanei-Yakhdan", "Hossein", ""], ["Kasaei", "Shohreh", ""]]}, {"id": "2107.03510", "submitter": "Mohammad Mohammadi Amiri Dr.", "authors": "Mohammad Mohammadi Amiri, Sanjeev R. Kulkarni, H. Vincent Poor", "title": "Federated Learning with Downlink Device Selection", "comments": "accepted in IEEE International Workshop on Signal Processing Advances\n  in Wireless Communications (SPAWC), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI eess.SP math.IT", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We study federated edge learning, where a global model is trained\ncollaboratively using privacy-sensitive data at the edge of a wireless network.\nA parameter server (PS) keeps track of the global model and shares it with the\nwireless edge devices for training using their private local data. The devices\nthen transmit their local model updates, which are used to update the global\nmodel, to the PS. The algorithm, which involves transmission over PS-to-device\nand device-to-PS links, continues until the convergence of the global model or\nlack of any participating devices. In this study, we consider device selection\nbased on downlink channels over which the PS shares the global model with the\ndevices. Performing digital downlink transmission, we design a partial device\nparticipation framework where a subset of the devices is selected for training\nat each iteration. Therefore, the participating devices can have a better\nestimate of the global model compared to the full device participation case\nwhich is due to the shared nature of the broadcast channel with the price of\nupdating the global model with respect to a smaller set of data. At each\niteration, the PS broadcasts different quantized global model updates to\ndifferent participating devices based on the last global model estimates\navailable at the devices. We investigate the best number of participating\ndevices through experimental results for image classification using the MNIST\ndataset with biased distribution.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 22:42:39 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Amiri", "Mohammad Mohammadi", ""], ["Kulkarni", "Sanjeev R.", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2107.03564", "submitter": "Junsu Cho", "authors": "Junsu Cho, SeongKu Kang, Dongmin Hyun, Hwanjo Yu", "title": "Unsupervised Proxy Selection for Session-based Recommender Systems", "comments": "Accepted to SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462958", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session-based Recommender Systems (SRSs) have been actively developed to\nrecommend the next item of an anonymous short item sequence (i.e., session).\nUnlike sequence-aware recommender systems where the whole interaction sequence\nof each user can be used to model both the short-term interest and the general\ninterest of the user, the absence of user-dependent information in SRSs makes\nit difficult to directly derive the user's general interest from data.\nTherefore, existing SRSs have focused on how to effectively model the\ninformation about short-term interest within the sessions, but they are\ninsufficient to capture the general interest of users. To this end, we propose\na novel framework to overcome the limitation of SRSs, named ProxySR, which\nimitates the missing information in SRSs (i.e., general interest of users) by\nmodeling proxies of sessions. ProxySR selects a proxy for the input session in\nan unsupervised manner, and combines it with the encoded short-term interest of\nthe session. As a proxy is jointly learned with the short-term interest and\nselected by multiple sessions, a proxy learns to play the role of the general\ninterest of a user and ProxySR learns how to select a suitable proxy for an\ninput session. Moreover, we propose another real-world situation of SRSs where\na few users are logged-in and leave their identifiers in sessions, and a\nrevision of ProxySR for the situation. Our experiments on real-world datasets\nshow that ProxySR considerably outperforms the state-of-the-art competitors,\nand the proxies successfully imitate the general interest of the users without\nany user-dependent information.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 02:03:06 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Cho", "Junsu", ""], ["Kang", "SeongKu", ""], ["Hyun", "Dongmin", ""], ["Yu", "Hwanjo", ""]]}, {"id": "2107.03573", "submitter": "Jiangxia Cao", "authors": "Jiangxia Cao, Xixun Lin, Xin Cong, Shu Guo, Hengzhu Tang, Tingwen Liu,\n  Bin Wang", "title": "Deep Structural Point Process for Learning Temporal Interaction Networks", "comments": "Accepted by ECML/PKDD 2021, 16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the problem of learning temporal interaction networks.\nA temporal interaction network consists of a series of chronological\ninteractions between users and items. Previous methods tackle this problem by\nusing different variants of recurrent neural networks to model sequential\ninteractions, which fail to consider the structural information of temporal\ninteraction networks and inevitably lead to sub-optimal results. To this end,\nwe propose a novel Deep Structural Point Process termed as DSPP for learning\ntemporal interaction networks. DSPP simultaneously incorporates the topological\nstructure and long-range dependency structure into our intensity function to\nenhance model expressiveness. To be specific, by using the topological\nstructure as a strong prior, we first design a topological fusion encoder to\nobtain node embeddings. An attentive shift encoder is then developed to learn\nthe long-range dependency structure between users and items in continuous time.\nThe proposed two modules enable our model to capture the user-item correlation\nand dynamic influence in temporal interaction networks. DSPP is evaluated on\nthree real-world datasets for both tasks of item prediction and time\nprediction. Extensive experiments demonstrate that our model achieves\nconsistent and significant improvements over state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 03:07:34 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Cao", "Jiangxia", ""], ["Lin", "Xixun", ""], ["Cong", "Xin", ""], ["Guo", "Shu", ""], ["Tang", "Hengzhu", ""], ["Liu", "Tingwen", ""], ["Wang", "Bin", ""]]}, {"id": "2107.03577", "submitter": "Khalid El-Awady", "authors": "Khalid El-Awady", "title": "Adaptive Stress Testing for Adversarial Learning in a Financial\n  Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-fin.CP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We demonstrate the use of Adaptive Stress Testing to detect and address\npotential vulnerabilities in a financial environment. We develop a simplified\nmodel for credit card fraud detection that utilizes a linear regression\nclassifier based on historical payment transaction data coupled with business\nrules. We then apply the reinforcement learning model known as Adaptive Stress\nTesting to train an agent, that can be thought of as a potential fraudster, to\nfind the most likely path to system failure -- successfully defrauding the\nsystem. We show the connection between this most likely failure path and the\nlimits of the classifier and discuss how the fraud detection system's business\nrules can be further augmented to mitigate these failure modes.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 03:19:40 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["El-Awady", "Khalid", ""]]}, {"id": "2107.03603", "submitter": "Dexun Li", "authors": "Dexun Li, Meghna Lowalekar, Pradeep Varakantham", "title": "CLAIM: Curriculum Learning Policy for Influence Maximization in Unknown\n  Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence maximization is the problem of finding a small subset of nodes in a\nnetwork that can maximize the diffusion of information. Recently, it has also\nfound application in HIV prevention, substance abuse prevention, micro-finance\nadoption, etc., where the goal is to identify the set of peer leaders in a\nreal-world physical social network who can disseminate information to a large\ngroup of people. Unlike online social networks, real-world networks are not\ncompletely known, and collecting information about the network is costly as it\ninvolves surveying multiple people. In this paper, we focus on this problem of\nnetwork discovery for influence maximization. The existing work in this\ndirection proposes a reinforcement learning framework. As the environment\ninteractions in real-world settings are costly, so it is important for the\nreinforcement learning algorithms to have minimum possible environment\ninteractions, i.e, to be sample efficient. In this work, we propose CLAIM -\nCurriculum LeArning Policy for Influence Maximization to improve the sample\nefficiency of RL methods. We conduct experiments on real-world datasets and\nshow that our approach can outperform the current best approach.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 04:52:50 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Li", "Dexun", ""], ["Lowalekar", "Meghna", ""], ["Varakantham", "Pradeep", ""]]}, {"id": "2107.03619", "submitter": "Dale Townsend", "authors": "D. Townsend", "title": "Validation and Inference of Agent Based Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Agent Based Modelling (ABM) is a computational framework for simulating the\nbehaviours and interactions of autonomous agents. As Agent Based Models are\nusually representative of complex systems, obtaining a likelihood function of\nthe model parameters is nearly always intractable. There is a necessity to\nconduct inference in a likelihood free context in order to understand the model\noutput. Approximate Bayesian Computation is a suitable approach for this\ninference. It can be applied to an Agent Based Model to both validate the\nsimulation and infer a set of parameters to describe the model. Recent research\nin ABC has yielded increasingly efficient algorithms for calculating the\napproximate likelihood. These are investigated and compared using a pedestrian\nmodel in the Hamilton CBD.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 05:53:37 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Townsend", "D.", ""]]}, {"id": "2107.03640", "submitter": "Ningyuan Xu", "authors": "Ningyuan Xu, Jiayan Zhuang, Yaojun Wu, Jiangjian Xiao", "title": "A Dataset and Method for Hallux Valgus Angle Estimation Based on Deep\n  Learing", "comments": "7pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Angular measurements is essential to make a resonable treatment for Hallux\nvalgus (HV), a common forefoot deformity. However, it still depends on manual\nlabeling and measurement, which is time-consuming and sometimes unreliable.\nAutomating this process is a thing of concern. However, it lack of dataset and\nthe keypoints based method which made a great success in pose estimation is not\nsuitable for this field.To solve the problems, we made a dataset and developed\nan algorithm based on deep learning and linear regression. It shows great\nfitting ability to the ground truth.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 07:11:12 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Xu", "Ningyuan", ""], ["Zhuang", "Jiayan", ""], ["Wu", "Yaojun", ""], ["Xiao", "Jiangjian", ""]]}, {"id": "2107.03685", "submitter": "Nicol\\`o Botteghi", "authors": "Nicol\\`o Botteghi, Luuk Grefte, Mannes Poel, Beril Sirmacek, Christoph\n  Brune, Edwin Dertien, and Stefano Stramigioli", "title": "Towards Autonomous Pipeline Inspection with Hierarchical Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspection and maintenance are two crucial aspects of industrial pipeline\nplants. While robotics has made tremendous progress in the mechanic design of\nin-pipe inspection robots, the autonomous control of such robots is still a big\nopen challenge due to the high number of actuators and the complex manoeuvres\nrequired. To address this problem, we investigate the usage of Deep\nReinforcement Learning for achieving autonomous navigation of in-pipe robots in\npipeline networks with complex topologies. Moreover, we introduce a\nhierarchical policy decomposition based on Hierarchical Reinforcement Learning\nto learn robust high-level navigation skills. We show that the hierarchical\nstructure introduced in the policy is fundamental for solving the navigation\ntask through pipes and necessary for achieving navigation performances superior\nto human-level control.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 08:58:59 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Botteghi", "Nicol\u00f2", ""], ["Grefte", "Luuk", ""], ["Poel", "Mannes", ""], ["Sirmacek", "Beril", ""], ["Brune", "Christoph", ""], ["Dertien", "Edwin", ""], ["Stramigioli", "Stefano", ""]]}, {"id": "2107.03700", "submitter": "Ayushe Gangal", "authors": "Ayushe Gangal, Peeyush Kumar and Sunita Kumari", "title": "Complete Scanning Application Using OpenCv", "comments": "10 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In the following paper, we have combined the various basic functionalities\nprovided by the NumPy library and OpenCv library, which is an open source for\nComputer Vision applications, like conversion of colored images to grayscale,\ncalculating threshold, finding contours and using those contour points to take\nperspective transform of the image inputted by the user, using Python version\n3.7. Additional features include cropping, rotating and saving as well. All\nthese functions and features, when implemented step by step, results in a\ncomplete scanning application. The applied procedure involves the following\nsteps: Finding contours, applying Perspective transform and brightening the\nimage, Adaptive Thresholding and applying filters for noise cancellation, and\nRotation features and perspective transform for a special cropping algorithm.\nThe described technique is implemented on various samples.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 09:21:57 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Gangal", "Ayushe", ""], ["Kumar", "Peeyush", ""], ["Kumari", "Sunita", ""]]}, {"id": "2107.03719", "submitter": "Thomas Elsken", "authors": "Thomas Elsken, Benedikt Staffler, Arber Zela, Jan Hendrik Metzen,\n  Frank Hutter", "title": "Bag of Tricks for Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While neural architecture search methods have been successful in previous\nyears and led to new state-of-the-art performance on various problems, they\nhave also been criticized for being unstable, being highly sensitive with\nrespect to their hyperparameters, and often not performing better than random\nsearch. To shed some light on this issue, we discuss some practical\nconsiderations that help improve the stability, efficiency and overall\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 09:57:39 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Elsken", "Thomas", ""], ["Staffler", "Benedikt", ""], ["Zela", "Arber", ""], ["Metzen", "Jan Hendrik", ""], ["Hutter", "Frank", ""]]}, {"id": "2107.03721", "submitter": "Michael Veale", "authors": "Michael Veale and Frederik Zuiderveen Borgesius", "title": "Demystifying the Draft EU Artificial Intelligence Act", "comments": "16 pages, 1 table", "journal-ref": "Computer Law Review International (2021), 22(4)", "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In April 2021, the European Commission proposed a Regulation on Artificial\nIntelligence, known as the AI Act. We present an overview of the Act and\nanalyse its implications, drawing on scholarship ranging from the study of\ncontemporary AI practices to the structure of EU product safety regimes over\nthe last four decades. Aspects of the AI Act, such as different rules for\ndifferent risk-levels of AI, make sense. But we also find that some provisions\nof the Draft AI Act have surprising legal implications, whilst others may be\nlargely ineffective at achieving their stated goals. Several overarching\naspects, including the enforcement regime and the risks of maximum\nharmonisation pre-empting legitimate national AI policy, engender significant\nconcern. These issues should be addressed as a priority in the legislative\nprocess.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 10:04:07 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 08:39:22 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Veale", "Michael", ""], ["Borgesius", "Frederik Zuiderveen", ""]]}, {"id": "2107.03743", "submitter": "Kashif Rasul", "authors": "Ad\\`ele Gouttes, Kashif Rasul, Mateusz Koren, Johannes Stephan, Tofigh\n  Naghibi", "title": "Probabilistic Time Series Forecasting with Implicit Quantile Networks", "comments": "Accepted at the ICML 2021 Time Series Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Here, we propose a general method for probabilistic time series forecasting.\nWe combine an autoregressive recurrent neural network to model temporal\ndynamics with Implicit Quantile Networks to learn a large class of\ndistributions over a time-series target. When compared to other probabilistic\nneural forecasting models on real- and simulated data, our approach is\nfavorable in terms of point-wise prediction accuracy as well as on estimating\nthe underlying temporal distribution.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 10:37:24 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Gouttes", "Ad\u00e8le", ""], ["Rasul", "Kashif", ""], ["Koren", "Mateusz", ""], ["Stephan", "Johannes", ""], ["Naghibi", "Tofigh", ""]]}, {"id": "2107.03751", "submitter": "Luis Lucas", "authors": "Luis Lucas and David Tomas and Jose Garcia-Rodriguez", "title": "Exploiting the relationship between visual and textual features in\n  social networks for image classification with zero-shot deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main issues related to unsupervised machine learning is the cost\nof processing and extracting useful information from large datasets. In this\nwork, we propose a classifier ensemble based on the transferable learning\ncapabilities of the CLIP neural network architecture in multimodal environments\n(image and text) from social media. For this purpose, we used the InstaNY100K\ndataset and proposed a validation approach based on sampling techniques. Our\nexperiments, based on image classification tasks according to the labels of the\nPlaces dataset, are performed by first considering only the visual part, and\nthen adding the associated texts as support. The results obtained demonstrated\nthat trained neural networks such as CLIP can be successfully applied to image\nclassification with little fine-tuning, and considering the associated texts to\nthe images can help to improve the accuracy depending on the goal. The results\ndemonstrated what seems to be a promising research direction.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 10:54:59 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Lucas", "Luis", ""], ["Tomas", "David", ""], ["Garcia-Rodriguez", "Jose", ""]]}, {"id": "2107.03767", "submitter": "Menglin Yang", "authors": "Menglin Yang, Min Zhou, Marcus Kalander, Zengfeng Huang, Irwin King", "title": "Discrete-time Temporal Network Embedding via Implicit Hierarchical\n  Learning in Hyperbolic Space", "comments": "KDD2021", "journal-ref": null, "doi": "10.1145/3447548.3467422", "report-no": null, "categories": "cs.SI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Representation learning over temporal networks has drawn considerable\nattention in recent years. Efforts are mainly focused on modeling structural\ndependencies and temporal evolving regularities in Euclidean space which,\nhowever, underestimates the inherent complex and hierarchical properties in\nmany real-world temporal networks, leading to sub-optimal embeddings. To\nexplore these properties of a complex temporal network, we propose a hyperbolic\ntemporal graph network (HTGN) that fully takes advantage of the exponential\ncapacity and hierarchical awareness of hyperbolic geometry. More specially,\nHTGN maps the temporal graph into hyperbolic space, and incorporates hyperbolic\ngraph neural network and hyperbolic gated recurrent neural network, to capture\nthe evolving behaviors and implicitly preserve hierarchical information\nsimultaneously. Furthermore, in the hyperbolic space, we propose two important\nmodules that enable HTGN to successfully model temporal networks: (1)\nhyperbolic temporal contextual self-attention (HTA) module to attend to\nhistorical states and (2) hyperbolic temporal consistency (HTC) module to\nensure stability and generalization. Experimental results on multiple\nreal-world datasets demonstrate the superiority of HTGN for temporal graph\nembedding, as it consistently outperforms competing methods by significant\nmargins in various temporal link prediction tasks. Specifically, HTGN achieves\nAUC improvement up to 9.98% for link prediction and 11.4% for new link\nprediction. Moreover, the ablation study further validates the representational\nability of hyperbolic geometry and the effectiveness of the proposed HTA and\nHTC modules.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 11:24:59 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Yang", "Menglin", ""], ["Zhou", "Min", ""], ["Kalander", "Marcus", ""], ["Huang", "Zengfeng", ""], ["King", "Irwin", ""]]}, {"id": "2107.03772", "submitter": "Sylvia Wenmackers", "authors": "Leander Vignero and Sylvia Wenmackers", "title": "Degrees of riskiness, falsifiability, and truthlikeness. A neo-Popperian\n  account applicable to probabilistic theories", "comments": "41 pages; 3 figures; accepted for publication in Synthese", "journal-ref": null, "doi": "10.1007/s11229-021-03310-5", "report-no": null, "categories": "physics.hist-ph cs.AI cs.IT math.IT math.PR math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we take a fresh look at three Popperian concepts: riskiness,\nfalsifiability, and truthlikeness (or verisimilitude) of scientific hypotheses\nor theories. First, we make explicit the dimensions that underlie the notion of\nriskiness. Secondly, we examine if and how degrees of falsifiability can be\ndefined, and how they are related to various dimensions of the concept of\nriskiness as well as the experimental context. Thirdly, we consider the\nrelation of riskiness to (expected degrees of) truthlikeness. Throughout, we\npay special attention to probabilistic theories and we offer a tentative,\nquantitative account of verisimilitude for probabilistic theories.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 11:36:50 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Vignero", "Leander", ""], ["Wenmackers", "Sylvia", ""]]}, {"id": "2107.03786", "submitter": "Xingtai Gui", "authors": "Xingtai Gui, Jiyang Zhang", "title": "Deep Metric Learning Model for Imbalanced Fault Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent diagnosis method based on data-driven and deep learning is an\nattractive and meaningful field in recent years. However, in practical\napplication scenarios, the imbalance of time-series fault is an urgent problem\nto be solved. This paper proposes a novel deep metric learning model, where\nimbalanced fault data and a quadruplet data pair design manner are considered.\nBased on such data pair, a quadruplet loss function which takes into account\nthe inter-class distance and the intra-class data distribution are proposed.\nThis quadruplet loss pays special attention to imbalanced sample pair. The\nreasonable combination of quadruplet loss and softmax loss function can reduce\nthe impact of imbalance. Experiment results on two open-source datasets show\nthat the proposed method can effectively and robustly improve the performance\nof imbalanced fault diagnosis.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 11:56:41 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 07:46:54 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Gui", "Xingtai", ""], ["Zhang", "Jiyang", ""]]}, {"id": "2107.03813", "submitter": "Yitong Pang", "authors": "Yitong Pang, Lingfei Wu, Qi Shen, Yiming Zhang, Zhihua Wei, Fangli Xu,\n  Ethan Chang, Bo Long", "title": "Heterogeneous Global Graph Neural Networks for Personalized\n  Session-based Recommendation", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the next interaction of a short-term interaction session is a\nchallenging task in session-based recommendation. Almost all existing works\nrely on item transition patterns, and neglect the impact of user historical\nsessions while modeling user preference, which often leads to non-personalized\nrecommendation. Additionally, existing personalized session-based recommenders\ncapture user preference only based on the sessions of the current user, but\nignore the useful item-transition patterns from other user's historical\nsessions. To address these issues, we propose a novel Heterogeneous Global\nGraph Neural Networks (HG-GNN) to exploit the item transitions over all\nsessions in a subtle manner for better inferring user preference from the\ncurrent and historical sessions. To effectively exploit the item transitions\nover all sessions from users, we propose a novel heterogeneous global graph\nthat contains item transitions of sessions, user-item interactions and global\nco-occurrence items. Moreover, to capture user preference from sessions\ncomprehensively, we propose to learn two levels of user representations from\nthe global graph via two graph augmented preference encoders. Specifically, we\ndesign a novel heterogeneous graph neural network (HGNN) on the heterogeneous\nglobal graph to learn the long-term user preference and item representations\nwith rich semantics. Based on the HGNN, we propose the Current Preference\nEncoder and the Historical Preference Encoder to capture the different levels\nof user preference from the current and historical sessions, respectively. To\nachieve personalized recommendation, we integrate the representations of the\nuser current preference and historical interests to generate the final user\npreference representation. Extensive experimental results on three real-world\ndatasets show that our model outperforms other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 12:38:26 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Pang", "Yitong", ""], ["Wu", "Lingfei", ""], ["Shen", "Qi", ""], ["Zhang", "Yiming", ""], ["Wei", "Zhihua", ""], ["Xu", "Fangli", ""], ["Chang", "Ethan", ""], ["Long", "Bo", ""]]}, {"id": "2107.03844", "submitter": "Firoj Alam", "authors": "Firoj Alam, Arid Hasan, Tanvirul Alam, Akib Khan, Janntatul Tajrin,\n  Naira Khan, Shammur Absar Chowdhury", "title": "A Review of Bangla Natural Language Processing Tasks and the Utility of\n  Transformer Models", "comments": "Under Review, Bangla language processing, text classification,\n  sequence tagging, datasets, benchmarks, transformer models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Bangla -- ranked as the 6th most widely spoken language across the world\n(https://www.ethnologue.com/guides/ethnologue200), with 230 million native\nspeakers -- is still considered as a low-resource language in the natural\nlanguage processing (NLP) community. With three decades of research, Bangla NLP\n(BNLP) is still lagging behind mainly due to the scarcity of resources and the\nchallenges that come with it. There is sparse work in different areas of BNLP;\nhowever, a thorough survey reporting previous work and recent advances is yet\nto be done. In this study, we first provide a review of Bangla NLP tasks,\nresources, and tools available to the research community; we benchmark datasets\ncollected from various platforms for nine NLP tasks using current\nstate-of-the-art algorithms (i.e., transformer-based models). We provide\ncomparative results for the studied NLP tasks by comparing monolingual vs.\nmultilingual models of varying sizes. We report our results using both\nindividual and consolidated datasets and provide data splits for future\nresearch. We reviewed a total of 108 papers and conducted 175 sets of\nexperiments. Our results show promising performance using transformer-based\nmodels while highlighting the trade-off with computational costs. We hope that\nsuch a comprehensive survey will motivate the community to build on and further\nadvance the research on Bangla NLP.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 13:49:46 GMT"}, {"version": "v2", "created": "Sun, 11 Jul 2021 06:43:33 GMT"}, {"version": "v3", "created": "Sun, 25 Jul 2021 05:41:15 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Alam", "Firoj", ""], ["Hasan", "Arid", ""], ["Alam", "Tanvirul", ""], ["Khan", "Akib", ""], ["Tajrin", "Janntatul", ""], ["Khan", "Naira", ""], ["Chowdhury", "Shammur Absar", ""]]}, {"id": "2107.03851", "submitter": "Andrew Jaegle", "authors": "Andrew Jaegle, Yury Sulsky, Arun Ahuja, Jake Bruce, Rob Fergus, Greg\n  Wayne", "title": "Imitation by Predicting Observations", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning enables agents to reuse and adapt the hard-won expertise\nof others, offering a solution to several key challenges in learning behavior.\nAlthough it is easy to observe behavior in the real-world, the underlying\nactions may not be accessible. We present a new method for imitation solely\nfrom observations that achieves comparable performance to experts on\nchallenging continuous control tasks while also exhibiting robustness in the\npresence of observations unrelated to the task. Our method, which we call FORM\n(for \"Future Observation Reward Model\") is derived from an inverse RL objective\nand imitates using a model of expert behavior learned by generative modelling\nof the expert's observations, without needing ground truth actions. We show\nthat FORM performs comparably to a strong baseline IRL method (GAIL) on the\nDeepMind Control Suite benchmark, while outperforming GAIL in the presence of\ntask-irrelevant features.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 14:09:30 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Jaegle", "Andrew", ""], ["Sulsky", "Yury", ""], ["Ahuja", "Arun", ""], ["Bruce", "Jake", ""], ["Fergus", "Rob", ""], ["Wayne", "Greg", ""]]}, {"id": "2107.03869", "submitter": "Ahmad Kamal Bin Mohd Nor", "authors": "Ahmad Kamal BIN MOHD NOR, Srinivasa Rao PEDAPATI, Masdi MUHAMMAD", "title": "Explainable AI (XAI) for PHM of Industrial Asset: A State-of-The-Art,\n  PRISMA-Compliant Systematic Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A state-of-the-art systematic review on XAI applied to Prognostic and Health\nManagement (PHM) of industrial asset is presented. The work attempts to provide\nan overview of the general trend of XAI in PHM, answers the question of\naccuracy versus explainability, investigates the extent of human role,\nexplainability evaluation and uncertainty management in PHM XAI. Research\narticles linked to PHM XAI, in English language, from 2015 to 2021 are selected\nfrom IEEE Xplore, ScienceDirect, SpringerLink, ACM Digital Library and Scopus\ndatabases using PRISMA guidelines. Data was extracted from 35 selected articles\nand examined using MS. Excel. Several findings were synthesized. Firstly, while\nthe discipline is still young, the analysis indicates the growing acceptance of\nXAI in PHM domain. Secondly, XAI functions as a double edge sword, where it is\nassimilated as a tool to execute PHM tasks as well as a mean of explanation, in\nparticular in diagnostic and anomaly detection. There is thus a need for XAI in\nPHM. Thirdly, the review shows that PHM XAI papers produce either good or\nexcellent results in general, suggesting that PHM performance is unaffected by\nXAI. Fourthly, human role, explainability metrics and uncertainty management\nare areas requiring further attention by the PHM community. Adequate\nexplainability metrics to cater for PHM need are urgently needed. Finally, most\ncase study featured on the accepted articles are based on real, indicating that\navailable AI and XAI approaches are equipped to solve complex real-world\nchallenges, increasing the confidence of AI model adoption in the industry.\nThis work is funded by the Universiti Teknologi Petronas Foundation.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 14:22:32 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["NOR", "Ahmad Kamal BIN MOHD", ""], ["PEDAPATI", "Srinivasa Rao", ""], ["MUHAMMAD", "Masdi", ""]]}, {"id": "2107.03876", "submitter": "Artem Polyvyanyy", "authors": "Artem Polyvyanyy, Alistair Moffat, Luciano Garc\\'ia-Ba\\~nuelos", "title": "Bootstrapping Generalization of Process Models Discovered From Event\n  Data", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Process mining studies ways to derive value from process executions recorded\nin event logs of IT-systems, with process discovery the task of inferring a\nprocess model for an event log emitted by some unknown system. One quality\ncriterion for discovered process models is generalization. Generalization seeks\nto quantify how well the discovered model describes future executions of the\nsystem, and is perhaps the least understood quality criterion in process\nmining. The lack of understanding is primarily a consequence of generalization\nseeking to measure properties over the entire future behavior of the system,\nwhen the only available sample of behavior is that provided by the event log\nitself. In this paper, we draw inspiration from computational statistics, and\nemploy a bootstrap approach to estimate properties of a population based on a\nsample. Specifically, we define an estimator of the model's generalization\nbased on the event log it was discovered from, and then use bootstrapping to\nmeasure the generalization of the model with respect to the system, and its\nstatistical significance. Experiments demonstrate the feasibility of the\napproach in industrial settings.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 14:35:56 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Polyvyanyy", "Artem", ""], ["Moffat", "Alistair", ""], ["Garc\u00eda-Ba\u00f1uelos", "Luciano", ""]]}, {"id": "2107.03884", "submitter": "Aadesh Gupta", "authors": "Aadesh Gupta, Kaustubh D.Dhole, Rahul Tarway, Swetha Prabhakar, Ashish\n  Shrivastava", "title": "CANDLE: Decomposing Conditional and Conjunctive Queries for\n  Task-Oriented Dialogue Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain-specific dialogue systems generally determine user intents by relying\non sentence-level classifiers which mainly focus on single action sentences.\nSuch classifiers are not designed to effectively handle complex queries\ncomposed of conditional and sequential clauses that represent multiple actions.\nWe attempt to decompose such queries into smaller single-action sub-queries\nthat are reasonable for intent classifiers to understand in a dialogue\npipeline. We release CANDLE (Conditional & AND type Expressions), a dataset\nconsisting of 3124 utterances manually tagged with conditional and sequential\nlabels and demonstrates this decomposition by training two baseline taggers.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 15:07:11 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Gupta", "Aadesh", ""], ["Dhole", "Kaustubh D.", ""], ["Tarway", "Rahul", ""], ["Prabhakar", "Swetha", ""], ["Shrivastava", "Ashish", ""]]}, {"id": "2107.03901", "submitter": "Akis Linardos", "authors": "Akis Linardos, Kaisar Kushibar, Sean Walsh, Polyxeni Gkontra, Karim\n  Lekadir", "title": "Federated Learning for Multi-Center Imaging Diagnostics: A Study in\n  Cardiovascular Disease", "comments": "Code used in this study can be found in:\n  https://github.com/Linardos/federated-HCM-diagnosis", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models can enable accurate and efficient disease diagnosis, but\nhave thus far been hampered by the data scarcity present in the medical world.\nAutomated diagnosis studies have been constrained by underpowered single-center\ndatasets, and although some results have shown promise, their generalizability\nto other institutions remains questionable as the data heterogeneity between\ninstitutions is not taken into account. By allowing models to be trained in a\ndistributed manner that preserves patients' privacy, federated learning\npromises to alleviate these issues, by enabling diligent multi-center studies.\nWe present the first federated learning study on the modality of cardiovascular\nmagnetic resonance (CMR) and use four centers derived from subsets of the M\\&M\nand ACDC datasets, focusing on the diagnosis of hypertrophic cardiomyopathy\n(HCM). We adapt a 3D-CNN network pretrained on action recognition and explore\ntwo different ways of incorporating shape prior information to the model, and\nfour different data augmentation set-ups, systematically analyzing their impact\non the different collaborative learning choices. We show that despite the small\nsize of data (180 subjects derived from four centers), the privacy preserving\nfederated learning achieves promising results that are competitive with\ntraditional centralized learning. We further find that federatively trained\nmodels exhibit increased robustness and are more sensitive to domain shift\neffects.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 08:54:08 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Linardos", "Akis", ""], ["Kushibar", "Kaisar", ""], ["Walsh", "Sean", ""], ["Gkontra", "Polyxeni", ""], ["Lekadir", "Karim", ""]]}, {"id": "2107.03924", "submitter": "Mahmoud Nasr Mr", "authors": "Mahmoud Nasr, MD. Milon Islam, Shady Shehata, Fakhri Karray and Yuri\n  Quintana", "title": "Smart Healthcare in the Age of AI: Recent Advances, Challenges, and\n  Future Prospects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The significant increase in the number of individuals with chronic ailments\n(including the elderly and disabled) has dictated an urgent need for an\ninnovative model for healthcare systems. The evolved model will be more\npersonalized and less reliant on traditional brick-and-mortar healthcare\ninstitutions such as hospitals, nursing homes, and long-term healthcare\ncenters. The smart healthcare system is a topic of recently growing interest\nand has become increasingly required due to major developments in modern\ntechnologies, especially in artificial intelligence (AI) and machine learning\n(ML). This paper is aimed to discuss the current state-of-the-art smart\nhealthcare systems highlighting major areas like wearable and smartphone\ndevices for health monitoring, machine learning for disease diagnosis, and the\nassistive frameworks, including social robots developed for the ambient\nassisted living environment. Additionally, the paper demonstrates software\nintegration architectures that are very significant to create smart healthcare\nsystems, integrating seamlessly the benefit of data analytics and other tools\nof AI. The explained developed systems focus on several facets: the\ncontribution of each developed framework, the detailed working procedure, the\nperformance as outcomes, and the comparative merits and limitations. The\ncurrent research challenges with potential future directions are addressed to\nhighlight the drawbacks of existing systems and the possible methods to\nintroduce novel frameworks, respectively. This review aims at providing\ncomprehensive insights into the recent developments of smart healthcare systems\nto equip experts to contribute to the field.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 05:10:47 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Nasr", "Mahmoud", ""], ["Islam", "MD. Milon", ""], ["Shehata", "Shady", ""], ["Karray", "Fakhri", ""], ["Quintana", "Yuri", ""]]}, {"id": "2107.03930", "submitter": "Qianli Zhou", "authors": "Qianli Zhou, Guojing Tian, Yong Deng", "title": "Quantum belief function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The belief function in Dempster Shafer evidence theory can express more\ninformation than the traditional Bayesian distribution. It is widely used in\napproximate reasoning, decision-making and information fusion. However, its\npower exponential explosion characteristics leads to the extremely high\ncomputational complexity when handling large amounts of elements in classic\ncomputers. In order to solve the problem, we encode the basic belief assignment\n(BBA) into quantum states, which makes each qubit correspond to control an\nelement. Besides the high efficiency, this quantum expression is very conducive\nto measure the similarity between two BBAs, and the measuring quantum algorithm\nwe come up with has exponential acceleration theoretically compared to the\ncorresponding classical algorithm. In addition, we simulate our quantum version\nof BBA on Qiskit platform, which ensures the rationality of our algorithm\nexperimentally. We believe our results will shed some light on utilizing the\ncharacteristic of quantum computation to handle belief function more\nconveniently.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 15:57:32 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Zhou", "Qianli", ""], ["Tian", "Guojing", ""], ["Deng", "Yong", ""]]}, {"id": "2107.03959", "submitter": "Jason R.C. Nurse Dr", "authors": "Rahime Belen Saglam and Jason R.C. Nurse and Duncan Hodges", "title": "Privacy Concerns in Chatbot Interactions: When to Trust and When to\n  Worry", "comments": null, "journal-ref": "23rd International Conference on Human-Computer Interaction (HCII\n  2021)", "doi": "10.1007/978-3-030-78642-7_53", "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through advances in their conversational abilities, chatbots have started to\nrequest and process an increasing variety of sensitive personal information.\nThe accurate disclosure of sensitive information is essential where it is used\nto provide advice and support to users in the healthcare and finance sectors.\nIn this study, we explore users' concerns regarding factors associated with the\nuse of sensitive data by chatbot providers. We surveyed a representative sample\nof 491 British citizens. Our results show that the user concerns focus on\ndeleting personal information and concerns about their data's inappropriate\nuse. We also identified that individuals were concerned about losing control\nover their data after a conversation with conversational agents. We found no\neffect from a user's gender or education but did find an effect from the user's\nage, with those over 45 being more concerned than those under 45. We also\nconsidered the factors that engender trust in a chatbot. Our respondents'\nprimary focus was on the chatbot's technical elements, with factors such as the\nresponse quality being identified as the most critical factor. We again found\nno effect from the user's gender or education level; however, when we\nconsidered some social factors (e.g. avatars or perceived 'friendliness'), we\nfound those under 45 years old rated these as more important than those over\n45. The paper concludes with a discussion of these results within the context\nof designing inclusive, digital systems that support a wide range of users.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 16:31:58 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Saglam", "Rahime Belen", ""], ["Nurse", "Jason R. C.", ""], ["Hodges", "Duncan", ""]]}, {"id": "2107.03961", "submitter": "Yuexiang Zhai", "authors": "Yuexiang Zhai, Christina Baek, Zhengyuan Zhou, Jiantao Jiao, Yi Ma", "title": "Computational Benefits of Intermediate Rewards for Hierarchical Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many hierarchical reinforcement learning (RL) applications have empirically\nverified that incorporating prior knowledge in reward design improves\nconvergence speed and practical performance. We attempt to quantify the\ncomputational benefits of hierarchical RL from a planning perspective under\nassumptions about the intermediate state and intermediate rewards frequently\n(but often implicitly) adopted in practice. Our approach reveals a trade-off\nbetween computational complexity and the pursuit of the shortest path in\nhierarchical planning: using intermediate rewards significantly reduces the\ncomputational complexity in finding a successful policy but does not guarantee\nto find the shortest path, whereas using sparse terminal rewards finds the\nshortest path at a significantly higher computational cost. We also corroborate\nour theoretical results with extensive experiments on the MiniGrid environments\nusing Q-learning and other popular deep RL algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 16:39:13 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Zhai", "Yuexiang", ""], ["Baek", "Christina", ""], ["Zhou", "Zhengyuan", ""], ["Jiao", "Jiantao", ""], ["Ma", "Yi", ""]]}, {"id": "2107.03974", "submitter": "Vitchyr H. Pong", "authors": "Vitchyr H. Pong, Ashvin Nair, Laura Smith, Catherine Huang, Sergey\n  Levine", "title": "Offline Meta-Reinforcement Learning with Online Self-Supervision", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-reinforcement learning (RL) can meta-train policies that adapt to new\ntasks with orders of magnitude less data than standard RL, but meta-training\nitself is costly and time-consuming. If we can meta-train on offline data, then\nwe can reuse the same static dataset, labeled once with rewards for different\ntasks, to meta-train policies that adapt to a variety of new tasks at meta-test\ntime. Although this capability would make meta-RL a practical tool for\nreal-world use, offline meta-RL presents additional challenges beyond online\nmeta-RL or standard offline RL settings. Meta-RL learns an exploration strategy\nthat collects data for adapting, and also meta-trains a policy that quickly\nadapts to data from a new task. Since this policy was meta-trained on a fixed,\noffline dataset, it might behave unpredictably when adapting to data collected\nby the learned exploration strategy, which differs systematically from the\noffline data and thus induces distributional shift. We do not want to remove\nthis distributional shift by simply adopting a conservative exploration\nstrategy, because learning an exploration strategy enables an agent to collect\nbetter data for faster adaptation. Instead, we propose a hybrid offline meta-RL\nalgorithm, which uses offline data with rewards to meta-train an adaptive\npolicy, and then collects additional unsupervised online data, without any\nreward labels to bridge this distribution shift. By not requiring reward labels\nfor online collection, this data can be much cheaper to collect. We compare our\nmethod to prior work on offline meta-RL on simulated robot locomotion and\nmanipulation tasks and find that using additional unsupervised online data\ncollection leads to a dramatic improvement in the adaptive capabilities of the\nmeta-trained policies, matching the performance of fully online meta-RL on a\nrange of challenging domains that require generalization to new tasks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 17:01:32 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 21:42:36 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Pong", "Vitchyr H.", ""], ["Nair", "Ashvin", ""], ["Smith", "Laura", ""], ["Huang", "Catherine", ""], ["Levine", "Sergey", ""]]}, {"id": "2107.04000", "submitter": "Siddharth Ancha", "authors": "Siddharth Ancha, Gaurav Pathak, Srinivasa G. Narasimhan, David Held", "title": "Active Safety Envelopes using Light Curtains with Probabilistic\n  Guarantees", "comments": "18 pages, Published at Robotics: Science and Systems (RSS) 2021", "journal-ref": null, "doi": "10.15607/rss.2021.xvii.045", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To safely navigate unknown environments, robots must accurately perceive\ndynamic obstacles. Instead of directly measuring the scene depth with a LiDAR\nsensor, we explore the use of a much cheaper and higher resolution sensor:\nprogrammable light curtains. Light curtains are controllable depth sensors that\nsense only along a surface that a user selects. We use light curtains to\nestimate the safety envelope of a scene: a hypothetical surface that separates\nthe robot from all obstacles. We show that generating light curtains that sense\nrandom locations (from a particular distribution) can quickly discover the\nsafety envelope for scenes with unknown objects. Importantly, we produce\ntheoretical safety guarantees on the probability of detecting an obstacle using\nrandom curtains. We combine random curtains with a machine learning based model\nthat forecasts and tracks the motion of the safety envelope efficiently. Our\nmethod accurately estimates safety envelopes while providing probabilistic\nsafety guarantees that can be used to certify the efficacy of a robot\nperception system to detect and avoid dynamic obstacles. We evaluate our\napproach in a simulated urban driving environment and a real-world environment\nwith moving pedestrians using a light curtain device and show that we can\nestimate safety envelopes efficiently and effectively. Project website:\nhttps://siddancha.github.io/projects/active-safety-envelopes-with-guarantees\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 17:46:05 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Ancha", "Siddharth", ""], ["Pathak", "Gaurav", ""], ["Narasimhan", "Srinivasa G.", ""], ["Held", "David", ""]]}, {"id": "2107.04007", "submitter": "Melissa Roemmele", "authors": "Melissa Roemmele", "title": "Inspiration through Observation: Demonstrating the Influence of\n  Automatically Generated Text on Creative Writing", "comments": "Accepted at ICCC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Getting machines to generate text perceived as creative is a long-pursued\ngoal. A growing body of research directs this goal towards augmenting the\ncreative writing abilities of human authors. In this paper, we pursue this\nobjective by analyzing how observing examples of automatically generated text\ninfluences writing. In particular, we examine a task referred to as sentence\ninfilling, which involves transforming a list of words into a complete\nsentence. We emphasize \"storiability\" as a desirable feature of the resulting\nsentences, where \"storiable\" sentences are those that suggest a story a reader\nwould be curious to hear about. Both humans and an automated system (based on a\nneural language model) performed this sentence infilling task. In one setting,\npeople wrote sentences on their own; in a different setting, people observed\nthe sentences produced by the model while writing their own sentences. Readers\nthen assigned storiability preferences to the resulting sentences in a\nsubsequent evaluation. We find that human-authored sentences were judged as\nmore storiable when authors observed the generated examples, and that\nstoriability increased as authors derived more semantic content from the\nexamples. This result gives evidence of an \"inspiration through observation\"\nparadigm for human-computer collaborative writing, through which human writing\ncan be enhanced by text generation models without directly copying their\noutput.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 17:53:22 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Roemmele", "Melissa", ""]]}, {"id": "2107.04009", "submitter": "Byungsoo Kim", "authors": "Byungsoo Kim, Hangyeol Yu, Dongmin Shin, Youngduck Choi", "title": "Knowledge Transfer by Discriminative Pre-training for Academic\n  Performance Prediction", "comments": "Nominated for the best short paper award of EDM 2021. This is an\n  extended version of the published one", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The needs for precisely estimating a student's academic performance have been\nemphasized with an increasing amount of attention paid to Intelligent Tutoring\nSystem (ITS). However, since labels for academic performance, such as test\nscores, are collected from outside of ITS, obtaining the labels is costly,\nleading to label-scarcity problem which brings challenge in taking machine\nlearning approaches for academic performance prediction. To this end, inspired\nby the recent advancement of pre-training method in natural language processing\ncommunity, we propose DPA, a transfer learning framework with Discriminative\nPre-training tasks for Academic performance prediction. DPA pre-trains two\nmodels, a generator and a discriminator, and fine-tunes the discriminator on\nacademic performance prediction. In DPA's pre-training phase, a sequence of\ninteractions where some tokens are masked is provided to the generator which is\ntrained to reconstruct the original sequence. Then, the discriminator takes an\ninteraction sequence where the masked tokens are replaced by the generator's\noutputs, and is trained to predict the originalities of all tokens in the\nsequence. Compared to the previous state-of-the-art generative pre-training\nmethod, DPA is more sample efficient, leading to fast convergence to lower\nacademic performance prediction error. We conduct extensive experimental\nstudies on a real-world dataset obtained from a multi-platform ITS application\nand show that DPA outperforms the previous state-of-the-art generative\npre-training method with a reduction of 4.05% in mean absolute error and more\nrobust to increased label-scarcity.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 13:02:23 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 03:42:14 GMT"}, {"version": "v3", "created": "Mon, 12 Jul 2021 05:36:22 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kim", "Byungsoo", ""], ["Yu", "Hangyeol", ""], ["Shin", "Dongmin", ""], ["Choi", "Youngduck", ""]]}, {"id": "2107.04013", "submitter": "Jinhyung Park", "authors": "Jinhyung Park, Xinshuo Weng, Yunze Man, Kris Kitani", "title": "Multi-Modality Task Cascade for 3D Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point clouds and RGB images are naturally complementary modalities for 3D\nvisual understanding - the former provides sparse but accurate locations of\npoints on objects, while the latter contains dense color and texture\ninformation. Despite this potential for close sensor fusion, many methods train\ntwo models in isolation and use simple feature concatenation to represent 3D\nsensor data. This separated training scheme results in potentially sub-optimal\nperformance and prevents 3D tasks from being used to benefit 2D tasks that are\noften useful on their own. To provide a more integrated approach, we propose a\nnovel Multi-Modality Task Cascade network (MTC-RCNN) that leverages 3D box\nproposals to improve 2D segmentation predictions, which are then used to\nfurther refine the 3D boxes. We show that including a 2D network between two\nstages of 3D modules significantly improves both 2D and 3D task performance.\nMoreover, to prevent the 3D module from over-relying on the overfitted 2D\npredictions, we propose a dual-head 2D segmentation training and inference\nscheme, allowing the 2nd 3D module to learn to interpret imperfect 2D\nsegmentation predictions. Evaluating our model on the challenging SUN RGB-D\ndataset, we improve upon state-of-the-art results of both single modality and\nfusion networks by a large margin ($\\textbf{+3.8}$ mAP@0.5). Code will be\nreleased $\\href{https://github.com/Divadi/MTC_RCNN}{\\text{here.}}$\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 17:55:01 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Park", "Jinhyung", ""], ["Weng", "Xinshuo", ""], ["Man", "Yunze", ""], ["Kitani", "Kris", ""]]}, {"id": "2107.04026", "submitter": "Ghalib Tahir", "authors": "Attiq ur Rehman, Asad Waqar Malik, Anis ur Rahman, Sohail Iqbal and\n  Ghalib Ahmed Tahir", "title": "CVEH: A Dynamic Framework To Profile Vehicle Movements To Mitigate Hit\n  And Run Cases Using Crowdsourcing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In developed countries like the USA, Germany, and the UK, the security forces\nused highly sophisticated equipment, fast vehicles, drones, and helicopters to\ncatch offenders' vehicles. Whereas, in developing countries with limited\nresources such schemes cannot be utilized due to management cost and other\nconstraints. In this paper, we proposed a framework called CVEH that enables\ndeveloping countries to profile the offender vehicle movements through\ncrowdsourcing technique and act as an early warning system to the law forcing\nagencies. It also engages citizens to play their role in improving security\nconditions. The proposed CVEH framework allows Vehicle-to-Infrastructure (V2I)\ncommunication to monitor the movement of the offender's vehicle and shared its\ninformation with the Command and Control (CC) centre. The CC centre projects\nthe path and engages nearly located law enforcement agencies. CVEH is developed\nand evaluated on android smartphones. Simulations conducted for this study\nexhibit the effectiveness of our framework.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 15:52:28 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Rehman", "Attiq ur", ""], ["Malik", "Asad Waqar", ""], ["Rahman", "Anis ur", ""], ["Iqbal", "Sohail", ""], ["Tahir", "Ghalib Ahmed", ""]]}, {"id": "2107.04034", "submitter": "Deepak Pathak", "authors": "Ashish Kumar, Zipeng Fu, Deepak Pathak, Jitendra Malik", "title": "RMA: Rapid Motor Adaptation for Legged Robots", "comments": "RSS 2021. Webpage at https://ashish-kmr.github.io/rma-legged-robots/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful real-world deployment of legged robots would require them to adapt\nin real-time to unseen scenarios like changing terrains, changing payloads,\nwear and tear. This paper presents Rapid Motor Adaptation (RMA) algorithm to\nsolve this problem of real-time online adaptation in quadruped robots. RMA\nconsists of two components: a base policy and an adaptation module. The\ncombination of these components enables the robot to adapt to novel situations\nin fractions of a second. RMA is trained completely in simulation without using\nany domain knowledge like reference trajectories or predefined foot trajectory\ngenerators and is deployed on the A1 robot without any fine-tuning. We train\nRMA on a varied terrain generator using bioenergetics-inspired rewards and\ndeploy it on a variety of difficult terrains including rocky, slippery,\ndeformable surfaces in environments with grass, long vegetation, concrete,\npebbles, stairs, sand, etc. RMA shows state-of-the-art performance across\ndiverse real-world as well as simulation experiments. Video results at\nhttps://ashish-kmr.github.io/rma-legged-robots/\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 17:59:59 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Kumar", "Ashish", ""], ["Fu", "Zipeng", ""], ["Pathak", "Deepak", ""], ["Malik", "Jitendra", ""]]}, {"id": "2107.04061", "submitter": "Jacob Gardner", "authors": "Misha Padidar, Xinran Zhu, Leo Huang, Jacob R. Gardner, David Bindel", "title": "Scaling Gaussian Processes with Derivative Information Using Variational\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Gaussian processes with derivative information are useful in many settings\nwhere derivative information is available, including numerous Bayesian\noptimization and regression tasks that arise in the natural sciences.\nIncorporating derivative observations, however, comes with a dominating\n$O(N^3D^3)$ computational cost when training on $N$ points in $D$ input\ndimensions. This is intractable for even moderately sized problems. While\nrecent work has addressed this intractability in the low-$D$ setting, the\nhigh-$N$, high-$D$ setting is still unexplored and of great value, particularly\nas machine learning problems increasingly become high dimensional. In this\npaper, we introduce methods to achieve fully scalable Gaussian process\nregression with derivatives using variational inference. Analogous to the use\nof inducing values to sparsify the labels of a training set, we introduce the\nconcept of inducing directional derivatives to sparsify the partial derivative\ninformation of a training set. This enables us to construct a variational\nposterior that incorporates derivative information but whose size depends\nneither on the full dataset size $N$ nor the full dimensionality $D$. We\ndemonstrate the full scalability of our approach on a variety of tasks, ranging\nfrom a high dimensional stellarator fusion regression task to training graph\nconvolutional neural networks on Pubmed using Bayesian optimization.\nSurprisingly, we find that our approach can improve regression performance even\nin settings where only label data is available.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 18:23:59 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Padidar", "Misha", ""], ["Zhu", "Xinran", ""], ["Huang", "Leo", ""], ["Gardner", "Jacob R.", ""], ["Bindel", "David", ""]]}, {"id": "2107.04086", "submitter": "Mohit Bajaj", "authors": "Mohit Bajaj, Lingyang Chu, Zi Yu Xue, Jian Pei, Lanjun Wang, Peter\n  Cho-Ho Lam, Yong Zhang", "title": "Robust Counterfactual Explanations on Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive deployment of Graph Neural Networks (GNNs) in high-stake applications\ngenerates a strong demand for explanations that are robust to noise and align\nwell with human intuition. Most existing methods generate explanations by\nidentifying a subgraph of an input graph that has a strong correlation with the\nprediction. These explanations are not robust to noise because independently\noptimizing the correlation for a single input can easily overfit noise.\nMoreover, they do not align well with human intuition because removing an\nidentified subgraph from an input graph does not necessarily change the\nprediction result. In this paper, we propose a novel method to generate robust\ncounterfactual explanations on GNNs by explicitly modelling the common decision\nlogic of GNNs on similar input graphs. Our explanations are naturally robust to\nnoise because they are produced from the common decision boundaries of a GNN\nthat govern the predictions of many similar input graphs. The explanations also\nalign well with human intuition because removing the set of edges identified by\nan explanation from the input graph changes the prediction significantly.\nExhaustive experiments on many public datasets demonstrate the superior\nperformance of our method.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 19:50:00 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 21:13:20 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Bajaj", "Mohit", ""], ["Chu", "Lingyang", ""], ["Xue", "Zi Yu", ""], ["Pei", "Jian", ""], ["Wang", "Lanjun", ""], ["Lam", "Peter Cho-Ho", ""], ["Zhang", "Yong", ""]]}, {"id": "2107.04092", "submitter": "Dennis Bautembach", "authors": "Dennis Bautembach, Iason Oikonomidis, Antonis Argyros", "title": "Even Faster SNN Simulation with Lazy+Event-driven Plasticity and Shared\n  Atomics", "comments": "Submitted to IEEE-HPEC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two novel optimizations that accelerate clock-based spiking neural\nnetwork (SNN) simulators. The first one targets spike timing dependent\nplasticity (STDP). It combines lazy- with event-driven plasticity and\nefficiently facilitates the computation of pre- and post-synaptic spikes using\nbitfields and integer intrinsics. It offers higher bandwidth than event-driven\nplasticity alone and achieves a 1.5x-2x speedup over our closest competitor.\nThe second optimization targets spike delivery. We partition our graph\nrepresentation in a way that bounds the number of neurons that need be updated\nat any given time which allows us to perform said update in shared memory\ninstead of global memory. This is 2x-2.5x faster than our closest competitor.\nBoth optimizations represent the final evolutionary stages of years of\niteration on STDP and spike delivery inside \"Spice\" (/spaIk/), our state of the\nart SNN simulator. The proposed optimizations are not exclusive to our graph\nrepresentation or pipeline but are applicable to a multitude of simulator\ndesigns. We evaluate our performance on three well-established models and\ncompare ourselves against three other state of the art simulators.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 20:13:54 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Bautembach", "Dennis", ""], ["Oikonomidis", "Iason", ""], ["Argyros", "Antonis", ""]]}, {"id": "2107.04125", "submitter": "Fariba Irany", "authors": "Fariba Afrin Irany, Arnav Iyer, Rubenia Borge Flores, Armin R. Mikler", "title": "The Multi-phase spatial meta-heuristic algorithm for public health\n  emergency transportation", "comments": "17 pages, 3 figures, 3 tables, Journals", "journal-ref": "International Journal of Scientific Research & Engineering Trends\n  Volume 7, Issue 4, July-Aug-2020, ISSN (Online): 2395-566X", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The delivery of Medical Countermeasures(MCMs) for mass prophylaxis in the\ncase of a bio-terrorist attack is an active research topic that has interested\nthe research community over the past decades. The objective of this study is to\ndesign an efficient algorithm for the Receive Reload and Store Problem(RSS) in\nwhich we aim to find feasible routes to deliver MCMs to a target population\nconsidering time, physical, and human resources, and capacity limitations. For\ndoing this, we adapt the p-median problem to the POD-based emergency response\nplanning procedures and propose an efficient algorithm solution to perform the\np-median in reasonable computational time. We present RE-PLAN, the Response\nPLan Analyzer system that contains some RSS solutions developed at The Center\nfor Computational Epidemiology and Response Analysis (CeCERA) at the University\nof North Texas. Finally, we analyze a study case where we show how the\ncomputational performance of the algorithm can impact the process of decision\nmaking and emergency planning in the short and long terms.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 22:34:42 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Irany", "Fariba Afrin", ""], ["Iyer", "Arnav", ""], ["Flores", "Rubenia Borge", ""], ["Mikler", "Armin R.", ""]]}, {"id": "2107.04132", "submitter": "Peter Jansen", "authors": "Peter A Jansen", "title": "A Systematic Survey of Text Worlds as Embodied Natural Language\n  Environments", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Text Worlds are virtual environments for embodied agents that, unlike 2D or\n3D environments, are rendered exclusively using textual descriptions. These\nenvironments offer an alternative to higher-fidelity 3D environments due to\ntheir low barrier to entry, providing the ability to study semantics,\ncompositional inference, and other high-level tasks with rich high-level action\nspaces while controlling for perceptual input. This systematic survey outlines\nrecent developments in tooling, environments, and agent modeling for Text\nWorlds, while examining recent trends in knowledge graphs, common sense\nreasoning, transfer learning of Text World performance to higher-fidelity\nenvironments, as well as near-term development targets that, once achieved,\nmake Text Worlds an attractive general research paradigm for natural language\nprocessing.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 22:15:16 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Jansen", "Peter A", ""]]}, {"id": "2107.04139", "submitter": "Sirui Li", "authors": "Sirui Li, Zhongxia Yan, Cathy Wu", "title": "Learning to Delegate for Large-scale Vehicle Routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle routing problems (VRPs) are a class of combinatorial problems with\nwide practical applications. While previous heuristic or learning-based works\nachieve decent solutions on small problem instances of up to 100 customers,\ntheir performance does not scale to large problems. This article presents a\nnovel learning-augmented local search algorithm to solve large-scale VRP. The\nmethod iteratively improves the solution by identifying appropriate subproblems\nand $\\textit{delegating}$ their improvement to a black box subsolver. At each\nstep, we leverage spatial locality to consider only a linear number of\nsubproblems, rather than exponential. We frame subproblem selection as a\nregression problem and train a Transformer on a generated training set of\nproblem instances. We show that our method achieves state-of-the-art\nperformance, with a speed-up of up to 15 times over strong baselines, on VRPs\nwith sizes ranging from 500 to 3000.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 22:51:58 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Li", "Sirui", ""], ["Yan", "Zhongxia", ""], ["Wu", "Cathy", ""]]}, {"id": "2107.04144", "submitter": "Alexander Wong", "authors": "Saad Abbasi, Mohammad Javad Shafiee, Ellick Chan, and Alexander Wong", "title": "Does Form Follow Function? An Empirical Exploration of the Impact of\n  Deep Neural Network Architecture Design on Hardware-Specific Acceleration", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fine-grained relationship between form and function with respect to deep\nneural network architecture design and hardware-specific acceleration is one\narea that is not well studied in the research literature, with form often\ndictated by accuracy as opposed to hardware function. In this study, a\ncomprehensive empirical exploration is conducted to investigate the impact of\ndeep neural network architecture design on the degree of inference speedup that\ncan be achieved via hardware-specific acceleration. More specifically, we\nempirically study the impact of a variety of commonly used macro-architecture\ndesign patterns across different architectural depths through the lens of\nOpenVINO microprocessor-specific and GPU-specific acceleration. Experimental\nresults showed that while leveraging hardware-specific acceleration achieved an\naverage inference speed-up of 380%, the degree of inference speed-up varied\ndrastically depending on the macro-architecture design pattern, with the\ngreatest speedup achieved on the depthwise bottleneck convolution design\npattern at 550%. Furthermore, we conduct an in-depth exploration of the\ncorrelation between FLOPs requirement, level 3 cache efficacy, and network\nlatency with increasing architectural depth and width. Finally, we analyze the\ninference time reductions using hardware-specific acceleration when compared to\nnative deep learning frameworks across a wide variety of hand-crafted deep\nconvolutional neural network architecture designs as well as ones found via\nneural architecture search strategies. We found that the DARTS-derived\narchitecture to benefit from the greatest improvement from hardware-specific\nsoftware acceleration (1200%) while the depthwise bottleneck convolution-based\nMobileNet-V2 to have the lowest overall inference time of around 2.4 ms.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 23:05:39 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Abbasi", "Saad", ""], ["Shafiee", "Mohammad Javad", ""], ["Chan", "Ellick", ""], ["Wong", "Alexander", ""]]}, {"id": "2107.04152", "submitter": "Han He", "authors": "Han He, Jinho D. Choi", "title": "Levi Graph AMR Parser using Heterogeneous Attention", "comments": "Accepted in IWPT 2021: The 17th International Conference on Parsing\n  Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coupled with biaffine decoders, transformers have been effectively adapted to\ntext-to-graph transduction and achieved state-of-the-art performance on AMR\nparsing. Many prior works, however, rely on the biaffine decoder for either or\nboth arc and label predictions although most features used by the decoder may\nbe learned by the transformer already. This paper presents a novel approach to\nAMR parsing by combining heterogeneous data (tokens, concepts, labels) as one\ninput to a transformer to learn attention, and use only attention matrices from\nthe transformer to predict all elements in AMR graphs (concepts, arcs, labels).\nAlthough our models use significantly fewer parameters than the previous\nstate-of-the-art graph parser, they show similar or better accuracy on AMR 2.0\nand 3.0.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 00:06:17 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["He", "Han", ""], ["Choi", "Jinho D.", ""]]}, {"id": "2107.04164", "submitter": "Kesav Viswanadha", "authors": "Kesav Viswanadha, Edward Kim, Francis Indaheng, Daniel J. Fremont,\n  Sanjit A. Seshia", "title": "Parallel and Multi-Objective Falsification with Scenic and VerifAI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Falsification has emerged as an important tool for simulation-based\nverification of autonomous systems. In this paper, we present extensions to the\nScenic scenario specification language and VerifAI toolkit that improve the\nscalability of sampling-based falsification methods by using parallelism and\nextend falsification to multi-objective specifications. We first present a\nparallelized framework that is interfaced with both the simulation and sampling\ncapabilities of Scenic and the falsification capabilities of VerifAI, reducing\nthe execution time bottleneck inherently present in simulation-based testing.\nWe then present an extension of VerifAI's falsification algorithms to support\nmulti-objective optimization during sampling, using the concept of rulebooks to\nspecify a preference ordering over multiple metrics that can be used to guide\nthe counterexample search process. Lastly, we evaluate the benefits of these\nextensions with a comprehensive set of benchmarks written in the Scenic\nlanguage.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 01:08:49 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Viswanadha", "Kesav", ""], ["Kim", "Edward", ""], ["Indaheng", "Francis", ""], ["Fremont", "Daniel J.", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "2107.04169", "submitter": "Roni Stern", "authors": "Brendan Juba, Hai S. Le, Roni Stern", "title": "Safe Learning of Lifted Action Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating a domain model, even for classical, domain-independent planning, is\na notoriously hard knowledge-engineering task. A natural approach to solve this\nproblem is to learn a domain model from observations. However, model learning\napproaches frequently do not provide safety guarantees: the learned model may\nassume actions are applicable when they are not, and may incorrectly capture\nactions' effects. This may result in generating plans that will fail when\nexecuted. In some domains such failures are not acceptable, due to the cost of\nfailure or inability to replan online after failure. In such settings, all\nlearning must be done offline, based on some observations collected, e.g., by\nsome other agents or a human. Through this learning, the task is to generate a\nplan that is guaranteed to be successful. This is called the model-free\nplanning problem. Prior work proposed an algorithm for solving the model-free\nplanning problem in classical planning. However, they were limited to learning\ngrounded domains, and thus they could not scale. We generalize this prior work\nand propose the first safe model-free planning algorithm for lifted domains. We\nprove the correctness of our approach, and provide a statistical analysis\nshowing that the number of trajectories needed to solve future problems with\nhigh probability is linear in the potential size of the domain model. We also\npresent experiments on twelve IPC domains showing that our approach is able to\nlearn the real action model in all cases with at most two trajectories.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 01:24:01 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Juba", "Brendan", ""], ["Le", "Hai S.", ""], ["Stern", "Roni", ""]]}, {"id": "2107.04228", "submitter": "Liangming Chen", "authors": "Mei Liu, Liangming Chen, Xiaohao Du, Long Jin, and Mingsheng Shang", "title": "Activated Gradients for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks often suffer from poor performance or even training\nfailure due to the ill-conditioned problem, the vanishing/exploding gradient\nproblem, and the saddle point problem. In this paper, a novel method by acting\nthe gradient activation function (GAF) on the gradient is proposed to handle\nthese challenges. Intuitively, the GAF enlarges the tiny gradients and\nrestricts the large gradient. Theoretically, this paper gives conditions that\nthe GAF needs to meet, and on this basis, proves that the GAF alleviates the\nproblems mentioned above. In addition, this paper proves that the convergence\nrate of SGD with the GAF is faster than that without the GAF under some\nassumptions. Furthermore, experiments on CIFAR, ImageNet, and PASCAL visual\nobject classes confirm the GAF's effectiveness. The experimental results also\ndemonstrate that the proposed method is able to be adopted in various deep\nneural networks to improve their performance. The source code is publicly\navailable at\nhttps://github.com/LongJin-lab/Activated-Gradients-for-Deep-Neural-Networks.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 06:00:55 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Liu", "Mei", ""], ["Chen", "Liangming", ""], ["Du", "Xiaohao", ""], ["Jin", "Long", ""], ["Shang", "Mingsheng", ""]]}, {"id": "2107.04231", "submitter": "Vinod K Kurmi", "authors": "Vinod K Kurmi and Venkatesh K Subramanian and Vinay P. Namboodiri", "title": "Exploring Dropout Discriminator for Domain Adaptation", "comments": "This work is an extension of our BMVC-2019 paper (arXiv:1907.10628)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Adaptation of a classifier to new domains is one of the challenging problems\nin machine learning. This has been addressed using many deep and non-deep\nlearning based methods. Among the methodologies used, that of adversarial\nlearning is widely applied to solve many deep learning problems along with\ndomain adaptation. These methods are based on a discriminator that ensures\nsource and target distributions are close. However, here we suggest that rather\nthan using a point estimate obtaining by a single discriminator, it would be\nuseful if a distribution based on ensembles of discriminators could be used to\nbridge this gap. This could be achieved using multiple classifiers or using\ntraditional ensemble methods. In contrast, we suggest that a Monte Carlo\ndropout based ensemble discriminator could suffice to obtain the distribution\nbased discriminator. Specifically, we propose a curriculum based dropout\ndiscriminator that gradually increases the variance of the sample based\ndistribution and the corresponding reverse gradients are used to align the\nsource and target feature representations. An ensemble of discriminators helps\nthe model to learn the data distribution efficiently. It also provides a better\ngradient estimates to train the feature extractor. The detailed results and\nthorough ablation analysis show that our model outperforms state-of-the-art\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 06:11:34 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Kurmi", "Vinod K", ""], ["Subramanian", "Venkatesh K", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "2107.04244", "submitter": "Yao Chen", "authors": "Xinheng Liu, Yao Chen, Cong Hao, Ashutosh Dhar, Deming Chen", "title": "WinoCNN: Kernel Sharing Winograd Systolic Array for Efficient\n  Convolutional Neural Network Acceleration on FPGAs", "comments": "Published in the proceedings of ASAP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The combination of Winograd's algorithm and systolic array architecture has\ndemonstrated the capability of improving DSP efficiency in accelerating\nconvolutional neural networks (CNNs) on FPGA platforms. However, handling\narbitrary convolution kernel sizes in FPGA-based Winograd processing elements\nand supporting efficient data access remain underexplored. In this work, we are\nthe first to propose an optimized Winograd processing element (WinoPE), which\ncan naturally support multiple convolution kernel sizes with the same amount of\ncomputing resources and maintains high runtime DSP efficiency. Using the\nproposed WinoPE, we construct a highly efficient systolic array accelerator,\ntermed WinoCNN. We also propose a dedicated memory subsystem to optimize the\ndata access. Based on the accelerator architecture, we build accurate resource\nand performance modeling to explore optimal accelerator configurations under\ndifferent resource constraints. We implement our proposed accelerator on\nmultiple FPGAs, which outperforms the state-of-the-art designs in terms of both\nthroughput and DSP efficiency. Our implementation achieves DSP efficiency up to\n1.33 GOPS/DSP and throughput up to 3.1 TOPS with the Xilinx ZCU102 FPGA. These\nare 29.1\\% and 20.0\\% better than the best solutions reported previously,\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 06:37:47 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Liu", "Xinheng", ""], ["Chen", "Yao", ""], ["Hao", "Cong", ""], ["Dhar", "Ashutosh", ""], ["Chen", "Deming", ""]]}, {"id": "2107.04303", "submitter": "Utkarsh Soni", "authors": "Sriram Gopalakrishnan, Utkarsh Soni, Tung Thai, Panagiotis\n  Lymperopoulos, Matthias Scheutz, Subbarao Kambhampati", "title": "Integrating Planning, Execution and Monitoring in the presence of Open\n  World Novelties: Case Study of an Open World Monopoly Solver", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The game of monopoly is an adversarial multi-agent domain where there is no\nfixed goal other than to be the last player solvent, There are useful subgoals\nlike monopolizing sets of properties, and developing them. There is also a lot\nof randomness from dice rolls, card-draws, and adversaries' strategies. This\nunpredictability is made worse when unknown novelties are added during\ngameplay. Given these challenges, Monopoly was one of the test beds chosen for\nthe DARPA-SAILON program which aims to create agents that can detect and\naccommodate novelties. To handle the game complexities, we developed an agent\nthat eschews complete plans, and adapts it's policy online as the game evolves.\nIn the most recent independent evaluation in the SAILON program, our agent was\nthe best performing agent on most measures. We herein present our approach and\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 08:26:28 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Gopalakrishnan", "Sriram", ""], ["Soni", "Utkarsh", ""], ["Thai", "Tung", ""], ["Lymperopoulos", "Panagiotis", ""], ["Scheutz", "Matthias", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "2107.04309", "submitter": "Rafael Poyiadzi", "authors": "Rafael Poyiadzi, Xavier Renard, Thibault Laugel, Raul\n  Santos-Rodriguez, Marcin Detyniecki", "title": "Understanding surrogate explanations: the interplay between complexity,\n  fidelity and coverage", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyses the fundamental ingredients behind surrogate explanations\nto provide a better understanding of their inner workings. We start our\nexposition by considering global surrogates, describing the trade-off between\ncomplexity of the surrogate and fidelity to the black-box being modelled. We\nshow that transitioning from global to local - reducing coverage - allows for\nmore favourable conditions on the Pareto frontier of fidelity-complexity of a\nsurrogate. We discuss the interplay between complexity, fidelity and coverage,\nand consider how different user needs can lead to problem formulations where\nthese are either constraints or penalties. We also present experiments that\ndemonstrate how the local surrogate interpretability procedure can be made\ninteractive and lead to better explanations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 08:43:31 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Poyiadzi", "Rafael", ""], ["Renard", "Xavier", ""], ["Laugel", "Thibault", ""], ["Santos-Rodriguez", "Raul", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2107.04326", "submitter": "Floris Naber", "authors": "Floris Naber", "title": "Semantic Segmentation on Multiple Visual Domains", "comments": "Graduation project report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Semantic segmentation models only perform well on the domain they are trained\non and datasets for training are scarce and often have a small label-spaces,\nbecause the pixel level annotations required are expensive to make. Thus\ntraining models on multiple existing domains is desired to increase the output\nlabel-space. Current research shows that there is potential to improve accuracy\nacross datasets by using multi-domain training, but this has not yet been\nsuccessfully extended to datasets of three different non-overlapping domains\nwithout manual labelling. In this paper a method for this is proposed for the\ndatasets Cityscapes, SUIM and SUN RGB-D, by creating a label-space that spans\nall classes of the datasets. Duplicate classes are merged and discrepant\ngranularity is solved by keeping classes separate. Results show that accuracy\nof the multi-domain model has higher accuracy than all baseline models\ntogether, if hardware performance is equalized, as resources are not limitless,\nshowing that models benefit from additional data even from domains that have\nnothing in common.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 09:34:51 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Naber", "Floris", ""]]}, {"id": "2107.04333", "submitter": "Jingwei Zhang", "authors": "Jingwei Zhang, Bin Zi, Xiaoyu Ge", "title": "Attend2Pack: Bin Packing through Deep Reinforcement Learning with\n  Attention", "comments": "Reinforcement Learning for Real Life (RL4RealLife) Workshop in the\n  38th International Conference on Machine Learning, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper seeks to tackle the bin packing problem (BPP) through a learning\nperspective. Building on self-attention-based encoding and deep reinforcement\nlearning algorithms, we propose a new end-to-end learning model for this task\nof interest. By decomposing the combinatorial action space, as well as\nutilizing a new training technique denoted as prioritized oversampling, which\nis a general scheme to speed up on-policy learning, we achieve state-of-the-art\nperformance in a range of experimental settings. Moreover, although the\nproposed approach attend2pack targets offline-BPP, we strip our method down to\nthe strict online-BPP setting where it is also able to achieve state-of-the-art\nperformance. With a set of ablation studies as well as comparisons against a\nrange of previous works, we hope to offer as a valid baseline approach to this\nfield of study.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 10:00:30 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Zhang", "Jingwei", ""], ["Zi", "Bin", ""], ["Ge", "Xiaoyu", ""]]}, {"id": "2107.04347", "submitter": "Gilles Falquet", "authors": "Vincenzo Daponte and Gilles Falquet", "title": "An ontology for the formalization and visualization of scientific\n  knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The construction of an ontology of scientific knowledge objects, presented\nhere, is part of the development of an approach oriented towards the\nvisualization of scientific knowledge. It is motivated by the fact that the\nconcepts that are used to organize scientific knowledge (theorem, law,\nexperience, proof, etc.) appear in existing ontologies but that none of these\nontologies is centered on this topic and presents them in a simple and easily\nunderstandable organization. This ontology has been constructed by 1) selecting\nconcepts that appear in high level ontologies or in ontologies of knowledge\nobjects of specific fields and 2) by interviewing scientists in different\nfields. We have aligned this ontology with some of the sources used, which has\nallowed us to verify its consistency with respect to them. The validation of\nthe ontology consists in using it to formalize knowledge from various sources,\nwhich we have begun to do in the field of physics.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 10:33:45 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 18:00:17 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Daponte", "Vincenzo", ""], ["Falquet", "Gilles", ""]]}, {"id": "2107.04362", "submitter": "Chenhao Wang", "authors": "Chenhao Wang, Hongxiang Cai, Yuxin Zou, Yichao Xiong", "title": "RGB Stream Is Enough for Temporal Action Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art temporal action detectors to date are based on two-stream\ninput including RGB frames and optical flow. Although combining RGB frames and\noptical flow boosts performance significantly, optical flow is a hand-designed\nrepresentation which not only requires heavy computation, but also makes it\nmethodologically unsatisfactory that two-stream methods are often not learned\nend-to-end jointly with the flow. In this paper, we argue that optical flow is\ndispensable in high-accuracy temporal action detection and image level data\naugmentation (ILDA) is the key solution to avoid performance degradation when\noptical flow is removed. To evaluate the effectiveness of ILDA, we design a\nsimple yet efficient one-stage temporal action detector based on single RGB\nstream named DaoTAD. Our results show that when trained with ILDA, DaoTAD has\ncomparable accuracy with all existing state-of-the-art two-stream detectors\nwhile surpassing the inference speed of previous methods by a large margin and\nthe inference speed is astounding 6668 fps on GeForce GTX 1080 Ti. Code is\navailable at \\url{https://github.com/Media-Smart/vedatad}.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 11:10:11 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Wang", "Chenhao", ""], ["Cai", "Hongxiang", ""], ["Zou", "Yuxin", ""], ["Xiong", "Yichao", ""]]}, {"id": "2107.04378", "submitter": "Stefan Bischof", "authors": "Stefan Bischof, Gottfried Schenner", "title": "Rail Topology Ontology: A Rail Infrastructure Base Ontology", "comments": "accepted at the International Semantic Web Conference'21 (ISWC 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Engineering projects for railway infrastructure typically involve many\nsubsystems which need consistent views of the planned and built infrastructure\nand its underlying topology. Consistency is typically ensured by exchanging and\nverifying data between tools using XML-based data formats and UML-based\nobject-oriented models. A tighter alignment of these data representations via a\ncommon topology model could decrease the development effort of railway\ninfrastructure engineering tools. A common semantic model is also a\nprerequisite for the successful adoption of railway knowledge graphs. Based on\nthe RailTopoModel standard, we developed the Rail Topology Ontology as a model\nto represent core features of railway infrastructures in a standard-compliant\nmanner. This paper describes the ontology and its development method, and\ndiscusses its suitability for integrating data of railway engineering systems\nand other sources in a knowledge graph.\n  With the Rail Topology Ontology, software engineers and knowledge scientists\nhave a standard-based ontology for representing railway topologies to integrate\ndisconnected data sources. We use the Rail Topology Ontology for our rail\nknowledge graph and plan to extend it by rail infrastructure ontologies derived\nfrom existing data exchange standards, since many such standards use the same\nbase model as the presented ontology, viz., RailTopoModel.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 12:03:50 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Bischof", "Stefan", ""], ["Schenner", "Gottfried", ""]]}, {"id": "2107.04386", "submitter": "Shaowu Chen", "authors": "Shaowu Chen, Jiahao Zhou, Weize Sun, Lei Huang", "title": "Joint Matrix Decomposition for Deep Convolutional Neural Networks\n  Compression", "comments": "Code is publicly available on GitHub:\n  https://github.com/ShaowuChen/JointSVD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) with a large number of parameters\nrequires huge computational resources, which has limited the application of\nCNNs on resources constrained appliances. Decomposition-based methods,\ntherefore, have been utilized to compress CNNs in recent years. However, since\nthe compression factor and performance are negatively correlated, the\nstate-of-the-art works either suffer from severe performance degradation or\nhave limited low compression factors. To overcome these problems, unlike\nprevious works compressing layers separately, we propose to compress CNNs and\nalleviate performance degradation via joint matrix decomposition. The idea is\ninspired by the fact that there are lots of repeated modules in CNNs, and by\nprojecting weights with the same structures into the same subspace, networks\ncan be further compressed and even accelerated. In particular, three joint\nmatrix decomposition schemes are developed, and the corresponding optimization\napproaches based on Singular Values Decomposition are proposed. Extensive\nexperiments are conducted across three challenging compact CNNs and 3 benchmark\ndata sets to demonstrate the superior performance of our proposed algorithms.\nAs a result, our methods can compress the size of ResNet-34 by 22x with\nslighter accuracy degradation compared with several state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 12:32:10 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 03:06:42 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Chen", "Shaowu", ""], ["Zhou", "Jiahao", ""], ["Sun", "Weize", ""], ["Huang", "Lei", ""]]}, {"id": "2107.04388", "submitter": "Jessica Cooper", "authors": "Jessica Cooper, In Hwa Um, Ognjen Arandjelovi\\'c and David J Harrison", "title": "Hoechst Is All You Need: Lymphocyte Classification with Deep Learning", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiplex immunofluorescence and immunohistochemistry benefit patients by\nallowing cancer pathologists to identify several proteins expressed on the\nsurface of cells, enabling cell classification, better understanding of the\ntumour micro-environment, more accurate diagnoses, prognoses, and tailored\nimmunotherapy based on the immune status of individual patients. However, they\nare expensive and time consuming processes which require complex staining and\nimaging techniques by expert technicians. Hoechst staining is much cheaper and\neasier to perform, but is not typically used in this case as it binds to DNA\nrather than to the proteins targeted by immunofluorescent techniques, and it\nwas not previously thought possible to differentiate cells expressing these\nproteins based only on DNA morphology. In this work we show otherwise, training\na deep convolutional neural network to identify cells expressing three proteins\n(T lymphocyte markers CD3 and CD8, and the B lymphocyte marker CD20) with\ngreater than 90% precision and recall, from Hoechst 33342 stained tissue only.\nOur model learns previously unknown morphological features associated with\nexpression of these proteins which can be used to accurately differentiate\nlymphocyte subtypes for use in key prognostic metrics such as assessment of\nimmune cell infiltration,and thereby predict and improve patient outcomes\nwithout the need for costly multiplex immunofluorescence.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 12:33:22 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 13:43:59 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Cooper", "Jessica", ""], ["Um", "In Hwa", ""], ["Arandjelovi\u0107", "Ognjen", ""], ["Harrison", "David J", ""]]}, {"id": "2107.04409", "submitter": "Raphael Cohen", "authors": "Raphael Y. Cohen, Aaron D. Sodickson", "title": "An Orchestration Platform that Puts Radiologists in the Driver's Seat of\n  AI Innovation: A Methodological Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.DC eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current AI-driven research in radiology requires resources and expertise that\nare often inaccessible to small and resource-limited labs. The clinicians who\nare able to participate in AI research are frequently well-funded,\nwell-staffed, and either have significant experience with AI and computing, or\nhave access to colleagues or facilities that do. Current imaging data is\nclinician-oriented and is not easily amenable to machine learning initiatives,\nresulting in inefficient, time consuming, and costly efforts that rely upon a\ncrew of data engineers and machine learning scientists, and all too often\npreclude radiologists from driving AI research and innovation. We present the\nsystem and methodology we have developed to address infrastructure and platform\nneeds, while reducing the staffing and resource barriers to entry. We emphasize\na data-first and modular approach that streamlines the AI development and\ndeployment process while providing efficient and familiar interfaces for\nradiologists, such that they can be the drivers of new AI innovations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 20:32:14 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Cohen", "Raphael Y.", ""], ["Sodickson", "Aaron D.", ""]]}, {"id": "2107.04427", "submitter": "Tom Vermeire", "authors": "Tom Vermeire and Thibault Laugel and Xavier Renard and David Martens\n  and Marcin Detyniecki", "title": "How to choose an Explainability Method? Towards a Methodical\n  Implementation of XAI in Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability is becoming an important requirement for organizations that\nmake use of automated decision-making due to regulatory initiatives and a shift\nin public awareness. Various and significantly different algorithmic methods to\nprovide this explainability have been introduced in the field, but the existing\nliterature in the machine learning community has paid little attention to the\nstakeholder whose needs are rather studied in the human-computer interface\ncommunity. Therefore, organizations that want or need to provide this\nexplainability are confronted with the selection of an appropriate method for\ntheir use case. In this paper, we argue there is a need for a methodology to\nbridge the gap between stakeholder needs and explanation methods. We present\nour ongoing work on creating this methodology to help data scientists in the\nprocess of providing explainability to stakeholders. In particular, our\ncontributions include documents used to characterize XAI methods and user\nrequirements (shown in Appendix), which our methodology builds upon.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 13:22:58 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Vermeire", "Tom", ""], ["Laugel", "Thibault", ""], ["Renard", "Xavier", ""], ["Martens", "David", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2107.04438", "submitter": "Timo Bertram", "authors": "Timo Bertram, Johannes F\\\"urnkranz, Martin M\\\"uller", "title": "A Comparison of Contextual and Non-Contextual Preference Ranking for Set\n  Addition Problems", "comments": "arXiv admin note: substantial text overlap with arXiv:2105.11864", "journal-ref": "SubSetML: Subset Selection in Machine Learning: From Theory to\n  Practice @ ICML 2021", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the problem of evaluating the addition of elements to\na set. This problem is difficult, because it can, in the general case, not be\nreduced to unconditional preferences between the choices. Therefore, we model\npreferences based on the context of the decision. We discuss and compare two\ndifferent Siamese network architectures for this task: a twin network that\ncompares the two sets resulting after the addition, and a triplet network that\nmodels the contribution of each candidate to the existing set. We evaluate the\ntwo settings on a real-world task; learning human card preferences for deck\nbuilding in the collectible card game Magic: The Gathering. We show that the\ntriplet approach achieves a better result than the twin network and that both\noutperform previous results on this task.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 13:33:16 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Bertram", "Timo", ""], ["F\u00fcrnkranz", "Johannes", ""], ["M\u00fcller", "Martin", ""]]}, {"id": "2107.04452", "submitter": "Xiaoxue Zang", "authors": "Xiaoxue Zang, Ying Xu, Jindong Chen", "title": "Multimodal Icon Annotation For Mobile Applications", "comments": "11 pages, MobileHCI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Annotating user interfaces (UIs) that involves localization and\nclassification of meaningful UI elements on a screen is a critical step for\nmany mobile applications such as screen readers and voice control of devices.\nAnnotating object icons, such as menu, search, and arrow backward, is\nespecially challenging due to the lack of explicit labels on screens, their\nsimilarity to pictures, and their diverse shapes. Existing studies either use\nview hierarchy or pixel based methods to tackle the task. Pixel based\napproaches are more popular as view hierarchy features on mobile platforms are\noften incomplete or inaccurate, however it leaves out instructional information\nin the view hierarchy such as resource-ids or content descriptions. We propose\na novel deep learning based multi-modal approach that combines the benefits of\nboth pixel and view hierarchy features as well as leverages the\nstate-of-the-art object detection techniques. In order to demonstrate the\nutility provided, we create a high quality UI dataset by manually annotating\nthe most commonly used 29 icons in Rico, a large scale mobile design dataset\nconsisting of 72k UI screenshots. The experimental results indicate the\neffectiveness of our multi-modal approach. Our model not only outperforms a\nwidely used object classification baseline but also pixel based object\ndetection models. Our study sheds light on how to combine view hierarchy with\npixel features for annotating UI elements.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 13:57:37 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Zang", "Xiaoxue", ""], ["Xu", "Ying", ""], ["Chen", "Jindong", ""]]}, {"id": "2107.04457", "submitter": "Stepan Makarenko", "authors": "Stepan Makarenko, Dmitry Sorokin, Alexander Ulanov, A. I. Lvovsky", "title": "Aligning an optical interferometer with beam divergence control and\n  continuous action space", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is finding its way to real-world problem application,\ntransferring from simulated environments to physical setups. In this work, we\nimplement vision-based alignment of an optical Mach-Zehnder interferometer with\na confocal telescope in one arm, which controls the diameter and divergence of\nthe corresponding beam. We use a continuous action space; exponential scaling\nenables us to handle actions within a range of over two orders of magnitude.\nOur agent trains only in a simulated environment with domain randomizations. In\nan experimental evaluation, the agent significantly outperforms an existing\nsolution and a human expert.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 14:23:01 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Makarenko", "Stepan", ""], ["Sorokin", "Dmitry", ""], ["Ulanov", "Alexander", ""], ["Lvovsky", "A. I.", ""]]}, {"id": "2107.04485", "submitter": "Sampo Kuutti", "authors": "Sampo Kuutti, Saber Fallah, Richard Bowden", "title": "Adversarial Mixture Density Networks: Learning to Drive Safely from\n  Collision Data", "comments": "Accepted in IEEE Intelligent Transportation Systems Conference (ITSC)\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning has been widely used to learn control policies for\nautonomous driving based on pre-recorded data. However, imitation learning\nbased policies have been shown to be susceptible to compounding errors when\nencountering states outside of the training distribution. Further, these agents\nhave been demonstrated to be easily exploitable by adversarial road users\naiming to create collisions. To overcome these shortcomings, we introduce\nAdversarial Mixture Density Networks (AMDN), which learns two distributions\nfrom separate datasets. The first is a distribution of safe actions learned\nfrom a dataset of naturalistic human driving. The second is a distribution\nrepresenting unsafe actions likely to lead to collision, learned from a dataset\nof collisions. During training, we leverage these two distributions to provide\nan additional loss based on the similarity of the two distributions. By\npenalising the safe action distribution based on its similarity to the unsafe\naction distribution when training on the collision dataset, a more robust and\nsafe control policy is obtained. We demonstrate the proposed AMDN approach in a\nvehicle following use-case, and evaluate under naturalistic and adversarial\ntesting environments. We show that despite its simplicity, AMDN provides\nsignificant benefits for the safety of the learned control policy, when\ncompared to pure imitation learning or standard mixture density network\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 15:16:30 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Kuutti", "Sampo", ""], ["Fallah", "Saber", ""], ["Bowden", "Richard", ""]]}, {"id": "2107.04487", "submitter": "Sampo Kuutti", "authors": "Sampo Kuutti, Saber Fallah, Richard Bowden", "title": "ARC: Adversarially Robust Control Policies for Autonomous Vehicles", "comments": "Accepted in IEEE Intelligent Transportation Systems Conference (ITSC)\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have demonstrated their capability to learn control\npolicies for a variety of tasks. However, these neural network-based policies\nhave been shown to be susceptible to exploitation by adversarial agents.\nTherefore, there is a need to develop techniques to learn control policies that\nare robust against adversaries. We introduce Adversarially Robust Control\n(ARC), which trains the protagonist policy and the adversarial policy\nend-to-end on the same loss. The aim of the protagonist is to maximise this\nloss, whilst the adversary is attempting to minimise it. We demonstrate the\nproposed ARC training in a highway driving scenario, where the protagonist\ncontrols the follower vehicle whilst the adversary controls the lead vehicle.\nBy training the protagonist against an ensemble of adversaries, it learns a\nsignificantly more robust control policy, which generalises to a variety of\nadversarial strategies. The approach is shown to reduce the amount of\ncollisions against new adversaries by up to 90.25%, compared to the original\npolicy. Moreover, by utilising an auxiliary distillation loss, we show that the\nfine-tuned control policy shows no drop in performance across its original\ntraining distribution.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 15:22:29 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Kuutti", "Sampo", ""], ["Fallah", "Saber", ""], ["Bowden", "Richard", ""]]}, {"id": "2107.04491", "submitter": "Ran Liu", "authors": "Ran Liu (1 and 2), Joseph L. Greenstein (1 and 2), James C. Fackler\n  (3), Jules Bergmann (3), Melania M. Bembea (3 and 4), Raimond L. Winslow (1\n  and 2) ((1) Institute for Computational Medicine, the Johns Hopkins\n  University, (2) Department of Biomedical Engineering, the Johns Hopkins\n  University School of Medicine and Whiting School of Engineering, (3)\n  Department of Anesthesiology and Critical Care Medicine, the Johns Hopkins\n  University, (4) Department of Pediatrics, the Johns Hopkins University School\n  of Medicine)", "title": "Offline reinforcement learning with uncertainty for treatment strategies\n  in sepsis", "comments": "25 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Guideline-based treatment for sepsis and septic shock is difficult because\nsepsis is a disparate range of life-threatening organ dysfunctions whose\npathophysiology is not fully understood. Early intervention in sepsis is\ncrucial for patient outcome, yet those interventions have adverse effects and\nare frequently overadministered. Greater personalization is necessary, as no\nsingle action is suitable for all patients. We present a novel application of\nreinforcement learning in which we identify optimal recommendations for sepsis\ntreatment from data, estimate their confidence level, and identify treatment\noptions infrequently observed in training data. Rather than a single\nrecommendation, our method can present several treatment options. We examine\nlearned policies and discover that reinforcement learning is biased against\naggressive intervention due to the confounding relationship between mortality\nand level of treatment received. We mitigate this bias using subspace learning,\nand develop methodology that can yield more accurate learning policies across\nhealthcare applications.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 15:29:05 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Liu", "Ran", "", "1 and 2"], ["Greenstein", "Joseph L.", "", "1 and 2"], ["Fackler", "James C.", "", "3 and 4"], ["Bergmann", "Jules", "", "3 and 4"], ["Bembea", "Melania M.", "", "3 and 4"], ["Winslow", "Raimond L.", "", "1\n  and 2"]]}, {"id": "2107.04497", "submitter": "Vincent Mai", "authors": "Vincent Mai, Waleed Khamies, Liam Paull", "title": "Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression", "comments": "Accepted at the Uncertainty in Deep Learning (UDL) workshop at ICML\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Heteroscedastic regression is the task of supervised learning where each\nlabel is subject to noise from a different distribution. This noise can be\ncaused by the labelling process, and impacts negatively the performance of the\nlearning algorithm as it violates the i.i.d. assumptions. In many situations\nhowever, the labelling process is able to estimate the variance of such\ndistribution for each label, which can be used as an additional information to\nmitigate this impact. We adapt an inverse-variance weighted mean square error,\nbased on the Gauss-Markov theorem, for parameter optimization on neural\nnetworks. We introduce Batch Inverse-Variance, a loss function which is robust\nto near-ground truth samples, and allows to control the effective learning\nrate. Our experimental results show that BIV improves significantly the\nperformance of the networks on two noisy datasets, compared to L2 loss,\ninverse-variance weighting, as well as a filtering-based baseline.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 15:39:31 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Mai", "Vincent", ""], ["Khamies", "Waleed", ""], ["Paull", "Liam", ""]]}, {"id": "2107.04529", "submitter": "Ariel Caticha", "authors": "Ariel Caticha", "title": "Entropy, Information, and the Updating of Probabilities", "comments": "28 pages. Invited paper to appear in Entropy in the special volume\n  \"Statistical Foundations of Entropy\", ed. by P. Jizba and J. Korbel. arXiv\n  admin note: text overlap with arXiv:1412.5644", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.AI stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is a review of a particular approach to the method of maximum\nentropy as a general framework for inference. The discussion emphasizes the\npragmatic elements in the derivation. An epistemic notion of information is\ndefined in terms of its relation to the Bayesian beliefs of ideally rational\nagents. The method of updating from a prior to a posterior probability\ndistribution is designed through an eliminative induction process. The\nlogarithmic relative entropy is singled out as the unique tool for updating\nthat (a) is of universal applicability; (b) that recognizes the value of prior\ninformation; and (c) that recognizes the privileged role played by the notion\nof independence in science. The resulting framework -- the ME method -- can\nhandle arbitrary priors and arbitrary constraints. It includes MaxEnt and\nBayes' rule as special cases and, therefore, it unifies entropic and Bayesian\nmethods into a single general inference scheme. The ME method goes beyond the\nmere selection of a single posterior, but also addresses the question of how\nmuch less probable other distributions might be, which provides a direct bridge\nto the theories of fluctuations and large deviations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 16:27:23 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Caticha", "Ariel", ""]]}, {"id": "2107.04538", "submitter": "Bruno Brito", "authors": "Bruno Brito, Achin Agarwal and Javier Alonso-Mora", "title": "Learning Interaction-aware Guidance Policies for Motion Planning in\n  Dense Traffic Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous navigation in dense traffic scenarios remains challenging for\nautonomous vehicles (AVs) because the intentions of other drivers are not\ndirectly observable and AVs have to deal with a wide range of driving\nbehaviors. To maneuver through dense traffic, AVs must be able to reason how\ntheir actions affect others (interaction model) and exploit this reasoning to\nnavigate through dense traffic safely. This paper presents a novel framework\nfor interaction-aware motion planning in dense traffic scenarios. We explore\nthe connection between human driving behavior and their velocity changes when\ninteracting. Hence, we propose to learn, via deep Reinforcement Learning (RL),\nan interaction-aware policy providing global guidance about the cooperativeness\nof other vehicles to an optimization-based planner ensuring safety and\nkinematic feasibility through constraint satisfaction. The learned policy can\nreason and guide the local optimization-based planner with interactive behavior\nto pro-actively merge in dense traffic while remaining safe in case the other\nvehicles do not yield. We present qualitative and quantitative results in\nhighly interactive simulation environments (highway merging and unprotected\nleft turns) against two baseline approaches, a learning-based and an\noptimization-based method. The presented results demonstrate that our method\nsignificantly reduces the number of collisions and increases the success rate\nwith respect to both learning-based and optimization-based baselines.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 16:43:12 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Brito", "Bruno", ""], ["Agarwal", "Achin", ""], ["Alonso-Mora", "Javier", ""]]}, {"id": "2107.04619", "submitter": "Gaurav Shrivastava", "authors": "Gaurav Shrivastava and Abhinav Shrivastava", "title": "Diverse Video Generation using a Gaussian Process Trigger", "comments": "International Conference on Learning Representations, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Generating future frames given a few context (or past) frames is a\nchallenging task. It requires modeling the temporal coherence of videos and\nmulti-modality in terms of diversity in the potential future states. Current\nvariational approaches for video generation tend to marginalize over\nmulti-modal future outcomes. Instead, we propose to explicitly model the\nmulti-modality in the future outcomes and leverage it to sample diverse\nfutures. Our approach, Diverse Video Generator, uses a Gaussian Process (GP) to\nlearn priors on future states given the past and maintains a probability\ndistribution over possible futures given a particular sample. In addition, we\nleverage the changes in this distribution over time to control the sampling of\ndiverse future states by estimating the end of ongoing sequences. That is, we\nuse the variance of GP over the output function space to trigger a change in an\naction sequence. We achieve state-of-the-art results on diverse future frame\ngeneration in terms of reconstruction quality and diversity of the generated\nsequences.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 18:15:16 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Shrivastava", "Gaurav", ""], ["Shrivastava", "Abhinav", ""]]}, {"id": "2107.04632", "submitter": "Mart\\'i Pedemonte", "authors": "Mart\\'i Pedemonte, Jordi Vitri\\`a and \\'Alvaro Parafita (Universitat\n  de Barcelona)", "title": "Algorithmic Causal Effect Identification with causaleffect", "comments": "40 pages, 27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.AI math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our evolution as a species made a huge step forward when we understood the\nrelationships between causes and effects. These associations may be trivial for\nsome events, but they are not in complex scenarios. To rigorously prove that\nsome occurrences are caused by others, causal theory and causal inference were\nformalized, introducing the $do$-operator and its associated rules. The main\ngoal of this report is to review and implement in Python some algorithms to\ncompute conditional and non-conditional causal queries from observational data.\nTo this end, we first present some basic background knowledge on probability\nand graph theory, before introducing important results on causal theory, used\nin the construction of the algorithms. We then thoroughly study the\nidentification algorithms presented by Shpitser and Pearl in 2006, explaining\nour implementation in Python alongside. The main identification algorithm can\nbe seen as a repeated application of the rules of $do$-calculus, and it\neventually either returns an expression for the causal query from experimental\nprobabilities or fails to identify the causal effect, in which case the effect\nis non-identifiable. We introduce our newly developed Python library and give\nsome usage examples.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 19:00:33 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Pedemonte", "Mart\u00ed", "", "Universitat\n  de Barcelona"], ["Vitri\u00e0", "Jordi", "", "Universitat\n  de Barcelona"], ["Parafita", "\u00c1lvaro", "", "Universitat\n  de Barcelona"]]}, {"id": "2107.04635", "submitter": "Wiktor Piotrowski", "authors": "Wiktor Piotrowski, Roni Stern, Matthew Klenk, Alexandre Perez, Shiwali\n  Mohan, Johan de Kleer, Jacob Le", "title": "Playing Angry Birds with a Domain-Independent PDDL+ Planner", "comments": "2 pages, submitted to ICAPS 2021 Demonstration Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This demo paper presents the first system for playing the popular Angry Birds\ngame using a domain-independent planner. Our system models Angry Birds levels\nusing PDDL+, a planning language for mixed discrete/continuous domains. It uses\na domain-independent PDDL+ planner to generate plans and executes them. In this\ndemo paper, we present the system's PDDL+ model for this domain, identify key\ndesign decisions that reduce the problem complexity, and compare the\nperformance of our system to model-specific methods for this domain. The\nresults show that our system's performance is on par with other domain-specific\nsystems for Angry Birds, suggesting the applicability of domain-independent\nplanning to this benchmark AI challenge.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 19:12:49 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Piotrowski", "Wiktor", ""], ["Stern", "Roni", ""], ["Klenk", "Matthew", ""], ["Perez", "Alexandre", ""], ["Mohan", "Shiwali", ""], ["de Kleer", "Johan", ""], ["Le", "Jacob", ""]]}, {"id": "2107.04641", "submitter": "Harikrishna Narasimhan", "authors": "Harikrishna Narasimhan, Aditya Krishna Menon", "title": "Training Over-parameterized Models with Non-decomposable Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern machine learning applications come with complex and nuanced\ndesign goals such as minimizing the worst-case error, satisfying a given\nprecision or recall target, or enforcing group-fairness constraints. Popular\ntechniques for optimizing such non-decomposable objectives reduce the problem\ninto a sequence of cost-sensitive learning tasks, each of which is then solved\nby re-weighting the training loss with example-specific costs. We point out\nthat the standard approach of re-weighting the loss to incorporate label costs\ncan produce unsatisfactory results when used to train over-parameterized\nmodels. As a remedy, we propose new cost-sensitive losses that extend the\nclassical idea of logit adjustment to handle more general cost matrices. Our\nlosses are calibrated, and can be further improved with distilled labels from a\nteacher model. Through experiments on benchmark image datasets, we showcase the\neffectiveness of our approach in training ResNet models with common robust and\nconstrained optimization objectives.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 19:29:33 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Narasimhan", "Harikrishna", ""], ["Menon", "Aditya Krishna", ""]]}, {"id": "2107.04661", "submitter": "Serge Assaad", "authors": "Serge Assaad, Shuxi Zeng, Henry Pfister, Fan Li, Lawrence Carin", "title": "H\\\"older Bounds for Sensitivity Analysis in Causal Reasoning", "comments": "Workshop on the Neglected Assumptions in Causal Inference at the\n  International Conference on Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine interval estimation of the effect of a treatment T on an outcome Y\ngiven the existence of an unobserved confounder U. Using H\\\"older's inequality,\nwe derive a set of bounds on the confounding bias |E[Y|T=t]-E[Y|do(T=t)]| based\non the degree of unmeasured confounding (i.e., the strength of the connection\nU->T, and the strength of U->Y). These bounds are tight either when U is\nindependent of T or when U is independent of Y given T (when there is no\nunobserved confounding). We focus on a special case of this bound depending on\nthe total variation distance between the distributions p(U) and p(U|T=t), as\nwell as the maximum (over all possible values of U) deviation of the\nconditional expected outcome E[Y|U=u,T=t] from the average expected outcome\nE[Y|T=t]. We discuss possible calibration strategies for this bound to get\ninterval estimates for treatment effects, and experimentally validate the bound\nusing synthetic and semi-synthetic datasets.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 20:26:36 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Assaad", "Serge", ""], ["Zeng", "Shuxi", ""], ["Pfister", "Henry", ""], ["Li", "Fan", ""], ["Carin", "Lawrence", ""]]}, {"id": "2107.04680", "submitter": "Raphael Mazzine", "authors": "Raphael Mazzine and David Martens", "title": "A Framework and Benchmarking Study for Counterfactual Generating Methods\n  on Tabular Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Counterfactual explanations are viewed as an effective way to explain machine\nlearning predictions. This interest is reflected by a relatively young\nliterature with already dozens of algorithms aiming to generate such\nexplanations. These algorithms are focused on finding how features can be\nmodified to change the output classification. However, this rather general\nobjective can be achieved in different ways, which brings about the need for a\nmethodology to test and benchmark these algorithms. The contributions of this\nwork are manifold: First, a large benchmarking study of 10 algorithmic\napproaches on 22 tabular datasets is performed, using 9 relevant evaluation\nmetrics. Second, the introduction of a novel, first of its kind, framework to\ntest counterfactual generation algorithms. Third, a set of objective metrics to\nevaluate and compare counterfactual results. And finally, insight from the\nbenchmarking results that indicate which approaches obtain the best performance\non what type of dataset. This benchmarking study and framework can help\npractitioners in determining which technique and building blocks most suit\ntheir context, and can help researchers in the design and evaluation of current\nand future counterfactual generation algorithms. Our findings show that,\noverall, there's no single best algorithm to generate counterfactual\nexplanations as the performance highly depends on properties related to the\ndataset, model, score and factual point specificities.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 21:06:03 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Mazzine", "Raphael", ""], ["Martens", "David", ""]]}, {"id": "2107.04689", "submitter": "Fei Ye", "authors": "Fei Ye and Adrian G. Bors", "title": "Lifelong Teacher-Student Network Learning", "comments": "18 pages, 18 figures. in IEEE Transactions on Pattern Analysis and\n  Machine Intelligence", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3092677", "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A unique cognitive capability of humans consists in their ability to acquire\nnew knowledge and skills from a sequence of experiences. Meanwhile, artificial\nintelligence systems are good at learning only the last given task without\nbeing able to remember the databases learnt in the past. We propose a novel\nlifelong learning methodology by employing a Teacher-Student network framework.\nWhile the Student module is trained with a new given database, the Teacher\nmodule would remind the Student about the information learnt in the past. The\nTeacher, implemented by a Generative Adversarial Network (GAN), is trained to\npreserve and replay past knowledge corresponding to the probabilistic\nrepresentations of previously learn databases. Meanwhile, the Student module is\nimplemented by a Variational Autoencoder (VAE) which infers its latent variable\nrepresentation from both the output of the Teacher module as well as from the\nnewly available database. Moreover, the Student module is trained to capture\nboth continuous and discrete underlying data representations across different\ndomains. The proposed lifelong learning framework is applied in supervised,\nsemi-supervised and unsupervised training. The code is available~:\n\\url{https://github.com/dtuzi123/Lifelong-Teacher-Student-Network-Learning}\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 21:25:56 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Ye", "Fei", ""], ["Bors", "Adrian G.", ""]]}, {"id": "2107.04694", "submitter": "Fei Ye", "authors": "Fei Ye and Adrian G. Bors", "title": "Lifelong Mixture of Variational Autoencoders", "comments": "Accepted by IEEE Transactions on Neural Networks and Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we propose an end-to-end lifelong learning mixture of experts.\nEach expert is implemented by a Variational Autoencoder (VAE). The experts in\nthe mixture system are jointly trained by maximizing a mixture of individual\ncomponent evidence lower bounds (MELBO) on the log-likelihood of the given\ntraining samples. The mixing coefficients in the mixture, control the\ncontributions of each expert in the goal representation. These are sampled from\na Dirichlet distribution whose parameters are determined through non-parametric\nestimation during lifelong learning. The model can learn new tasks fast when\nthese are similar to those previously learnt. The proposed Lifelong mixture of\nVAE (L-MVAE) expands its architecture with new components when learning a\ncompletely new task. After the training, our model can automatically determine\nthe relevant expert to be used when fed with new data samples. This mechanism\nbenefits both the memory efficiency and the required computational cost as only\none expert is used during the inference. The L-MVAE inference model is able to\nperform interpolation in the joint latent space across the data domains\nassociated with different tasks and is shown to be efficient for disentangled\nlearning representation.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 22:07:39 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Ye", "Fei", ""], ["Bors", "Adrian G.", ""]]}, {"id": "2107.04705", "submitter": "Fei Ye", "authors": "Fei Ye and Adrian G. Bors", "title": "InfoVAEGAN : learning joint interpretable representations by information\n  maximization and maximum likelihood", "comments": "Accepted at International Conference on Image Processing (ICIP 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Learning disentangled and interpretable representations is an important step\ntowards accomplishing comprehensive data representations on the manifold. In\nthis paper, we propose a novel representation learning algorithm which combines\nthe inference abilities of Variational Autoencoders (VAE) with the\ngeneralization capability of Generative Adversarial Networks (GAN). The\nproposed model, called InfoVAEGAN, consists of three networks~: Encoder,\nGenerator and Discriminator. InfoVAEGAN aims to jointly learn discrete and\ncontinuous interpretable representations in an unsupervised manner by using two\ndifferent data-free log-likelihood functions onto the variables sampled from\nthe generator's distribution. We propose a two-stage algorithm for optimizing\nthe inference network separately from the generator training. Moreover, we\nenforce the learning of interpretable representations through the maximization\nof the mutual information between the existing latent variables and those\ncreated through generative and inference processes.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 22:38:10 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Ye", "Fei", ""], ["Bors", "Adrian G.", ""]]}, {"id": "2107.04708", "submitter": "Fei Ye", "authors": "Fei Ye and Adrian G. Bors", "title": "Lifelong Twin Generative Adversarial Networks", "comments": "Accepted at International Conference on Image Processing (ICIP 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we propose a new continuously learning generative model,\ncalled the Lifelong Twin Generative Adversarial Networks (LT-GANs). LT-GANs\nlearns a sequence of tasks from several databases and its architecture consists\nof three components: two identical generators, namely the Teacher and\nAssistant, and one Discriminator. In order to allow for the LT-GANs to learn\nnew concepts without forgetting, we introduce a new lifelong training approach,\nnamely Lifelong Adversarial Knowledge Distillation (LAKD), which encourages the\nTeacher and Assistant to alternately teach each other, while learning a new\ndatabase. This training approach favours transferring knowledge from a more\nknowledgeable player to another player which knows less information about a\npreviously given task.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 22:52:49 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Ye", "Fei", ""], ["Bors", "Adrian G.", ""]]}, {"id": "2107.04755", "submitter": "Shirui Pan", "authors": "Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, Chengqi Zhang", "title": "Beyond Low-pass Filtering: Graph Convolutional Networks with Automatic\n  Filtering", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Graph convolutional networks are becoming indispensable for deep learning\nfrom graph-structured data. Most of the existing graph convolutional networks\nshare two big shortcomings. First, they are essentially low-pass filters, thus\nthe potentially useful middle and high frequency band of graph signals are\nignored. Second, the bandwidth of existing graph convolutional filters is\nfixed. Parameters of a graph convolutional filter only transform the graph\ninputs without changing the curvature of a graph convolutional filter function.\nIn reality, we are uncertain about whether we should retain or cut off the\nfrequency at a certain point unless we have expert domain knowledge. In this\npaper, we propose Automatic Graph Convolutional Networks (AutoGCN) to capture\nthe full spectrum of graph signals and automatically update the bandwidth of\ngraph convolutional filters. While it is based on graph spectral theory, our\nAutoGCN is also localized in space and has a spatial form. Experimental results\nshow that AutoGCN achieves significant improvement over baseline methods which\nonly work as low-pass filters.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 04:11:25 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wu", "Zonghan", ""], ["Pan", "Shirui", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Zhang", "Chengqi", ""]]}, {"id": "2107.04764", "submitter": "Mohamed Nassar", "authors": "Sara Hajj Ibrahim and Mohamed Nassar", "title": "Hack The Box: Fooling Deep Learning Abstraction-Based Monitors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning is a type of machine learning that adapts a deep hierarchy of\nconcepts. Deep learning classifiers link the most basic version of concepts at\nthe input layer to the most abstract version of concepts at the output layer,\nalso known as a class or label. However, once trained over a finite set of\nclasses, some deep learning models do not have the power to say that a given\ninput does not belong to any of the classes and simply cannot be linked.\nCorrectly invalidating the prediction of unrelated classes is a challenging\nproblem that has been tackled in many ways in the literature. Novelty detection\ngives deep learning the ability to output \"do not know\" for novel/unseen\nclasses. Still, no attention has been given to the security aspects of novelty\ndetection. In this paper, we consider the case study of abstraction-based\nnovelty detection and show that it is not robust against adversarial samples.\nMoreover, we show the feasibility of crafting adversarial samples that fool the\ndeep learning classifier and bypass the novelty detection monitoring at the\nsame time. In other words, these monitoring boxes are hackable. We demonstrate\nthat novelty detection itself ends up as an attack surface.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 05:06:04 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 05:19:11 GMT"}, {"version": "v3", "created": "Sun, 18 Jul 2021 20:50:55 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ibrahim", "Sara Hajj", ""], ["Nassar", "Mohamed", ""]]}, {"id": "2107.04767", "submitter": "Mayur Parate", "authors": "Mayur R. Parate, Kishor M. Bhurchandi, Ashwin G. Kothari", "title": "Anomaly Detection in Residential Video Surveillance on Edge Devices in\n  IoT Framework", "comments": "7 Pages, 7 Figures and 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Intelligent resident surveillance is one of the most essential smart\ncommunity services. The increasing demand for security needs surveillance\nsystems to be able to detect anomalies in surveillance scenes. Employing\nhigh-capacity computational devices for intelligent surveillance in residential\nsocieties is costly and not feasible. Therefore, we propose anomaly detection\nfor intelligent surveillance using CPU-only edge devices. A modular framework\nto capture object-level inferences and tracking is developed. To cope with\npartial occlusions, posture deformations, and complex scenes we employed\nfeature encoding and trajectory associations. Elements of the anomaly detection\nframework are optimized to run on CPU-only edge devices with sufficient FPS.\nThe experimental results indicate the proposed method is feasible and achieves\nsatisfactory results in real-life scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 05:52:15 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Parate", "Mayur R.", ""], ["Bhurchandi", "Kishor M.", ""], ["Kothari", "Ashwin G.", ""]]}, {"id": "2107.04768", "submitter": "Jianyu Wang", "authors": "Jianyu Wang, Bing-Kun Bao, Changsheng Xu", "title": "DualVGR: A Dual-Visual Graph Reasoning Unit for Video Question Answering", "comments": "12 pages, 12 figures", "journal-ref": "IEEE Transactions on Multimedia 2021", "doi": "10.1109/TMM.2021.3097171", "report-no": null, "categories": "cs.MM cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video question answering is a challenging task, which requires agents to be\nable to understand rich video contents and perform spatial-temporal reasoning.\nHowever, existing graph-based methods fail to perform multi-step reasoning\nwell, neglecting two properties of VideoQA: (1) Even for the same video,\ndifferent questions may require different amount of video clips or objects to\ninfer the answer with relational reasoning; (2) During reasoning, appearance\nand motion features have complicated interdependence which are correlated and\ncomplementary to each other. Based on these observations, we propose a\nDual-Visual Graph Reasoning Unit (DualVGR) which reasons over videos in an\nend-to-end fashion. The first contribution of our DualVGR is the design of an\nexplainable Query Punishment Module, which can filter out irrelevant visual\nfeatures through multiple cycles of reasoning. The second contribution is the\nproposed Video-based Multi-view Graph Attention Network, which captures the\nrelations between appearance and motion features. Our DualVGR network achieves\nstate-of-the-art performance on the benchmark MSVD-QA and SVQA datasets, and\ndemonstrates competitive results on benchmark MSRVTT-QA datasets. Our code is\navailable at https://github.com/MMIR/DualVGR-VideoQA.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 06:08:15 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Wang", "Jianyu", ""], ["Bao", "Bing-Kun", ""], ["Xu", "Changsheng", ""]]}, {"id": "2107.04771", "submitter": "Balaji Ganesan", "authors": "Jaspreet Singh Dhani, Ruchika Bhatt, Balaji Ganesan, Parikshet Sirohi,\n  Vasudha Bhatnagar", "title": "Similar Cases Recommendation using Legal Knowledge Graphs", "comments": "4 pages. 5 figures. KG Workshop at KDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A legal knowledge graph constructed from court cases, judgments, laws and\nother legal documents can enable a number of applications like question\nanswering, document similarity, and search. While the use of knowledge graphs\nfor distant supervision in NLP tasks is well researched, using knowledge graphs\nfor downstream graph tasks like node similarity presents challenges in\nselecting node types and their features. In this demo, we describe our solution\nfor predicting similar nodes in a case graph derived from our legal knowledge\ngraph.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 06:37:36 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Dhani", "Jaspreet Singh", ""], ["Bhatt", "Ruchika", ""], ["Ganesan", "Balaji", ""], ["Sirohi", "Parikshet", ""], ["Bhatnagar", "Vasudha", ""]]}, {"id": "2107.04775", "submitter": "Ashwin Balakrishna", "authors": "Albert Wilcox and Ashwin Balakrishna and Brijen Thananjeyan and Joseph\n  E. Gonzalez and Ken Goldberg", "title": "LS3: Latent Space Safe Sets for Long-Horizon Visuomotor Control of\n  Iterative Tasks", "comments": "Preprint, Under Review. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning (RL) algorithms have shown impressive success in\nexploring high-dimensional environments to learn complex, long-horizon tasks,\nbut can often exhibit unsafe behaviors and require extensive environment\ninteraction when exploration is unconstrained. A promising strategy for safe\nlearning in dynamically uncertain environments is requiring that the agent can\nrobustly return to states where task success (and therefore safety) can be\nguaranteed. While this approach has been successful in low-dimensions,\nenforcing this constraint in environments with high-dimensional state spaces,\nsuch as images, is challenging. We present Latent Space Safe Sets (LS3), which\nextends this strategy to iterative, long-horizon tasks with image observations\nby using suboptimal demonstrations and a learned dynamics model to restrict\nexploration to the neighborhood of a learned Safe Set where task completion is\nlikely. We evaluate LS3 on 4 domains, including a challenging sequential\npushing task in simulation and a physical cable routing task. We find that LS3\ncan use prior task successes to restrict exploration and learn more efficiently\nthan prior algorithms while satisfying constraints. See\nhttps://tinyurl.com/latent-ss for code and supplementary material.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 06:46:10 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wilcox", "Albert", ""], ["Balakrishna", "Ashwin", ""], ["Thananjeyan", "Brijen", ""], ["Gonzalez", "Joseph E.", ""], ["Goldberg", "Ken", ""]]}, {"id": "2107.04781", "submitter": "Bryar Hassan Dr.", "authors": "Bryar A. Hassan, Tarik A. Rashid and Seyedali Mirjalili", "title": "Formal context reduction in deriving concept hierarchies from corpora\n  using adaptive evolutionary clustering algorithm star", "comments": "Complex Intell. Syst. (2021)", "journal-ref": null, "doi": "10.1007/s40747-021-00422-w", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  It is beneficial to automate the process of deriving concept hierarchies from\ncorpora since a manual construction of concept hierarchies is typically a\ntime-consuming and resource-intensive process. As such, the overall process of\nlearning concept hierarchies from corpora encompasses a set of steps: parsing\nthe text into sentences, splitting the sentences and then tokenising it. After\nthe lemmatisation step, the pairs are extracted using FCA. However, there might\nbe some uninteresting and erroneous pairs in the formal context. Generating\nformal context may lead to a time-consuming process, so formal context size\nreduction is required to remove uninterested and erroneous pairs, taking less\ntime to extract the concept lattice and concept hierarchies accordingly. In\nthis premise, this study aims to propose two frameworks: (1) A framework to\nreview the current process of deriving concept hierarchies from corpus\nutilising FCA; (2) A framework to decrease the formal contexts ambiguity of the\nfirst framework using an adaptive version of ECA*. Experiments are conducted by\napplying 385 sample corpora from Wikipedia on the two frameworks to examine the\nreducing size of formal context, which leads to yield concept lattice and\nconcept hierarchy. The resulting lattice of formal context is evaluated to the\nstandard one using concept lattice-invariants. Accordingly, the homomorphic\nbetween the two lattices preserves the quality of resulting concept hierarchies\nby 89% in contrast to the basic ones, and the reduced concept lattice inherits\nthe structural relation of the standard one. The adaptive ECA* is examined\nagainst its four counterpart baseline algorithms to measure the execution time\non random datasets with different densities (fill ratios). The results show\nthat adaptive ECA* performs concept lattice faster than other mentioned\ncompetitive techniques in different fill ratios.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 07:18:03 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Hassan", "Bryar A.", ""], ["Rashid", "Tarik A.", ""], ["Mirjalili", "Seyedali", ""]]}, {"id": "2107.04810", "submitter": "Fangqiu Yi", "authors": "Fangqiu Yi and Tingting Jiang", "title": "Not End-to-End: Explore Multi-Stage Architecture for Online Surgical\n  Phase Recognition", "comments": "Not accepted by M2CAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surgical phase recognition is of particular interest to computer assisted\nsurgery systems, in which the goal is to predict what phase is occurring at\neach frame for a surgery video. Networks with multi-stage architecture have\nbeen widely applied in many computer vision tasks with rich patterns, where a\npredictor stage first outputs initial predictions and an additional refinement\nstage operates on the initial predictions to perform further refinement.\nExisting works show that surgical video contents are well ordered and contain\nrich temporal patterns, making the multi-stage architecture well suited for the\nsurgical phase recognition task. However, we observe that when simply applying\nthe multi-stage architecture to the surgical phase recognition task, the\nend-to-end training manner will make the refinement ability fall short of its\nwishes. To address the problem, we propose a new non end-to-end training\nstrategy and explore different designs of multi-stage architecture for surgical\nphase recognition task. For the non end-to-end training strategy, the\nrefinement stage is trained separately with proposed two types of disturbed\nsequences. Meanwhile, we evaluate three different choices of refinement models\nto show that our analysis and solution are robust to the choices of specific\nmulti-stage models. We conduct experiments on two public benchmarks, the\nM2CAI16 Workflow Challenge, and the Cholec80 dataset. Results show that\nmulti-stage architecture trained with our strategy largely boosts the\nperformance of the current state-of-the-art single-stage model. Code is\navailable at \\url{https://github.com/ChinaYi/casual_tcn}.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 11:00:38 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Yi", "Fangqiu", ""], ["Jiang", "Tingting", ""]]}, {"id": "2107.04827", "submitter": "Shoaib Ahmed Siddiqui", "authors": "Shoaib Ahmed Siddiqui, Thomas Breuel", "title": "Identifying Layers Susceptible to Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common neural network architectures are susceptible to attack by adversarial\nsamples. Neural network architectures are commonly thought of as divided into\nlow-level feature extraction layers and high-level classification layers;\nsusceptibility of networks to adversarial samples is often thought of as a\nproblem related to classification rather than feature extraction. We test this\nidea by selectively retraining different portions of VGG and ResNet\narchitectures on CIFAR-10, Imagenette and ImageNet using non-adversarial and\nadversarial data. Our experimental results show that susceptibility to\nadversarial samples is associated with low-level feature extraction layers.\nTherefore, retraining high-level layers is insufficient for achieving\nrobustness. This phenomenon could have two explanations: either, adversarial\nattacks yield outputs from early layers that are indistinguishable from\nfeatures found in the attack classes, or adversarial attacks yield outputs from\nearly layers that differ statistically from features for non-adversarial\nsamples and do not permit consistent classification by subsequent layers. We\ntest this question by large-scale non-linear dimensionality reduction and\ndensity modeling on distributions of feature vectors in hidden layers and find\nthat the feature distributions between non-adversarial and adversarial samples\ndiffer substantially. Our results provide new insights into the statistical\norigins of adversarial samples and possible defenses.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 12:38:49 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Siddiqui", "Shoaib Ahmed", ""], ["Breuel", "Thomas", ""]]}, {"id": "2107.04846", "submitter": "Haodong Chang", "authors": "Haodong Chang and Yabo Chu", "title": "Propagation-aware Social Recommendation by Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social-aware recommendation approaches have been recognized as an effective\nway to solve the data sparsity issue of traditional recommender systems. The\nassumption behind is that the knowledge in social user-user connections can be\nshared and transferred to the domain of user-item interactions, whereby to help\nlearn user preferences. However, most existing approaches merely adopt the\nfirst-order connections among users during transfer learning, ignoring those\nconnections in higher orders. We argue that better recommendation performance\ncan also benefit from high-order social relations. In this paper, we propose a\nnovel Propagation-aware Transfer Learning Network (PTLN) based on the\npropagation of social relations. We aim to better mine the sharing knowledge\nhidden in social networks and thus further improve recommendation performance.\nSpecifically, we explore social influence in two aspects: (a) higher-order\nfriends have been taken into consideration by order bias; (b) different friends\nin the same order will have distinct importance for recommendation by an\nattention mechanism. Besides, we design a novel regularization to bridge the\ngap between social relations and user-item interactions. We conduct extensive\nexperiments on two real-world datasets and beat other counterparts in terms of\nranking accuracy, especially for the cold-start users with few historical\ninteractions.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 14:21:27 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Chang", "Haodong", ""], ["Chu", "Yabo", ""]]}, {"id": "2107.04851", "submitter": "Martin Spindler", "authors": "Helmut Wasserbacher and Martin Spindler", "title": "Machine Learning for Financial Forecasting, Planning and Analysis:\n  Recent Developments and Pitfalls", "comments": "31 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is an introduction to machine learning for financial\nforecasting, planning and analysis (FP\\&A). Machine learning appears well\nsuited to support FP\\&A with the highly automated extraction of information\nfrom large amounts of data. However, because most traditional machine learning\ntechniques focus on forecasting (prediction), we discuss the particular care\nthat must be taken to avoid the pitfalls of using them for planning and\nresource allocation (causal inference). While the naive application of machine\nlearning usually fails in this context, the recently developed double machine\nlearning framework can address causal questions of interest. We review the\ncurrent literature on machine learning in FP\\&A and illustrate in a simulation\nstudy how machine learning can be used for both forecasting and planning. We\nalso investigate how forecasting and planning improve as the number of data\npoints increases.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 14:54:36 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wasserbacher", "Helmut", ""], ["Spindler", "Martin", ""]]}, {"id": "2107.04857", "submitter": "Basit Alawode", "authors": "Basit O. Alawode, Mudassir Masood, Tarig Ballal, and Tareq Al-Naffouri", "title": "Dense-Sparse Deep CNN Training for Image Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, deep learning (DL) methods such as convolutional neural networks\n(CNNs) have gained prominence in the area of image denoising. This is owing to\ntheir proven ability to surpass state-of-the-art classical image denoising\nalgorithms such as BM3D. Deep denoising CNNs (DnCNNs) use many feedforward\nconvolution layers with added regularization methods of batch normalization and\nresidual learning to improve denoising performance significantly. However, this\ncomes at the expense of a huge number of trainable parameters. In this paper,\nwe address this issue by reducing the number of parameters while achieving a\ncomparable level of performance. We derive motivation from the improved\nperformance obtained by training networks using the dense-sparse-dense (DSD)\ntraining approach. We extend this training approach to a reduced DnCNN (RDnCNN)\nnetwork resulting in a faster denoising network with significantly reduced\nparameters and comparable performance to the DnCNN.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 15:14:19 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Alawode", "Basit O.", ""], ["Masood", "Mudassir", ""], ["Ballal", "Tarig", ""], ["Al-Naffouri", "Tareq", ""]]}, {"id": "2107.04870", "submitter": "Laura Giordano", "authors": "Laura Giordano, Valentina Gliozzi, Daniele Theseider Dupr\\'e", "title": "From Common Sense Reasoning to Neural Network Models through Multiple\n  Preferences: an overview", "comments": "17 pages. arXiv admin note: text overlap with arXiv:2008.13278,\n  arXiv:2012.13421, arXiv:2103.06854", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we discuss the relationships between conditional and\npreferential logics and neural network models, based on a multi-preferential\nsemantics. We propose a concept-wise multipreference semantics, recently\nintroduced for defeasible description logics to take into account preferences\nwith respect to different concepts, as a tool for providing a semantic\ninterpretation to neural network models. This approach has been explored both\nfor unsupervised neural network models (Self-Organising Maps) and for\nsupervised ones (Multilayer Perceptrons), and we expect that the same approach\nmight be extended to other neural network models. It allows for logical\nproperties of the network to be checked (by model checking) over an\ninterpretation capturing the input-output behavior of the network. For\nMultilayer Perceptrons, the deep network itself can be regarded as a\nconditional knowledge base, in which synaptic connections correspond to\nweighted conditionals. The paper describes the general approach, through the\ncases of Self-Organising Maps and Multilayer Perceptrons, and discusses some\nopen issues and perspectives.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 16:25:19 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Giordano", "Laura", ""], ["Gliozzi", "Valentina", ""], ["Dupr\u00e9", "Daniele Theseider", ""]]}, {"id": "2107.04924", "submitter": "Behzad Khamidehi", "authors": "Behzad Khamidehi and Elvino S. Sousa", "title": "Distributed Deep Reinforcement Learning for Intelligent Traffic\n  Monitoring with a Team of Aerial Robots", "comments": "IEEE International Conference on Intelligent Transportation -\n  ITSC2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the traffic monitoring problem in a road network using a\nteam of aerial robots. The problem is challenging due to two main reasons.\nFirst, the traffic events are stochastic, both temporally and spatially.\nSecond, the problem has a non-homogeneous structure as the traffic events\narrive at different locations of the road network at different rates.\nAccordingly, some locations require more visits by the robots compared to other\nlocations. To address these issues, we define an uncertainty metric for each\nlocation of the road network and formulate a path planning problem for the\naerial robots to minimize the network's average uncertainty. We express this\nproblem as a partially observable Markov decision process (POMDP) and propose a\ndistributed and scalable algorithm based on deep reinforcement learning to\nsolve it. We consider two different scenarios depending on the communication\nmode between the agents (aerial robots) and the traffic management center\n(TMC). The first scenario assumes that the agents continuously communicate with\nthe TMC to send/receive real-time information about the traffic events. Hence,\nthe agents have global and real-time knowledge of the environment. However, in\nthe second scenario, we consider a challenging setting where the observation of\nthe aerial robots is partial and limited to their sensing ranges. Moreover, in\ncontrast to the first scenario, the information exchange between the aerial\nrobots and the TMC is restricted to specific time instances. We evaluate the\nperformance of our proposed algorithm in both scenarios for a real road network\ntopology and demonstrate its functionality in a traffic monitoring system.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 22:41:32 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Khamidehi", "Behzad", ""], ["Sousa", "Elvino S.", ""]]}, {"id": "2107.04932", "submitter": "Yuecong Xu", "authors": "Yuecong Xu, Jianfei Yang, Haozhi Cao, Kezhi Mao, Jianxiong Yin, Simon\n  See", "title": "Aligning Correlation Information for Domain Adaptation in Action\n  Recognition", "comments": "The dataset HMDB-ARID is available at\n  https://xuyu0010.github.io/vuda.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Domain adaptation (DA) approaches address domain shift and enable networks to\nbe applied to different scenarios. Although various image DA approaches have\nbeen proposed in recent years, there is limited research towards video DA. This\nis partly due to the complexity in adapting the different modalities of\nfeatures in videos, which includes the correlation features extracted as\nlong-term dependencies of pixels across spatiotemporal dimensions. The\ncorrelation features are highly associated with action classes and proven their\neffectiveness in accurate video feature extraction through the supervised\naction recognition task. Yet correlation features of the same action would\ndiffer across domains due to domain shift. Therefore we propose a novel\nAdversarial Correlation Adaptation Network (ACAN) to align action videos by\naligning pixel correlations. ACAN aims to minimize the distribution of\ncorrelation information, termed as Pixel Correlation Discrepancy (PCD).\nAdditionally, video DA research is also limited by the lack of cross-domain\nvideo datasets with larger domain shifts. We, therefore, introduce a novel\nHMDB-ARID dataset with a larger domain shift caused by a larger statistical\ndifference between domains. This dataset is built in an effort to leverage\ncurrent datasets for dark video classification. Empirical results demonstrate\nthe state-of-the-art performance of our proposed ACAN for both existing and the\nnew video DA datasets.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 00:13:36 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Xu", "Yuecong", ""], ["Yang", "Jianfei", ""], ["Cao", "Haozhi", ""], ["Mao", "Kezhi", ""], ["Yin", "Jianxiong", ""], ["See", "Simon", ""]]}, {"id": "2107.04941", "submitter": "Yuecong Xu", "authors": "Yuecong Xu, Jianfei Yang, Haozhi Cao, Qi Li, Kezhi Mao, Zhenghua Chen", "title": "Partial Video Domain Adaptation with Partial Adversarial Temporal\n  Attentive Network", "comments": "The new datasets for PVDA: HMDB-ARID(partial), MiniKinetics-UCF,\n  HMDB-ARID(partial) can be downloaded from\n  https://xuyu0010.github.io/pvda.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Partial Domain Adaptation (PDA) is a practical and general domain adaptation\nscenario, which relaxes the fully shared label space assumption such that the\nsource label space subsumes the target one. The key challenge of PDA is the\nissue of negative transfer caused by source-only classes. For videos, such\nnegative transfer could be triggered by both spatial and temporal features,\nwhich leads to a more challenging Partial Video Domain Adaptation (PVDA)\nproblem. In this paper, we propose a novel Partial Adversarial Temporal\nAttentive Network (PATAN) to address the PVDA problem by utilizing both spatial\nand temporal features for filtering source-only classes. Besides, PATAN\nconstructs effective overall temporal features by attending to local temporal\nfeatures that contribute more toward the class filtration process. We further\nintroduce new benchmarks to facilitate research on PVDA problems, covering a\nwide range of PVDA scenarios. Empirical results demonstrate the\nstate-of-the-art performance of our proposed PATAN across the multiple PVDA\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 02:17:29 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Xu", "Yuecong", ""], ["Yang", "Jianfei", ""], ["Cao", "Haozhi", ""], ["Li", "Qi", ""], ["Mao", "Kezhi", ""], ["Chen", "Zhenghua", ""]]}, {"id": "2107.04952", "submitter": "Gaurav Bhatt", "authors": "Gaurav Bhatt, Shivam Chandhok and Vineeth N Balasubramanian", "title": "Learn from Anywhere: Rethinking Generalized Zero-Shot Learning with\n  Limited Supervision", "comments": "Accepted at IJCAI'21 workshop on Weakly Supervised Representation\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A common problem with most zero and few-shot learning approaches is they\nsuffer from bias towards seen classes resulting in sub-optimal performance.\nExisting efforts aim to utilize unlabeled images from unseen classes (i.e\ntransductive zero-shot) during training to enable generalization. However, this\nlimits their use in practical scenarios where data from target unseen classes\nis unavailable or infeasible to collect. In this work, we present a practical\nsetting of inductive zero and few-shot learning, where unlabeled images from\nother out-of-data classes, that do not belong to seen or unseen categories, can\nbe used to improve generalization in any-shot learning. We leverage a\nformulation based on product-of-experts and introduce a new AUD module that\nenables us to use unlabeled samples from out-of-data classes which are usually\neasily available and practically entail no annotation cost. In addition, we\nalso demonstrate the applicability of our model to address a more practical and\nchallenging, Generalized Zero-shot under a limited supervision setting, where\neven base seen classes do not have sufficient annotated samples.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 03:23:20 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 01:28:32 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bhatt", "Gaurav", ""], ["Chandhok", "Shivam", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "2107.04971", "submitter": "Boris Kovalerchuk", "authors": "Sridevi Narayana Wagle, Boris Kovalerchuk", "title": "Self-service Data Classification Using Interactive Visualization and\n  Interpretable Machine Learning", "comments": "37 pages, 33 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms often produce models considered as complex\nblack-box models by both end users and developers. They fail to explain the\nmodel in terms of the domain they are designed for. The proposed Iterative\nVisual Logical Classifier (IVLC) is an interpretable machine learning algorithm\nthat allows end users to design a model and classify data with more confidence\nand without having to compromise on the accuracy. Such technique is especially\nhelpful when dealing with sensitive and crucial data like cancer data in the\nmedical domain with high cost of errors. With the help of the proposed\ninteractive and lossless multidimensional visualization, end users can identify\nthe pattern in the data based on which they can make explainable decisions.\nSuch options would not be possible in black box machine learning methodologies.\nThe interpretable IVLC algorithm is supported by the Interactive Shifted Paired\nCoordinates Software System (SPCVis). It is a lossless multidimensional data\nvisualization system with user interactive features. The interactive approach\nprovides flexibility to the end user to perform data classification as\nself-service without having to rely on a machine learning expert. Interactive\npattern discovery becomes challenging while dealing with large data sets with\nhundreds of dimensions/features. To overcome this problem, this chapter\nproposes an automated classification approach combined with new Coordinate\nOrder Optimizer (COO) algorithm and a Genetic algorithm. The COO algorithm\nautomatically generates the coordinate pair sequences that best represent the\ndata separation and the genetic algorithm helps optimizing the proposed IVLC\nalgorithm by automatically generating the areas for data classification. The\nfeasibility of the approach is shown by experiments on benchmark datasets\ncovering both interactive and automated processes used for data classification.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 05:39:14 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wagle", "Sridevi Narayana", ""], ["Kovalerchuk", "Boris", ""]]}, {"id": "2107.04982", "submitter": "Mohamad H Danesh", "authors": "Mohamad H Danesh and Alan Fern", "title": "Out-of-Distribution Dynamics Detection: RL-Relevant Benchmarks and\n  Results", "comments": "ICML 2021 Workshop on Uncertainty and Robustness in Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of out-of-distribution dynamics (OODD) detection, which\ninvolves detecting when the dynamics of a temporal process change compared to\nthe training-distribution dynamics. This is relevant to applications in\ncontrol, reinforcement learning (RL), and multi-variate time-series, where\nchanges to test time dynamics can impact the performance of learning\ncontrollers/predictors in unknown ways. This problem is particularly important\nin the context of deep RL, where learned controllers often overfit to the\ntraining environment. Currently, however, there is a lack of established OODD\nbenchmarks for the types of environments commonly used in RL research. Our\nfirst contribution is to design a set of OODD benchmarks derived from common RL\nenvironments with varying types and intensities of OODD. Our second\ncontribution is to design a strong OODD baseline approach based on recurrent\nimplicit quantile networks (RIQNs), which monitors autoregressive prediction\nerrors for OODD detection. Our final contribution is to evaluate the RIQN\napproach on the benchmarks to provide baseline results for future comparison.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 06:40:02 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Danesh", "Mohamad H", ""], ["Fern", "Alan", ""]]}, {"id": "2107.04991", "submitter": "Ferhat Ozgur Catak", "authors": "Ferhat Ozgur Catak, Tao Yue, Shaukat Ali", "title": "Prediction Surface Uncertainty Quantification in Object Detection Models\n  for Autonomous Driving", "comments": "Accepted in AITest 2021, The Third IEEE International Conference On\n  Artificial Intelligence Testing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection in autonomous cars is commonly based on camera images and\nLidar inputs, which are often used to train prediction models such as deep\nartificial neural networks for decision making for object recognition,\nadjusting speed, etc. A mistake in such decision making can be damaging; thus,\nit is vital to measure the reliability of decisions made by such prediction\nmodels via uncertainty measurement. Uncertainty, in deep learning models, is\noften measured for classification problems. However, deep learning models in\nautonomous driving are often multi-output regression models. Hence, we propose\na novel method called PURE (Prediction sURface uncErtainty) for measuring\nprediction uncertainty of such regression models. We formulate the object\nrecognition problem as a regression model with more than one outputs for\nfinding object locations in a 2-dimensional camera view. For evaluation, we\nmodified three widely-applied object recognition models (i.e., YoLo, SSD300 and\nSSD512) and used the KITTI, Stanford Cars, Berkeley DeepDrive, and NEXET\ndatasets. Results showed the statistically significant negative correlation\nbetween prediction surface uncertainty and prediction accuracy suggesting that\nuncertainty significantly impacts the decisions made by autonomous driving.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 08:31:15 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Catak", "Ferhat Ozgur", ""], ["Yue", "Tao", ""], ["Ali", "Shaukat", ""]]}, {"id": "2107.05001", "submitter": "Shami Nisimov", "authors": "Shami Nisimov, Yaniv Gurwicz, Raanan Y. Rohekar, Gal Novik", "title": "Improving Efficiency and Accuracy of Causal Discovery Using a\n  Hierarchical Wrapper", "comments": "The 37th Conference on Uncertainty in Artificial Intelligence (UAI\n  2021), Workshop on Tractable Probabilistic Modeling", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal discovery from observational data is an important tool in many\nbranches of science. Under certain assumptions it allows scientists to explain\nphenomena, predict, and make decisions. In the large sample limit, sound and\ncomplete causal discovery algorithms have been previously introduced, where a\ndirected acyclic graph (DAG), or its equivalence class, representing causal\nrelations is searched. However, in real-world cases, only finite training data\nis available, which limits the power of statistical tests used by these\nalgorithms, leading to errors in the inferred causal model. This is commonly\naddressed by devising a strategy for using as few as possible statistical\ntests. In this paper, we introduce such a strategy in the form of a recursive\nwrapper for existing constraint-based causal discovery algorithms, which\npreserves soundness and completeness. It recursively clusters the observed\nvariables using the normalized min-cut criterion from the outset, and uses a\nbaseline causal discovery algorithm during backtracking for learning local\nsub-graphs. It then combines them and ensures completeness. By an ablation\nstudy, using synthetic data, and by common real-world benchmarks, we\ndemonstrate that our approach requires significantly fewer statistical tests,\nlearns more accurate graphs, and requires shorter run-times than the baseline\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 09:24:49 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Nisimov", "Shami", ""], ["Gurwicz", "Yaniv", ""], ["Rohekar", "Raanan Y.", ""], ["Novik", "Gal", ""]]}, {"id": "2107.05002", "submitter": "Gaochen Wu", "authors": "Gaochen Wu, Bin Xu1, Yuxin Qin, Fei Kong, Bangchang Liu, Hongwen Zhao,\n  Dejie Chang", "title": "Improving Low-resource Reading Comprehension via Cross-lingual\n  Transposition Rethinking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extractive Reading Comprehension (ERC) has made tremendous advances enabled\nby the availability of large-scale high-quality ERC training data. Despite of\nsuch rapid progress and widespread application, the datasets in languages other\nthan high-resource languages such as English remain scarce. To address this\nissue, we propose a Cross-Lingual Transposition ReThinking (XLTT) model by\nmodelling existing high-quality extractive reading comprehension datasets in a\nmultilingual environment. To be specific, we present multilingual adaptive\nattention (MAA) to combine intra-attention and inter-attention to learn more\ngeneral generalizable semantic and lexical knowledge from each pair of language\nfamilies. Furthermore, to make full use of existing datasets, we adopt a new\ntraining framework to train our model by calculating task-level similarities\nbetween each existing dataset and target dataset. The experimental results show\nthat our XLTT model surpasses six baselines on two multilingual ERC benchmarks,\nespecially more effective for low-resource languages with 3.9 and 4.1 average\nimprovement in F1 and EM, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 09:35:16 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wu", "Gaochen", ""], ["Xu1", "Bin", ""], ["Qin", "Yuxin", ""], ["Kong", "Fei", ""], ["Liu", "Bangchang", ""], ["Zhao", "Hongwen", ""], ["Chang", "Dejie", ""]]}, {"id": "2107.05031", "submitter": "FangYuan Zhang", "authors": "Fangyuan Zhang, Tianxiang Pan, Bin Wang", "title": "Semi-Supervised Object Detection with Adaptive Class-Rebalancing\n  Self-Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study delves into semi-supervised object detection (SSOD) to improve\ndetector performance with additional unlabeled data. State-of-the-art SSOD\nperformance has been achieved recently by self-training, in which training\nsupervision consists of ground truths and pseudo-labels. In current studies, we\nobserve that class imbalance in SSOD severely impedes the effectiveness of\nself-training. To address the class imbalance, we propose adaptive\nclass-rebalancing self-training (ACRST) with a novel memory module called\nCropBank. ACRST adaptively rebalances the training data with foreground\ninstances extracted from the CropBank, thereby alleviating the class imbalance.\nOwing to the high complexity of detection tasks, we observe that both\nself-training and data-rebalancing suffer from noisy pseudo-labels in SSOD.\nTherefore, we propose a novel two-stage filtering algorithm to generate\naccurate pseudo-labels. Our method achieves satisfactory improvements on\nMS-COCO and VOC benchmarks. When using only 1\\% labeled data in MS-COCO, our\nmethod achieves 17.02 mAP improvement over supervised baselines, and 5.32 mAP\nimprovement compared with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 12:14:42 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Zhang", "Fangyuan", ""], ["Pan", "Tianxiang", ""], ["Wang", "Bin", ""]]}, {"id": "2107.05033", "submitter": "Zhongzhan Huang", "authors": "Wei He, Zhongzhan Huang, Mingfu Liang, Senwei Liang, Haizhao Yang", "title": "Blending Pruning Criteria for Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancement of convolutional neural networks (CNNs) on various vision\napplications has attracted lots of attention. Yet the majority of CNNs are\nunable to satisfy the strict requirement for real-world deployment. To overcome\nthis, the recent popular network pruning is an effective method to reduce the\nredundancy of the models. However, the ranking of filters according to their\n\"importance\" on different pruning criteria may be inconsistent. One filter\ncould be important according to a certain criterion, while it is unnecessary\naccording to another one, which indicates that each criterion is only a partial\nview of the comprehensive \"importance\". From this motivation, we propose a\nnovel framework to integrate the existing filter pruning criteria by exploring\nthe criteria diversity. The proposed framework contains two stages: Criteria\nClustering and Filters Importance Calibration. First, we condense the pruning\ncriteria via layerwise clustering based on the rank of \"importance\" score.\nSecond, within each cluster, we propose a calibration factor to adjust their\nsignificance for each selected blending candidates and search for the optimal\nblending criterion via Evolutionary Algorithm. Quantitative results on the\nCIFAR-100 and ImageNet benchmarks show that our framework outperforms the\nstate-of-the-art baselines, regrading to the compact model performance after\npruning.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 12:34:19 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["He", "Wei", ""], ["Huang", "Zhongzhan", ""], ["Liang", "Mingfu", ""], ["Liang", "Senwei", ""], ["Yang", "Haizhao", ""]]}, {"id": "2107.05071", "submitter": "Yunsong Xie", "authors": "Yunsong Xie, Ryan Stearrett", "title": "Machine Learning based CVD Virtual Metrology in Mass Produced\n  Semiconductor Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cross-benchmark has been done on three critical aspects, data imputing,\nfeature selection and regression algorithms, for machine learning based\nchemical vapor deposition (CVD) virtual metrology (VM). The result reveals that\nlinear feature selection regression algorithm would extensively under-fit the\nVM data. Data imputing is also necessary to achieve a higher prediction\naccuracy as the data availability is only ~70% when optimal accuracy is\nobtained. This work suggests a nonlinear feature selection and regression\nalgorithm combined with nearest data imputing algorithm would provide a\nprediction accuracy as high as 0.7. This would lead to 70% reduced CVD\nprocessing variation, which is believed to will lead to reduced frequency of\nphysical metrology as well as more reliable mass-produced wafer with improved\nquality.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 15:32:31 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 04:34:44 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Xie", "Yunsong", ""], ["Stearrett", "Ryan", ""]]}, {"id": "2107.05073", "submitter": "Xiangzhu Meng", "authors": "Xiangzhu Meng, Wei Wei, Wenzhe Liu", "title": "Locality Relationship Constrained Multi-view Clustering Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In most practical applications, it's common to utilize multiple features from\ndifferent views to represent one object. Among these works, multi-view\nsubspace-based clustering has gained extensive attention from many researchers,\nwhich aims to provide clustering solutions to multi-view data. However, most\nexisting methods fail to take full use of the locality geometric structure and\nsimilarity relationship among samples under the multi-view scenario. To solve\nthese issues, we propose a novel multi-view learning method with locality\nrelationship constraint to explore the problem of multi-view clustering, called\nLocality Relationship Constrained Multi-view Clustering Framework (LRC-MCF).\nLRC-MCF aims to explore the diversity, geometric, consensus and complementary\ninformation among different views, by capturing the locality relationship\ninformation and the common similarity relationships among multiple views.\nMoreover, LRC-MCF takes sufficient consideration to weights of different views\nin finding the common-view locality structure and straightforwardly produce the\nfinal clusters. To effectually reduce the redundancy of the learned\nrepresentations, the low-rank constraint on the common similarity matrix is\nconsidered additionally. To solve the minimization problem of LRC-MCF, an\nAlternating Direction Minimization (ADM) method is provided to iteratively\ncalculate all variables LRC-MCF. Extensive experimental results on seven\nbenchmark multi-view datasets validate the effectiveness of the LRC-MCF method.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 15:45:10 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Meng", "Xiangzhu", ""], ["Wei", "Wei", ""], ["Liu", "Wenzhe", ""]]}, {"id": "2107.05074", "submitter": "Ayush Sekhari", "authors": "Satyen Kale, Ayush Sekhari, Karthik Sridharan", "title": "SGD: The Role of Implicit Regularization, Batch-size and Multiple-epochs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Multi-epoch, small-batch, Stochastic Gradient Descent (SGD) has been the\nmethod of choice for learning with large over-parameterized models. A popular\ntheory for explaining why SGD works well in practice is that the algorithm has\nan implicit regularization that biases its output towards a good solution.\nPerhaps the theoretically most well understood learning setting for SGD is that\nof Stochastic Convex Optimization (SCO), where it is well known that SGD learns\nat a rate of $O(1/\\sqrt{n})$, where $n$ is the number of samples. In this\npaper, we consider the problem of SCO and explore the role of implicit\nregularization, batch size and multiple epochs for SGD. Our main contributions\nare threefold:\n  (a) We show that for any regularizer, there is an SCO problem for which\nRegularized Empirical Risk Minimzation fails to learn. This automatically rules\nout any implicit regularization based explanation for the success of SGD.\n  (b) We provide a separation between SGD and learning via Gradient Descent on\nempirical loss (GD) in terms of sample complexity. We show that there is an SCO\nproblem such that GD with any step size and number of iterations can only learn\nat a suboptimal rate: at least $\\widetilde{\\Omega}(1/n^{5/12})$.\n  (c) We present a multi-epoch variant of SGD commonly used in practice. We\nprove that this algorithm is at least as good as single pass SGD in the worst\ncase. However, for certain SCO problems, taking multiple passes over the\ndataset can significantly outperform single pass SGD.\n  We extend our results to the general learning setting by showing a problem\nwhich is learnable for any data distribution, and for this problem, SGD is\nstrictly better than RERM for any regularization function. We conclude by\ndiscussing the implications of our results for deep learning, and show a\nseparation between SGD and ERM for two layer diagonal neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 15:50:01 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kale", "Satyen", ""], ["Sekhari", "Ayush", ""], ["Sridharan", "Karthik", ""]]}, {"id": "2107.05088", "submitter": "TIm Menzies", "authors": "Tim Menzies, Kewen Peng, Andre Lustosa", "title": "Fairer Software Made Easier (using \"Keys\")", "comments": "Submitted to NIER ASE 2021 (new ideas, emerging research)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Can we simplify explanations for software analytics? Maybe. Recent results\nshow that systems often exhibit a \"keys effect\"; i.e. a few key features\ncontrol the rest. Just to say the obvious, for systems controlled by a few\nkeys, explanation and control is just a matter of running a handful of\n\"what-if\" queries across the keys. By exploiting the keys effect, it should be\npossible to dramatically simplify even complex explanations, such as those\nrequired for ethical AI systems.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 17:02:07 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Menzies", "Tim", ""], ["Peng", "Kewen", ""], ["Lustosa", "Andre", ""]]}, {"id": "2107.05101", "submitter": "Racine Ly", "authors": "Racine Ly", "title": "Machine Learning Challenges and Opportunities in the African\n  Agricultural Sector -- A General Perspective", "comments": "This paper has been submitted as an internal discussion paper at\n  AKADEMIYA2063. It has 13 pages and contains 4 images and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The improvement of computers' capacities, advancements in algorithmic\ntechniques, and the significant increase of available data have enabled the\nrecent developments of Artificial Intelligence (AI) technology. One of its\nbranches, called Machine Learning (ML), has shown strong capacities in\nmimicking characteristics attributed to human intelligence, such as vision,\nspeech, and problem-solving. However, as previous technological revolutions\nsuggest, their most significant impacts could be mostly expected on other\nsectors that were not traditional users of that technology. The agricultural\nsector is vital for African economies; improving yields, mitigating losses, and\neffective management of natural resources are crucial in a climate change era.\nMachine Learning is a technology with an added value in making predictions,\nhence the potential to reduce uncertainties and risk across sectors, in this\ncase, the agricultural sector. The purpose of this paper is to contextualize\nand discuss barriers to ML-based solutions for African agriculture. In the\nsecond section, we provided an overview of ML technology from a historical and\ntechnical perspective and its main driving force. In the third section, we\nprovided a brief review of the current use of ML in agriculture. Finally, in\nsection 4, we discuss ML growing interest in Africa and the potential barriers\nto creating and using ML-based solutions in the agricultural sector.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 17:48:23 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Ly", "Racine", ""]]}, {"id": "2107.05112", "submitter": "Md Omar Faruk Rokon", "authors": "Md Omar Faruk Rokon, Pei Yan, Risul Islam, Michalis Faloutsos", "title": "Repo2Vec: A Comprehensive Embedding Approach for Determining Repository\n  Similarity", "comments": "10 pages, 8 figures, 5 tables. In press: ICSME'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How can we identify similar repositories and clusters among a large online\narchive, such as GitHub? Determiningrepository similarity is an essential\nbuilding block in studying the dynamics and the evolution of such software\necosystems. The key challenge is to determine the right representation for the\ndiverse repository features in a way that: (a) it captures all aspects of the\navailable information, and (b) it is readily usable by MLalgorithms. We propose\nRepo2Vec, a comprehensive embedding approach to represent a repository as a\ndistributed vector by combining features from three types of information\nsources. As our key novelty, we consider three types of information:\n(a)metadata, (b) the structure of the repository, and (c) the source code. We\nalso introduce a series of embedding approaches to represent and combine these\ninformation types into a single embedding. We evaluate our method with two real\ndatasets from GitHub for a combined 1013 repositories. First, we show that our\nmethod outperforms previous methods in terms of precision (93%vs 78%), with\nnearly twice as many Strongly Similar repositories and 30% fewer False\nPositives. Second, we show how Repo2Vecprovides a solid basis for: (a)\ndistinguishing between malware and benign repositories, and (b) identifying a\nmeaningful hierarchical clustering. For example, we achieve 98% precision and\n96%recall in distinguishing malware and benign repositories. Overall, our work\nis a fundamental building block for enabling many repository analysis functions\nsuch as repository categorization by target platform or intention, detecting\ncode-reuse and clones, and identifying lineage and evolution.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 18:57:03 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Rokon", "Md Omar Faruk", ""], ["Yan", "Pei", ""], ["Islam", "Risul", ""], ["Faloutsos", "Michalis", ""]]}, {"id": "2107.05151", "submitter": "Reza Karimi Dr", "authors": "H.J. Meijer, J. Truong, R. Karimi", "title": "Document Embedding for Scientific Articles: Efficacy of Word Embeddings\n  vs TFIDF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the last few years, neural network derived word embeddings became\npopular in the natural language processing literature. Studies conducted have\nmostly focused on the quality and application of word embeddings trained on\npublic available corpuses such as Wikipedia or other news and social media\nsources. However, these studies are limited to generic text and thus lack\ntechnical and scientific nuances such as domain specific vocabulary,\nabbreviations, or scientific formulas which are commonly used in academic\ncontext. This research focuses on the performance of word embeddings applied to\na large scale academic corpus. More specifically, we compare quality and\nefficiency of trained word embeddings to TFIDF representations in modeling\ncontent of scientific articles. We use a word2vec skip-gram model trained on\ntitles and abstracts of about 70 million scientific articles. Furthermore, we\nhave developed a benchmark to evaluate content models in a scientific context.\nThe benchmark is based on a categorization task that matches articles to\njournals for about 1.3 million articles published in 2017. Our results show\nthat content models based on word embeddings are better for titles (short text)\nwhile TFIDF works better for abstracts (longer text). However, the slight\nimprovement of TFIDF for larger text comes at the expense of 3.7 times more\nmemory requirement as well as up to 184 times higher computation times which\nmay make it inefficient for online applications. In addition, we have created a\n2-dimensional visualization of the journals modeled via embeddings to\nqualitatively inspect embedding model. This graph shows useful insights and can\nbe used to find competitive journals or gaps to propose new journals.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 23:58:39 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Meijer", "H. J.", ""], ["Truong", "J.", ""], ["Karimi", "R.", ""]]}, {"id": "2107.05154", "submitter": "Shalini Pandey", "authors": "Shalini Pandey, Jaideep Srivastava", "title": "MOOCRep: A Unified Pre-trained Embedding of MOOC Entities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning models have been built to tackle information overload\nissues on Massive Open Online Courses (MOOC) platforms. These models rely on\nlearning powerful representations of MOOC entities. However, they suffer from\nthe problem of scarce expert label data. To overcome this problem, we propose\nto learn pre-trained representations of MOOC entities using abundant unlabeled\ndata from the structure of MOOCs which can directly be applied to the\ndownstream tasks. While existing pre-training methods have been successful in\nNLP areas as they learn powerful textual representation, their models do not\nleverage the richer information about MOOC entities. This richer information\nincludes the graph relationship between the lectures, concepts, and courses\nalong with the domain knowledge about the complexity of a concept. We develop\nMOOCRep, a novel method based on Transformer language model trained with two\npre-training objectives : 1) graph-based objective to capture the powerful\nsignal of entities and relations that exist in the graph, and 2)\ndomain-oriented objective to effectively incorporate the complexity level of\nconcepts. Our experiments reveal that MOOCRep's embeddings outperform\nstate-of-the-art representation learning methods on two tasks important for\neducation community, concept pre-requisite prediction and lecture\nrecommendation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 00:11:25 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Pandey", "Shalini", ""], ["Srivastava", "Jaideep", ""]]}, {"id": "2107.05166", "submitter": "Soham Pal", "authors": "Soham Pal, Yash Gupta, Aditya Kanade, Shirish Shevade", "title": "Stateful Detection of Model Extraction Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-Learning-as-a-Service providers expose machine learning (ML) models\nthrough application programming interfaces (APIs) to developers. Recent work\nhas shown that attackers can exploit these APIs to extract good approximations\nof such ML models, by querying them with samples of their choosing. We propose\nVarDetect, a stateful monitor that tracks the distribution of queries made by\nusers of such a service, to detect model extraction attacks. Harnessing the\nlatent distributions learned by a modified variational autoencoder, VarDetect\nrobustly separates three types of attacker samples from benign samples, and\nsuccessfully raises an alarm for each. Further, with VarDetect deployed as an\nautomated defense mechanism, the extracted substitute models are found to\nexhibit poor performance and transferability, as intended. Finally, we\ndemonstrate that even adaptive attackers with prior knowledge of the deployment\nof VarDetect, are detected by it.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 02:18:26 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Pal", "Soham", ""], ["Gupta", "Yash", ""], ["Kanade", "Aditya", ""], ["Shevade", "Shirish", ""]]}, {"id": "2107.05172", "submitter": "Ziaur Rahman", "authors": "Sk. Tanzir Mehedi, Adnan Anwar, Ziaur Rahman and Kawsar Ahmed", "title": "Deep Transfer Learning Based Intrusion Detection System for Electric\n  Vehicular Networks", "comments": "23 Pages, 14 Figures, 6 Tables with Appendix", "journal-ref": "MDPI Sensor, 2021, 21(14), 4736", "doi": "10.3390/s21144736", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Controller Area Network (CAN) bus works as an important protocol in the\nreal-time In-Vehicle Network (IVN) systems for its simple, suitable, and robust\narchitecture. The risk of IVN devices has still been insecure and vulnerable\ndue to the complex data-intensive architectures which greatly increase the\naccessibility to unauthorized networks and the possibility of various types of\ncyberattacks. Therefore, the detection of cyberattacks in IVN devices has\nbecome a growing interest. With the rapid development of IVNs and evolving\nthreat types, the traditional machine learning-based IDS has to update to cope\nwith the security requirements of the current environment. Nowadays, the\nprogression of deep learning, deep transfer learning, and its impactful outcome\nin several areas has guided as an effective solution for network intrusion\ndetection. This manuscript proposes a deep transfer learning-based IDS model\nfor IVN along with improved performance in comparison to several other existing\nmodels. The unique contributions include effective attribute selection which is\nbest suited to identify malicious CAN messages and accurately detect the normal\nand abnormal activities, designing a deep transfer learning-based LeNet model,\nand evaluating considering real-world data. To this end, an extensive\nexperimental performance evaluation has been conducted. The architecture along\nwith empirical analyses shows that the proposed IDS greatly improves the\ndetection accuracy over the mainstream machine learning, deep learning, and\nbenchmark deep transfer learning models and has demonstrated better performance\nfor real-time IVN security.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 03:06:49 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Mehedi", "Sk. Tanzir", ""], ["Anwar", "Adnan", ""], ["Rahman", "Ziaur", ""], ["Ahmed", "Kawsar", ""]]}, {"id": "2107.05181", "submitter": "Biplav Choudhury", "authors": "Biplav Choudhury, Vijay K. Shah, Aidin Ferdowsi, Jeffrey H. Reed, and\n  Y. Thomas Hou", "title": "AoI-minimizing Scheduling in UAV-relayed IoT Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to flexibility, autonomy and low operational cost, unmanned aerial\nvehicles (UAVs), as fixed aerial base stations, are increasingly being used as\n\\textit{relays} to collect time-sensitive information (i.e., status updates)\nfrom IoT devices and deliver it to the nearby terrestrial base station (TBS),\nwhere the information gets processed. In order to ensure timely delivery of\ninformation to the TBS (from all IoT devices), optimal scheduling of\ntime-sensitive information over two hop UAV-relayed IoT networks (i.e., IoT\ndevice to the UAV [hop 1], and UAV to the TBS [hop 2]) becomes a critical\nchallenge. To address this, we propose scheduling policies for Age of\nInformation (AoI) minimization in such two-hop UAV-relayed IoT networks. To\nthis end, we present a low-complexity MAF-MAD scheduler, that employs Maximum\nAoI First (MAF) policy for sampling of IoT devices at UAV (hop 1) and Maximum\nAoI Difference (MAD) policy for updating sampled packets from UAV to the TBS\n(hop 2). We show that MAF-MAD is the optimal scheduler under ideal conditions,\ni.e., error-free channels and generate-at-will traffic generation at IoT\ndevices. On the contrary, for realistic conditions, we propose a\nDeep-Q-Networks (DQN) based scheduler. Our simulation results show that\nDQN-based scheduler outperforms MAF-MAD scheduler and three other baseline\nschedulers, i.e., Maximal AoI First (MAF), Round Robin (RR) and Random,\nemployed at both hops under general conditions when the network is small (with\n10's of IoT devices). However, it does not scale well with network size whereas\nMAF-MAD outperforms all other schedulers under all considered scenarios for\nlarger networks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 03:52:59 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 14:26:43 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 12:39:36 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Choudhury", "Biplav", ""], ["Shah", "Vijay K.", ""], ["Ferdowsi", "Aidin", ""], ["Reed", "Jeffrey H.", ""], ["Hou", "Y. Thomas", ""]]}, {"id": "2107.05188", "submitter": "Menghan Hu", "authors": "Yao Chang, Hu Menghan, Zhai Guangtao, Zhang Xiao-Ping", "title": "TransClaw U-Net: Claw U-Net with Transformers for Medical Image\n  Segmentation", "comments": "8 page, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, computer-aided diagnosis has become an increasingly popular\ntopic. Methods based on convolutional neural networks have achieved good\nperformance in medical image segmentation and classification. Due to the\nlimitations of the convolution operation, the long-term spatial features are\noften not accurately obtained. Hence, we propose a TransClaw U-Net network\nstructure, which combines the convolution operation with the transformer\noperation in the encoding part. The convolution part is applied for extracting\nthe shallow spatial features to facilitate the recovery of the image resolution\nafter upsampling. The transformer part is used to encode the patches, and the\nself-attention mechanism is used to obtain global information between\nsequences. The decoding part retains the bottom upsampling structure for better\ndetail segmentation performance. The experimental results on Synapse\nMulti-organ Segmentation Datasets show that the performance of TransClaw U-Net\nis better than other network structures. The ablation experiments also prove\nthe generalization performance of TransClaw U-Net.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 04:17:39 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Chang", "Yao", ""], ["Menghan", "Hu", ""], ["Guangtao", "Zhai", ""], ["Xiao-Ping", "Zhang", ""]]}, {"id": "2107.05216", "submitter": "Sobhan Miryoosefi", "authors": "Sobhan Miryoosefi, Chi Jin", "title": "A Simple Reward-free Approach to Constrained Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In constrained reinforcement learning (RL), a learning agent seeks to not\nonly optimize the overall reward but also satisfy the additional safety,\ndiversity, or budget constraints. Consequently, existing constrained RL\nsolutions require several new algorithmic ingredients that are notably\ndifferent from standard RL. On the other hand, reward-free RL is independently\ndeveloped in the unconstrained literature, which learns the transition dynamics\nwithout using the reward information, and thus naturally capable of addressing\nRL with multiple objectives under the common dynamics. This paper bridges\nreward-free RL and constrained RL. Particularly, we propose a simple\nmeta-algorithm such that given any reward-free RL oracle, the approachability\nand constrained RL problems can be directly solved with negligible overheads in\nsample complexity. Utilizing the existing reward-free RL solvers, our framework\nprovides sharp sample complexity results for constrained RL in the tabular MDP\nsetting, matching the best existing results up to a factor of horizon\ndependence; our framework directly extends to a setting of tabular two-player\nMarkov games, and gives a new result for constrained RL with linear function\napproximation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 06:27:30 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Miryoosefi", "Sobhan", ""], ["Jin", "Chi", ""]]}, {"id": "2107.05217", "submitter": "Lingwei Zhu", "authors": "Lingwei Zhu, Toshinori Kitamura, Takamitsu Matsubara", "title": "Cautious Actor-Critic", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The oscillating performance of off-policy learning and persisting errors in\nthe actor-critic (AC) setting call for algorithms that can conservatively learn\nto suit the stability-critical applications better. In this paper, we propose a\nnovel off-policy AC algorithm cautious actor-critic (CAC). The name cautious\ncomes from the doubly conservative nature that we exploit the classic policy\ninterpolation from conservative policy iteration for the actor and the\nentropy-regularization of conservative value iteration for the critic. Our key\nobservation is the entropy-regularized critic facilitates and simplifies the\nunwieldy interpolated actor update while still ensuring robust policy\nimprovement. We compare CAC to state-of-the-art AC methods on a set of\nchallenging continuous control problems and demonstrate that CAC achieves\ncomparable performance while significantly stabilizes learning.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 06:40:02 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Zhu", "Lingwei", ""], ["Kitamura", "Toshinori", ""], ["Matsubara", "Takamitsu", ""]]}, {"id": "2107.05249", "submitter": "Margarita Rebolledo", "authors": "Margarita Rebolledo, Daan Zeeuwe, Thomas Bartz-Beielstein, A.E. Eiben", "title": "Impact of Energy Efficiency on the Morphology and Behaviour of Evolved\n  Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most evolutionary robotics studies focus on evolving some targeted behavior\nwithout taking the energy usage into account. This limits the practical value\nof such systems because energy efficiency is an important property for\nreal-world autonomous robots. In this paper, we mitigate this problem by\nextending our simulator with a battery model and taking energy consumption into\naccount during fitness evaluations. Using this system we investigate how energy\nawareness affects the evolution of robots. Since our system is to evolve\nmorphologies as well as controllers, the main research question is twofold: (i)\nwhat is the impact on the morphologies of the evolved robots, and (ii) what is\nthe impact on the behavior of the evolved robots if energy consumption is\nincluded in the fitness evaluation? The results show that including the energy\nconsumption in the fitness in a multi-objective fashion (by NSGA-II) reduces\nthe average size of robot bodies while at the same time reducing their speed.\nHowever, robots generated without size reduction can achieve speeds comparable\nto robots from the baseline set.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 08:13:09 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Rebolledo", "Margarita", ""], ["Zeeuwe", "Daan", ""], ["Bartz-Beielstein", "Thomas", ""], ["Eiben", "A. E.", ""]]}, {"id": "2107.05278", "submitter": "Erwin de Gelder", "authors": "Erwin de Gelder, Eric Cator, Jan-Pieter Paardekooper, Olaf Op den\n  Camp, Bart De Schutter", "title": "Constrained Sampling from a Kernel Density Estimator to Generate\n  Scenarios for the Assessment of Automated Vehicles", "comments": "6 pages, 3 figures, to be published in the proceedings of the IEEE\n  Intelligent Vehicle Symposium Workshops (IV workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The safety assessment of automated vehicles (AVs) is an important aspect of\nthe development cycle of AVs. A scenario-based assessment approach is accepted\nby many players in the field as part of the complete safety assessment. A\nscenario is a representation of a situation on the road to which the AV needs\nto respond appropriately. One way to generate the required scenario-based test\ndescriptions is to parameterize the scenarios and to draw these parameters from\na probability density function (pdf). Because the shape of the pdf is unknown\nbeforehand, assuming a functional form of the pdf and fitting the parameters to\nthe data may lead to inaccurate fits. As an alternative, Kernel Density\nEstimation (KDE) is a promising candidate for estimating the underlying pdf,\nbecause it is flexible with the underlying distribution of the parameters.\nDrawing random samples from a pdf estimated with KDE is possible without the\nneed of evaluating the actual pdf, which makes it suitable for drawing random\nsamples for, e.g., Monte Carlo methods. Sampling from a KDE while the samples\nsatisfy a linear equality constraint, however, has not been described in the\nliterature, as far as the authors know.\n  In this paper, we propose a method to sample from a pdf estimated using KDE,\nsuch that the samples satisfy a linear equality constraint. We also present an\nalgorithm of our method in pseudo-code. The method can be used to generating\nscenarios that have, e.g., a predetermined starting speed or to generate\ndifferent types of scenarios. This paper also shows that the method for\nsampling scenarios can be used in case a Singular Value Decomposition (SVD) is\nused to reduce the dimension of the parameter vectors.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 09:28:25 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["de Gelder", "Erwin", ""], ["Cator", "Eric", ""], ["Paardekooper", "Jan-Pieter", ""], ["Camp", "Olaf Op den", ""], ["De Schutter", "Bart", ""]]}, {"id": "2107.05289", "submitter": "Manjesh Kumar Hanawal", "authors": "Rahul Vaze and Manjesh K. Hanawal", "title": "Continuous Time Bandits With Sampling Costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a continuous-time multi-arm bandit problem (CTMAB), where the\nlearner can sample arms any number of times in a given interval and obtain a\nrandom reward from each sample, however, increasing the frequency of sampling\nincurs an additive penalty/cost. Thus, there is a tradeoff between obtaining\nlarge reward and incurring sampling cost as a function of the sampling\nfrequency. The goal is to design a learning algorithm that minimizes regret,\nthat is defined as the difference of the payoff of the oracle policy and that\nof the learning algorithm. CTMAB is fundamentally different than the usual\nmulti-arm bandit problem (MAB), e.g., even the single-arm case is non-trivial\nin CTMAB, since the optimal sampling frequency depends on the mean of the arm,\nwhich needs to be estimated. We first establish lower bounds on the regret\nachievable with any algorithm and then propose algorithms that achieve the\nlower bound up to logarithmic factors. For the single-arm case, we show that\nthe lower bound on the regret is $\\Omega((\\log T)^2/\\mu)$, where $\\mu$ is the\nmean of the arm, and $T$ is the time horizon. For the multiple arms case, we\nshow that the lower bound on the regret is $\\Omega((\\log T)^2 \\mu/\\Delta^2)$,\nwhere $\\mu$ now represents the mean of the best arm, and $\\Delta$ is the\ndifference of the mean of the best and the second-best arm. We then propose an\nalgorithm that achieves the bound up to constant terms.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 10:00:35 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Vaze", "Rahul", ""], ["Hanawal", "Manjesh K.", ""]]}, {"id": "2107.05298", "submitter": "Enzo Tartaglione", "authors": "Enzo Tartaglione, St\\'ephane Lathuili\\`ere, Attilio Fiandrotti, Marco\n  Cagnazzo, Marco Grangetto", "title": "HEMP: High-order Entropy Minimization for neural network comPression", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2021.07.022", "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We formulate the entropy of a quantized artificial neural network as a\ndifferentiable function that can be plugged as a regularization term into the\ncost function minimized by gradient descent. Our formulation scales efficiently\nbeyond the first order and is agnostic of the quantization scheme. The network\ncan then be trained to minimize the entropy of the quantized parameters, so\nthat they can be optimally compressed via entropy coding. We experiment with\nour entropy formulation at quantizing and compressing well-known network\narchitectures over multiple datasets. Our approach compares favorably over\nsimilar methods, enjoying the benefits of higher order entropy estimate,\nshowing flexibility towards non-uniform quantization (we use Lloyd-max\nquantization), scalability towards any entropy order to be minimized and\nefficiency in terms of compression. We show that HEMP is able to work in\nsynergy with other approaches aiming at pruning or quantizing the model itself,\ndelivering significant benefits in terms of storage size compressibility\nwithout harming the model's performance.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 10:17:53 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Tartaglione", "Enzo", ""], ["Lathuili\u00e8re", "St\u00e9phane", ""], ["Fiandrotti", "Attilio", ""], ["Cagnazzo", "Marco", ""], ["Grangetto", "Marco", ""]]}, {"id": "2107.05307", "submitter": "Chengcheng Wang", "authors": "Yanpeng Cao, Chengcheng Wang, Changjun Song, Yongming Tang, He Li", "title": "Real-Time Super-Resolution System of 4K-Video Based on Deep Learning", "comments": "8 pages, 7 figures, ASAP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video super-resolution (VSR) technology excels in reconstructing low-quality\nvideo, avoiding unpleasant blur effect caused by interpolation-based\nalgorithms. However, vast computation complexity and memory occupation hampers\nthe edge of deplorability and the runtime inference in real-life applications,\nespecially for large-scale VSR task. This paper explores the possibility of\nreal-time VSR system and designs an efficient and generic VSR network, termed\nEGVSR. The proposed EGVSR is based on spatio-temporal adversarial learning for\ntemporal coherence. In order to pursue faster VSR processing ability up to 4K\nresolution, this paper tries to choose lightweight network structure and\nefficient upsampling method to reduce the computation required by EGVSR network\nunder the guarantee of high visual quality. Besides, we implement the batch\nnormalization computation fusion, convolutional acceleration algorithm and\nother neural network acceleration techniques on the actual hardware platform to\noptimize the inference process of EGVSR network. Finally, our EGVSR achieves\nthe real-time processing capacity of 4K@29.61FPS. Compared with TecoGAN, the\nmost advanced VSR network at present, we achieve 85.04% reduction of\ncomputation density and 7.92x performance speedups. In terms of visual quality,\nthe proposed EGVSR tops the list of most metrics (such as LPIPS, tOF, tLP,\netc.) on the public test dataset Vid4 and surpasses other state-of-the-art\nmethods in overall performance score. The source code of this project can be\nfound on https://github.com/Thmen/EGVSR.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 10:35:05 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 14:42:34 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Cao", "Yanpeng", ""], ["Wang", "Chengcheng", ""], ["Song", "Changjun", ""], ["Tang", "Yongming", ""], ["Li", "He", ""]]}, {"id": "2107.05320", "submitter": "Amit Peleg", "authors": "Amit Peleg, Naama Pearl and Ron Meir", "title": "Metalearning Linear Bandits by Prior Update", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully Bayesian approaches to sequential decision-making assume that problem\nparameters are generated from a known prior, while in practice, such\ninformation is often lacking, and needs to be estimated through learning. This\nproblem is exacerbated in decision-making setups with partial information,\nwhere using a misspecified prior may lead to poor exploration and inferior\nperformance. In this work we prove, in the context of stochastic linear bandits\nand Gaussian priors, that as long as the prior estimate is sufficiently close\nto the true prior, the performance of an algorithm that uses the misspecified\nprior is close to that of the algorithm that uses the true prior. Next, we\naddress the task of learning the prior through metalearning, where a learner\nupdates its estimate of the prior across multiple task instances in order to\nimprove performance on future tasks. The estimated prior is then updated within\neach task based on incoming observations, while actions are selected in order\nto maximize expected reward. In this work we apply this scheme within a linear\nbandit setting, and provide algorithms and regret bounds, demonstrating its\neffectiveness, as compared to an algorithm that knows the correct prior. Our\nresults hold for a broad class of algorithms, including, for example, Thompson\nSampling and Information Directed Sampling.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 11:17:01 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Peleg", "Amit", ""], ["Pearl", "Naama", ""], ["Meir", "Ron", ""]]}, {"id": "2107.05344", "submitter": "Jin-Gu Kang", "authors": "Jin-Gu Kang, Jin-Woo Jung", "title": "Post Triangular Rewiring Method for Shorter RRT Robot Path Planning", "comments": "Under review on IJFIS(International Journal of Fuzzy logic and\n  Intelligent Systems; http://www.ijfis.org)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper proposed the 'Post Triangular Rewiring' method that minimizes the\nsacrifice of planning time and overcomes the limit of Optimality of\nsampling-based algorithm such as Rapidly-exploring Random Tree (RRT) algorithm.\nThe proposed 'Post Triangular Rewiring' method creates a closer to the optimal\npath than RRT algorithm before application through the triangular inequality\nprinciple. The experiments were conducted to verify a performance of the\nproposed method. When the method proposed in this paper are applied to the RRT\nalgorithm, the Optimality efficiency increase compared to the planning time.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 12:10:37 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kang", "Jin-Gu", ""], ["Jung", "Jin-Woo", ""]]}, {"id": "2107.05346", "submitter": "Muhammad Salman Shaukat", "authors": "Muhammad Salman Shaukat, Bjarne Christian Hiller, Sebastian Bader,\n  Thomas Kirste", "title": "SimDem A Multi-agent Simulation Environment to Model Persons with\n  Dementia and their Assistance", "comments": "5 pages, accepted in ARIAL@IJCAI 2021: 4th Workshop on AI for Aging,\n  Rehabilitation, and Intelligent Assisted Living", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Developing artificial intelligence based assistive systems to aid Persons\nwith Dementia (PwD) requires large amounts of training data. However, data\ncollection poses ethical, legal, economic, and logistic issues. Synthetic data\ngeneration tools, in this regard, provide a potential solution. However, we\nbelieve that already available such tools do not adequately reflect cognitive\ndeficiencies in behavior simulation. To counter these issues we propose a\nsimulation model (SimDem ) that primarily focuses on cognitive impairments\nsuffered by PwD and can be easily configured and adapted by the users to model\nand evaluate assistive solutions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 12:13:47 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Shaukat", "Muhammad Salman", ""], ["Hiller", "Bjarne Christian", ""], ["Bader", "Sebastian", ""], ["Kirste", "Thomas", ""]]}, {"id": "2107.05348", "submitter": "Zhuo Chen", "authors": "Zhuo Chen, Jiaoyan Chen, Yuxia Geng, Jeff Z. Pan, Zonggang Yuan and\n  Huajun Chen", "title": "Zero-shot Visual Question Answering using Knowledge Graph", "comments": "accepted at the International Semantic Web Conference '21 (ISWC 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating external knowledge to Visual Question Answering (VQA) has\nbecome a vital practical need. Existing methods mostly adopt pipeline\napproaches with different components for knowledge matching and extraction,\nfeature learning, etc.However, such pipeline approaches suffer when some\ncomponent does not perform well, which leads to error propagation and poor\noverall performance. Furthermore, the majority of existing approaches ignore\nthe answer bias issue -- many answers may have never appeared during training\n(i.e., unseen answers) in real-word application. To bridge these gaps, in this\npaper, we propose a Zero-shot VQA algorithm using knowledge graphs and a\nmask-based learning mechanism for better incorporating external knowledge, and\npresent new answer-based Zero-shot VQA splits for the F-VQA dataset.\nExperiments show that our method can achieve state-of-the-art performance in\nZero-shot VQA with unseen answers, meanwhile dramatically augment existing\nend-to-end models on the normal F-VQA task.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 12:17:18 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 02:50:38 GMT"}, {"version": "v3", "created": "Wed, 14 Jul 2021 11:37:13 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Chen", "Zhuo", ""], ["Chen", "Jiaoyan", ""], ["Geng", "Yuxia", ""], ["Pan", "Jeff Z.", ""], ["Yuan", "Zonggang", ""], ["Chen", "Huajun", ""]]}, {"id": "2107.05363", "submitter": "Domonkos Czifra", "authors": "Domonkos Czifra, Endre Cs\\'oka, Zsolt Zombori, G\\'eza Makay", "title": "Towards solving the 7-in-a-row game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our paper explores the game theoretic value of the 7-in-a-row game. We reduce\nthe problem to solving a finite board game, which we target using Proof Number\nSearch. We present a number of heuristic improvements to Proof Number Search\nand examine their effect within the context of this particular game. Although\nour paper does not solve the 7-in-a-row game, our experiments indicate that we\nhave made significant progress towards it.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 08:17:12 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Czifra", "Domonkos", ""], ["Cs\u00f3ka", "Endre", ""], ["Zombori", "Zsolt", ""], ["Makay", "G\u00e9za", ""]]}, {"id": "2107.05366", "submitter": "Xiaoleii Liu", "authors": "Naicheng Guo and Xiaolei Liu and Shaoshuai Li and Qiongxu Ma and Yunan\n  Zhao and Bing Han and Lin Zheng and Kaixin Gao and Xiaobo Guo", "title": "HCGR: Hyperbolic Contrastive Graph Representation Learning for\n  Session-based Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Session-based recommendation (SBR) learns users' preferences by capturing the\nshort-term and sequential patterns from the evolution of user behaviors. Among\nthe studies in the SBR field, graph-based approaches are a relatively powerful\nkind of way, which generally extract item information by message aggregation\nunder Euclidean space. However, such methods can't effectively extract the\nhierarchical information contained among consecutive items in a session, which\nis critical to represent users' preferences. In this paper, we present a\nhyperbolic contrastive graph recommender (HCGR), a principled session-based\nrecommendation framework involving Lorentz hyperbolic space to adequately\ncapture the coherence and hierarchical representations of the items. Within\nthis framework, we design a novel adaptive hyperbolic attention computation to\naggregate the graph message of each user's preference in a session-based\nbehavior sequence. In addition, contrastive learning is leveraged to optimize\nthe item representation by considering the geodesic distance between positive\nand negative samples in hyperbolic space. Extensive experiments on four\nreal-world datasets demonstrate that HCGR consistently outperforms\nstate-of-the-art baselines by 0.43$\\%$-28.84$\\%$ in terms of $HitRate$, $NDCG$\nand $MRR$.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 01:46:16 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Guo", "Naicheng", ""], ["Liu", "Xiaolei", ""], ["Li", "Shaoshuai", ""], ["Ma", "Qiongxu", ""], ["Zhao", "Yunan", ""], ["Han", "Bing", ""], ["Zheng", "Lin", ""], ["Gao", "Kaixin", ""], ["Guo", "Xiaobo", ""]]}, {"id": "2107.05368", "submitter": "Golsa Heidari", "authors": "Golsa Heidari, Kamran Zamanifar", "title": "A Three Phase Semantic Web Matchmaker", "comments": "14 pages, 1 figure, International Journal of Smart Home. arXiv admin\n  note: text overlap with arXiv:2107.02609", "journal-ref": "International Journal of Smart Home, Vol.4, No.3, July, 2010", "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since using environments that are made according to the service oriented\narchitecture, we have more effective and dynamic applications. Semantic\nmatchmaking process is finding valuable service candidates for substitution. It\nis a very important aspect of using semantic Web Services. Our proposed\nmatchmaker algorithm performs semantic matching of Web Services on the basis of\ninput and output descriptions of semantic Web Services matching. This technique\ntakes advantages from a graph structure and flow networks. Our novel approach\nis assigning matchmaking scores to semantics of the inputs and outputs\nparameters and their types. It makes a flow network in which the weights of the\nedges are these scores, using FordFulkerson algorithm, we find matching rate of\ntwo web services. So, all services should be described in the same Ontology Web\nLanguage. Among these candidates, best one is chosen for substitution in the\ncase of an execution failure. Our approach uses the algorithm that has the\nleast running time among all others that can be used for bipartite matching.\nThe importance of problem is that in real systems, many fundamental problems\nwill occur by late answering. So system`s service should always be on and if\none of them crashes, it would be replaced fast. Semantic web matchmaker eases\nthis process.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 13:39:11 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Heidari", "Golsa", ""], ["Zamanifar", "Kamran", ""]]}, {"id": "2107.05369", "submitter": "Carsten Lutz", "authors": "Anneke Haga and Carsten Lutz and Leif Sabellek and Frank Wolter", "title": "How to Approximate Ontology-Mediated Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We introduce and study several notions of approximation for ontology-mediated\nqueries based on the description logics ALC and ALCI. Our approximations are of\ntwo kinds: we may (1) replace the ontology with one formulated in a tractable\nontology language such as ELI or certain TGDs and (2) replace the database with\none from a tractable class such as the class of databases whose treewidth is\nbounded by a constant. We determine the computational complexity and the\nrelative completeness of the resulting approximations. (Almost) all of them\nreduce the data complexity from coNP-complete to PTime, in some cases even to\nfixed-parameter tractable and to linear time. While approximations of kind (1)\nalso reduce the combined complexity, this tends to not be the case for\napproximations of kind (2). In some cases, the combined complexity even\nincreases.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 12:29:50 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Haga", "Anneke", ""], ["Lutz", "Carsten", ""], ["Sabellek", "Leif", ""], ["Wolter", "Frank", ""]]}, {"id": "2107.05373", "submitter": "Wei Tao", "authors": "Wei Tao, Yanlin Wang, Ensheng Shi, Lun Du, Shi Han, Hongyu Zhang,\n  Dongmei Zhang, Wenqiang Zhang", "title": "On the Evaluation of Commit Message Generation Models: An Experimental\n  Study", "comments": "Accepted to International Conference on Software Maintenance and\n  Evolution (ICSME) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commit messages are natural language descriptions of code changes, which are\nimportant for program understanding and maintenance. However, writing commit\nmessages manually is time-consuming and laborious, especially when the code is\nupdated frequently. Various approaches utilizing generation or retrieval\ntechniques have been proposed to automatically generate commit messages. To\nachieve a better understanding of how the existing approaches perform in\nsolving this problem, this paper conducts a systematic and in-depth analysis of\nthe state-of-the-art models and datasets. We find that: (1) Different variants\nof the BLEU metric are used in previous works, which affects the evaluation and\nunderstanding of existing methods. (2) Most existing datasets are crawled only\nfrom Java repositories while repositories in other programming languages are\nnot sufficiently explored. (3) Dataset splitting strategies can influence the\nperformance of existing models by a large margin. Some models show better\nperformance when the datasets are split by commit, while other models perform\nbetter when the datasets are split by timestamp or by project. Based on our\nfindings, we conduct a human evaluation and find the BLEU metric that best\ncorrelates with the human scores for the task. We also collect a large-scale,\ninformation-rich, and multi-language commit message dataset MCMD and evaluate\nexisting models on this dataset. Furthermore, we conduct extensive experiments\nunder different dataset splitting strategies and suggest the suitable models\nunder different scenarios. Based on the experimental results and findings, we\nprovide feasible suggestions for comprehensively evaluating commit message\ngeneration models and discuss possible future research directions. We believe\nthis work can help practitioners and researchers better evaluate and select\nmodels for automatic commit message generation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 12:38:02 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 02:04:53 GMT"}, {"version": "v3", "created": "Mon, 26 Jul 2021 11:32:56 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Tao", "Wei", ""], ["Wang", "Yanlin", ""], ["Shi", "Ensheng", ""], ["Du", "Lun", ""], ["Han", "Shi", ""], ["Zhang", "Hongyu", ""], ["Zhang", "Dongmei", ""], ["Zhang", "Wenqiang", ""]]}, {"id": "2107.05380", "submitter": "Anish Acharya", "authors": "Anish Acharya, Rudrajit Das", "title": "DISCO : efficient unsupervised decoding for discrete natural language\n  problems via convex relaxation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper we study test time decoding; an ubiquitous step in almost all\nsequential text generation task spanning across a wide array of natural\nlanguage processing (NLP) problems. Our main contribution is to develop a\ncontinuous relaxation framework for the combinatorial NP-hard decoding problem\nand propose Disco - an efficient algorithm based on standard first order\ngradient based. We provide tight analysis and show that our proposed algorithm\nlinearly converges to within $\\epsilon$ neighborhood of the optima. Finally, we\nperform preliminary experiments on the task of adversarial text generation and\nshow superior performance of Disco over several popular decoding approaches.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 00:40:25 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 20:34:37 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Acharya", "Anish", ""], ["Das", "Rudrajit", ""]]}, {"id": "2107.05383", "submitter": "Jesse David Dinneen", "authors": "Jesse David Dinneen and Helen Bubinger", "title": "Not Quite 'Ask a Librarian': AI on the Nature, Value, and Future of LIS", "comments": "Final version to appear in ASIS&T '21: Proceedings of the 84th Annual\n  Meeting of the Association for Information Science & Technology, 58", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.CY cs.HC cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  AI language models trained on Web data generate prose that reflects human\nknowledge and public sentiments, but can also contain novel insights and\npredictions. We asked the world's best language model, GPT-3, fifteen difficult\nquestions about the nature, value, and future of library and information\nscience (LIS), topics that receive perennial attention from LIS scholars. We\npresent highlights from its 45 different responses, which range from platitudes\nand caricatures to interesting perspectives and worrisome visions of the\nfuture, thus providing an LIS-tailored demonstration of the current performance\nof AI language models. We also reflect on the viability of using AI to forecast\nor generate research ideas in this way today. Finally, we have shared the full\nresponse log online for readers to consider and evaluate for themselves.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:20:17 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Dinneen", "Jesse David", ""], ["Bubinger", "Helen", ""]]}, {"id": "2107.05385", "submitter": "Monika Daryani", "authors": "Monika Daryani and James Caverlee", "title": "Identifying Hijacked Reviews", "comments": "To be published in ACL-IJCNLP 2021 Workshop on e-Commerce and NLP\n  (ECNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake reviews and review manipulation are growing problems on online\nmarketplaces globally. Review Hijacking is a new review manipulation tactic in\nwhich unethical sellers \"hijack\" an existing product page (usually one with\nmany positive reviews), then update the product details like title, photo, and\ndescription with those of an entirely different product. With the earlier\nreviews still attached, the new item appears well-reviewed. However, there are\nno public datasets of review hijacking and little is known in the literature\nabout this tactic. Hence, this paper proposes a three-part study: (i) we\npropose a framework to generate synthetically labeled data for review hijacking\nby swapping products and reviews; (ii) then, we evaluate the potential of both\na Twin LSTM network and BERT sequence pair classifier to distinguish legitimate\nreviews from hijacked ones using this data; and (iii) we then deploy the best\nperforming model on a collection of 31K products (with 6.5 M reviews) in the\noriginal data, where we find 100s of previously unknown examples of review\nhijacking.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 20:43:36 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Daryani", "Monika", ""], ["Caverlee", "James", ""]]}, {"id": "2107.05407", "submitter": "Andrea Banino", "authors": "Andrea Banino, Jan Balaguer, Charles Blundell", "title": "PonderNet: Learning to Ponder", "comments": "16 pages, 2 figures, 2 tables, 8th ICML Workshop on Automated Machine\n  Learning (2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In standard neural networks the amount of computation used grows with the\nsize of the inputs, but not with the complexity of the problem being learnt. To\novercome this limitation we introduce PonderNet, a new algorithm that learns to\nadapt the amount of computation based on the complexity of the problem at hand.\nPonderNet learns end-to-end the number of computational steps to achieve an\neffective compromise between training prediction accuracy, computational cost\nand generalization. On a complex synthetic problem, PonderNet dramatically\nimproves performance over previous adaptive computation methods and\nadditionally succeeds at extrapolation tests where traditional neural networks\nfail. Also, our method matched the current state of the art results on a real\nworld question and answering dataset, but using less compute. Finally,\nPonderNet reached state of the art results on a complex task designed to test\nthe reasoning capabilities of neural networks.1\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 13:24:03 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Banino", "Andrea", ""], ["Balaguer", "Jan", ""], ["Blundell", "Charles", ""]]}, {"id": "2107.05418", "submitter": "Zhenhua Feng", "authors": "Shuang Wu, Xiaoning Song and Zhenhua Feng", "title": "MECT: Multi-Metadata Embedding based Cross-Transformer for Chinese Named\n  Entity Recognition", "comments": "Accepted to ACL-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently, word enhancement has become very popular for Chinese Named Entity\nRecognition (NER), reducing segmentation errors and increasing the semantic and\nboundary information of Chinese words. However, these methods tend to ignore\nthe information of the Chinese character structure after integrating the\nlexical information. Chinese characters have evolved from pictographs since\nancient times, and their structure often reflects more information about the\ncharacters. This paper presents a novel Multi-metadata Embedding based\nCross-Transformer (MECT) to improve the performance of Chinese NER by fusing\nthe structural information of Chinese characters. Specifically, we use\nmulti-metadata embedding in a two-stream Transformer to integrate Chinese\ncharacter features with the radical-level embedding. With the structural\ncharacteristics of Chinese characters, MECT can better capture the semantic\ninformation of Chinese characters for NER. The experimental results obtained on\nseveral well-known benchmarking datasets demonstrate the merits and superiority\nof the proposed MECT method.\\footnote{The source code of the proposed method is\npublicly available at https://github.com/CoderMusou/MECT4CNER.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 13:39:06 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wu", "Shuang", ""], ["Song", "Xiaoning", ""], ["Feng", "Zhenhua", ""]]}, {"id": "2107.05431", "submitter": "Andrea Banino", "authors": "Andrea Banino, Adri\\`a Puidomenech Badia, Jacob Walker, Tim Scholtes,\n  Jovana Mitrovic, Charles Blundell", "title": "CoBERL: Contrastive BERT for Reinforcement Learning", "comments": "9 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reinforcement learning (RL) agents require a large amount of experience\nto solve tasks. We propose Contrastive BERT for RL (CoBERL), an agent that\ncombines a new contrastive loss and a hybrid LSTM-transformer architecture to\ntackle the challenge of improving data efficiency. CoBERL enables efficient,\nrobust learning from pixels across a wide range of domains. We use\nbidirectional masked prediction in combination with a generalization of recent\ncontrastive methods to learn better representations for transformers in RL,\nwithout the need of hand engineered data augmentations. We find that CoBERL\nconsistently improves performance across the full Atari suite, a set of control\ntasks and a challenging 3D environment.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 13:54:18 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Banino", "Andrea", ""], ["Badia", "Adri\u00e0 Puidomenech", ""], ["Walker", "Jacob", ""], ["Scholtes", "Tim", ""], ["Mitrovic", "Jovana", ""], ["Blundell", "Charles", ""]]}, {"id": "2107.05438", "submitter": "Noor Sajid", "authors": "Noor Sajid and Francesco Faccio and Lancelot Da Costa and Thomas Parr\n  and J\\\"urgen Schmidhuber and Karl Friston", "title": "Bayesian brains and the R\\'enyi divergence", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Under the Bayesian brain hypothesis, behavioural variations can be attributed\nto different priors over generative model parameters. This provides a formal\nexplanation for why individuals exhibit inconsistent behavioural preferences\nwhen confronted with similar choices. For example, greedy preferences are a\nconsequence of confident (or precise) beliefs over certain outcomes. Here, we\noffer an alternative account of behavioural variability using R\\'enyi\ndivergences and their associated variational bounds. R\\'enyi bounds are\nanalogous to the variational free energy (or evidence lower bound) and can be\nderived under the same assumptions. Importantly, these bounds provide a formal\nway to establish behavioural differences through an $\\alpha$ parameter, given\nfixed priors. This rests on changes in $\\alpha$ that alter the bound (on a\ncontinuous scale), inducing different posterior estimates and consequent\nvariations in behaviour. Thus, it looks as if individuals have different\npriors, and have reached different conclusions. More specifically, $\\alpha \\to\n0^{+}$ optimisation leads to mass-covering variational estimates and increased\nvariability in choice behaviour. Furthermore, $\\alpha \\to + \\infty$\noptimisation leads to mass-seeking variational posteriors and greedy\npreferences. We exemplify this formulation through simulations of the\nmulti-armed bandit task. We note that these $\\alpha$ parameterisations may be\nespecially relevant, i.e., shape preferences, when the true posterior is not in\nthe same family of distributions as the assumed (simpler) approximate density,\nwhich may be the case in many real-world scenarios. The ensuing departure from\nvanilla variational inference provides a potentially useful explanation for\ndifferences in behavioural preferences of biological (or artificial) agents\nunder the assumption that the brain performs variational Bayesian inference.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 14:14:36 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Sajid", "Noor", ""], ["Faccio", "Francesco", ""], ["Da Costa", "Lancelot", ""], ["Parr", "Thomas", ""], ["Schmidhuber", "J\u00fcrgen", ""], ["Friston", "Karl", ""]]}, {"id": "2107.05445", "submitter": "Yipeng Zhang", "authors": "Yipeng Zhang, Tyler L. Hayes, Christopher Kanan", "title": "Disentangling Transfer and Interference in Multi-Domain Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are incredibly good at transferring knowledge from one domain to\nanother, enabling rapid learning of new tasks. Likewise, transfer learning has\nenabled enormous success in many computer vision problems using pretraining.\nHowever, the benefits of transfer in multi-domain learning, where a network\nlearns multiple tasks defined by different datasets, has not been adequately\nstudied. Learning multiple domains could be beneficial or these domains could\ninterfere with each other given limited network capacity. In this work, we\ndecipher the conditions where interference and knowledge transfer occur in\nmulti-domain learning. We propose new metrics disentangling interference and\ntransfer and set up experimental protocols. We further examine the roles of\nnetwork capacity, task grouping, and dynamic loss weighting in reducing\ninterference and facilitating transfer. We demonstrate our findings on the\nCIFAR-100, MiniPlaces, and Tiny-ImageNet datasets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 01:30:36 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 01:14:21 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Zhang", "Yipeng", ""], ["Hayes", "Tyler L.", ""], ["Kanan", "Christopher", ""]]}, {"id": "2107.05446", "submitter": "Cian Eastwood", "authors": "Cian Eastwood, Ian Mason, Christopher K. I. Williams, Bernhard\n  Sch\\\"olkopf", "title": "Source-Free Adaptation to Measurement Shift via Bottom-Up Feature\n  Restoration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source-free domain adaptation (SFDA) aims to adapt a model trained on\nlabelled data in a source domain to unlabelled data in a target domain without\naccess to the source-domain data during adaptation. Existing methods for SFDA\nleverage entropy-minimization techniques which: (i) apply only to\nclassification; (ii) destroy model calibration; and (iii) rely on the source\nmodel achieving a good level of feature-space class-separation in the target\ndomain. We address these issues for a particularly pervasive type of domain\nshift called measurement shift, characterized by a change in measurement system\n(e.g. a change in sensor or lighting). In the source domain, we store a\nlightweight and flexible approximation of the feature distribution under the\nsource data. In the target domain, we adapt the feature-extractor such that the\napproximate feature distribution under the target data realigns with that saved\non the source. We call this method Feature Restoration (FR) as it seeks to\nextract features with the same semantics from the target domain as were\npreviously extracted from the source. We additionally propose Bottom-Up Feature\nRestoration (BUFR), a bottom-up training scheme for FR which boosts performance\nby preserving learnt structure in the later layers of a network. Through\nexperiments we demonstrate that BUFR often outperforms existing SFDA methods in\nterms of accuracy, calibration, and data efficiency, while being less reliant\non the performance of the source model in the target domain.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 14:21:14 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Eastwood", "Cian", ""], ["Mason", "Ian", ""], ["Williams", "Christopher K. I.", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2107.05457", "submitter": "Mehdi Amian", "authors": "Mehdi Amian", "title": "Improving the Algorithm of Deep Learning with Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an adjustment to the original differentially private\nstochastic gradient descent (DPSGD) algorithm for deep learning models is\nproposed. As a matter of motivation, to date, almost no state-of-the-art\nmachine learning algorithm hires the existing privacy protecting components due\nto otherwise serious compromise in their utility despite the vital necessity.\nThe idea in this study is natural and interpretable, contributing to improve\nthe utility with respect to the state-of-the-art. Another property of the\nproposed technique is its simplicity which makes it again more natural and also\nmore appropriate for real world and specially commercial applications. The\nintuition is to trim and balance out wild individual discrepancies for privacy\nreasons, and at the same time, to preserve relative individual differences for\nseeking performance. The idea proposed here can also be applied to the\nrecurrent neural networks (RNN) to solve the gradient exploding problem. The\nalgorithm is applied to benchmark datasets MNIST and CIFAR-10 for a\nclassification task and the utility measure is calculated. The results\noutperformed the original work.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 14:28:12 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Amian", "Mehdi", ""]]}, {"id": "2107.05458", "submitter": "Soma Bandyopadhyay", "authors": "Soma Bandyopadhyay, Anish Datta, Arpan Pal", "title": "Automated Label Generation for Time Series Classification with\n  Representation Learning: Reduction of Label Cost for Training", "comments": "8 pages, 5 figures, 3 tables accepted in IJCAI2021 Weakly Supervised\n  Representation Learning (WSRL) Workshop ;\n  https://wsl-workshop.github.io/ijcai21.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-series generated by end-users, edge devices, and different wearables are\nmostly unlabelled. We propose a method to auto-generate labels of un-labelled\ntime-series, exploiting very few representative labelled time-series. Our\nmethod is based on representation learning using Auto Encoded Compact Sequence\n(AECS) with a choice of best distance measure. It performs self-correction in\niterations, by learning latent structure, as well as synthetically boosting\nrepresentative time-series using Variational-Auto-Encoder (VAE) to improve the\nquality of labels. We have experimented with UCR and UCI archives, public\nreal-world univariate, multivariate time-series taken from different\napplication domains. Experimental results demonstrate that the proposed method\nis very close to the performance achieved by fully supervised classification.\nThe proposed method not only produces close to benchmark results but\noutperforms the benchmark performance in some cases.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 14:28:40 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Bandyopadhyay", "Soma", ""], ["Datta", "Anish", ""], ["Pal", "Arpan", ""]]}, {"id": "2107.05464", "submitter": "Yao Yao", "authors": "Xiaoyan Cao, Yao Yao, Lanqing Li, Wanpeng Zhang, Zhicheng An, Zhong\n  Zhang, Shihui Guo, Li Xiao, Xiaoyu Cao, and Dijun Luo", "title": "IGrow: A Smart Agriculture Solution to Autonomous Greenhouse Control", "comments": "10 pages, 6 figures, 4 tables, submitted to journal Nature Machine\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agriculture is the foundation of human civilization. However, the rapid\nincrease and aging of the global population pose challenges on this cornerstone\nby demanding more healthy and fresh food. Internet of Things (IoT) technology\nmakes modern autonomous greenhouse a viable and reliable engine of food\nproduction. However, the educated and skilled labor capable of overseeing\nhigh-tech greenhouses is scarce. Artificial intelligence (AI) and cloud\ncomputing technologies are promising solutions for precision control and\nhigh-efficiency production in such controlled environments. In this paper, we\npropose a smart agriculture solution, namely iGrow: (1) we use IoT and cloud\ncomputing technologies to measure, collect, and manage growing data, to support\niteration of our decision-making AI module, which consists of an incremental\nmodel and an optimization algorithm; (2) we propose a three-stage incremental\nmodel based on accumulating data, enabling growers/central computers to\nschedule control strategies conveniently and at low cost; (3) we propose a\nmodel-based iterative optimization algorithm, which can dynamically optimize\nthe greenhouse control strategy in real-time production. In the simulated\nexperiment, evaluation results show the accuracy of our incremental model is\ncomparable to an advanced tomato simulator, while our optimization algorithms\ncan beat the champion of the 2nd Autonomous Greenhouse Challenge. Compelling\nresults from the A/B test in real greenhouses demonstrate that our solution\nsignificantly increases production (commercially sellable fruits) (+ 10.15%)\nand net profit (+ 87.07%) with statistical significance compared to planting\nexperts.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 11:35:50 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Cao", "Xiaoyan", ""], ["Yao", "Yao", ""], ["Li", "Lanqing", ""], ["Zhang", "Wanpeng", ""], ["An", "Zhicheng", ""], ["Zhang", "Zhong", ""], ["Guo", "Shihui", ""], ["Xiao", "Li", ""], ["Cao", "Xiaoyu", ""], ["Luo", "Dijun", ""]]}, {"id": "2107.05468", "submitter": "Shaoyu Cai", "authors": "Shaoyu Cai, Kening Zhu, Yuki Ban, Takuji Narumi", "title": "Visual-Tactile Cross-Modal Data Generation using Residue-Fusion GAN with\n  Feature-Matching and Perceptual Losses", "comments": "8 pages, 6 figures, Accepted by IEEE Robotics and Automation Letters", "journal-ref": null, "doi": "10.1109/LRA.2021.3095925", "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing psychophysical studies have revealed that the cross-modal\nvisual-tactile perception is common for humans performing daily activities.\nHowever, it is still challenging to build the algorithmic mapping from one\nmodality space to another, namely the cross-modal visual-tactile data\ntranslation/generation, which could be potentially important for robotic\noperation. In this paper, we propose a deep-learning-based approach for\ncross-modal visual-tactile data generation by leveraging the framework of the\ngenerative adversarial networks (GANs). Our approach takes the visual image of\na material surface as the visual data, and the accelerometer signal induced by\nthe pen-sliding movement on the surface as the tactile data. We adopt the\nconditional-GAN (cGAN) structure together with the residue-fusion (RF) module,\nand train the model with the additional feature-matching (FM) and perceptual\nlosses to achieve the cross-modal data generation. The experimental results\nshow that the inclusion of the RF module, and the FM and the perceptual losses\nsignificantly improves cross-modal data generation performance in terms of the\nclassification accuracy upon the generated data and the visual similarity\nbetween the ground-truth and the generated data.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 14:36:16 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Cai", "Shaoyu", ""], ["Zhu", "Kening", ""], ["Ban", "Yuki", ""], ["Narumi", "Takuji", ""]]}, {"id": "2107.05474", "submitter": "Hao Fu", "authors": "Zhi Bian, Shaojun Zhou, Hao Fu, Qihong Yang, Zhenqi Sun, Junjie Tang,\n  Guiquan Liu, Kaikui Liu, Xiaolong Li", "title": "Denoising User-aware Memory Network for Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For better user satisfaction and business effectiveness, more and more\nattention has been paid to the sequence-based recommendation system, which is\nused to infer the evolution of users' dynamic preferences, and recent studies\nhave noticed that the evolution of users' preferences can be better understood\nfrom the implicit and explicit feedback sequences. However, most of the\nexisting recommendation techniques do not consider the noise contained in\nimplicit feedback, which will lead to the biased representation of user\ninterest and a suboptimal recommendation performance. Meanwhile, the existing\nmethods utilize item sequence for capturing the evolution of user interest. The\nperformance of these methods is limited by the length of the sequence, and can\nnot effectively model the long-term interest in a long period of time. Based on\nthis observation, we propose a novel CTR model named denoising user-aware\nmemory network (DUMN). Specifically, the framework: (i) proposes a feature\npurification module based on orthogonal mapping, which use the representation\nof explicit feedback to purify the representation of implicit feedback, and\neffectively denoise the implicit feedback; (ii) designs a user memory network\nto model the long-term interests in a fine-grained way by improving the memory\nnetwork, which is ignored by the existing methods; and (iii) develops a\npreference-aware interactive representation component to fuse the long-term and\nshort-term interests of users based on gating to understand the evolution of\nunbiased preferences of users. Extensive experiments on two real e-commerce\nuser behavior datasets show that DUMN has a significant improvement over the\nstate-of-the-art baselines. The code of DUMN model has been uploaded as an\nadditional material.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 14:39:36 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bian", "Zhi", ""], ["Zhou", "Shaojun", ""], ["Fu", "Hao", ""], ["Yang", "Qihong", ""], ["Sun", "Zhenqi", ""], ["Tang", "Junjie", ""], ["Liu", "Guiquan", ""], ["Liu", "Kaikui", ""], ["Li", "Xiaolong", ""]]}, {"id": "2107.05482", "submitter": "Bo Zhou", "authors": "Bo Zhou, Chi Liu, James S. Duncan", "title": "Anatomy-Constrained Contrastive Learning for Synthetic Segmentation\n  without Ground-truth", "comments": "Accepted at MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A large amount of manual segmentation is typically required to train a robust\nsegmentation network so that it can segment objects of interest in a new\nimaging modality. The manual efforts can be alleviated if the manual\nsegmentation in one imaging modality (e.g., CT) can be utilized to train a\nsegmentation network in another imaging modality (e.g., CBCT/MRI/PET). In this\nwork, we developed an anatomy-constrained contrastive synthetic segmentation\nnetwork (AccSeg-Net) to train a segmentation network for a target imaging\nmodality without using its ground truth. Specifically, we proposed to use\nanatomy-constraint and patch contrastive learning to ensure the anatomy\nfidelity during the unsupervised adaptation, such that the segmentation network\ncan be trained on the adapted image with correct anatomical structure/content.\nThe training data for our AccSeg-Net consists of 1) imaging data paired with\nsegmentation ground-truth in source modality, and 2) unpaired source and target\nmodality imaging data. We demonstrated successful applications on CBCT, MRI,\nand PET imaging data, and showed superior segmentation performances as compared\nto previous methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 14:54:04 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Zhou", "Bo", ""], ["Liu", "Chi", ""], ["Duncan", "James S.", ""]]}, {"id": "2107.05491", "submitter": "Bo Zhou", "authors": "Bo Zhou, Rui Wang, Ming-Kai Chen, Adam P. Mecca, Ryan S. O'Dell,\n  Christopher H. Van Dyck, Richard E. Carson, James S. Duncan, Chi Liu", "title": "Synthesizing Multi-Tracer PET Images for Alzheimer's Disease Patients\n  using a 3D Unified Anatomy-aware Cyclic Adversarial Network", "comments": "Accepted at MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Positron Emission Tomography (PET) is an important tool for studying\nAlzheimer's disease (AD). PET scans can be used as diagnostics tools, and to\nprovide molecular characterization of patients with cognitive disorders.\nHowever, multiple tracers are needed to measure glucose metabolism (18F-FDG),\nsynaptic vesicle protein (11C-UCB-J), and $\\beta$-amyloid (11C-PiB).\nAdministering multiple tracers to patient will lead to high radiation dose and\ncost. In addition, access to PET scans using new or less-available tracers with\nsophisticated production methods and short half-life isotopes may be very\nlimited. Thus, it is desirable to develop an efficient multi-tracer PET\nsynthesis model that can generate multi-tracer PET from single-tracer PET.\nPrevious works on medical image synthesis focus on one-to-one fixed domain\ntranslations, and cannot simultaneously learn the feature from multi-tracer\ndomains. Given 3 or more tracers, relying on previous methods will also create\na heavy burden on the number of models to be trained. To tackle these issues,\nwe propose a 3D unified anatomy-aware cyclic adversarial network (UCAN) for\ntranslating multi-tracer PET volumes with one unified generative model, where\nMR with anatomical information is incorporated. Evaluations on a multi-tracer\nPET dataset demonstrate the feasibility that our UCAN can generate high-quality\nmulti-tracer PET volumes, with NMSE less than 15% for all PET tracers.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 15:10:29 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Zhou", "Bo", ""], ["Wang", "Rui", ""], ["Chen", "Ming-Kai", ""], ["Mecca", "Adam P.", ""], ["O'Dell", "Ryan S.", ""], ["Van Dyck", "Christopher H.", ""], ["Carson", "Richard E.", ""], ["Duncan", "James S.", ""], ["Liu", "Chi", ""]]}, {"id": "2107.05534", "submitter": "Xianbiao Qi", "authors": "Yuxiang Zhong, Xianbiao Qi, Shanjun Li, Dengyi Gu, Yihao Chen, Peiyang\n  Ning, Rong Xiao", "title": "1st Place Solution for ICDAR 2021 Competition on Mathematical Formula\n  Detection", "comments": "1st Place Solution for ICDAR 2021 Competition on Mathematical Formula\n  Detection. http://transcriptorium.eu/~htrcontest/MathsICDAR2021/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this technical report, we present our 1st place solution for the ICDAR\n2021 competition on mathematical formula detection (MFD). The MFD task has\nthree key challenges including a large scale span, large variation of the ratio\nbetween height and width, and rich character set and mathematical expressions.\nConsidering these challenges, we used Generalized Focal Loss (GFL), an\nanchor-free method, instead of the anchor-based method, and prove the Adaptive\nTraining Sampling Strategy (ATSS) and proper Feature Pyramid Network (FPN) can\nwell solve the important issue of scale variation. Meanwhile, we also found\nsome tricks, e.g., Deformable Convolution Network (DCN), SyncBN, and Weighted\nBox Fusion (WBF), were effective in MFD task. Our proposed method ranked 1st in\nthe final 15 teams.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 16:03:16 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Zhong", "Yuxiang", ""], ["Qi", "Xianbiao", ""], ["Li", "Shanjun", ""], ["Gu", "Dengyi", ""], ["Chen", "Yihao", ""], ["Ning", "Peiyang", ""], ["Xiao", "Rong", ""]]}, {"id": "2107.05541", "submitter": "Mohammad Sabik Irbaz", "authors": "Fahim Shahriar Khan, Mueeze Al Mushabbir, Mohammad Sabik Irbaz, MD\n  Abdullah Al Nasim", "title": "End-to-End Natural Language Understanding Pipeline for Bangla\n  Conversational Agents", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Chatbots are intelligent software built to be used as a replacement for human\ninteraction. However, existing studies typically do not provide enough support\nfor low-resource languages like Bangla. Moreover, due to the increasing\npopularity of social media, we can also see the rise of interactions in Bangla\ntransliteration (mostly in English) among the native Bangla speakers. In this\npaper, we propose a novel approach to build a Bangla chatbot aimed to be used\nas a business assistant which can communicate in Bangla and Bangla\nTransliteration in English with high confidence consistently. Since annotated\ndata was not available for this purpose, we had to work on the whole machine\nlearning life cycle (data preparation, machine learning modeling, and model\ndeployment) using Rasa Open Source Framework, fastText embeddings, Polyglot\nembeddings, Flask, and other systems as building blocks. While working with the\nskewed annotated dataset, we try out different setups and pipelines to evaluate\nwhich works best and provide possible reasoning behind the observed results.\nFinally, we present a pipeline for intent classification and entity extraction\nwhich achieves reasonable performance (accuracy: 83.02%, precision: 80.82%,\nrecall: 83.02%, F1-score: 80%).\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 16:09:22 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 01:52:58 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 19:23:43 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Khan", "Fahim Shahriar", ""], ["Mushabbir", "Mueeze Al", ""], ["Irbaz", "Mohammad Sabik", ""], ["Nasim", "MD Abdullah Al", ""]]}, {"id": "2107.05545", "submitter": "Kaixin Wang", "authors": "Kaixin Wang, Kuangqi Zhou, Qixin Zhang, Jie Shao, Bryan Hooi, Jiashi\n  Feng", "title": "Towards Better Laplacian Representation in Reinforcement Learning with\n  Generalized Graph Drawing", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Laplacian representation recently gains increasing attention for\nreinforcement learning as it provides succinct and informative representation\nfor states, by taking the eigenvectors of the Laplacian matrix of the\nstate-transition graph as state embeddings. Such representation captures the\ngeometry of the underlying state space and is beneficial to RL tasks such as\noption discovery and reward shaping. To approximate the Laplacian\nrepresentation in large (or even continuous) state spaces, recent works propose\nto minimize a spectral graph drawing objective, which however has infinitely\nmany global minimizers other than the eigenvectors. As a result, their learned\nLaplacian representation may differ from the ground truth. To solve this\nproblem, we reformulate the graph drawing objective into a generalized form and\nderive a new learning objective, which is proved to have eigenvectors as its\nunique global minimizer. It enables learning high-quality Laplacian\nrepresentations that faithfully approximate the ground truth. We validate this\nvia comprehensive experiments on a set of gridworld and continuous control\nenvironments. Moreover, we show that our learned Laplacian representations lead\nto more exploratory options and better reward shaping.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 16:14:02 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wang", "Kaixin", ""], ["Zhou", "Kuangqi", ""], ["Zhang", "Qixin", ""], ["Shao", "Jie", ""], ["Hooi", "Bryan", ""], ["Feng", "Jiashi", ""]]}, {"id": "2107.05558", "submitter": "Zixuan Kang", "authors": "Chen Weiya, Li Jiajia, Kang Zixuan", "title": "Research on Metro Service Quality Improvement Schemes Considering\n  Feasibility", "comments": "in Chinese language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is an important management task of metro agencies to formulate reasonable\nimprovement schemes based on the result of service quality surveys. Considering\nscores, weights, and improvement feasibility of service quality attributes in a\ncertain period, this paper integrates Decision Tree (DT) into\nImportance-Performance analysis (IPA) to build a DT-IPA model, which is used to\ndetermine the improvement priority of attributes, and to quantify the\nimprovement degree. If-then rules extracted from the optimal decision tree and\nthe improvement feasibility computed by analytic hierarchy process are two main\nitems derived from the DT-IPA model. They are used to optimize the initial\nimprovement priority of attributes determined by IPA and to quantify the degree\nof improvement of the adjusted attributes. Then, the overall service quality\ncan reach a high score, realizing the operation goal. The effectiveness of the\nDT-IPA model was verified through an empirical study which was taken place in\nChangsha Metro, China. The proposed method can be a decision-making tool for\nmetro agency managers to improve the quality of metro service.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 09:26:00 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Weiya", "Chen", ""], ["Jiajia", "Li", ""], ["Zixuan", "Kang", ""]]}, {"id": "2107.05566", "submitter": "Philipp Seifer", "authors": "Philipp Seifer, Ralf L\\\"ammel, Steffen Staab", "title": "ProGS: Property Graph Shapes Language (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Property graphs constitute data models for representing knowledge graphs.\nThey allow for the convenient representation of facts, including facts about\nfacts, represented by triples in subject or object position of other triples.\nKnowledge graphs such as Wikidata are created by a diversity of contributors\nand a range of sources leaving them prone to two types of errors. The first\ntype of error, falsity of facts, is addressed by property graphs through the\nrepresentation of provenance and validity, making triples occur as first-order\nobjects in subject position of metadata triples. The second type of error,\nviolation of domain constraints, has not been addressed with regard to property\ngraphs so far. In RDF representations, this error can be addressed by shape\nlanguages such as SHACL or ShEx, which allow for checking whether graphs are\nvalid with respect to a set of domain constraints. Borrowing ideas from the\nsyntax and semantics definitions of SHACL, we design a shape language for\nproperty graphs, ProGS, which allows for formulating shape constraints on\nproperty graphs including their specific constructs, such as edges with\nidentities and key-value annotations to both nodes and edges. We define a\nformal semantics of ProGS, investigate the resulting complexity of validating\nproperty graphs against sets of ProGS shapes, compare with corresponding\nresults for SHACL, and implement a prototypical validator that utilizes answer\nset programming.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 16:44:21 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Seifer", "Philipp", ""], ["L\u00e4mmel", "Ralf", ""], ["Staab", "Steffen", ""]]}, {"id": "2107.05599", "submitter": "Terence Broad", "authors": "Terence Broad, Sebastian Berns, Simon Colton, Mick Grierson", "title": "Active Divergence with Generative Deep Learning -- A Survey and Taxonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Generative deep learning systems offer powerful tools for artefact\ngeneration, given their ability to model distributions of data and generate\nhigh-fidelity results. In the context of computational creativity, however, a\nmajor shortcoming is that they are unable to explicitly diverge from the\ntraining data in creative ways and are limited to fitting the target data\ndistribution. To address these limitations, there have been a growing number of\napproaches for optimising, hacking and rewriting these models in order to\nactively diverge from the training data. We present a taxonomy and\ncomprehensive survey of the state of the art of active divergence techniques,\nhighlighting the potential for computational creativity researchers to advance\nthese methods and use deep generative models in truly creative systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:29:28 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Broad", "Terence", ""], ["Berns", "Sebastian", ""], ["Colton", "Simon", ""], ["Grierson", "Mick", ""]]}, {"id": "2107.05612", "submitter": "Valts Blukis", "authors": "Valts Blukis, Chris Paxton, Dieter Fox, Animesh Garg, Yoav Artzi", "title": "A Persistent Spatial Semantic Representation for High-level Natural\n  Language Instruction Execution", "comments": "Submitted to CoRL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language provides an accessible and expressive interface to specify\nlong-term tasks for robotic agents. However, non-experts are likely to specify\nsuch tasks with high-level instructions, which abstract over specific robot\nactions through several layers of abstraction. We propose that key to bridging\nthis gap between language and robot actions over long execution horizons are\npersistent representations. We propose a persistent spatial semantic\nrepresentation method, and show how it enables building an agent that performs\nhierarchical reasoning to effectively execute long-term tasks. We evaluate our\napproach on the ALFRED benchmark and achieve state-of-the-art results, despite\ncompletely avoiding the commonly used step-by-step instructions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:47:19 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Blukis", "Valts", ""], ["Paxton", "Chris", ""], ["Fox", "Dieter", ""], ["Garg", "Animesh", ""], ["Artzi", "Yoav", ""]]}, {"id": "2107.05617", "submitter": "Alina Roitberg", "authors": "Alina Roitberg, David Schneider, Aulia Djamal, Constantin Seibold,\n  Simon Rei{\\ss}, Rainer Stiefelhagen", "title": "Let's Play for Action: Recognizing Activities of Daily Living by\n  Learning from Life Simulation Video Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing Activities of Daily Living (ADL) is a vital process for\nintelligent assistive robots, but collecting large annotated datasets requires\ntime-consuming temporal labeling and raises privacy concerns, e.g., if the data\nis collected in a real household. In this work, we explore the concept of\nconstructing training examples for ADL recognition by playing life simulation\nvideo games and introduce the SIMS4ACTION dataset created with the popular\ncommercial game THE SIMS 4. We build Sims4Action by specifically executing\nactions-of-interest in a \"top-down\" manner, while the gaming circumstances\nallow us to freely switch between environments, camera angles and subject\nappearances. While ADL recognition on gaming data is interesting from the\ntheoretical perspective, the key challenge arises from transferring it to the\nreal-world applications, such as smart-homes or assistive robotics. To meet\nthis requirement, Sims4Action is accompanied with a GamingToReal benchmark,\nwhere the models are evaluated on real videos derived from an existing ADL\ndataset. We integrate two modern algorithms for video-based activity\nrecognition in our framework, revealing the value of life simulation video\ngames as an inexpensive and far less intrusive source of training data.\nHowever, our results also indicate that tasks involving a mixture of gaming and\nreal data are challenging, opening a new research direction. We will make our\ndataset publicly available at https://github.com/aroitberg/sims4action.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:53:38 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Roitberg", "Alina", ""], ["Schneider", "David", ""], ["Djamal", "Aulia", ""], ["Seibold", "Constantin", ""], ["Rei\u00df", "Simon", ""], ["Stiefelhagen", "Rainer", ""]]}, {"id": "2107.05627", "submitter": "Deepak Pathak", "authors": "Shikhar Bahl, Abhinav Gupta, Deepak Pathak", "title": "Hierarchical Neural Dynamic Policies", "comments": "Accepted at RSS 2021. Videos and code at\n  https://shikharbahl.github.io/hierarchical-ndps/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of generalization to unseen configurations for dynamic\ntasks in the real world while learning from high-dimensional image input. The\nfamily of nonlinear dynamical system-based methods have successfully\ndemonstrated dynamic robot behaviors but have difficulty in generalizing to\nunseen configurations as well as learning from image inputs. Recent works\napproach this issue by using deep network policies and reparameterize actions\nto embed the structure of dynamical systems but still struggle in domains with\ndiverse configurations of image goals, and hence, find it difficult to\ngeneralize. In this paper, we address this dichotomy by leveraging embedding\nthe structure of dynamical systems in a hierarchical deep policy learning\nframework, called Hierarchical Neural Dynamical Policies (H-NDPs). Instead of\nfitting deep dynamical systems to diverse data directly, H-NDPs form a\ncurriculum by learning local dynamical system-based policies on small regions\nin state-space and then distill them into a global dynamical system-based\npolicy that operates only from high-dimensional images. H-NDPs additionally\nprovide smooth trajectories, a strong safety benefit in the real world. We\nperform extensive experiments on dynamic tasks both in the real world (digit\nwriting, scooping, and pouring) and simulation (catching, throwing, picking).\nWe show that H-NDPs are easily integrated with both imitation as well as\nreinforcement learning setups and achieve state-of-the-art results. Video\nresults are at https://shikharbahl.github.io/hierarchical-ndps/\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:59:58 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Bahl", "Shikhar", ""], ["Gupta", "Abhinav", ""], ["Pathak", "Deepak", ""]]}, {"id": "2107.05682", "submitter": "Angelica Louren\\c{c}o Oliveira", "authors": "Angelica Louren\\c{c}o Oliveira and Marcos Eduardo Valle", "title": "Least-Squares Linear Dilation-Erosion Regressor Trained using Stochastic\n  Descent Gradient or the Difference of Convex Methods", "comments": "15 pages", "journal-ref": "BRACIS 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a hybrid morphological neural network for regression\ntasks called linear dilation-erosion regression ($\\ell$-DER). In few words, an\n$\\ell$-DER model is given by a convex combination of the composition of linear\nand elementary morphological operators. As a result, they yield continuous\npiecewise linear functions and, thus, are universal approximators. Apart from\nintroducing the $\\ell$-DER models, we present three approaches for training\nthese models: one based on stochastic descent gradient and two based on the\ndifference of convex programming problems. Finally, we evaluate the performance\nof the $\\ell$-DER model using 14 regression tasks. Although the approach based\non SDG revealed faster than the other two, the $\\ell$-DER trained using a\ndisciplined convex-concave programming problem outperformed the others in terms\nof the least mean absolute error score.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 18:41:59 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Oliveira", "Angelica Louren\u00e7o", ""], ["Valle", "Marcos Eduardo", ""]]}, {"id": "2107.05729", "submitter": "Yicheng Fei", "authors": "Yicheng Fei, Xaq Pitkow", "title": "Generalization of graph network inferences in higher-order probabilistic\n  graphical models", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Probabilistic graphical models provide a powerful tool to describe complex\nstatistical structure, with many real-world applications in science and\nengineering from controlling robotic arms to understanding neuronal\ncomputations. A major challenge for these graphical models is that inferences\nsuch as marginalization are intractable for general graphs. These inferences\nare often approximated by a distributed message-passing algorithm such as\nBelief Propagation, which does not always perform well on graphs with cycles,\nnor can it always be easily specified for complex continuous probability\ndistributions. Such difficulties arise frequently in expressive graphical\nmodels that include intractable higher-order interactions. In this paper we\nconstruct iterative message-passing algorithms using Graph Neural Networks\ndefined on factor graphs to achieve fast approximate inference on graphical\nmodels that involve many-variable interactions. Experimental results on several\nfamilies of graphical models demonstrate the out-of-distribution generalization\ncapability of our method to different sized graphs, and indicate the domain in\nwhich our method gains advantage over Belief Propagation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 20:51:27 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Fei", "Yicheng", ""], ["Pitkow", "Xaq", ""]]}, {"id": "2107.05731", "submitter": "Md Mabrur Husan Dihyat", "authors": "M.M.H Dihyat, K Malik, M.A Khan, B Imran", "title": "Detecting Ideal Instagram Influencer Using Social Network Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social Media is a key aspect of modern society where people share their\nthoughts, views, feelings and sentiments. Over the last few years, the\ninflation in popularity of social media has resulted in a monumental increase\nin data. Users use this medium to express their thoughts, feelings, and\nopinions on a wide variety of subjects, including politics and celebrities.\nSocial Media has thus evolved into a lucrative platform for companies to expand\ntheir scope and improve their prospects. The paper focuses on social network\nanalysis (SNA) for a real-world online marketing strategy. The study\ncontributes by comparing various centrality measures to identify the most\ncentral nodes in the network and uses a linear threshold model to understand\nthe spreading behaviour of individual users. In conclusion, the paper\ncorrelates different centrality measures and spreading behaviour to identify\nthe most influential user in the network\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 20:53:58 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Dihyat", "M. M. H", ""], ["Malik", "K", ""], ["Khan", "M. A", ""], ["Imran", "B", ""]]}, {"id": "2107.05747", "submitter": "Timoleon Moraitis", "authors": "Timoleon Moraitis, Dmitry Toichkin, Yansong Chua, Qinghai Guo", "title": "SoftHebb: Bayesian inference in unsupervised Hebbian soft\n  winner-take-all networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art artificial neural networks (ANNs) require labelled data or\nfeedback between layers, are often biologically implausible, and are vulnerable\nto adversarial attacks that humans are not susceptible to. On the other hand,\nHebbian learning in winner-take-all (WTA) networks, is unsupervised,\nfeed-forward, and biologically plausible. However, an objective optimization\ntheory for WTA networks has been missing, except under very limiting\nassumptions. Here we derive formally such a theory, based on biologically\nplausible but generic ANN elements. Through Hebbian learning, network\nparameters maintain a Bayesian generative model of the data. There is no\nsupervisory loss function, but the network does minimize cross-entropy between\nits activations and the input distribution. The key is a \"soft\" WTA where there\nis no absolute \"hard\" winner neuron, and a specific type of Hebbian-like\nplasticity of weights and biases. We confirm our theory in practice, where, in\nhandwritten digit (MNIST) recognition, our Hebbian algorithm, SoftHebb,\nminimizes cross-entropy without having access to it, and outperforms the more\nfrequently used, hard-WTA-based method. Strikingly, it even outperforms\nsupervised end-to-end backpropagation, under certain conditions. Specifically,\nin a two-layered network, SoftHebb outperforms backpropagation when the\ntraining dataset is only presented once, when the testing data is noisy, and\nunder gradient-based adversarial attacks. Adversarial attacks that confuse\nSoftHebb are also confusing to the human eye. Finally, the model can generate\ninterpolations of objects from its input distribution.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 21:34:45 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Moraitis", "Timoleon", ""], ["Toichkin", "Dmitry", ""], ["Chua", "Yansong", ""], ["Guo", "Qinghai", ""]]}, {"id": "2107.05756", "submitter": "Aron Laszka", "authors": "Salah U. Kadir, Subir Majumder, Ajay D. Chhokra, Abhishek Dubey,\n  Himanshu Neema, Aron Laszka, Anurag K. Srivastava", "title": "Reinforcement Learning based Proactive Control for Transmission Grid\n  Resilience to Wildfire", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power grid operation subject to an extreme event requires decision-making by\nhuman operators under stressful condition with high cognitive load. Decision\nsupport under adverse dynamic events, specially if forecasted, can be\nsupplemented by intelligent proactive control. Power system operation during\nwildfires require resiliency-driven proactive control for load shedding, line\nswitching and resource allocation considering the dynamics of the wildfire and\nfailure propagation. However, possible number of line- and load-switching in a\nlarge system during an event make traditional prediction-driven and stochastic\napproaches computationally intractable, leading operators to often use greedy\nalgorithms. We model and solve the proactive control problem as a Markov\ndecision process and introduce an integrated testbed for spatio-temporal\nwildfire propagation and proactive power-system operation. We transform the\nenormous wildfire-propagation observation space and utilize it as part of a\nheuristic for proactive de-energization of transmission assets. We integrate\nthis heuristic with a reinforcement-learning based proactive policy for\ncontrolling the generating assets. Our approach allows this controller to\nprovide setpoints for a part of the generation fleet, while a myopic operator\ncan determine the setpoints for the remaining set, which results in a symbiotic\naction. We evaluate our approach utilizing the IEEE 24-node system mapped on a\nhypothetical terrain. Our results show that the proposed approach can help the\noperator to reduce load loss during an extreme event, reduce power flow through\nlines that are to be de-energized, and reduce the likelihood of infeasible\npower-flow solutions, which would indicate violation of short-term thermal\nlimits of transmission lines.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 22:04:12 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Kadir", "Salah U.", ""], ["Majumder", "Subir", ""], ["Chhokra", "Ajay D.", ""], ["Dubey", "Abhishek", ""], ["Neema", "Himanshu", ""], ["Laszka", "Aron", ""], ["Srivastava", "Anurag K.", ""]]}, {"id": "2107.05757", "submitter": "Xiantong Zhen", "authors": "Mohammad Mahdi Derakhshani, Xiantong Zhen, Ling Shao, Cees G. M. Snoek", "title": "Kernel Continual Learning", "comments": "accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper introduces kernel continual learning, a simple but effective\nvariant of continual learning that leverages the non-parametric nature of\nkernel methods to tackle catastrophic forgetting. We deploy an episodic memory\nunit that stores a subset of samples for each task to learn task-specific\nclassifiers based on kernel ridge regression. This does not require memory\nreplay and systematically avoids task interference in the classifiers. We\nfurther introduce variational random features to learn a data-driven kernel for\neach task. To do so, we formulate kernel continual learning as a variational\ninference problem, where a random Fourier basis is incorporated as the latent\nvariable. The variational posterior distribution over the random Fourier basis\nis inferred from the coreset of each task. In this way, we are able to generate\nmore informative kernels specific to each task, and, more importantly, the\ncoreset size can be reduced to achieve more compact memory, resulting in more\nefficient continual learning based on episodic memory. Extensive evaluation on\nfour benchmarks demonstrates the effectiveness and promise of kernels for\ncontinual learning.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 22:09:30 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 23:49:54 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Derakhshani", "Mohammad Mahdi", ""], ["Zhen", "Xiantong", ""], ["Shao", "Ling", ""], ["Snoek", "Cees G. M.", ""]]}, {"id": "2107.05777", "submitter": "Bryce Primavera", "authors": "Bryce A. Primavera and Jeffrey M. Shainline", "title": "An active dendritic tree can mitigate fan-in limitations in\n  superconducting neurons", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Superconducting electronic circuits have much to offer with regard to\nneuromorphic hardware. Superconducting quantum interference devices (SQUIDs)\ncan serve as an active element to perform the thresholding operation of a\nneuron's soma. However, a SQUID has a response function that is periodic in the\napplied signal. We show theoretically that if one restricts the total input to\na SQUID to maintain a monotonically increasing response, a large fraction of\nsynapses must be active to drive a neuron to threshold. We then demonstrate\nthat an active dendritic tree (also based on SQUIDs) can significantly reduce\nthe fraction of synapses that must be active to drive the neuron to threshold.\nIn this context, the inclusion of a dendritic tree provides the dual benefits\nof enhancing the computational abilities of each neuron and allowing the neuron\nto spike with sparse input activity.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 23:33:39 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Primavera", "Bryce A.", ""], ["Shainline", "Jeffrey M.", ""]]}, {"id": "2107.05786", "submitter": "Q. Tyrell Davis", "authors": "Q. Tyrell Davis", "title": "Carle's Game: An Open-Ended Challenge in Exploratory Machine Creativity", "comments": "8 pages, 11 figures, accepted to IEEE Conference on Games 2021:\n  978-1-6654-3886-5/21/$31.00 \\copyright 2021 IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is both an introduction and an invitation. It is an introduction\nto CARLE, a Life-like cellular automata simulator and reinforcement learning\nenvironment. It is also an invitation to Carle's Game, a challenge in\nopen-ended machine exploration and creativity. Inducing machine agents to excel\nat creating interesting patterns across multiple cellular automata universes is\na substantial challenge, and approaching this challenge is likely to require\ncontributions from the fields of artificial life, AI, machine learning, and\ncomplexity, at multiple levels of interest. Carle's Game is based on machine\nagent interaction with CARLE, a Cellular Automata Reinforcement Learning\nEnvironment. CARLE is flexible, capable of simulating any of the 262,144\ndifferent rules defining Life-like cellular automaton universes. CARLE is also\nfast and can simulate automata universes at a rate of tens of thousands of\nsteps per second through a combination of vectorization and GPU acceleration.\nFinally, CARLE is simple. Compared to high-fidelity physics simulators and\nvideo games designed for human players, CARLE's two-dimensional grid world\noffers a discrete, deterministic, and atomic universal playground, despite its\ncomplexity. In combination with CARLE, Carle's Game offers an initial set of\nagent policies, learning and meta-learning algorithms, and reward wrappers that\ncan be tailored to encourage exploration or specific tasks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 00:07:44 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Davis", "Q. Tyrell", ""]]}, {"id": "2107.05789", "submitter": "Ashwin Balakrishna", "authors": "Shivin Devgon and Jeffrey Ichnowski and Michael Danielczuk and Daniel\n  S. Brown and Ashwin Balakrishna and Shirin Joshi and Eduardo M. C. Rocha and\n  Eugen Solowjow and Ken Goldberg", "title": "Kit-Net: Self-Supervised Learning to Kit Novel 3D Objects into Novel 3D\n  Cavities", "comments": null, "journal-ref": "Conference on Automation Science and Engineering (CASE) 2021", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In industrial part kitting, 3D objects are inserted into cavities for\ntransportation or subsequent assembly. Kitting is a critical step as it can\ndecrease downstream processing and handling times and enable lower storage and\nshipping costs. We present Kit-Net, a framework for kitting previously unseen\n3D objects into cavities given depth images of both the target cavity and an\nobject held by a gripper in an unknown initial orientation. Kit-Net uses\nself-supervised deep learning and data augmentation to train a convolutional\nneural network (CNN) to robustly estimate 3D rotations between objects and\nmatching concave or convex cavities using a large training dataset of simulated\ndepth images pairs. Kit-Net then uses the trained CNN to implement a controller\nto orient and position novel objects for insertion into novel prismatic and\nconformal 3D cavities. Experiments in simulation suggest that Kit-Net can\norient objects to have a 98.9% average intersection volume between the object\nmesh and that of the target cavity. Physical experiments with industrial\nobjects succeed in 18% of trials using a baseline method and in 63% of trials\nwith Kit-Net. Video, code, and data are available at\nhttps://github.com/BerkeleyAutomation/Kit-Net.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 00:21:23 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Devgon", "Shivin", ""], ["Ichnowski", "Jeffrey", ""], ["Danielczuk", "Michael", ""], ["Brown", "Daniel S.", ""], ["Balakrishna", "Ashwin", ""], ["Joshi", "Shirin", ""], ["Rocha", "Eduardo M. C.", ""], ["Solowjow", "Eugen", ""], ["Goldberg", "Ken", ""]]}, {"id": "2107.05798", "submitter": "Lingwei Zhu", "authors": "Lingwei Zhu, Toshinori Kitamura, Takamitsu Matsubara", "title": "Cautious Policy Programming: Exploiting KL Regularization in Monotonic\n  Policy Improvement for Reinforcement Learning", "comments": "15 pages. arXiv admin note: text overlap with arXiv:2008.10806", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose cautious policy programming (CPP), a novel\nvalue-based reinforcement learning (RL) algorithm that can ensure monotonic\npolicy improvement during learning. Based on the nature of entropy-regularized\nRL, we derive a new entropy regularization-aware lower bound of policy\nimprovement that only requires estimating the expected policy advantage\nfunction. CPP leverages this lower bound as a criterion for adjusting the\ndegree of a policy update for alleviating policy oscillation. Different from\nsimilar algorithms that are mostly theory-oriented, we also propose a novel\ninterpolation scheme that makes CPP better scale in high dimensional control\nproblems. We demonstrate that the proposed algorithm can trade o? performance\nand stability in both didactic classic control problems and challenging\nhigh-dimensional Atari games.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 01:03:10 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Zhu", "Lingwei", ""], ["Kitamura", "Toshinori", ""], ["Matsubara", "Takamitsu", ""]]}, {"id": "2107.05799", "submitter": "Jiajie Zou", "authors": "Jiajie Zou and Nai Ding", "title": "Deep Neural Networks Evolve Human-like Attention Distribution during\n  Reading Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention is a key mechanism for information selection in both biological\nbrains and many state-of-the-art deep neural networks (DNNs). Here, we\ninvestigate whether humans and DNNs allocate attention in comparable ways when\nreading a text passage to subsequently answer a specific question. We analyze 3\ntransformer-based DNNs that reach human-level performance when trained to\nperform the reading comprehension task. We find that the DNN attention\ndistribution quantitatively resembles human attention distribution measured by\nfixation times. Human readers fixate longer on words that are more relevant to\nthe question-answering task, demonstrating that attention is modulated by\ntop-down reading goals, on top of lower-level visual and text features of the\nstimulus. Further analyses reveal that the attention weights in DNNs are also\ninfluenced by both top-down reading goals and lower-level stimulus features,\nwith the shallow layers more strongly influenced by lower-level text features\nand the deep layers attending more to task-relevant words. Additionally, deep\nlayers' attention to task-relevant words gradually emerges when pre-trained DNN\nmodels are fine-tuned to perform the reading comprehension task, which\ncoincides with the improvement in task performance. These results demonstrate\nthat DNNs can evolve human-like attention distribution through task\noptimization, which suggests that human attention during goal-directed reading\ncomprehension is a consequence of task optimization.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 01:07:22 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Zou", "Jiajie", ""], ["Ding", "Nai", ""]]}, {"id": "2107.05804", "submitter": "Zhongzhan Huang", "authors": "Zhongzhan Huang, Mingfu Liang, Senwei Liang, Wei He", "title": "AlterSGD: Finding Flat Minima for Continual Learning by Alternative\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks suffer from catastrophic forgetting when learning\nmultiple knowledge sequentially, and a growing number of approaches have been\nproposed to mitigate this problem. Some of these methods achieved considerable\nperformance by associating the flat local minima with forgetting mitigation in\ncontinual learning. However, they inevitably need (1) tedious hyperparameters\ntuning, and (2) additional computational cost. To alleviate these problems, in\nthis paper, we propose a simple yet effective optimization method, called\nAlterSGD, to search for a flat minima in the loss landscape. In AlterSGD, we\nconduct gradient descent and ascent alternatively when the network tends to\nconverge at each session of learning new knowledge. Moreover, we theoretically\nprove that such a strategy can encourage the optimization to converge to a flat\nminima. We verify AlterSGD on continual learning benchmark for semantic\nsegmentation and the empirical results show that we can significantly mitigate\nthe forgetting and outperform the state-of-the-art methods with a large margin\nunder challenging continual learning protocols.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 01:43:51 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Huang", "Zhongzhan", ""], ["Liang", "Mingfu", ""], ["Liang", "Senwei", ""], ["He", "Wei", ""]]}, {"id": "2107.05825", "submitter": "Faraz Torabi", "authors": "Ruohan Zhang, Faraz Torabi, Garrett Warnell, Peter Stone", "title": "Recent Advances in Leveraging Human Guidance for Sequential\n  Decision-Making Tasks", "comments": "Springer journal, Autonomous Agents and Multi-Agent Systems (JAAMAS)", "journal-ref": "JAAMAS 35 (2021) 1-39", "doi": "10.1007/s10458-021-09514-w", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A longstanding goal of artificial intelligence is to create artificial agents\ncapable of learning to perform tasks that require sequential decision making.\nImportantly, while it is the artificial agent that learns and acts, it is still\nup to humans to specify the particular task to be performed. Classical\ntask-specification approaches typically involve humans providing stationary\nreward functions or explicit demonstrations of the desired tasks. However,\nthere has recently been a great deal of research energy invested in exploring\nalternative ways in which humans may guide learning agents that may, e.g., be\nmore suitable for certain tasks or require less human effort. This survey\nprovides a high-level overview of five recent machine learning frameworks that\nprimarily rely on human guidance apart from pre-specified reward functions or\nconventional, step-by-step action demonstrations. We review the motivation,\nassumptions, and implementation of each framework, and we discuss possible\nfuture research directions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 03:11:04 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Zhang", "Ruohan", ""], ["Torabi", "Faraz", ""], ["Warnell", "Garrett", ""], ["Stone", "Peter", ""]]}, {"id": "2107.05850", "submitter": "Angeline Aguinaldo", "authors": "Angeline Aguinaldo, William Regli", "title": "Encoding Compositionality in Classical Planning Solutions", "comments": "IJCAI Generalization in Planning Workshop 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classical AI planners provide solutions to planning problems in the form of\nlong and opaque text outputs. To aid in the understanding transferability of\nplanning solutions, it is necessary to have a rich and comprehensible\nrepresentation for both human and computers beyond the current line-by-line\ntext notation. In particular, it is desirable to encode the trace of literals\nthroughout the plan to capture the dependencies between actions selected. The\napproach of this paper is to view the actions as maps between literals and the\nselected plan as a composition of those maps. The mathematical theory, called\ncategory theory, provides the relevant structures for capturing maps, their\ncompositions, and maps between compositions. We employ this theory to propose\nan algorithm agnostic, model-based representation for domains, problems, and\nplans expressed in the commonly used planning description language, PDDL. This\ncategory theoretic representation is accompanied by a graphical syntax in\naddition to a linear notation, similar to algebraic expressions, that can be\nused to infer literals used at every step of the plan. This provides the\nappropriate constructive abstraction and facilitates comprehension for human\noperators. In this paper, we demonstrate this on a plan within the Blocksworld\ndomain.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 05:05:11 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Aguinaldo", "Angeline", ""], ["Regli", "William", ""]]}, {"id": "2107.05877", "submitter": "Frederic Lardeux", "authors": "Fr\\'ed\\'eric Lardeux (LERIA), Eric Monfroy (LERIA)", "title": "GA and ILS for optimizing the size of NFA models", "comments": null, "journal-ref": "The 8th International Conference on Metaheuristics and Nature\n  Inspired Computing (META), Oct 2021, Marrakech, Morocco", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammatical inference consists in learning a formal grammar (as a set of\nrewrite rules or a finite state machine). We are concerned with learning\nNondeterministic Finite Automata (NFA) of a given size from samples of positive\nand negative words. NFA can naturally be modeled in SAT. The standard model [1]\nbeing enormous, we also try a model based on prefixes [2] which generates\nsmaller instances. We also propose a new model based on suffixes and a hybrid\nmodel based on prefixes and suffixes. We then focus on optimizing the size of\ngenerated SAT instances issued from the hybrid models. We present two\ntechniques to optimize this combination, one based on Iterated Local Search\n(ILS), the second one based on Genetic Algorithm (GA). Optimizing the\ncombination significantly reduces the SAT instances and their solving time, but\nat the cost of longer generation time. We, therefore, study the balance between\ngeneration time and solving time thanks to some experimental comparisons, and\nwe analyze our various model improvements.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 06:52:41 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Lardeux", "Fr\u00e9d\u00e9ric", "", "LERIA"], ["Monfroy", "Eric", "", "LERIA"]]}, {"id": "2107.05884", "submitter": "Junkun Yuan", "authors": "Junkun Yuan, Anpeng Wu, Kun Kuang, Bo Li, Runze Wu, Fei Wu, Lanfen Lin", "title": "Auto IV: Counterfactual Prediction via Automatic Instrumental Variable\n  Decomposition", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Instrumental variables (IVs), sources of treatment randomization that are\nconditionally independent of the outcome, play an important role in causal\ninference with unobserved confounders. However, the existing IV-based\ncounterfactual prediction methods need well-predefined IVs, while it's an art\nrather than science to find valid IVs in many real-world scenes. Moreover, the\npredefined hand-made IVs could be weak or erroneous by violating the conditions\nof valid IVs. These thorny facts hinder the application of the IV-based\ncounterfactual prediction methods. In this paper, we propose a novel Automatic\nInstrumental Variable decomposition (AutoIV) algorithm to automatically\ngenerate representations serving the role of IVs from observed variables (IV\ncandidates). Specifically, we let the learned IV representations satisfy the\nrelevance condition with the treatment and exclusion condition with the outcome\nvia mutual information maximization and minimization constraints, respectively.\nWe also learn confounder representations by encouraging them to be relevant to\nboth the treatment and the outcome. The IV and confounder representations\ncompete for the information with their constraints in an adversarial game,\nwhich allows us to get valid IV representations for IV-based counterfactual\nprediction. Extensive experiments demonstrate that our method generates valid\nIV representations for accurate IV-based counterfactual prediction.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 07:30:21 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Yuan", "Junkun", ""], ["Wu", "Anpeng", ""], ["Kuang", "Kun", ""], ["Li", "Bo", ""], ["Wu", "Runze", ""], ["Wu", "Fei", ""], ["Lin", "Lanfen", ""]]}, {"id": "2107.05904", "submitter": "Ling Zhou", "authors": "Qirong Mao, Ling Zhou, Wenming Zheng, Xiuyan Shao, Xiaohua Huang", "title": "Region attention and graph embedding network for occlusion objective\n  class-based micro-expression recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Micro-expression recognition (\\textbf{MER}) has attracted lots of\nresearchers' attention in a decade. However, occlusion will occur for MER in\nreal-world scenarios. This paper deeply investigates an interesting but\nunexplored challenging issue in MER, \\ie, occlusion MER. First, to research MER\nunder real-world occlusion, synthetic occluded micro-expression databases are\ncreated by using various mask for the community. Second, to suppress the\ninfluence of occlusion, a \\underline{R}egion-inspired \\underline{R}elation\n\\underline{R}easoning \\underline{N}etwork (\\textbf{RRRN}) is proposed to model\nrelations between various facial regions. RRRN consists of a backbone network,\nthe Region-Inspired (\\textbf{RI}) module and Relation Reasoning (\\textbf{RR})\nmodule. More specifically, the backbone network aims at extracting feature\nrepresentations from different facial regions, RI module computing an adaptive\nweight from the region itself based on attention mechanism with respect to the\nunobstructedness and importance for suppressing the influence of occlusion, and\nRR module exploiting the progressive interactions among these regions by\nperforming graph convolutions. Experiments are conducted on handout-database\nevaluation and composite database evaluation tasks of MEGC 2018 protocol.\nExperimental results show that RRRN can significantly explore the importance of\nfacial regions and capture the cooperative complementary relationship of facial\nregions for MER. The results also demonstrate RRRN outperforms the\nstate-of-the-art approaches, especially on occlusion, and RRRN acts more robust\nto occlusion.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 08:04:03 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Mao", "Qirong", ""], ["Zhou", "Ling", ""], ["Zheng", "Wenming", ""], ["Shao", "Xiuyan", ""], ["Huang", "Xiaohua", ""]]}, {"id": "2107.05916", "submitter": "Hao-Wen Dong", "authors": "Hao-Wen Dong, Chris Donahue, Taylor Berg-Kirkpatrick, Julian McAuley", "title": "Towards Automatic Instrumentation by Learning to Separate Parts in\n  Symbolic Multitrack Music", "comments": "Accepted to ISMIR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern keyboards allow a musician to play multiple instruments at the same\ntime by assigning zones -- fixed pitch ranges of the keyboard -- to different\ninstruments. In this paper, we aim to further extend this idea and examine the\nfeasibility of automatic instrumentation -- dynamically assigning instruments\nto notes in solo music during performance. In addition to the online,\nreal-time-capable setting for performative use cases, automatic instrumentation\ncan also find applications in assistive composing tools in an offline setting.\nDue to the lack of paired data of original solo music and their full\narrangements, we approach automatic instrumentation by learning to separate\nparts (e.g., voices, instruments and tracks) from their mixture in symbolic\nmultitrack music, assuming that the mixture is to be played on a keyboard. We\nframe the task of part separation as a sequential multi-class classification\nproblem and adopt machine learning to map sequences of notes into sequences of\npart labels. To examine the effectiveness of our proposed models, we conduct a\ncomprehensive empirical evaluation over four diverse datasets of different\ngenres and ensembles -- Bach chorales, string quartets, game music and pop\nmusic. Our experiments show that the proposed models outperform various\nbaselines. We also demonstrate the potential for our proposed models to produce\nalternative convincing instrumentations for an existing arrangement by\nseparating its mixture into parts. All source code and audio samples can be\nfound at https://salu133445.github.io/arranger/ .\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 08:34:44 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Dong", "Hao-Wen", ""], ["Donahue", "Chris", ""], ["Berg-Kirkpatrick", "Taylor", ""], ["McAuley", "Julian", ""]]}, {"id": "2107.05917", "submitter": "Chuanqiang Shan", "authors": "Chuanqiang Shan, Huiyun Jiao, Jie Fu", "title": "Towards Representation Identical Privacy-Preserving Graph Neural Network\n  via Split Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, the fast rise in number of studies on graph neural network\n(GNN) has put it from the theories research to reality application stage.\nDespite the encouraging performance achieved by GNN, less attention has been\npaid to the privacy-preserving training and inference over distributed graph\ndata in the related literature. Due to the particularity of graph structure, it\nis challenging to extend the existing private learning framework to GNN.\nMotivated by the idea of split learning, we propose a \\textbf{S}erver\n\\textbf{A}ided \\textbf{P}rivacy-preserving \\textbf{GNN} (SAPGNN) for the node\nlevel task on horizontally partitioned cross-silo scenario. It offers a natural\nextension of centralized GNN to isolated graph with max/min pooling\naggregation, while guaranteeing that all the private data involved in\ncomputation still stays at local data holders. To further enhancing the data\nprivacy, a secure pooling aggregation mechanism is proposed. Theoretical and\nexperimental results show that the proposed model achieves the same accuracy as\nthe one learned over the combined data.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 08:35:43 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Shan", "Chuanqiang", ""], ["Jiao", "Huiyun", ""], ["Fu", "Jie", ""]]}, {"id": "2107.05944", "submitter": "L\\'eopold Crestel", "authors": "Ga\\\"etan Hadjeres and L\\'eopold Crestel", "title": "The Piano Inpainting Application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autoregressive models are now capable of generating high-quality minute-long\nexpressive MIDI piano performances. Even though this progress suggests new\ntools to assist music composition, we observe that generative algorithms are\nstill not widely used by artists due to the limited control they offer,\nprohibitive inference times or the lack of integration within musicians'\nworkflows. In this work, we present the Piano Inpainting Application (PIA), a\ngenerative model focused on inpainting piano performances, as we believe that\nthis elementary operation (restoring missing parts of a piano performance)\nencourages human-machine interaction and opens up new ways to approach music\ncomposition. Our approach relies on an encoder-decoder Linear Transformer\narchitecture trained on a novel representation for MIDI piano performances\ntermed Structured MIDI Encoding. By uncovering an interesting synergy between\nLinear Transformers and our inpainting task, we are able to efficiently inpaint\ncontiguous regions of a piano performance, which makes our model suitable for\ninteractive and responsive A.I.-assisted composition. Finally, we introduce our\nfreely-available Ableton Live PIA plugin, which allows musicians to smoothly\ngenerate or modify any MIDI clip using PIA within a widely-used professional\nDigital Audio Workstation.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 09:33:11 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Hadjeres", "Ga\u00ebtan", ""], ["Crestel", "L\u00e9opold", ""]]}, {"id": "2107.05946", "submitter": "Pingping Zhang Dr", "authors": "Guowen Zhang and Pingping Zhang and Jinqing Qi and Huchuan Lu", "title": "HAT: Hierarchical Aggregation Transformers for Person Re-identification", "comments": "This work has been accepted by ACM International Conference on\n  Multimedia 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, with the advance of deep Convolutional Neural Networks (CNNs),\nperson Re-Identification (Re-ID) has witnessed great success in various\napplications. However, with limited receptive fields of CNNs, it is still\nchallenging to extract discriminative representations in a global view for\npersons under non-overlapped cameras. Meanwhile, Transformers demonstrate\nstrong abilities of modeling long-range dependencies for spatial and sequential\ndata. In this work, we take advantages of both CNNs and Transformers, and\npropose a novel learning framework named Hierarchical Aggregation Transformer\n(HAT) for image-based person Re-ID with high performance. To achieve this goal,\nwe first propose a Deeply Supervised Aggregation (DSA) to recurrently aggregate\nhierarchical features from CNN backbones. With multi-granularity supervisions,\nthe DSA can enhance multi-scale features for person retrieval, which is very\ndifferent from previous methods. Then, we introduce a Transformer-based Feature\nCalibration (TFC) to integrate low-level detail information as the global prior\nfor high-level semantic information. The proposed TFC is inserted to each level\nof hierarchical features, resulting in great performance improvements. To our\nbest knowledge, this work is the first to take advantages of both CNNs and\nTransformers for image-based person Re-ID. Comprehensive experiments on four\nlarge-scale Re-ID benchmarks demonstrate that our method shows better results\nthan several state-of-the-art methods. The code is released at\nhttps://github.com/AI-Zhpp/HAT.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 09:34:54 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 01:42:35 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Zhang", "Guowen", ""], ["Zhang", "Pingping", ""], ["Qi", "Jinqing", ""], ["Lu", "Huchuan", ""]]}, {"id": "2107.05948", "submitter": "Qinglin Li", "authors": "Qinglin Li, Bin Li, Jonathan M Garibaldi, Guoping Qiu", "title": "On Designing Good Representation Learning Models", "comments": "15 pages,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of representation learning is different from the ultimate objective\nof machine learning such as decision making, it is therefore very difficult to\nestablish clear and direct objectives for training representation learning\nmodels. It has been argued that a good representation should disentangle the\nunderlying variation factors, yet how to translate this into training\nobjectives remains unknown. This paper presents an attempt to establish direct\ntraining criterions and design principles for developing good representation\nlearning models. We propose that a good representation learning model should be\nmaximally expressive, i.e., capable of distinguishing the maximum number of\ninput configurations. We formally define expressiveness and introduce the\nmaximum expressiveness (MEXS) theorem of a general learning model. We propose\nto train a model by maximizing its expressiveness while at the same time\nincorporating general priors such as model smoothness. We present a conscience\ncompetitive learning algorithm which encourages the model to reach its MEXS\nwhilst at the same time adheres to model smoothness prior. We also introduce a\nlabel consistent training (LCT) technique to boost model smoothness by\nencouraging it to assign consistent labels to similar samples. We present\nextensive experimental results to show that our method can indeed design\nrepresentation learning models capable of developing representations that are\nas good as or better than state of the art. We also show that our technique is\ncomputationally efficient, robust against different parameter settings and can\nwork effectively on a variety of datasets.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 09:39:43 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Li", "Qinglin", ""], ["Li", "Bin", ""], ["Garibaldi", "Jonathan M", ""], ["Qiu", "Guoping", ""]]}, {"id": "2107.05949", "submitter": "Hamed Rahimi", "authors": "Hamed Rahimi, Iago Felipe Trentin, Fano Ramparany, Olivier Boissier", "title": "Q-SMASH: Q-Learning-based Self-Adaptation of Human-Centered Internet of\n  Things", "comments": "Submitted to wi-iat2021. arXiv admin note: text overlap with\n  arXiv:2105.14915", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the number of Human-Centered Internet of Things (HCIoT) applications\nincreases, the self-adaptation of its services and devices is becoming a\nfundamental requirement for addressing the uncertainties of the environment in\ndecision-making processes. Self-adaptation of HCIoT aims to manage run-time\nchanges in a dynamic environment and to adjust the functionality of IoT objects\nin order to achieve desired goals during execution. SMASH is a semantic-enabled\nmulti-agent system for self-adaptation of HCIoT that autonomously adapts IoT\nobjects to uncertainties of their environment. SMASH addresses the\nself-adaptation of IoT applications only according to the human values of\nusers, while the behavior of users is not addressed. This article presents\nQ-SMASH: a multi-agent reinforcement learning-based approach for\nself-adaptation of IoT objects in human-centered environments. Q-SMASH aims to\nlearn the behaviors of users along with respecting human values. The learning\nability of Q-SMASH allows it to adapt itself to the behavioral change of users\nand make more accurate decisions in different states and situations.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 09:41:05 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Rahimi", "Hamed", ""], ["Trentin", "Iago Felipe", ""], ["Ramparany", "Fano", ""], ["Boissier", "Olivier", ""]]}, {"id": "2107.05978", "submitter": "Umang Bhatt", "authors": "Umang Bhatt, Isabel Chien, Muhammad Bilal Zafar, Adrian Weller", "title": "DIVINE: Diverse Influential Training Points for Data Visualization and\n  Model Refinement", "comments": "30 pages, 32 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the complexity of machine learning (ML) models increases, resulting in a\nlack of prediction explainability, several methods have been developed to\nexplain a model's behavior in terms of the training data points that most\ninfluence the model. However, these methods tend to mark outliers as highly\ninfluential points, limiting the insights that practitioners can draw from\npoints that are not representative of the training data. In this work, we take\na step towards finding influential training points that also represent the\ntraining data well. We first review methods for assigning importance scores to\ntraining points. Given importance scores, we propose a method to select a set\nof DIVerse INfluEntial (DIVINE) training points as a useful explanation of\nmodel behavior. As practitioners might not only be interested in finding data\npoints influential with respect to model accuracy, but also with respect to\nother important metrics, we show how to evaluate training data points on the\nbasis of group fairness. Our method can identify unfairness-inducing training\npoints, which can be removed to improve fairness outcomes. Our quantitative\nexperiments and user studies show that visualizing DIVINE points helps\npractitioners understand and explain model behavior better than earlier\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 10:50:58 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Bhatt", "Umang", ""], ["Chien", "Isabel", ""], ["Zafar", "Muhammad Bilal", ""], ["Weller", "Adrian", ""]]}, {"id": "2107.05992", "submitter": "Shiqing Wu", "authors": "Shiqing Wu, Weihua Li, Hao Shen, Quan Bai", "title": "Identifying Influential Users in Unknown Social Networks for Adaptive\n  Incentive Allocation Under Budget Restriction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, recommendation systems have been widely applied in many\ndomains. These systems are impotent in affecting users to choose the behavior\nthat the system expects. Meanwhile, providing incentives has been proven to be\na more proactive way to affect users' behaviors. Due to the budget limitation,\nthe number of users who can be incentivized is restricted. In this light, we\nintend to utilize social influence existing among users to enhance the effect\nof incentivization. Through incentivizing influential users directly, their\nfollowers in the social network are possibly incentivized indirectly. However,\nin many real-world scenarios, the topological structure of the network is\nusually unknown, which makes identifying influential users difficult. To tackle\nthe aforementioned challenges, in this paper, we propose a novel algorithm for\nexploring influential users in unknown networks, which can estimate the\ninfluential relationships among users based on their historical behaviors and\nwithout knowing the topology of the network. Meanwhile, we design an adaptive\nincentive allocation approach that determines incentive values based on users'\npreferences and their influence ability. We evaluate the performance of the\nproposed approaches by conducting experiments on both synthetic and real-world\ndatasets. The experimental results demonstrate the effectiveness of the\nproposed approaches.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 11:20:10 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 13:16:25 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Wu", "Shiqing", ""], ["Li", "Weihua", ""], ["Shen", "Hao", ""], ["Bai", "Quan", ""]]}, {"id": "2107.06015", "submitter": "Steven Van Vaerenbergh", "authors": "Steven Van Vaerenbergh and Adri\\'an P\\'erez-Suay", "title": "A Classification of Artificial Intelligence Systems for Mathematics\n  Education", "comments": "Chapter in the upcoming book \"Mathematics Education in the Age of\n  Artificial Intelligence: How Artificial Intelligence can serve Mathematical\n  Human Learning\", Springer Nature, edited by P.R. Richard, P. V\\'elez, and S.\n  Van Vaerenbergh", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI math.HO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter provides an overview of the different Artificial Intelligence\n(AI) systems that are being used in contemporary digital tools for Mathematics\nEducation (ME). It is aimed at researchers in AI and Machine Learning (ML), for\nwhom we shed some light on the specific technologies that are being used in\neducational applications; and at researchers in ME, for whom we clarify: i)\nwhat the possibilities of the current AI technologies are, ii) what is still\nout of reach and iii) what is to be expected in the near future. We start our\nanalysis by establishing a high-level taxonomy of AI tools that are found as\ncomponents in digital ME applications. Then, we describe in detail how these AI\ntools, and in particular ML, are being used in two key applications,\nspecifically AI-based calculators and intelligent tutoring systems. We finish\nthe chapter with a discussion about student modeling systems and their\nrelationship to artificial general intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 12:09:10 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Van Vaerenbergh", "Steven", ""], ["P\u00e9rez-Suay", "Adri\u00e1n", ""]]}, {"id": "2107.06018", "submitter": "Ryan Webster", "authors": "Ryan Webster and Julien Rabin and Loic Simon and Frederic Jurie", "title": "This Person (Probably) Exists. Identity Membership Attacks Against GAN\n  Generated Faces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, generative adversarial networks (GANs) have achieved stunning\nrealism, fooling even human observers. Indeed, the popular tongue-in-cheek\nwebsite {\\small \\url{ http://thispersondoesnotexist.com}}, taunts users with\nGAN generated images that seem too real to believe. On the other hand, GANs do\nleak information about their training data, as evidenced by membership attacks\nrecently demonstrated in the literature. In this work, we challenge the\nassumption that GAN faces really are novel creations, by constructing a\nsuccessful membership attack of a new kind. Unlike previous works, our attack\ncan accurately discern samples sharing the same identity as training samples\nwithout being the same samples. We demonstrate the interest of our attack\nacross several popular face datasets and GAN training procedures. Notably, we\nshow that even in the presence of significant dataset diversity, an over\nrepresented person can pose a privacy concern.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 12:11:21 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Webster", "Ryan", ""], ["Rabin", "Julien", ""], ["Simon", "Loic", ""], ["Jurie", "Frederic", ""]]}, {"id": "2107.06031", "submitter": "Alberto Barbado Gonzalez", "authors": "Alberto Barbado, \\'Oscar Corcho", "title": "Vehicle Fuel Optimization Under Real-World Driving Conditions: An\n  Explainable Artificial Intelligence Approach", "comments": "30 pages, 15 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Fuel optimization of diesel and petrol vehicles within industrial fleets is\ncritical for mitigating costs and reducing emissions. This objective is\nachievable by acting on fuel-related factors, such as the driving behaviour\nstyle.\n  In this study, we developed an Explainable Boosting Machine (EBM) model to\npredict fuel consumption of different types of industrial vehicles, using\nreal-world data collected from 2020 to 2021. This Machine Learning model also\nexplains the relationship between the input factors and fuel consumption,\nquantifying the individual contribution of each one of them. The explanations\nprovided by the model are compared with domain knowledge in order to see if\nthey are aligned. The results show that the 70% of the categories associated to\nthe fuel-factors are similar to the previous literature.\n  With the EBM algorithm, we estimate that optimizing driving behaviour\ndecreases fuel consumption between 12% and 15% in a large fleet (more than 1000\nvehicles).\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 12:39:59 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 09:53:09 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 12:09:21 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Barbado", "Alberto", ""], ["Corcho", "\u00d3scar", ""]]}, {"id": "2107.06048", "submitter": "Xue Liu", "authors": "Xue Liu, Dan Sun, Wei Wei", "title": "A Graph Data Augmentation Strategy with Entropy Preserving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Graph Convolutional Networks (GCNs) proposed by Kipf and Welling are\neffective models for semi-supervised learning, but facing the obstacle of\nover-smoothing, which will weaken the representation ability of GCNs. Recently\nsome works are proposed to tackle with above limitation by randomly perturbing\ngraph topology or feature matrix to generate data augmentations as input for\ntraining. However, these operations have to pay the price of information\nstructure integrity breaking, and inevitably sacrifice information\nstochastically from original graph. In this paper, we introduce a novel graph\nentropy definition as an quantitative index to evaluate feature information\ndiffusion among a graph. Under considerations of preserving graph entropy, we\npropose an effective strategy to generate perturbed training data using a\nstochastic mechanism but guaranteeing graph topology integrity and with only a\nsmall amount of graph entropy decaying. Extensive experiments have been\nconducted on real-world datasets and the results verify the effectiveness of\nour proposed method in improving semi-supervised node classification accuracy\ncompared with a surge of baselines. Beyond that, our proposed approach\nsignificantly enhances the robustness and generalization ability of GCNs during\nthe training process.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 12:58:32 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Liu", "Xue", ""], ["Sun", "Dan", ""], ["Wei", "Wei", ""]]}, {"id": "2107.06054", "submitter": "Maxime Buron", "authors": "Maxime Buron, Marie-Laure Mugnier, Micha\\\"el Thomazo", "title": "Parallelisable Existential Rules: a Story of Pieces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider existential rules, an expressive formalism well\nsuited to the representation of ontological knowledge and data-to-ontology\nmappings in the context of ontology-based data integration. The chase is a\nfundamental tool to do reasoning with existential rules as it computes all the\nfacts entailed by the rules from a database instance. We introduce\nparallelisable sets of existential rules, for which the chase can be computed\nin a single breadth-first step from any instance. The question we investigate\nis the characterization of such rule sets. We show that parallelisable rule\nsets are exactly those rule sets both bounded for the chase and belonging to a\nnovel class of rules, called pieceful. The pieceful class includes in\nparticular frontier-guarded existential rules and (plain) datalog. We also give\nanother characterization of parallelisable rule sets in terms of rule\ncomposition based on rewriting.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 13:09:14 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Buron", "Maxime", ""], ["Mugnier", "Marie-Laure", ""], ["Thomazo", "Micha\u00ebl", ""]]}, {"id": "2107.06056", "submitter": "Prathamesh Kalamkar", "authors": "Prathamesh Kalamkar, Janani Venugopalan Ph.D., Vivek Raghavan Ph.D", "title": "Indian Legal NLP Benchmarks : A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Availability of challenging benchmarks is the key to advancement of AI in a\nspecific field.Since Legal Text is significantly different than normal English\ntext, there is a need to create separate Natural Language Processing benchmarks\nfor Indian Legal Text which are challenging and focus on tasks specific to\nLegal Systems. This will spur innovation in applications of Natural language\nProcessing for Indian Legal Text and will benefit AI community and Legal\nfraternity. We review the existing work in this area and propose ideas to\ncreate new benchmarks for Indian Legal Natural Language Processing.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 13:10:10 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Kalamkar", "Prathamesh", ""], ["D.", "Janani Venugopalan Ph.", ""], ["D", "Vivek Raghavan Ph.", ""]]}, {"id": "2107.06065", "submitter": "Dirk Riehle", "authors": "Dirk Riehle, Nikolay Harutyunyan, Ann Barcomb", "title": "Pattern Discovery and Validation Using Scientific Research Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pattern discovery, the process of discovering previously unrecognized\npatterns, is often performed as an ad-hoc process with little resulting\ncertainty in the quality of the proposed patterns. Pattern validation, the\nprocess of validating the accuracy of proposed patterns, remains dominated by\nthe simple heuristic of \"the rule of three\". This article shows how to use\nestablished scientific research methods for the purpose of pattern discovery\nand validation. We present a specific approach, called the handbook method,\nthat uses the qualitative survey, action research, and case study research for\npattern discovery and evaluation, and we discuss the underlying principle of\nusing scientific methods in general. We evaluate the handbook method using\nthree exploratory studies and demonstrate its usefulness.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 16:11:56 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Riehle", "Dirk", ""], ["Harutyunyan", "Nikolay", ""], ["Barcomb", "Ann", ""]]}, {"id": "2107.06071", "submitter": "Dorien Herremans", "authors": "Dorien Herremans", "title": "aiSTROM -- A roadmap for developing a successful AI strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A total of 34% of AI research and development projects fails or are\nabandoned, according to a recent survey by Rackspace Technology of 1,870\ncompanies. We propose a new strategic framework, aiSTROM, that empowers\nmanagers to create a successful AI strategy based on a thorough literature\nreview. This provides a unique and integrated approach that guides managers and\nlead developers through the various challenges in the implementation process.\nIn the aiSTROM framework, we start by identifying the top n potential projects\n(typically 3-5). For each of those, seven areas of focus are thoroughly\nanalysed. These areas include creating a data strategy that takes into account\nunique cross-departmental machine learning data requirements, security, and\nlegal requirements. aiSTROM then guides managers to think about how to put\ntogether an interdisciplinary artificial intelligence (AI) implementation team\ngiven the scarcity of AI talent. Once an AI team strategy has been established,\nit needs to be positioned within the organization, either cross-departmental or\nas a separate division. Other considerations include AI as a service (AIaas),\nor outsourcing development. Looking at new technologies, we have to consider\nchallenges such as bias, legality of black-box-models, and keeping humans in\nthe loop. Next, like any project, we need value-based key performance\nindicators (KPIs) to track and validate the progress. Depending on the\ncompany's risk-strategy, a SWOT analysis (strengths, weaknesses, opportunities,\nand threats) can help further classify the shortlisted projects. Finally, we\nshould make sure that our strategy includes continuous education of employees\nto enable a culture of adoption. This unique and comprehensive framework offers\na valuable, literature supported, tool for managers and lead developers.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 08:40:15 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Herremans", "Dorien", ""]]}, {"id": "2107.06075", "submitter": "Umberto Straccia", "authors": "Giovanni Casini, Umberto Straccia", "title": "A Rational Entailment for Expressive Description Logics via Description\n  Logic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lehmann and Magidor's rational closure is acknowledged as a landmark in the\nfield of non-monotonic logics and it has also been re-formulated in the context\nof Description Logics (DLs).\n  We show here how to model a rational form of entailment for expressive DLs,\nsuch as SROIQ, providing a novel reasoning procedure that compiles a\nnon-monotone DL knowledge base into a description logic program (dl-program).\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 14:35:42 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Casini", "Giovanni", ""], ["Straccia", "Umberto", ""]]}, {"id": "2107.06083", "submitter": "Golsa Heidari", "authors": "Kamran Zamanifar, Golsa Heidari, Naser Nematbakhsh, Farhad Mardookhi", "title": "A New Approach for Semantic Web Matching", "comments": "9 pages, 6 figures, SUComS 2010", "journal-ref": null, "doi": "10.1007/978-3-642-16444-6_12", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we propose a new approach for semantic web matching to improve\nthe performance of Web Service replacement. Because in automatic systems we\nshould ensure the self-healing, self-configuration, self-optimization and\nself-management, all services should be always available and if one of them\ncrashes, it should be replaced with the most similar one. Candidate services\nare advertised in Universal Description, Discovery and Integration (UDDI) all\nin Web Ontology Language (OWL). By the help of bipartite graph, we did the\nmatching between the crashed service and a Candidate one. Then we chose the\nbest service, which had the maximum rate of matching. In fact we compare two\nservices` functionalities and capabilities to see how much they match. We found\nthat the best way for matching two web services, is comparing the\nfunctionalities of them.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 13:47:12 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Zamanifar", "Kamran", ""], ["Heidari", "Golsa", ""], ["Nematbakhsh", "Naser", ""], ["Mardookhi", "Farhad", ""]]}, {"id": "2107.06099", "submitter": "Haiyang Wang", "authors": "Haiyang Wang, Guangyu Zhou, Siqi Liu, Jyun-Yu Jiang and Wei Wang", "title": "Drug-Target Interaction Prediction with Graph Attention networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivation: Predicting Drug-Target Interaction (DTI) is a well-studied topic\nin bioinformatics due to its relevance in the fields of proteomics and\npharmaceutical research. Although many machine learning methods have been\nsuccessfully applied in this task, few of them aim at leveraging the inherent\nheterogeneous graph structure in the DTI network to address the challenge. For\nbetter learning and interpreting the DTI topological structure and the\nsimilarity, it is desirable to have methods specifically for predicting\ninteractions from the graph structure.\n  Results: We present an end-to-end framework, DTI-GAT (Drug-Target Interaction\nprediction with Graph Attention networks) for DTI predictions. DTI-GAT\nincorporates a deep neural network architecture that operates on\ngraph-structured data with the attention mechanism, which leverages both the\ninteraction patterns and the features of drug and protein sequences. DTI-GAT\nfacilitates the interpretation of the DTI topological structure by assigning\ndifferent attention weights to each node with the self-attention mechanism.\nExperimental evaluations show that DTI-GAT outperforms various state-of-the-art\nsystems on the binary DTI prediction problem. Moreover, the independent study\nresults further demonstrate that our model can be generalized better than other\nconventional methods.\n  Availability: The source code and all datasets are available at\nhttps://github.com/Haiyang-W/DTI-GRAPH\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 07:06:36 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Wang", "Haiyang", ""], ["Zhou", "Guangyu", ""], ["Liu", "Siqi", ""], ["Jiang", "Jyun-Yu", ""], ["Wang", "Wei", ""]]}, {"id": "2107.06115", "submitter": "Zhenning Li", "authors": "Zhenning Li, Chengzhong Xu, Guohui Zhang", "title": "A Deep Reinforcement Learning Approach for Traffic Signal Control\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inefficient traffic signal control methods may cause numerous problems, such\nas traffic congestion and waste of energy. Reinforcement learning (RL) is a\ntrending data-driven approach for adaptive traffic signal control in complex\nurban traffic networks. Although the development of deep neural networks (DNN)\nfurther enhances its learning capability, there are still some challenges in\napplying deep RLs to transportation networks with multiple signalized\nintersections, including non-stationarity environment, exploration-exploitation\ndilemma, multi-agent training schemes, continuous action spaces, etc. In order\nto address these issues, this paper first proposes a multi-agent deep\ndeterministic policy gradient (MADDPG) method by extending the actor-critic\npolicy gradient algorithms. MADDPG has a centralized learning and decentralized\nexecution paradigm in which critics use additional information to streamline\nthe training process, while actors act on their own local observations. The\nmodel is evaluated via simulation on the Simulation of Urban MObility (SUMO)\nplatform. Model comparison results show the efficiency of the proposed\nalgorithm in controlling traffic lights.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 14:11:04 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Li", "Zhenning", ""], ["Xu", "Chengzhong", ""], ["Zhang", "Guohui", ""]]}, {"id": "2107.06132", "submitter": "Antonio Di Pilato", "authors": "Antonio Di Pilato, Nicol\\`o Taggio, Alexis Pompili, Michele\n  Iacobellis, Adriano Di Florio, Davide Passarelli, Sergio Samarelli", "title": "Deep learning approaches to Earth Observation change detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The interest for change detection in the field of remote sensing has\nincreased in the last few years. Searching for changes in satellite images has\nmany useful applications, ranging from land cover and land use analysis to\nanomaly detection. In particular, urban change detection provides an efficient\ntool to study urban spread and growth through several years of observation. At\nthe same time, change detection is often a computationally challenging and\ntime-consuming task, which requires innovative methods to guarantee optimal\nresults with unquestionable value and within reasonable time. In this paper we\npresent two different approaches to change detection (semantic segmentation and\nclassification) that both exploit convolutional neural networks to achieve good\nresults, which can be further refined and used in a post-processing workflow\nfor a large variety of applications.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 14:34:59 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Di Pilato", "Antonio", ""], ["Taggio", "Nicol\u00f2", ""], ["Pompili", "Alexis", ""], ["Iacobellis", "Michele", ""], ["Di Florio", "Adriano", ""], ["Passarelli", "Davide", ""], ["Samarelli", "Sergio", ""]]}, {"id": "2107.06146", "submitter": "Carl Corea", "authors": "Carl Corea, Michael Fellmann, Patrick Delfmann", "title": "Ontology-Based Process Modelling -- Will we live to see it?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In theory, ontology-based process modelling (OBPM) bares great potential to\nextend business process management. Many works have studied OBPM and are clear\non the potential amenities, such as eliminating ambiguities or enabling\nadvanced reasoning over company processes. However, despite this approval in\nacademia, a widespread industry adoption is still nowhere to be seen. This can\nbe mainly attributed to the fact, that it still requires high amounts of manual\nlabour to initially create ontologies and annotations to process models. As\nlong as these problems are not addressed, implementing OBPM seems unfeasible in\npractice. In this work, we therefore identify requirements needed for a\nsuccessful implementation of OBPM and assess the current state of research\nw.r.t. these requirements. Our results indicate that the research progress for\nmeans to facilitate OBPM are still alarmingly low and there needs to be urgent\nwork on extending existing approaches.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 09:44:17 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Corea", "Carl", ""], ["Fellmann", "Michael", ""], ["Delfmann", "Patrick", ""]]}, {"id": "2107.06158", "submitter": "Mehdi Ben Amor", "authors": "M. Ben Amor, J. Stier, M. Granitzer", "title": "Correlation Analysis between the Robustness of Sparse Neural Networks\n  and their Random Hidden Structural Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning models have been shown to be vulnerable to adversarial attacks.\nThis perception led to analyzing deep learning models not only from the\nperspective of their performance measures but also their robustness to certain\ntypes of adversarial attacks. We take another step forward in relating the\narchitectural structure of neural networks from a graph theoretic perspective\nto their robustness. We aim to investigate any existing correlations between\ngraph theoretic properties and the robustness of Sparse Neural Networks. Our\nhypothesis is, that graph theoretic properties as a prior of neural network\nstructures are related to their robustness. To answer to this hypothesis, we\ndesigned an empirical study with neural network models obtained through random\ngraphs used as sparse structural priors for the networks. We additionally\ninvestigated the evaluation of a randomly pruned fully connected network as a\npoint of reference.\n  We found that robustness measures are independent of initialization methods\nbut show weak correlations with graph properties: higher graph densities\ncorrelate with lower robustness, but higher average path lengths and average\nnode eccentricities show negative correlations with robustness measures. We\nhope to motivate further empirical and analytical research to tightening an\nanswer to our hypothesis.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 15:13:39 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Amor", "M. Ben", ""], ["Stier", "J.", ""], ["Granitzer", "M.", ""]]}, {"id": "2107.06212", "submitter": "Bharadwaj Manda", "authors": "Bharadwaj Manda, Shubham Dhayarkar, Sai Mitheran, V.K. Viekash,\n  Ramanathan Muthuganapathy", "title": "'CADSketchNet' -- An Annotated Sketch dataset for 3D CAD Model Retrieval\n  with Deep Neural Networks", "comments": "Computers & Graphics Journal, Special Section on 3DOR 2021", "journal-ref": "Computers & Graphics, Volume 99, 2021, Pages 100-113, ISSN\n  0097-8493", "doi": "10.1016/j.cag.2021.07.001", "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Ongoing advancements in the fields of 3D modelling and digital archiving have\nled to an outburst in the amount of data stored digitally. Consequently,\nseveral retrieval systems have been developed depending on the type of data\nstored in these databases. However, unlike text data or images, performing a\nsearch for 3D models is non-trivial. Among 3D models, retrieving 3D\nEngineering/CAD models or mechanical components is even more challenging due to\nthe presence of holes, volumetric features, presence of sharp edges etc., which\nmake CAD a domain unto itself. The research work presented in this paper aims\nat developing a dataset suitable for building a retrieval system for 3D CAD\nmodels based on deep learning. 3D CAD models from the available CAD databases\nare collected, and a dataset of computer-generated sketch data, termed\n'CADSketchNet', has been prepared. Additionally, hand-drawn sketches of the\ncomponents are also added to CADSketchNet. Using the sketch images from this\ndataset, the paper also aims at evaluating the performance of various retrieval\nsystem or a search engine for 3D CAD models that accepts a sketch image as the\ninput query. Many experimental models are constructed and tested on\nCADSketchNet. These experiments, along with the model architecture, choice of\nsimilarity metrics are reported along with the search results.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:10:16 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 06:26:54 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Manda", "Bharadwaj", ""], ["Dhayarkar", "Shubham", ""], ["Mitheran", "Sai", ""], ["Viekash", "V. K.", ""], ["Muthuganapathy", "Ramanathan", ""]]}, {"id": "2107.06217", "submitter": "Mohamed Ishmael Belghazi", "authors": "Mohamed Ishmael Belghazi and David Lopez-Paz", "title": "What classifiers know what they don't?", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Being uncertain when facing the unknown is key to intelligent decision\nmaking. However, machine learning algorithms lack reliable estimates about\ntheir predictive uncertainty. This leads to wrong and overly-confident\ndecisions when encountering classes unseen during training. Despite the\nimportance of equipping classifiers with uncertainty estimates ready for the\nreal world, prior work has focused on small datasets and little or no class\ndiscrepancy between training and testing data. To close this gap, we introduce\nUIMNET: a realistic, ImageNet-scale test-bed to evaluate predictive uncertainty\nestimates for deep image classifiers. Our benchmark provides implementations of\neight state-of-the-art algorithms, six uncertainty measures, four in-domain\nmetrics, three out-domain metrics, and a fully automated pipeline to train,\ncalibrate, ensemble, select, and evaluate models. Our test-bed is open-source\nand all of our results are reproducible from a fixed commit in our repository.\nAdding new datasets, algorithms, measures, or metrics is a matter of a few\nlines of code-in so hoping that UIMNET becomes a stepping stone towards\nrealistic, rigorous, and reproducible research in uncertainty estimation. Our\nresults show that ensembles of ERM classifiers as well as single MIMO\nclassifiers are the two best alternatives currently available to measure\nuncertainty about both in-domain and out-domain classes.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:17:06 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Belghazi", "Mohamed Ishmael", ""], ["Lopez-Paz", "David", ""]]}, {"id": "2107.06226", "submitter": "Masatoshi Uehara", "authors": "Masatoshi Uehara, Wen Sun", "title": "Pessimistic Model-based Offline RL: PAC Bounds and Posterior Sampling\n  under Partial Coverage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study model-based offline Reinforcement Learning with general function\napproximation. We present an algorithm named Constrained Pessimistic Policy\nOptimization (CPPO) which leverages a general function class and uses a\nconstraint to encode pessimism. Under the assumption that the ground truth\nmodel belongs to our function class, CPPO can learn with the offline data only\nproviding partial coverage, i.e., it can learn a policy that completes against\nany policy that is covered by the offline data, in polynomial sample complexity\nwith respect to the statistical complexity of the function class. We then\ndemonstrate that this algorithmic framework can be applied to many specialized\nMarkov Decision Processes where the additional structural assumptions can\nfurther refine the concept of partial coverage. One notable example is low-rank\nMDP with representation learning where the partial coverage is defined using\nthe concept of relative condition number measured by the underlying unknown\nground truth feature representation. Finally, we introduce and study the\nBayesian setting in offline RL. The key benefit of Bayesian offline RL is that\nalgorithmically, we do not need to explicitly construct pessimism or reward\npenalty which could be hard beyond models with linear structures. We present a\nposterior sampling-based incremental policy optimization algorithm (PS-PO)\nwhich proceeds by iteratively sampling a model from the posterior distribution\nand performing one-step incremental policy optimization inside the sampled\nmodel. Theoretically, in expectation with respect to the prior distribution,\nPS-PO can learn a near optimal policy under partial coverage with polynomial\nsample complexity.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:30:01 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Uehara", "Masatoshi", ""], ["Sun", "Wen", ""]]}, {"id": "2107.06243", "submitter": "Moniba Keymanesh", "authors": "Moniba Keymanesh, Tanya Berger-Wolf, Micha Elsner, Srinivasan\n  Parthasarathy", "title": "Fairness-aware Summarization for Justified Decision-Making", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many applications such as recidivism prediction, facility inspection, and\nbenefit assignment, it's important for individuals to know the\ndecision-relevant information for the model's prediction. In addition, the\nmodel's predictions should be fairly justified. Essentially, decision-relevant\nfeatures should provide sufficient information for the predicted outcome and\nshould be independent of the membership of individuals in protected groups such\nas race and gender. In this work, we focus on the problem of (un)fairness in\nthe justification of the text-based neural models. We tie the explanatory power\nof the model to fairness in the outcome and propose a fairness-aware\nsummarization mechanism to detect and counteract the bias in such models. Given\na potentially biased natural language explanation for a decision, we use a\nmulti-task neural model and an attribution mechanism based on integrated\ngradients to extract the high-utility and discrimination-free justifications in\nthe form of a summary. The extracted summary is then used for training a model\nto make decisions for individuals. Results on several real-world datasets\nsuggests that our method: (i) assists users to understand what information is\nused for the model's decision and (ii) enhances the fairness in outcomes while\nsignificantly reducing the demographic leakage.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 17:04:10 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Keymanesh", "Moniba", ""], ["Berger-Wolf", "Tanya", ""], ["Elsner", "Micha", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "2107.06277", "submitter": "Dibya Ghosh", "authors": "Dibya Ghosh, Jad Rahme, Aviral Kumar, Amy Zhang, Ryan P. Adams, Sergey\n  Levine", "title": "Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit\n  Partial Observability", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization is a central challenge for the deployment of reinforcement\nlearning (RL) systems in the real world. In this paper, we show that the\nsequential structure of the RL problem necessitates new approaches to\ngeneralization beyond the well-studied techniques used in supervised learning.\nWhile supervised learning methods can generalize effectively without explicitly\naccounting for epistemic uncertainty, we show that, perhaps surprisingly, this\nis not the case in RL. We show that generalization to unseen test conditions\nfrom a limited number of training conditions induces implicit partial\nobservability, effectively turning even fully-observed MDPs into POMDPs.\nInformed by this observation, we recast the problem of generalization in RL as\nsolving the induced partially observed Markov decision process, which we call\nthe epistemic POMDP. We demonstrate the failure modes of algorithms that do not\nappropriately handle this partial observability, and suggest a simple\nensemble-based technique for approximately solving the partially observed\nproblem. Empirically, we demonstrate that our simple algorithm derived from the\nepistemic POMDP achieves significant gains in generalization over current\nmethods on the Procgen benchmark suite.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 17:59:25 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Ghosh", "Dibya", ""], ["Rahme", "Jad", ""], ["Kumar", "Aviral", ""], ["Zhang", "Amy", ""], ["Adams", "Ryan P.", ""], ["Levine", "Sergey", ""]]}, {"id": "2107.06307", "submitter": "Qi Li", "authors": "Qi Li, Yue Wang, Yilun Wang, Hang Zhao", "title": "HDMapNet: An Online HD Map Construction and Evaluation Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High-definition map (HD map) construction is a crucial problem for autonomous\ndriving. This problem typically involves collecting high-quality point clouds,\nfusing multiple point clouds of the same scene, annotating map elements, and\nupdating maps constantly. This pipeline, however, requires a vast amount of\nhuman efforts and resources which limits its scalability. Additionally,\ntraditional HD maps are coupled with centimeter-level accurate localization\nwhich is unreliable in many scenarios. In this paper, we argue that online map\nlearning, which dynamically constructs the HD maps based on local sensor\nobservations, is a more scalable way to provide semantic and geometry priors to\nself-driving vehicles than traditional pre-annotated HD maps. Meanwhile, we\nintroduce an online map learning method, titled HDMapNet. It encodes image\nfeatures from surrounding cameras and/or point clouds from LiDAR, and predicts\nvectorized map elements in the bird's-eye view. We benchmark HDMapNet on the\nnuScenes dataset and show that in all settings, it performs better than\nbaseline methods. Of note, our fusion-based HDMapNet outperforms existing\nmethods by more than 50% in all metrics. To accelerate future research, we\ndevelop customized metrics to evaluate map learning performance, including both\nsemantic-level and instance-level ones. By introducing this method and metrics,\nwe invite the community to study this novel map learning problem. We will\nrelease our code and evaluation kit to facilitate future development.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 18:06:46 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 01:54:14 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Li", "Qi", ""], ["Wang", "Yue", ""], ["Wang", "Yilun", ""], ["Zhao", "Hang", ""]]}, {"id": "2107.06319", "submitter": "Julian Theis", "authors": "Julian Theis, Ilia Mokhtarian, and Houshang Darabi", "title": "On the Performance Analysis of the Adversarial System Variant\n  Approximation Method to Quantify Process Model Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process mining algorithms discover a process model from an event log. The\nresulting process model is supposed to describe all possible event sequences of\nthe underlying system. Generalization is a process model quality dimension of\ninterest. A generalization metric should quantify the extent to which a process\nmodel represents the observed event sequences contained in the event log and\nthe unobserved event sequences of the system. Most of the available metrics in\nthe literature cannot properly quantify the generalization of a process model.\nA recently published method [1] called Adversarial System Variant Approximation\nleverages Generative Adversarial Networks to approximate the underlying event\nsequence distribution of a system from an event log. While this method\ndemonstrated performance gains over existing methods in measuring the\ngeneralization of process models, its experimental evaluations have been\nperformed under ideal conditions. This paper experimentally investigates the\nperformance of Adversarial System Variant Approximation under non-ideal\nconditions such as biased and limited event logs. Moreover, experiments are\nperformed to investigate the originally proposed sampling hyperparameter value\nof the method on its performance to measure the generalization. The results\nconfirm the need to raise awareness about the working conditions of the\nAdversarial System Variant Approximation method. The outcomes of this paper\nalso serve to initiate future research directions.\n  [1] Theis, Julian, and Houshang Darabi. \"Adversarial System Variant\nApproximation to Quantify Process Model Generalization.\" IEEE Access 8 (2020):\n194410-194427.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 18:27:09 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Theis", "Julian", ""], ["Mokhtarian", "Ilia", ""], ["Darabi", "Houshang", ""]]}, {"id": "2107.06329", "submitter": "Maxime Chaveroche", "authors": "Maxime Chaveroche, Franck Davoine, V\\'eronique Cherfaoui", "title": "Efficient exact computation of the conjunctive and disjunctive\n  decompositions of D-S Theory for information fusion: Translation and\n  extension", "comments": "Extension of an article published in the proceedings of the french\n  conference GRETSI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Dempster-Shafer Theory (DST) generalizes Bayesian probability theory,\noffering useful additional information, but suffers from a high computational\nburden. A lot of work has been done to reduce the complexity of computations\nused in information fusion with Dempster's rule. Yet, few research had been\nconducted to reduce the complexity of computations for the conjunctive and\ndisjunctive decompositions of evidence, which are at the core of other\nimportant methods of information fusion. In this paper, we propose a method\ndesigned to exploit the actual evidence (information) contained in these\ndecompositions in order to compute them. It is based on a new notion that we\ncall focal point, derived from the notion of focal set. With it, we are able to\nreduce these computations up to a linear complexity in the number of focal sets\nin some cases. In a broader perspective, our formulas have the potential to be\ntractable when the size of the frame of discernment exceeds a few dozen\npossible states, contrary to the existing litterature. This article extends\n(and translates) our work published at the french conference GRETSI in 2019.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 18:41:54 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Chaveroche", "Maxime", ""], ["Davoine", "Franck", ""], ["Cherfaoui", "V\u00e9ronique", ""]]}, {"id": "2107.06383", "submitter": "Liunian Harold Li", "authors": "Sheng Shen, Liunian Harold Li, Hao Tan, Mohit Bansal, Anna Rohrbach,\n  Kai-Wei Chang, Zhewei Yao, Kurt Keutzer", "title": "How Much Can CLIP Benefit Vision-and-Language Tasks?", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing Vision-and-Language (V&L) models rely on pre-trained visual\nencoders, using a relatively small set of manually-annotated data (as compared\nto web-crawled data), to perceive the visual world. However, it has been\nobserved that large-scale pretraining usually can result in better\ngeneralization performance, e.g., CLIP (Contrastive Language-Image\nPre-training), trained on a massive amount of image-caption pairs, has shown a\nstrong zero-shot capability on various vision tasks. To further study the\nadvantage brought by CLIP, we propose to use CLIP as the visual encoder in\nvarious V&L models in two typical scenarios: 1) plugging CLIP into\ntask-specific fine-tuning; 2) combining CLIP with V&L pre-training and\ntransferring to downstream tasks. We show that CLIP significantly outperforms\nwidely-used visual encoders trained with in-domain annotated data, such as\nBottomUp-TopDown. We achieve competitive or better results on diverse V&L\ntasks, while establishing new state-of-the-art results on Visual Question\nAnswering, Visual Entailment, and V&L Navigation tasks. We release our code at\nhttps://github.com/clip-vil/CLIP-ViL.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 20:48:12 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Shen", "Sheng", ""], ["Li", "Liunian Harold", ""], ["Tan", "Hao", ""], ["Bansal", "Mohit", ""], ["Rohrbach", "Anna", ""], ["Chang", "Kai-Wei", ""], ["Yao", "Zhewei", ""], ["Keutzer", "Kurt", ""]]}, {"id": "2107.06386", "submitter": "Susama Agarwala", "authors": "Susama Agarwala, Benjamin Dees, Andrew Gearhart, Corey Lowman", "title": "Geometry and Generalization: Eigenvalues as predictors of where a\n  network will fail to generalize", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.DG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the deformation of the input space by a trained autoencoder via the\nJacobians of the trained weight matrices. In doing so, we prove bounds for the\nmean squared errors for points in the input space, under assumptions regarding\nthe orthogonality of the eigenvectors. We also show that the trace and the\nproduct of the eigenvalues of the Jacobian matrices is a good predictor of the\nMSE on test points. This is a dataset independent means of testing an\nautoencoder's ability to generalize on new input. Namely, no knowledge of the\ndataset on which the network was trained is needed, only the parameters of the\ntrained model.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 21:03:42 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Agarwala", "Susama", ""], ["Dees", "Benjamin", ""], ["Gearhart", "Andrew", ""], ["Lowman", "Corey", ""]]}, {"id": "2107.06393", "submitter": "Tuan Anh Le", "authors": "Tuan Anh Le, Katherine M. Collins, Luke Hewitt, Kevin Ellis, Siddharth\n  N, Samuel J. Gershman, Joshua B. Tenenbaum", "title": "Hybrid Memoised Wake-Sleep: Approximate Inference at the\n  Discrete-Continuous Interface", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling complex phenomena typically involves the use of both discrete and\ncontinuous variables. Such a setting applies across a wide range of problems,\nfrom identifying trends in time-series data to performing effective\ncompositional scene understanding in images. Here, we propose Hybrid Memoised\nWake-Sleep (HMWS), an algorithm for effective inference in such hybrid\ndiscrete-continuous models. Prior approaches to learning suffer as they need to\nperform repeated expensive inner-loop discrete inference. We build on a recent\napproach, Memoised Wake-Sleep (MWS), which alleviates part of the problem by\nmemoising discrete variables, and extend it to allow for a principled and\neffective way to handle continuous variables by learning a separate recognition\nmodel used for importance-sampling based approximate inference and\nmarginalization. We evaluate HMWS in the GP-kernel learning and 3D scene\nunderstanding domains, and show that it outperforms current state-of-the-art\ninference methods.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 00:57:14 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Le", "Tuan Anh", ""], ["Collins", "Katherine M.", ""], ["Hewitt", "Luke", ""], ["Ellis", "Kevin", ""], ["N", "Siddharth", ""], ["Gershman", "Samuel J.", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "2107.06405", "submitter": "Sungryull Sohn", "authors": "Sungryull Sohn, Sungtae Lee, Jongwook Choi, Harm van Seijen, Mehdi\n  Fatemi, Honglak Lee", "title": "Shortest-Path Constrained Reinforcement Learning for Sparse Reward Tasks", "comments": "In proceedings of ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose the k-Shortest-Path (k-SP) constraint: a novel constraint on the\nagent's trajectory that improves the sample efficiency in sparse-reward MDPs.\nWe show that any optimal policy necessarily satisfies the k-SP constraint.\nNotably, the k-SP constraint prevents the policy from exploring state-action\npairs along the non-k-SP trajectories (e.g., going back and forth). However, in\npractice, excluding state-action pairs may hinder the convergence of RL\nalgorithms. To overcome this, we propose a novel cost function that penalizes\nthe policy violating SP constraint, instead of completely excluding it. Our\nnumerical experiment in a tabular RL setting demonstrates that the SP\nconstraint can significantly reduce the trajectory space of policy. As a\nresult, our constraint enables more sample efficient learning by suppressing\nredundant exploration and exploitation. Our experiments on MiniGrid, DeepMind\nLab, Atari, and Fetch show that the proposed method significantly improves\nproximal policy optimization (PPO) and outperforms existing novelty-seeking\nexploration methods including count-based exploration even in continuous\ncontrol tasks, indicating that it improves the sample efficiency by preventing\nthe agent from taking redundant actions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 21:39:21 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Sohn", "Sungryull", ""], ["Lee", "Sungtae", ""], ["Choi", "Jongwook", ""], ["van Seijen", "Harm", ""], ["Fatemi", "Mehdi", ""], ["Lee", "Honglak", ""]]}, {"id": "2107.06413", "submitter": "Guilherme Paulino-Passos", "authors": "Guilherme Paulino-Passos, Francesca Toni", "title": "Monotonicity and Noise-Tolerance in Case-Based Reasoning with Abstract\n  Argumentation (with Appendix)", "comments": "Accepted for KR2021. Includes Appendix. arXiv admin note: substantial\n  text overlap with arXiv:2007.05284", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recently, abstract argumentation-based models of case-based reasoning\n($AA{\\text -} CBR$ in short) have been proposed, originally inspired by the\nlegal domain, but also applicable as classifiers in different scenarios.\nHowever, the formal properties of $AA{\\text -} CBR$ as a reasoning system\nremain largely unexplored. In this paper, we focus on analysing the\nnon-monotonicity properties of a regular version of $AA{\\text -} CBR$ (that we\ncall $AA{\\text -} CBR_{\\succeq}$). Specifically, we prove that $AA{\\text -}\nCBR_{\\succeq}$ is not cautiously monotonic, a property frequently considered\ndesirable in the literature. We then define a variation of $AA{\\text -}\nCBR_{\\succeq}$ which is cautiously monotonic. Further, we prove that such\nvariation is equivalent to using $AA{\\text -} CBR_{\\succeq}$ with a restricted\ncasebase consisting of all \"surprising\" and \"sufficient\" cases in the original\ncasebase. As a by-product, we prove that this variation of $AA{\\text -}\nCBR_{\\succeq}$ is cumulative, rationally monotonic, and empowers a principled\ntreatment of noise in \"incoherent\" casebases. Finally, we illustrate $AA{\\text\n-} CBR$ and cautious monotonicity questions on a case study on the U.S. Trade\nSecrets domain, a legal casebase.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 22:10:24 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Paulino-Passos", "Guilherme", ""], ["Toni", "Francesca", ""]]}, {"id": "2107.06424", "submitter": "Mohammadamin Tavakoli", "authors": "Mohammadamin Tavakoli, Peter Sadowski, Pierre Baldi", "title": "Tourbillon: a Physically Plausible Neural Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a physical neural system, backpropagation is faced with a number of\nobstacles including: the need for labeled data, the violation of the locality\nlearning principle, the need for symmetric connections, and the lack of\nmodularity. Tourbillon is a new architecture that addresses all these\nlimitations. At its core, it consists of a stack of circular autoencoders\nfollowed by an output layer. The circular autoencoders are trained in\nself-supervised mode by recirculation algorithms and the top layer in\nsupervised mode by stochastic gradient descent, with the option of propagating\nerror information through the entire stack using non-symmetric connections.\nWhile the Tourbillon architecture is meant primarily to address physical\nconstraints, and not to improve current engineering applications of deep\nlearning, we demonstrate its viability on standard benchmark datasets including\nMNIST, Fashion MNIST, and CIFAR10. We show that Tourbillon can achieve\ncomparable performance to models trained with backpropagation and outperform\nmodels that are trained with other physically plausible algorithms, such as\nfeedback alignment.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 22:51:42 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 04:25:05 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 04:15:50 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Tavakoli", "Mohammadamin", ""], ["Sadowski", "Peter", ""], ["Baldi", "Pierre", ""]]}, {"id": "2107.06426", "submitter": "Apurba Nath Mr", "authors": "Apurba Nath, Aayush Kubba", "title": "TSCAN : Dialog Structure discovery using SCAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we discover dialog structure by dividing utterances into labelled\nclusters. Can these labels be generated from the data. Typically for dialogs we\nneed an ontology and use that to discover structure, however by using\nunsupervised classification and self-labelling we are able to intuit this\nstructure without any labels or ontology. In this paper we apply SCAN (Semantic\nClustering using Nearest Neighbors) to dialog data. We used BERT for pretext\ntask and an adaptation of SCAN for clustering and self labeling. These clusters\nare used to identify transition probabilities and create the dialog structure.\nThe self-labelling method used for SCAN makes these structures interpretable as\nevery cluster has a label. As the approach is unsupervised, evaluation metrics\nis a challenge, we use statistical measures as proxies for structure quality\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 22:55:07 GMT"}, {"version": "v2", "created": "Sun, 18 Jul 2021 14:30:50 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Nath", "Apurba", ""], ["Kubba", "Aayush", ""]]}, {"id": "2107.06434", "submitter": "Qizhen Zhang", "authors": "Qizhen Zhang, Chris Lu, Animesh Garg, Jakob Foerster", "title": "Centralized Model and Exploration Policy for Multi-Agent RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) in partially observable, fully cooperative\nmulti-agent settings (Dec-POMDPs) can in principle be used to address many\nreal-world challenges such as controlling a swarm of rescue robots or a\nsynchronous team of quadcopters. However, Dec-POMDPs are significantly harder\nto solve than single-agent problems, with the former being NEXP-complete and\nthe latter, MDPs, being just P-complete. Hence, current RL algorithms for\nDec-POMDPs suffer from poor sample complexity, thereby reducing their\napplicability to practical problems where environment interaction is costly.\nOur key insight is that using just a polynomial number of samples, one can\nlearn a centralized model that generalizes across different policies. We can\nthen optimize the policy within the learned model instead of the true system,\nreducing the number of environment interactions. We also learn a centralized\nexploration policy within our model that learns to collect additional data in\nstate-action regions with high model uncertainty. Finally, we empirically\nevaluate the proposed model-based algorithm, MARCO, in three cooperative\ncommunication tasks, where it improves sample efficiency by up to 20x.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 00:34:08 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Zhang", "Qizhen", ""], ["Lu", "Chris", ""], ["Garg", "Animesh", ""], ["Foerster", "Jakob", ""]]}, {"id": "2107.06442", "submitter": "Jinpeng Li", "authors": "Baolian Qi, Gangming Zhao, Xin Wei, Chaowei Fang, Chengwei Pan,\n  Jinpeng Li, Huiguang He, and Licheng Jiao", "title": "GREN: Graph-Regularized Embedding Network for Weakly-Supervised Disease\n  Localization in X-ray images", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Locating diseases in chest X-ray images with few careful annotations saves\nlarge human effort. Recent works approached this task with innovative\nweakly-supervised algorithms such as multi-instance learning (MIL) and class\nactivation maps (CAM), however, these methods often yield inaccurate or\nincomplete regions. One of the reasons is the neglection of the pathological\nimplications hidden in the relationship across anatomical regions within each\nimage and the relationship across images. In this paper, we argue that the\ncross-region and cross-image relationship, as contextual and compensating\ninformation, is vital to obtain more consistent and integral regions. To model\nthe relationship, we propose the Graph Regularized Embedding Network (GREN),\nwhich leverages the intra-image and inter-image information to locate diseases\non chest X-ray images. GREN uses a pre-trained U-Net to segment the lung lobes,\nand then models the intra-image relationship between the lung lobes using an\nintra-image graph to compare different regions. Meanwhile, the relationship\nbetween in-batch images is modeled by an inter-image graph to compare multiple\nimages. This process mimics the training and decision-making process of a\nradiologist: comparing multiple regions and images for diagnosis. In order for\nthe deep embedding layers of the neural network to retain structural\ninformation (important in the localization task), we use the Hash coding and\nHamming distance to compute the graphs, which are used as regularizers to\nfacilitate training. By means of this, our approach achieves the\nstate-of-the-art result on NIH chest X-ray dataset for weakly-supervised\ndisease localization. Our codes are accessible online.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 01:27:07 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Qi", "Baolian", ""], ["Zhao", "Gangming", ""], ["Wei", "Xin", ""], ["Fang", "Chaowei", ""], ["Pan", "Chengwei", ""], ["Li", "Jinpeng", ""], ["He", "Huiguang", ""], ["Jiao", "Licheng", ""]]}, {"id": "2107.06456", "submitter": "Eunjung Lee", "authors": "Duhun Hwang, Eunjung Lee, Wonjong Rhee", "title": "AID-Purifier: A Light Auxiliary Network for Boosting Adversarial Defense", "comments": null, "journal-ref": "ICML 2021 Workshop on Adversarial Machine Learning", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an AID-purifier that can boost the robustness of\nadversarially-trained networks by purifying their inputs. AID-purifier is an\nauxiliary network that works as an add-on to an already trained main\nclassifier. To keep it computationally light, it is trained as a discriminator\nwith a binary cross-entropy loss. To obtain additionally useful information\nfrom the adversarial examples, the architecture design is closely related to\ninformation maximization principles where two layers of the main classification\nnetwork are piped to the auxiliary network. To assist the iterative\noptimization procedure of purification, the auxiliary network is trained with\nAVmixup. AID-purifier can be used together with other purifiers such as\nPixelDefend for an extra enhancement. The overall results indicate that the\nbest performing adversarially-trained networks can be enhanced by the best\nperforming purification networks, where AID-purifier is a competitive candidate\nthat is light and robust.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 02:39:15 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Hwang", "Duhun", ""], ["Lee", "Eunjung", ""], ["Rhee", "Wonjong", ""]]}, {"id": "2107.06475", "submitter": "Patryk Orzechowski", "authors": "Patryk Orzechowski and Jason H. Moore", "title": "Generative and reproducible benchmarks for comprehensive evaluation of\n  machine learning classifiers", "comments": "12 pages, 3 figures with subfigures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the strengths and weaknesses of machine learning (ML)\nalgorithms is crucial for determine their scope of application. Here, we\nintroduce the DIverse and GENerative ML Benchmark (DIGEN) - a collection of\nsynthetic datasets for comprehensive, reproducible, and interpretable\nbenchmarking of machine learning algorithms for classification of binary\noutcomes. The DIGEN resource consists of 40 mathematical functions which map\ncontinuous features to discrete endpoints for creating synthetic datasets.\nThese 40 functions were discovered using a heuristic algorithm designed to\nmaximize the diversity of performance among multiple popular machine learning\nalgorithms thus providing a useful test suite for evaluating and comparing new\nmethods. Access to the generative functions facilitates understanding of why a\nmethod performs poorly compared to other algorithms thus providing ideas for\nimprovement. The resource with extensive documentation and analyses is\nopen-source and available on GitHub.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 03:58:02 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Orzechowski", "Patryk", ""], ["Moore", "Jason H.", ""]]}, {"id": "2107.06481", "submitter": "Bharadwaj Manda", "authors": "Bharadwaj Manda, Pranjal Bhaskare, Ramanathan Muthuganapathy", "title": "A Convolutional Neural Network Approach to the Classification of\n  Engineering Models", "comments": null, "journal-ref": "in IEEE Access, vol. 9, pp. 22711-22723, 2021", "doi": "10.1109/ACCESS.2021.3055826", "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper presents a deep learning approach for the classification of\nEngineering (CAD) models using Convolutional Neural Networks (CNNs). Owing to\nthe availability of large annotated datasets and also enough computational\npower in the form of GPUs, many deep learning-based solutions for object\nclassification have been proposed of late, especially in the domain of images\nand graphical models. Nevertheless, very few solutions have been proposed for\nthe task of functional classification of CAD models. Hence, for this research,\nCAD models have been collected from Engineering Shape Benchmark (ESB), National\nDesign Repository (NDR) and augmented with newer models created using a\nmodelling software to form a dataset - 'CADNET'. It is proposed to use a\nresidual network architecture for CADNET, inspired by the popular ResNet. A\nweighted Light Field Descriptor (LFD) scheme is chosen as the method of feature\nextraction, and the generated images are fed as inputs to the CNN. The problem\nof class imbalance in the dataset is addressed using a class weights approach.\nExperiments have been conducted with other signatures such as geodesic distance\netc. using deep networks as well as other network architectures on the CADNET.\nThe LFD-based CNN approach using the proposed network architecture, along with\ngradient boosting yielded the best classification accuracy on CADNET.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 04:33:50 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Manda", "Bharadwaj", ""], ["Bhaskare", "Pranjal", ""], ["Muthuganapathy", "Ramanathan", ""]]}, {"id": "2107.06505", "submitter": "Anqi Pang", "authors": "Anqi Pang, Xin Chen, Haimin Luo, Minye Wu, Jingyi Yu, Lan Xu", "title": "Few-shot Neural Human Performance Rendering from Sparse RGBD Videos", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent neural rendering approaches for human activities achieve remarkable\nview synthesis results, but still rely on dense input views or dense training\nwith all the capture frames, leading to deployment difficulty and inefficient\ntraining overload. However, existing advances will be ill-posed if the input is\nboth spatially and temporally sparse. To fill this gap, in this paper we\npropose a few-shot neural human rendering approach (FNHR) from only sparse RGBD\ninputs, which exploits the temporal and spatial redundancy to generate\nphoto-realistic free-view output of human activities. Our FNHR is trained only\non the key-frames which expand the motion manifold in the input sequences. We\nintroduce a two-branch neural blending to combine the neural point render and\nclassical graphics texturing pipeline, which integrates reliable observations\nover sparse key-frames. Furthermore, we adopt a patch-based adversarial\ntraining process to make use of the local redundancy and avoids over-fitting to\nthe key-frames, which generates fine-detailed rendering results. Extensive\nexperiments demonstrate the effectiveness of our approach to generate\nhigh-quality free view-point results for challenging human performances under\nthe sparse setting.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 06:28:16 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Pang", "Anqi", ""], ["Chen", "Xin", ""], ["Luo", "Haimin", ""], ["Wu", "Minye", ""], ["Yu", "Jingyi", ""], ["Xu", "Lan", ""]]}, {"id": "2107.06516", "submitter": "Shengnan An", "authors": "Chenyao Liu, Shengnan An, Zeqi Lin, Qian Liu, Bei Chen, Jian-Guang\n  Lou, Lijie Wen, Nanning Zheng and Dongmei Zhang", "title": "Learning Algebraic Recombination for Compositional Generalization", "comments": "ACL Findings 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural sequence models exhibit limited compositional generalization ability\nin semantic parsing tasks. Compositional generalization requires algebraic\nrecombination, i.e., dynamically recombining structured expressions in a\nrecursive manner. However, most previous studies mainly concentrate on\nrecombining lexical units, which is an important but not sufficient part of\nalgebraic recombination. In this paper, we propose LeAR, an end-to-end neural\nmodel to learn algebraic recombination for compositional generalization. The\nkey insight is to model the semantic parsing task as a homomorphism between a\nlatent syntactic algebra and a semantic algebra, thus encouraging algebraic\nrecombination. Specifically, we learn two modules jointly: a Composer for\nproducing latent syntax, and an Interpreter for assigning semantic operations.\nExperiments on two realistic and comprehensive compositional generalization\nbenchmarks demonstrate the effectiveness of our model. The source code is\npublicly available at https://github.com/microsoft/ContextualSP.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 07:23:46 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Liu", "Chenyao", ""], ["An", "Shengnan", ""], ["Lin", "Zeqi", ""], ["Liu", "Qian", ""], ["Chen", "Bei", ""], ["Lou", "Jian-Guang", ""], ["Wen", "Lijie", ""], ["Zheng", "Nanning", ""], ["Zhang", "Dongmei", ""]]}, {"id": "2107.06533", "submitter": "Shaohuai Shi", "authors": "Shaohuai Shi, Lin Zhang, Bo Li", "title": "Accelerating Distributed K-FAC with Smart Parallelism of Computing and\n  Communication Tasks", "comments": "11 pages. Accepted to IEEE ICDCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed training with synchronous stochastic gradient descent (SGD) on\nGPU clusters has been widely used to accelerate the training process of deep\nmodels. However, SGD only utilizes the first-order gradient in model parameter\nupdates, which may take days or weeks. Recent studies have successfully\nexploited approximate second-order information to speed up the training\nprocess, in which the Kronecker-Factored Approximate Curvature (KFAC) emerges\nas one of the most efficient approximation algorithms for training deep models.\nYet, when leveraging GPU clusters to train models with distributed KFAC\n(D-KFAC), it incurs extensive computation as well as introduces extra\ncommunications during each iteration. In this work, we propose D-KFAC\n(SPD-KFAC) with smart parallelism of computing and communication tasks to\nreduce the iteration time. Specifically, 1) we first characterize the\nperformance bottlenecks of D-KFAC, 2) we design and implement a pipelining\nmechanism for Kronecker factors computation and communication with dynamic\ntensor fusion, and 3) we develop a load balancing placement for inverting\nmultiple matrices on GPU clusters. We conduct real-world experiments on a\n64-GPU cluster with 100Gb/s InfiniBand interconnect. Experimental results show\nthat our proposed SPD-KFAC training scheme can achieve 10%-35% improvement over\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 08:01:07 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Shi", "Shaohuai", ""], ["Zhang", "Lin", ""], ["Li", "Bo", ""]]}, {"id": "2107.06543", "submitter": "Davide Bacciu", "authors": "Davide Bacciu, Siranush Akarmazyan, Eric Armengaud, Manlio Bacco,\n  George Bravos, Calogero Calandra, Emanuele Carlini, Antonio Carta, Pietro\n  Cassara, Massimo Coppola, Charalampos Davalas, Patrizio Dazzi, Maria Carmela\n  Degennaro, Daniele Di Sarli, J\\\"urgen Dobaj, Claudio Gallicchio, Sylvain\n  Girbal, Alberto Gotta, Riccardo Groppo, Vincenzo Lomonaco, Georg Macher,\n  Daniele Mazzei, Gabriele Mencagli, Dimitrios Michail, Alessio Micheli,\n  Roberta Peroglio, Salvatore Petroni, Rosaria Potenza, Farank Pourdanesh,\n  Christos Sardianos, Konstantinos Tserpes, Fulvio Tagliab\\`o, Jakob Valtl,\n  Iraklis Varlamis, Omar Veledar", "title": "TEACHING -- Trustworthy autonomous cyber-physical applications through\n  human-centred intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the perspective of the H2020 TEACHING project on the\nnext generation of autonomous applications running in a distributed and highly\nheterogeneous environment comprising both virtual and physical resources\nspanning the edge-cloud continuum. TEACHING puts forward a human-centred vision\nleveraging the physiological, emotional, and cognitive state of the users as a\ndriver for the adaptation and optimization of the autonomous applications. It\ndoes so by building a distributed, embedded and federated learning system\ncomplemented by methods and tools to enforce its dependability, security and\nprivacy preservation. The paper discusses the main concepts of the TEACHING\napproach and singles out the main AI-related research challenges associated\nwith it. Further, we provide a discussion of the design choices for the\nTEACHING system to tackle the aforementioned challenges\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 08:25:58 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bacciu", "Davide", ""], ["Akarmazyan", "Siranush", ""], ["Armengaud", "Eric", ""], ["Bacco", "Manlio", ""], ["Bravos", "George", ""], ["Calandra", "Calogero", ""], ["Carlini", "Emanuele", ""], ["Carta", "Antonio", ""], ["Cassara", "Pietro", ""], ["Coppola", "Massimo", ""], ["Davalas", "Charalampos", ""], ["Dazzi", "Patrizio", ""], ["Degennaro", "Maria Carmela", ""], ["Di Sarli", "Daniele", ""], ["Dobaj", "J\u00fcrgen", ""], ["Gallicchio", "Claudio", ""], ["Girbal", "Sylvain", ""], ["Gotta", "Alberto", ""], ["Groppo", "Riccardo", ""], ["Lomonaco", "Vincenzo", ""], ["Macher", "Georg", ""], ["Mazzei", "Daniele", ""], ["Mencagli", "Gabriele", ""], ["Michail", "Dimitrios", ""], ["Micheli", "Alessio", ""], ["Peroglio", "Roberta", ""], ["Petroni", "Salvatore", ""], ["Potenza", "Rosaria", ""], ["Pourdanesh", "Farank", ""], ["Sardianos", "Christos", ""], ["Tserpes", "Konstantinos", ""], ["Tagliab\u00f2", "Fulvio", ""], ["Valtl", "Jakob", ""], ["Varlamis", "Iraklis", ""], ["Veledar", "Omar", ""]]}, {"id": "2107.06547", "submitter": "Sirko Schindler", "authors": "Barbara Magagna and Ilaria Rosati and Maria Stoica and Sirko Schindler\n  and Gwenaelle Moncoiffe and Anusuriya Devaraju and Johannes Peterseil and\n  Robert Huber", "title": "The I-ADOPT Interoperability Framework for FAIRer data descriptions of\n  biodiversity", "comments": "submitted to S4BioDiv 2021: 3rd International Workshop on Semantics\n  for Biodiversity, September 15, 2021, Bozen, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biodiversity, the variation within and between species and ecosystems, is\nessential for human well-being and the equilibrium of the planet. It is\ncritical for the sustainable development of human society and is an important\nglobal challenge. Biodiversity research has become increasingly data-intensive\nand it deals with heterogeneous and distributed data made available by global\nand regional initiatives, such as GBIF, ILTER, LifeWatch, BODC, PANGAEA, and\nTERN, that apply different data management practices. In particular, a variety\nof metadata and semantic resources have been produced by these initiatives to\ndescribe biodiversity observations, introducing interoperability issues across\ndata management systems. To address these challenges, the InteroperAble\nDescriptions of Observable Property Terminology WG (I-ADOPT WG) was formed by a\ngroup of international terminology providers and data center managers in 2019\nwith the aim to build a common approach to describe what is observed, measured,\ncalculated, or derived. Based on an extensive analysis of existing semantic\nrepresentations of variables, the WG has recently published the I-ADOPT\nframework ontology to facilitate interoperability between existing semantic\nresources and support the provision of machine-readable variable descriptions\nwhose components are mapped to FAIR vocabulary terms. The I-ADOPT framework\nontology defines a set of high level semantic components that can be used to\ndescribe a variety of patterns commonly found in scientific observations. This\ncontribution will focus on how the I-ADOPT framework can be applied to\nrepresent variables commonly used in the biodiversity domain.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 08:30:10 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Magagna", "Barbara", ""], ["Rosati", "Ilaria", ""], ["Stoica", "Maria", ""], ["Schindler", "Sirko", ""], ["Moncoiffe", "Gwenaelle", ""], ["Devaraju", "Anusuriya", ""], ["Peterseil", "Johannes", ""], ["Huber", "Robert", ""]]}, {"id": "2107.06552", "submitter": "Young Eun Kim", "authors": "Young Eun Kim and Seong-Whan Lee", "title": "Domain Generalization with Pseudo-Domain Label for Face Anti-Spoofing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face anti-spoofing (FAS) plays an important role in protecting face\nrecognition systems from face representation attacks. Many recent studies in\nFAS have approached this problem with domain generalization technique. Domain\ngeneralization aims to increase generalization performance to better detect\nvarious types of attacks and unseen attacks. However, previous studies in this\narea have defined each domain simply as an anti-spoofing datasets and focused\non developing learning techniques. In this paper, we proposed a method that\nenables network to judge its domain by itself with the clustered convolutional\nfeature statistics from intermediate layers of the network, without labeling\ndomains as datasets. We obtained pseudo-domain labels by not only using the\nnetwork extracting features, but also using depth estimators, which were\npreviously used only as an auxiliary task in FAS. In our experiments, we\ntrained with three datasets and evaluated the performance with the remaining\none dataset to demonstrate the effectiveness of the proposed method by\nconducting a total of four sets of experiments.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 08:35:07 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Kim", "Young Eun", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2107.06566", "submitter": "Erich Schubert", "authors": "Erik Thordsen and Erich Schubert", "title": "MESS: Manifold Embedding Motivated Super Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many approaches in the field of machine learning and data analysis rely on\nthe assumption that the observed data lies on lower-dimensional manifolds. This\nassumption has been verified empirically for many real data sets. To make use\nof this manifold assumption one generally requires the manifold to be locally\nsampled to a certain density such that features of the manifold can be\nobserved. However, for increasing intrinsic dimensionality of a data set the\nrequired data density introduces the need for very large data sets, resulting\nin one of the many faces of the curse of dimensionality. To combat the\nincreased requirement for local data density we propose a framework to generate\nvirtual data points that faithful to an approximate embedding function\nunderlying the manifold observable in the data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 09:07:54 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Thordsen", "Erik", ""], ["Schubert", "Erich", ""]]}, {"id": "2107.06570", "submitter": "Jakob Stigenberg", "authors": "Jakob Stigenberg, Vidit Saxena, Soma Tayamon, Euhanna Ghadimi", "title": "QoS-Aware Scheduling in New Radio Using Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fifth-generation (5G) New Radio (NR) cellular networks support a wide range\nof new services, many of which require an application-specific quality of\nservice (QoS), e.g. in terms of a guaranteed minimum bit-rate or a maximum\ntolerable delay. Therefore, scheduling multiple parallel data flows, each\nserving a unique application instance, is bound to become an even more\nchallenging task compared to the previous generations. Leveraging recent\nadvances in deep reinforcement learning, in this paper, we propose a QoS-Aware\nDeep Reinforcement learning Agent (QADRA) scheduler for NR networks. In\ncontrast to state-of-the-art scheduling heuristics, the QADRA scheduler\nexplicitly optimizes for the QoS satisfaction rate while simultaneously\nmaximizing the network performance. Moreover, we train our algorithm end-to-end\non these objectives. We evaluate QADRA in a full scale, near-product, system\nlevel NR simulator and demonstrate a significant boost in network performance.\nIn our particular evaluation scenario, the QADRA scheduler improves network\nthroughput by 30% while simultaneously maintaining the QoS satisfaction rate of\nVoIP users served by the network, compared to state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 09:18:39 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Stigenberg", "Jakob", ""], ["Saxena", "Vidit", ""], ["Tayamon", "Soma", ""], ["Ghadimi", "Euhanna", ""]]}, {"id": "2107.06573", "submitter": "Zeng Wenqi", "authors": "Wenqi Zeng, Siqin Cao, Xuhui Huang, Yuan Yao", "title": "A Note on Learning Rare Events in Molecular Dynamics using LSTM and\n  Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks for language models like long short-term memory\n(LSTM) have been utilized as a tool for modeling and predicting long term\ndynamics of complex stochastic molecular systems. Recently successful examples\non learning slow dynamics by LSTM are given with simulation data of low\ndimensional reaction coordinate. However, in this report we show that the\nfollowing three key factors significantly affect the performance of language\nmodel learning, namely dimensionality of reaction coordinates, temporal\nresolution and state partition. When applying recurrent neural networks to\nmolecular dynamics simulation trajectories of high dimensionality, we find that\nrare events corresponding to the slow dynamics might be obscured by other\nfaster dynamics of the system, and cannot be efficiently learned. Under such\nconditions, we find that coarse graining the conformational space into\nmetastable states and removing recrossing events when estimating transition\nprobabilities between states could greatly help improve the accuracy of slow\ndynamics learning in molecular dynamics. Moreover, we also explore other models\nlike Transformer, which do not show superior performance than LSTM in\novercoming these issues. Therefore, to learn rare events of slow molecular\ndynamics by LSTM and Transformer, it is critical to choose proper temporal\nresolution (i.e., saving intervals of MD simulation trajectories) and state\npartition in high resolution data, since deep neural network models might not\nautomatically disentangle slow dynamics from fast dynamics when both are\npresent in data influencing each other.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 09:26:36 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Zeng", "Wenqi", ""], ["Cao", "Siqin", ""], ["Huang", "Xuhui", ""], ["Yao", "Yuan", ""]]}, {"id": "2107.06578", "submitter": "Stephan Fahrenkrog-Petersen", "authors": "Fabian R\\\"osel, Stephan A. Fahrenkrog-Petersen, Han van der Aa,\n  Matthias Weidlich", "title": "A Distance Measure for Privacy-preserving Process Mining based on\n  Feature Learning", "comments": "Accepted for 17th International Workshop on Business Process\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To enable process analysis based on an event log without compromising the\nprivacy of individuals involved in process execution, a log may be anonymized.\nSuch anonymization strives to transform a log so that it satisfies provable\nprivacy guarantees, while largely maintaining its utility for process analysis.\nExisting techniques perform anonymization using simple, syntactic measures to\nidentify suitable transformation operations. This way, the semantics of the\nactivities referenced by the events in a trace are neglected, potentially\nleading to transformations in which events of unrelated activities are merged.\nTo avoid this and incorporate the semantics of activities during anonymization,\nwe propose to instead incorporate a distance measure based on feature learning.\nSpecifically, we show how embeddings of events enable the definition of a\ndistance measure for traces to guide event log anonymization. Our experiments\nwith real-world data indicate that anonymization using this measure, compared\nto a syntactic one, yields logs that are closer to the original log in various\ndimensions and, hence, have higher utility for process analysis.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 09:44:28 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["R\u00f6sel", "Fabian", ""], ["Fahrenkrog-Petersen", "Stephan A.", ""], ["van der Aa", "Han", ""], ["Weidlich", "Matthias", ""]]}, {"id": "2107.06581", "submitter": "Liming Zhang", "authors": "Tao Qian, Lei Dai, Liming Zhang, and Zehua Chen", "title": "A Granular Sieving Algorithm for Deterministic Global Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A gradient-free deterministic method is developed to solve global\noptimization problems for Lipschitz continuous functions defined in arbitrary\npath-wise connected compact sets in Euclidean spaces. The method can be\nregarded as granular sieving with synchronous analysis in both the domain and\nrange of the objective function. With straightforward mathematical formulation\napplicable to both univariate and multivariate objective functions, the global\nminimum value and all the global minimizers are located through two decreasing\nsequences of compact sets in, respectively, the domain and range spaces. The\nalgorithm is easy to implement with moderate computational cost. The method is\ntested against extensive benchmark functions in the literature. The\nexperimental results show remarkable effectiveness and applicability of the\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 10:03:03 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Qian", "Tao", ""], ["Dai", "Lei", ""], ["Zhang", "Liming", ""], ["Chen", "Zehua", ""]]}, {"id": "2107.06608", "submitter": "Nadav Cohen", "authors": "Omer Elkabetz and Nadav Cohen", "title": "Continuous vs. Discrete Optimization of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing analyses of optimization in deep learning are either continuous,\nfocusing on (variants of) gradient flow, or discrete, directly treating\n(variants of) gradient descent. Gradient flow is amenable to theoretical\nanalysis, but is stylized and disregards computational efficiency. The extent\nto which it represents gradient descent is an open question in deep learning\ntheory. The current paper studies this question. Viewing gradient descent as an\napproximate numerical solution to the initial value problem of gradient flow,\nwe find that the degree of approximation depends on the curvature along the\nlatter's trajectory. We then show that over deep neural networks with\nhomogeneous activations, gradient flow trajectories enjoy favorable curvature,\nsuggesting they are well approximated by gradient descent. This finding allows\nus to translate an analysis of gradient flow over deep linear neural networks\ninto a guarantee that gradient descent efficiently converges to global minimum\nalmost surely under random initialization. Experiments suggest that over simple\ndeep neural networks, gradient descent with conventional step size is indeed\nclose to the continuous limit. We hypothesize that the theory of gradient flows\nwill be central to unraveling mysteries behind deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 10:59:57 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Elkabetz", "Omer", ""], ["Cohen", "Nadav", ""]]}, {"id": "2107.06629", "submitter": "Miroslav Bogdanovic", "authors": "Miroslav Bogdanovic, Majid Khadiv, Ludovic Righetti", "title": "Model-free Reinforcement Learning for Robust Locomotion Using Trajectory\n  Optimization for Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a general, two-stage reinforcement learning approach\nfor going from a single demonstration trajectory to a robust policy that can be\ndeployed on hardware without any additional training. The demonstration is used\nin the first stage as a starting point to facilitate initial exploration. In\nthe second stage, the relevant task reward is optimized directly and a policy\nrobust to environment uncertainties is computed. We demonstrate and examine in\ndetail performance and robustness of our approach on highly dynamic hopping and\nbounding tasks on a real quadruped robot.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 12:07:19 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bogdanovic", "Miroslav", ""], ["Khadiv", "Majid", ""], ["Righetti", "Ludovic", ""]]}, {"id": "2107.06638", "submitter": "Anurag Sarkar", "authors": "Anurag Sarkar, Seth Cooper", "title": "Procedural Content Generation using Behavior Trees (PCGBT)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavior trees (BTs) are a popular method of modeling the behavior of NPCs\nand enemy AI and have found widespread use in a large number of commercial\ngames. In this paper, rather than use BTs to model game-playing agents, we\ndemonstrate their use for modeling game design agents, defining behaviors as\nexecuting content generation tasks rather than in-game actions. Similar to how\ntraditional BTs enable modeling behaviors in a modular and dynamic manner, BTs\nfor PCG enable simple subtrees for generating parts of levels to be combined\nmodularly to form more complex trees for generating whole levels as well as\ngenerators that can dynamically vary the generated content. We demonstrate this\napproach by using BTs to model generators for Super Mario Bros., Mega Man and\nMetroid levels as well as dungeon layouts and discuss several ways in which\nthis PCGBT paradigm could be applied and extended in the future.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 17:54:00 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Sarkar", "Anurag", ""], ["Cooper", "Seth", ""]]}, {"id": "2107.06639", "submitter": "Kacper Sokol", "authors": "Kacper Sokol and Peter Flach", "title": "You Only Write Thrice: Creating Documents, Computational Notebooks and\n  Presentations From a Single Source", "comments": "Published at Rethinking ML Papers -- ICLR 2021 Workshop. OpenReview:\n  https://openreview.net/forum?id=i4zpuNRiU4G Exhibit:\n  https://so-cool.github.io/you-only-write-thrice/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Academic trade requires juggling multiple variants of the same content\npublished in different formats: manuscripts, presentations, posters and\ncomputational notebooks. The need to track versions to accommodate for the\nwrite--review--rebut--revise life-cycle adds another layer of complexity. We\npropose to significantly reduce this burden by maintaining a single source\ndocument in a version-controlled environment (such as git), adding\nfunctionality to generate a collection of output formats popular in academia.\nTo this end, we utilise various open-source tools from the Jupyter scientific\ncomputing ecosystem and operationalise selected software engineering concepts.\nWe offer a proof-of-concept workflow that composes Jupyter Book (an online\ndocument), Jupyter Notebook (a computational narrative) and reveal.js slides\nfrom a single markdown source file. Hosted on GitHub, our approach supports\nchange tracking and versioning, as well as a transparent review process based\non the underlying code issue management infrastructure. An exhibit of our\nworkflow can be previewed at https://so-cool.github.io/you-only-write-thrice/.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 21:02:09 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Sokol", "Kacper", ""], ["Flach", "Peter", ""]]}, {"id": "2107.06641", "submitter": "Haochen Liu", "authors": "Haochen Liu, Yiqi Wang, Wenqi Fan, Xiaorui Liu, Yaxin Li, Shaili Jain,\n  Anil K. Jain, Jiliang Tang", "title": "Trustworthy AI: A Computational Perspective", "comments": "54 pages. arXiv admin note: text overlap with arXiv:1512.04150,\n  arXiv:1602.04938 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few decades, artificial intelligence (AI) technology has\nexperienced swift developments, changing everyone's daily life and profoundly\naltering the course of human society. The intention of developing AI is to\nbenefit humans, by reducing human labor, bringing everyday convenience to human\nlives, and promoting social good. However, recent research and AI applications\nshow that AI can cause unintentional harm to humans, such as making unreliable\ndecisions in safety-critical scenarios or undermining fairness by inadvertently\ndiscriminating against one group. Thus, trustworthy AI has attracted immense\nattention recently, which requires careful consideration to avoid the adverse\neffects that AI may bring to humans, so that humans can fully trust and live in\nharmony with AI technologies.\n  Recent years have witnessed a tremendous amount of research on trustworthy\nAI. In this survey, we present a comprehensive survey of trustworthy AI from a\ncomputational perspective, to help readers understand the latest technologies\nfor achieving trustworthy AI. Trustworthy AI is a large and complex area,\ninvolving various dimensions. In this work, we focus on six of the most crucial\ndimensions in achieving trustworthy AI: (i) Safety & Robustness, (ii)\nNon-discrimination & Fairness, (iii) Explainability, (iv) Privacy, (v)\nAccountability & Auditability, and (vi) Environmental Well-Being. For each\ndimension, we review the recent related technologies according to a taxonomy\nand summarize their applications in real-world systems. We also discuss the\naccordant and conflicting interactions among different dimensions and discuss\npotential aspects for trustworthy AI to investigate in the future.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 14:21:46 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Liu", "Haochen", ""], ["Wang", "Yiqi", ""], ["Fan", "Wenqi", ""], ["Liu", "Xiaorui", ""], ["Li", "Yaxin", ""], ["Jain", "Shaili", ""], ["Jain", "Anil K.", ""], ["Tang", "Jiliang", ""]]}, {"id": "2107.06661", "submitter": "Ingmar Schubert", "authors": "Ingmar Schubert and Ozgur S. Oguz and Marc Toussaint", "title": "Plan-Based Relaxed Reward Shaping for Goal-Directed Tasks", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": "ICLR 2021 - 9th International Conference on Learning\n  Representations", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In high-dimensional state spaces, the usefulness of Reinforcement Learning\n(RL) is limited by the problem of exploration. This issue has been addressed\nusing potential-based reward shaping (PB-RS) previously. In the present work,\nwe introduce Final-Volume-Preserving Reward Shaping (FV-RS). FV-RS relaxes the\nstrict optimality guarantees of PB-RS to a guarantee of preserved long-term\nbehavior. Being less restrictive, FV-RS allows for reward shaping functions\nthat are even better suited for improving the sample efficiency of RL\nalgorithms. In particular, we consider settings in which the agent has access\nto an approximate plan. Here, we use examples of simulated robotic manipulation\ntasks to demonstrate that plan-based FV-RS can indeed significantly improve the\nsample efficiency of RL over plan-based PB-RS.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 12:55:41 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Schubert", "Ingmar", ""], ["Oguz", "Ozgur S.", ""], ["Toussaint", "Marc", ""]]}, {"id": "2107.06668", "submitter": "Lixuan Yang", "authors": "Lixuan Yang and Dario Rossi", "title": "Thinkback: Task-SpecificOut-of-Distribution Detection", "comments": null, "journal-ref": "International Conference on Machine Leanring workshop on\n  Uncertainty and Robustness in Deep Learning 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased success of Deep Learning (DL) has recently sparked large-scale\ndeployment of DL models in many diverse industry segments. Yet, a crucial\nweakness of supervised model is the inherent difficulty in handling\nout-of-distribution samples, i.e., samples belonging to classes that were not\npresented to the model at training time. We propose in this paper a novel way\nto formulate the out-of-distribution detection problem, tailored for DL models.\nOur method does not require fine tuning process on training data, yet is\nsignificantly more accurate than the state of the art for out-of-distribution\ndetection.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 09:34:26 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Yang", "Lixuan", ""], ["Rossi", "Dario", ""]]}, {"id": "2107.06672", "submitter": "Frederic Lardeux", "authors": "Fr\\'ed\\'eric Lardeux (LERIA), Eric Monfroy (LERIA)", "title": "Improved SAT models for NFA learning", "comments": null, "journal-ref": "International Conference in Optimization and Learning (OLA), Jun\n  2021, Catania, Italy", "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammatical inference is concerned with the study of algorithms for learning\nautomata and grammars from words. We focus on learning Nondeterministic Finite\nAutomaton of size k from samples of words. To this end, we formulate the\nproblem as a SAT model. The generated SAT instances being enormous, we propose\nsome model improvements, both in terms of the number of variables, the number\nof clauses, and clauses size. These improvements significantly reduce the\ninstances, but at the cost of longer generation time. We thus try to balance\ninstance size vs. generation and solving time. We also achieved some\nexperimental comparisons and we analyzed our various model improvements.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 06:54:07 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Lardeux", "Fr\u00e9d\u00e9ric", "", "LERIA"], ["Monfroy", "Eric", "", "LERIA"]]}, {"id": "2107.06675", "submitter": "Florian Ziel", "authors": "Florian Ziel", "title": "M5 Competition Uncertainty: Overdispersion, distributional forecasting,\n  GAMLSS and beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The M5 competition uncertainty track aims for probabilistic forecasting of\nsales of thousands of Walmart retail goods. We show that the M5 competition\ndata faces strong overdispersion and sporadic demand, especially zero demand.\nWe discuss resulting modeling issues concerning adequate probabilistic\nforecasting of such count data processes. Unfortunately, the majority of\npopular prediction methods used in the M5 competition (e.g. lightgbm and\nxgboost GBMs) fails to address the data characteristics due to the considered\nobjective functions. The distributional forecasting provides a suitable\nmodeling approach for to the overcome those problems. The GAMLSS framework\nallows flexible probabilistic forecasting using low dimensional distributions.\nWe illustrate, how the GAMLSS approach can be applied for the M5 competition\ndata by modeling the location and scale parameter of various distributions,\ne.g. the negative binomial distribution. Finally, we discuss software packages\nfor distributional modeling and their drawback, like the R package gamlss with\nits package extensions, and (deep) distributional forecasting libraries such as\nTensorFlow Probability.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 13:05:55 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Ziel", "Florian", ""]]}, {"id": "2107.06686", "submitter": "Djordje Grbic", "authors": "Djordje Grbic and Sebastian Risi", "title": "Safer Reinforcement Learning through Transferable Instinct Networks", "comments": "The paper was accepted in the ALIFE 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Random exploration is one of the main mechanisms through which reinforcement\nlearning (RL) finds well-performing policies. However, it can lead to\nundesirable or catastrophic outcomes when learning online in safety-critical\nenvironments. In fact, safe learning is one of the major obstacles towards\nreal-world agents that can learn during deployment. One way of ensuring that\nagents respect hard limitations is to explicitly configure boundaries in which\nthey can operate. While this might work in some cases, we do not always have\nclear a-priori information which states and actions can lead dangerously close\nto hazardous states. Here, we present an approach where an additional policy\ncan override the main policy and offer a safer alternative action. In our\ninstinct-regulated RL (IR^2L) approach, an \"instinctual\" network is trained to\nrecognize undesirable situations, while guarding the learning policy against\nentering them. The instinct network is pre-trained on a single task where it is\nsafe to make mistakes, and transferred to environments in which learning a new\ntask safely is critical. We demonstrate IR^2L in the OpenAI Safety gym domain,\nin which it receives a significantly lower number of safety violations during\ntraining than a baseline RL approach while reaching similar task performance.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 13:22:04 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Grbic", "Djordje", ""], ["Risi", "Sebastian", ""]]}, {"id": "2107.06692", "submitter": "Ariyan Bighashdel", "authors": "Ariyan Bighashdel, Panagiotis Meletis, Pavol Jancura, and Gijs\n  Dubbelman", "title": "Deep Adaptive Multi-Intention Inverse Reinforcement Learning", "comments": "Accepted for presentation at ECML/PKDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a deep Inverse Reinforcement Learning (IRL) framework\nthat can learn an a priori unknown number of nonlinear reward functions from\nunlabeled experts' demonstrations. For this purpose, we employ the tools from\nDirichlet processes and propose an adaptive approach to simultaneously account\nfor both complex and unknown number of reward functions. Using the conditional\nmaximum entropy principle, we model the experts' multi-intention behaviors as a\nmixture of latent intention distributions and derive two algorithms to estimate\nthe parameters of the deep reward network along with the number of experts'\nintentions from unlabeled demonstrations. The proposed algorithms are evaluated\non three benchmarks, two of which have been specifically extended in this study\nfor multi-intention IRL, and compared with well-known baselines. We demonstrate\nthrough several experiments the advantages of our algorithms over the existing\napproaches and the benefits of online inferring, rather than fixing beforehand,\nthe number of expert's intentions.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 13:33:01 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bighashdel", "Ariyan", ""], ["Meletis", "Panagiotis", ""], ["Jancura", "Pavol", ""], ["Dubbelman", "Gijs", ""]]}, {"id": "2107.06708", "submitter": "Armin Moin", "authors": "Armin Moin, Moharram Challenger, Atta Badii and Stephan G\\\"unnemann", "title": "MDE4QAI: Towards Model-Driven Engineering for Quantum Artificial\n  Intelligence", "comments": "Preliminary Version - Vision Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Over the past decade, Artificial Intelligence (AI) has provided enormous new\npossibilities and opportunities, but also new demands and requirements for\nsoftware systems. In particular, Machine Learning (ML) has proven useful in\nalmost every vertical application domain. Although other sub-disciplines of AI,\nsuch as intelligent agents and Multi-Agent Systems (MAS) did not become\npromoted to the same extent, they still possess the potential to be integrated\ninto the mainstream technology stacks and ecosystems, for example, due to the\nongoing prevalence of the Internet of Things (IoT) and smart Cyber-Physical\nSystems (CPS). However, in the decade ahead, an unprecedented paradigm shift\nfrom classical computing towards Quantum Computing (QC) is expected, with\nperhaps a quantum-classical hybrid model. We expect the Model-Driven\nEngineering (MDE) paradigm to be an enabler and a facilitator, when it comes to\nthe quantum and the quantum-classical hybrid applications as it has already\nproven beneficial in the highly complex domains of IoT, smart CPS and AI with\ninherently heterogeneous hardware and software platforms, and APIs. This\nincludes not only automated code generation, but also automated model checking\nand verification, as well as model analysis in the early design phases, and\nmodel-to-model transformations both at the design-time and at the runtime. In\nthis paper, the vision is focused on MDE for Quantum AI, and a holistic\napproach integrating all of the above.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 13:56:15 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Moin", "Armin", ""], ["Challenger", "Moharram", ""], ["Badii", "Atta", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2107.06747", "submitter": "Arkadiusz Sitek", "authors": "Arkadiusz Sitek, Sangtae Ahn, Evren Asma, Adam Chandler, Alvin Ihsani,\n  Sven Prevrhal, Arman Rahmim, Babak Saboury, Kris Thielemans", "title": "Artificial Intelligence in PET: an Industry Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) has significant potential to positively impact\nand advance medical imaging, including positron emission tomography (PET)\nimaging applications. AI has the ability to enhance and optimize all aspects of\nthe PET imaging chain from patient scheduling, patient setup, protocoling, data\nacquisition, detector signal processing, reconstruction, image processing and\ninterpretation. AI poses industry-specific challenges which will need to be\naddressed and overcome to maximize the future potentials of AI in PET. This\npaper provides an overview of these industry-specific challenges for the\ndevelopment, standardization, commercialization, and clinical adoption of AI,\nand explores the potential enhancements to PET imaging brought on by AI in the\nnear future. In particular, the combination of on-demand image reconstruction,\nAI, and custom designed data processing workflows may open new possibilities\nfor innovation which would positively impact the industry and ultimately\npatients.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 14:47:24 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Sitek", "Arkadiusz", ""], ["Ahn", "Sangtae", ""], ["Asma", "Evren", ""], ["Chandler", "Adam", ""], ["Ihsani", "Alvin", ""], ["Prevrhal", "Sven", ""], ["Rahmim", "Arman", ""], ["Saboury", "Babak", ""], ["Thielemans", "Kris", ""]]}, {"id": "2107.06750", "submitter": "Zarathustra Amadeus Goertzel", "authors": "Zarathustra Goertzel, Karel Chvalovsk\\'y, Jan Jakub\\r{u}v, Miroslav\n  Ol\\v{s}\\'ak, Josef Urban", "title": "Fast and Slow Enigmas and Parental Guidance", "comments": "23 pages, 11 tables, 1 figure, submitted to FroCoS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe several additions to the ENIGMA system that guides clause\nselection in the E automated theorem prover. First, we significantly speed up\nits neural guidance by adding server-based GPU evaluation. The second addition\nis motivated by fast weight-based rejection filters that are currently used in\nsystems like E and Prover9. Such systems can be made more intelligent by\ninstead training fast versions of ENIGMA that implement more intelligent\npre-filtering. This results in combinations of trainable fast and slow thinking\nthat improves over both the fast-only and slow-only methods. The third addition\nis based on \"judging the children by their parents\", i.e., possibly rejecting\nan inference before it produces a clause. This is motivated by standard\nevolutionary mechanisms, where there is always a cost to producing all possible\noffsprings in the current population. This saves time by not evaluating all\nclauses by more expensive methods and provides a complementary view of the\ngenerated clauses. The methods are evaluated on a large benchmark coming from\nthe Mizar Mathematical Library, showing good improvements over the state of the\nart.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 14:53:08 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Goertzel", "Zarathustra", ""], ["Chvalovsk\u00fd", "Karel", ""], ["Jakub\u016fv", "Jan", ""], ["Ol\u0161\u00e1k", "Miroslav", ""], ["Urban", "Josef", ""]]}, {"id": "2107.06777", "submitter": "Christian Bartz", "authors": "Christian Bartz, Hendrik R\\\"atz, Haojin Yang, Joseph Bethge, Christoph\n  Meinel", "title": "Synthesis in Style: Semantic Segmentation of Historical Documents using\n  Synthetic Data", "comments": "Code available at: https://github.com/Bartzi/synthesis-in-style", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most pressing problems in the automated analysis of historical\ndocuments is the availability of annotated training data. In this paper, we\npropose a novel method for the synthesis of training data for semantic\nsegmentation of document images. We utilize clusters found in intermediate\nfeatures of a StyleGAN generator for the synthesis of RGB and label images at\nthe same time. Our model can be applied to any dataset of scanned documents\nwithout the need for manual annotation of individual images, as each model is\ncustom-fit to the dataset. In our experiments, we show that models trained on\nour synthetic data can reach competitive performance on open benchmark datasets\nfor line segmentation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 15:36:47 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bartz", "Christian", ""], ["R\u00e4tz", "Hendrik", ""], ["Yang", "Haojin", ""], ["Bethge", "Joseph", ""], ["Meinel", "Christoph", ""]]}, {"id": "2107.06817", "submitter": "Michael Leybovich", "authors": "Michael Leybovich and Oded Shmueli", "title": "Efficient Set of Vectors Search", "comments": "6 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We consider a similarity measure between two sets $A$ and $B$ of vectors,\nthat balances the average and maximum cosine distance between pairs of vectors,\none from set $A$ and one from set $B$. As a motivation for this measure, we\npresent lineage tracking in a database. To practically realize this measure, we\nneed an approximate search algorithm that given a set of vectors $A$ and sets\nof vectors $B_1,...,B_n$, the algorithm quickly locates the set $B_i$ that\nmaximizes the similarity measure. For the case where all sets are singleton\nsets, essentially each is a single vector, there are known efficient\napproximate search algorithms, e.g., approximated versions of tree search\nalgorithms, locality-sensitive hashing (LSH), vector quantization (VQ) and\nproximity graph algorithms. In this work, we present approximate search\nalgorithms for the general case. The underlying idea in these algorithms is\nencoding a set of vectors via a \"long\" single vector.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 16:22:20 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Leybovich", "Michael", ""], ["Shmueli", "Oded", ""]]}, {"id": "2107.06833", "submitter": "Tarik A. Rashid", "authors": "Ravi Teja Batchu, Abeer Alsadoon, P.W.C. Prasad, Rasha S. Ali, Tarik\n  A. Rashid, Ghossoon Alsadoon, Oday D. Jerew", "title": "A Review-based Taxonomy for Secure Health Care Monitoring: Wireless\n  Smart Cameras", "comments": "29 pages", "journal-ref": "Journal of Applied Security Research, 2021", "doi": "10.1080/19361610.2021.1947112", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Health records data security is one of the main challenges in e-health\nsystems. Authentication is one of the essential security services to support\nthe stored data confidentiality, integrity, and availability. This research\nfocuses on the secure storage of patient and medical records in the healthcare\nsector where data security and unauthorized access is an ongoing issue. A\npotential solution comes from biometrics, although their use may be\ntime-consuming and can slow down data retrieval. This research aims to overcome\nthese challenges and enhance data access control in the healthcare sector\nthrough the addition of biometrics in the form of fingerprints. The proposed\nmodel for application in the healthcare sector consists of Collection, Network\ncommunication, and Authentication (CNA) using biometrics, which replaces an\nexisting password-based access control method. A sensor then collects data and\nby using a network (wireless or Zig-bee), a connection is established, after\nconnectivity analytics and data management work which processes and aggregate\nthe data. Subsequently, access is granted to authenticated users of the\napplication. This IoT-based biometric authentication system facilitates\neffective recognition and ensures confidentiality, integrity, and reliability\nof patients, records and other sensitive data. The proposed solution provides\nreliable access to healthcare data and enables secure access through the\nprocess of user and device authentication. The proposed model has been\ndeveloped for access control to data through the authentication of users in\nhealthcare to reduce data manipulation or theft.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 11:59:10 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Batchu", "Ravi Teja", ""], ["Alsadoon", "Abeer", ""], ["Prasad", "P. W. C.", ""], ["Ali", "Rasha S.", ""], ["Rashid", "Tarik A.", ""], ["Alsadoon", "Ghossoon", ""], ["Jerew", "Oday D.", ""]]}, {"id": "2107.06835", "submitter": "Ripon Patgiri", "authors": "Sabuzima Nayak, Ripon Patgiri, Lilapati Waikhom, Arif Ahmed", "title": "A Review on Edge Analytics: Issues, Challenges, Opportunities, Promises,\n  Future Directions, and Applications", "comments": "Submitted to Elsevier for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.DB cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Edge technology aims to bring Cloud resources (specifically, the compute,\nstorage, and network) to the closed proximity of the Edge devices, i.e., smart\ndevices where the data are produced and consumed. Embedding computing and\napplication in Edge devices lead to emerging of two new concepts in Edge\ntechnology, namely, Edge computing and Edge analytics. Edge analytics uses some\ntechniques or algorithms to analyze the data generated by the Edge devices.\nWith the emerging of Edge analytics, the Edge devices have become a complete\nset. Currently, Edge analytics is unable to provide full support for the\nexecution of the analytic techniques. The Edge devices cannot execute advanced\nand sophisticated analytic algorithms following various constraints such as\nlimited power supply, small memory size, limited resources, etc. This article\naims to provide a detailed discussion on Edge analytics. A clear explanation to\ndistinguish between the three concepts of Edge technology, namely, Edge\ndevices, Edge computing, and Edge analytics, along with their issues.\nFurthermore, the article discusses the implementation of Edge analytics to\nsolve many problems in various areas such as retail, agriculture, industry, and\nhealthcare. In addition, the research papers of the state-of-the-art edge\nanalytics are rigorously reviewed in this article to explore the existing\nissues, emerging challenges, research opportunities and their directions, and\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 21:48:20 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Nayak", "Sabuzima", ""], ["Patgiri", "Ripon", ""], ["Waikhom", "Lilapati", ""], ["Ahmed", "Arif", ""]]}, {"id": "2107.06840", "submitter": "Akansel Cosgun", "authors": "Dylan Klein, Akansel Cosgun", "title": "Mixing Human Demonstrations with Self-Exploration in Experience Replay\n  for Deep Reinforcement Learning", "comments": "2 pages. Submitted to ICDL 2021 Workshop on Human aligned\n  Reinforcement Learning for Autonomous Agents and Robots", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the effect of using human demonstration data in the replay\nbuffer for Deep Reinforcement Learning. We use a policy gradient method with a\nmodified experience replay buffer where a human demonstration experience is\nsampled with a given probability. We analyze different ratios of using\ndemonstration data in a task where an agent attempts to reach a goal while\navoiding obstacles. Our results suggest that while the agents trained by pure\nself-exploration and pure demonstration had similar success rates, the pure\ndemonstration model converged faster to solutions with less number of steps.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 16:55:30 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Klein", "Dylan", ""], ["Cosgun", "Akansel", ""]]}, {"id": "2107.06845", "submitter": "Basit Alawode", "authors": "Basit O. Alawode, Motaz Alfarraj", "title": "Meta-Optimization of Deep CNN for Image Denoising Using LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent application of deep learning (DL) to various tasks has seen the\nperformance of classical techniques surpassed by their DL-based counterparts.\nAs a result, DL has equally seen application in the removal of noise from\nimages. In particular, the use of deep feed-forward convolutional neural\nnetworks (DnCNNs) has been investigated for denoising. It utilizes advances in\nDL techniques such as deep architecture, residual learning, and batch\nnormalization to achieve better denoising performance when compared with the\nother classical state-of-the-art denoising algorithms. However, its deep\narchitecture resulted in a huge set of trainable parameters. Meta-optimization\nis a training approach of enabling algorithms to learn to train themselves by\nthemselves. Training algorithms using meta-optimizers have been shown to enable\nalgorithms to achieve better performance when compared to the classical\ngradient descent-based training approach. In this work, we investigate the\napplication of the meta-optimization training approach to the DnCNN denoising\nalgorithm to enhance its denoising capability. Our preliminary experiments on\nsimpler algorithms reveal the prospects of utilizing the meta-optimization\ntraining approach towards the enhancement of the DnCNN denoising capability.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 16:59:44 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Alawode", "Basit O.", ""], ["Alfarraj", "Motaz", ""]]}, {"id": "2107.06846", "submitter": "Daniel Salles Civitarese", "authors": "Daniel Salles Civitarese, Daniela Szwarcman, Bianca Zadrozny, Campbell\n  Watson", "title": "Extreme Precipitation Seasonal Forecast Using a Transformer Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI physics.ao-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An impact of climate change is the increase in frequency and intensity of\nextreme precipitation events. However, confidently predicting the likelihood of\nextreme precipitation at seasonal scales remains an outstanding challenge.\nHere, we present an approach to forecasting the quantiles of the maximum daily\nprecipitation in each week up to six months ahead using the temporal fusion\ntransformer (TFT) model. Through experiments in two regions, we compare TFT\npredictions with those of two baselines: climatology and a calibrated ECMWF\nSEAS5 ensemble forecast (S5). Our results show that, in terms of quantile risk\nat six month lead time, the TFT predictions significantly outperform those from\nS5 and show an overall small improvement compared to climatology. The TFT also\nresponds positively to departures from normal that climatology cannot.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 17:02:15 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Civitarese", "Daniel Salles", ""], ["Szwarcman", "Daniela", ""], ["Zadrozny", "Bianca", ""], ["Watson", "Campbell", ""]]}, {"id": "2107.06857", "submitter": "Joel Leibo", "authors": "Joel Z. Leibo, Edgar Du\\'e\\~nez-Guzm\\'an, Alexander Sasha Vezhnevets,\n  John P. Agapiou, Peter Sunehag, Raphael Koster, Jayd Matyas, Charles Beattie,\n  Igor Mordatch, Thore Graepel", "title": "Scalable Evaluation of Multi-Agent Reinforcement Learning with Melting\n  Pot", "comments": "Accepted to ICML 2021 and presented as a long talk; 33 pages; 9\n  figures", "journal-ref": "In International Conference on Machine Learning 2021 (pp.\n  6187-6199). PMLR", "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing evaluation suites for multi-agent reinforcement learning (MARL) do\nnot assess generalization to novel situations as their primary objective\n(unlike supervised-learning benchmarks). Our contribution, Melting Pot, is a\nMARL evaluation suite that fills this gap, and uses reinforcement learning to\nreduce the human labor required to create novel test scenarios. This works\nbecause one agent's behavior constitutes (part of) another agent's environment.\nTo demonstrate scalability, we have created over 80 unique test scenarios\ncovering a broad range of research topics such as social dilemmas, reciprocity,\nresource sharing, and task partitioning. We apply these test scenarios to\nstandard MARL training algorithms, and demonstrate how Melting Pot reveals\nweaknesses not apparent from training performance alone.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 17:22:14 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Leibo", "Joel Z.", ""], ["Du\u00e9\u00f1ez-Guzm\u00e1n", "Edgar", ""], ["Vezhnevets", "Alexander Sasha", ""], ["Agapiou", "John P.", ""], ["Sunehag", "Peter", ""], ["Koster", "Raphael", ""], ["Matyas", "Jayd", ""], ["Beattie", "Charles", ""], ["Mordatch", "Igor", ""], ["Graepel", "Thore", ""]]}, {"id": "2107.06862", "submitter": "Eyvind Niklasson", "authors": "Alexander Mordvintsev, Ettore Randazzo, Eyvind Niklasson", "title": "Differentiable Programming of Reaction-Diffusion Patterns", "comments": "ALIFE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Reaction-Diffusion (RD) systems provide a computational framework that\ngoverns many pattern formation processes in nature. Current RD system design\npractices boil down to trial-and-error parameter search. We propose a\ndifferentiable optimization method for learning the RD system parameters to\nperform example-based texture synthesis on a 2D plane. We do this by\nrepresenting the RD system as a variant of Neural Cellular Automata and using\ntask-specific differentiable loss functions. RD systems generated by our method\nexhibit robust, non-trivial 'life-like' behavior.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 17:38:34 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Mordvintsev", "Alexander", ""], ["Randazzo", "Ettore", ""], ["Niklasson", "Eyvind", ""]]}, {"id": "2107.06870", "submitter": "Jiongzhi Zheng", "authors": "Jiongzhi Zheng and Menglei Chen and Jialun Zhong and Kun He", "title": "Reinforced Hybrid Genetic Algorithm for the Traveling Salesman Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a powerful Reinforced Hybrid Genetic Algorithm (RHGA) for the\nfamous NP-hard Traveling Salesman Problem (TSP). RHGA combines reinforcement\nlearning technique with the well-known Edge Assembly Crossover genetic\nalgorithm (EAX-GA) and the Lin-Kernighan-Helsgaun (LKH) local search heuristic.\nWith the help of the proposed hybrid mechanism, the genetic evolution of EAX-GA\nand the local search of LKH can boost each other's performance. And the\nreinforcement learning technique based on Q-learning further promotes the\nhybrid genetic algorithm. Experimental results on 138 well-known and widely\nused TSP benchmarks, with the number of cities ranging from 1,000 to 85,900,\ndemonstrate the excellent performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 07:36:12 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Zheng", "Jiongzhi", ""], ["Chen", "Menglei", ""], ["Zhong", "Jialun", ""], ["He", "Kun", ""]]}, {"id": "2107.06872", "submitter": "Jeff Mitchell", "authors": "Jeff Mitchell and Jeffrey S. Bowers", "title": "Generalisation in Neural Networks Does not Require Feature Overlap", "comments": "19 pages, 3 Figures. Submitted to Cognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  That shared features between train and test data are required for\ngeneralisation in artificial neural networks has been a common assumption of\nboth proponents and critics of these models. Here, we show that convolutional\narchitectures avoid this limitation by applying them to two well known\nchallenges, based on learning the identity function and learning rules\ngoverning sequences of words. In each case, successful performance on the test\nset requires generalising to features that were not present in the training\ndata, which is typically not feasible for standard connectionist models.\nHowever, our experiments demonstrate that neural networks can succeed on such\nproblems when they incorporate the weight sharing employed by convolutional\narchitectures. In the image processing domain, such architectures are intended\nto reflect the symmetry under spatial translations of the natural world that\nsuch images depict. We discuss the role of symmetry in the two tasks and its\nconnection to generalisation.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 09:23:49 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Mitchell", "Jeff", ""], ["Bowers", "Jeffrey S.", ""]]}, {"id": "2107.06875", "submitter": "Amir Yazdani", "authors": "Amir Yazdani, Roya Sabbagh Novin, Andrew Merryweather, Tucker Hermans", "title": "DULA: A Differentiable Ergonomics Model for Postural Optimization in\n  Physical HRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ergonomics and human comfort are essential concerns in physical human-robot\ninteraction applications. Defining an accurate and easy-to-use ergonomic\nassessment model stands as an important step in providing feedback for postural\ncorrection to improve operator health and comfort. In order to enable efficient\ncomputation, previously proposed automated ergonomic assessment and correction\ntools make approximations or simplifications to gold-standard assessment tools\nused by ergonomists in practice. In order to retain assessment quality, while\nimproving computational considerations, we introduce DULA, a differentiable and\ncontinuous ergonomics model learned to replicate the popular and scientifically\nvalidated RULA assessment. We show that DULA provides assessment comparable to\nRULA while providing computational benefits. We highlight DULA's strength in a\ndemonstration of gradient-based postural optimization for a simulated\nteleoperation task.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 17:39:45 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Yazdani", "Amir", ""], ["Novin", "Roya Sabbagh", ""], ["Merryweather", "Andrew", ""], ["Hermans", "Tucker", ""]]}, {"id": "2107.06916", "submitter": "Mingbao Lin", "authors": "Mingbao Lin, Rongrong Ji, Bohong Chen, Fei Chao, Jianzhuang Liu, Wei\n  Zeng, Yonghong Tian, Qi Tian", "title": "Training Compact CNNs for Image Classification using Dynamic-coded\n  Filter Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mainstream approach for filter pruning is usually either to force a\nhard-coded importance estimation upon a computation-heavy pretrained model to\nselect \"important\" filters, or to impose a hyperparameter-sensitive sparse\nconstraint on the loss objective to regularize the network training. In this\npaper, we present a novel filter pruning method, dubbed dynamic-coded filter\nfusion (DCFF), to derive compact CNNs in a computation-economical and\nregularization-free manner for efficient image classification. Each filter in\nour DCFF is firstly given an inter-similarity distribution with a temperature\nparameter as a filter proxy, on top of which, a fresh Kullback-Leibler\ndivergence based dynamic-coded criterion is proposed to evaluate the filter\nimportance. In contrast to simply keeping high-score filters in other methods,\nwe propose the concept of filter fusion, i.e., the weighted averages using the\nassigned proxies, as our preserved filters. We obtain a one-hot\ninter-similarity distribution as the temperature parameter approaches infinity.\nThus, the relative importance of each filter can vary along with the training\nof the compact CNN, leading to dynamically changeable fused filters without\nboth the dependency on the pretrained model and the introduction of sparse\nconstraints. Extensive experiments on classification benchmarks demonstrate the\nsuperiority of our DCFF over the compared counterparts. For example, our DCFF\nderives a compact VGGNet-16 with only 72.77M FLOPs and 1.06M parameters while\nreaching top-1 accuracy of 93.47% on CIFAR-10. A compact ResNet-50 is obtained\nwith 63.8% FLOPs and 58.6% parameter reductions, retaining 75.60% top-1\naccuracy on ILSVRC-2012. Our code, narrower models and training logs are\navailable at https://github.com/lmbxmu/DCFF.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 18:07:38 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Lin", "Mingbao", ""], ["Ji", "Rongrong", ""], ["Chen", "Bohong", ""], ["Chao", "Fei", ""], ["Liu", "Jianzhuang", ""], ["Zeng", "Wei", ""], ["Tian", "Yonghong", ""], ["Tian", "Qi", ""]]}, {"id": "2107.06941", "submitter": "Lalith Sharan", "authors": "Lalith Sharan, Gabriele Romano, Sven Koehler, Halvar Kelm, Matthias\n  Karck, Raffaele De Simone and Sandy Engelhardt", "title": "Mutually improved endoscopic image synthesis and landmark detection in\n  unpaired image-to-image translation", "comments": "Submitted to IEEE JBHI 2021, 13 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The CycleGAN framework allows for unsupervised image-to-image translation of\nunpaired data. In a scenario of surgical training on a physical surgical\nsimulator, this method can be used to transform endoscopic images of phantoms\ninto images which more closely resemble the intra-operative appearance of the\nsame surgical target structure. This can be viewed as a novel augmented reality\napproach, which we coined Hyperrealism in previous work. In this use case, it\nis of paramount importance to display objects like needles, sutures or\ninstruments consistent in both domains while altering the style to a more\ntissue-like appearance. Segmentation of these objects would allow for a direct\ntransfer, however, contouring of these, partly tiny and thin foreground objects\nis cumbersome and perhaps inaccurate. Instead, we propose to use landmark\ndetection on the points when sutures pass into the tissue. This objective is\ndirectly incorporated into a CycleGAN framework by treating the performance of\npre-trained detector models as an additional optimization goal. We show that a\ntask defined on these sparse landmark labels improves consistency of synthesis\nby the generator network in both domains. Comparing a baseline CycleGAN\narchitecture to our proposed extension (DetCycleGAN), mean precision (PPV)\nimproved by +61.32, mean sensitivity (TPR) by +37.91, and mean F1 score by\n+0.4743. Furthermore, it could be shown that by dataset fusion, generated\nintra-operative images can be leveraged as additional training data for the\ndetection network itself. The data is released within the scope of the AdaptOR\nMICCAI Challenge 2021 at https://adaptor2021.github.io/, and code at\nhttps://github.com/Cardio-AI/detcyclegan_pytorch.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 19:09:50 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Sharan", "Lalith", ""], ["Romano", "Gabriele", ""], ["Koehler", "Sven", ""], ["Kelm", "Halvar", ""], ["Karck", "Matthias", ""], ["De Simone", "Raffaele", ""], ["Engelhardt", "Sandy", ""]]}, {"id": "2107.06943", "submitter": "Szymon P{\\l}otka", "authors": "Szymon P{\\l}otka, Tomasz W{\\l}odarczyk, Adam Klasa, Micha{\\l} Lipa,\n  Arkadiusz Sitek, Tomasz Trzci\\'nski", "title": "FetalNet: Multi-task deep learning framework for fetal ultrasound\n  biometric measurements", "comments": "Submitted to ICONIP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we propose an end-to-end multi-task neural network called\nFetalNet with an attention mechanism and stacked module for spatio-temporal\nfetal ultrasound scan video analysis. Fetal biometric measurement is a standard\nexamination during pregnancy used for the fetus growth monitoring and\nestimation of gestational age and fetal weight. The main goal in fetal\nultrasound scan video analysis is to find proper standard planes to measure the\nfetal head, abdomen and femur. Due to natural high speckle noise and shadows in\nultrasound data, medical expertise and sonographic experience are required to\nfind the appropriate acquisition plane and perform accurate measurements of the\nfetus. In addition, existing computer-aided methods for fetal US biometric\nmeasurement address only one single image frame without considering temporal\nfeatures. To address these shortcomings, we propose an end-to-end multi-task\nneural network for spatio-temporal ultrasound scan video analysis to\nsimultaneously localize, classify and measure the fetal body parts. We propose\na new encoder-decoder segmentation architecture that incorporates a\nclassification branch. Additionally, we employ an attention mechanism with a\nstacked module to learn salient maps to suppress irrelevant US regions and\nefficient scan plane localization. We trained on the fetal ultrasound video\ncomes from routine examinations of 700 different patients. Our method called\nFetalNet outperforms existing state-of-the-art methods in both classification\nand segmentation in fetal ultrasound video recordings.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 19:13:33 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["P\u0142otka", "Szymon", ""], ["W\u0142odarczyk", "Tomasz", ""], ["Klasa", "Adam", ""], ["Lipa", "Micha\u0142", ""], ["Sitek", "Arkadiusz", ""], ["Trzci\u0144ski", "Tomasz", ""]]}, {"id": "2107.06990", "submitter": "Tazin Afrin", "authors": "Tazin Afrin, Elaine Wang, Diane Litman, Lindsay C. Matsumura, Richard\n  Correnti", "title": "Annotation and Classification of Evidence and Reasoning Revisions in\n  Argumentative Writing", "comments": "10 pages, 11 tables, 15th Workshop on Innovative Use of NLP for\n  Building Educational Applications", "journal-ref": null, "doi": "10.18653/v1/2020.bea-1.7", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automated writing evaluation systems can improve students' writing insofar as\nstudents attend to the feedback provided and revise their essay drafts in ways\naligned with such feedback. Existing research on revision of argumentative\nwriting in such systems, however, has focused on the types of revisions\nstudents make (e.g., surface vs. content) rather than the extent to which\nrevisions actually respond to the feedback provided and improve the essay. We\nintroduce an annotation scheme to capture the nature of sentence-level\nrevisions of evidence use and reasoning (the `RER' scheme) and apply it to 5th-\nand 6th-grade students' argumentative essays. We show that reliable manual\nannotation can be achieved and that revision annotations correlate with a\nholistic assessment of essay improvement in line with the feedback provided.\nFurthermore, we explore the feasibility of automatically classifying revisions\naccording to our scheme.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 20:58:26 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Afrin", "Tazin", ""], ["Wang", "Elaine", ""], ["Litman", "Diane", ""], ["Matsumura", "Lindsay C.", ""], ["Correnti", "Richard", ""]]}, {"id": "2107.06994", "submitter": "James McClelland", "authors": "Andrew Joohun Nam and James L. McClelland (Stanford University)", "title": "What underlies rapid learning and systematic generalization in humans", "comments": "22 pages, 48 references, 6 Figures, and one Table, plus SI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Despite the groundbreaking successes of neural networks, contemporary models\nrequire extensive training with massive datasets and exhibit poor out-of-sample\ngeneralization. One proposed solution is to build systematicity and\ndomain-specific constraints into the model, echoing the tenets of classical,\nsymbolic cognitive architectures. In this paper, we consider the limitations of\nthis approach by examining human adults' ability to learn an abstract reasoning\ntask from a brief instructional tutorial and explanatory feedback for incorrect\nresponses, demonstrating that human learning dynamics and ability to generalize\noutside the range of the training examples differ drastically from those of a\nrepresentative neural network model, and that the model is brittle to changes\nin features not anticipated by its authors. We present further evidence from\nhuman data that the ability to consistently solve the puzzles was associated\nwith education, particularly basic mathematics education, and with the ability\nto provide a reliably identifiable, valid description of the strategy used. We\npropose that rapid learning and systematic generalization in humans may depend\non a gradual, experience-dependent process of learning-to-learn using\ninstructions and explanations to guide the construction of explicit abstract\nrules that support generalizable inferences.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 00:14:41 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Nam", "Andrew Joohun", "", "Stanford University"], ["McClelland", "James L.", "", "Stanford University"]]}, {"id": "2107.06996", "submitter": "Xiaorui Liu", "authors": "Xiaorui Liu, Wei Jin, Yao Ma, Yaxin Li, Hua Liu, Yiqi Wang, Ming Yan,\n  Jiliang Tang", "title": "Elastic Graph Neural Networks", "comments": "ICML 2021 (International Conference on Machine Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While many existing graph neural networks (GNNs) have been proven to perform\n$\\ell_2$-based graph smoothing that enforces smoothness globally, in this work\nwe aim to further enhance the local smoothness adaptivity of GNNs via\n$\\ell_1$-based graph smoothing. As a result, we introduce a family of GNNs\n(Elastic GNNs) based on $\\ell_1$ and $\\ell_2$-based graph smoothing. In\nparticular, we propose a novel and general message passing scheme into GNNs.\nThis message passing algorithm is not only friendly to back-propagation\ntraining but also achieves the desired smoothing properties with a theoretical\nconvergence guarantee. Experiments on semi-supervised learning tasks\ndemonstrate that the proposed Elastic GNNs obtain better adaptivity on\nbenchmark datasets and are significantly robust to graph adversarial attacks.\nThe implementation of Elastic GNNs is available at\n\\url{https://github.com/lxiaorui/ElasticGNN}.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 01:36:01 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Liu", "Xiaorui", ""], ["Jin", "Wei", ""], ["Ma", "Yao", ""], ["Li", "Yaxin", ""], ["Liu", "Hua", ""], ["Wang", "Yiqi", ""], ["Yan", "Ming", ""], ["Tang", "Jiliang", ""]]}, {"id": "2107.06997", "submitter": "Vincenzo Riccio", "authors": "Tahereh Zohdinasab, Vincenzo Riccio, Alessio Gambi, and Paolo Tonella", "title": "DeepHyperion: Exploring the Feature Space of Deep Learning-Based Systems\n  through Illumination Search", "comments": "To be published in Proceedings of the 30th ACM SIGSOFT International\n  Symposium on Software Testing and Analysis (ISSTA '21), July 11-17, 2021,\n  Virtual, Denmark. ACM, New York, NY, USA, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) has been successfully applied to a wide range of\napplication domains, including safety-critical ones. Several DL testing\napproaches have been recently proposed in the literature but none of them aims\nto assess how different interpretable features of the generated inputs affect\nthe system's behaviour. In this paper, we resort to Illumination Search to find\nthe highest-performing test cases (i.e., misbehaving and closest to\nmisbehaving), spread across the cells of a map representing the feature space\nof the system. We introduce a methodology that guides the users of our approach\nin the tasks of identifying and quantifying the dimensions of the feature space\nfor a given domain. We developed DeepHyperion, a search-based tool for DL\nsystems that illuminates, i.e., explores at large, the feature space, by\nproviding developers with an interpretable feature map where automatically\ngenerated inputs are placed along with information about the exposed\nbehaviours.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:14:38 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Zohdinasab", "Tahereh", ""], ["Riccio", "Vincenzo", ""], ["Gambi", "Alessio", ""], ["Tonella", "Paolo", ""]]}, {"id": "2107.07002", "submitter": "Mostafa Dehghani", "authors": "Mostafa Dehghani, Yi Tay, Alexey A. Gritsenko, Zhe Zhao, Neil Houlsby,\n  Fernando Diaz, Donald Metzler, Oriol Vinyals", "title": "The Benchmark Lottery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world of empirical machine learning (ML) strongly relies on benchmarks in\norder to determine the relative effectiveness of different algorithms and\nmethods. This paper proposes the notion of \"a benchmark lottery\" that describes\nthe overall fragility of the ML benchmarking process. The benchmark lottery\npostulates that many factors, other than fundamental algorithmic superiority,\nmay lead to a method being perceived as superior. On multiple benchmark setups\nthat are prevalent in the ML community, we show that the relative performance\nof algorithms may be altered significantly simply by choosing different\nbenchmark tasks, highlighting the fragility of the current paradigms and\npotential fallacious interpretation derived from benchmarking ML methods. Given\nthat every benchmark makes a statement about what it perceives to be important,\nwe argue that this might lead to biased progress in the community. We discuss\nthe implications of the observed phenomena and provide recommendations on\nmitigating them using multiple machine learning domains and communities as use\ncases, including natural language processing, computer vision, information\nretrieval, recommender systems, and reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 21:08:30 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Dehghani", "Mostafa", ""], ["Tay", "Yi", ""], ["Gritsenko", "Alexey A.", ""], ["Zhao", "Zhe", ""], ["Houlsby", "Neil", ""], ["Diaz", "Fernando", ""], ["Metzler", "Donald", ""], ["Vinyals", "Oriol", ""]]}, {"id": "2107.07005", "submitter": "Sahib Singh", "authors": "Ayush Manish Agrawal, Atharva Tendle, Harshvardhan Sikka, Sahib Singh", "title": "WeightScale: Interpreting Weight Change in Neural Networks", "comments": "9 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:2011.06735", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interpreting the learning dynamics of neural networks can provide useful\ninsights into how networks learn and the development of better training and\ndesign approaches. We present an approach to interpret learning in neural\nnetworks by measuring relative weight change on a per layer basis and\ndynamically aggregating emerging trends through combination of dimensionality\nreduction and clustering which allows us to scale to very deep networks. We use\nthis approach to investigate learning in the context of vision tasks across a\nvariety of state-of-the-art networks and provide insights into the learning\nbehavior of these networks, including how task complexity affects layer-wise\nlearning in deeper layers of networks.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 21:18:38 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Agrawal", "Ayush Manish", ""], ["Tendle", "Atharva", ""], ["Sikka", "Harshvardhan", ""], ["Singh", "Sahib", ""]]}, {"id": "2107.07015", "submitter": "Kailas Vodrahalli", "authors": "Kailas Vodrahalli, Tobias Gerstenberg, James Zou", "title": "Do Humans Trust Advice More if it Comes from AI? An Analysis of Human-AI\n  Interactions", "comments": "34 pages, 6 figures + 18 full page figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications of AI, the algorithm's output is framed as a suggestion\nto a human user. The user may ignore the advice or take it into consideration\nto modify his/her decisions. With the increasing prevalence of such human-AI\ninteractions, it is important to understand how users act (or do not act) upon\nAI advice, and how users regard advice differently if they believe the advice\ncome from an \"AI\" versus another human. In this paper, we characterize how\nhumans use AI suggestions relative to equivalent suggestions from a group of\npeer humans across several experimental settings. We find that participants'\nbeliefs about the human versus AI performance on a given task affects whether\nor not they heed the advice. When participants decide to use the advice, they\ndo so similarly for human and AI suggestions. These results provide insights\ninto factors that affect human-AI interactions.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 21:33:14 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Vodrahalli", "Kailas", ""], ["Gerstenberg", "Tobias", ""], ["Zou", "James", ""]]}, {"id": "2107.07016", "submitter": "Ricardo Gon\\c{c}alves", "authors": "Ricardo Gon\\c{c}alves, Matthias Knorr, Jo\\~ao Leite", "title": "Forgetting in Answer Set Programming -- A Survey", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Forgetting - or variable elimination - is an operation that allows the\nremoval, from a knowledge base, of middle variables no longer deemed relevant.\nIn recent years, many different approaches for forgetting in Answer Set\nProgramming have been proposed, in the form of specific operators, or classes\nof such operators, commonly following different principles and obeying\ndifferent properties. Each such approach was developed to somehow address some\nparticular view on forgetting, aimed at obeying a specific set of properties\ndeemed desirable in such view, but a comprehensive and uniform overview of all\nthe existing operators and properties is missing. In this paper, we thoroughly\nexamine existing properties and (classes of) operators for forgetting in Answer\nSet Programming, drawing a complete picture of the landscape of these classes\nof forgetting operators, which includes many novel results on relations between\nproperties and operators, including considerations on concrete operators to\ncompute results of forgetting and computational complexity. Our goal is to\nprovide guidance to help users in choosing the operator most adequate for their\napplication requirements.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 21:37:08 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Gon\u00e7alves", "Ricardo", ""], ["Knorr", "Matthias", ""], ["Leite", "Jo\u00e3o", ""]]}, {"id": "2107.07031", "submitter": "Francesco Massari", "authors": "Francesco Massari, Martin Biehl, Lisa Meeden, Ryota Kanai", "title": "Experimental Evidence that Empowerment May Drive Exploration in\n  Sparse-Reward Environments", "comments": "6 pages, 3 figures, to be published in proceedings of the\n  International Conference on Development and Learning 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) is known to be often unsuccessful in environments\nwith sparse extrinsic rewards. A possible countermeasure is to endow RL agents\nwith an intrinsic reward function, or 'intrinsic motivation', which rewards the\nagent based on certain features of the current sensor state. An intrinsic\nreward function based on the principle of empowerment assigns rewards\nproportional to the amount of control the agent has over its own sensors. We\nimplemented a variation on a recently proposed intrinsically motivated agent,\nwhich we refer to as the 'curious' agent, and an empowerment-inspired agent.\nThe former leverages sensor state encoding with a variational autoencoder,\nwhile the latter predicts the next sensor state via a variational information\nbottleneck. We compared the performance of both agents to that of an advantage\nactor-critic baseline in four sparse reward grid worlds. Both the empowerment\nagent and its curious competitor seem to benefit to similar extents from their\nintrinsic rewards. This provides some experimental support to the conjecture\nthat empowerment can be used to drive exploration.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 22:52:38 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Massari", "Francesco", ""], ["Biehl", "Martin", ""], ["Meeden", "Lisa", ""], ["Kanai", "Ryota", ""]]}, {"id": "2107.07038", "submitter": "Manuel Garcia-Piqueras", "authors": "Manuel Garcia-Piqueras and Jos\\'e Hern\\'andez-Orallo", "title": "Conditional Teaching Size", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent research in machine teaching has explored the instruction of any\nconcept expressed in a universal language. In this compositional context, new\nexperimental results have shown that there exist data teaching sets\nsurprisingly shorter than the concept description itself. However, there exists\na bound for those remarkable experimental findings through teaching size and\nconcept complexity that we further explore here. As concepts are rarely taught\nin isolation we investigate the best configuration of concepts to teach a given\nset of concepts, where those that have been acquired first can be reused for\nthe description of new ones. This new notion of conditional teaching size\nuncovers new insights, such as the interposition phenomenon: certain prior\nknowledge generates simpler compatible concepts that increase the teaching size\nof the concept that we want to teach. This does not happen for conditional\nKolmogorov complexity. Furthermore, we provide an algorithm that constructs\noptimal curricula based on interposition avoidance. This paper presents a\nseries of theoretical results, including their proofs, and some directions for\nfuture work. New research possibilities in curriculum teaching in compositional\nscenarios are now wide open to exploration.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 23:08:58 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Garcia-Piqueras", "Manuel", ""], ["Hern\u00e1ndez-Orallo", "Jos\u00e9", ""]]}, {"id": "2107.07043", "submitter": "Zuohui Chen", "authors": "Zuohui Chen, Renxuan Wang, Jingyang Xiang, Yue Yu, Xin Xia, Shouling\n  Ji, Qi Xuan, and Xiaoniu Yang", "title": "GGT: Graph-Guided Testing for Adversarial Sample Detection of Deep\n  Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNN) are known to be vulnerable to adversarial samples,\nthe detection of which is crucial for the wide application of these DNN models.\nRecently, a number of deep testing methods in software engineering were\nproposed to find the vulnerability of DNN systems, and one of them, i.e., Model\nMutation Testing (MMT), was used to successfully detect various adversarial\nsamples generated by different kinds of adversarial attacks. However, the\nmutated models in MMT are always huge in number (e.g., over 100 models) and\nlack diversity (e.g., can be easily circumvented by high-confidence adversarial\nsamples), which makes it less efficient in real applications and less effective\nin detecting high-confidence adversarial samples. In this study, we propose\nGraph-Guided Testing (GGT) for adversarial sample detection to overcome these\naforementioned challenges. GGT generates pruned models with the guide of graph\ncharacteristics, each of them has only about 5% parameters of the mutated model\nin MMT, and graph guided models have higher diversity. The experiments on\nCIFAR10 and SVHN validate that GGT performs much better than MMT with respect\nto both effectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 12:12:36 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Chen", "Zuohui", ""], ["Wang", "Renxuan", ""], ["Xiang", "Jingyang", ""], ["Yu", "Yue", ""], ["Xia", "Xin", ""], ["Ji", "Shouling", ""], ["Xuan", "Qi", ""], ["Yang", "Xiaoniu", ""]]}, {"id": "2107.07045", "submitter": "Prashant Gohel", "authors": "Prashant Gohel, Priyanka Singh and Manoranjan Mohanty", "title": "Explainable AI: current status and future directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explainable Artificial Intelligence (XAI) is an emerging area of research in\nthe field of Artificial Intelligence (AI). XAI can explain how AI obtained a\nparticular solution (e.g., classification or object detection) and can also\nanswer other \"wh\" questions. This explainability is not possible in traditional\nAI. Explainability is essential for critical applications, such as defense,\nhealth care, law and order, and autonomous driving vehicles, etc, where the\nknow-how is required for trust and transparency. A number of XAI techniques so\nfar have been purposed for such applications. This paper provides an overview\nof these techniques from a multimedia (i.e., text, image, audio, and video)\npoint of view. The advantages and shortcomings of these techniques have been\ndiscussed, and pointers to some future directions have also been provided.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 08:42:19 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Gohel", "Prashant", ""], ["Singh", "Priyanka", ""], ["Mohanty", "Manoranjan", ""]]}, {"id": "2107.07054", "submitter": "Bijan Mazaheri", "authors": "Bijan Mazaheri, Siddharth Jain, Jehoshua Bruck", "title": "Expert Graphs: Synthesizing New Expertise via Collaboration", "comments": "13 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DM cs.IT econ.TH math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider multiple experts with overlapping expertise working on a\nclassification problem under uncertain input. What constitutes a consistent set\nof opinions? How can we predict the opinions of experts on missing sub-domains?\nIn this paper, we define a framework of to analyze this problem, termed \"expert\ngraphs.\" In an expert graph, vertices represent classes and edges represent\nbinary opinions on the topics of their vertices. We derive necessary conditions\nfor expert graph validity and use them to create \"synthetic experts\" which\ndescribe opinions consistent with the observed opinions of other experts. We\nshow this framework to be equivalent to the well-studied linear ordering\npolytope. We show our conditions are not sufficient for describing all expert\ngraphs on cliques, but are sufficient for cycles.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 00:27:16 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Mazaheri", "Bijan", ""], ["Jain", "Siddharth", ""], ["Bruck", "Jehoshua", ""]]}, {"id": "2107.07066", "submitter": "Ai Guanqun", "authors": "Guanqun Ai, Xingquan Zuo, Gang chen, and Binglin Wu", "title": "Deep Reinforcement Learning based Dynamic Optimization of Bus Timetable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bus timetable optimization is a key issue to reduce operational cost of bus\ncompanies and improve the service quality. Existing methods use exact or\nheuristic algorithms to optimize the timetable in an offline manner. In\npractice, the passenger flow may change significantly over time. Timetables\ndetermined in offline cannot adjust the departure interval to satisfy the\nchanged passenger flow. Aiming at improving the online performance of bus\ntimetable, we propose a Deep Reinforcement Learning based bus Timetable dynamic\nOptimization method (DRL-TO). In this method, the timetable optimization is\nconsidered as a sequential decision problem. A Deep Q-Network (DQN) is employed\nas the decision model to determine whether to dispatch a bus service during\neach minute of the service period. Therefore, the departure intervals of bus\nservices are determined in real time in accordance with passenger demand. We\nidentify several new and useful state features for the DQN, including the load\nfactor, carrying capacity utilization rate, and the number of stranding\npassengers. Taking into account both the interests of the bus company and\npassengers, a reward function is designed, which includes the indicators of\nfull load rate, empty load rate, passengers' waiting time, and the number of\nstranding passengers. Building on an existing method for calculating the\ncarrying capacity, we develop a new technique to enhance the matching degree at\neach bus station. Experiments demonstrate that compared with the timetable\ngenerated by the state-of-the-art bus timetable optimization approach based on\na memetic algorithm (BTOA-MA), Genetic Algorithm (GA) and the manual method,\nDRL-TO can dynamically determine the departure intervals based on the real-time\npassenger flow, saving 8$\\%$ of vehicles and reducing 17$\\%$ of passengers'\nwaiting time on average.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 01:22:49 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Ai", "Guanqun", ""], ["Zuo", "Xingquan", ""], ["chen", "Gang", ""], ["Wu", "Binglin", ""]]}, {"id": "2107.07089", "submitter": "Feng Shi", "authors": "Feng Shi, Chonghan Lee, Liang Qiu, Yizhou Zhao, Tianyi Shen, Shivran\n  Muralidhar, Tian Han, Song-Chun Zhu, Vijaykrishnan Narayanan", "title": "STAR: Sparse Transformer-based Action Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cognitive system for human action and behavior has evolved into a deep\nlearning regime, and especially the advent of Graph Convolution Networks has\ntransformed the field in recent years. However, previous works have mainly\nfocused on over-parameterized and complex models based on dense graph\nconvolution networks, resulting in low efficiency in training and inference.\nMeanwhile, the Transformer architecture-based model has not yet been well\nexplored for cognitive application in human action and behavior estimation.\nThis work proposes a novel skeleton-based human action recognition model with\nsparse attention on the spatial dimension and segmented linear attention on the\ntemporal dimension of data. Our model can also process the variable length of\nvideo clips grouped as a single batch. Experiments show that our model can\nachieve comparable performance while utilizing much less trainable parameters\nand achieve high speed in training and inference. Experiments show that our\nmodel achieves 4~18x speedup and 1/7~1/15 model size compared with the baseline\nmodels at competitive accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 02:53:11 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Shi", "Feng", ""], ["Lee", "Chonghan", ""], ["Qiu", "Liang", ""], ["Zhao", "Yizhou", ""], ["Shen", "Tianyi", ""], ["Muralidhar", "Shivran", ""], ["Han", "Tian", ""], ["Zhu", "Song-Chun", ""], ["Narayanan", "Vijaykrishnan", ""]]}, {"id": "2107.07095", "submitter": "Xiaomeng Ye", "authors": "Xiaomeng Ye and Ziwei Zhao and David Leake and Xizi Wang and David\n  Crandall", "title": "Applying the Case Difference Heuristic to Learn Adaptations from Deep\n  Network Features", "comments": "7 pages, 2 figures, 1 table. To be published in the IJCAI-21 Workshop\n  on Deep Learning, Case-Based Reasoning, and AutoML: Present and Future\n  Synergies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The case difference heuristic (CDH) approach is a knowledge-light method for\nlearning case adaptation knowledge from the case base of a case-based reasoning\nsystem. Given a pair of cases, the CDH approach attributes the difference in\ntheir solutions to the difference in the problems they solve, and generates\nadaptation rules to adjust solutions accordingly when a retrieved case and new\nquery have similar problem differences. As an alternative to learning\nadaptation rules, several researchers have applied neural networks to learn to\npredict solution differences from problem differences. Previous work on such\napproaches has assumed that the feature set describing problems is predefined.\nThis paper investigates a two-phase process combining deep learning for feature\nextraction and neural network based adaptation learning from extracted\nfeatures. Its performance is demonstrated in a regression task on an image\ndata: predicting age given the image of a face. Results show that the combined\nprocess can successfully learn adaptation knowledge applicable to nonsymbolic\ndifferences in cases. The CBR system achieves slightly lower performance\noverall than a baseline deep network regressor, but better performance than the\nbaseline on novel queries.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 03:11:56 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Ye", "Xiaomeng", ""], ["Zhao", "Ziwei", ""], ["Leake", "David", ""], ["Wang", "Xizi", ""], ["Crandall", "David", ""]]}, {"id": "2107.07112", "submitter": "Ensheng Shi", "authors": "Ensheng Shi, Yanlin Wang, Lun Du, Junjie Chen, Shi Han, Hongyu Zhang,\n  Dongmei Zhang, Hongbin Sun", "title": "Neural Code Summarization: How Far Are We?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source code summaries are important for the comprehension and maintenance of\nprograms. However, there are plenty of programs with missing, outdated, or\nmismatched summaries. Recently, deep learning techniques have been exploited to\nautomatically generate summaries for given code snippets. To achieve a profound\nunderstanding of how far we are from solving this problem, in this paper, we\nconduct a systematic and in-depth analysis of five state-of-the-art neural\nsource code summarization models on three widely used datasets. Our evaluation\nresults suggest that: (1) The BLEU metric, which is widely used by existing\nwork for evaluating the performance of the summarization models, has many\nvariants. Ignoring the differences among the BLEU variants could affect the\nvalidity of the claimed results. Furthermore, we discover an important,\npreviously unknown bug about BLEU calculation in a commonly-used software\npackage. (2) Code pre-processing choices can have a large impact on the\nsummarization performance, therefore they should not be ignored. (3) Some\nimportant characteristics of datasets (corpus size, data splitting method, and\nduplication ratio) have a significant impact on model evaluation. Based on the\nexperimental results, we give some actionable guidelines on more systematic\nways for evaluating code summarization and choosing the best method in\ndifferent scenarios. We also suggest possible future research directions. We\nbelieve that our results can be of great help for practitioners and researchers\nin this interesting area.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 04:33:59 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Shi", "Ensheng", ""], ["Wang", "Yanlin", ""], ["Du", "Lun", ""], ["Chen", "Junjie", ""], ["Han", "Shi", ""], ["Zhang", "Hongyu", ""], ["Zhang", "Dongmei", ""], ["Sun", "Hongbin", ""]]}, {"id": "2107.07113", "submitter": "Zitao Liu", "authors": "Guowei Xu, Wenbiao Ding, Weiping Fu, Zhongqin Wu, Zitao Liu", "title": "Robust Learning for Text Classification with Multi-source Noise\n  Simulation and Hard Example Mining", "comments": "ECML-PKDD'21: The European Conference on Machine Learning and\n  Principles and Practice of Knowledge Discovery in Databases, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world applications involve the use of Optical Character Recognition\n(OCR) engines to transform handwritten images into transcripts on which\ndownstream Natural Language Processing (NLP) models are applied. In this\nprocess, OCR engines may introduce errors and inputs to downstream NLP models\nbecome noisy. Despite that pre-trained models achieve state-of-the-art\nperformance in many NLP benchmarks, we prove that they are not robust to noisy\ntexts generated by real OCR engines. This greatly limits the application of NLP\nmodels in real-world scenarios. In order to improve model performance on noisy\nOCR transcripts, it is natural to train the NLP model on labelled noisy texts.\nHowever, in most cases there are only labelled clean texts. Since there is no\nhandwritten pictures corresponding to the text, it is impossible to directly\nuse the recognition model to obtain noisy labelled data. Human resources can be\nemployed to copy texts and take pictures, but it is extremely expensive\nconsidering the size of data for model training. Consequently, we are\ninterested in making NLP models intrinsically robust to OCR errors in a low\nresource manner. We propose a novel robust training framework which 1) employs\nsimple but effective methods to directly simulate natural OCR noises from clean\ntexts and 2) iteratively mines the hard examples from a large number of\nsimulated samples for optimal performance. 3) To make our model learn\nnoise-invariant representations, a stability loss is employed. Experiments on\nthree real-world datasets show that the proposed framework boosts the\nrobustness of pre-trained models by a large margin. We believe that this work\ncan greatly promote the application of NLP models in actual scenarios, although\nthe algorithm we use is simple and straightforward. We make our codes and three\ndatasets publicly\navailable\\footnote{https://github.com/tal-ai/Robust-learning-MSSHEM}.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 04:39:22 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Xu", "Guowei", ""], ["Ding", "Wenbiao", ""], ["Fu", "Weiping", ""], ["Wu", "Zhongqin", ""], ["Liu", "Zitao", ""]]}, {"id": "2107.07114", "submitter": "Yibo Hu", "authors": "Yibo Hu, Latifur Khan", "title": "Uncertainty-Aware Reliable Text Classification", "comments": "KDD 2021", "journal-ref": null, "doi": "10.1145/3447548.3467382", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks have significantly contributed to the success in\npredictive accuracy for classification tasks. However, they tend to make\nover-confident predictions in real-world settings, where domain shifting and\nout-of-distribution (OOD) examples exist. Most research on uncertainty\nestimation focuses on computer vision because it provides visual validation on\nuncertainty quality. However, few have been presented in the natural language\nprocess domain. Unlike Bayesian methods that indirectly infer uncertainty\nthrough weight uncertainties, current evidential uncertainty-based methods\nexplicitly model the uncertainty of class probabilities through subjective\nopinions. They further consider inherent uncertainty in data with different\nroot causes, vacuity (i.e., uncertainty due to a lack of evidence) and\ndissonance (i.e., uncertainty due to conflicting evidence). In our paper, we\nfirstly apply evidential uncertainty in OOD detection for text classification\ntasks. We propose an inexpensive framework that adopts both auxiliary outliers\nand pseudo off-manifold samples to train the model with prior knowledge of a\ncertain class, which has high vacuity for OOD samples. Extensive empirical\nexperiments demonstrate that our model based on evidential uncertainty\noutperforms other counterparts for detecting OOD examples. Our approach can be\neasily deployed to traditional recurrent neural networks and fine-tuned\npre-trained transformers.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 04:39:55 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Hu", "Yibo", ""], ["Khan", "Latifur", ""]]}, {"id": "2107.07116", "submitter": "Feng Shi", "authors": "Feng Shi, Chonghan Lee, Mohammad Khairul Bashar, Nikhil Shukla,\n  Song-Chun Zhu and Vijaykrishnan Narayanan", "title": "Transformer-based Machine Learning for Fast SAT Solvers and Logic\n  Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CNF-based SAT and MaxSAT solvers are central to logic synthesis and\nverification systems. The increasing popularity of these constraint problems in\nelectronic design automation encourages studies on different SAT problems and\ntheir properties for further computational efficiency. There has been both\ntheoretical and practical success of modern Conflict-driven clause learning SAT\nsolvers, which allows solving very large industrial instances in a relatively\nshort amount of time. Recently, machine learning approaches provide a new\ndimension to solving this challenging problem. Neural symbolic models could\nserve as generic solvers that can be specialized for specific domains based on\ndata without any changes to the structure of the model. In this work, we\npropose a one-shot model derived from the Transformer architecture to solve the\nMaxSAT problem, which is the optimization version of SAT where the goal is to\nsatisfy the maximum number of clauses. Our model has a scale-free structure\nwhich could process varying size of instances. We use meta-path and\nself-attention mechanism to capture interactions among homogeneous nodes. We\nadopt cross-attention mechanisms on the bipartite graph to capture interactions\namong heterogeneous nodes. We further apply an iterative algorithm to our model\nto satisfy additional clauses, enabling a solution approaching that of an\nexact-SAT problem. The attention mechanisms leverage the parallelism for\nspeedup. Our evaluation indicates improved speedup compared to heuristic\napproaches and improved completion rate compared to machine learning\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 04:47:35 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Shi", "Feng", ""], ["Lee", "Chonghan", ""], ["Bashar", "Mohammad Khairul", ""], ["Shukla", "Nikhil", ""], ["Zhu", "Song-Chun", ""], ["Narayanan", "Vijaykrishnan", ""]]}, {"id": "2107.07119", "submitter": "Zitao Liu", "authors": "Yang Hao, Hang Li, Wenbiao Ding, Zhongqin Wu, Jiliang Tang, Rose\n  Luckin, Zitao Liu", "title": "Multi-Task Learning based Online Dialogic Instruction Detection with\n  Pre-trained Language Models", "comments": "AIED'21: The 22nd International Conference on Artificial Intelligence\n  in Education, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study computational approaches to detect online dialogic\ninstructions, which are widely used to help students understand learning\nmaterials, and build effective study habits. This task is rather challenging\ndue to the widely-varying quality and pedagogical styles of dialogic\ninstructions. To address these challenges, we utilize pre-trained language\nmodels, and propose a multi-task paradigm which enhances the ability to\ndistinguish instances of different classes by enlarging the margin between\ncategories via contrastive loss. Furthermore, we design a strategy to fully\nexploit the misclassified examples during the training stage. Extensive\nexperiments on a real-world online educational data set demonstrate that our\napproach achieves superior performance compared to representative baselines. To\nencourage reproducible results, we make our implementation online available at\n\\url{https://github.com/AIED2021/multitask-dialogic-instruction}.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 04:57:57 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Hao", "Yang", ""], ["Li", "Hang", ""], ["Ding", "Wenbiao", ""], ["Wu", "Zhongqin", ""], ["Tang", "Jiliang", ""], ["Luckin", "Rose", ""], ["Liu", "Zitao", ""]]}, {"id": "2107.07122", "submitter": "Zitao Liu", "authors": "Qiongqiong Liu, Tianqiao Liu, Jiafu Zhao, Qiang Fang, Wenbiao Ding,\n  Zhongqin Wu, Feng Xia, Jiliang Tang, Zitao Liu", "title": "Solving ESL Sentence Completion Questions via Pre-trained Neural\n  Language Models", "comments": "AIED'21: The 22nd International Conference on Artificial Intelligence\n  in Education, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence completion (SC) questions present a sentence with one or more blanks\nthat need to be filled in, three to five possible words or phrases as options.\nSC questions are widely used for students learning English as a Second Language\n(ESL) and building computational approaches to automatically solve such\nquestions is beneficial to language learners. In this work, we propose a neural\nframework to solve SC questions in English examinations by utilizing\npre-trained language models. We conduct extensive experiments on a real-world\nK-12 ESL SC question dataset and the results demonstrate the superiority of our\nmodel in terms of prediction accuracy. Furthermore, we run precision-recall\ntrade-off analysis to discuss the practical issues when deploying it in\nreal-life scenarios. To encourage reproducible results, we make our code\npublicly available at \\url{https://github.com/AIED2021/ESL-SentenceCompletion}.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 05:01:39 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Liu", "Qiongqiong", ""], ["Liu", "Tianqiao", ""], ["Zhao", "Jiafu", ""], ["Fang", "Qiang", ""], ["Ding", "Wenbiao", ""], ["Wu", "Zhongqin", ""], ["Xia", "Feng", ""], ["Tang", "Jiliang", ""], ["Liu", "Zitao", ""]]}, {"id": "2107.07124", "submitter": "Zitao Liu", "authors": "Jiahao Chen, Hang Li, Wenbiao Ding, Zitao Liu", "title": "An Educational System for Personalized Teacher Recommendation in K-12\n  Online Classrooms", "comments": "AIED'21: The 22nd International Conference on Artificial Intelligence\n  in Education, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a simple yet effective solution to build practical\nteacher recommender systems for online one-on-one classes. Our system consists\nof (1) a pseudo matching score module that provides reliable training labels;\n(2) a ranking model that scores every candidate teacher; (3) a novelty boosting\nmodule that gives additional opportunities to new teachers; and (4) a diversity\nmetric that guardrails the recommended results to reduce the chance of\ncollision. Offline experimental results show that our approach outperforms a\nwide range of baselines. Furthermore, we show that our approach is able to\nreduce the number of student-teacher matching attempts from 7.22 to 3.09 in a\nfive-month observation on a third-party online education platform.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 05:04:28 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Chen", "Jiahao", ""], ["Li", "Hang", ""], ["Ding", "Wenbiao", ""], ["Liu", "Zitao", ""]]}, {"id": "2107.07136", "submitter": "Mohit Kumar", "authors": "Mohit Kumar, Samuel Kolb, Luc De Raedt and Stefano Teso", "title": "Learning Mixed-Integer Linear Programs from Contextual Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mixed-integer linear programs (MILPs) are widely used in artificial\nintelligence and operations research to model complex decision problems like\nscheduling and routing. Designing such programs however requires both domain\nand modelling expertise. In this paper, we study the problem of acquiring MILPs\nfrom contextual examples, a novel and realistic setting in which examples\ncapture solutions and non-solutions within a specific context. The resulting\nlearning problem involves acquiring continuous parameters -- namely, a cost\nvector and a feasibility polytope -- but has a distinctly combinatorial flavor.\nTo solve this complex problem, we also contribute MISSLE, an algorithm for\nlearning MILPs from contextual examples. MISSLE uses a variant of stochastic\nlocal search that is guided by the gradient of a continuous surrogate loss\nfunction. Our empirical evaluation on synthetic data shows that MISSLE acquires\nbetter MILPs faster than alternatives based on stochastic local search and\ngradient descent.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 05:45:52 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Kumar", "Mohit", ""], ["Kolb", "Samuel", ""], ["De Raedt", "Luc", ""], ["Teso", "Stefano", ""]]}, {"id": "2107.07154", "submitter": "Sangmin Woo", "authors": "Sangmin Woo, Junhyug Noh, Kangil Kim", "title": "What and When to Look?: Temporal Span Proposal Network for Video Visual\n  Relation Detection", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Identifying relations between objects is central to understanding the scene.\nWhile several works have been proposed for relation modeling in the image\ndomain, there have been many constraints in the video domain due to challenging\ndynamics of spatio-temporal interactions (e.g., Between which objects are there\nan interaction? When do relations occur and end?). To date, two representative\nmethods have been proposed to tackle Video Visual Relation Detection (VidVRD):\nsegment-based and window-based. We first point out the limitations these two\nmethods have and propose Temporal Span Proposal Network (TSPN), a novel method\nwith two advantages in terms of efficiency and effectiveness. 1) TSPN tells\nwhat to look: it sparsifies relation search space by scoring relationness\n(i.e., confidence score for the existence of a relation between pair of\nobjects) of object pair. 2) TSPN tells when to look: it leverages the full\nvideo context to simultaneously predict the temporal span and categories of the\nentire relations. TSPN demonstrates its effectiveness by achieving new\nstate-of-the-art by a significant margin on two VidVRD benchmarks\n(ImageNet-VidVDR and VidOR) while also showing lower time complexity than\nexisting methods - in particular, twice as efficient as a popular segment-based\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 07:01:26 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Woo", "Sangmin", ""], ["Noh", "Junhyug", ""], ["Kim", "Kangil", ""]]}, {"id": "2107.07173", "submitter": "Lei Chen", "authors": "Lei Chen, Fajie Yuan, Jiaxi Yang, Min Yang, and Chengming Li", "title": "Scene-adaptive Knowledge Distillation for Sequential Recommendation via\n  Differentiable Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sequential recommender systems (SRS) have become a research hotspot due to\nits power in modeling user dynamic interests and sequential behavioral\npatterns. To maximize model expressive ability, a default choice is to apply a\nlarger and deeper network architecture, which, however, often brings high\nnetwork latency when generating online recommendations. Naturally, we argue\nthat compressing the heavy recommendation models into middle- or light- weight\nneural networks is of great importance for practical production systems. To\nrealize such a goal, we propose AdaRec, a knowledge distillation (KD) framework\nwhich compresses knowledge of a teacher model into a student model adaptively\naccording to its recommendation scene by using differentiable Neural\nArchitecture Search (NAS). Specifically, we introduce a target-oriented\ndistillation loss to guide the structure search process for finding the student\nnetwork architecture, and a cost-sensitive loss as constraints for model size,\nwhich achieves a superior trade-off between recommendation effectiveness and\nefficiency. In addition, we leverage Earth Mover's Distance (EMD) to realize\nmany-to-many layer mapping during knowledge distillation, which enables each\nintermediate student layer to learn from other intermediate teacher layers\nadaptively. Extensive experiments on real-world recommendation datasets\ndemonstrate that our model achieves competitive or better accuracy with notable\ninference speedup comparing to strong counterparts, while discovering diverse\nneural architectures for sequential recommender models under different\nrecommendation scenes.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 07:47:46 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Chen", "Lei", ""], ["Yuan", "Fajie", ""], ["Yang", "Jiaxi", ""], ["Yang", "Min", ""], ["Li", "Chengming", ""]]}, {"id": "2107.07191", "submitter": "Joosoon Lee", "authors": "D. Park, J. Lee, J. Lee and K. Lee", "title": "Deep Learning based Food Instance Segmentation using Synthetic Data", "comments": "Accepted by UR2021(Ubiquitous Robots 2021) conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the process of intelligently segmenting foods in images using deep neural\nnetworks for diet management, data collection and labeling for network training\nare very important but labor-intensive tasks. In order to solve the\ndifficulties of data collection and annotations, this paper proposes a food\nsegmentation method applicable to real-world through synthetic data. To perform\nfood segmentation on healthcare robot systems, such as meal assistance robot\narm, we generate synthetic data using the open-source 3D graphics software\nBlender placing multiple objects on meal plate and train Mask R-CNN for\ninstance segmentation. Also, we build a data collection system and verify our\nsegmentation model on real-world food data. As a result, on our real-world\ndataset, the model trained only synthetic data is available to segment food\ninstances that are not trained with 52.2% mask AP@all, and improve performance\nby +6.4%p after fine-tuning comparing to the model trained from scratch. In\naddition, we also confirm the possibility and performance improvement on the\npublic dataset for fair analysis. Our code and pre-trained weights are\navaliable online at: https://github.com/gist-ailab/Food-Instance-Segmentation\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 08:36:54 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 13:42:37 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Park", "D.", ""], ["Lee", "J.", ""], ["Lee", "J.", ""], ["Lee", "K.", ""]]}, {"id": "2107.07229", "submitter": "Ishan Tarunesh", "authors": "Ishan Tarunesh, Somak Aditya and Monojit Choudhury", "title": "Trusting RoBERTa over BERT: Insights from CheckListing the Natural\n  Language Inference Task", "comments": "15 pages, 5 figures and 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent state-of-the-art natural language understanding (NLU) systems\noften behave unpredictably, failing on simpler reasoning examples. Despite\nthis, there has been limited focus on quantifying progress towards systems with\nmore predictable behavior. We think that reasoning capability-wise behavioral\nsummary is a step towards bridging this gap. We create a CheckList test-suite\n(184K examples) for the Natural Language Inference (NLI) task, a representative\nNLU task. We benchmark state-of-the-art NLI systems on this test-suite, which\nreveals fine-grained insights into the reasoning abilities of BERT and RoBERTa.\nOur analysis further reveals inconsistencies of the models on examples derived\nfrom the same template or distinct templates but pertaining to same reasoning\ncapability, indicating that generalizing the models' behavior through\nobservations made on a CheckList is non-trivial. Through an user-study, we find\nthat users were able to utilize behavioral information to generalize much\nbetter for examples predicted from RoBERTa, compared to that of BERT.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 10:08:18 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Tarunesh", "Ishan", ""], ["Aditya", "Somak", ""], ["Choudhury", "Monojit", ""]]}, {"id": "2107.07233", "submitter": "Sagnik Sarkar", "authors": "Shaashwat Agrawal, Sagnik Sarkar, Mamoun Alazab, Praveen Kumar Reddy\n  Maddikunta, Thippa Reddy Gadekallu and Quoc-Viet Pham", "title": "Genetic CFL: Optimization of Hyper-Parameters in Clustered Federated\n  Learning", "comments": "7 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning (FL) is a distributed model for deep learning that\nintegrates client-server architecture, edge computing, and real-time\nintelligence. FL has the capability of revolutionizing machine learning (ML)\nbut lacks in the practicality of implementation due to technological\nlimitations, communication overhead, non-IID (independent and identically\ndistributed) data, and privacy concerns. Training a ML model over heterogeneous\nnon-IID data highly degrades the convergence rate and performance. The existing\ntraditional and clustered FL algorithms exhibit two main limitations, including\ninefficient client training and static hyper-parameter utilization. To overcome\nthese limitations, we propose a novel hybrid algorithm, namely genetic\nclustered FL (Genetic CFL), that clusters edge devices based on the training\nhyper-parameters and genetically modifies the parameters cluster-wise. Then, we\nintroduce an algorithm that drastically increases the individual cluster\naccuracy by integrating the density-based clustering and genetic\nhyper-parameter optimization. The results are bench-marked using MNIST\nhandwritten digit dataset and the CIFAR-10 dataset. The proposed genetic CFL\nshows significant improvements and works well with realistic cases of non-IID\nand ambiguous data.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 10:16:05 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 13:15:20 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Agrawal", "Shaashwat", ""], ["Sarkar", "Sagnik", ""], ["Alazab", "Mamoun", ""], ["Maddikunta", "Praveen Kumar Reddy", ""], ["Gadekallu", "Thippa Reddy", ""], ["Pham", "Quoc-Viet", ""]]}, {"id": "2107.07235", "submitter": "Jizhizi Li", "authors": "Jizhizi Li, Jing Zhang, Dacheng Tao", "title": "Deep Automatic Natural Image Matting", "comments": "Accepted to IJCAI-21, code and dataset available at\n  https://github.com/JizhiziLi/AIM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic image matting (AIM) refers to estimating the soft foreground from\nan arbitrary natural image without any auxiliary input like trimap, which is\nuseful for image editing. Prior methods try to learn semantic features to aid\nthe matting process while being limited to images with salient opaque\nforegrounds such as humans and animals. In this paper, we investigate the\ndifficulties when extending them to natural images with salient\ntransparent/meticulous foregrounds or non-salient foregrounds. To address the\nproblem, a novel end-to-end matting network is proposed, which can predict a\ngeneralized trimap for any image of the above types as a unified semantic\nrepresentation. Simultaneously, the learned semantic features guide the matting\nnetwork to focus on the transition areas via an attention mechanism. We also\nconstruct a test set AIM-500 that contains 500 diverse natural images covering\nall types along with manually labeled alpha mattes, making it feasible to\nbenchmark the generalization ability of AIM models. Results of the experiments\ndemonstrate that our network trained on available composite matting datasets\noutperforms existing methods both objectively and subjectively. The source code\nand dataset are available at https://github.com/JizhiziLi/AIM.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 10:29:01 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Li", "Jizhizi", ""], ["Zhang", "Jing", ""], ["Tao", "Dacheng", ""]]}, {"id": "2107.07253", "submitter": "Asier Guti\\'errez-Fandi\\~no", "authors": "Asier Guti\\'errez-Fandi\\~no, Jordi Armengol-Estap\\'e, Marc P\\`amies,\n  Joan Llop-Palao, Joaqu\\'in Silveira-Ocampo, Casimiro Pio Carrino, Aitor\n  Gonzalez-Agirre, Carme Armentano-Oller, Carlos Rodriguez-Penagos, Marta\n  Villegas", "title": "Spanish Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents the Spanish RoBERTa-base and RoBERTa-large models, as\nwell as the corresponding performance evaluations. Both models were pre-trained\nusing the largest Spanish corpus known to date, with a total of 570GB of clean\nand deduplicated text processed for this work, compiled from the web crawlings\nperformed by the National Library of Spain from 2009 to 2019.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 11:23:05 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Guti\u00e9rrez-Fandi\u00f1o", "Asier", ""], ["Armengol-Estap\u00e9", "Jordi", ""], ["P\u00e0mies", "Marc", ""], ["Llop-Palao", "Joan", ""], ["Silveira-Ocampo", "Joaqu\u00edn", ""], ["Carrino", "Casimiro Pio", ""], ["Gonzalez-Agirre", "Aitor", ""], ["Armentano-Oller", "Carme", ""], ["Rodriguez-Penagos", "Carlos", ""], ["Villegas", "Marta", ""]]}, {"id": "2107.07316", "submitter": "Danial Kamran", "authors": "Danial Kamran, Tizian Engelgeh, Marvin Busch, Johannes Fischer and\n  Christoph Stiller", "title": "Minimizing Safety Interference for Safe and Comfortable Automated\n  Driving with Distributional Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite recent advances in reinforcement learning (RL), its application in\nsafety critical domains like autonomous vehicles is still challenging. Although\npunishing RL agents for risky situations can help to learn safe policies, it\nmay also lead to highly conservative behavior. In this paper, we propose a\ndistributional RL framework in order to learn adaptive policies that can tune\ntheir level of conservativity at run-time based on the desired comfort and\nutility. Using a proactive safety verification approach, the proposed framework\ncan guarantee that actions generated from RL are fail-safe according to the\nworst-case assumptions. Concurrently, the policy is encouraged to minimize\nsafety interference and generate more comfortable behavior. We trained and\nevaluated the proposed approach and baseline policies using a high level\nsimulator with a variety of randomized scenarios including several corner cases\nwhich rarely happen in reality but are very crucial. In light of our\nexperiments, the behavior of policies learned using distributional RL can be\nadaptive at run-time and robust to the environment uncertainty. Quantitatively,\nthe learned distributional RL agent drives in average 8 seconds faster than the\nnormal DQN policy and requires 83\\% less safety interference compared to the\nrule-based policy with slightly increasing the average crossing time. We also\nstudy sensitivity of the learned policy in environments with higher perception\nnoise and show that our algorithm learns policies that can still drive reliable\nwhen the perception noise is two times higher than the training configuration\nfor automated merging and crossing at occluded intersections.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 13:36:55 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Kamran", "Danial", ""], ["Engelgeh", "Tizian", ""], ["Busch", "Marvin", ""], ["Fischer", "Johannes", ""], ["Stiller", "Christoph", ""]]}, {"id": "2107.07331", "submitter": "Runze Chen", "authors": "Runze Chen and Haiyong Luo and Fang Zhao and Xuechun Meng and Zhiqing\n  Xie and Yida Zhu", "title": "Modeling Accurate Human Activity Recognition for Embedded Devices Using\n  Multi-level Distillation", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activity recognition (HAR) based on IMU sensors is an essential domain\nin ubiquitous computing. Because of the improving trend to deploy artificial\nintelligence into IoT devices or smartphones, more researchers design the HAR\nmodels for embedded devices. We propose a plug-and-play HAR modeling pipeline\nwith multi-level distillation to build deep convolutional HAR models with\nnative support of embedded devices. SMLDist consists of stage distillation,\nmemory distillation, and logits distillation, which covers all the information\nflow of the deep models. Stage distillation constrains the learning direction\nof the intermediate features. Memory distillation teaches the student models\nhow to explain and store the inner relationship between high-dimensional\nfeatures based on Hopfield networks. Logits distillation constructs distilled\nlogits by a smoothed conditional rule to keep the probable distribution and\nimprove the correctness of the soft target. We compare the performance of\naccuracy, F1 macro score, and energy cost on the embedded platform of various\nstate-of-the-art HAR frameworks with a MobileNet V3 model built by SMLDist. The\nproduced model has well balance with robustness, efficiency, and accuracy.\nSMLDist can also compress the models with minor performance loss in an equal\ncompression rate than other state-of-the-art knowledge distillation methods on\nseven public datasets.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 09:01:41 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Chen", "Runze", ""], ["Luo", "Haiyong", ""], ["Zhao", "Fang", ""], ["Meng", "Xuechun", ""], ["Xie", "Zhiqing", ""], ["Zhu", "Yida", ""]]}, {"id": "2107.07335", "submitter": "Hyungju Ahn", "authors": "Hyung-Ju Ahn, Dae-Hyeok Lee, Ji-Hoon Jeong, Seong-Whan Lee", "title": "Towards Natural Brain-Machine Interaction using Endogenous Potentials\n  based on Deep Neural Networks", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-robot collaboration has the potential to maximize the efficiency of the\noperation of autonomous robots. Brain-machine interface (BMI) would be a\ndesirable technology to collaborate with robots since the intention or state of\nusers can be translated from the neural activities. However, the\nelectroencephalogram (EEG), which is one of the most popularly used\nnon-invasive BMI modalities, has low accuracy and a limited degree of freedom\n(DoF) due to a low signal-to-noise ratio. Thus, improving the performance of\nmulti-class EEG classification is crucial to develop more flexible BMI-based\nhuman-robot collaboration. In this study, we investigated the possibility for\ninter-paradigm classification of multiple endogenous BMI paradigms, such as\nmotor imagery (MI), visual imagery (VI), and speech imagery (SI), to enhance\nthe limited DoF while maintaining robust accuracy. We conducted the statistical\nand neurophysiological analyses on MI, VI, and SI and classified three\nparadigms using the proposed temporal information-based neural network (TINN).\nWe confirmed that statistically significant features could be extracted on\ndifferent brain regions when classifying three endogenous paradigms. Moreover,\nour proposed TINN showed the highest accuracy of 0.93 compared to the previous\nmethods for classifying three different types of mental imagery tasks (MI, VI,\nand SI).\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 05:34:15 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Ahn", "Hyung-Ju", ""], ["Lee", "Dae-Hyeok", ""], ["Jeong", "Ji-Hoon", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2107.07341", "submitter": "Rutwik Shah", "authors": "Rutwik Shah, Bruno Astuto, Tyler Gleason, Will Fletcher, Justin\n  Banaga, Kevin Sweetwood, Allen Ye, Rina Patel, Kevin McGill, Thomas Link,\n  Jason Crane, Valentina Pedoia, Sharmila Majumdar", "title": "Leveraging wisdom of the crowds to improve consensus among radiologists\n  by real time, blinded collaborations on a digital swarm platform", "comments": "24 pages, 2 tables, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.DC cs.LG cs.NE cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Radiologists today play a key role in making diagnostic decisions and\nlabeling images for training A.I. algorithms. Low inter-reader reliability\n(IRR) can be seen between experts when interpreting challenging cases. While\nteams-based decisions are known to outperform individual decisions,\ninter-personal biases often creep up in group interactions which limit\nnon-dominant participants from expressing true opinions. To overcome the dual\nproblems of low consensus and inter-personal bias, we explored a solution\nmodeled on biological swarms of bees. Two separate cohorts; three radiologists\nand five radiology residents collaborated on a digital swarm platform in real\ntime and in a blinded fashion, grading meniscal lesions on knee MR exams. These\nconsensus votes were benchmarked against clinical (arthroscopy) and\nradiological (senior-most radiologist) observations. The IRR of the consensus\nvotes was compared to the IRR of the majority and most confident votes of the\ntwo cohorts.The radiologist cohort saw an improvement of 23% in IRR of swarm\nvotes over majority vote. Similar improvement of 23% in IRR in 3-resident swarm\nvotes over majority vote, was observed. The 5-resident swarm had an even higher\nimprovement of 32% in IRR over majority vote. Swarm consensus votes also\nimproved specificity by up to 50%. The swarm consensus votes outperformed\nindividual and majority vote decisions in both the radiologists and resident\ncohorts. The 5-resident swarm had higher IRR than 3-resident swarm indicating\npositive effect of increased swarm size. The attending and resident swarms also\noutperformed predictions from a state-of-the-art A.I. algorithm. Utilizing a\ndigital swarm platform improved agreement and allows participants to express\njudgement free intent, resulting in superior clinical performance and robust\nA.I. training labels.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 06:52:06 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Shah", "Rutwik", ""], ["Astuto", "Bruno", ""], ["Gleason", "Tyler", ""], ["Fletcher", "Will", ""], ["Banaga", "Justin", ""], ["Sweetwood", "Kevin", ""], ["Ye", "Allen", ""], ["Patel", "Rina", ""], ["McGill", "Kevin", ""], ["Link", "Thomas", ""], ["Crane", "Jason", ""], ["Pedoia", "Valentina", ""], ["Majumdar", "Sharmila", ""]]}, {"id": "2107.07344", "submitter": "Nirmalya Thakur", "authors": "Nirmalya Thakur and Chia Y. Han", "title": "Framework for A Personalized Intelligent Assistant to Elderly People for\n  Activities of Daily Living", "comments": "arXiv admin note: text overlap with arXiv:2106.15599", "journal-ref": "International Journal of Recent Trends in Human Computer\n  Interaction (IJHCI), Volume 9, Issue 1, 2019, pp. 1-22", "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing population of elderly people is associated with the need to\nmeet their increasing requirements and to provide solutions that can improve\ntheir quality of life in a smart home. In addition to fear and anxiety towards\ninterfacing with systems; cognitive disabilities, weakened memory, disorganized\nbehavior and even physical limitations are some of the problems that elderly\npeople tend to face with increasing age. The essence of providing\ntechnology-based solutions to address these needs of elderly people and to\ncreate smart and assisted living spaces for the elderly; lies in developing\nsystems that can adapt by addressing their diversity and can augment their\nperformances in the context of their day to day goals. Therefore, this work\nproposes a framework for development of a Personalized Intelligent Assistant to\nhelp elderly people perform Activities of Daily Living (ADLs) in a smart and\nconnected Internet of Things (IoT) based environment. This Personalized\nIntelligent Assistant can analyze different tasks performed by the user and\nrecommend activities by considering their daily routine, current affective\nstate and the underlining user experience. To uphold the efficacy of this\nproposed framework, it has been tested on a couple of datasets for modelling an\naverage user and a specific user respectively. The results presented show that\nthe model achieves a performance accuracy of 73.12% when modelling a specific\nuser, which is considerably higher than its performance while modelling an\naverage user, this upholds the relevance for development and implementation of\nthis proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 17:36:07 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Thakur", "Nirmalya", ""], ["Han", "Chia Y.", ""]]}, {"id": "2107.07349", "submitter": "Saptarshi Bej", "authors": "Saptarshi Bej, Kristian Schultz, Prashant Srivastava, Markus Wolfien,\n  Olaf Wolkenhauer", "title": "A multi-schematic classifier-independent oversampling approach for\n  imbalanced datasets", "comments": "12 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over 85 oversampling algorithms, mostly extensions of the SMOTE algorithm,\nhave been built over the past two decades, to solve the problem of imbalanced\ndatasets. However, it has been evident from previous studies that different\noversampling algorithms have different degrees of efficiency with different\nclassifiers. With numerous algorithms available, it is difficult to decide on\nan oversampling algorithm for a chosen classifier. Here, we overcome this\nproblem with a multi-schematic and classifier-independent oversampling\napproach: ProWRAS(Proximity Weighted Random Affine Shadowsampling). ProWRAS\nintegrates the Localized Random Affine Shadowsampling (LoRAS)algorithm and the\nProximity Weighted Synthetic oversampling (ProWSyn) algorithm. By controlling\nthe variance of the synthetic samples, as well as a proximity-weighted\nclustering system of the minority classdata, the ProWRAS algorithm improves\nperformance, compared to algorithms that generate synthetic samples through\nmodelling high dimensional convex spaces of the minority class. ProWRAS has\nfour oversampling schemes, each of which has its unique way to model the\nvariance of the generated data. Most importantly, the performance of ProWRAS\nwith proper choice of oversampling schemes, is independent of the classifier\nused. We have benchmarked our newly developed ProWRAS algorithm against five\nsate-of-the-art oversampling models and four different classifiers on 20\npublicly available datasets. ProWRAS outperforms other oversampling algorithms\nin a statistically significant way, in terms of both F1-score and Kappa-score.\nMoreover, we have introduced a novel measure for classifier independence\nI-score, and showed quantitatively that ProWRAS performs better, independent of\nthe classifier used. In practice, ProWRAS customizes synthetic sample\ngeneration according to a classifier of choice and thereby reduces benchmarking\nefforts.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 14:03:24 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Bej", "Saptarshi", ""], ["Schultz", "Kristian", ""], ["Srivastava", "Prashant", ""], ["Wolfien", "Markus", ""], ["Wolkenhauer", "Olaf", ""]]}, {"id": "2107.07352", "submitter": "Mike Laszkiewicz", "authors": "Mike Laszkiewicz, Johannes Lederer, Asja Fischer", "title": "Copula-Based Normalizing Flows", "comments": "Accepted for presentation at the ICML 2021 Workshop on Invertible\n  Neural Networks, Normalizing Flows, and Explicit Likelihood Models (INNF+\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Normalizing flows, which learn a distribution by transforming the data to\nsamples from a Gaussian base distribution, have proven powerful density\napproximations. But their expressive power is limited by this choice of the\nbase distribution. We, therefore, propose to generalize the base distribution\nto a more elaborate copula distribution to capture the properties of the target\ndistribution more accurately. In a first empirical analysis, we demonstrate\nthat this replacement can dramatically improve the vanilla normalizing flows in\nterms of flexibility, stability, and effectivity for heavy-tailed data. Our\nresults suggest that the improvements are related to an increased local\nLipschitz-stability of the learned flow.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 14:22:28 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Laszkiewicz", "Mike", ""], ["Lederer", "Johannes", ""], ["Fischer", "Asja", ""]]}, {"id": "2107.07356", "submitter": "Kunal Relia", "authors": "Kunal Relia", "title": "DiRe Committee : Diversity and Representation Constraints in Multiwinner\n  Elections", "comments": "30 pages, 8 figures, 2 tables, 4 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The study of fairness in multiwinner elections focuses on settings where\ncandidates have attributes. However, voters may also be divided into predefined\npopulations under one or more attributes (e.g., \"California\" and \"Illinois\"\npopulations under the \"state\" attribute), which may be same or different from\ncandidate attributes. The models that focus on candidate attributes alone may\nsystematically under-represent smaller voter populations. Hence, we develop a\nmodel, DiRe Committee Winner Determination (DRCWD), which delineates candidate\nand voter attributes to select a committee by specifying diversity and\nrepresentation constraints and a voting rule. We show the generalizability of\nour model, and analyze its computational complexity, inapproximability, and\nparameterized complexity. We develop a heuristic-based algorithm, which finds\nthe winning DiRe committee in under two minutes on 63% of the instances of\nsynthetic datasets and on 100% of instances of real-world datasets. We present\nan empirical analysis of the running time, feasibility, and utility traded-off.\n  Overall, DRCWD motivates that a study of multiwinner elections should\nconsider both its actors, namely candidates and voters, as candidate-specific\n\"fair\" models can unknowingly harm voter populations, and vice versa.\nAdditionally, even when the attributes of candidates and voters coincide, it is\nimportant to treat them separately as having a female candidate on the\ncommittee, for example, is different from having a candidate on the committee\nwho is preferred by the female voters, and who themselves may or may not be\nfemale.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 14:32:56 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Relia", "Kunal", ""]]}, {"id": "2107.07373", "submitter": "Joseph Palermo", "authors": "Joseph Palermo, Johnny Ye, Alok Singh", "title": "A Reinforcement Learning Environment for Mathematical Reasoning via\n  Program Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We convert the DeepMind Mathematics Dataset into a reinforcement learning\nenvironment by interpreting it as a program synthesis problem. Each action\ntaken in the environment adds an operator or an input into a discrete compute\ngraph. Graphs which compute correct answers yield positive reward, enabling the\noptimization of a policy to construct compute graphs conditioned on problem\nstatements. Baseline models are trained using Double DQN on various subsets of\nproblem types, demonstrating the capability to learn to correctly construct\ngraphs despite the challenges of combinatorial explosion and noisy rewards.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 14:55:34 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 02:40:38 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Palermo", "Joseph", ""], ["Ye", "Johnny", ""], ["Singh", "Alok", ""]]}, {"id": "2107.07376", "submitter": "EPTCS", "authors": "Elaine Pimentel (UFRN), Enrico Tassi (Inria)", "title": "Proceedings of the Sixteenth Workshop on Logical Frameworks and\n  Meta-Languages: Theory and Practice", "comments": null, "journal-ref": "EPTCS 337, 2021", "doi": "10.4204/EPTCS.337", "report-no": null, "categories": "cs.LO cs.AI cs.LG cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Logical frameworks and meta-languages form a common substrate for\nrepresenting, implementing and reasoning about a wide variety of deductive\nsystems of interest in logic and computer science. Their design, implementation\nand their use in reasoning tasks, ranging from the correctness of software to\nthe properties of formal systems, have been the focus of considerable research\nover the last two decades. This workshop brings together designers,\nimplementors and practitioners to discuss various aspects impinging on the\nstructure and utility of logical frameworks, including the treatment of\nvariable binding, inductive and co-inductive reasoning techniques and the\nexpressiveness and lucidity of the reasoning process.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 05:19:09 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Pimentel", "Elaine", "", "UFRN"], ["Tassi", "Enrico", "", "Inria"]]}, {"id": "2107.07393", "submitter": "Vijay Keswani", "authors": "Vijay Keswani and L. Elisa Celis", "title": "Auditing for Diversity using Representative Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessing the diversity of a dataset of information associated with people is\ncrucial before using such data for downstream applications. For a given\ndataset, this often involves computing the imbalance or disparity in the\nempirical marginal distribution of a protected attribute (e.g. gender, dialect,\netc.). However, real-world datasets, such as images from Google Search or\ncollections of Twitter posts, often do not have protected attributes labeled.\nConsequently, to derive disparity measures for such datasets, the elements need\nto hand-labeled or crowd-annotated, which are expensive processes.\n  We propose a cost-effective approach to approximate the disparity of a given\nunlabeled dataset, with respect to a protected attribute, using a control set\nof labeled representative examples. Our proposed algorithm uses the pairwise\nsimilarity between elements in the dataset and elements in the control set to\neffectively bootstrap an approximation to the disparity of the dataset.\nImportantly, we show that using a control set whose size is much smaller than\nthe size of the dataset is sufficient to achieve a small approximation error.\nFurther, based on our theoretical framework, we also provide an algorithm to\nconstruct adaptive control sets that achieve smaller approximation errors than\nrandomly chosen control sets. Simulations on two image datasets and one Twitter\ndataset demonstrate the efficacy of our approach (using random and adaptive\ncontrol sets) in auditing the diversity of a wide variety of datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 15:21:17 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Keswani", "Vijay", ""], ["Celis", "L. Elisa", ""]]}, {"id": "2107.07394", "submitter": "Arnaud Fickinger", "authors": "Arnaud Fickinger, Natasha Jaques, Samyak Parajuli, Michael Chang,\n  Nicholas Rhinehart, Glen Berseth, Stuart Russell, Sergey Levine", "title": "Explore and Control with Adversarial Surprise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning (RL) provides a framework for learning goal-directed\npolicies given user-specified rewards. However, since designing rewards often\nrequires substantial engineering effort, we are interested in the problem of\nlearning without rewards, where agents must discover useful behaviors in the\nabsence of task-specific incentives. Intrinsic motivation is a family of\nunsupervised RL techniques which develop general objectives for an RL agent to\noptimize that lead to better exploration or the discovery of skills. In this\npaper, we propose a new unsupervised RL technique based on an adversarial game\nwhich pits two policies against each other to compete over the amount of\nsurprise an RL agent experiences. The policies each take turns controlling the\nagent. The Explore policy maximizes entropy, putting the agent into surprising\nor unfamiliar situations. Then, the Control policy takes over and seeks to\nrecover from those situations by minimizing entropy. The game harnesses the\npower of multi-agent competition to drive the agent to seek out increasingly\nsurprising parts of the environment while learning to gain mastery over them.\nWe show empirically that our method leads to the emergence of complex skills by\nexhibiting clear phase transitions. Furthermore, we show both theoretically\n(via a latent state space coverage argument) and empirically that our method\nhas the potential to be applied to the exploration of stochastic,\npartially-observed environments. We show that Adversarial Surprise learns more\ncomplex behaviors, and explores more effectively than competitive baselines,\noutperforming intrinsic motivation methods based on active inference,\nnovelty-seeking (Random Network Distillation (RND)), and multi-agent\nunsupervised RL (Asymmetric Self-Play (ASP)) in MiniGrid, Atari and VizDoom\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:58:40 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Fickinger", "Arnaud", ""], ["Jaques", "Natasha", ""], ["Parajuli", "Samyak", ""], ["Chang", "Michael", ""], ["Rhinehart", "Nicholas", ""], ["Berseth", "Glen", ""], ["Russell", "Stuart", ""], ["Levine", "Sergey", ""]]}, {"id": "2107.07404", "submitter": "Evi Micha", "authors": "Rupert Freeman, Evi Micha and Nisarg Shah", "title": "Two-Sided Matching Meets Fair Division", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce a new model for two-sided matching which allows us to borrow\npopular fairness notions from the fair division literature such as\nenvy-freeness up to one good and maximin share guarantee. In our model, each\nagent is matched to multiple agents on the other side over whom she has\nadditive preferences. We demand fairness for each side separately, giving rise\nto notions such as double envy-freeness up to one match (DEF1) and double\nmaximin share guarantee (DMMS). We show that (a slight strengthening of) DEF1\ncannot always be achieved, but in the special case where both sides have\nidentical preferences, the round-robin algorithm with a carefully designed\nagent ordering achieves it. In contrast, DMMS cannot be achieved even when both\nsides have identical preferences.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 15:45:17 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Freeman", "Rupert", ""], ["Micha", "Evi", ""], ["Shah", "Nisarg", ""]]}, {"id": "2107.07413", "submitter": "Danial Kamran", "authors": "Danial Kamran, Yu Ren and Martin Lauer", "title": "High-level Decisions from a Safe Maneuver Catalog with Reinforcement\n  Learning for Safe and Cooperative Automated Merging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning (RL) has recently been used for solving challenging\ndecision-making problems in the context of automated driving. However, one of\nthe main drawbacks of the presented RL-based policies is the lack of safety\nguarantees, since they strive to reduce the expected number of collisions but\nstill tolerate them. In this paper, we propose an efficient RL-based\ndecision-making pipeline for safe and cooperative automated driving in merging\nscenarios. The RL agent is able to predict the current situation and provide\nhigh-level decisions, specifying the operation mode of the low level planner\nwhich is responsible for safety. In order to learn a more generic policy, we\npropose a scalable RL architecture for the merging scenario that is not\nsensitive to changes in the environment configurations. According to our\nexperiments, the proposed RL agent can efficiently identify cooperative drivers\nfrom their vehicle state history and generate interactive maneuvers, resulting\nin faster and more comfortable automated driving. At the same time, thanks to\nthe safety constraints inside the planner, all of the maneuvers are collision\nfree and safe.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 15:49:53 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Kamran", "Danial", ""], ["Ren", "Yu", ""], ["Lauer", "Martin", ""]]}, {"id": "2107.07425", "submitter": "Amir Ivry", "authors": "Amir Ivry, Elad Fisher, Roger Alimi, Idan Mosseri, and Kanna Nahir", "title": "Multiclass Permanent Magnets Superstructure for Indoor Localization\n  using Artificial Intelligence", "comments": "Accepted to IEEE Transactions on Magnetics", "journal-ref": "year 2021", "doi": "10.1109/TMAG.2021.3085107", "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphones have become a popular tool for indoor localization and position\nestimation of users. Existing solutions mainly employ Wi-Fi, RFID, and magnetic\nsensing techniques to track movements in crowded venues. These are highly\nsensitive to magnetic clutters and depend on local ambient magnetic fields,\nwhich frequently degrades their performance. Also, these techniques often\nrequire pre-known mapping surveys of the area, or the presence of active\nbeacons, which are not always available. We embed small-volume and large-moment\nmagnets in pre-known locations and arrange them in specific geometric\nconstellations that create magnetic superstructure patterns of supervised\nmagnetic signatures. These signatures constitute an unambiguous magnetic\nenvironment with respect to the moving sensor carrier. The localization\nalgorithm learns the unique patterns of the scattered magnets during training\nand detects them from the ongoing streaming of data during localization. Our\ncontribution is twofold. First, we deploy passive permanent magnets that do not\nrequire a power supply, in contrast to active magnetic transmitters. Second, we\nperform localization based on smartphone motion rather than on static\npositioning of the magnetometer. In our previous study, we considered a single\nsuperstructure pattern. Here, we present an extended version of that algorithm\nfor multi-superstructure localization, which covers a broader localization area\nof the user. Experimental results demonstrate localization accuracy of 95% with\na mean localization error of less than 1m using artificial intelligence.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 09:59:58 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Ivry", "Amir", ""], ["Fisher", "Elad", ""], ["Alimi", "Roger", ""], ["Mosseri", "Idan", ""], ["Nahir", "Kanna", ""]]}, {"id": "2107.07443", "submitter": "Yonatan Carlos Carranza Alarc\\'on YcCa", "authors": "Yonatan Carlos Carranza Alarc\\'on, S\\'ebastien Destercke", "title": "Multi-label Chaining with Imprecise Probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present two different strategies to extend the classical multi-label\nchaining approach to handle imprecise probability estimates. These estimates\nuse convex sets of distributions (or credal sets) in order to describe our\nuncertainty rather than a precise one. The main reasons one could have for\nusing such estimations are (1) to make cautious predictions (or no decision at\nall) when a high uncertainty is detected in the chaining and (2) to make better\nprecise predictions by avoiding biases caused in early decisions in the\nchaining. We adapt both strategies to the case of the naive credal classifier,\nshowing that this adaptations are computationally efficient. Our experimental\nresults on missing labels, which investigate how reliable these predictions are\nin both approaches, indicate that our approaches produce relevant cautiousness\non those hard-to-predict instances where the precise models fail.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 16:43:31 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 19:43:12 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Alarc\u00f3n", "Yonatan Carlos Carranza", ""], ["Destercke", "S\u00e9bastien", ""]]}, {"id": "2107.07452", "submitter": "G C Nandi", "authors": "Priya Shukla, Nilotpal Pramanik, Deepesh Mehta and G.C. Nandi", "title": "GI-NNet \\& RGI-NNet: Development of Robotic Grasp Pose Models, Trainable\n  with Large as well as Limited Labelled Training Datasets, under supervised\n  and semi supervised paradigms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our way of grasping objects is challenging for efficient, intelligent and\noptimal grasp by COBOTs. To streamline the process, here we use deep learning\ntechniques to help robots learn to generate and execute appropriate grasps\nquickly. We developed a Generative Inception Neural Network (GI-NNet) model,\ncapable of generating antipodal robotic grasps on seen as well as unseen\nobjects. It is trained on Cornell Grasping Dataset (CGD) and attained 98.87%\ngrasp pose accuracy for detecting both regular and irregular shaped objects\nfrom RGB-Depth (RGB-D) images while requiring only one third of the network\ntrainable parameters as compared to the existing approaches. However, to attain\nthis level of performance the model requires the entire 90% of the available\nlabelled data of CGD keeping only 10% labelled data for testing which makes it\nvulnerable to poor generalization. Furthermore, getting sufficient and quality\nlabelled dataset is becoming increasingly difficult keeping in pace with the\nrequirement of gigantic networks. To address these issues, we attach our model\nas a decoder with a semi-supervised learning based architecture known as Vector\nQuantized Variational Auto Encoder (VQVAE), which works efficiently when\ntrained both with the available labelled and unlabelled data. The proposed\nmodel, which we name as Representation based GI-NNet (RGI-NNet), has been\ntrained with various splits of label data on CGD with as minimum as 10%\nlabelled dataset together with latent embedding generated from VQVAE up to 50%\nlabelled data with latent embedding obtained from VQVAE. The performance level,\nin terms of grasp pose accuracy of RGI-NNet, varies between 92.13% to 95.6%\nwhich is far better than several existing models trained with only labelled\ndataset. For the performance verification of both GI-NNet and RGI-NNet models,\nwe use Anukul (Baxter) hardware cobot.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 16:55:49 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Shukla", "Priya", ""], ["Pramanik", "Nilotpal", ""], ["Mehta", "Deepesh", ""], ["Nandi", "G. C.", ""]]}, {"id": "2107.07455", "submitter": "Andrey Malinin Dr.", "authors": "Andrey Malinin and Neil Band and Ganshin, Alexander and German\n  Chesnokov and Yarin Gal and Mark J. F. Gales and Alexey Noskov and Andrey\n  Ploskonosov and Liudmila Prokhorenkova and Ivan Provilkov and Vatsal Raina\n  and Vyas Raina and Roginskiy, Denis and Mariya Shmatova and Panos Tigas and\n  Boris Yangel", "title": "Shifts: A Dataset of Real Distributional Shift Across Multiple\n  Large-Scale Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been significant research done on developing methods for improving\nrobustness to distributional shift and uncertainty estimation. In contrast,\nonly limited work has examined developing standard datasets and benchmarks for\nassessing these approaches. Additionally, most work on uncertainty estimation\nand robustness has developed new techniques based on small-scale regression or\nimage classification tasks. However, many tasks of practical interest have\ndifferent modalities, such as tabular data, audio, text, or sensor data, which\noffer significant challenges involving regression and discrete or continuous\nstructured prediction. Thus, given the current state of the field, a\nstandardized large-scale dataset of tasks across a range of modalities affected\nby distributional shifts is necessary. This will enable researchers to\nmeaningfully evaluate the plethora of recently developed uncertainty\nquantification methods, as well as assessment criteria and state-of-the-art\nbaselines. In this work, we propose the \\emph{Shifts Dataset} for evaluation of\nuncertainty estimates and robustness to distributional shift. The dataset,\nwhich has been collected from industrial sources and services, is composed of\nthree tasks, with each corresponding to a particular data modality: tabular\nweather prediction, machine translation, and self-driving car (SDC) vehicle\nmotion prediction. All of these data modalities and tasks are affected by real,\n`in-the-wild' distributional shifts and pose interesting challenges with\nrespect to uncertainty estimation. In this work we provide a description of the\ndataset and baseline results for all tasks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 16:59:34 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 17:39:44 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Malinin", "Andrey", ""], ["Band", "Neil", ""], ["Ganshin", "", ""], ["Alexander", "", ""], ["Chesnokov", "German", ""], ["Gal", "Yarin", ""], ["Gales", "Mark J. F.", ""], ["Noskov", "Alexey", ""], ["Ploskonosov", "Andrey", ""], ["Prokhorenkova", "Liudmila", ""], ["Provilkov", "Ivan", ""], ["Raina", "Vatsal", ""], ["Raina", "Vyas", ""], ["Roginskiy", "", ""], ["Denis", "", ""], ["Shmatova", "Mariya", ""], ["Tigas", "Panos", ""], ["Yangel", "Boris", ""]]}, {"id": "2107.07498", "submitter": "Liang  Xu", "authors": "Liang Xu, Xiaojing Lu, Chenyang Yuan, Xuanwei Zhang, Hu Yuan, Huilin\n  Xu, Guoao Wei, Xiang Pan, Hai Hu", "title": "FewCLUE: A Chinese Few-shot Learning Evaluation Benchmark", "comments": "Work in Progress; 8 pages, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pretrained Language Models (PLMs) have achieved tremendous success in natural\nlanguage understanding tasks. While different learning schemes -- fine-tuning,\nzero-shot and few-shot learning -- have been widely explored and compared for\nlanguages such as English, there is comparatively little work in Chinese to\nfairly and comprehensively evaluate and compare these methods. This work first\nintroduces Chinese Few-shot Learning Evaluation Benchmark (FewCLUE), the first\ncomprehensive small sample evaluation benchmark in Chinese. It includes nine\ntasks, ranging from single-sentence and sentence-pair classification tasks to\nmachine reading comprehension tasks. Given the high variance of the few-shot\nlearning performance, we provide multiple training/validation sets to\nfacilitate a more accurate and stable evaluation of few-shot modeling. An\nunlabeled training set with up to 20,000 additional samples per task is\nprovided, allowing researchers to explore better ways of using unlabeled\nsamples. Next, we implement a set of state-of-the-art (SOTA) few-shot learning\nmethods (including PET, ADAPET, LM-BFF, P-tuning and EFL), and compare their\nperformance with fine-tuning and zero-shot learning schemes on the newly\nconstructed FewCLUE benchmark.Our results show that: 1) all five few-shot\nlearning methods exhibit better performance than fine-tuning or zero-shot\nlearning; 2) among the five methods, PET is the best performing few-shot\nmethod; 3) few-shot learning performance is highly dependent on the specific\ntask. Our benchmark and code are available at\nhttps://github.com/CLUEbenchmark/FewCLUE\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:51:25 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Xu", "Liang", ""], ["Lu", "Xiaojing", ""], ["Yuan", "Chenyang", ""], ["Zhang", "Xuanwei", ""], ["Yuan", "Hu", ""], ["Xu", "Huilin", ""], ["Wei", "Guoao", ""], ["Pan", "Xiang", ""], ["Hu", "Hai", ""]]}, {"id": "2107.07501", "submitter": "Jie Xu", "authors": "Jie Xu, Tao Chen, Lara Zlokapa, Michael Foshey, Wojciech Matusik,\n  Shinjiro Sueda, Pulkit Agrawal", "title": "An End-to-End Differentiable Framework for Contact-Aware Robot Design", "comments": "Robotics: Science and Systems", "journal-ref": null, "doi": "10.15607/RSS.2021.XVII.008", "report-no": null, "categories": "cs.RO cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current dominant paradigm for robotic manipulation involves two separate\nstages: manipulator design and control. Because the robot's morphology and how\nit can be controlled are intimately linked, joint optimization of design and\ncontrol can significantly improve performance. Existing methods for\nco-optimization are limited and fail to explore a rich space of designs. The\nprimary reason is the trade-off between the complexity of designs that is\nnecessary for contact-rich tasks against the practical constraints of\nmanufacturing, optimization, contact handling, etc. We overcome several of\nthese challenges by building an end-to-end differentiable framework for\ncontact-aware robot design. The two key components of this framework are: a\nnovel deformation-based parameterization that allows for the design of\narticulated rigid robots with arbitrary, complex geometry, and a differentiable\nrigid body simulator that can handle contact-rich scenarios and computes\nanalytical gradients for a full spectrum of kinematic and dynamic parameters.\nOn multiple manipulation tasks, our framework outperforms existing methods that\neither only optimize for control or for design using alternate representations\nor co-optimize using gradient-free methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:53:44 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Xu", "Jie", ""], ["Chen", "Tao", ""], ["Zlokapa", "Lara", ""], ["Foshey", "Michael", ""], ["Matusik", "Wojciech", ""], ["Sueda", "Shinjiro", ""], ["Agrawal", "Pulkit", ""]]}, {"id": "2107.07502", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Yiwei Lyu, Xiang Fan, Zetian Wu, Yun Cheng, Jason Wu,\n  Leslie Chen, Peter Wu, Michelle A. Lee, Yuke Zhu, Ruslan Salakhutdinov,\n  Louis-Philippe Morency", "title": "MultiBench: Multiscale Benchmarks for Multimodal Representation Learning", "comments": "Code: https://github.com/pliang279/MultiBench and Website:\n  https://cmu-multicomp-lab.github.io/multibench/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning multimodal representations involves integrating information from\nmultiple heterogeneous sources of data. It is a challenging yet crucial area\nwith numerous real-world applications in multimedia, affective computing,\nrobotics, finance, human-computer interaction, and healthcare. Unfortunately,\nmultimodal research has seen limited resources to study (1) generalization\nacross domains and modalities, (2) complexity during training and inference,\nand (3) robustness to noisy and missing modalities. In order to accelerate\nprogress towards understudied modalities and tasks while ensuring real-world\nrobustness, we release MultiBench, a systematic and unified large-scale\nbenchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6\nresearch areas. MultiBench provides an automated end-to-end machine learning\npipeline that simplifies and standardizes data loading, experimental setup, and\nmodel evaluation. To enable holistic evaluation, MultiBench offers a\ncomprehensive methodology to assess (1) generalization, (2) time and space\ncomplexity, and (3) modality robustness. MultiBench introduces impactful\nchallenges for future research, including scalability to large-scale multimodal\ndatasets and robustness to realistic imperfections. To accompany this\nbenchmark, we also provide a standardized implementation of 20 core approaches\nin multimodal learning. Simply applying methods proposed in different research\nareas can improve the state-of-the-art performance on 9/15 datasets. Therefore,\nMultiBench presents a milestone in unifying disjoint efforts in multimodal\nresearch and paves the way towards a better understanding of the capabilities\nand limitations of multimodal models, all the while ensuring ease of use,\naccessibility, and reproducibility. MultiBench, our standardized code, and\nleaderboards are publicly available, will be regularly updated, and welcomes\ninputs from the community.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:54:36 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Liang", "Paul Pu", ""], ["Lyu", "Yiwei", ""], ["Fan", "Xiang", ""], ["Wu", "Zetian", ""], ["Cheng", "Yun", ""], ["Wu", "Jason", ""], ["Chen", "Leslie", ""], ["Wu", "Peter", ""], ["Lee", "Michelle A.", ""], ["Zhu", "Yuke", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "2107.07511", "submitter": "Anastasios Angelopoulos", "authors": "Anastasios N. Angelopoulos, Stephen Bates", "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free\n  Uncertainty Quantification", "comments": "Blog and tutorial video\n  http://angelopoulos.ai/blog/posts/gentle-intro/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box machine learning learning methods are now routinely used in\nhigh-risk settings, like medical diagnostics, which demand uncertainty\nquantification to avoid consequential model failures. Distribution-free\nuncertainty quantification (distribution-free UQ) is a user-friendly paradigm\nfor creating statistically rigorous confidence intervals/sets for such\npredictions. Critically, the intervals/sets are valid without distributional\nassumptions or model assumptions, with explicit guarantees with finitely many\ndatapoints. Moreover, they adapt to the difficulty of the input; when the input\nexample is difficult, the uncertainty intervals/sets are large, signaling that\nthe model might be wrong. Without much work, one can use distribution-free\nmethods on any underlying algorithm, such as a neural network, to produce\nconfidence sets guaranteed to contain the ground truth with a user-specified\nprobability, such as 90%. Indeed, the methods are easy-to-understand and\ngeneral, applying to many modern prediction problems arising in the fields of\ncomputer vision, natural language processing, deep reinforcement learning, and\nso on. This hands-on introduction is aimed at a reader interested in the\npractical implementation of distribution-free UQ, including conformal\nprediction and related methods, who is not necessarily a statistician. We will\ninclude many explanatory illustrations, examples, and code samples in Python,\nwith PyTorch syntax. The goal is to provide the reader a working understanding\nof distribution-free UQ, allowing them to put confidence intervals on their\nalgorithms, with one self-contained document.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:59:50 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Angelopoulos", "Anastasios N.", ""], ["Bates", "Stephen", ""]]}, {"id": "2107.07566", "submitter": "Jason  Weston", "authors": "Mojtaba Komeili, Kurt Shuster, Jason Weston", "title": "Internet-Augmented Dialogue Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The largest store of continually updating knowledge on our planet can be\naccessed via internet search. In this work we study giving access to this\ninformation to conversational agents. Large language models, even though they\nstore an impressive amount of knowledge within their weights, are known to\nhallucinate facts when generating dialogue (Shuster et al., 2021); moreover,\nthose facts are frozen in time at the point of model training. In contrast, we\npropose an approach that learns to generate an internet search query based on\nthe context, and then conditions on the search results to finally generate a\nresponse, a method that can employ up-to-the-minute relevant information. We\ntrain and evaluate such models on a newly collected dataset of human-human\nconversations whereby one of the speakers is given access to internet search\nduring knowledgedriven discussions in order to ground their responses. We find\nthat search-query based access of the internet in conversation provides\nsuperior performance compared to existing approaches that either use no\naugmentation or FAISS-based retrieval (Lewis et al., 2020).\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 19:00:35 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Komeili", "Mojtaba", ""], ["Shuster", "Kurt", ""], ["Weston", "Jason", ""]]}, {"id": "2107.07567", "submitter": "Jason  Weston", "authors": "Jing Xu, Arthur Szlam, Jason Weston", "title": "Beyond Goldfish Memory: Long-Term Open-Domain Conversation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent improvements in open-domain dialogue models, state of the art\nmodels are trained and evaluated on short conversations with little context. In\ncontrast, the long-term conversation setting has hardly been studied. In this\nwork we collect and release a human-human dataset consisting of multiple chat\nsessions whereby the speaking partners learn about each other's interests and\ndiscuss the things they have learnt from past sessions. We show how existing\nmodels trained on existing datasets perform poorly in this long-term\nconversation setting in both automatic and human evaluations, and we study\nlong-context models that can perform much better. In particular, we find\nretrieval-augmented methods and methods with an ability to summarize and recall\nprevious conversations outperform the standard encoder-decoder architectures\ncurrently considered state of the art.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 19:01:08 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Xu", "Jing", ""], ["Szlam", "Arthur", ""], ["Weston", "Jason", ""]]}, {"id": "2107.07578", "submitter": "Mann Patel", "authors": "Mann Patel", "title": "Real-Time Violence Detection Using CNN-LSTM", "comments": "5 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Violence rates however have been brought down about 57% during the span of\nthe past 4 decades yet it doesn't change the way that the demonstration of\nviolence actually happens, unseen by the law. Violence can be mass controlled\nsometimes by higher authorities, however, to hold everything in line one must\n\"Microgovern\" over each movement occurring in every road of each square. To\naddress the butterfly effects impact in our setting, I made a unique model and\na theorized system to handle the issue utilizing deep learning. The model takes\nthe input of the CCTV video feeds and after drawing inference, recognizes if a\nviolent movement is going on. And hypothesized architecture aims towards\nprobability-driven computation of video feeds and reduces overhead from naively\ncomputing for every CCTV video feeds.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 19:37:41 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Patel", "Mann", ""]]}, {"id": "2107.07579", "submitter": "Rui Li", "authors": "Rui Li, Ondrej Bohdal, Rajesh Mishra, Hyeji Kim, Da Li, Nicholas Lane,\n  Timothy Hospedales", "title": "A Channel Coding Benchmark for Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning provides a popular and effective family of methods for\ndata-efficient learning of new tasks. However, several important issues in\nmeta-learning have proven hard to study thus far. For example, performance\ndegrades in real-world settings where meta-learners must learn from a wide and\npotentially multi-modal distribution of training tasks; and when distribution\nshift exists between meta-train and meta-test task distributions. These issues\nare typically hard to study since the shape of task distributions, and shift\nbetween them are not straightforward to measure or control in standard\nbenchmarks. We propose the channel coding problem as a benchmark for\nmeta-learning. Channel coding is an important practical application where task\ndistributions naturally arise, and fast adaptation to new tasks is practically\nvaluable. We use this benchmark to study several aspects of meta-learning,\nincluding the impact of task distribution breadth and shift, which can be\ncontrolled in the coding problem. Going forward, this benchmark provides a tool\nfor the community to study the capabilities and limitations of meta-learning,\nand to drive research on practically robust and effective meta-learners.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 19:37:43 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Li", "Rui", ""], ["Bohdal", "Ondrej", ""], ["Mishra", "Rajesh", ""], ["Kim", "Hyeji", ""], ["Li", "Da", ""], ["Lane", "Nicholas", ""], ["Hospedales", "Timothy", ""]]}, {"id": "2107.07596", "submitter": "Chen-Chou Lo", "authors": "Chen-Chou Lo and Patrick Vandewalle", "title": "Depth Estimation from Monocular Images and Sparse radar using Deep\n  Ordinal Regression Network", "comments": "Accepted to ICIP2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We integrate sparse radar data into a monocular depth estimation model and\nintroduce a novel preprocessing method for reducing the sparseness and limited\nfield of view provided by radar. We explore the intrinsic error of different\nradar modalities and show our proposed method results in more data points with\nreduced error. We further propose a novel method for estimating dense depth\nmaps from monocular 2D images and sparse radar measurements using deep learning\nbased on the deep ordinal regression network by Fu et al. Radar data are\nintegrated by first converting the sparse 2D points to a height-extended 3D\nmeasurement and then including it into the network using a late fusion\napproach. Experiments are conducted on the nuScenes dataset. Our experiments\ndemonstrate state-of-the-art performance in both day and night scenes.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 20:17:48 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Lo", "Chen-Chou", ""], ["Vandewalle", "Patrick", ""]]}, {"id": "2107.07630", "submitter": "Ho Chit Siu", "authors": "Ho Chit Siu, Jaime D. Pena, Kimberlee C. Chang, Edenna Chen, Yutai\n  Zhou, Victor J. Lopez, Kyle Palko, Ross E. Allen", "title": "Evaluation of Human-AI Teams for Learned and Rule-Based Agents in Hanabi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep reinforcement learning has generated superhuman AI in competitive games\nsuch as Go and StarCraft. Can similar learning techniques create a superior AI\nteammate for human-machine collaborative games? Will humans prefer AI teammates\nthat improve objective team performance or those that improve subjective\nmetrics of trust? In this study, we perform a single-blind evaluation of teams\nof humans and AI agents in the cooperative card game Hanabi, with both\nrule-based and learning-based agents. In addition to the game score, used as an\nobjective metric of the human-AI team performance, we also quantify subjective\nmeasures of the human's perceived performance, teamwork, interpretability,\ntrust, and overall preference of AI teammate. We find that humans have a clear\npreference toward a rule-based AI teammate (SmartBot) over a state-of-the-art\nlearning-based AI teammate (Other-Play) across nearly all subjective metrics,\nand generally view the learning-based agent negatively, despite no statistical\ndifference in the game score. This result has implications for future AI design\nand reinforcement learning benchmarking, highlighting the need to incorporate\nsubjective metrics of human-AI teaming rather than a singular focus on\nobjective task performance.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 22:19:15 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 03:15:47 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Siu", "Ho Chit", ""], ["Pena", "Jaime D.", ""], ["Chang", "Kimberlee C.", ""], ["Chen", "Edenna", ""], ["Zhou", "Yutai", ""], ["Lopez", "Victor J.", ""], ["Palko", "Kyle", ""], ["Allen", "Ross E.", ""]]}, {"id": "2107.07651", "submitter": "Junnan Li Dr", "authors": "Junnan Li, Ramprasaath R. Selvaraju, Akhilesh Deepak Gotmare, Shafiq\n  Joty, Caiming Xiong, Steven Hoi", "title": "Align before Fuse: Vision and Language Representation Learning with\n  Momentum Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large-scale vision and language representation learning has shown promising\nimprovements on various vision-language tasks. Most existing methods employ a\ntransformer-based multimodal encoder to jointly model visual tokens\n(region-based image features) and word tokens. Because the visual tokens and\nword tokens are unaligned, it is challenging for the multimodal encoder to\nlearn image-text interactions. In this paper, we introduce a contrastive loss\nto ALign the image and text representations BEfore Fusing (ALBEF) them through\ncross-modal attention, which enables more grounded vision and language\nrepresentation learning. Unlike most existing methods, our method does not\nrequire bounding box annotations nor high-resolution images. In order to\nimprove learning from noisy web data, we propose momentum distillation, a\nself-training method which learns from pseudo-targets produced by a momentum\nmodel. We provide a theoretical analysis of ALBEF from a mutual information\nmaximization perspective, showing that different training tasks can be\ninterpreted as different ways to generate views for an image-text pair. ALBEF\nachieves state-of-the-art performance on multiple downstream vision-language\ntasks. On image-text retrieval, ALBEF outperforms methods that are pre-trained\non orders of magnitude larger datasets. On VQA and NLVR$^2$, ALBEF achieves\nabsolute improvements of 2.37% and 3.84% compared to the state-of-the-art,\nwhile enjoying faster inference speed. Code and pre-trained models are\navailable at https://github.com/salesforce/ALBEF/.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 00:19:22 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Li", "Junnan", ""], ["Selvaraju", "Ramprasaath R.", ""], ["Gotmare", "Akhilesh Deepak", ""], ["Joty", "Shafiq", ""], ["Xiong", "Caiming", ""], ["Hoi", "Steven", ""]]}, {"id": "2107.07653", "submitter": "Qian Liu", "authors": "Qian Liu and Bei Chen and Jiaqi Guo and Zeqi Lin and Jian-guang Lou", "title": "TAPEX: Table Pre-training via Learning a Neural SQL Executor", "comments": "Work in progress, the project homepage is at\n  https://table-pretraining.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent years pre-trained language models hit a success on modeling natural\nlanguage sentences and (semi-)structured tables. However, existing table\npre-training techniques always suffer from low data quality and low\npre-training efficiency. In this paper, we show that table pre-training can be\nrealized by learning a neural SQL executor over a synthetic corpus, which is\nobtained by automatically synthesizing executable SQL queries. By pre-training\non the synthetic corpus, our approach TAPEX dramatically improves the\nperformance on downstream tasks, boosting existing language models by at most\n19.5%. Meanwhile, TAPEX has remarkably high pre-training efficiency and yields\nstrong results when using a small pre-trained corpus. Experimental results\ndemonstrate that TAPEX outperforms previous table pre-training approaches by a\nlarge margin, and our model achieves new state-of-the-art results on four\nwell-known datasets, including improving the WikiSQL denotation accuracy to\n89.6% (+4.9%), the WikiTableQuestions denotation accuracy to 57.5% (+4.8%), the\nSQA denotation accuracy to 74.5% (+3.5%), and the TabFact accuracy to 84.6%\n(+3.6%). Our work opens the way to reason over structured data by pre-training\non synthetic executable programs.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 00:40:11 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Liu", "Qian", ""], ["Chen", "Bei", ""], ["Guo", "Jiaqi", ""], ["Lin", "Zeqi", ""], ["Lou", "Jian-guang", ""]]}, {"id": "2107.07684", "submitter": "Yasunori Ishii Mr", "authors": "Yasunori Ishii and Takayoshi Yamashita", "title": "CutDepth:Edge-aware Data Augmentation in Depth Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is difficult to collect data on a large scale in a monocular depth\nestimation because the task requires the simultaneous acquisition of RGB images\nand depths. Data augmentation is thus important to this task. However, there\nhas been little research on data augmentation for tasks such as monocular depth\nestimation, where the transformation is performed pixel by pixel. In this\npaper, we propose a data augmentation method, called CutDepth. In CutDepth,\npart of the depth is pasted onto an input image during training. The method\nextends variations data without destroying edge features. Experiments\nobjectively and subjectively show that the proposed method outperforms\nconventional methods of data augmentation. The estimation accuracy is improved\nwith CutDepth even though there are few training data at long distances.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 03:20:49 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Ishii", "Yasunori", ""], ["Yamashita", "Takayoshi", ""]]}, {"id": "2107.07693", "submitter": "Wen-Ji Zhou", "authors": "Yongqing Gao, Guangda Huzhang, Weijie Shen, Yawen Liu, Wen-Ji Zhou,\n  Qing Da, Dan Shen, Yang Yu", "title": "Imitate TheWorld: A Search Engine Simulation Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent E-commerce applications benefit from the growth of deep learning\ntechniques. However, we notice that many works attempt to maximize business\nobjectives by closely matching offline labels which follow the supervised\nlearning paradigm. This results in models obtain high offline performance in\nterms of Area Under Curve (AUC) and Normalized Discounted Cumulative Gain\n(NDCG), but cannot consistently increase the revenue metrics such as purchases\namount of users. Towards the issues, we build a simulated search engine AESim\nthat can properly give feedback by a well-trained discriminator for generated\npages, as a dynamic dataset. Different from previous simulation platforms which\nlose connection with the real world, ours depends on the real data in\nAliExpress Search: we use adversarial learning to generate virtual users and\nuse Generative Adversarial Imitation Learning (GAIL) to capture behavior\npatterns of users. Our experiments also show AESim can better reflect the\nonline performance of ranking models than classic ranking metrics, implying\nAESim can play a surrogate of AliExpress Search and evaluate models without\ngoing online.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 03:55:33 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Gao", "Yongqing", ""], ["Huzhang", "Guangda", ""], ["Shen", "Weijie", ""], ["Liu", "Yawen", ""], ["Zhou", "Wen-Ji", ""], ["Da", "Qing", ""], ["Shen", "Dan", ""], ["Yu", "Yang", ""]]}, {"id": "2107.07696", "submitter": "Long Kiu Chung", "authors": "Long Kiu Chung, Adam Dai, Derek Knowles, Shreyas Kousik, Grace X. Gao", "title": "Constrained Feedforward Neural Network Training via Reachability\n  Analysis", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have recently become popular for a wide variety of uses, but\nhave seen limited application in safety-critical domains such as robotics near\nand around humans. This is because it remains an open challenge to train a\nneural network to obey safety constraints. Most existing safety-related methods\nonly seek to verify that already-trained networks obey constraints, requiring\nalternating training and verification. Instead, this work proposes a\nconstrained method to simultaneously train and verify a feedforward neural\nnetwork with rectified linear unit (ReLU) nonlinearities. Constraints are\nenforced by computing the network's output-space reachable set and ensuring\nthat it does not intersect with unsafe sets; training is achieved by\nformulating a novel collision-check loss function between the reachable set and\nunsafe portions of the output space. The reachable and unsafe sets are\nrepresented by constrained zonotopes, a convex polytope representation that\nenables differentiable collision checking. The proposed method is demonstrated\nsuccessfully on a network with one nonlinearity layer and approximately 50\nparameters.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 04:03:01 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Chung", "Long Kiu", ""], ["Dai", "Adam", ""], ["Knowles", "Derek", ""], ["Kousik", "Shreyas", ""], ["Gao", "Grace X.", ""]]}, {"id": "2107.07702", "submitter": "Fran\\c{c}ois-Xavier Aubet", "authors": "Chris U. Carmona, Fran\\c{c}ois-Xavier Aubet, Valentin Flunkert, Jan\n  Gasthaus", "title": "Neural Contextual Anomaly Detection for Time Series", "comments": "Chris and Fran\\c{c}ois-Xavier contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Neural Contextual Anomaly Detection (NCAD), a framework for\nanomaly detection on time series that scales seamlessly from the unsupervised\nto supervised setting, and is applicable to both univariate and multivariate\ntime series. This is achieved by effectively combining recent developments in\nrepresentation learning for multivariate time series, with techniques for deep\nanomaly detection originally developed for computer vision that we tailor to\nthe time series setting. Our window-based approach facilitates learning the\nboundary between normal and anomalous classes by injecting generic synthetic\nanomalies into the available data. Moreover, our method can effectively take\nadvantage of all the available information, be it as domain knowledge, or as\ntraining labels in the semi-supervised setting. We demonstrate empirically on\nstandard benchmark datasets that our approach obtains a state-of-the-art\nperformance in these settings.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 04:33:53 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Carmona", "Chris U.", ""], ["Aubet", "Fran\u00e7ois-Xavier", ""], ["Flunkert", "Valentin", ""], ["Gasthaus", "Jan", ""]]}, {"id": "2107.07729", "submitter": "Maneet Singh", "authors": "Shivshankar Reddy, Anand Vir Singh Chauhan, Maneet Singh, and Karamjit\n  Singh", "title": "Semi-supervised Learning for Marked Temporal Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal Point Processes (TPPs) are often used to represent the sequence of\nevents ordered as per the time of occurrence. Owing to their flexible nature,\nTPPs have been used to model different scenarios and have shown applicability\nin various real-world applications. While TPPs focus on modeling the event\noccurrence, Marked Temporal Point Process (MTPP) focuses on modeling the\ncategory/class of the event as well (termed as the marker). Research in MTPP\nhas garnered substantial attention over the past few years, with an extensive\nfocus on supervised algorithms. Despite the research focus, limited attention\nhas been given to the challenging problem of developing solutions in\nsemi-supervised settings, where algorithms have access to a mix of labeled and\nunlabeled data. This research proposes a novel algorithm for Semi-supervised\nLearning for Marked Temporal Point Processes (SSL-MTPP) applicable in such\nscenarios. The proposed SSL-MTPP algorithm utilizes a combination of labeled\nand unlabeled data for learning a robust marker prediction model. The proposed\nalgorithm utilizes an RNN-based Encoder-Decoder module for learning effective\nrepresentations of the time sequence. The efficacy of the proposed algorithm\nhas been demonstrated via multiple protocols on the Retweet dataset, where the\nproposed SSL-MTPP demonstrates improved performance in comparison to the\ntraditional supervised learning approach.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 06:59:38 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Reddy", "Shivshankar", ""], ["Chauhan", "Anand Vir Singh", ""], ["Singh", "Maneet", ""], ["Singh", "Karamjit", ""]]}, {"id": "2107.07740", "submitter": "Jinpeng Li", "authors": "Hao Chen, Ming Jin, Zhunan Li, Cunhang Fan, Jinpeng Li and Huiguang He", "title": "MS-MDA: Multisource Marginal Distribution Adaptation for Cross-subject\n  and Cross-session EEG Emotion Recognition", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As an essential element for the diagnosis and rehabilitation of psychiatric\ndisorders, the electroencephalogram (EEG) based emotion recognition has\nachieved significant progress due to its high precision and reliability.\nHowever, one obstacle to practicality lies in the variability between subjects\nand sessions. Although several studies have adopted domain adaptation (DA)\napproaches to tackle this problem, most of them treat multiple EEG data from\ndifferent subjects and sessions together as a single source domain for\ntransfer, which either fails to satisfy the assumption of domain adaptation\nthat the source has a certain marginal distribution, or increases the\ndifficulty of adaptation. We therefore propose the multi-source marginal\ndistribution adaptation (MS-MDA) for EEG emotion recognition, which takes both\ndomain-invariant and domain-specific features into consideration. First, we\nassume that different EEG data share the same low-level features, then we\nconstruct independent branches for multiple EEG data source domains to adopt\none-to-one domain adaptation and extract domain-specific features. Finally, the\ninference is made by multiple branches. We evaluate our method on SEED and\nSEED-IV for recognizing three and four emotions, respectively. Experimental\nresults show that the MS-MDA outperforms the comparison methods and\nstate-of-the-art models in cross-session and cross-subject transfer scenarios\nin our settings. Codes at https://github.com/VoiceBeer/MS-MDA.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 07:19:54 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Chen", "Hao", ""], ["Jin", "Ming", ""], ["Li", "Zhunan", ""], ["Fan", "Cunhang", ""], ["Li", "Jinpeng", ""], ["He", "Huiguang", ""]]}, {"id": "2107.07769", "submitter": "Anton Kolonin Dr.", "authors": "Ali Raheman, Anton Kolonin, Ben Goertzel, Gergely Hegykozi, Ikram\n  Ansari", "title": "Architecture of Automated Crypto-Finance Agent", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the cognitive architecture of an autonomous agent for active\nportfolio management in decentralized finance, involving activities such as\nasset selection, portfolio balancing, liquidity provision, and trading. Partial\nimplementation of the architecture is provided and supplied with preliminary\nresults and conclusions.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 08:57:50 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 13:22:47 GMT"}, {"version": "v3", "created": "Mon, 26 Jul 2021 16:58:23 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Raheman", "Ali", ""], ["Kolonin", "Anton", ""], ["Goertzel", "Ben", ""], ["Hegykozi", "Gergely", ""], ["Ansari", "Ikram", ""]]}, {"id": "2107.07771", "submitter": "Yajing Sun", "authors": "Yajing Sun, Yue Hu, Luxi Xing, Yuqiang Xie, Xiangpeng Wei", "title": "Know Deeper: Knowledge-Conversation Cyclic Utilization Mechanism for\n  Open-domain Dialogue Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  End-to-End intelligent neural dialogue systems suffer from the problems of\ngenerating inconsistent and repetitive responses. Existing dialogue models pay\nattention to unilaterally incorporating personal knowledge into the dialog\nwhile ignoring the fact that incorporating the personality-related conversation\ninformation into personal knowledge taken as the bilateral information flow\nboosts the quality of the subsequent conversation. Besides, it is indispensable\nto control personal knowledge utilization over the conversation level. In this\npaper, we propose a conversation-adaption multi-view persona aware response\ngeneration model that aims at enhancing conversation consistency and\nalleviating the repetition from two folds. First, we consider conversation\nconsistency from multiple views. From the view of the persona profile, we\ndesign a novel interaction module that not only iteratively incorporates\npersonalized knowledge into each turn conversation but also captures the\npersonality-related information from conversation to enhance personalized\nknowledge semantic representation. From the view of speaking style, we\nintroduce the speaking style vector and feed it into the decoder to keep the\nspeaking style consistency. To avoid conversation repetition, we devise a\ncoverage mechanism to keep track of the activation of personal knowledge\nutilization. Experiments on both automatic and human evaluation verify the\nsuperiority of our model over previous models.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 08:59:06 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Sun", "Yajing", ""], ["Hu", "Yue", ""], ["Xing", "Luxi", ""], ["Xie", "Yuqiang", ""], ["Wei", "Xiangpeng", ""]]}, {"id": "2107.07791", "submitter": "Zahra Gharaee", "authors": "Zahra Gharaee and Shreyas Kowshik and Oliver Stromann and Michael\n  Felsberg", "title": "Graph Representation Learning for Road Type Classification", "comments": null, "journal-ref": null, "doi": "10.1016/j.patcog.2021.108174", "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel learning-based approach to graph representations of road\nnetworks employing state-of-the-art graph convolutional neural networks. Our\napproach is applied to realistic road networks of 17 cities from Open Street\nMap. While edge features are crucial to generate descriptive graph\nrepresentations of road networks, graph convolutional networks usually rely on\nnode features only. We show that the highly representative edge features can\nstill be integrated into such networks by applying a line graph transformation.\nWe also propose a method for neighborhood sampling based on a topological\nneighborhood composed of both local and global neighbors. We compare the\nperformance of learning representations using different types of neighborhood\naggregation functions in transductive and inductive tasks and in supervised and\nunsupervised learning. Furthermore, we propose a novel aggregation approach,\nGraph Attention Isomorphism Network, GAIN. Our results show that GAIN\noutperforms state-of-the-art methods on the road type classification problem.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 09:32:58 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Gharaee", "Zahra", ""], ["Kowshik", "Shreyas", ""], ["Stromann", "Oliver", ""], ["Felsberg", "Michael", ""]]}, {"id": "2107.07842", "submitter": "Shivani Choudhary", "authors": "Shivani Choudhary, Tarun Luthra, Ashima Mittal, Rajat Singh", "title": "A Survey of Knowledge Graph Embedding and Their Applications", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge Graph embedding provides a versatile technique for representing\nknowledge. These techniques can be used in a variety of applications such as\ncompletion of knowledge graph to predict missing information, recommender\nsystems, question answering, query expansion, etc. The information embedded in\nKnowledge graph though being structured is challenging to consume in a\nreal-world application. Knowledge graph embedding enables the real-world\napplication to consume information to improve performance. Knowledge graph\nembedding is an active research area. Most of the embedding methods focus on\nstructure-based information. Recent research has extended the boundary to\ninclude text-based information and image-based information in entity embedding.\nEfforts have been made to enhance the representation with context information.\nThis paper introduces growth in the field of KG embedding from simple\ntranslation-based models to enrichment-based models. This paper includes the\nutility of the Knowledge graph in real-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 12:07:53 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Choudhary", "Shivani", ""], ["Luthra", "Tarun", ""], ["Mittal", "Ashima", ""], ["Singh", "Rajat", ""]]}, {"id": "2107.07843", "submitter": "Rafail Ismayilov", "authors": "Rafail Ismayilov, Renato L. G. Cavalcante, S{\\l}awomir Sta\\'nczak", "title": "Deep Learning Based Hybrid Precoding in Dual-Band Communication Systems", "comments": null, "journal-ref": null, "doi": "10.1109/ICASSP39728.2021.9414488", "report-no": null, "categories": "eess.SP cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep learning-based method that uses spatial and temporal\ninformation extracted from the sub-6GHz band to predict/track beams in the\nmillimeter-wave (mmWave) band. In more detail, we consider a dual-band\ncommunication system operating in both the sub-6GHz and mmWave bands. The\nobjective is to maximize the achievable mutual information in the mmWave band\nwith a hybrid analog/digital architecture where analog precoders (RF precoders)\nare taken from a finite codebook. Finding a RF precoder using conventional\nsearch methods incurs large signalling overhead, and the signalling scales with\nthe number of RF chains and the resolution of the phase shifters. To overcome\nthe issue of large signalling overhead in the mmWave band, the proposed method\nexploits the spatiotemporal correlation between sub-6GHz and mmWave bands, and\nit predicts/tracks the RF precoders in the mmWave band from sub-6GHz channel\nmeasurements. The proposed method provides a smaller candidate set so that\nperforming a search over that set significantly reduces the signalling overhead\ncompared with conventional search heuristics. Simulations show that the\nproposed method can provide reasonable achievable rates while significantly\nreducing the signalling overhead.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 12:10:32 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Ismayilov", "Rafail", ""], ["Cavalcante", "Renato L. G.", ""], ["Sta\u0144czak", "S\u0142awomir", ""]]}, {"id": "2107.07844", "submitter": "Mathias Thor", "authors": "Mathias Thor, Poramate Manoonpong", "title": "Versatile modular neural locomotion control with fast learning", "comments": "For supplementary video files see:\n  https://youtube.com/playlist?list=PLKaJNfU8acRCjKphvzqqFE0UNwzJBo5M1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Legged robots have significant potential to operate in highly unstructured\nenvironments. The design of locomotion control is, however, still challenging.\nCurrently, controllers must be either manually designed for specific robots and\ntasks, or automatically designed via machine learning methods that require long\ntraining times and yield large opaque controllers. Drawing inspiration from\nanimal locomotion, we propose a simple yet versatile modular neural control\nstructure with fast learning. The key advantages of our approach are that\nbehavior-specific control modules can be added incrementally to obtain\nincreasingly complex emergent locomotion behaviors, and that neural connections\ninterfacing with existing modules can be quickly and automatically learned. In\na series of experiments, we show how eight modules can be quickly learned and\nadded to a base control module to obtain emergent adaptive behaviors allowing a\nhexapod robot to navigate in complex environments. We also show that modules\ncan be added and removed during operation without affecting the functionality\nof the remaining controller. Finally, the control approach was successfully\ndemonstrated on a physical hexapod robot. Taken together, our study reveals a\nsignificant step towards fast automatic design of versatile neural locomotion\ncontrol for complex robotic systems.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 12:12:28 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Thor", "Mathias", ""], ["Manoonpong", "Poramate", ""]]}, {"id": "2107.07846", "submitter": "Rafail Ismayilov", "authors": "Rafail Ismayilov, Renato L. G. Cavalcante, S{\\l}awomir Sta\\'nczak", "title": "Deep Learning Beam Optimization in Millimeter-Wave Communication Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method that combines fixed point algorithms with a neural\nnetwork to optimize jointly discrete and continuous variables in\nmillimeter-wave communication systems, so that the users' rates are allocated\nfairly in a well-defined sense. In more detail, the discrete variables include\nuser-access point assignments and the beam configurations, while the continuous\nvariables refer to the power allocation. The beam configuration is predicted\nfrom user-related information using a neural network. Given the predicted beam\nconfiguration, a fixed point algorithm allocates power and assigns users to\naccess points so that the users achieve the maximum fraction of their\ninterference-free rates. The proposed method predicts the beam configuration in\na \"one-shot\" manner, which significantly reduces the complexity of the beam\nsearch procedure. Moreover, even if the predicted beam configurations are not\noptimal, the fixed point algorithm still provides the optimal power allocation\nand user-access point assignments for the given beam configuration.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 12:16:37 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Ismayilov", "Rafail", ""], ["Cavalcante", "Renato L. G.", ""], ["Sta\u0144czak", "S\u0142awomir", ""]]}, {"id": "2107.07878", "submitter": "Igor Muniz MSc.", "authors": "I. Muniz, F. H. F. Camargo and A. Marques", "title": "Ranking labs-of-origin for genetically engineered DNA using Metric\n  Learning", "comments": "4 pages, 2 figures, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the constant advancements of genetic engineering, a common concern is to\nbe able to identify the lab-of-origin of genetically engineered DNA sequences.\nFor that reason, AltLabs has hosted the genetic Engineering Attribution\nChallenge to gather many teams to propose new tools to solve this problem. Here\nwe show our proposed method to rank the most likely labs-of-origin and generate\nembeddings for DNA sequences and labs. These embeddings can also perform\nvarious other tasks, like clustering both DNA sequences and labs and using them\nas features for Machine Learning models applied to solve other problems. This\nwork demonstrates that our method outperforms the classic training method for\nthis task while generating other helpful information.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 13:06:47 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Muniz", "I.", ""], ["Camargo", "F. H. F.", ""], ["Marques", "A.", ""]]}, {"id": "2107.07905", "submitter": "Hong-Xing Yu", "authors": "Hong-Xing Yu, Leonidas J. Guibas, Jiajun Wu", "title": "Unsupervised Discovery of Object Radiance Fields", "comments": "Project page: https://kovenyu.com/uorf/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of inferring an object-centric scene representation from\na single image, aiming to derive a representation that explains the image\nformation process, captures the scene's 3D nature, and is learned without\nsupervision. Most existing methods on scene decomposition lack one or more of\nthese characteristics, due to the fundamental challenge in integrating the\ncomplex 3D-to-2D image formation process into powerful inference schemes like\ndeep networks. In this paper, we propose unsupervised discovery of Object\nRadiance Fields (uORF), integrating recent progresses in neural 3D scene\nrepresentations and rendering with deep inference networks for unsupervised 3D\nscene decomposition. Trained on multi-view RGB images without annotations, uORF\nlearns to decompose complex scenes with diverse, textured background from a\nsingle image. We show that uORF performs well on unsupervised 3D scene\nsegmentation, novel view synthesis, and scene editing on three datasets.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 13:53:36 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Yu", "Hong-Xing", ""], ["Guibas", "Leonidas J.", ""], ["Wu", "Jiajun", ""]]}, {"id": "2107.07957", "submitter": "Zitao Liu", "authors": "Shiting Xu, Guowei Xu, Peilei Jia, Wenbiao Ding, Zhongqin Wu, Zitao\n  Liu", "title": "Automatic Task Requirements Writing Evaluation via Machine Reading\n  Comprehension", "comments": "AIED'21: The 22nd International Conference on Artificial Intelligence\n  in Education, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task requirements (TRs) writing is an important question type in Key English\nTest and Preliminary English Test. A TR writing question may include multiple\nrequirements and a high-quality essay must respond to each requirement\nthoroughly and accurately. However, the limited teacher resources prevent\nstudents from getting detailed grading instantly. The majority of existing\nautomatic essay scoring systems focus on giving a holistic score but rarely\nprovide reasons to support it. In this paper, we proposed an end-to-end\nframework based on machine reading comprehension (MRC) to address this problem\nto some extent. The framework not only detects whether an essay responds to a\nrequirement question, but clearly marks where the essay answers the question.\nOur framework consists of three modules: question normalization module, ELECTRA\nbased MRC module and response locating module. We extensively explore\nstate-of-the-art MRC methods. Our approach achieves 0.93 accuracy score and\n0.85 F1 score on a real-world educational dataset. To encourage reproducible\nresults, we make our code publicly available at\n\\url{https://github.com/aied2021TRMRC/AIED_2021_TRMRC_code}.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 05:12:52 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Xu", "Shiting", ""], ["Xu", "Guowei", ""], ["Jia", "Peilei", ""], ["Ding", "Wenbiao", ""], ["Wu", "Zhongqin", ""], ["Liu", "Zitao", ""]]}, {"id": "2107.07958", "submitter": "Zitao Liu", "authors": "Yang Hao, Xiao Zhai, Wenbiao Ding, Zitao Liu", "title": "Temporal-aware Language Representation Learning From Crowdsourced Labels", "comments": "The 59th Annual Meeting of the Association for Computational\n  Linguistics Workshop on Representation Learning for NLP (ACL RepL4NLP 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning effective language representations from crowdsourced labels is\ncrucial for many real-world machine learning tasks. A challenging aspect of\nthis problem is that the quality of crowdsourced labels suffer high intra- and\ninter-observer variability. Since the high-capacity deep neural networks can\neasily memorize all disagreements among crowdsourced labels, directly applying\nexisting supervised language representation learning algorithms may yield\nsuboptimal solutions. In this paper, we propose \\emph{TACMA}, a\n\\underline{t}emporal-\\underline{a}ware language representation learning\nheuristic for \\underline{c}rowdsourced labels with \\underline{m}ultiple\n\\underline{a}nnotators. The proposed approach (1) explicitly models the\nintra-observer variability with attention mechanism; (2) computes and\naggregates per-sample confidence scores from multiple workers to address the\ninter-observer disagreements. The proposed heuristic is extremely easy to\nimplement in around 5 lines of code. The proposed heuristic is evaluated on\nfour synthetic and four real-world data sets. The results show that our\napproach outperforms a wide range of state-of-the-art baselines in terms of\nprediction accuracy and AUC. To encourage the reproducible results, we make our\ncode publicly available at \\url{https://github.com/CrowdsourcingMining/TACMA}.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 05:25:56 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Hao", "Yang", ""], ["Zhai", "Xiao", ""], ["Ding", "Wenbiao", ""], ["Liu", "Zitao", ""]]}, {"id": "2107.07961", "submitter": "Yongxin Zhang", "authors": "Yongxin Zhang, Jiahai Wang, Zizhen Zhang, Yalan Zhou", "title": "MODRL/D-EL: Multiobjective Deep Reinforcement Learning with Evolutionary\n  Learning for Multiobjective Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based heuristics for solving combinatorial optimization problems has\nrecently attracted much academic attention. While most of the existing works\nonly consider the single objective problem with simple constraints, many\nreal-world problems have the multiobjective perspective and contain a rich set\nof constraints. This paper proposes a multiobjective deep reinforcement\nlearning with evolutionary learning algorithm for a typical complex problem\ncalled the multiobjective vehicle routing problem with time windows (MO-VRPTW).\nIn the proposed algorithm, the decomposition strategy is applied to generate\nsubproblems for a set of attention models. The comprehensive context\ninformation is introduced to further enhance the attention models. The\nevolutionary learning is also employed to fine-tune the parameters of the\nmodels. The experimental results on MO-VRPTW instances demonstrate the\nsuperiority of the proposed algorithm over other learning-based and\niterative-based approaches.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 15:22:20 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Zhang", "Yongxin", ""], ["Wang", "Jiahai", ""], ["Zhang", "Zizhen", ""], ["Zhou", "Yalan", ""]]}, {"id": "2107.07964", "submitter": "Bosubabu Sambana", "authors": "Bosubabu Sambana", "title": "Blockchain Technology: Bitcoins, Cryptocurrency and Applications", "comments": "7 Pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Blockchain is a decentralized ledger used to securely exchange digital\ncurrency, perform deals and transactions efficient manner, each user of the\nnetwork has access to the least copy of the encrypted ledger so that they can\nvalidate a new transaction. The blockchain ledger is a collection of all\nBitcoin transactions executed in the past. Basically, it's distributed database\nthat maintains continuously growing tamper-proof data structure blocks that\nholds batches of individual transactions. The completed blocks are added in a\nlinear and chronological order. Each block contains a timestamp and information\nlink which points to a previous block. Bitcoin is a peer-to-peer permissionless\nnetwork that allows every user to connect to the network and send new\ntransactions to verify and create new blocks. Satoshi Nakamoto described the\ndesign of Bitcoin digital currency in his research paper posted to a\ncryptography listserv 2008. Nakamoto's suggestion has solved the long-pending\nproblem of cryptography and laid the foundation stone for digital currency.\nThis paper explains the concept of bitcoin, its characteristics, the need for\nBlockchain, and how Bitcoin works. It attempts to highlight the role of\nBlockchain in shaping the future of banking , financial services, and the\nadoption of the Internet of Thinks and future Technologies.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 15:27:04 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Sambana", "Bosubabu", ""]]}, {"id": "2107.07999", "submitter": "Han Lin", "authors": "Krzysztof Choromanski, Han Lin, Haoxian Chen, Jack Parker-Holder", "title": "Graph Kernel Attention Transformers", "comments": "18 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new class of graph neural networks (GNNs), by combining\nseveral concepts that were so far studied independently - graph kernels,\nattention-based networks with structural priors and more recently, efficient\nTransformers architectures applying small memory footprint implicit attention\nmethods via low rank decomposition techniques. The goal of the paper is\ntwofold. Proposed by us Graph Kernel Attention Transformers (or GKATs) are much\nmore expressive than SOTA GNNs as capable of modeling longer-range dependencies\nwithin a single layer. Consequently, they can use more shallow architecture\ndesign. Furthermore, GKAT attention layers scale linearly rather than\nquadratically in the number of nodes of the input graphs, even when those\ngraphs are dense, requiring less compute than their regular graph attention\ncounterparts. They achieve it by applying new classes of graph kernels\nadmitting random feature map decomposition via random walks on graphs. As a\nbyproduct of the introduced techniques, we obtain a new class of learnable\ngraph sketches, called graphots, compactly encoding topological graph\nproperties as well as nodes' features. We conducted exhaustive empirical\ncomparison of our method with nine different GNN classes on tasks ranging from\nmotif detection through social network classification to bioinformatics\nchallenges, showing consistent gains coming from GKATs.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 16:39:10 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Choromanski", "Krzysztof", ""], ["Lin", "Han", ""], ["Chen", "Haoxian", ""], ["Parker-Holder", "Jack", ""]]}, {"id": "2107.08030", "submitter": "Adrien Brilhault", "authors": "Adrien Brilhault, Sergio Neuenschwander, Ricardo Araujo Rios", "title": "A New Robust Multivariate Mode Estimator for Eye-tracking Calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose in this work a new method for estimating the main mode of\nmultivariate distributions, with application to eye-tracking calibrations. When\nperforming eye-tracking experiments with poorly cooperative subjects, such as\ninfants or monkeys, the calibration data generally suffer from high\ncontamination. Outliers are typically organized in clusters, corresponding to\nthe time intervals when subjects were not looking at the calibration points. In\nthis type of multimodal distributions, most central tendency measures fail at\nestimating the principal fixation coordinates (the first mode), resulting in\nerrors and inaccuracies when mapping the gaze to the screen coordinates. Here,\nwe developed a new algorithm to identify the first mode of multivariate\ndistributions, named BRIL, which rely on recursive depth-based filtering. This\nnovel approach was tested on artificial mixtures of Gaussian and Uniform\ndistributions, and compared to existing methods (conventional depth medians,\nrobust estimators of location and scatter, and clustering-based approaches). We\nobtained outstanding performances, even for distributions containing very high\nproportions of outliers, both grouped in clusters and randomly distributed.\nFinally, we demonstrate the strength of our method in a real-world scenario\nusing experimental data from eye-tracking calibrations with Capuchin monkeys,\nespecially for distributions where other algorithms typically lack accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 17:45:19 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Brilhault", "Adrien", ""], ["Neuenschwander", "Sergio", ""], ["Rios", "Ricardo Araujo", ""]]}, {"id": "2107.08045", "submitter": "Carlos Mougan", "authors": "Carlos Mougan Navarro, Georgios Kanellos, Thomas Gottron", "title": "Desiderata for Explainable AI in statistical production systems of the\n  European Central Bank", "comments": "Submitted for review at European Congress of Machine Learning\n  (ECMLPKDD) - 2ND Worksho on bias and fairness in AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable AI constitutes a fundamental step towards establishing fairness\nand addressing bias in algorithmic decision-making. Despite the large body of\nwork on the topic, the benefit of solutions is mostly evaluated from a\nconceptual or theoretical point of view and the usefulness for real-world use\ncases remains uncertain. In this work, we aim to state clear user-centric\ndesiderata for explainable AI reflecting common explainability needs\nexperienced in statistical production systems of the European Central Bank. We\nlink the desiderata to archetypical user roles and give examples of techniques\nand methods which can be used to address the user's needs. To this end, we\nprovide two concrete use cases from the domain of statistical data production\nin central banks: the detection of outliers in the Centralised Securities\nDatabase and the data-driven identification of data quality checks for the\nSupervisory Banking data system.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 05:58:11 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Navarro", "Carlos Mougan", ""], ["Kanellos", "Georgios", ""], ["Gottron", "Thomas", ""]]}, {"id": "2107.08067", "submitter": "Bao Thach", "authors": "Bao Thach, Alan Kuntz, Tucker Hermans", "title": "DeformerNet: A Deep Learning Approach to 3D Deformable Object\n  Manipulation", "comments": "Published at RSS 2021 Workshop on Deformable Object Simulation in\n  Robotics; received Honorable Mention for Best Paper Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we propose a novel approach to 3D deformable object\nmanipulation leveraging a deep neural network called DeformerNet. Controlling\nthe shape of a 3D object requires an effective state representation that can\ncapture the full 3D geometry of the object. Current methods work around this\nproblem by defining a set of feature points on the object or only deforming the\nobject in 2D image space, which does not truly address the 3D shape control\nproblem. Instead, we explicitly use 3D point clouds as the state representation\nand apply Convolutional Neural Network on point clouds to learn the 3D\nfeatures. These features are then mapped to the robot end-effector's position\nusing a fully-connected neural network. Once trained in an end-to-end fashion,\nDeformerNet directly maps the current point cloud of a deformable object, as\nwell as a target point cloud shape, to the desired displacement in robot\ngripper position. In addition, we investigate the problem of predicting the\nmanipulation point location given the initial and goal shape of the object.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 18:20:58 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Thach", "Bao", ""], ["Kuntz", "Alan", ""], ["Hermans", "Tucker", ""]]}, {"id": "2107.08068", "submitter": "Mark Gluzman", "authors": "J. G. Dai and Mark Gluzman", "title": "Refined Policy Improvement Bounds for MDPs", "comments": "Workshop on Reinforcement Learning Theory, ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The policy improvement bound on the difference of the discounted returns\nplays a crucial role in the theoretical justification of the trust-region\npolicy optimization (TRPO) algorithm. The existing bound leads to a degenerate\nbound when the discount factor approaches one, making the applicability of TRPO\nand related algorithms questionable when the discount factor is close to one.\nWe refine the results in \\cite{Schulman2015, Achiam2017} and propose a novel\nbound that is \"continuous\" in the discount factor. In particular, our bound is\napplicable for MDPs with the long-run average rewards as well.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 18:22:30 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Dai", "J. G.", ""], ["Gluzman", "Mark", ""]]}, {"id": "2107.08074", "submitter": "Jorge Guevara", "authors": "Jorge Guevara, Dario Borges, Campbell Watson, Bianca Zadrozny", "title": "A comparative study of stochastic and deep generative models for\n  multisite precipitation synthesis", "comments": "ICML 2021 Workshop Tackling Climate Change with Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future climate change scenarios are usually hypothesized using simulations\nfrom weather generators. However, there only a few works comparing and\nevaluating promising deep learning models for weather generation against\nclassical approaches. This study shows preliminary results making such\nevaluations for the multisite precipitation synthesis task. We compared two\nopen-source weather generators: IBMWeathergen (an extension of the Weathergen\nlibrary) and RGeneratePrec, and two deep generative models: GAN and VAE, on a\nvariety of metrics. Our preliminary results can serve as a guide for improving\nthe design of deep learning architectures and algorithms for the multisite\nprecipitation synthesis task.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 18:35:24 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Guevara", "Jorge", ""], ["Borges", "Dario", ""], ["Watson", "Campbell", ""], ["Zadrozny", "Bianca", ""]]}, {"id": "2107.08122", "submitter": "Gordana Dodig Crnkovic", "authors": "Gordana Dodig-Crnkovic, Tobias Holstein, Patrizio Pelliccione", "title": "Future Intelligent Autonomous Robots, Ethical by Design. Learning from\n  Autonomous Cars Ethics", "comments": "11 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of the intelligent autonomous robot technology presupposes its\nanticipated beneficial effect on the individuals and societies. In the case of\nsuch disruptive emergent technology, not only questions of how to build, but\nalso why to build and with what consequences are important. The field of ethics\nof intelligent autonomous robotic cars is a good example of research with\nactionable practical value, where a variety of stakeholders, including the\nlegal system and other societal and governmental actors, as well as companies\nand businesses, collaborate bringing about shared view of ethics and societal\naspects of technology. It could be used as a starting platform for the\napproaches to the development of intelligent autonomous robots in general,\nconsidering human-machine interfaces in different phases of the life cycle of\ntechnology - the development, implementation, testing, use and disposal.\nDrawing from our work on ethics of autonomous intelligent robocars, and the\nexisting literature on ethics of robotics, our contribution consists of a set\nof values and ethical principles with identified challenges and proposed\napproaches for meeting them. This may help stakeholders in the field of\nintelligent autonomous robotics to connect ethical principles with their\napplications. Our recommendations of ethical requirements for autonomous cars\ncan be used for other types of intelligent autonomous robots, with the caveat\nfor social robots that require more research regarding interactions with the\nusers. We emphasize that existing ethical frameworks need to be applied in a\ncontext-sensitive way, by assessments in interdisciplinary, multi-competent\nteams through multi-criteria analysis. Furthermore, we argue for the need of a\ncontinuous development of ethical principles, guidelines, and regulations,\ninformed by the progress of technologies and involving relevant stakeholders.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 21:10:04 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Dodig-Crnkovic", "Gordana", ""], ["Holstein", "Tobias", ""], ["Pelliccione", "Patrizio", ""]]}, {"id": "2107.08124", "submitter": "Oskar Wysocki", "authors": "Oskar Wysocki, Malina Florea, Donal Landers and Andre Freitas", "title": "Architectures of Meaning, A Systematic Corpus Analysis of NLP Systems", "comments": "20 pages, 6 figures, 9 supplementary figures, Lexicon.txt in the\n  appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a novel statistical corpus analysis framework targeted\ntowards the interpretation of Natural Language Processing (NLP) architectural\npatterns at scale. The proposed approach combines saturation-based lexicon\nconstruction, statistical corpus analysis methods and graph collocations to\ninduce a synthesis representation of NLP architectural patterns from corpora.\nThe framework is validated in the full corpus of Semeval tasks and demonstrated\ncoherent architectural patterns which can be used to answer architectural\nquestions on a data-driven fashion, providing a systematic mechanism to\ninterpret a largely dynamic and exponentially growing field.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 21:10:43 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Wysocki", "Oskar", ""], ["Florea", "Malina", ""], ["Landers", "Donal", ""], ["Freitas", "Andre", ""]]}, {"id": "2107.08142", "submitter": "Peter Ondruska", "authors": "Ashesh Jain, Luca Del Pero, Hugo Grimmett, Peter Ondruska", "title": "Autonomy 2.0: Why is self-driving always 5 years away?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the numerous successes of machine learning over the past decade\n(image recognition, decision-making, NLP, image synthesis), self-driving\ntechnology has not yet followed the same trend. In this paper, we study the\nhistory, composition, and development bottlenecks of the modern self-driving\nstack. We argue that the slow progress is caused by approaches that require too\nmuch hand-engineering, an over-reliance on road testing, and high fleet\ndeployment costs. We observe that the classical stack has several bottlenecks\nthat preclude the necessary scale needed to capture the long tail of rare\nevents. To resolve these problems, we outline the principles of Autonomy 2.0,\nan ML-first approach to self-driving, as a viable alternative to the currently\nadopted state-of-the-art. This approach is based on (i) a fully differentiable\nAV stack trainable from human demonstrations, (ii) closed-loop data-driven\nreactive simulation, and (iii) large-scale, low-cost data collections as\ncritical solutions towards scalability issues. We outline the general\narchitecture, survey promising works in this direction and propose key\nchallenges to be addressed by the community in the future.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 23:20:26 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 22:51:45 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Jain", "Ashesh", ""], ["Del Pero", "Luca", ""], ["Grimmett", "Hugo", ""], ["Ondruska", "Peter", ""]]}, {"id": "2107.08148", "submitter": "Piero Molino", "authors": "Piero Molino and Christopher R\\'e", "title": "Declarative Machine Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years machine learning (ML) has moved from a academic endeavor to\na pervasive technology adopted in almost every aspect of computing. ML-powered\nproducts are now embedded in our digital lives: from recommendations of what to\nwatch, to divining our search intent, to powering virtual assistants in\nconsumer and enterprise settings. Recent successes in applying ML in natural\nsciences revealed that ML can be used to tackle some of the hardest real-world\nproblems humanity faces today. For these reasons ML has become central in the\nstrategy of tech companies and has gathered even more attention from academia\nthan ever before. Despite these successes, what we have witnessed so far is\njust the beginning. Right now the people training and using ML models are\nexpert developers working within large organizations, but we believe the next\nwave of ML systems will allow a larger amount of people, potentially without\ncoding skills, to perform the same tasks. These new ML systems will not require\nusers to fully understand all the details of how models are trained and\nutilized for obtaining predictions. Declarative interfaces are well suited for\nthis goal, by hiding complexity and favouring separation of interests, and can\nlead to increased productivity. We worked on such abstract interfaces by\ndeveloping two declarative ML systems, Overton and Ludwig, that require users\nto declare only their data schema (names and types of inputs) and tasks rather\nthen writing low level ML code. In this article we will describe how ML systems\nare currently structured, highlight important factors for their success and\nadoption, what are the issues current ML systems are facing and how the systems\nwe developed addressed them. Finally we will talk about learnings from the\ndevelopment of ML systems throughout the years and how we believe the next\ngeneration of ML systems will look like.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 23:57:57 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Molino", "Piero", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2107.08170", "submitter": "Aleksei Petrenko", "authors": "Aleksei Petrenko, Erik Wijmans, Brennan Shacklett, Vladlen Koltun", "title": "Megaverse: Simulating Embodied Agents at One Million Experiences per\n  Second", "comments": "Paper published in ICML2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Megaverse, a new 3D simulation platform for reinforcement learning\nand embodied AI research. The efficient design of our engine enables\nphysics-based simulation with high-dimensional egocentric observations at more\nthan 1,000,000 actions per second on a single 8-GPU node. Megaverse is up to\n70x faster than DeepMind Lab in fully-shaded 3D scenes with interactive\nobjects. We achieve this high simulation performance by leveraging batched\nsimulation, thereby taking full advantage of the massive parallelism of modern\nGPUs. We use Megaverse to build a new benchmark that consists of several\nsingle-agent and multi-agent tasks covering a variety of cognitive challenges.\nWe evaluate model-free RL on this benchmark to provide baselines and facilitate\nfuture research. The source code is available at https://www.megaverse.info\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 03:16:25 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 03:17:43 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Petrenko", "Aleksei", ""], ["Wijmans", "Erik", ""], ["Shacklett", "Brennan", ""], ["Koltun", "Vladlen", ""]]}, {"id": "2107.08176", "submitter": "Peixin Zhang", "authors": "Peixin Zhang, Jingyi Wang, Jun Sun, Xinyu Wang, Guoliang Dong, Xingen\n  Wang, Ting Dai, Jin Song Dong", "title": "Automatic Fairness Testing of Neural Classifiers through Adversarial\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning has demonstrated astonishing performance in many\napplications, there are still concerns about its dependability. One desirable\nproperty of deep learning applications with societal impact is fairness (i.e.,\nnon-discrimination). Unfortunately, discrimination might be intrinsically\nembedded into the models due to the discrimination in the training data. As a\ncountermeasure, fairness testing systemically identifies discriminatory\nsamples, which can be used to retrain the model and improve the model's\nfairness. Existing fairness testing approaches however have two major\nlimitations. Firstly, they only work well on traditional machine learning\nmodels and have poor performance (e.g., effectiveness and efficiency) on deep\nlearning models. Secondly, they only work on simple structured (e.g., tabular)\ndata and are not applicable for domains such as text. In this work, we bridge\nthe gap by proposing a scalable and effective approach for systematically\nsearching for discriminatory samples while extending existing fairness testing\napproaches to address a more challenging domain, i.e., text classification.\nCompared with state-of-the-art methods, our approach only employs lightweight\nprocedures like gradient computation and clustering, which is significantly\nmore scalable and effective. Experimental results show that on average, our\napproach explores the search space much more effectively (9.62 and 2.38 times\nmore than the state-of-the-art methods respectively on tabular and text\ndatasets) and generates much more discriminatory samples (24.95 and 2.68 times)\nwithin a same reasonable time. Moreover, the retrained models reduce\ndiscrimination by 57.2% and 60.2% respectively on average.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 03:47:08 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 05:09:52 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Zhang", "Peixin", ""], ["Wang", "Jingyi", ""], ["Sun", "Jun", ""], ["Wang", "Xinyu", ""], ["Dong", "Guoliang", ""], ["Wang", "Xingen", ""], ["Dai", "Ting", ""], ["Dong", "Jin Song", ""]]}, {"id": "2107.08194", "submitter": "Abhishek Dandekar", "authors": "Abhishek Dandekar", "title": "Towards autonomic orchestration of machine learning pipelines in future\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning (ML) techniques are being increasingly used in mobile\nnetworks for network planning, operation, management, optimisation and much\nmore. These techniques are realised using a set of logical nodes known as ML\npipeline. A single network operator might have thousands of such ML pipelines\ndistributed across its network. These pipelines need to be managed and\norchestrated across network domains. Thus it is essential to have autonomic\nmulti-domain orchestration of ML pipelines in mobile networks. International\nTelecommunications Union (ITU) has provided an architectural framework for\nmanagement and orchestration of ML pipelines in future networks. We extend this\nframework to enable autonomic orchestration of ML pipelines across multiple\nnetwork domains. We present our system architecture and describe its\napplication using a smart factory use case. Our work allows autonomic\norchestration of multi-domain ML pipelines in a standardised, technology\nagnostic, privacy preserving fashion.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 06:52:48 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Dandekar", "Abhishek", ""]]}, {"id": "2107.08241", "submitter": "Aske Plaat", "authors": "Aske Plaat and Walter Kosters and Mike Preuss", "title": "High-Accuracy Model-Based Reinforcement Learning, a Survey", "comments": "arXiv admin note: text overlap with arXiv:2008.05598", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep reinforcement learning has shown remarkable success in the past few\nyears. Highly complex sequential decision making problems from game playing and\nrobotics have been solved with deep model-free methods. Unfortunately, the\nsample complexity of model-free methods is often high. To reduce the number of\nenvironment samples, model-based reinforcement learning creates an explicit\nmodel of the environment dynamics. Achieving high model accuracy is a challenge\nin high-dimensional problems. In recent years, a diverse landscape of\nmodel-based methods has been introduced to improve model accuracy, using\nmethods such as uncertainty modeling, model-predictive control, latent models,\nand end-to-end learning and planning. Some of these methods succeed in\nachieving high accuracy at low sample complexity, most do so either in a\nrobotics or in a games context. In this paper, we survey these methods; we\nexplain in detail how they work and what their strengths and weaknesses are. We\nconclude with a research agenda for future work to make the methods more robust\nand more widely applicable to other applications.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 14:01:05 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Plaat", "Aske", ""], ["Kosters", "Walter", ""], ["Preuss", "Mike", ""]]}, {"id": "2107.08249", "submitter": "Jie Luo", "authors": "Jie Luo, Jakub M. Tomczak, Agoston E. Eiben", "title": "The Effects of Learning in Morphologically Evolving Robot Systems", "comments": "9 pages, 11 figures, IEEE SSCI conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When controllers (brains) and morphologies (bodies) of robots simultaneously\nevolve, this can lead to a problem, namely the brain & body mismatch problem.\nIn this research, we propose a solution of lifetime learning. We set up a\nsystem where modular robots can create offspring that inherit the bodies of\nparents by recombination and mutation. With regards to the brains of the\noffspring, we use two methods to create them. The first one entails solely\nevolution which means the brain of a robot child is inherited from its parents.\nThe second approach is evolution plus learning which means the brain of a child\nis inherited as well, but additionally is developed by a learning algorithm -\nRevDEknn. We compare these two methods by running experiments in a simulator\ncalled Revolve and use efficiency, efficacy, and the morphology intelligence of\nthe robots for the comparison. The experiments show that the evolution plus\nlearning method does not only lead to a higher fitness level, but also to more\nmorphologically evolving robots. This constitutes a quantitative demonstration\nthat changes in the brain can induce changes in the body, leading to the\nconcept of morphological intelligence, which is quantified by the learning\ndelta, meaning the ability of a morphology to facilitate learning.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 14:38:26 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Luo", "Jie", ""], ["Tomczak", "Jakub M.", ""], ["Eiben", "Agoston E.", ""]]}, {"id": "2107.08252", "submitter": "Yuliya Lierler", "authors": "Yuliya Lierler", "title": "Constraint Answer Set Programming: Integrational and Translational (or\n  SMT-based) Approaches", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Constraint answer set programming or CASP, for short, is a hybrid approach in\nautomated reasoning putting together the advances of distinct research areas\nsuch as answer set programming, constraint processing, and satisfiability\nmodulo theories. Constraint answer set programming demonstrates promising\nresults, including the development of a multitude of solvers: acsolver,\nclingcon, ezcsp, idp, inca, dingo, mingo, aspmt, clingo[l,dl], and ezsmt. It\nopens new horizons for declarative programming applications such as solving\ncomplex train scheduling problems. Systems designed to find solutions to\nconstraint answer set programs can be grouped according to their construction\ninto, what we call, integrational or translational approaches. The focus of\nthis paper is an overview of the key ingredients of the design of constraint\nanswer set solvers drawing distinctions and parallels between integrational and\ntranslational approaches. The paper also provides a glimpse at the kind of\nprograms its users develop by utilizing a CASP encoding of Travelling Salesman\nproblem for illustration. In addition, we place the CASP technology on the map\namong its automated reasoning peers as well as discuss future possibilities for\nthe development of CASP.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 14:58:57 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Lierler", "Yuliya", ""]]}, {"id": "2107.08262", "submitter": "Wenshuo Wang", "authors": "Wenshuo Wang, Chen Wu, Liang Cheng, Yang Zhang", "title": "Tea: Program Repair Using Neural Network Based on Program Information\n  Attention Matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advance in machine learning (ML)-driven natural language process (NLP)\npoints a promising direction for automatic bug fixing for software programs, as\nfixing a buggy program can be transformed to a translation task. While software\nprograms contain much richer information than one-dimensional natural language\ndocuments, pioneering work on using ML-driven NLP techniques for automatic\nprogram repair only considered a limited set of such information. We\nhypothesize that more comprehensive information of software programs, if\nappropriately utilized, can improve the effectiveness of ML-driven NLP\napproaches in repairing software programs. As the first step towards proving\nthis hypothesis, we propose a unified representation to capture the syntax,\ndata flow, and control flow aspects of software programs, and devise a method\nto use such a representation to guide the transformer model from NLP in better\nunderstanding and fixing buggy programs. Our preliminary experiment confirms\nthat the more comprehensive information of software programs used, the better\nML-driven NLP techniques can perform in fixing bugs in these programs.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 15:49:22 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Wang", "Wenshuo", ""], ["Wu", "Chen", ""], ["Cheng", "Liang", ""], ["Zhang", "Yang", ""]]}, {"id": "2107.08295", "submitter": "Christian Schroeder de Witt", "authors": "Samuel Sokota, Christian Schroeder de Witt, Maximilian Igl, Luisa\n  Zintgraf, Philip Torr, Shimon Whiteson, Jakob Foerster", "title": "Implicit Communication as Minimum Entropy Coupling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many common-payoff games, achieving good performance requires players to\ndevelop protocols for communicating their private information implicitly --\ni.e., using actions that have non-communicative effects on the environment.\nMulti-agent reinforcement learning practitioners typically approach this\nproblem using independent learning methods in the hope that agents will learn\nimplicit communication as a byproduct of expected return maximization.\nUnfortunately, independent learning methods are incapable of doing this in many\nsettings. In this work, we isolate the implicit communication problem by\nidentifying a class of partially observable common-payoff games, which we call\nimplicit referential games, whose difficulty can be attributed to implicit\ncommunication. Next, we introduce a principled method based on minimum entropy\ncoupling that leverages the structure of implicit referential games, yielding a\nnew perspective on implicit communication. Lastly, we show that this method can\ndiscover performant implicit communication protocols in settings with very\nlarge spaces of messages.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 17:44:30 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Sokota", "Samuel", ""], ["de Witt", "Christian Schroeder", ""], ["Igl", "Maximilian", ""], ["Zintgraf", "Luisa", ""], ["Torr", "Philip", ""], ["Whiteson", "Shimon", ""], ["Foerster", "Jakob", ""]]}, {"id": "2107.08325", "submitter": "Peide Cai", "authors": "Peide Cai, Hengli Wang, Huaiyang Huang, Yuxuan Liu, Ming Liu", "title": "Vision-Based Autonomous Car Racing Using Deep Imitative Reinforcement\n  Learning", "comments": "8 pages, 8 figures. IEEE Robotics and Automation Letters (RA-L) &\n  IROS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous car racing is a challenging task in the robotic control area.\nTraditional modular methods require accurate mapping, localization and\nplanning, which makes them computationally inefficient and sensitive to\nenvironmental changes. Recently, deep-learning-based end-to-end systems have\nshown promising results for autonomous driving/racing. However, they are\ncommonly implemented by supervised imitation learning (IL), which suffers from\nthe distribution mismatch problem, or by reinforcement learning (RL), which\nrequires a huge amount of risky interaction data. In this work, we present a\ngeneral deep imitative reinforcement learning approach (DIRL), which\nsuccessfully achieves agile autonomous racing using visual inputs. The driving\nknowledge is acquired from both IL and model-based RL, where the agent can\nlearn from human teachers as well as perform self-improvement by safely\ninteracting with an offline world model. We validate our algorithm both in a\nhigh-fidelity driving simulation and on a real-world 1/20-scale RC-car with\nlimited onboard computation. The evaluation results demonstrate that our method\noutperforms previous IL and RL methods in terms of sample efficiency and task\nperformance. Demonstration videos are available at\nhttps://caipeide.github.io/autorace-dirl/\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 00:00:48 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Cai", "Peide", ""], ["Wang", "Hengli", ""], ["Huang", "Huaiyang", ""], ["Liu", "Yuxuan", ""], ["Liu", "Ming", ""]]}, {"id": "2107.08353", "submitter": "Chirag Gupta", "authors": "Chirag Gupta and Aaditya K. Ramdas", "title": "Top-label calibration", "comments": "33 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of post-hoc calibration for multiclass classification,\nwith an emphasis on histogram binning. Multiple works have focused on\ncalibration with respect to the confidence of just the predicted class (or\n'top-label'). We find that the popular notion of confidence calibration [Guo et\nal., 2017] is not sufficiently strong -- there exist predictors that are not\ncalibrated in any meaningful way but are perfectly confidence calibrated. We\npropose a closely related (but subtly different) notion, top-label calibration,\nthat accurately captures the intuition and simplicity of confidence\ncalibration, but addresses its drawbacks. We formalize a histogram binning (HB)\nalgorithm that reduces top-label multiclass calibration to the binary case,\nprove that it has clean theoretical guarantees without distributional\nassumptions, and perform a methodical study of its practical performance. Some\nprediction tasks require stricter notions of multiclass calibration such as\nclass-wise or canonical calibration. We formalize appropriate HB algorithms\ncorresponding to each of these goals. In experiments with deep neural nets, we\nfind that our principled versions of HB are often better than temperature\nscaling, for both top-label and class-wise calibration. Code for this work will\nbe made publicly available at https://github.com/aigen/df-posthoc-calibration.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 03:27:50 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Gupta", "Chirag", ""], ["Ramdas", "Aaditya K.", ""]]}, {"id": "2107.08361", "submitter": "Xiangheng He", "authors": "Xiangheng He, Junjie Chen, Georgios Rizos, Bj\\\"orn W. Schuller", "title": "An Improved StarGAN for Emotional Voice Conversion: Enhancing Voice\n  Quality and Data Augmentation", "comments": "Accepted by Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotional Voice Conversion (EVC) aims to convert the emotional style of a\nsource speech signal to a target style while preserving its content and speaker\nidentity information. Previous emotional conversion studies do not disentangle\nemotional information from emotion-independent information that should be\npreserved, thus transforming it all in a monolithic manner and generating audio\nof low quality, with linguistic distortions. To address this distortion\nproblem, we propose a novel StarGAN framework along with a two-stage training\nprocess that separates emotional features from those independent of emotion by\nusing an autoencoder with two encoders as the generator of the Generative\nAdversarial Network (GAN). The proposed model achieves favourable results in\nboth the objective evaluation and the subjective evaluation in terms of\ndistortion, which reveals that the proposed model can effectively reduce\ndistortion. Furthermore, in data augmentation experiments for end-to-end speech\nemotion recognition, the proposed StarGAN model achieves an increase of 2% in\nMicro-F1 and 5% in Macro-F1 compared to the baseline StarGAN model, which\nindicates that the proposed model is more valuable for data augmentation.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 04:28:47 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["He", "Xiangheng", ""], ["Chen", "Junjie", ""], ["Rizos", "Georgios", ""], ["Schuller", "Bj\u00f6rn W.", ""]]}, {"id": "2107.08362", "submitter": "Bing Sun", "authors": "Bing Sun, Jun Sun, Ting Dai, Lijun Zhang", "title": "Probabilistic Verification of Neural Networks Against Group Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness is crucial for neural networks which are used in applications with\nimportant societal implication. Recently, there have been multiple attempts on\nimproving fairness of neural networks, with a focus on fairness testing (e.g.,\ngenerating individual discriminatory instances) and fairness training (e.g.,\nenhancing fairness through augmented training). In this work, we propose an\napproach to formally verify neural networks against fairness, with a focus on\nindependence-based fairness such as group fairness. Our method is built upon an\napproach for learning Markov Chains from a user-provided neural network (i.e.,\na feed-forward neural network or a recurrent neural network) which is\nguaranteed to facilitate sound analysis. The learned Markov Chain not only\nallows us to verify (with Probably Approximate Correctness guarantee) whether\nthe neural network is fair or not, but also facilities sensitivity analysis\nwhich helps to understand why fairness is violated. We demonstrate that with\nour analysis results, the neural weights can be optimized to improve fairness.\nOur approach has been evaluated with multiple models trained on benchmark\ndatasets and the experiment results show that our approach is effective and\nefficient.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 04:34:31 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Sun", "Bing", ""], ["Sun", "Jun", ""], ["Dai", "Ting", ""], ["Zhang", "Lijun", ""]]}, {"id": "2107.08364", "submitter": "Triet Le", "authors": "Triet H. M. Le, Huaming Chen, M. Ali Babar", "title": "A Survey on Data-driven Software Vulnerability Assessment and\n  Prioritization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Software Vulnerabilities (SVs) are increasing in complexity and scale, posing\ngreat security risks to many software systems. Given the limited resources in\npractice, SV assessment and prioritization help practitioners devise optimal SV\nmitigation plans based on various SV characteristics. The surge in SV data\nsources and data-driven techniques such as Machine Learning and Deep Learning\nhave taken SV assessment and prioritization to the next level. Our survey\nprovides a taxonomy of the past research efforts and highlights the best\npractices for data-driven SV assessment and prioritization. We also discuss the\ncurrent limitations and propose potential solutions to address such issues.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 04:49:22 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 05:28:28 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Le", "Triet H. M.", ""], ["Chen", "Huaming", ""], ["Babar", "M. Ali", ""]]}, {"id": "2107.08369", "submitter": "Siddha Ganju", "authors": "Sayak Paul and Siddha Ganju", "title": "Flood Segmentation on Sentinel-1 SAR Imagery with Semi-Supervised\n  Learning", "comments": "Equal authorship. This is a work in progress and is a submission to\n  the Emerging Techniques in Computational Intelligence (ETCI) competition on\n  Flood Detection. Code and models are available on GitHub", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Floods wreak havoc throughout the world, causing billions of dollars in\ndamages, and uprooting communities, ecosystems and economies. Accurate and\nrobust flood detection including delineating open water flood areas and\nidentifying flood levels can aid in disaster response and mitigation. However,\nestimating flood levels remotely is of essence as physical access to flooded\nareas is limited and the ability to deploy instruments in potential flood zones\ncan be dangerous. Aligning flood extent mapping with local topography can\nprovide a plan-of-action that the disaster response team can consider. Thus,\nremote flood level estimation via satellites like Sentinel-1 can prove to be\nremedial. The Emerging Techniques in Computational Intelligence (ETCI)\ncompetition on Flood Detection tasked participants with predicting flooded\npixels after training with synthetic aperture radar (SAR) images in a\nsupervised setting. We use a cyclical approach involving two stages (1)\ntraining an ensemble model of multiple UNet architectures with available high\nand low confidence labeled data and, (2) generating pseudo labels or low\nconfidence labels on the unlabeled test dataset, and then, combining the\ngenerated labels with the previously available high confidence labeled dataset.\nThis assimilated dataset is used for the next round of training ensemble\nmodels. This cyclical process is repeated until the performance improvement\nplateaus. Additionally, we post process our results with Conditional Random\nFields. Our approach sets a high score on the public leaderboard for the ETCI\ncompetition with 0.7654 IoU. Our method, which we release with all the code\nincluding trained models, can also be used as an open science benchmark for the\nSentinel-1 released dataset on GitHub. To the best of our knowledge we believe\nthis the first works to try out semi-supervised learning to improve flood\nsegmentation models.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 05:42:10 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 16:20:51 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Paul", "Sayak", ""], ["Ganju", "Siddha", ""]]}, {"id": "2107.08371", "submitter": "Liangqiong Qu", "authors": "Liangqiong Qu, Niranjan Balachandar and Daniel L Rubin", "title": "An Experimental Study of Data Heterogeneity in Federated Learning\n  Methods for Medical Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables multiple institutions to collaboratively train\nmachine learning models on their local data in a privacy-preserving way.\nHowever, its distributed nature often leads to significant heterogeneity in\ndata distributions across institutions. In this paper, we investigate the\ndeleterious impact of a taxonomy of data heterogeneity regimes on federated\nlearning methods, including quantity skew, label distribution skew, and imaging\nacquisition skew. We show that the performance degrades with the increasing\ndegrees of data heterogeneity. We present several mitigation strategies to\novercome performance drops from data heterogeneity, including weighted average\nfor data quantity skew, weighted loss and batch normalization averaging for\nlabel distribution skew. The proposed optimizations to federated learning\nmethods improve their capability of handling heterogeneity across institutions,\nwhich provides valuable guidance for the deployment of federated learning in\nreal clinical applications.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 05:47:48 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Qu", "Liangqiong", ""], ["Balachandar", "Niranjan", ""], ["Rubin", "Daniel L", ""]]}, {"id": "2107.08378", "submitter": "Sayan Sinha", "authors": "Rumia Masburah and Sayan Sinha and Rajib Lochan Jana, Soumyajit Dey,\n  Qi Zhu", "title": "Co-designing Intelligent Control of Building HVACs and Microgrids", "comments": "DSD 2021: Euromicro Conference on Digital System Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Building loads consume roughly 40% of the energy produced in developed\ncountries, a significant part of which is invested towards building\ntemperature-control infrastructure. Therein, renewable resource-based\nmicrogrids offer a greener and cheaper alternative. This communication explores\nthe possible co-design of microgrid power dispatch and building HVAC (heating,\nventilation and air conditioning system) actuations with the objective of\neffective temperature control under minimised operating cost. For this, we\nattempt control designs with various levels of abstractions based on\ninformation available about microgrid and HVAC system models using the Deep\nReinforcement Learning (DRL) technique. We provide control architectures that\nconsider model information ranging from completely determined system models to\nsystems with fully unknown parameter settings and illustrate the advantages of\nDRL for the design prescriptions.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 06:39:52 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Masburah", "Rumia", ""], ["Sinha", "Sayan", ""], ["Jana", "Rajib Lochan", ""], ["Dey", "Soumyajit", ""], ["Zhu", "Qi", ""]]}, {"id": "2107.08379", "submitter": "Xuan Guo", "authors": "Pengfei Jiao, Xuan Guo, Ting Pan, Wang Zhang, Yulong Pei", "title": "A Survey on Role-Oriented Network Embedding", "comments": "20 pages,9 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently, Network Embedding (NE) has become one of the most attractive\nresearch topics in machine learning and data mining. NE approaches have\nachieved promising performance in various of graph mining tasks including link\nprediction and node clustering and classification. A wide variety of NE methods\nfocus on the proximity of networks. They learn community-oriented embedding for\neach node, where the corresponding representations are similar if two nodes are\ncloser to each other in the network. Meanwhile, there is another type of\nstructural similarity, i.e., role-based similarity, which is usually\ncomplementary and completely different from the proximity. In order to preserve\nthe role-based structural similarity, the problem of role-oriented NE is\nraised. However, compared to community-oriented NE problem, there are only a\nfew role-oriented embedding approaches proposed recently. Although less\nexplored, considering the importance of roles in analyzing networks and many\napplications that role-oriented NE can shed light on, it is necessary and\ntimely to provide a comprehensive overview of existing role-oriented NE\nmethods. In this review, we first clarify the differences between\ncommunity-oriented and role-oriented network embedding. Afterwards, we propose\na general framework for understanding role-oriented NE and a two-level\ncategorization to better classify existing methods. Then, we select some\nrepresentative methods according to the proposed categorization and briefly\nintroduce them by discussing their motivation, development and differences.\nMoreover, we conduct comprehensive experiments to empirically evaluate these\nmethods on a variety of role-related tasks including node classification and\nclustering (role discovery), top-k similarity search and visualization using\nsome widely used synthetic and real-world datasets...\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 06:41:04 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Jiao", "Pengfei", ""], ["Guo", "Xuan", ""], ["Pan", "Ting", ""], ["Zhang", "Wang", ""], ["Pei", "Yulong", ""]]}, {"id": "2107.08387", "submitter": "Shai Ben-Assayag", "authors": "Shai Ben-Assayag, Ran El-Yaniv", "title": "Train on Small, Play the Large: Scaling Up Board Games with AlphaZero\n  and GNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Playing board games is considered a major challenge for both humans and AI\nresearchers. Because some complicated board games are quite hard to learn,\nhumans usually begin with playing on smaller boards and incrementally advance\nto master larger board strategies. Most neural network frameworks that are\ncurrently tasked with playing board games neither perform such incremental\nlearning nor possess capabilities to automatically scale up. In this work, we\nlook at the board as a graph and combine a graph neural network architecture\ninside the AlphaZero framework, along with some other innovative improvements.\nOur ScalableAlphaZero is capable of learning to play incrementally on small\nboards, and advancing to play on large ones. Our model can be trained quickly\nto play different challenging board games on multiple board sizes, without\nusing any domain knowledge. We demonstrate the effectiveness of\nScalableAlphaZero and show, for example, that by training it for only three\ndays on small Othello boards, it can defeat the AlphaZero model on a large\nboard, which was trained to play the large board for $30$ days.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 08:36:00 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ben-Assayag", "Shai", ""], ["El-Yaniv", "Ran", ""]]}, {"id": "2107.08398", "submitter": "Juan Jos\\'e Nieto", "authors": "Juan Jos\\'e Nieto, Roger Creus and Xavier Giro-i-Nieto", "title": "Unsupervised Skill-Discovery and Skill-Learning in Minecraft", "comments": "Accepted at ICML Unsupervised RL Workshop, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pre-training Reinforcement Learning agents in a task-agnostic manner has\nshown promising results. However, previous works still struggle in learning and\ndiscovering meaningful skills in high-dimensional state-spaces, such as\npixel-spaces. We approach the problem by leveraging unsupervised skill\ndiscovery and self-supervised learning of state representations. In our work,\nwe learn a compact latent representation by making use of variational and\ncontrastive techniques. We demonstrate that both enable RL agents to learn a\nset of basic navigation skills by maximizing an information theoretic\nobjective. We assess our method in Minecraft 3D pixel maps with different\ncomplexities. Our results show that representations and conditioned policies\nlearned from pixels are enough for toy examples, but do not scale to realistic\nand complex maps. To overcome these limitations, we explore alternative input\nobservations such as the relative position of the agent along with the raw\npixels.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 09:28:21 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Nieto", "Juan Jos\u00e9", ""], ["Creus", "Roger", ""], ["Giro-i-Nieto", "Xavier", ""]]}, {"id": "2107.08402", "submitter": "Farnaz Tahmasebian", "authors": "Farnaz Tahmasebian, Jian Lou, and Li Xiong", "title": "RobustFed: A Truth Inference Approach for Robust Federated Learning", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning is a prominent framework that enables clients (e.g.,\nmobile devices or organizations) to train a collaboratively global model under\na central server's orchestration while keeping local training datasets'\nprivacy. However, the aggregation step in federated learning is vulnerable to\nadversarial attacks as the central server cannot manage clients' behavior.\nTherefore, the global model's performance and convergence of the training\nprocess will be affected under such attacks.To mitigate this vulnerability\nissue, we propose a novel robust aggregation algorithm inspired by the truth\ninference methods in crowdsourcing via incorporating the worker's reliability\ninto aggregation. We evaluate our solution on three real-world datasets with a\nvariety of machine learning models. Experimental results show that our solution\nensures robust federated learning and is resilient to various types of attacks,\nincluding noisy data attacks, Byzantine attacks, and label flipping attacks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 09:34:57 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Tahmasebian", "Farnaz", ""], ["Lou", "Jian", ""], ["Xiong", "Li", ""]]}, {"id": "2107.08403", "submitter": "Laura Giordano", "authors": "Laura Giordano, Alberto Martelli, and Daniele Theseider Dupr\\'e", "title": "Reasoning about actions with EL ontologies with temporal answer sets", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach based on Answer Set Programming for reasoning about\nactions with domain descriptions including ontological knowledge, expressed in\nthe lightweight description logic EL^\\bot. We consider a temporal action\ntheory, which allows for non-deterministic actions and causal rules to deal\nwith ramifications, and whose extensions are defined by temporal answer sets.\nWe provide conditions under which action consistency can be guaranteed with\nrespect to an ontology, by a polynomial encoding of an action theory extended\nwith an EL^\\bot knowledge base (in normal form) into a temporal action theory.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 09:43:53 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Giordano", "Laura", ""], ["Martelli", "Alberto", ""], ["Dupr\u00e9", "Daniele Theseider", ""]]}, {"id": "2107.08408", "submitter": "Ashutosh Modi", "authors": "Ishika Singh and Gargi Singh and Ashutosh Modi", "title": "Pre-trained Language Models as Prior Knowledge for Playing Text-based\n  Games", "comments": "55 Pages (8 Pages main content + 2 Pages references + 45 Pages\n  Appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.MA cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently, text world games have been proposed to enable artificial agents to\nunderstand and reason about real-world scenarios. These text-based games are\nchallenging for artificial agents, as it requires understanding and interaction\nusing natural language in a partially observable environment. In this paper, we\nimprove the semantic understanding of the agent by proposing a simple RL with\nLM framework where we use transformer-based language models with Deep RL\nmodels. We perform a detailed study of our framework to demonstrate how our\nmodel outperforms all existing agents on the popular game, Zork1, to achieve a\nscore of 44.7, which is 1.6 higher than the state-of-the-art model. Our\nproposed approach also performs comparably to the state-of-the-art models on\nthe other set of text games.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 10:28:48 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Singh", "Ishika", ""], ["Singh", "Gargi", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2107.08444", "submitter": "Shay Moran", "authors": "Noga Alon and Steve Hanneke and Ron Holzman and Shay Moran", "title": "A Theory of PAC Learnability of Partial Concept Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC cs.CG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We extend the theory of PAC learning in a way which allows to model a rich\nvariety of learning tasks where the data satisfy special properties that ease\nthe learning process. For example, tasks where the distance of the data from\nthe decision boundary is bounded away from zero. The basic and simple idea is\nto consider partial concepts: these are functions that can be undefined on\ncertain parts of the space. When learning a partial concept, we assume that the\nsource distribution is supported only on points where the partial concept is\ndefined.\n  This way, one can naturally express assumptions on the data such as lying on\na lower dimensional surface or margin conditions. In contrast, it is not at all\nclear that such assumptions can be expressed by the traditional PAC theory. In\nfact we exhibit easy-to-learn partial concept classes which provably cannot be\ncaptured by the traditional PAC theory. This also resolves a question posed by\nAttias, Kontorovich, and Mansour 2019.\n  We characterize PAC learnability of partial concept classes and reveal an\nalgorithmic landscape which is fundamentally different than the classical one.\nFor example, in the classical PAC model, learning boils down to Empirical Risk\nMinimization (ERM). In stark contrast, we show that the ERM principle fails in\nexplaining learnability of partial concept classes. In fact, we demonstrate\nclasses that are incredibly easy to learn, but such that any algorithm that\nlearns them must use an hypothesis space with unbounded VC dimension. We also\nfind that the sample compression conjecture fails in this setting.\n  Thus, this theory features problems that cannot be represented nor solved in\nthe traditional way. We view this as evidence that it might provide insights on\nthe nature of learnability in realistic scenarios which the classical theory\nfails to explain.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 13:29:26 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 19:25:35 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Alon", "Noga", ""], ["Hanneke", "Steve", ""], ["Holzman", "Ron", ""], ["Moran", "Shay", ""]]}, {"id": "2107.08467", "submitter": "Ramin Hasani", "authors": "Sophie Gruenbacher, Mathias Lechner, Ramin Hasani, Daniela Rus, Thomas\n  A. Henzinger, Scott Smolka, Radu Grosu", "title": "GoTube: Scalable Stochastic Verification of Continuous-Depth Models", "comments": "17 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.DS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce a new stochastic verification algorithm that formally quantifies\nthe behavioral robustness of any time-continuous process formulated as a\ncontinuous-depth model. The algorithm solves a set of global optimization (Go)\nproblems over a given time horizon to construct a tight enclosure (Tube) of the\nset of all process executions starting from a ball of initial states. We call\nour algorithm GoTube. Through its construction, GoTube ensures that the\nbounding tube is conservative up to a desired probability. GoTube is\nimplemented in JAX and optimized to scale to complex continuous-depth models.\nCompared to advanced reachability analysis tools for time-continuous neural\nnetworks, GoTube provably does not accumulate over-approximation errors between\ntime steps and avoids the infamous wrapping effect inherent in symbolic\ntechniques. We show that GoTube substantially outperforms state-of-the-art\nverification tools in terms of the size of the initial ball, speed,\ntime-horizon, task completion, and scalability, on a large set of experiments.\nGoTube is stable and sets the state-of-the-art for its ability to scale up to\ntime horizons well beyond what has been possible before.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 14:59:31 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Gruenbacher", "Sophie", ""], ["Lechner", "Mathias", ""], ["Hasani", "Ramin", ""], ["Rus", "Daniela", ""], ["Henzinger", "Thomas A.", ""], ["Smolka", "Scott", ""], ["Grosu", "Radu", ""]]}, {"id": "2107.08558", "submitter": "Duligur Ibeling", "authors": "Duligur Ibeling, Thomas Icard", "title": "A Topological Perspective on Causal Inference", "comments": "ICML 2021 NACI workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a topological learning-theoretic perspective on causal\ninference by introducing a series of topologies defined on general spaces of\nstructural causal models (SCMs). As an illustration of the framework we prove a\ntopological causal hierarchy theorem, showing that substantive assumption-free\ncausal inference is possible only in a meager set of SCMs. Thanks to a known\ncorrespondence between open sets in the weak topology and statistically\nverifiable hypotheses, our results show that inductive assumptions sufficient\nto license valid causal inferences are statistically unverifiable in principle.\nSimilar to no-free-lunch theorems for statistical inference, the present\nresults clarify the inevitability of substantial assumptions for causal\ninference. An additional benefit of our topological approach is that it easily\naccommodates SCMs with infinitely many variables. We finally suggest that the\nframework may be helpful for the positive project of exploring and assessing\nalternative causal-inductive assumptions.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 23:09:03 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ibeling", "Duligur", ""], ["Icard", "Thomas", ""]]}, {"id": "2107.08572", "submitter": "Spyridon Ampanavos", "authors": "Spyridon Ampanavos, Ali Malkawi", "title": "Early-Phase Performance-Driven Design using Generative Models", "comments": "CAAD Futures 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Current performance-driven building design methods are not widely adopted\noutside the research field for several reasons that make them difficult to\nintegrate into a typical design process. In the early design phase, in\nparticular, the time-intensity and the cognitive load associated with\noptimization and form parametrization are incompatible with design exploration,\nwhich requires quick iteration. This research introduces a novel method for\nperformance-driven geometry generation that can afford interaction directly in\nthe 3d modeling environment, eliminating the need for explicit parametrization,\nand is multiple orders faster than the equivalent form optimization. The method\nuses Machine Learning techniques to train a generative model offline. The\ngenerative model learns a distribution of optimal performing geometries and\ntheir simulation contexts based on a dataset that addresses the performance(s)\nof interest. By navigating the generative model's latent space, geometries with\nthe desired characteristics can be quickly generated. A case study is\npresented, demonstrating the generation of a synthetic dataset and the use of a\nVariational Autoencoder (VAE) as a generative model for geometries with optimal\nsolar gain. The results show that the VAE-generated geometries perform on\naverage at least as well as the optimized ones, suggesting that the introduced\nmethod shows a feasible path towards more intuitive and interactive early-phase\nperformance-driven design assistance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 01:25:11 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ampanavos", "Spyridon", ""], ["Malkawi", "Ali", ""]]}, {"id": "2107.08574", "submitter": "Mohamed Abdelhack", "authors": "Mohamed Abdelhack, Jiaming Zhang, Sandhya Tripathi, Bradley Fritz,\n  Michael Avidan, Yixin Chen, Christopher King", "title": "A Modulation Layer to Increase Neural Network Robustness Against Data\n  Quality Issues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data quality is a common problem in machine learning, especially in\nhigh-stakes settings such as healthcare. Missing data affects accuracy,\ncalibration, and feature attribution in complex patterns. Developers often\ntrain models on carefully curated datasets to minimize missing data bias;\nhowever, this reduces the usability of such models in production environments,\nsuch as real-time healthcare records. Making machine learning models robust to\nmissing data is therefore crucial for practical application. While some\nclassifiers naturally handle missing data, others, such as deep neural\nnetworks, are not designed for unknown values. We propose a novel neural\nnetwork modification to mitigate the impacts of missing data. The approach is\ninspired by neuromodulation that is performed by biological neural networks.\nOur proposal replaces the fixed weights of a fully-connected layer with a\nfunction of an additional input (reliability score) at each input, mimicking\nthe ability of cortex to up- and down-weight inputs based on the presence of\nother data. The modulation function is jointly learned with the main task using\na multi-layer perceptron. We tested our modulating fully connected layer on\nmultiple classification, regression, and imputation problems, and it either\nimproved performance or generated comparable performance to conventional neural\nnetwork architectures concatenating reliability to the inputs. Models with\nmodulating layers were more robust against degradation of data quality by\nintroducing additional missingness at evaluation time. These results suggest\nthat explicitly accounting for reduced information quality with a modulating\nfully connected layer can enable the deployment of artificial intelligence\nsystems in real-time settings.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 01:29:16 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Abdelhack", "Mohamed", ""], ["Zhang", "Jiaming", ""], ["Tripathi", "Sandhya", ""], ["Fritz", "Bradley", ""], ["Avidan", "Michael", ""], ["Chen", "Yixin", ""], ["King", "Christopher", ""]]}, {"id": "2107.08577", "submitter": "Gautam Singh", "authors": "Gautam Singh, Skand Peri, Junghyun Kim, Hyunseok Kim, Sungjin Ahn", "title": "Structured World Belief for Reinforcement Learning in POMDP", "comments": "Published in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object-centric world models provide structured representation of the scene\nand can be an important backbone in reinforcement learning and planning.\nHowever, existing approaches suffer in partially-observable environments due to\nthe lack of belief states. In this paper, we propose Structured World Belief, a\nmodel for learning and inference of object-centric belief states. Inferred by\nSequential Monte Carlo (SMC), our belief states provide multiple object-centric\nscene hypotheses. To synergize the benefits of SMC particles with object\nrepresentations, we also propose a new object-centric dynamics model that\nconsiders the inductive bias of object permanence. This enables tracking of\nobject states even when they are invisible for a long time. To further\nfacilitate object tracking in this regime, we allow our model to attend\nflexibly to any spatial location in the image which was restricted in previous\nmodels. In experiments, we show that object-centric belief provides a more\naccurate and robust performance for filtering and generation. Furthermore, we\nshow the efficacy of structured world belief in improving the performance of\nreinforcement learning, planning and supervised reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 01:47:53 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Singh", "Gautam", ""], ["Peri", "Skand", ""], ["Kim", "Junghyun", ""], ["Kim", "Hyunseok", ""], ["Ahn", "Sungjin", ""]]}, {"id": "2107.08581", "submitter": "Songlin Yang", "authors": "Songlin Yang, Wei Wang, Yuehua Cheng and Jing Dong", "title": "A Systematical Solution for Face De-identification", "comments": "accepted by the 15th Chinese Conference on Biometrics Recognition\n  (CCBR2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the identity information in face data more closely related to personal\ncredit and property security, people pay increasing attention to the protection\nof face data privacy. In different tasks, people have various requirements for\nface de-identification (De-ID), so we propose a systematical solution\ncompatible for these De-ID operations. Firstly, an attribute disentanglement\nand generative network is constructed to encode two parts of the face, which\nare the identity (facial features like mouth, nose and eyes) and expression\n(including expression, pose and illumination). Through face swapping, we can\nremove the original ID completely. Secondly, we add an adversarial vector\nmapping network to perturb the latent code of the face image, different from\nprevious traditional adversarial methods. Through this, we can construct\nunrestricted adversarial image to decrease ID similarity recognized by model.\nOur method can flexibly de-identify the face data in various ways and the\nprocessed images have high image quality.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 02:02:51 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Yang", "Songlin", ""], ["Wang", "Wei", ""], ["Cheng", "Yuehua", ""], ["Dong", "Jing", ""]]}, {"id": "2107.08590", "submitter": "Zhi Wang", "authors": "Zhi Wang, Chaoge Liu, Xiang Cui", "title": "EvilModel: Hiding Malware Inside of Neural Network Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delivering malware covertly and evasively is critical to advanced malware\ncampaigns. In this paper, we present a new method to covertly and evasively\ndeliver malware through a neural network model. Neural network models are\npoorly explainable and have a good generalization ability. By embedding malware\nin neurons, the malware can be delivered covertly, with minor or no impact on\nthe performance of neural network. Meanwhile, because the structure of the\nneural network model remains unchanged, it can pass the security scan of\nantivirus engines. Experiments show that 36.9MB of malware can be embedded in a\n178MB-AlexNet model within 1% accuracy loss, and no suspicion is raised by\nanti-virus engines in VirusTotal, which verifies the feasibility of this\nmethod. With the widespread application of artificial intelligence, utilizing\nneural networks for attacks becomes a forwarding trend. We hope this work can\nprovide a reference scenario for the defense on neural network-assisted\nattacks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 02:44:31 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 14:31:13 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Wang", "Zhi", ""], ["Liu", "Chaoge", ""], ["Cui", "Xiang", ""]]}, {"id": "2107.08598", "submitter": "Guangda Huzhang", "authors": "Xuesi Wang, Guangda Huzhang, Qianying Lin, Qing Da, Dan Shen", "title": "Learning-To-Ensemble by Contextual Rank Aggregation in E-Commerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble models in E-commerce combine predictions from multiple sub-models\nfor ranking and revenue improvement. Industrial ensemble models are typically\ndeep neural networks, following the supervised learning paradigm to infer\nconversion rate given inputs from sub-models. However, this process has the\nfollowing two problems. Firstly, the point-wise scoring approach disregards the\nrelationships between items and leads to homogeneous displayed results, while\ndiversified display benefits user experience and revenue. Secondly, the\nlearning paradigm focuses on the ranking metrics and does not directly optimize\nthe revenue. In our work, we propose a new Learning-To-Ensemble (LTE) framework\nRAEGO, which replaces the ensemble model with a contextual Rank Aggregator (RA)\nand explores the best weights of sub-models by the Evaluator-Generator\nOptimization (EGO). To achieve the best online performance, we propose a new\nrank aggregation algorithm TournamentGreedy as a refinement of classic rank\naggregators, which also produces the best average weighted Kendall Tau Distance\n(KTD) amongst all the considered algorithms with quadratic time complexity.\nUnder the assumption that the best output list should be Pareto Optimal on the\nKTD metric for sub-models, we show that our RA algorithm has higher efficiency\nand coverage in exploring the optimal weights. Combined with the idea of\nBayesian Optimization and gradient descent, we solve the online contextual\nBlack-Box Optimization task that finds the optimal weights for sub-models given\na chosen RA model. RA-EGO has been deployed in our online system and has\nimproved the revenue significantly.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 03:24:06 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Wang", "Xuesi", ""], ["Huzhang", "Guangda", ""], ["Lin", "Qianying", ""], ["Da", "Qing", ""], ["Shen", "Dan", ""]]}, {"id": "2107.08621", "submitter": "Qingzhong Wang", "authors": "Qingzhong Wang, Pengfei Zhang, Haoyi Xiong and Jian Zhao", "title": "Face.evoLVe: A High-Performance Face Recognition Library", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we develop face.evoLVe -- a comprehensive library that\ncollects and implements a wide range of popular deep learning-based methods for\nface recognition. First of all, face.evoLVe is composed of key components that\ncover the full process of face analytics, including face alignment, data\nprocessing, various backbones, losses, and alternatives with bags of tricks for\nimproving performance. Later, face.evoLVe supports multi-GPU training on top of\ndifferent deep learning platforms, such as PyTorch and PaddlePaddle, which\nfacilitates researchers to work on both large-scale datasets with millions of\nimages and low-shot counterparts with limited well-annotated data. More\nimportantly, along with face.evoLVe, images before & after alignment in the\ncommon benchmark datasets are released with source codes and trained models\nprovided. All these efforts lower the technical burdens in reproducing the\nexisting methods for comparison, while users of our library could focus on\ndeveloping advanced approaches more efficiently. Last but not least,\nface.evoLVe is well designed and vibrantly evolving, so that new face\nrecognition approaches can be easily plugged into our framework. Note that we\nhave used face.evoLVe to participate in a number of face recognition\ncompetitions and secured the first place. The version that supports PyTorch is\npublicly available at https://github.com/ZhaoJ9014/face.evoLVe.PyTorch and the\nPaddlePaddle version is available at\nhttps://github.com/ZhaoJ9014/face.evoLVe.PyTorch/tree/master/paddle.\nFace.evoLVe has been widely used for face analytics, receiving 2.4K stars and\n622 forks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 05:38:50 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 09:24:48 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Wang", "Qingzhong", ""], ["Zhang", "Pengfei", ""], ["Xiong", "Haoyi", ""], ["Zhao", "Jian", ""]]}, {"id": "2107.08630", "submitter": "Mohammad Rasouli", "authors": "Mohammad Rasouli, Michael I. Jordan", "title": "Data Sharing Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.AI cs.GT", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  With the growing use of distributed machine learning techniques, there is a\ngrowing need for data markets that allows agents to share data with each other.\nNevertheless data has unique features that separates it from other commodities\nincluding replicability, cost of sharing, and ability to distort. We study a\nsetup where each agent can be both buyer and seller of data. For this setup, we\nconsider two cases: bilateral data exchange (trading data with data) and\nunilateral data exchange (trading data with money). We model bilateral sharing\nas a network formation game and show the existence of strongly stable outcome\nunder the top agents property by allowing limited complementarity. We propose\nordered match algorithm which can find the stable outcome in O(N^2) (N is the\nnumber of agents). For the unilateral sharing, under the assumption of additive\ncost structure, we construct competitive prices that can implement any social\nwelfare maximizing outcome. Finally for this setup when agents have private\ninformation, we propose mixed-VCG mechanism which uses zero cost data\ndistortion of data sharing with its isolated impact to achieve budget balance\nwhile truthfully implementing socially optimal outcomes to the exact level of\nbudget imbalance of standard VCG mechanisms. Mixed-VCG uses data distortions as\ndata money for this purpose. We further relax zero cost data distortion\nassumption by proposing distorted-mixed-VCG. We also extend our model and\nresults to data sharing via incremental inquiries and differential privacy\ncosts.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 06:00:34 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 06:31:23 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Rasouli", "Mohammad", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2107.08640", "submitter": "Subodh Lonkar", "authors": "Subodh Lonkar", "title": "Facial Expressions Recognition with Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Over the centuries, humans have developed and acquired a number of ways to\ncommunicate. But hardly any of them can be as natural and instinctive as facial\nexpressions. On the other hand, neural networks have taken the world by storm.\nAnd no surprises, that the area of Computer Vision and the problem of facial\nexpressions recognitions hasn't remained untouched. Although a wide range of\ntechniques have been applied, achieving extremely high accuracies and preparing\nhighly robust FER systems still remains a challenge due to heterogeneous\ndetails in human faces. In this paper, we will be deep diving into implementing\na system for recognition of facial expressions (FER) by leveraging neural\nnetworks, and more specifically, Convolutional Neural Networks (CNNs). We adopt\nthe fundamental concepts of deep learning and computer vision with various\narchitectures, fine-tune it's hyperparameters and experiment with various\noptimization methods and demonstrate a state-of-the-art single-network-accuracy\nof 70.10% on the FER2013 dataset without using any additional training data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 06:41:00 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Lonkar", "Subodh", ""]]}, {"id": "2107.08697", "submitter": "Catarina Moreira", "authors": "Chihcheng Hsieh and Catarina Moreira and Chun Ouyang", "title": "Interpreting Process Predictions using a Milestone-Aware Counterfactual\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predictive process analytics often apply machine learning to predict the\nfuture states of a running business process. However, the internal mechanisms\nof many existing predictive algorithms are opaque and a human decision-maker is\nunable to understand \\emph{why} a certain activity was predicted. Recently,\ncounterfactuals have been proposed in the literature to derive\nhuman-understandable explanations from predictive models. Current\ncounterfactual approaches consist of finding the minimum feature change that\ncan make a certain prediction flip its outcome. Although many algorithms have\nbeen proposed, their application to the sequence and multi-dimensional data\nlike event logs has not been explored in the literature.\n  In this paper, we explore the use of a recent, popular model-agnostic\ncounterfactual algorithm, DiCE, in the context of predictive process analytics.\nThe analysis reveals that the algorithm is limited when being applied to derive\nexplanations of process predictions, due to (1) process domain knowledge not\nbeing taken into account, (2) long traces that often tend to be less\nunderstandable, and (3) difficulties in optimising the counterfactual search\nwith categorical variables. We design an extension of DiCE that can generate\ncounterfactuals for process predictions, and propose an approach that supports\nderiving milestone-aware counterfactuals at different stages of a trace to\npromote interpretability. We apply our approach to BPIC2012 event log and the\nanalysis results demonstrate the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 09:14:16 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Hsieh", "Chihcheng", ""], ["Moreira", "Catarina", ""], ["Ouyang", "Chun", ""]]}, {"id": "2107.08714", "submitter": "Zhenyu Guo", "authors": "Zhenyu Guo, Shuai Zheng, Zhizhe Liu, Kun Yan, Zhenfeng Zhu", "title": "CETransformer: Casual Effect Estimation via Transformer Based\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Treatment effect estimation, which refers to the estimation of causal effects\nand aims to measure the strength of the causal relationship, is of great\nimportance in many fields but is a challenging problem in practice. As present,\ndata-driven causal effect estimation faces two main challenges, i.e., selection\nbias and the missing of counterfactual. To address these two issues, most of\nthe existing approaches tend to reduce the selection bias by learning a\nbalanced representation, and then to estimate the counterfactual through the\nrepresentation. However, they heavily rely on the finely hand-crafted metric\nfunctions when learning balanced representations, which generally doesn't work\nwell for the situations where the original distribution is complicated. In this\npaper, we propose a CETransformer model for casual effect estimation via\ntransformer based representation learning. To learn the representation of\ncovariates(features) robustly, a self-supervised transformer is proposed, by\nwhich the correlation between covariates can be well exploited through\nself-attention mechanism. In addition, an adversarial network is adopted to\nbalance the distribution of the treated and control groups in the\nrepresentation space. Experimental results on three real-world datasets\ndemonstrate the advantages of the proposed CETransformer, compared with the\nstate-of-the-art treatment effect estimation methods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 09:39:57 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Guo", "Zhenyu", ""], ["Zheng", "Shuai", ""], ["Liu", "Zhizhe", ""], ["Yan", "Kun", ""], ["Zhu", "Zhenfeng", ""]]}, {"id": "2107.08739", "submitter": "Francesco Fabiano", "authors": "Francesco Fabiano, Biplav Srivastava, Jonathan Lenchner, Lior Horesh,\n  Francesca Rossi, Marianna Bergamaschi Ganapini", "title": "E-PDDL: A Standardized Way of Defining Epistemic Planning Problems", "comments": "9 pages, Knowledge Engineering for Planning and Scheduling - ICAPS\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Epistemic Planning (EP) refers to an automated planning setting where the\nagent reasons in the space of knowledge states and tries to find a plan to\nreach a desirable state from the current state. Its general form, the\nMulti-agent Epistemic Planning (MEP) problem involves multiple agents who need\nto reason about both the state of the world and the information flow between\nagents. In a MEP problem, multiple approaches have been developed recently with\nvarying restrictions, such as considering only the concept of knowledge while\nnot allowing the idea of belief, or not allowing for ``complex\" modal operators\nsuch as those needed to handle dynamic common knowledge. While the diversity of\napproaches has led to a deeper understanding of the problem space, the lack of\na standardized way to specify MEP problems independently of solution approaches\nhas created difficulties in comparing performance of planners, identifying\npromising techniques, exploring new strategies like ensemble methods, and\nmaking it easy for new researchers to contribute to this research area. To\naddress the situation, we propose a unified way of specifying EP problems - the\nEpistemic Planning Domain Definition Language, E-PDDL. We show that E-PPDL can\nbe supported by leading MEP planners and provide corresponding parser code that\ntranslates EP problems specified in E-PDDL into (M)EP problems that can be\nhandled by several planners. This work is also useful in building more general\nepistemic planning environments where we envision a meta-cognitive module that\ntakes a planning problem in E-PDDL, identifies and assesses some of its\nfeatures, and autonomously decides which planner is the best one to solve it.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 10:20:20 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Fabiano", "Francesco", ""], ["Srivastava", "Biplav", ""], ["Lenchner", "Jonathan", ""], ["Horesh", "Lior", ""], ["Rossi", "Francesca", ""], ["Ganapini", "Marianna Bergamaschi", ""]]}, {"id": "2107.08760", "submitter": "Leon Moonen", "authors": "Guru Prasad Bhandari, Amara Naseer and Leon Moonen (Simula Research\n  Laboratory, Norway)", "title": "CVEfixes: Automated Collection of Vulnerabilities and Their Fixes from\n  Open-Source Software", "comments": "Accepted for publication in Proceedings of the 17th International\n  Conference on Predictive Models and Data Analytics in Software Engineering\n  (PROMISE '21), August 19-20, 2021, Athens, Greece", "journal-ref": null, "doi": "10.1145/3475960.3475985", "report-no": null, "categories": "cs.SE cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data-driven research on the automated discovery and repair of security\nvulnerabilities in source code requires comprehensive datasets of real-life\nvulnerable code and their fixes. To assist in such research, we propose a\nmethod to automatically collect and curate a comprehensive vulnerability\ndataset from Common Vulnerabilities and Exposures (CVE) records in the public\nNational Vulnerability Database (NVD). We implement our approach in a fully\nautomated dataset collection tool and share an initial release of the resulting\nvulnerability dataset named CVEfixes.\n  The CVEfixes collection tool automatically fetches all available CVE records\nfrom the NVD, gathers the vulnerable code and corresponding fixes from\nassociated open-source repositories, and organizes the collected information in\na relational database. Moreover, the dataset is enriched with meta-data such as\nprogramming language, and detailed code and security metrics at five levels of\nabstraction. The collection can easily be repeated to keep up-to-date with\nnewly discovered or patched vulnerabilities. The initial release of CVEfixes\nspans all published CVEs up to 9 June 2021, covering 5365 CVE records for 1754\nopen-source projects that were addressed in a total of 5495 vulnerability\nfixing commits.\n  CVEfixes supports various types of data-driven software security research,\nsuch as vulnerability prediction, vulnerability classification, vulnerability\nseverity prediction, analysis of vulnerability-related code changes, and\nautomated vulnerability repair.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 11:34:09 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Bhandari", "Guru Prasad", "", "Simula Research\n  Laboratory, Norway"], ["Naseer", "Amara", "", "Simula Research\n  Laboratory, Norway"], ["Moonen", "Leon", "", "Simula Research\n  Laboratory, Norway"]]}, {"id": "2107.08773", "submitter": "Jianwen Chen", "authors": "Jianwen Chen, Shuangjia Zheng, Ying Song, Jiahua Rao, Yuedong Yang", "title": "Learning Attributed Graph Representations with Communicative Message\n  Passing Transformer", "comments": "Accepted by IJCAI2021. 7 pages, 2 figures, 3 tables, 1 appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing appropriate representations of molecules lies at the core of\nnumerous tasks such as material science, chemistry and drug designs. Recent\nresearches abstract molecules as attributed graphs and employ graph neural\nnetworks (GNN) for molecular representation learning, which have made\nremarkable achievements in molecular graph modeling. Albeit powerful, current\nmodels either are based on local aggregation operations and thus miss\nhigher-order graph properties or focus on only node information without fully\nusing the edge information. For this sake, we propose a Communicative Message\nPassing Transformer (CoMPT) neural network to improve the molecular graph\nrepresentation by reinforcing message interactions between nodes and edges\nbased on the Transformer architecture. Unlike the previous transformer-style\nGNNs that treat molecules as fully connected graphs, we introduce a message\ndiffusion mechanism to leverage the graph connectivity inductive bias and\nreduce the message enrichment explosion. Extensive experiments demonstrated\nthat the proposed model obtained superior performances (around 4$\\%$ on\naverage) against state-of-the-art baselines on seven chemical property datasets\n(graph-level tasks) and two chemical shift datasets (node-level tasks). Further\nvisualization studies also indicated a better representation capacity achieved\nby our model.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 11:58:32 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 07:10:29 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Chen", "Jianwen", ""], ["Zheng", "Shuangjia", ""], ["Song", "Ying", ""], ["Rao", "Jiahua", ""], ["Yang", "Yuedong", ""]]}, {"id": "2107.08792", "submitter": "Kyeongbo Kong", "authors": "Kyeongbo Kong, Kyunghun Kim, Woo-Jin Song, and Suk-Ju Kang", "title": "Selective Focusing Learning in Conditional GANs", "comments": "14 pages, 9 figures, spotlight presented at the ICML 2021 Workshop on\n  Subset Selection in ML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional generative adversarial networks (cGANs) have demonstrated\nremarkable success due to their class-wise controllability and superior quality\nfor complex generation tasks. Typical cGANs solve the joint distribution\nmatching problem by decomposing two easier sub-problems: marginal matching and\nconditional matching. From our toy experiments, we found that it is the best to\napply only conditional matching to certain samples due to the content-aware\noptimization of the discriminator. This paper proposes a simple (a few lines of\ncode) but effective training methodology, selective focusing learning, which\nenforces the discriminator and generator to learn easy samples of each class\nrapidly while maintaining diversity. Our key idea is to selectively apply\nconditional and joint matching for the data in each mini-batch. We conducted\nexperiments on recent cGAN variants in ImageNet (64x64 and 128x128), CIFAR-10,\nand CIFAR-100 datasets, and improved the performance significantly (up to\n35.18% in terms of FID) without sacrificing diversity.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 06:06:56 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Kong", "Kyeongbo", ""], ["Kim", "Kyunghun", ""], ["Song", "Woo-Jin", ""], ["Kang", "Suk-Ju", ""]]}, {"id": "2107.08803", "submitter": "Xu Li", "authors": "Xu Li, Xixin Wu, Hui Lu, Xunying Liu, Helen Meng", "title": "Channel-wise Gated Res2Net: Towards Robust Detection of Synthetic Speech\n  Attacks", "comments": "Accepted to INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches for anti-spoofing in automatic speaker verification (ASV)\nstill lack generalizability to unseen attacks. The Res2Net approach designs a\nresidual-like connection between feature groups within one block, which\nincreases the possible receptive fields and improves the system's detection\ngeneralizability. However, such a residual-like connection is performed by a\ndirect addition between feature groups without channel-wise priority. We argue\nthat the information across channels may not contribute to spoofing cues\nequally, and the less relevant channels are expected to be suppressed before\nadding onto the next feature group, so that the system can generalize better to\nunseen attacks. This argument motivates the current work that presents a novel,\nchannel-wise gated Res2Net (CG-Res2Net), which modifies Res2Net to enable a\nchannel-wise gating mechanism in the connection between feature groups. This\ngating mechanism dynamically selects channel-wise features based on the input,\nto suppress the less relevant channels and enhance the detection\ngeneralizability. Three gating mechanisms with different structures are\nproposed and integrated into Res2Net. Experimental results conducted on\nASVspoof 2019 logical access (LA) demonstrate that the proposed CG-Res2Net\nsignificantly outperforms Res2Net on both the overall LA evaluation set and\nindividual difficult unseen attacks, which also outperforms other\nstate-of-the-art single systems, depicting the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 12:27:40 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Li", "Xu", ""], ["Wu", "Xixin", ""], ["Lu", "Hui", ""], ["Liu", "Xunying", ""], ["Meng", "Helen", ""]]}, {"id": "2107.08815", "submitter": "Jiandong Mu", "authors": "Jiandong Mu, Mengdi Wang, Feiwen Zhu, Jun Yang, Wei Lin, Wei Zhang", "title": "Boosting the Convergence of Reinforcement Learning-based Auto-pruning\n  Using Historical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural network compression schemes like channel pruning have been\nwidely used to reduce the model size and computational complexity of deep\nneural network (DNN) for applications in power-constrained scenarios such as\nembedded systems. Reinforcement learning (RL)-based auto-pruning has been\nfurther proposed to automate the DNN pruning process to avoid expensive\nhand-crafted work. However, the RL-based pruner involves a time-consuming\ntraining process and the high expense of each sample further exacerbates this\nproblem. These impediments have greatly restricted the real-world application\nof RL-based auto-pruning. Thus, in this paper, we propose an efficient\nauto-pruning framework which solves this problem by taking advantage of the\nhistorical data from the previous auto-pruning process. In our framework, we\nfirst boost the convergence of the RL-pruner by transfer learning. Then, an\naugmented transfer learning scheme is proposed to further speed up the training\nprocess by improving the transferability. Finally, an assistant learning\nprocess is proposed to improve the sample efficiency of the RL agent. The\nexperiments have shown that our framework can accelerate the auto-pruning\nprocess by 1.5-2.5 times for ResNet20, and 1.81-2.375 times for other neural\nnetworks like ResNet56, ResNet18, and MobileNet v1.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 07:17:26 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Mu", "Jiandong", ""], ["Wang", "Mengdi", ""], ["Zhu", "Feiwen", ""], ["Yang", "Jun", ""], ["Lin", "Wei", ""], ["Zhang", "Wei", ""]]}, {"id": "2107.08821", "submitter": "Jie Ren", "authors": "Quanshi Zhang, Tian Han, Lixin Fan, Zhanxing Zhu, Hang Su, Ying Nian\n  Wu, Jie Ren, Hao Zhang", "title": "Proceedings of ICML 2021 Workshop on Theoretic Foundation, Criticism,\n  and Application Trend of Explainable AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of ICML 2021 Workshop on Theoretic Foundation,\nCriticism, and Application Trend of Explainable AI. Deep neural networks (DNNs)\nhave undoubtedly brought great success to a wide range of applications in\ncomputer vision, computational linguistics, and AI. However, foundational\nprinciples underlying the DNNs' success and their resilience to adversarial\nattacks are still largely missing. Interpreting and theorizing the internal\nmechanisms of DNNs becomes a compelling yet controversial topic. This workshop\npays a special interest in theoretic foundations, limitations, and new\napplication trends in the scope of XAI. These issues reflect new bottlenecks in\nthe future development of XAI.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 13:14:16 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 12:34:33 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zhang", "Quanshi", ""], ["Han", "Tian", ""], ["Fan", "Lixin", ""], ["Zhu", "Zhanxing", ""], ["Su", "Hang", ""], ["Wu", "Ying Nian", ""], ["Ren", "Jie", ""], ["Zhang", "Hao", ""]]}, {"id": "2107.08823", "submitter": "Ha Young Jo", "authors": "Ha Young Jo, Seong-Whan Lee", "title": "One-Class Classification for Wafer Map using Adversarial Autoencoder\n  with DSVDD Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, semiconductors' demand has exploded in virtual reality,\nsmartphones, wearable devices, the internet of things, robotics, and\nautomobiles. Semiconductor manufacturers want to make semiconductors with high\nyields. To do this, manufacturers conduct many quality assurance activities.\nWafer map pattern classification is a typical way of quality assurance. The\ndefect pattern on the wafer map can tell us which process has a problem. Most\nof the existing wafer map classification methods are based on supervised\nmethods. The supervised methods tend to have high performance, but they require\nextensive labor and expert knowledge to produce labeled datasets with a\nbalanced distribution in mind. In the semiconductor manufacturing process, it\nis challenging to get defect data with balanced distribution. In this paper, we\npropose a one-class classification method using an Adversarial Autoencoder\n(AAE) with Deep Support Vector Data Description (DSVDD) prior, which generates\nrandom vectors within the hypersphere of DSVDD. We use the WM-811k dataset,\nwhich consists of a real-world wafer map. We compare the F1 score performance\nof our model with DSVDD and AAE.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 05:45:27 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Jo", "Ha Young", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2107.08828", "submitter": "Adish Singla", "authors": "Adish Singla, Anna N. Rafferty, Goran Radanovic, Neil T. Heffernan", "title": "Reinforcement Learning for Education: Opportunities and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey article has grown out of the RL4ED workshop organized by the\nauthors at the Educational Data Mining (EDM) 2021 conference. We organized this\nworkshop as part of a community-building effort to bring together researchers\nand practitioners interested in the broad areas of reinforcement learning (RL)\nand education (ED). This article aims to provide an overview of the workshop\nactivities and summarize the main research directions in the area of RL for ED.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 21:27:45 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Singla", "Adish", ""], ["Rafferty", "Anna N.", ""], ["Radanovic", "Goran", ""], ["Heffernan", "Neil T.", ""]]}, {"id": "2107.08829", "submitter": "Rafael Rafailov", "authors": "Rafael Rafailov, Tianhe Yu, Aravind Rajeswaran, Chelsea Finn", "title": "Visual Adversarial Imitation Learning using Variational Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reward function specification, which requires considerable human effort and\niteration, remains a major impediment for learning behaviors through deep\nreinforcement learning. In contrast, providing visual demonstrations of desired\nbehaviors often presents an easier and more natural way to teach agents. We\nconsider a setting where an agent is provided a fixed dataset of visual\ndemonstrations illustrating how to perform a task, and must learn to solve the\ntask using the provided demonstrations and unsupervised environment\ninteractions. This setting presents a number of challenges including\nrepresentation learning for visual observations, sample complexity due to high\ndimensional spaces, and learning instability due to the lack of a fixed reward\nor learning signal. Towards addressing these challenges, we develop a\nvariational model-based adversarial imitation learning (V-MAIL) algorithm. The\nmodel-based approach provides a strong signal for representation learning,\nenables sample efficiency, and improves the stability of adversarial training\nby enabling on-policy learning. Through experiments involving several\nvision-based locomotion and manipulation tasks, we find that V-MAIL learns\nsuccessful visuomotor policies in a sample-efficient manner, has better\nstability compared to prior work, and also achieves higher asymptotic\nperformance. We further find that by transferring the learned models, V-MAIL\ncan learn new tasks from visual demonstrations without any additional\nenvironment interactions. All results including videos can be found online at\n\\url{https://sites.google.com/view/variational-mail}.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 00:15:18 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Rafailov", "Rafael", ""], ["Yu", "Tianhe", ""], ["Rajeswaran", "Aravind", ""], ["Finn", "Chelsea", ""]]}, {"id": "2107.08842", "submitter": "Ran Liu", "authors": "Zhiqiang Cao and Ran Liu and Chau Yuen and Achala Athukorala and Benny\n  Kai Kiat Ng and Muraleetharan Mathanraj and U-Xuan Tan", "title": "Relative Localization of Mobile Robots with Multiple Ultra-WideBand\n  Ranging Measurements", "comments": "Accepted by the 2021 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2021), Prague, Czech Republic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Relative localization between autonomous robots without infrastructure is\ncrucial to achieve their navigation, path planning, and formation in many\napplications, such as emergency response, where acquiring a prior knowledge of\nthe environment is not possible. The traditional Ultra-WideBand (UWB)-based\napproach provides a good estimation of the distance between the robots, but\nobtaining the relative pose (including the displacement and orientation)\nremains challenging. We propose an approach to estimate the relative pose\nbetween a group of robots by equipping each robot with multiple UWB ranging\nnodes. We determine the pose between two robots by minimizing the residual\nerror of the ranging measurements from all UWB nodes. To improve the\nlocalization accuracy, we propose to utilize the odometry constraints through a\nsliding window-based optimization. The optimized pose is then fused with the\nodometry in a particle filtering for pose tracking among a group of mobile\nrobots. We have conducted extensive experiments to validate the effectiveness\nof the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 12:57:02 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Cao", "Zhiqiang", ""], ["Liu", "Ran", ""], ["Yuen", "Chau", ""], ["Athukorala", "Achala", ""], ["Ng", "Benny Kai Kiat", ""], ["Mathanraj", "Muraleetharan", ""], ["Tan", "U-Xuan", ""]]}, {"id": "2107.08865", "submitter": "Siwei Chen", "authors": "Siwei Chen, Xiao Ma, Yunfan Lu and David Hsu", "title": "Ab Initio Particle-based Object Manipulation", "comments": "Robotics: Science and Systems (RSS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents Particle-based Object Manipulation (Prompt), a new\napproach to robot manipulation of novel objects ab initio, without prior object\nmodels or pre-training on a large object data set. The key element of Prompt is\na particle-based object representation, in which each particle represents a\npoint in the object, the local geometric, physical, and other features of the\npoint, and also its relation with other particles. Like the model-based\nanalytic approaches to manipulation, the particle representation enables the\nrobot to reason about the object's geometry and dynamics in order to choose\nsuitable manipulation actions. Like the data-driven approaches, the particle\nrepresentation is learned online in real-time from visual sensor input,\nspecifically, multi-view RGB images. The particle representation thus connects\nvisual perception with robot control. Prompt combines the benefits of both\nmodel-based reasoning and data-driven learning. We show empirically that Prompt\nsuccessfully handles a variety of everyday objects, some of which are\ntransparent. It handles various manipulation tasks, including grasping,\npushing, etc,. Our experiments also show that Prompt outperforms a\nstate-of-the-art data-driven grasping method on the daily objects, even though\nit does not use any offline training data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 13:27:00 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chen", "Siwei", ""], ["Ma", "Xiao", ""], ["Lu", "Yunfan", ""], ["Hsu", "David", ""]]}, {"id": "2107.08881", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "Petar Veli\\v{c}kovi\\'c, Matko Bo\\v{s}njak, Thomas Kipf, Alexander\n  Lerchner, Raia Hadsell, Razvan Pascanu, Charles Blundell", "title": "Reasoning-Modulated Representations", "comments": "ICML 2021 Workshop on Self-Supervised Learning for Reasoning and\n  Perception (Spotlight Talk). 7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks leverage robust internal representations in order to\ngeneralise. Learning them is difficult, and often requires a large training set\nthat covers the data distribution densely. We study a common setting where our\ntask is not purely opaque. Indeed, very often we may have access to information\nabout the underlying system (e.g. that observations must obey certain laws of\nphysics) that any \"tabula rasa\" neural network would need to re-learn from\nscratch, penalising data efficiency. We incorporate this information into a\npre-trained reasoning module, and investigate its role in shaping the\ndiscovered representations in diverse self-supervised learning settings from\npixels. Our approach paves the way for a new class of data-efficient\nrepresentation learning.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 13:57:13 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Veli\u010dkovi\u0107", "Petar", ""], ["Bo\u0161njak", "Matko", ""], ["Kipf", "Thomas", ""], ["Lerchner", "Alexander", ""], ["Hadsell", "Raia", ""], ["Pascanu", "Razvan", ""], ["Blundell", "Charles", ""]]}, {"id": "2107.08888", "submitter": "Mingqi Yuan", "authors": "Mingqi Yuan, Mon-on Pun, Yi Chen, Dong Wang, Haojun Li", "title": "Multimodal Reward Shaping for Efficient Exploration in Reinforcement\n  Learning", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Maintaining long-term exploration ability remains one of the challenges of\ndeep reinforcement learning (DRL). In practice, the reward shaping-based\napproaches are leveraged to provide intrinsic rewards for the agent to\nincentivize motivation. However, most existing IRS modules rely on attendant\nmodels or additional memory to record and analyze learning procedures, which\nleads to high computational complexity and low robustness. Moreover, they\noveremphasize the influence of a single state on exploration, which cannot\nevaluate the exploration performance from a global perspective. To tackle the\nproblem, state entropy-based methods are proposed to encourage the agent to\nvisit the state space more equitably. However, the estimation error and sample\ncomplexity are prohibitive when handling environments with high-dimensional\nobservation. In this paper, we introduce a novel metric entitled Jain's\nfairness index (JFI) to replace the entropy regularizer, which requires no\nadditional models or memory. In particular, JFI overcomes the vanishing\nintrinsic rewards problem and can be generalized into arbitrary tasks.\nFurthermore, we use a variational auto-encoder (VAE) model to capture the\nlife-long novelty of states. Finally, the global JFI score and local state\nnovelty are combined to form a multimodal intrinsic reward, controlling the\nexploration extent more precisely. Finally, extensive simulation results\ndemonstrate that our multimodal reward shaping (MMRS) method can achieve higher\nperformance in contrast to other benchmark schemes.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:04:32 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Yuan", "Mingqi", ""], ["Pun", "Mon-on", ""], ["Chen", "Yi", ""], ["Wang", "Dong", ""], ["Li", "Haojun", ""]]}, {"id": "2107.08908", "submitter": "Tarik A. Rashid", "authors": "Aram Ahmed, Tarik A. Rashid and Soran Saeed", "title": "Dynamic Cat Swarm Optimization Algorithm for Backboard Wiring Problem", "comments": "22 pages", "journal-ref": "Neural Computing and Applications, 2021", "doi": "10.1007/s00521-021-06041-3", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper presents a powerful swarm intelligence meta-heuristic optimization\nalgorithm called Dynamic Cat Swarm Optimization. The formulation is through\nmodifying the existing Cat Swarm Optimization. The original Cat Swarm\nOptimization suffers from the shortcoming of 'premature convergence', which is\nthe possibility of entrapment in local optima which usually happens due to the\noff-balance between exploration and exploitation phases. Therefore, the\nproposed algorithm suggests a new method to provide a proper balance between\nthese phases by modifying the selection scheme and the seeking mode of the\nalgorithm. To evaluate the performance of the proposed algorithm, 23 classical\ntest functions, 10 modern test functions (CEC 2019) and a real world scenario\nare used. In addition, the Dimension-wise diversity metric is used to measure\nthe percentage of the exploration and exploitation phases. The optimization\nresults show the effectiveness of the proposed algorithm, which ranks first\ncompared to several well-known algorithms available in the literature.\nFurthermore, statistical methods and graphs are also used to further confirm\nthe outperformance of the algorithm. Finally, the conclusion as well as future\ndirections to further improve the algorithm are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 19:41:27 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ahmed", "Aram", ""], ["Rashid", "Tarik A.", ""], ["Saeed", "Soran", ""]]}, {"id": "2107.08924", "submitter": "Ian Osband", "authors": "Ian Osband, Zheng Wen, Mohammad Asghari, Morteza Ibrahimi, Xiyuan Lu,\n  and Benjamin Van Roy", "title": "Epistemic Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the \\textit{epistemic neural network} (ENN) as an interface for\nuncertainty modeling in deep learning. All existing approaches to uncertainty\nmodeling can be expressed as ENNs, and any ENN can be identified with a\nBayesian neural network. However, this new perspective provides several\npromising directions for future research. Where prior work has developed\nprobabilistic inference tools for neural networks; we ask instead, `which\nneural networks are suitable as tools for probabilistic inference?'. We propose\na clear and simple metric for progress in ENNs: the KL-divergence with respect\nto a target distribution. We develop a computational testbed based on inference\nin a neural network Gaussian process and release our code as a benchmark at\n\\url{https://github.com/deepmind/enn}. We evaluate several canonical approaches\nto uncertainty modeling in deep learning, and find they vary greatly in their\nperformance. We provide insight to the sensitivity of these results and show\nthat our metric is highly correlated with performance in sequential decision\nproblems. Finally, we provide indications that new ENN architectures can\nimprove performance in both the statistical quality and computational cost.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:37:57 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Osband", "Ian", ""], ["Wen", "Zheng", ""], ["Asghari", "Mohammad", ""], ["Ibrahimi", "Morteza", ""], ["Lu", "Xiyuan", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "2107.08939", "submitter": "Seung-Hun Nam", "authors": "Seung-Hun Nam, Wonhyuk Ahn, Myung-Joon Kwon, In-Jae Yu", "title": "Detection of Double Compression in MPEG-4 Videos Using Refined\n  Features-based CNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Double compression is accompanied by various types of video manipulation and\nits traces can be exploited to determine whether a video is a forgery. This\nLetter presents a convolutional neural network for detecting double compression\nin MPEG-4 videos. Through analysis of the intra-coding process, we utilize two\nrefined features for capturing the subtle artifacts caused by double\ncompression. The discrete cosine transform (DCT) histogram feature effectively\ndetects the change of statistical characteristics in DCT coefficients and the\nparameter-based feature is utilized as auxiliary information to help the\nnetwork learn double compression artifacts. When compared with state-of-the-art\nnetworks and forensic method, the results show that the proposed approach\nachieves a higher performance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:53:17 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Nam", "Seung-Hun", ""], ["Ahn", "Wonhyuk", ""], ["Kwon", "Myung-Joon", ""], ["Yu", "In-Jae", ""]]}, {"id": "2107.08942", "submitter": "Priya Sundaresan", "authors": "Priya Sundaresan, Jennifer Grannen, Brijen Thananjeyan, Ashwin\n  Balakrishna, Jeffrey Ichnowski, Ellen Novoseller, Minho Hwang, Michael\n  Laskey, Joseph E. Gonzalez, Ken Goldberg", "title": "Untangling Dense Non-Planar Knots by Learning Manipulation Features and\n  Recovery Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot manipulation for untangling 1D deformable structures such as ropes,\ncables, and wires is challenging due to their infinite dimensional\nconfiguration space, complex dynamics, and tendency to self-occlude. Analytical\ncontrollers often fail in the presence of dense configurations, due to the\ndifficulty of grasping between adjacent cable segments. We present two\nalgorithms that enhance robust cable untangling, LOKI and SPiDERMan, which\noperate alongside HULK, a high-level planner from prior work. LOKI uses a\nlearned model of manipulation features to refine a coarse grasp keypoint\nprediction to a precise, optimized location and orientation, while SPiDERMan\nuses a learned model to sense task progress and apply recovery actions. We\nevaluate these algorithms in physical cable untangling experiments with 336\nknots and over 1500 actions on real cables using the da Vinci surgical robot.\nWe find that the combination of HULK, LOKI, and SPiDERMan is able to untangle\ndense overhand, figure-eight, double-overhand, square, bowline, granny,\nstevedore, and triple-overhand knots. The composition of these methods\nsuccessfully untangles a cable from a dense initial configuration in 68.3% of\n60 physical experiments and achieves 50% higher success rates than baselines\nfrom prior work. Supplementary material, code, and videos can be found at\nhttps://tinyurl.com/rssuntangling.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 04:13:14 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Sundaresan", "Priya", ""], ["Grannen", "Jennifer", ""], ["Thananjeyan", "Brijen", ""], ["Balakrishna", "Ashwin", ""], ["Ichnowski", "Jeffrey", ""], ["Novoseller", "Ellen", ""], ["Hwang", "Minho", ""], ["Laskey", "Michael", ""], ["Gonzalez", "Joseph E.", ""], ["Goldberg", "Ken", ""]]}, {"id": "2107.08959", "submitter": "Matthew Sun", "authors": "Eli Lucherini, Matthew Sun, Amy Winecoff, Arvind Narayanan", "title": "T-RECS: A Simulation Tool to Study the Societal Impact of Recommender\n  Systems", "comments": "17 pages, 5 figures; updated Figure 2(b) after fixing small bug in\n  replication code (see Github for more details)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation has emerged as a popular method to study the long-term societal\nconsequences of recommender systems. This approach allows researchers to\nspecify their theoretical model explicitly and observe the evolution of\nsystem-level outcomes over time. However, performing simulation-based studies\noften requires researchers to build their own simulation environments from the\nground up, which creates a high barrier to entry, introduces room for\nimplementation error, and makes it difficult to disentangle whether observed\noutcomes are due to the model or the implementation.\n  We introduce T-RECS, an open-sourced Python package designed for researchers\nto simulate recommendation systems and other types of sociotechnical systems in\nwhich an algorithm mediates the interactions between multiple stakeholders,\nsuch as users and content creators. To demonstrate the flexibility of T-RECS,\nwe perform a replication of two prior simulation-based research on\nsociotechnical systems. We additionally show how T-RECS can be used to generate\nnovel insights with minimal overhead. Our tool promotes reproducibility in this\narea of research, provides a unified language for simulating sociotechnical\nsystems, and removes the friction of implementing simulations from scratch.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 15:16:44 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 00:52:04 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Lucherini", "Eli", ""], ["Sun", "Matthew", ""], ["Winecoff", "Amy", ""], ["Narayanan", "Arvind", ""]]}, {"id": "2107.08966", "submitter": "Lukas Sch\\\"afer", "authors": "Lukas Sch\\\"afer, Filippos Christianos, Josiah Hanna, Stefano V.\n  Albrecht", "title": "Decoupling Exploration and Exploitation in Reinforcement Learning", "comments": "Unsupervised Reinforcement Learning (URL) Workshop in the 38th\n  International Conference on Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsic rewards are commonly applied to improve exploration in\nreinforcement learning. However, these approaches suffer from instability\ncaused by non-stationary reward shaping and strong dependency on\nhyperparameters. In this work, we propose Decoupled RL (DeRL) which trains\nseparate policies for exploration and exploitation. DeRL can be applied with\non-policy and off-policy RL algorithms. We evaluate DeRL algorithms in two\nsparse-reward environments with multiple types of intrinsic rewards. We show\nthat DeRL is more robust to scaling and speed of decay of intrinsic rewards and\nconverges to the same evaluation returns than intrinsically motivated baselines\nin fewer interactions.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 15:31:02 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 18:50:01 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Sch\u00e4fer", "Lukas", ""], ["Christianos", "Filippos", ""], ["Hanna", "Josiah", ""], ["Albrecht", "Stefano V.", ""]]}, {"id": "2107.08981", "submitter": "Kourosh Hakhamaneshi", "authors": "Kourosh Hakhamaneshi, Ruihan Zhao, Albert Zhan, Pieter Abbeel, Michael\n  Laskin", "title": "Hierarchical Few-Shot Imitation with Skill Transition Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A desirable property of autonomous agents is the ability to both solve\nlong-horizon problems and generalize to unseen tasks. Recent advances in\ndata-driven skill learning have shown that extracting behavioral priors from\noffline data can enable agents to solve challenging long-horizon tasks with\nreinforcement learning. However, generalization to tasks unseen during\nbehavioral prior training remains an outstanding challenge. To this end, we\npresent Few-shot Imitation with Skill Transition Models (FIST), an algorithm\nthat extracts skills from offline data and utilizes them to generalize to\nunseen tasks given a few downstream demonstrations. FIST learns an inverse\nskill dynamics model, a distance function, and utilizes a semi-parametric\napproach for imitation. We show that FIST is capable of generalizing to new\ntasks and substantially outperforms prior baselines in navigation experiments\nrequiring traversing unseen parts of a large maze and 7-DoF robotic arm\nexperiments requiring manipulating previously unseen objects in a kitchen.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 15:56:01 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Hakhamaneshi", "Kourosh", ""], ["Zhao", "Ruihan", ""], ["Zhan", "Albert", ""], ["Abbeel", "Pieter", ""], ["Laskin", "Michael", ""]]}, {"id": "2107.08988", "submitter": "Ndivhuwo Makondo", "authors": "Ndivhuwo Makondo, Arinze Lawrence Folarin, Simphiwe Nhlahla Zitha,\n  Sekou Lionel Remy", "title": "An Analysis of Reinforcement Learning for Malaria Control", "comments": "27 pages including appendix and references. Submitted to the Journal\n  of Artificial Intelligence Research (JAIR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work on policy learning for Malaria control has often formulated the\nproblem as an optimization problem assuming the objective function and the\nsearch space have a specific structure. The problem has been formulated as\nmulti-armed bandits, contextual bandits and a Markov Decision Process in\nisolation. Furthermore, an emphasis is put on developing new algorithms\nspecific to an instance of Malaria control, while ignoring a plethora of\nsimpler and general algorithms in the literature. In this work, we formally\nstudy the formulation of Malaria control and present a comprehensive analysis\nof several formulations used in the literature. In addition, we implement and\nanalyze several reinforcement learning algorithms in all formulations and\ncompare them to black box optimization. In contrast to previous work, our\nresults show that simple algorithms based on Upper Confidence Bounds are\nsufficient for learning good Malaria policies, and tend to outperform their\nmore advanced counterparts on the malaria OpenAI Gym environment.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 16:00:40 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Makondo", "Ndivhuwo", ""], ["Folarin", "Arinze Lawrence", ""], ["Zitha", "Simphiwe Nhlahla", ""], ["Remy", "Sekou Lionel", ""]]}, {"id": "2107.09003", "submitter": "Haoran Xu", "authors": "Haoran Xu, Xianyuan Zhan, Xiangyu Zhu", "title": "Constraints Penalized Q-Learning for Safe Offline Reinforcement Learning", "comments": "Accepted by RL4RealLife workshop in ICML 2021, appendix included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the problem of safe offline reinforcement learning (RL), the goal is\nto learn a policy that maximizes long-term reward while satisfying safety\nconstraints given only offline data, without further interaction with the\nenvironment. This problem is more appealing for real world RL applications, in\nwhich data collection is costly or dangerous. Enforcing constraint satisfaction\nis non-trivial, especially in offline settings, as there is a potential large\ndiscrepancy between the policy distribution and the data distribution, causing\nerrors in estimating the value of safety constraints. We show that na\\\"ive\napproaches that combine techniques from safe RL and offline RL can only learn\nsub-optimal solutions. We thus develop a simple yet effective algorithm,\nConstraints Penalized Q-Learning (CPQ), to solve the problem. Our method admits\nthe use of data generated by mixed behavior policies. We present a theoretical\nanalysis and demonstrate empirically that our approach can learn robustly\nacross a variety of benchmark control tasks, outperforming several baselines.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 16:30:14 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Xu", "Haoran", ""], ["Zhan", "Xianyuan", ""], ["Zhu", "Xiangyu", ""]]}, {"id": "2107.09016", "submitter": "Debayan Ganguly", "authors": "Diptakshi Sen, Rupam Kumar Roy, Ritajit Majumdar, Kingshuk Chatterjee,\n  Debayan Ganguly", "title": "Prediction of the final rank of Players in PUBG with the optimal number\n  of features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  PUBG is an online video game that has become very popular among the youths in\nrecent years. Final rank, which indicates the performance of a player, is one\nof the most important feature for this game. This paper focuses on predicting\nthe final rank of the players based on their skills and abilities. In this\npaper we have used different machine learning algorithms to predict the final\nrank of the players on a dataset obtained from kaggle which has 29 features.\nUsing the correlation heatmap,we have varied the number of features used for\nthe model. Out of these models GBR and LGBM have given the best result with the\naccuracy of 91.63% and 91.26% respectively for 14 features and the accuracy of\n90.54% and 90.01% for 8 features. Although the accuracy of the models with 14\nfeatures is slightly better than 8 features, the empirical time taken by 8\nfeatures is 1.4x lesser than 14 features for LGBM and 1.5x lesser for GBR.\nFurthermore, reducing the number of features any more significantly hampers the\nperformance of all the ML models. Therefore, we conclude that 8 is the optimal\nnumber of features that can be used to predict the final rank of a player in\nPUBG with high accuracy and low run-time.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 07:44:45 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Sen", "Diptakshi", ""], ["Roy", "Rupam Kumar", ""], ["Majumdar", "Ritajit", ""], ["Chatterjee", "Kingshuk", ""], ["Ganguly", "Debayan", ""]]}, {"id": "2107.09044", "submitter": "Evan Liu", "authors": "Evan Zheran Liu, Behzad Haghgoo, Annie S. Chen, Aditi Raghunathan,\n  Pang Wei Koh, Shiori Sagawa, Percy Liang, Chelsea Finn", "title": "Just Train Twice: Improving Group Robustness without Training Group\n  Information", "comments": "International Conference on Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard training via empirical risk minimization (ERM) can produce models\nthat achieve high accuracy on average but low accuracy on certain groups,\nespecially in the presence of spurious correlations between the input and\nlabel. Prior approaches that achieve high worst-group accuracy, like group\ndistributionally robust optimization (group DRO) require expensive group\nannotations for each training point, whereas approaches that do not use such\ngroup annotations typically achieve unsatisfactory worst-group accuracy. In\nthis paper, we propose a simple two-stage approach, JTT, that first trains a\nstandard ERM model for several epochs, and then trains a second model that\nupweights the training examples that the first model misclassified.\nIntuitively, this upweights examples from groups on which standard ERM models\nperform poorly, leading to improved worst-group performance. Averaged over four\nimage classification and natural language processing tasks with spurious\ncorrelations, JTT closes 75% of the gap in worst-group accuracy between\nstandard ERM and group DRO, while only requiring group annotations on a small\nvalidation set in order to tune hyperparameters.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 17:52:32 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Liu", "Evan Zheran", ""], ["Haghgoo", "Behzad", ""], ["Chen", "Annie S.", ""], ["Raghunathan", "Aditi", ""], ["Koh", "Pang Wei", ""], ["Sagawa", "Shiori", ""], ["Liang", "Percy", ""], ["Finn", "Chelsea", ""]]}, {"id": "2107.09045", "submitter": "Verena Praher", "authors": "Verena Praher, Katharina Prinz, Arthur Flexer, Gerhard Widmer", "title": "On the Veracity of Local, Model-agnostic Explanations in Audio\n  Classification: Targeted Investigations with Adversarial Examples", "comments": "8 pages, 4 figures, to be published in Proceedings of the\n  International Society for Music Information Retrieval Conference 2021 (ISMIR\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Local explanation methods such as LIME have become popular in MIR as tools\nfor generating post-hoc, model-agnostic explanations of a model's\nclassification decisions. The basic idea is to identify a small set of\nhuman-understandable features of the classified example that are most\ninfluential on the classifier's prediction. These are then presented as an\nexplanation. Evaluation of such explanations in publications often resorts to\naccepting what matches the expectation of a human without actually being able\nto verify if what the explanation shows is what really caused the model's\nprediction. This paper reports on targeted investigations where we try to get\nmore insight into the actual veracity of LIME's explanations in an audio\nclassification task. We deliberately design adversarial examples for the\nclassifier, in a way that gives us knowledge about which parts of the input are\npotentially responsible for the model's (wrong) prediction. Asking LIME to\nexplain the predictions for these adversaries permits us to study whether local\nexplanations do indeed detect these regions of interest. We also look at\nwhether LIME is more successful in finding perturbations that are more\nprominent and easily noticeable for a human. Our results suggest that LIME does\nnot necessarily manage to identify the most relevant input features and hence\nit remains unclear whether explanations are useful or even misleading.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 17:54:10 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Praher", "Verena", ""], ["Prinz", "Katharina", ""], ["Flexer", "Arthur", ""], ["Widmer", "Gerhard", ""]]}, {"id": "2107.09046", "submitter": "Sarah Young", "authors": "Sarah Young, Jyothish Pari, Pieter Abbeel, Lerrel Pinto", "title": "Playful Interactions for Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the key challenges in visual imitation learning is collecting large\namounts of expert demonstrations for a given task. While methods for collecting\nhuman demonstrations are becoming easier with teleoperation methods and the use\nof low-cost assistive tools, we often still require 100-1000 demonstrations for\nevery task to learn a visual representation and policy. To address this, we\nturn to an alternate form of data that does not require task-specific\ndemonstrations -- play. Playing is a fundamental method children use to learn a\nset of skills and behaviors and visual representations in early learning.\nImportantly, play data is diverse, task-agnostic, and relatively cheap to\nobtain. In this work, we propose to use playful interactions in a\nself-supervised manner to learn visual representations for downstream tasks. We\ncollect 2 hours of playful data in 19 diverse environments and use\nself-predictive learning to extract visual representations. Given these\nrepresentations, we train policies using imitation learning for two downstream\ntasks: Pushing and Stacking. We demonstrate that our visual representations\ngeneralize better than standard behavior cloning and can achieve similar\nperformance with only half the number of required demonstrations. Our\nrepresentations, which are trained from scratch, compare favorably against\nImageNet pretrained representations. Finally, we provide an experimental\nanalysis on the effects of different pretraining modes on downstream task\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 17:54:48 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Young", "Sarah", ""], ["Pari", "Jyothish", ""], ["Abbeel", "Pieter", ""], ["Pinto", "Lerrel", ""]]}, {"id": "2107.09049", "submitter": "Li Chen", "authors": "Li Chen, Wenjin Liu, Niranjan Balu, Mahmud Mossa-Basha, Thomas S.\n  Hatsukami, Jenq-Neng Hwang, Chun Yuan", "title": "Deep Open Snake Tracker for Vessel Tracing", "comments": "MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vessel tracing by modeling vascular structures in 3D medical images with\ncenterlines and radii can provide useful information for vascular health.\nExisting algorithms have been developed but there are certain persistent\nproblems such as incomplete or inaccurate vessel tracing, especially in\ncomplicated vascular beds like the intracranial arteries. We propose here a\ndeep learning based open curve active contour model (DOST) to trace vessels in\n3D images. Initial curves were proposed from a centerline segmentation neural\nnetwork. Then data-driven machine knowledge was used to predict the stretching\ndirection and vessel radius of the initial curve, while the active contour\nmodel (as human knowledge) maintained smoothness and intensity fitness of\ncurves. Finally, considering the nonloop topology of most vasculatures,\nindividually traced vessels were connected into a tree topology by applying a\nminimum spanning tree algorithm on a global connection graph. We evaluated DOST\non a Time-of-Flight (TOF) MRA intracranial artery dataset and demonstrated its\nsuperior performance over existing segmentation-based and tracking-based vessel\ntracing methods. In addition, DOST showed strong adaptability on different\nimaging modalities (CTA, MR T1 SPACE) and vascular beds (coronary arteries).\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 17:59:31 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chen", "Li", ""], ["Liu", "Wenjin", ""], ["Balu", "Niranjan", ""], ["Mossa-Basha", "Mahmud", ""], ["Hatsukami", "Thomas S.", ""], ["Hwang", "Jenq-Neng", ""], ["Yuan", "Chun", ""]]}, {"id": "2107.09051", "submitter": "Longbing Cao", "authors": "Longbing Cao", "title": "AI in Finance: Challenges, Techniques and Opportunities", "comments": "The paper is in the revision for ACM Computing Surveys, 40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.AI cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI in finance broadly refers to the applications of AI techniques in\nfinancial businesses. This area has been lasting for decades with both classic\nand modern AI techniques applied to increasingly broader areas of finance,\neconomy and society. In contrast to either discussing the problems, aspects and\nopportunities of finance that have benefited from specific AI techniques and in\nparticular some new-generation AI and data science (AIDS) areas or reviewing\nthe progress of applying specific techniques to resolving certain financial\nproblems, this review offers a comprehensive and dense roadmap of the\noverwhelming challenges, techniques and opportunities of AI research in finance\nover the past decades. The landscapes and challenges of financial businesses\nand data are firstly outlined, followed by a comprehensive categorization and a\ndense overview of the decades of AI research in finance. We then structure and\nillustrate the data-driven analytics and learning of financial businesses and\ndata. The comparison, criticism and discussion of classic vs. modern AI\ntechniques for finance are followed. Lastly, open issues and opportunities\naddress future AI-empowered finance and finance-motivated AI research.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 01:39:10 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Cao", "Longbing", ""]]}, {"id": "2107.09060", "submitter": "Thomas K\\\"ustner", "authors": "Thomas K\\\"ustner, Jiazhen Pan, Haikun Qi, Gastao Cruz, Christopher\n  Gilliam, Thierry Blu, Bin Yang, Sergios Gatidis, Ren\\'e Botnar, Claudia\n  Prieto", "title": "LAPNet: Non-rigid Registration derived in k-space for Magnetic Resonance\n  Imaging", "comments": null, "journal-ref": null, "doi": "10.1109/TMI.2021.3096131", "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Physiological motion, such as cardiac and respiratory motion, during Magnetic\nResonance (MR) image acquisition can cause image artifacts. Motion correction\ntechniques have been proposed to compensate for these types of motion during\nthoracic scans, relying on accurate motion estimation from undersampled\nmotion-resolved reconstruction. A particular interest and challenge lie in the\nderivation of reliable non-rigid motion fields from the undersampled\nmotion-resolved data. Motion estimation is usually formulated in image space\nvia diffusion, parametric-spline, or optical flow methods. However, image-based\nregistration can be impaired by remaining aliasing artifacts due to the\nundersampled motion-resolved reconstruction. In this work, we describe a\nformalism to perform non-rigid registration directly in the sampled Fourier\nspace, i.e. k-space. We propose a deep-learning based approach to perform fast\nand accurate non-rigid registration from the undersampled k-space data. The\nbasic working principle originates from the Local All-Pass (LAP) technique, a\nrecently introduced optical flow-based registration. The proposed LAPNet is\ncompared against traditional and deep learning image-based registrations and\ntested on fully-sampled and highly-accelerated (with two undersampling\nstrategies) 3D respiratory motion-resolved MR images in a cohort of 40 patients\nwith suspected liver or lung metastases and 25 healthy subjects. The proposed\nLAPNet provided consistent and superior performance to image-based approaches\nthroughout different sampling trajectories and acceleration factors.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 15:39:23 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["K\u00fcstner", "Thomas", ""], ["Pan", "Jiazhen", ""], ["Qi", "Haikun", ""], ["Cruz", "Gastao", ""], ["Gilliam", "Christopher", ""], ["Blu", "Thierry", ""], ["Yang", "Bin", ""], ["Gatidis", "Sergios", ""], ["Botnar", "Ren\u00e9", ""], ["Prieto", "Claudia", ""]]}, {"id": "2107.09088", "submitter": "Dylan Ashley", "authors": "Miroslav \\v{S}trupl, Francesco Faccio, Dylan R. Ashley, Rupesh Kumar\n  Srivastava, J\\\"urgen Schmidhuber", "title": "Reward-Weighted Regression Converges to a Global Optimum", "comments": "10 pages in main text + 2 pages of references + 4 pages of\n  appendices, 2 figures in main text; source code available at\n  https://github.com/dylanashley/reward-weighted-regression", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reward-Weighted Regression (RWR) belongs to a family of widely known\niterative Reinforcement Learning algorithms based on the\nExpectation-Maximization framework. In this family, learning at each iteration\nconsists of sampling a batch of trajectories using the current policy and\nfitting a new policy to maximize a return-weighted log-likelihood of actions.\nAlthough RWR is known to yield monotonic improvement of the policy under\ncertain circumstances, whether and under which conditions RWR converges to the\noptimal policy have remained open questions. In this paper, we provide for the\nfirst time a proof that RWR converges to a global optimum when no function\napproximation is used.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 18:01:04 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["\u0160trupl", "Miroslav", ""], ["Faccio", "Francesco", ""], ["Ashley", "Dylan R.", ""], ["Srivastava", "Rupesh Kumar", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "2107.09119", "submitter": "Muhammad Najib", "authors": "Julian Gutierrez, Lewis Hammond, Anthony W. Lin, Muhammad Najib,\n  Michael Wooldridge", "title": "Rational Verification for Probabilistic Systems", "comments": "18th International Conference on Principles of Knowledge\n  Representation and Reasoning (KR 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Rational verification is the problem of determining which temporal logic\nproperties will hold in a multi-agent system, under the assumption that agents\nin the system act rationally, by choosing strategies that collectively form a\ngame-theoretic equilibrium. Previous work in this area has largely focussed on\ndeterministic systems. In this paper, we develop the theory and algorithms for\nrational verification in probabilistic systems. We focus on concurrent\nstochastic games (CSGs), which can be used to model uncertainty and randomness\nin complex multi-agent environments. We study the rational verification problem\nfor both non-cooperative games and cooperative games in the qualitative\nprobabilistic setting. In the former case, we consider LTL properties satisfied\nby the Nash equilibria of the game and in the latter case LTL properties\nsatisfied by the core. In both cases, we show that the problem is\n2EXPTIME-complete, thus not harder than the much simpler verification problem\nof model checking LTL properties of systems modelled as Markov decision\nprocesses (MDPs).\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 19:24:16 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 09:52:31 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Gutierrez", "Julian", ""], ["Hammond", "Lewis", ""], ["Lin", "Anthony W.", ""], ["Najib", "Muhammad", ""], ["Wooldridge", "Michael", ""]]}, {"id": "2107.09123", "submitter": "Rohit Verma", "authors": "Tanmay Jain, Avaneesh, Rohit Verma, Rajeev Shorey", "title": "Latency-Memory Optimized Splitting of Convolution Neural Networks for\n  Resource Constrained Edge Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing reliance of users on smart devices, bringing essential\ncomputation at the edge has become a crucial requirement for any type of\nbusiness. Many such computations utilize Convolution Neural Networks (CNNs) to\nperform AI tasks, having high resource and computation requirements, that are\ninfeasible for edge devices. Splitting the CNN architecture to perform part of\nthe computation on edge and remaining on the cloud is an area of research that\nhas seen increasing interest in the field. In this paper, we assert that\nrunning CNNs between an edge device and the cloud is synonymous to solving a\nresource-constrained optimization problem that minimizes the latency and\nmaximizes resource utilization at the edge. We formulate a multi-objective\noptimization problem and propose the LMOS algorithm to achieve a Pareto\nefficient solution. Experiments done on real-world edge devices show that, LMOS\nensures feasible execution of different CNN models at the edge and also\nimproves upon existing state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 19:39:56 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Jain", "Tanmay", ""], ["Avaneesh", "", ""], ["Verma", "Rohit", ""], ["Shorey", "Rajeev", ""]]}, {"id": "2107.09129", "submitter": "Luis Olsina PhD", "authors": "Luis Olsina", "title": "ThingFO v1.2's Terms, Properties, Relationships and Axioms --\n  Foundational Ontology for Things", "comments": "9 pgs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The present preprint specifies and defines all Terms, Properties,\nRelationships and Axioms of ThingFO (Thing Foundational Ontology) v1.2, which\nis a slightly updated version of its predecessor, ThingFO v1.1. It is an\nontology for particular and universal Things placed at the foundational level\nin the context of a four-layered ontological architecture named FCD-OntoArch\n(Foundational, Core, and Domain Ontological Architecture for Sciences). This is\na five-layered ontological architecture, which considers Foundational, Core,\nDomain and Instance levels. In turn, the domain level is split down in two\nsub-levels, namely: Top-domain and Low-domain. Ontologies at the same level can\nbe related to each other, except for the foundational level where only the\nThingFO ontology is. In addition, ontologies' terms and relationships at lower\nlevels can be semantically enriched by ontologies' terms and relationships from\nthe higher levels. ThingFO and ontologies at the core level such as\nSituationCO, ProcessCO, ProjectCO, among others, are domain independent.\nThingFO is made up of three main concepts, namely: Thing with the semantics of\nParticular, Thing Category with the semantics of Universal, and Assertion that\nrepresents human statements about different aspects of Particulars and\nUniversals. Note that annotations of updates from the previous version (v1.1)\nto the current one (v1.2) can be found in Appendix A.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 20:04:05 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Olsina", "Luis", ""]]}, {"id": "2107.09134", "submitter": "Daniel M\\'ario Lima", "authors": "Daniel Lima, Catharine Graves, Marco Gutierrez, Bruno Brandoli, Jose\n  Rodrigues-Jr", "title": "Convolutional module for heart localization and segmentation in MRI", "comments": "Submitted to CMIG", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Magnetic resonance imaging (MRI) is a widely known medical imaging technique\nused to assess the heart function. Deep learning (DL) models perform several\ntasks in cardiac MRI (CMR) images with good efficacy, such as segmentation,\nestimation, and detection of diseases. Many DL models based on convolutional\nneural networks (CNN) were improved by detecting regions-of-interest (ROI)\neither automatically or by hand. In this paper we describe Visual-Motion-Focus\n(VMF), a module that detects the heart motion in the 4D MRI sequence, and\nhighlights ROIs by focusing a Radial Basis Function (RBF) on the estimated\nmotion field. We experimented and evaluated VMF on three CMR datasets,\nobserving that the proposed ROIs cover 99.7% of data labels (Recall score),\nimproved the CNN segmentation (mean Dice score) by 1.7 (p < .001) after the ROI\nextraction, and improved the overall training speed by 2.5 times (+150%).\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 20:19:40 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Lima", "Daniel", ""], ["Graves", "Catharine", ""], ["Gutierrez", "Marco", ""], ["Brandoli", "Bruno", ""], ["Rodrigues-Jr", "Jose", ""]]}, {"id": "2107.09170", "submitter": "Juan Pablo De Vicente", "authors": "Juan Pablo de Vicente, Alvaro Soto", "title": "DeepSocNav: Social Navigation by Imitating Human Behaviors", "comments": "6 pages, Accepted paper at the RSS Workshop on Social Robot\n  Navigation 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current datasets to train social behaviors are usually borrowed from\nsurveillance applications that capture visual data from a bird's-eye\nperspective. This leaves aside precious relationships and visual cues that\ncould be captured through a first-person view of a scene. In this work, we\npropose a strategy to exploit the power of current game engines, such as Unity,\nto transform pre-existing bird's-eye view datasets into a first-person view, in\nparticular, a depth view. Using this strategy, we are able to generate large\nvolumes of synthetic data that can be used to pre-train a social navigation\nmodel. To test our ideas, we present DeepSocNav, a deep learning based model\nthat takes advantage of the proposed approach to generate synthetic data.\nFurthermore, DeepSocNav includes a self-supervised strategy that is included as\nan auxiliary task. This consists of predicting the next depth frame that the\nagent will face. Our experiments show the benefits of the proposed model that\nis able to outperform relevant baselines in terms of social navigation scores.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 21:51:06 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["de Vicente", "Juan Pablo", ""], ["Soto", "Alvaro", ""]]}, {"id": "2107.09232", "submitter": "Kenta Hongo", "authors": "Keishu Utimula, Ken-taro Hayaschi, Kousuke Nakano, Kenta Hongo, Ryo\n  Maezono", "title": "Reinforcement learning autonomously identifying the source of errors for\n  agents in a group mission", "comments": "4 pages, 1 figure. References added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When agents are swarmed to carry out a mission, there is often a sudden\nfailure of some of the agents observed from the command base. It is generally\ndifficult to distinguish whether the failure is caused by actuators\n(hypothesis, $h_a$) or sensors (hypothesis, $h_s$) solely by the communication\nbetween the command base and the concerning agent. By making a collision to the\nagent by another, we would be able to distinguish which hypothesis is likely:\nFor $h_a$, we expect to detect corresponding displacements while for $h_a$ we\ndo not. Such swarm strategies to grasp the situation are preferably to be\ngenerated autonomously by artificial intelligence (AI). Preferable actions\n($e.g.$, the collision) for the distinction would be those maximizing the\ndifference between the expected behaviors for each hypothesis, as a value\nfunction. Such actions exist, however, only very sparsely in the whole\npossibilities, for which the conventional search based on gradient methods does\nnot make sense. Instead, we have successfully applied the reinforcement\nlearning technique, achieving the maximization of such a sparse value function.\nThe machine learning actually concluded autonomously the colliding action to\ndistinguish the hypothesises. Getting recognized an agent with actuator error\nby the action, the agents behave as if other ones want to assist the\nmalfunctioning one to achieve a given mission.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 02:40:19 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 01:20:22 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Utimula", "Keishu", ""], ["Hayaschi", "Ken-taro", ""], ["Nakano", "Kousuke", ""], ["Hongo", "Kenta", ""], ["Maezono", "Ryo", ""]]}, {"id": "2107.09244", "submitter": "Li Shen", "authors": "Li Shen, Yao Lu, Hao Chen, Hao Wei, Donghai Xie, Jiabao Yue, Rui Chen,\n  Yue Zhang, Ao Zhang, Shouye Lv, Bitao Jiang", "title": "S2Looking: A Satellite Side-Looking Dataset for Building Change\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Collecting large-scale annotated satellite imagery datasets is essential for\ndeep-learning-based global building change surveillance. In particular, the\nscroll imaging mode of optical satellites enables larger observation ranges and\nshorter revisit periods, facilitating efficient global surveillance. However,\nthe images in recent satellite change detection datasets are mainly captured at\nnear-nadir viewing angles. In this paper, we introduce S2Looking, a building\nchange detection dataset that contains large-scale side-looking satellite\nimages captured at varying off-nadir angles. Our S2Looking dataset consists of\n5000 registered bitemporal image pairs (size of 1024*1024, 0.5 ~ 0.8 m/pixel)\nof rural areas throughout the world and more than 65,920 annotated change\ninstances. We provide two label maps to separately indicate the newly built and\ndemolished building regions for each sample in the dataset. We establish a\nbenchmark task based on this dataset, i.e., identifying the pixel-level\nbuilding changes in the bi-temporal images. We test several state-of-the-art\nmethods on both the S2Looking dataset and the (near-nadir) LEVIR-CD+ dataset.\nThe experimental results show that recent change detection methods exhibit much\npoorer performance on the S2Looking than on LEVIR-CD+. The proposed S2Looking\ndataset presents three main challenges: 1) large viewing angle changes, 2)\nlarge illumination variances and 3) various complex scene characteristics\nencountered in rural areas. Our proposed dataset may promote the development of\nalgorithms for satellite image change detection and registration under\nconditions of large off-nadir angles. The dataset is available at\nhttps://github.com/AnonymousForACMMM/.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 03:31:00 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Shen", "Li", ""], ["Lu", "Yao", ""], ["Chen", "Hao", ""], ["Wei", "Hao", ""], ["Xie", "Donghai", ""], ["Yue", "Jiabao", ""], ["Chen", "Rui", ""], ["Zhang", "Yue", ""], ["Zhang", "Ao", ""], ["Lv", "Shouye", ""], ["Jiang", "Bitao", ""]]}, {"id": "2107.09262", "submitter": "Sanchita Ghose", "authors": "Sanchita Ghose and John J. Prevost", "title": "FoleyGAN: Visually Guided Generative Adversarial Network-Based\n  Synchronous Sound Generation in Silent Videos", "comments": "This article is under review in IEEE Transaction on Multimedia. It\n  contains total 12 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.MM cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning based visual to sound generation systems essentially need to be\ndeveloped particularly considering the synchronicity aspects of visual and\naudio features with time. In this research we introduce a novel task of guiding\na class conditioned generative adversarial network with the temporal visual\ninformation of a video input for visual to sound generation task adapting the\nsynchronicity traits between audio-visual modalities. Our proposed FoleyGAN\nmodel is capable of conditioning action sequences of visual events leading\ntowards generating visually aligned realistic sound tracks. We expand our\npreviously proposed Automatic Foley dataset to train with FoleyGAN and evaluate\nour synthesized sound through human survey that shows noteworthy (on average\n81\\%) audio-visual synchronicity performance. Our approach also outperforms in\nstatistical experiments compared with other baseline models and audio-visual\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 04:59:26 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Ghose", "Sanchita", ""], ["Prevost", "John J.", ""]]}, {"id": "2107.09285", "submitter": "Kaylee Burns", "authors": "Kaylee Burns, Christopher D. Manning, Li Fei-Fei", "title": "Neural Abstructions: Abstractions that Support Construction for Grounded\n  Language Learning", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although virtual agents are increasingly situated in environments where\nnatural language is the most effective mode of interaction with humans, these\nexchanges are rarely used as an opportunity for learning. Leveraging language\ninteractions effectively requires addressing limitations in the two most common\napproaches to language grounding: semantic parsers built on top of fixed object\ncategories are precise but inflexible and end-to-end models are maximally\nexpressive, but fickle and opaque. Our goal is to develop a system that\nbalances the strengths of each approach so that users can teach agents new\ninstructions that generalize broadly from a single example. We introduce the\nidea of neural abstructions: a set of constraints on the inference procedure of\na label-conditioned generative model that can affect the meaning of the label\nin context. Starting from a core programming language that operates over\nabstructions, users can define increasingly complex mappings from natural\nlanguage to actions. We show that with this method a user population is able to\nbuild a semantic parser for an open-ended house modification task in Minecraft.\nThe semantic parser that results is both flexible and expressive: the\npercentage of utterances sourced from redefinitions increases steadily over the\ncourse of 191 total exchanges, achieving a final value of 28%.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 07:01:15 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Burns", "Kaylee", ""], ["Manning", "Christopher D.", ""], ["Fei-Fei", "Li", ""]]}, {"id": "2107.09288", "submitter": "Xueping Peng", "authors": "Xueping Peng and Guodong Long and Tao Shen and Sen Wang and Zhendong\n  Niu and Chengqi Zhang", "title": "MIMO: Mutual Integration of Patient Journey and Medical Ontology for\n  Healthcare Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Healthcare representation learning on the Electronic Health Record (EHR) is\nseen as crucial for predictive analytics in the medical field. Many natural\nlanguage processing techniques, such as word2vec, RNN and self-attention, have\nbeen adapted for use in hierarchical and time stamped EHR data, but fail when\nthey lack either general or task-specific data. Hence, some recent works train\nhealthcare representations by incorporating medical ontology (a.k.a. knowledge\ngraph), by self-supervised tasks like diagnosis prediction, but (1) the\nsmall-scale, monotonous ontology is insufficient for robust learning, and (2)\ncritical contexts or dependencies underlying patient journeys are never\nexploited to enhance ontology learning. To address this, we propose an\nend-to-end robust Transformer-based solution, Mutual Integration of patient\njourney and Medical Ontology (MIMO) for healthcare representation learning and\npredictive analytics. Specifically, it consists of task-specific representation\nlearning and graph-embedding modules to learn both patient journey and medical\nontology interactively. Consequently, this creates a mutual integration to\nbenefit both healthcare representation learning and medical ontology embedding.\nMoreover, such integration is achieved by a joint training of both\ntask-specific predictive and ontology-based disease typing tasks based on fused\nembeddings of the two modules. Experiments conducted on two real-world\ndiagnosis prediction datasets show that, our healthcare representation model\nMIMO not only achieves better predictive results than previous state-of-the-art\napproaches regardless of sufficient or insufficient training data, but also\nderives more interpretable embeddings of diagnoses.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 07:04:52 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 01:00:00 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 03:01:26 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Peng", "Xueping", ""], ["Long", "Guodong", ""], ["Shen", "Tao", ""], ["Wang", "Sen", ""], ["Niu", "Zhendong", ""], ["Zhang", "Chengqi", ""]]}, {"id": "2107.09332", "submitter": "Seongsik Park", "authors": "Seongsik Park, Harksoo Kim", "title": "Improving Sentence-Level Relation Extraction through Curriculum Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The sentence-level relation extraction mainly aims to classify the relation\nbetween two entities in a sentence. The sentence-level relation extraction\ncorpus is often containing data of difficulty for the model to infer or noise\ndata. In this paper, we propose a curriculum learning-based relation extraction\nmodel that split data by difficulty and utilize it for learning. In the\nexperiments with the representative sentence-level relation extraction\ndatasets, TACRED and Re-TACRED, the proposed method showed good performances.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 08:44:40 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Park", "Seongsik", ""], ["Kim", "Harksoo", ""]]}, {"id": "2107.09352", "submitter": "Diego Pino", "authors": "Diego Pino, Javier Garc\\'ia, Fernando Fern\\'andez, Svitlana S\n  Vyetrenko", "title": "Similarity metrics for Different Market Scenarios in Abides", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Markov Decision Processes (MDPs) are an effective way to formally describe\nmany Machine Learning problems. In fact, recently MDPs have also emerged as a\npowerful framework to model financial trading tasks. For example, financial\nMDPs can model different market scenarios. However, the learning of a\n(near-)optimal policy for each of these financial MDPs can be a very\ntime-consuming process, especially when nothing is known about the policy to\nbegin with. An alternative approach is to find a similar financial MDP for\nwhich we have already learned its policy, and then reuse such policy in the\nlearning of a new policy for a new financial MDP. Such a knowledge transfer\nbetween market scenarios raises several issues. On the one hand, how to measure\nthe similarity between financial MDPs. On the other hand, how to use this\nsimilarity measurement to effectively transfer the knowledge between financial\nMDPs. This paper addresses both of these issues. Regarding the first one, this\npaper analyzes the use of three similarity metrics based on conceptual,\nstructural and performance aspects of the financial MDPs. Regarding the second\none, this paper uses Probabilistic Policy Reuse to balance the\nexploitation/exploration in the learning of a new financial MDP according to\nthe similarity of the previous financial MDPs whose knowledge is reused.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 09:18:06 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Pino", "Diego", ""], ["Garc\u00eda", "Javier", ""], ["Fern\u00e1ndez", "Fernando", ""], ["Vyetrenko", "Svitlana S", ""]]}, {"id": "2107.09359", "submitter": "Jo\\~ao Carvalho", "authors": "Jo\\~ao Carvalho, Davide Tateo, Fabio Muratore, Jan Peters", "title": "An Empirical Analysis of Measure-Valued Derivatives for Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning methods for robotics are increasingly successful due\nto the constant development of better policy gradient techniques. A precise\n(low variance) and accurate (low bias) gradient estimator is crucial to face\nincreasingly complex tasks. Traditional policy gradient algorithms use the\nlikelihood-ratio trick, which is known to produce unbiased but high variance\nestimates. More modern approaches exploit the reparametrization trick, which\ngives lower variance gradient estimates but requires differentiable value\nfunction approximators. In this work, we study a different type of stochastic\ngradient estimator: the Measure-Valued Derivative. This estimator is unbiased,\nhas low variance, and can be used with differentiable and non-differentiable\nfunction approximators. We empirically evaluate this estimator in the\nactor-critic policy gradient setting and show that it can reach comparable\nperformance with methods based on the likelihood-ratio or reparametrization\ntricks, both in low and high-dimensional action spaces.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 09:26:10 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Carvalho", "Jo\u00e3o", ""], ["Tateo", "Davide", ""], ["Muratore", "Fabio", ""], ["Peters", "Jan", ""]]}, {"id": "2107.09391", "submitter": "Sadaf Gulshad", "authors": "Sadaf Gulshad, Ivan Sosnovik, Arnold Smeulders", "title": "Built-in Elastic Transformations for Improved Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on building robustness in the convolutions of neural visual\nclassifiers, especially against natural perturbations like elastic\ndeformations, occlusions and Gaussian noise. Existing CNNs show outstanding\nperformance on clean images, but fail to tackle naturally occurring\nperturbations. In this paper, we start from elastic perturbations, which\napproximate (local) view-point changes of the object. We present\nelastically-augmented convolutions (EAConv) by parameterizing filters as a\ncombination of fixed elastically-perturbed bases functions and trainable\nweights for the purpose of integrating unseen viewpoints in the CNN. We show on\nCIFAR-10 and STL-10 datasets that the general robustness of our method on\nunseen occlusion and Gaussian perturbations improves, while even improving the\nperformance on clean images slightly without performing any data augmentation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 10:16:38 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Gulshad", "Sadaf", ""], ["Sosnovik", "Ivan", ""], ["Smeulders", "Arnold", ""]]}, {"id": "2107.09414", "submitter": "Alexander Tornede", "authors": "Alexander Tornede, Lukas Gehring, Tanja Tornede, Marcel Wever, Eyke\n  H\\\"ullermeier", "title": "Algorithm Selection on a Meta Level", "comments": "under review for a special issue @ MLJ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of selecting an algorithm that appears most suitable for a\nspecific instance of an algorithmic problem class, such as the Boolean\nsatisfiability problem, is called instance-specific algorithm selection. Over\nthe past decade, the problem has received considerable attention, resulting in\na number of different methods for algorithm selection. Although most of these\nmethods are based on machine learning, surprisingly little work has been done\non meta learning, that is, on taking advantage of the complementarity of\nexisting algorithm selection methods in order to combine them into a single\nsuperior algorithm selector. In this paper, we introduce the problem of meta\nalgorithm selection, which essentially asks for the best way to combine a given\nset of algorithm selectors. We present a general methodological framework for\nmeta algorithm selection as well as several concrete learning methods as\ninstantiations of this framework, essentially combining ideas of meta learning\nand ensemble learning. In an extensive experimental evaluation, we demonstrate\nthat ensembles of algorithm selectors can significantly outperform single\nalgorithm selectors and have the potential to form the new state of the art in\nalgorithm selection.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 11:23:21 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Tornede", "Alexander", ""], ["Gehring", "Lukas", ""], ["Tornede", "Tanja", ""], ["Wever", "Marcel", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2107.09422", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "Ravichandra Addanki, Peter W. Battaglia, David Budden, Andreea Deac,\n  Jonathan Godwin, Thomas Keck, Wai Lok Sibon Li, Alvaro Sanchez-Gonzalez,\n  Jacklynn Stott, Shantanu Thakoor, Petar Veli\\v{c}kovi\\'c", "title": "Large-scale graph representation learning with very deep GNNs and\n  self-supervision", "comments": "To appear at KDD Cup 2021. 13 pages, 3 figures. All authors\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effectively and efficiently deploying graph neural networks (GNNs) at scale\nremains one of the most challenging aspects of graph representation learning.\nMany powerful solutions have only ever been validated on comparatively small\ndatasets, often with counter-intuitive outcomes -- a barrier which has been\nbroken by the Open Graph Benchmark Large-Scale Challenge (OGB-LSC). We entered\nthe OGB-LSC with two large-scale GNNs: a deep transductive node classifier\npowered by bootstrapping, and a very deep (up to 50-layer) inductive graph\nregressor regularised by denoising objectives. Our models achieved an\naward-level (top-3) performance on both the MAG240M and PCQM4M benchmarks. In\ndoing so, we demonstrate evidence of scalable self-supervised graph\nrepresentation learning, and utility of very deep GNNs -- both very important\nopen issues. Our code is publicly available at:\nhttps://github.com/deepmind/deepmind-research/tree/master/ogb_lsc.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 11:35:25 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Addanki", "Ravichandra", ""], ["Battaglia", "Peter W.", ""], ["Budden", "David", ""], ["Deac", "Andreea", ""], ["Godwin", "Jonathan", ""], ["Keck", "Thomas", ""], ["Li", "Wai Lok Sibon", ""], ["Sanchez-Gonzalez", "Alvaro", ""], ["Stott", "Jacklynn", ""], ["Thakoor", "Shantanu", ""], ["Veli\u010dkovi\u0107", "Petar", ""]]}, {"id": "2107.09437", "submitter": "Ling Feng", "authors": "Lin Zhang, Ling Feng, Kan Chen and Choy Heng Lai", "title": "Edge of chaos as a guiding principle for modern neural network training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI nlin.CD physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep neural networks in real-world problems has prompted many\nattempts to explain their training dynamics and generalization performance, but\nmore guiding principles for the training of neural networks are still needed.\nMotivated by the edge of chaos principle behind the optimal performance of\nneural networks, we study the role of various hyperparameters in modern neural\nnetwork training algorithms in terms of the order-chaos phase diagram. In\nparticular, we study a fully analytical feedforward neural network trained on\nthe widely adopted Fashion-MNIST dataset, and study the dynamics associated\nwith the hyperparameters in back-propagation during the training process. We\nfind that for the basic algorithm of stochastic gradient descent with momentum,\nin the range around the commonly used hyperparameter values, clear scaling\nrelations are present with respect to the training time during the ordered\nphase in the phase diagram, and the model's optimal generalization power at the\nedge of chaos is similar across different training parameter combinations. In\nthe chaotic phase, the same scaling no longer exists. The scaling allows us to\nchoose the training parameters to achieve faster training without sacrificing\nperformance. In addition, we find that the commonly used model regularization\nmethod - weight decay - effectively pushes the model towards the ordered phase\nto achieve better performance. Leveraging on this fact and the scaling\nrelations in the other hyperparameters, we derived a principled guideline for\nhyperparameter determination, such that the model can achieve optimal\nperformance by saturating it at the edge of chaos. Demonstrated on this simple\nneural network model and training algorithm, our work improves the\nunderstanding of neural network training dynamics, and can potentially be\nextended to guiding principles of more complex model architectures and\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 12:17:55 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Zhang", "Lin", ""], ["Feng", "Ling", ""], ["Chen", "Kan", ""], ["Lai", "Choy Heng", ""]]}, {"id": "2107.09483", "submitter": "Delong Chen", "authors": "Delong Chen, Fan Liu, Zheqi Zhang, Xiaomin Lu, Zewen Li", "title": "Significant Wave Height Prediction based on Wavelet Graph Neural Network", "comments": "Accepted by 2021 4th International Conference on Big Data and\n  Artificial Intelligence (BDAI). Best presentation winner", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computational intelligence-based ocean characteristics forecasting\napplications, such as Significant Wave Height (SWH) prediction, are crucial for\navoiding social and economic loss in coastal cities. Compared to the\ntraditional empirical-based or numerical-based forecasting models, \"soft\ncomputing\" approaches, including machine learning and deep learning models,\nhave shown numerous success in recent years. In this paper, we focus on\nenabling the deep learning model to learn both short-term and long-term\nspatial-temporal dependencies for SWH prediction. A Wavelet Graph Neural\nNetwork (WGNN) approach is proposed to integrate the advantages of wavelet\ntransform and graph neural network. Several parallel graph neural networks are\nseparately trained on wavelet decomposed data, and the reconstruction of each\nmodel's prediction forms the final SWH prediction. Experimental results show\nthat the proposed WGNN approach outperforms other models, including the\nnumerical models, the machine learning models, and several deep learning\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 13:34:48 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Chen", "Delong", ""], ["Liu", "Fan", ""], ["Zhang", "Zheqi", ""], ["Lu", "Xiaomin", ""], ["Li", "Zewen", ""]]}, {"id": "2107.09540", "submitter": "Andrew Melnik", "authors": "Andrew Melnik, Augustin Harter, Christian Limberg, Krishan Rana, Niko\n  Suenderhauf, Helge Ritter", "title": "Critic Guided Segmentation of Rewarding Objects in First-Person Views", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work discusses a learning approach to mask rewarding objects in images\nusing sparse reward signals from an imitation learning dataset. For that, we\ntrain an Hourglass network using only feedback from a critic model. The\nHourglass network learns to produce a mask to decrease the critic's score of a\nhigh score image and increase the critic's score of a low score image by\nswapping the masked areas between these two images. We trained the model on an\nimitation learning dataset from the NeurIPS 2020 MineRL Competition Track,\nwhere our model learned to mask rewarding objects in a complex interactive 3D\nenvironment with a sparse reward signal. This approach was part of the 1st\nplace winning solution in this competition. Video demonstration and code:\nhttps://rebrand.ly/critic-guided-segmentation\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 14:54:43 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Melnik", "Andrew", ""], ["Harter", "Augustin", ""], ["Limberg", "Christian", ""], ["Rana", "Krishan", ""], ["Suenderhauf", "Niko", ""], ["Ritter", "Helge", ""]]}, {"id": "2107.09542", "submitter": "Steve Hanneke", "authors": "Steve Hanneke", "title": "Open Problem: Is There an Online Learning Algorithm That Learns Whenever\n  Online Learning Is Possible?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This open problem asks whether there exists an online learning algorithm for\nbinary classification that guarantees, for all target concepts, to make a\nsublinear number of mistakes, under only the assumption that the (possibly\nrandom) sequence of points X allows that such a learning algorithm can exist\nfor that sequence. As a secondary problem, it also asks whether a specific\nconcise condition completely determines whether a given (possibly random)\nsequence of points X admits the existence of online learning algorithms\nguaranteeing a sublinear number of mistakes for all target concepts.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 14:57:37 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Hanneke", "Steve", ""]]}, {"id": "2107.09556", "submitter": "Luyu Wang", "authors": "Luyu Wang, Yujia Li, Ozlem Aslan, Oriol Vinyals", "title": "WikiGraphs: A Wikipedia Text - Knowledge Graph Paired Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a new dataset of Wikipedia articles each paired with a knowledge\ngraph, to facilitate the research in conditional text generation, graph\ngeneration and graph representation learning. Existing graph-text paired\ndatasets typically contain small graphs and short text (1 or few sentences),\nthus limiting the capabilities of the models that can be learned on the data.\nOur new dataset WikiGraphs is collected by pairing each Wikipedia article from\nthe established WikiText-103 benchmark (Merity et al., 2016) with a subgraph\nfrom the Freebase knowledge graph (Bollacker et al., 2008). This makes it easy\nto benchmark against other state-of-the-art text generative models that are\ncapable of generating long paragraphs of coherent text. Both the graphs and the\ntext data are of significantly larger scale compared to prior graph-text paired\ndatasets. We present baseline graph neural network and transformer model\nresults on our dataset for 3 tasks: graph -> text generation, graph -> text\nretrieval and text -> graph retrieval. We show that better conditioning on the\ngraph provides gains in generation and retrieval quality but there is still\nlarge room for improvement.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 15:18:30 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Wang", "Luyu", ""], ["Li", "Yujia", ""], ["Aslan", "Ozlem", ""], ["Vinyals", "Oriol", ""]]}, {"id": "2107.09574", "submitter": "Tong Zhang", "authors": "Tong Zhang, Shuai Wang, Guoliang Li, Fan Liu, Guangxu Zhu, and Rui\n  Wang", "title": "Accelerating Edge Intelligence via Integrated Sensing and Communication", "comments": "7 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Realizing edge intelligence consists of sensing, communication, training, and\ninference stages. Conventionally, the sensing and communication stages are\nexecuted sequentially, which results in excessive amount of dataset generation\nand uploading time. This paper proposes to accelerate edge intelligence via\nintegrated sensing and communication (ISAC). As such, the sensing and\ncommunication stages are merged so as to make the best use of the wireless\nsignals for the dual purpose of dataset generation and uploading. However, ISAC\nalso introduces additional interference between sensing and communication\nfunctionalities. To address this challenge, this paper proposes a\nclassification error minimization formulation to design the ISAC beamforming\nand time allocation. Globally optimal solution is derived via the rank-1\nguaranteed semidefinite relaxation, and performance analysis is performed to\nquantify the ISAC gain. Simulation results are provided to verify the\neffectiveness of the proposed ISAC scheme. Interestingly, it is found that when\nthe sensing time dominates the communication time, ISAC is always beneficial.\nHowever, when the communication time dominates, the edge intelligence with ISAC\nscheme may not be better than that with the conventional scheme, since ISAC\nintroduces harmful interference between the sensing and communication signals.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 15:42:06 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Zhang", "Tong", ""], ["Wang", "Shuai", ""], ["Li", "Guoliang", ""], ["Liu", "Fan", ""], ["Zhu", "Guangxu", ""], ["Wang", "Rui", ""]]}, {"id": "2107.09579", "submitter": "Alberto Cetoli", "authors": "Alberto Cetoli", "title": "Semantic Reasoning with Differentiable Graph Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces a differentiable semantic reasoner, where rules are\npresented as a relevant set of graph transformations. These rules can be\nwritten manually or inferred by a set of facts and goals presented as a\ntraining set. While the internal representation uses embeddings in a latent\nspace, each rule can be expressed as a set of predicates conforming to a subset\nof Description Logic.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 15:48:54 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Cetoli", "Alberto", ""]]}, {"id": "2107.09591", "submitter": "Giovanni Stabile", "authors": "Matteo Zancanaro, Markus Mrosek, Giovanni Stabile, Carsten Othmer,\n  Gianluigi Rozza", "title": "Hybrid neural network reduced order modelling for turbulent flows with\n  geometric parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.AI cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Geometrically parametrized Partial Differential Equations are nowadays widely\nused in many different fields as, for example, shape optimization processes or\npatient specific surgery studies. The focus of this work is on some advances\nfor this topic, capable of increasing the accuracy with respect to previous\napproaches while relying on a high cost-benefit ratio performance. The main\nscope of this paper is the introduction of a new technique mixing up a\nclassical Galerkin-projection approach together with a data-driven method to\nobtain a versatile and accurate algorithm for the resolution of geometrically\nparametrized incompressible turbulent Navier-Stokes problems. The effectiveness\nof this procedure is demonstrated on two different test cases: a classical\nacademic back step problem and a shape deformation Ahmed body application. The\nresults show into details the properties of the architecture we developed while\nexposing possible future perspectives for this work.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 16:06:18 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Zancanaro", "Matteo", ""], ["Mrosek", "Markus", ""], ["Stabile", "Giovanni", ""], ["Othmer", "Carsten", ""], ["Rozza", "Gianluigi", ""]]}, {"id": "2107.09598", "submitter": "Tim Franzmeyer", "authors": "Tim Franzmeyer, Mateusz Malinowski and Jo\\~ao F. Henriques", "title": "Learning Altruistic Behaviours in Reinforcement Learning without\n  External Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Can artificial agents learn to assist others in achieving their goals without\nknowing what those goals are? Generic reinforcement learning agents could be\ntrained to behave altruistically towards others by rewarding them for\naltruistic behaviour, i.e., rewarding them for benefiting other agents in a\ngiven situation. Such an approach assumes that other agents' goals are known so\nthat the altruistic agent can cooperate in achieving those goals. However,\nexplicit knowledge of other agents' goals is often difficult to acquire. Even\nassuming such knowledge to be given, training of altruistic agents would\nrequire manually-tuned external rewards for each new environment. Thus, it is\nbeneficial to develop agents that do not depend on external supervision and can\nlearn altruistic behaviour in a task-agnostic manner. Assuming that other\nagents rationally pursue their goals, we hypothesize that giving them more\nchoices will allow them to pursue those goals better. Some concrete examples\ninclude opening a door for others or safeguarding them to pursue their\nobjectives without interference. We formalize this concept and propose an\naltruistic agent that learns to increase the choices another agent has by\nmaximizing the number of states that the other agent can reach in its future.\nWe evaluate our approach on three different multi-agent environments where\nanother agent's success depends on the altruistic agent's behaviour. Finally,\nwe show that our unsupervised agents can perform comparably to agents\nexplicitly trained to work cooperatively. In some cases, our agents can even\noutperform the supervised ones.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 16:19:39 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 06:43:03 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Franzmeyer", "Tim", ""], ["Malinowski", "Mateusz", ""], ["Henriques", "Jo\u00e3o F.", ""]]}, {"id": "2107.09600", "submitter": "Li Gao", "authors": "Li Gao, Jing Zhang, Lefei Zhang, Dacheng Tao", "title": "DSP: Dual Soft-Paste for Unsupervised Domain Adaptive Semantic\n  Segmentation", "comments": null, "journal-ref": null, "doi": "10.1145/3474085.3475186", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation (UDA) for semantic segmentation aims to adapt\na segmentation model trained on the labeled source domain to the unlabeled\ntarget domain. Existing methods try to learn domain invariant features while\nsuffering from large domain gaps that make it difficult to correctly align\ndiscrepant features, especially in the initial training phase. To address this\nissue, we propose a novel Dual Soft-Paste (DSP) method in this paper.\nSpecifically, DSP selects some classes from a source domain image using a\nlong-tail class first sampling strategy and softly pastes the corresponding\nimage patch on both the source and target training images with a fusion weight.\nTechnically, we adopt the mean teacher framework for domain adaptation, where\nthe pasted source and target images go through the student network while the\noriginal target image goes through the teacher network. Output-level alignment\nis carried out by aligning the probability maps of the target fused image from\nboth networks using a weighted cross-entropy loss. In addition, feature-level\nalignment is carried out by aligning the feature maps of the source and target\nimages from student network using a weighted maximum mean discrepancy loss. DSP\nfacilitates the model learning domain-invariant features from the intermediate\ndomains, leading to faster convergence and better performance. Experiments on\ntwo challenging benchmarks demonstrate the superiority of DSP over\nstate-of-the-art methods. Code is available at\n\\url{https://github.com/GaoLii/DSP}.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 16:22:40 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 15:20:09 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 15:41:13 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Gao", "Li", ""], ["Zhang", "Jing", ""], ["Zhang", "Lefei", ""], ["Tao", "Dacheng", ""]]}, {"id": "2107.09609", "submitter": "Jie Lei", "authors": "Jie Lei, Tamara L. Berg, Mohit Bansal", "title": "QVHighlights: Detecting Moments and Highlights in Videos via Natural\n  Language Queries", "comments": "17 pages, 11 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting customized moments and highlights from videos given natural\nlanguage (NL) user queries is an important but under-studied topic. One of the\nchallenges in pursuing this direction is the lack of annotated data. To address\nthis issue, we present the Query-based Video Highlights (QVHighlights) dataset.\nIt consists of over 10,000 YouTube videos, covering a wide range of topics,\nfrom everyday activities and travel in lifestyle vlog videos to social and\npolitical activities in news videos. Each video in the dataset is annotated\nwith: (1) a human-written free-form NL query, (2) relevant moments in the video\nw.r.t. the query, and (3) five-point scale saliency scores for all\nquery-relevant clips. This comprehensive annotation enables us to develop and\nevaluate systems that detect relevant moments as well as salient highlights for\ndiverse, flexible user queries. We also present a strong baseline for this\ntask, Moment-DETR, a transformer encoder-decoder model that views moment\nretrieval as a direct set prediction problem, taking extracted video and query\nrepresentations as inputs and predicting moment coordinates and saliency scores\nend-to-end. While our model does not utilize any human prior, we show that it\nperforms competitively when compared to well-engineered architectures. With\nweakly supervised pretraining using ASR captions, Moment-DETR substantially\noutperforms previous methods. Lastly, we present several ablations and\nvisualizations of Moment-DETR. Data and code is publicly available at\nhttps://github.com/jayleicn/moment_detr\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 16:42:58 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Lei", "Jie", ""], ["Berg", "Tamara L.", ""], ["Bansal", "Mohit", ""]]}, {"id": "2107.09645", "submitter": "Denis Yarats", "authors": "Denis Yarats, Rob Fergus, Alessandro Lazaric, Lerrel Pinto", "title": "Mastering Visual Continuous Control: Improved Data-Augmented\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DrQ-v2, a model-free reinforcement learning (RL) algorithm for\nvisual continuous control. DrQ-v2 builds on DrQ, an off-policy actor-critic\napproach that uses data augmentation to learn directly from pixels. We\nintroduce several improvements that yield state-of-the-art results on the\nDeepMind Control Suite. Notably, DrQ-v2 is able to solve complex humanoid\nlocomotion tasks directly from pixel observations, previously unattained by\nmodel-free RL. DrQ-v2 is conceptually simple, easy to implement, and provides\nsignificantly better computational footprint compared to prior work, with the\nmajority of tasks taking just 8 hours to train on a single GPU. Finally, we\npublicly release DrQ-v2's implementation to provide RL practitioners with a\nstrong and computationally efficient baseline.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 17:29:13 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Yarats", "Denis", ""], ["Fergus", "Rob", ""], ["Lazaric", "Alessandro", ""], ["Pinto", "Lerrel", ""]]}, {"id": "2107.09648", "submitter": "James Michaelov", "authors": "James A. Michaelov, Megan D. Bardolph, Seana Coulson, Benjamin K.\n  Bergen", "title": "Different kinds of cognitive plausibility: why are transformers better\n  than RNNs at predicting N400 amplitude?", "comments": null, "journal-ref": "Proceedings of the 43rd Annual Meeting of the Cognitive Science\n  Society (2021) 300-306", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite being designed for performance rather than cognitive plausibility,\ntransformer language models have been found to be better at predicting metrics\nused to assess human language comprehension than language models with other\narchitectures, such as recurrent neural networks. Based on how well they\npredict the N400, a neural signal associated with processing difficulty, we\npropose and provide evidence for one possible explanation - their predictions\nare affected by the preceding context in a way analogous to the effect of\nsemantic facilitation in humans.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 17:33:13 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Michaelov", "James A.", ""], ["Bardolph", "Megan D.", ""], ["Coulson", "Seana", ""], ["Bergen", "Benjamin K.", ""]]}, {"id": "2107.09667", "submitter": "Nicolas Michael M\\\"uller", "authors": "Nicolas M. M\\\"uller, Karla Markert, Konstantin B\\\"ottinger", "title": "Human Perception of Audio Deepfakes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent emergence of deepfakes, computerized realistic multimedia fakes,\nbrought the detection of manipulated and generated content to the forefront.\nWhile many machine learning models for deepfakes detection have been proposed,\nthe human detection capabilities have remained far less explored. This is of\nspecial importance as human perception differs from machine perception and\ndeepfakes are generally designed to fool the human. So far, this issue has only\nbeen addressed in the area of images and video.\n  To compare the ability of humans and machines in detecting audio deepfakes,\nwe conducted an online gamified experiment in which we asked users to discern\nbonda-fide audio samples from spoofed audio, generated with a variety of\nalgorithms. 200 users competed for 8976 game rounds with an artificial\nintelligence (AI) algorithm trained for audio deepfake detection. With the\ncollected data we found that the machine generally outperforms the humans in\ndetecting audio deepfakes, but that the converse holds for a certain attack\ntype, for which humans are still more accurate. Furthermore, we found that\nyounger participants are on average better at detecting audio deepfakes than\nolder participants, while IT-professionals hold no advantage over laymen. We\nconclude that it is important to combine human and machine knowledge in order\nto improve audio deepfake detection.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 09:19:42 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["M\u00fcller", "Nicolas M.", ""], ["Markert", "Karla", ""], ["B\u00f6ttinger", "Konstantin", ""]]}, {"id": "2107.09668", "submitter": "Pegdwende Minoungou", "authors": "Pegdwende Minoungou, Vincent Mousseau, Wassila Ouerdane, Paolo Scotton", "title": "Learning MR-Sort Models from Non-Monotone Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Majority Rule Sorting (MR-Sort) method assigns alternatives evaluated on\nmultiple criteria to one of the predefined ordered categories. The Inverse\nMR-Sort problem (Inv-MR-Sort) computes MR-Sort parameters that match a dataset.\nExisting learning algorithms for Inv-MR-Sort consider monotone preferences on\ncriteria. We extend this problem to the case where the preferences on criteria\nare not necessarily monotone, but possibly single-peaked (or single-valley). We\npropose a mixed-integer programming based algorithm that learns the preferences\non criteria together with the other MR-Sort parameters from the training data.\nWe investigate the performance of the algorithm using numerical experiments and\nwe illustrate its use on a real-world case study.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 13:51:16 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Minoungou", "Pegdwende", ""], ["Mousseau", "Vincent", ""], ["Ouerdane", "Wassila", ""], ["Scotton", "Paolo", ""]]}, {"id": "2107.09718", "submitter": "Carolina Gil Marcelino", "authors": "C.G. Marcelino, G.M.C. Leite, C.A.D.M Delgado, L.B. de Oliveira, E.F.\n  Wanner, S. Jim\\'enez-Fern\\'andez, S. Salcedo-Sanz", "title": "An Efficient Multi-objective Evolutionary Approach for Solving the\n  Operation of Multi-Reservoir System Scheduling in Hydro-Power Plants", "comments": "Accepted Manuscript version (after peer review, and editor-author\n  communications). https://doi.org/10.1016/j.eswa.2021.115638", "journal-ref": "Expert Systems With Applications (2021)", "doi": "10.1016/2021.j.eswa.2021.115638", "report-no": null, "categories": "cs.NE cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper tackles the short-term hydro-power unit commitment problem in a\nmulti-reservoir system - a cascade-based operation scenario. For this, we\npropose a new mathematical modelling in which the goal is to maximize the total\nenergy production of the hydro-power plant in a sub-daily operation, and,\nsimultaneously, to maximize the total water content (volume) of reservoirs. For\nsolving the problem, we discuss the Multi-objective Evolutionary Swarm\nHybridization (MESH) algorithm, a recently proposed multi-objective swarm\nintelligence-based optimization method which has obtained very competitive\nresults when compared to existing evolutionary algorithms in specific\napplications. The MESH approach has been applied to find the optimal water\ndischarge and the power produced at the maximum reservoir volume for all\npossible combinations of turbines in a hydro-power plant. The performance of\nMESH has been compared with that of well-known evolutionary approaches such as\nNSGA-II, NSGA-III, SPEA2, and MOEA/D in a realistic problem considering data\nfrom a hydro-power energy system with two cascaded hydro-power plants in\nBrazil. Results indicate that MESH showed a superior performance than\nalternative multi-objective approaches in terms of efficiency and accuracy,\nproviding a profit of \\$412,500 per month in a projection analysis carried out.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 18:39:09 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 16:24:51 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Marcelino", "C. G.", ""], ["Leite", "G. M. C.", ""], ["Delgado", "C. A. D. M", ""], ["de Oliveira", "L. B.", ""], ["Wanner", "E. F.", ""], ["Jim\u00e9nez-Fern\u00e1ndez", "S.", ""], ["Salcedo-Sanz", "S.", ""]]}, {"id": "2107.09729", "submitter": "Uri Shaham", "authors": "Uri Shaham and Omer Levy", "title": "What Do You Get When You Cross Beam Search with Nucleus Sampling?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine beam search with the probabilistic pruning technique of nucleus\nsampling to create two deterministic nucleus search algorithms for natural\nlanguage generation. The first algorithm, p-exact search, locally prunes the\nnext-token distribution and performs an exact search over the remaining space.\nThe second algorithm, dynamic beam search, shrinks and expands the beam size\naccording to the entropy of the candidate's probability distribution. Despite\nthe probabilistic intuition behind nucleus search, experiments on machine\ntranslation and summarization benchmarks show that both algorithms reach the\nsame performance levels as standard beam search.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 18:59:14 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 11:49:36 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Shaham", "Uri", ""], ["Levy", "Omer", ""]]}, {"id": "2107.09734", "submitter": "Eoin Delaney", "authors": "Eoin Delaney, Derek Greene and Mark T. Keane", "title": "Uncertainty Estimation and Out-of-Distribution Detection for\n  Counterfactual Explanations: Pitfalls and Solutions", "comments": null, "journal-ref": "ICML Workshop on Algorithmic Recourse, July 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whilst an abundance of techniques have recently been proposed to generate\ncounterfactual explanations for the predictions of opaque black-box systems,\nmarkedly less attention has been paid to exploring the uncertainty of these\ngenerated explanations. This becomes a critical issue in high-stakes scenarios,\nwhere uncertain and misleading explanations could have dire consequences (e.g.,\nmedical diagnosis and treatment planning). Moreover, it is often difficult to\ndetermine if the generated explanations are well grounded in the training data\nand sensitive to distributional shifts. This paper proposes several practical\nsolutions that can be leveraged to solve these problems by establishing novel\nconnections with other research works in explainability (e.g., trust scores)\nand uncertainty estimation (e.g., Monte Carlo Dropout). Two experiments\ndemonstrate the utility of our proposed solutions.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 19:09:10 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Delaney", "Eoin", ""], ["Greene", "Derek", ""], ["Keane", "Mark T.", ""]]}, {"id": "2107.09766", "submitter": "Taro Sekiyama", "authors": "Takeshi Tsukada and Hiroshi Unno and Taro Sekiyama and Kohei Suenaga", "title": "Enhancing Loop-Invariant Synthesis via Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loop-invariant synthesis is the basis of every program verification\nprocedure. Due to its undecidability in general, a tool for invariant synthesis\nnecessarily uses heuristics. Despite the common belief that the design of\nheuristics is vital for the effective performance of a verifier, little work\nhas been performed toward obtaining the optimal heuristics for each\ninvariant-synthesis tool. Instead, developers have hand-tuned the heuristics of\ntools. This study demonstrates that we can effectively and automatically learn\na good heuristic via reinforcement learning for an invariant synthesizer PCSat.\nOur experiment shows that PCSat combined with the heuristic learned by\nreinforcement learning outperforms the state-of-the-art solvers for this task.\nTo the best of our knowledge, this is the first work that investigates learning\nthe heuristics of an invariant synthesis tool.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 11:17:05 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Tsukada", "Takeshi", ""], ["Unno", "Hiroshi", ""], ["Sekiyama", "Taro", ""], ["Suenaga", "Kohei", ""]]}, {"id": "2107.09767", "submitter": "Chun Ouyang", "authors": "Chun Ouyang, Renuka Sindhgatta, Catarina Moreira", "title": "Explainable AI Enabled Inspection of Business Process Prediction Models", "comments": "17 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Modern data analytics underpinned by machine learning techniques has become a\nkey enabler to the automation of data-led decision making. As an important\nbranch of state-of-the-art data analytics, business process predictions are\nalso faced with a challenge in regard to the lack of explanation to the\nreasoning and decision by the underlying `black-box' prediction models. With\nthe development of interpretable machine learning techniques, explanations can\nbe generated for a black-box model, making it possible for (human) users to\naccess the reasoning behind machine learned predictions. In this paper, we aim\nto present an approach that allows us to use model explanations to investigate\ncertain reasoning applied by machine learned predictions and detect potential\nissues with the underlying methods thus enhancing trust in business process\nprediction models. A novel contribution of our approach is the proposal of\nmodel inspection that leverages both the explanations generated by\ninterpretable machine learning mechanisms and the contextual or domain\nknowledge extracted from event logs that record historical process execution.\nFindings drawn from this work are expected to serve as a key input to\ndeveloping model reliability metrics and evaluation in the context of business\nprocess predictions.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 06:51:18 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Ouyang", "Chun", ""], ["Sindhgatta", "Renuka", ""], ["Moreira", "Catarina", ""]]}, {"id": "2107.09785", "submitter": "Frederico Gadelha Guimaraes", "authors": "Hugo Vinicius Bitencourt and Frederico Gadelha Guimar\\~aes", "title": "High-dimensional Multivariate Time Series Forecasting in IoT\n  Applications using Embedding Non-stationary Fuzzy Time Series", "comments": "6 pages, 1 figure, submitted to the 7th IEEE LA-CCI (Latin American\n  Conference on Computational Intelligence)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SP eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In Internet of things (IoT), data is continuously recorded from different\ndata sources and devices can suffer faults in their embedded electronics, thus\nleading to a high-dimensional data sets and concept drift events. Therefore,\nmethods that are capable of high-dimensional non-stationary time series are of\ngreat value in IoT applications. Fuzzy Time Series (FTS) models stand out as\ndata-driven non-parametric models of easy implementation and high accuracy.\nUnfortunately, FTS encounters difficulties when dealing with data sets of many\nvariables and scenarios with concept drift. We present a new approach to handle\nhigh-dimensional non-stationary time series, by projecting the original\nhigh-dimensional data into a low dimensional embedding space and using FTS\napproach. Combining these techniques enables a better representation of the\ncomplex content of non-stationary multivariate time series and accurate\nforecasts. Our model is able to explain 98% of the variance and reach 11.52% of\nRMSE, 2.68% of MAE and 2.91% of MAPE.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 22:00:43 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Bitencourt", "Hugo Vinicius", ""], ["Guimar\u00e3es", "Frederico Gadelha", ""]]}, {"id": "2107.09801", "submitter": "Borko Bo\\v{s}kovi\\'c", "authors": "Borko Bo\\v{s}kovi\\'c, Janez Brest", "title": "Two-phase Optimization of Binary Sequences with Low Peak Sidelobe Level\n  Value", "comments": "8 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The search for binary sequences with low peak sidelobe level value represents\na formidable computational problem. To locate better sequences for this\nproblem, we designed a stochastic algorithm that uses two fitness functions. In\nthese fitness functions, the value of the autocorrelation function has a\ndifferent impact on the final fitness value. It is defined with the value of\nthe exponent over the autocorrelation function values. Each function is used in\nthe corresponding optimization phase, and the optimization process switches\nbetween these two phases until the stopping condition is satisfied. The\nproposed algorithm was implemented using the compute unified device\narchitecture and therefore allowed us to exploit the computational power of\ngraphics processing units. This algorithm was tested on sequences with lengths\n$L = 2^m - 1$, for $14 \\le m \\le 20$. From the obtained results it is evident\nthat the usage of two fitness functions improved the efficiency of the\nalgorithm significantly, new-best known solutions were achieved, and the\nachieved PSL values were significantly less than $\\sqrt{L}$.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 13:59:55 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Bo\u0161kovi\u0107", "Borko", ""], ["Brest", "Janez", ""]]}, {"id": "2107.09807", "submitter": "Amin Nikanjam", "authors": "Mahnoosh Mahdavimoghaddam, Amin Nikanjam, Monireh Abdoos", "title": "Multi-agent Reinforcement Learning Improvement in a Dynamic Environment\n  Using Knowledge Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative multi-agent systems are being widely used in variety of areas.\nInteraction between agents would bring positive points, including reducing\ncosts of operating, high scalability, and facilitating parallel processing.\nThese systems pave the way for handling large-scale, unknown, and dynamic\nenvironments. However, learning in these environments has become a prominent\nchallenge in different applications. These challenges include the effect of\nsize of search space on learning time, inappropriate cooperation among agents,\nand the lack of proper coordination among agents' decisions. Moreover,\nreinforcement learning algorithms may suffer from long time of convergence in\nthese problems. In this paper, a communication framework using knowledge\ntransfer concepts is introduced to address such challenges in the herding\nproblem with large state space. To handle the problems of convergence,\nknowledge transfer has been utilized that can significantly increase the\nefficiency of reinforcement learning algorithms. Coordination between the\nagents is carried out through a head agent in each group of agents and a\ncoordinator agent respectively. The results demonstrate that this framework\ncould indeed enhance the speed of learning and reduce convergence time.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 23:42:39 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 14:17:50 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Mahdavimoghaddam", "Mahnoosh", ""], ["Nikanjam", "Amin", ""], ["Abdoos", "Monireh", ""]]}, {"id": "2107.09822", "submitter": "Krishan Rana Mr", "authors": "Krishan Rana, Vibhavari Dasagi, Jesse Haviland, Ben Talbot, Michael\n  Milford and Niko S\\\"underhauf", "title": "Bayesian Controller Fusion: Leveraging Control Priors in Deep\n  Reinforcement Learning for Robotics", "comments": "Under review for The International Journal of Robotics Research\n  (IJRR). Project page: https://krishanrana.github.io/bcf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Bayesian Controller Fusion (BCF): a hybrid control strategy that\ncombines the strengths of traditional hand-crafted controllers and model-free\ndeep reinforcement learning (RL). BCF thrives in the robotics domain, where\nreliable but suboptimal control priors exist for many tasks, but RL from\nscratch remains unsafe and data-inefficient. By fusing uncertainty-aware\ndistributional outputs from each system, BCF arbitrates control between them,\nexploiting their respective strengths. We study BCF on two real-world robotics\ntasks involving navigation in a vast and long-horizon environment, and a\ncomplex reaching task that involves manipulability maximisation. For both these\ndomains, there exist simple handcrafted controllers that can solve the task at\nhand in a risk-averse manner but do not necessarily exhibit the optimal\nsolution given limitations in analytical modelling, controller miscalibration\nand task variation. As exploration is naturally guided by the prior in the\nearly stages of training, BCF accelerates learning, while substantially\nimproving beyond the performance of the control prior, as the policy gains more\nexperience. More importantly, given the risk-aversity of the control prior, BCF\nensures safe exploration and deployment, where the control prior naturally\ndominates the action distribution in states unknown to the policy. We\nadditionally show BCF's applicability to the zero-shot sim-to-real setting and\nits ability to deal with out-of-distribution states in the real-world. BCF is a\npromising approach for combining the complementary strengths of deep RL and\ntraditional robotic control, surpassing what either can achieve independently.\nThe code and supplementary video material are made publicly available at\nhttps://krishanrana.github.io/bcf.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 00:43:32 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 05:48:12 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Rana", "Krishan", ""], ["Dasagi", "Vibhavari", ""], ["Haviland", "Jesse", ""], ["Talbot", "Ben", ""], ["Milford", "Michael", ""], ["S\u00fcnderhauf", "Niko", ""]]}, {"id": "2107.09847", "submitter": "Minjung Shin", "authors": "Minjung Shin (1), Jeonghoon Kim (1 and 2), Seongho Choi (3), Yu-Jung\n  Heo (3), Donghyun Kim (1 and 4), Minsu Lee (3 and 5), Byoung-Tak Zhang (3 and\n  5) and Jeh-Kwang Ryu (1 and 4) ((1) Laboratory for Natural and Artificial\n  Kin\\\"asthese, Convergence Research Center for Artificial Intelligence\n  (CRC4AI), Dongguk University, Seoul, South Korea, (2) Department of\n  Artificial Intelligence, Dongguk University, Seoul, South Korea, (3)\n  Biointelligence Laboratory, Department of Computer Science and Engineering,\n  Seoul National University, Seoul, South Korea, (4) Department of Physical\n  Education, College of Education, Dongguk University, Seoul, South Korea, (5)\n  AI Institute of Seoul National University (AIIS), Seoul, South Korea)", "title": "CogME: A Novel Evaluation Metric for Video Understanding Intelligence", "comments": "17 pages with 3 figures and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing video understanding intelligence is quite challenging because it\nrequires holistic integration of images, scripts, and sounds based on natural\nlanguage processing, temporal dependency, and reasoning. Recently, substantial\nattempts have been made on several video datasets with associated question\nanswering (QA) on a large scale. However, existing evaluation metrics for video\nquestion answering (VideoQA) do not provide meaningful analysis. To make\nprogress, we argue that a well-made framework, established on the way humans\nunderstand, is required to explain and evaluate the performance of\nunderstanding in detail. Then we propose a top-down evaluation system for\nVideoQA, based on the cognitive process of humans and story elements: Cognitive\nModules for Evaluation (CogME). CogME is composed of three cognitive modules:\ntargets, contents, and thinking. The interaction among the modules in the\nunderstanding procedure can be expressed in one sentence as follows: \"I\nunderstand the CONTENT of the TARGET through a way of THINKING.\" Each module\nhas sub-components derived from the story elements. We can specify the required\naspects of understanding by annotating the sub-components to individual\nquestions. CogME thus provides a framework for an elaborated specification of\nVideoQA datasets. To examine the suitability of a VideoQA dataset for\nvalidating video understanding intelligence, we evaluated the baseline model of\nthe DramaQA dataset by applying CogME. The evaluation reveals that story\nelements are unevenly reflected in the existing dataset, and the model based on\nthe dataset may cause biased predictions. Although this study has only been\nable to grasp a narrow range of stories, we expect that it offers the first\nstep in considering the cognitive process of humans on the video understanding\nintelligence of humans and AI.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 02:33:37 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Shin", "Minjung", "", "1 and 2"], ["Kim", "Jeonghoon", "", "1 and 2"], ["Choi", "Seongho", "", "1 and 4"], ["Heo", "Yu-Jung", "", "1 and 4"], ["Kim", "Donghyun", "", "1 and 4"], ["Lee", "Minsu", "", "3 and 5"], ["Zhang", "Byoung-Tak", "", "3 and\n  5"], ["Ryu", "Jeh-Kwang", "", "1 and 4"]]}, {"id": "2107.09888", "submitter": "Venkata Sriram Siddhardh Nadendla", "authors": "Qizi Zhang and Venkata Sriram Siddhardh Nadendla and S. N.\n  Balakrishnan and Jerome Busemeyer", "title": "Strategic Mitigation of Agent Inattention in Drivers with Open-Quantum\n  Cognition Models", "comments": "12 pages, 4 figures, submitted to IEEE Transactions on Human-Machine\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.GT cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art driver-assist systems have failed to effectively mitigate\ndriver inattention and had minimal impacts on the ever-growing number of road\nmishaps (e.g. life loss, physical injuries due to accidents caused by various\nfactors that lead to driver inattention). This is because traditional\nhuman-machine interaction settings are modeled in classical and behavioral\ngame-theoretic domains which are technically appropriate to characterize\nstrategic interaction between either two utility maximizing agents, or human\ndecision makers. Therefore, in an attempt to improve the persuasive\neffectiveness of driver-assist systems, we develop a novel strategic and\npersonalized driver-assist system which adapts to the driver's mental state and\nchoice behavior. First, we propose a novel equilibrium notion in human-system\ninteraction games, where the system maximizes its expected utility and human\ndecisions can be characterized using any general decision model. Then we use\nthis novel equilibrium notion to investigate the strategic driver-vehicle\ninteraction game where the car presents a persuasive recommendation to steer\nthe driver towards safer driving decisions. We assume that the driver employs\nan open-quantum system cognition model, which captures complex aspects of human\ndecision making such as violations to classical law of total probability and\nincompatibility of certain mental representations of information. We present\nclosed-form expressions for players' final responses to each other's strategies\nso that we can numerically compute both pure and mixed equilibria. Numerical\nresults are presented to illustrate both kinds of equilibria.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 06:02:03 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Zhang", "Qizi", ""], ["Nadendla", "Venkata Sriram Siddhardh", ""], ["Balakrishnan", "S. N.", ""], ["Busemeyer", "Jerome", ""]]}, {"id": "2107.09990", "submitter": "Xubo Liu", "authors": "Xubo Liu, Qiushi Huang, Xinhao Mei, Tom Ko, H Lilian Tang, Mark D.\n  Plumbley and Wenwu Wang", "title": "CL4AC: A Contrastive Loss for Audio Captioning", "comments": "The first two authors contributed equally, 5 pages, 3 figures,\n  submitted to DCASE2021 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated Audio captioning (AAC) is a cross-modal translation task that aims\nto use natural language to describe the content of an audio clip. As shown in\nthe submissions received for Task 6 of the DCASE 2021 Challenges, this problem\nhas received increasing interest in the community. The existing AAC systems are\nusually based on an encoder-decoder architecture, where the audio signal is\nencoded into a latent representation, and aligned with its corresponding text\ndescriptions, then a decoder is used to generate the captions. However,\ntraining of an AAC system often encounters the problem of data scarcity, which\nmay lead to inaccurate representation and audio-text alignment. To address this\nproblem, we propose a novel encoder-decoder framework called Contrastive Loss\nfor Audio Captioning (CL4AC). In CL4AC, the self-supervision signals derived\nfrom the original audio-text paired data are used to exploit the\ncorrespondences between audio and texts by contrasting samples, which can\nimprove the quality of latent representation and the alignment between audio\nand texts, while trained with limited data. Experiments are performed on the\nClotho dataset to show the effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 10:13:02 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Liu", "Xubo", ""], ["Huang", "Qiushi", ""], ["Mei", "Xinhao", ""], ["Ko", "Tom", ""], ["Tang", "H Lilian", ""], ["Plumbley", "Mark D.", ""], ["Wang", "Wenwu", ""]]}, {"id": "2107.09996", "submitter": "Athanasios Kapoutsis Ch.", "authors": "Dimitrios I. Koutras, Athanasios Ch. Kapoutsis, Angelos A.\n  Amanatiadis, Elias B. Kosmatopoulos", "title": "MarsExplorer: Exploration of Unknown Terrains via Deep Reinforcement\n  Learning and Procedurally Generated Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is an initial endeavor to bridge the gap between powerful Deep\nReinforcement Learning methodologies and the problem of exploration/coverage of\nunknown terrains. Within this scope, MarsExplorer, an openai-gym compatible\nenvironment tailored to exploration/coverage of unknown areas, is presented.\nMarsExplorer translates the original robotics problem into a Reinforcement\nLearning setup that various off-the-shelf algorithms can tackle. Any learned\npolicy can be straightforwardly applied to a robotic platform without an\nelaborate simulation model of the robot's dynamics to apply a different\nlearning/adaptation phase. One of its core features is the controllable\nmulti-dimensional procedural generation of terrains, which is the key for\nproducing policies with strong generalization capabilities. Four different\nstate-of-the-art RL algorithms (A3C, PPO, Rainbow, and SAC) are trained on the\nMarsExplorer environment, and a proper evaluation of their results compared to\nthe average human-level performance is reported. In the follow-up experimental\nanalysis, the effect of the multi-dimensional difficulty setting on the\nlearning capabilities of the best-performing algorithm (PPO) is analyzed. A\nmilestone result is the generation of an exploration policy that follows the\nHilbert curve without providing this information to the environment or\nrewarding directly or indirectly Hilbert-curve-like trajectories. The\nexperimental analysis is concluded by comparing PPO learned policy results with\nfrontier-based exploration context for extended terrain sizes. The source code\ncan be found at: https://github.com/dimikout3/GeneralExplorationPolicy.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 10:29:39 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Koutras", "Dimitrios I.", ""], ["Kapoutsis", "Athanasios Ch.", ""], ["Amanatiadis", "Angelos A.", ""], ["Kosmatopoulos", "Elias B.", ""]]}, {"id": "2107.09998", "submitter": "Xubo Liu", "authors": "Xubo Liu, Turab Iqbal, Jinzheng Zhao, Qiushi Huang, Mark D. Plumbley,\n  Wenwu Wang", "title": "Conditional Sound Generation Using Neural Discrete Time-Frequency\n  Representation Learning", "comments": "Submitted to MLSP 2021, 6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have recently achieved impressive performance in\nspeech and music synthesis. However, compared to the generation of those\ndomain-specific sounds, generating general sounds (such as siren, gunshots) has\nreceived less attention, despite their wide applications. In previous work, the\nSampleRNN method was considered for sound generation in the time domain.\nHowever, SampleRNN is potentially limited in capturing long-range dependencies\nwithin sounds as it only back-propagates through a limited number of samples.\nIn this work, we propose a method for generating sounds via neural discrete\ntime-frequency representation learning, conditioned on sound classes. This\noffers an advantage in efficiently modelling long-range dependencies and\nretaining local fine-grained structures within sound clips. We evaluate our\napproach on the UrbanSound8K dataset, compared to SampleRNN, with the\nperformance metrics measuring the quality and diversity of generated sounds.\nExperimental results show that our method offers comparable performance in\nquality and significantly better performance in diversity.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 10:31:28 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 17:33:30 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Liu", "Xubo", ""], ["Iqbal", "Turab", ""], ["Zhao", "Jinzheng", ""], ["Huang", "Qiushi", ""], ["Plumbley", "Mark D.", ""], ["Wang", "Wenwu", ""]]}, {"id": "2107.10013", "submitter": "Ren Hu", "authors": "Ren Hu and Qifeng Li", "title": "Optimal Operation of Power Systems with Energy Storage under\n  Uncertainty: A Scenario-based Method with Strategic Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-period dynamics of energy storage (ES), intermittent renewable\ngeneration and uncontrollable power loads, make the optimization of power\nsystem operation (PSO) challenging. A multi-period optimal PSO under\nuncertainty is formulated using the chance-constrained optimization (CCO)\nmodeling paradigm, where the constraints include the nonlinear energy storage\nand AC power flow models. Based on the emerging scenario optimization method\nwhich does not rely on pre-known probability distribution functions, this paper\ndevelops a novel solution method for this challenging CCO problem. The proposed\nmeth-od is computationally effective for mainly two reasons. First, the\noriginal AC power flow constraints are approximated by a set of\nlearning-assisted quadratic convex inequalities based on a generalized least\nabsolute shrinkage and selection operator. Second, considering the physical\npatterns of data and motived by learning-based sampling, the strategic sampling\nmethod is developed to significantly reduce the required number of scenarios\nthrough different sampling strategies. The simulation results on IEEE standard\nsystems indicate that 1) the proposed strategic sampling significantly improves\nthe computational efficiency of the scenario-based approach for solving the\nchance-constrained optimal PSO problem, 2) the data-driven convex approximation\nof power flow can be promising alternatives of nonlinear and nonconvex AC power\nflow.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 11:21:50 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Hu", "Ren", ""], ["Li", "Qifeng", ""]]}, {"id": "2107.10021", "submitter": "Henry Watkins", "authors": "Henry Watkins, Robert Gray, Ashwani Jha, Parashkev Nachev", "title": "An artificial intelligence natural language processing pipeline for\n  information extraction in neuroradiology", "comments": "20 pages, 2 png image figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of electronic health records in medical research is difficult because\nof the unstructured format. Extracting information within reports and\nsummarising patient presentations in a way amenable to downstream analysis\nwould be enormously beneficial for operational and clinical research. In this\nwork we present a natural language processing pipeline for information\nextraction of radiological reports in neurology. Our pipeline uses a hybrid\nsequence of rule-based and artificial intelligence models to accurately extract\nand summarise neurological reports. We train and evaluate a custom language\nmodel on a corpus of 150000 radiological reports from National Hospital for\nNeurology and Neurosurgery, London MRI imaging. We also present results for\nstandard NLP tasks on domain-specific neuroradiology datasets. We show our\npipeline, called `neuroNLP', can reliably extract clinically relevant\ninformation from these reports, enabling downstream modelling of reports and\nassociated imaging on a heretofore unprecedented scale.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 11:31:57 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Watkins", "Henry", ""], ["Gray", "Robert", ""], ["Jha", "Ashwani", ""], ["Nachev", "Parashkev", ""]]}, {"id": "2107.10034", "submitter": "Jan Jakubuv", "authors": "Karel Chvalovsk\\'y, Jan Jakub\\r{u}v, Miroslav Ol\\v{s}\\'ak, Josef Urban", "title": "Learning Theorem Proving Components", "comments": "Accepted to TABLEAUX'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG cs.NE cs.SC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Saturation-style automated theorem provers (ATPs) based on the given clause\nprocedure are today the strongest general reasoners for classical first-order\nlogic. The clause selection heuristics in such systems are, however, often\nevaluating clauses in isolation, ignoring other clauses. This has changed\nrecently by equipping the E/ENIGMA system with a graph neural network (GNN)\nthat chooses the next given clause based on its evaluation in the context of\npreviously selected clauses. In this work, we describe several algorithms and\nexperiments with ENIGMA, advancing the idea of contextual evaluation based on\nlearning important components of the graph of clauses.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 12:00:05 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chvalovsk\u00fd", "Karel", ""], ["Jakub\u016fv", "Jan", ""], ["Ol\u0161\u00e1k", "Miroslav", ""], ["Urban", "Josef", ""]]}, {"id": "2107.10083", "submitter": "Luis Olsina PhD", "authors": "Luis Olsina, Guido Tebes, Pablo Becker", "title": "SituationCO v1.2's Terms, Properties, Relationships and Axioms -- A Core\n  Ontology for Particular and Generic Situations", "comments": "9 pgs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The current preprint is an update to SituationCO v1.1 (Situation Core\nOntology), which represents its new version 1.2. It specifies and defines all\nthe terms, properties, relationships and axioms of SituationCO v1.2, being an\nontology for particular and generic Situations placed at the core level in the\ncontext of a four-layered ontological architecture called FCD-OntoArch\n(Foundational, Core, and Domain Ontological Architecture for Sciences). This is\na four-layered ontological architecture, which considers Foundational, Core,\nDomain and Instance levels. In turn, the domain level is split down in two\nsub-levels, namely: Top-domain and Low-domain ontological levels. So in fact,\nwe can consider it to be a five-tier architecture. Ontologies at the same level\ncan be related to each other, except for the foundational level where only\nThingFO (Thing Foundational Ontology) is found. In addition, ontologies' terms\nand relationships at lower levels can be semantically enriched by ontologies'\nterms and relationships from the higher levels. Note that both ThingFO and\nontologies at the core level such as SituationCO, ProcessCO, among others, are\ndomain independent. SituationCO's terms and relationships are specialized\nprimarily from ThingFO. It also completely reuses terms primarily from\nProcessCO, ProjectCO and GoalCO ontologies. Stereotypes are the used mechanism\nfor enriching SituationCO terms. Note that in the end of this document, we\naddress the SituationCO vs. ThingFO non-taxonomic relationship verification\nmatrix.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 13:54:40 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Olsina", "Luis", ""], ["Tebes", "Guido", ""], ["Becker", "Pablo", ""]]}, {"id": "2107.10111", "submitter": "Martin Pil\\'at", "authors": "Martin Pil\\'at", "title": "Training Electric Vehicle Charging Controllers with Imitation Learning", "comments": "Submitted to ICTAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of coordinating the charging of electric vehicles gains more\nimportance as the number of such vehicles grows. In this paper, we develop a\nmethod for the training of controllers for the coordination of EV charging. In\ncontrast to most existing works on this topic, we require the controllers to\npreserve the privacy of the users, therefore we do not allow any communication\nfrom the controller to any third party.\n  In order to train the controllers, we use the idea of imitation learning --\nwe first find an optimum solution for a relaxed version of the problem using\nquadratic optimization and then train the controllers to imitate this solution.\nWe also investigate the effects of regularization of the optimum solution on\nthe performance of the controllers. The method is evaluated on realistic data\nand shows improved performance and training speed compared to similar\ncontrollers trained using evolutionary algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 14:39:55 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Pil\u00e1t", "Martin", ""]]}, {"id": "2107.10121", "submitter": "Stanislav Zhydkov", "authors": "Omer Lev, Nicholas Mattei, Paolo Turrini, Stanislav Zhydkov", "title": "Peer Selection with Noisy Assessments", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the peer selection problem a group of agents must select a subset of\nthemselves as winners for, e.g., peer-reviewed grants or prizes. Here, we take\na Condorcet view of this aggregation problem, i.e., that there is a\nground-truth ordering over the agents and we wish to select the best set of\nagents, subject to the noisy assessments of the peers. Given this model, some\nagents may be unreliable, while others might be self-interested, attempting to\ninfluence the outcome in their favour. In this paper we extend PeerNomination,\nthe most accurate peer reviewing algorithm to date, into\nWeightedPeerNomination, which is able to handle noisy and inaccurate agents. To\ndo this, we explicitly formulate assessors' reliability weights in a way that\ndoes not violate strategyproofness, and use this information to reweight their\nscores. We show analytically that a weighting scheme can improve the overall\naccuracy of the selection significantly. Finally, we implement several\ninstances of reweighting methods and show empirically that our methods are\nrobust in the face of noisy assessments.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 14:47:11 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Lev", "Omer", ""], ["Mattei", "Nicholas", ""], ["Turrini", "Paolo", ""], ["Zhydkov", "Stanislav", ""]]}, {"id": "2107.10146", "submitter": "Majid Raeis", "authors": "Majid Raeis and Alberto Leon-Garcia", "title": "A Deep Reinforcement Learning Approach for Fair Traffic Signal Control", "comments": "7 pages, Accepted at ITSC 2021 (International Conference on\n  Intelligent Transportation Systems)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic signal control is one of the most effective methods of traffic\nmanagement in urban areas. In recent years, traffic control methods based on\ndeep reinforcement learning (DRL) have gained attention due to their ability to\nexploit real-time traffic data, which is often poorly used by the traditional\nhand-crafted methods. While most recent DRL-based methods have focused on\nmaximizing the throughput or minimizing the average travel time of the\nvehicles, the fairness of the traffic signal controllers has often been\nneglected. This is particularly important as neglecting fairness can lead to\nsituations where some vehicles experience extreme waiting times, or where the\nthroughput of a particular traffic flow is highly impacted by the fluctuations\nof another conflicting flow at the intersection. In order to address these\nissues, we introduce two notions of fairness: delay-based and throughput-based\nfairness, which correspond to the two issues mentioned above. Furthermore, we\npropose two DRL-based traffic signal control methods for implementing these\nfairness notions, that can achieve a high throughput as well. We evaluate the\nperformance of our proposed methods using three traffic arrival distributions,\nand find that our methods outperform the baselines in the tested scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 15:23:52 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Raeis", "Majid", ""], ["Leon-Garcia", "Alberto", ""]]}, {"id": "2107.10159", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi and Gabriela Reyes", "title": "Answer-Set Programs for Reasoning about Counterfactual Interventions and\n  Responsibility Scores for Classification", "comments": "Extended version with appendices of conference submission (under\n  review). arXiv admin note: text overlap with arXiv:2106.10562", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe how answer-set programs can be used to declaratively specify\ncounterfactual interventions on entities under classification, and reason about\nthem. In particular, they can be used to define and compute responsibility\nscores as attribution-based explanations for outcomes from classification\nmodels. The approach allows for the inclusion of domain knowledge and supports\nquery answering. A detailed example with a naive-Bayes classifier is presented.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 15:41:56 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Bertossi", "Leopoldo", ""], ["Reyes", "Gabriela", ""]]}, {"id": "2107.10199", "submitter": "Andrzej Banburski", "authors": "Andrzej Banburski, Fernanda De La Torre, Nishka Pant, Ishana Shastri,\n  Tomaso Poggio", "title": "Distribution of Classification Margins: Are All Data Equal?", "comments": "Previously online as CBMM Memo 115 on the CBMM MIT site", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent theoretical results show that gradient descent on deep neural networks\nunder exponential loss functions locally maximizes classification margin, which\nis equivalent to minimizing the norm of the weight matrices under margin\nconstraints. This property of the solution however does not fully characterize\nthe generalization performance. We motivate theoretically and show empirically\nthat the area under the curve of the margin distribution on the training set is\nin fact a good measure of generalization. We then show that, after data\nseparation is achieved, it is possible to dynamically reduce the training set\nby more than 99% without significant loss of performance. Interestingly, the\nresulting subset of \"high capacity\" features is not consistent across different\ntraining runs, which is consistent with the theoretical claim that all training\npoints should converge to the same asymptotic margin under SGD and in the\npresence of both batch normalization and weight decay.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 16:41:57 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Banburski", "Andrzej", ""], ["De La Torre", "Fernanda", ""], ["Pant", "Nishka", ""], ["Shastri", "Ishana", ""], ["Poggio", "Tomaso", ""]]}, {"id": "2107.10234", "submitter": "Zhiqian Chen", "authors": "Zhiqian Chen, Fanglan Chen, Lei Zhang, Taoran Ji, Kaiqun Fu, Liang\n  Zhao, Feng Chen, Lingfei Wu, Charu Aggarwal and Chang-Tien Lu", "title": "Bridging the Gap between Spatial and Spectral Domains: A Theoretical\n  Framework for Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the past decade, deep learning's performance has been widely\nrecognized in a variety of machine learning tasks, ranging from image\nclassification, speech recognition to natural language understanding. Graph\nneural networks (GNN) are a type of deep learning that is designed to handle\nnon-Euclidean issues using graph-structured data that are difficult to solve\nwith traditional deep learning techniques. The majority of GNNs were created\nusing a variety of processes, including random walk, PageRank, graph\nconvolution, and heat diffusion, making direct comparisons impossible. Previous\nstudies have primarily focused on classifying current models into distinct\ncategories, with little investigation of their internal relationships. This\nresearch proposes a unified theoretical framework and a novel perspective that\ncan methodologically integrate existing GNN into our framework. We survey and\ncategorize existing GNN models into spatial and spectral domains, as well as\nshow linkages between subcategories within each domain. Further investigation\nreveals a strong relationship between the spatial, spectral, and subgroups of\nthese domains.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 17:34:33 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chen", "Zhiqian", ""], ["Chen", "Fanglan", ""], ["Zhang", "Lei", ""], ["Ji", "Taoran", ""], ["Fu", "Kaiqun", ""], ["Zhao", "Liang", ""], ["Chen", "Feng", ""], ["Wu", "Lingfei", ""], ["Aggarwal", "Charu", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "2107.10253", "submitter": "Karl Pertsch", "authors": "Karl Pertsch, Youngwoon Lee, Yue Wu, Joseph J. Lim", "title": "Demonstration-Guided Reinforcement Learning with Learned Skills", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Demonstration-guided reinforcement learning (RL) is a promising approach for\nlearning complex behaviors by leveraging both reward feedback and a set of\ntarget task demonstrations. Prior approaches for demonstration-guided RL treat\nevery new task as an independent learning problem and attempt to follow the\nprovided demonstrations step-by-step, akin to a human trying to imitate a\ncompletely unseen behavior by following the demonstrator's exact muscle\nmovements. Naturally, such learning will be slow, but often new behaviors are\nnot completely unseen: they share subtasks with behaviors we have previously\nlearned. In this work, we aim to exploit this shared subtask structure to\nincrease the efficiency of demonstration-guided RL. We first learn a set of\nreusable skills from large offline datasets of prior experience collected\nacross many tasks. We then propose Skill-based Learning with Demonstrations\n(SkiLD), an algorithm for demonstration-guided RL that efficiently leverages\nthe provided demonstrations by following the demonstrated skills instead of the\nprimitive actions, resulting in substantial performance improvements over prior\ndemonstration-guided RL approaches. We validate the effectiveness of our\napproach on long-horizon maze navigation and complex robot manipulation tasks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 17:59:34 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Pertsch", "Karl", ""], ["Lee", "Youngwoon", ""], ["Wu", "Yue", ""], ["Lim", "Joseph J.", ""]]}, {"id": "2107.10254", "submitter": "Brandon Amos", "authors": "Shobha Venkataraman, Brandon Amos", "title": "Neural Fixed-Point Acceleration for Convex Optimization", "comments": "AutoML@ICML2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fixed-point iterations are at the heart of numerical computing and are often\na computational bottleneck in real-time applications that typically need a fast\nsolution of moderate accuracy. We present neural fixed-point acceleration which\ncombines ideas from meta-learning and classical acceleration methods to\nautomatically learn to accelerate fixed-point problems that are drawn from a\ndistribution. We apply our framework to SCS, the state-of-the-art solver for\nconvex cone programming, and design models and loss functions to overcome the\nchallenges of learning over unrolled optimization and acceleration\ninstabilities. Our work brings neural acceleration into any optimization\nproblem expressible with CVXPY. The source code behind this paper is available\nat https://github.com/facebookresearch/neural-scs\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 17:59:34 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 17:43:00 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Venkataraman", "Shobha", ""], ["Amos", "Brandon", ""]]}, {"id": "2107.10295", "submitter": "Tirtharaj Dash", "authors": "Tirtharaj Dash, Sharad Chitlangia, Aditya Ahuja, Ashwin Srinivasan", "title": "How to Tell Deep Neural Networks What We Know", "comments": "12 pages (full version); substantial overlap with arXiv:2103.00180", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a short survey of ways in which existing scientific knowledge are\nincluded when constructing models with neural networks. The inclusion of\ndomain-knowledge is of special interest not just to constructing scientific\nassistants, but also, many other areas that involve understanding data using\nhuman-machine collaboration. In many such instances, machine-based model\nconstruction may benefit significantly from being provided with human-knowledge\nof the domain encoded in a sufficiently precise form. This paper examines the\ninclusion of domain-knowledge by means of changes to: the input, the\nloss-function, and the architecture of deep networks. The categorisation is for\nease of exposition: in practice we expect a combination of such changes will be\nemployed. In each category, we describe techniques that have been shown to\nyield significant changes in network performance.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 18:18:02 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Dash", "Tirtharaj", ""], ["Chitlangia", "Sharad", ""], ["Ahuja", "Aditya", ""], ["Srinivasan", "Ashwin", ""]]}, {"id": "2107.10300", "submitter": "Aman Chadha Mr.", "authors": "Aman Chadha and Vinija Jain", "title": "iReason: Multimodal Commonsense Reasoning using Videos and Natural\n  Language with Interpretability", "comments": "12 pages, 1 figure, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causality knowledge is vital to building robust AI systems. Deep learning\nmodels often perform poorly on tasks that require causal reasoning, which is\noften derived using some form of commonsense knowledge not immediately\navailable in the input but implicitly inferred by humans. Prior work has\nunraveled spurious observational biases that models fall prey to in the absence\nof causality. While language representation models preserve contextual\nknowledge within learned embeddings, they do not factor in causal relationships\nduring training. By blending causal relationships with the input features to an\nexisting model that performs visual cognition tasks (such as scene\nunderstanding, video captioning, video question-answering, etc.), better\nperformance can be achieved owing to the insight causal relationships bring\nabout. Recently, several models have been proposed that have tackled the task\nof mining causal data from either the visual or textual modality. However,\nthere does not exist widespread research that mines causal relationships by\njuxtaposing the visual and language modalities. While images offer a rich and\neasy-to-process resource for us to mine causality knowledge from, videos are\ndenser and consist of naturally time-ordered events. Also, textual information\noffers details that could be implicit in videos. We propose iReason, a\nframework that infers visual-semantic commonsense knowledge using both videos\nand natural language captions. Furthermore, iReason's architecture integrates a\ncausal rationalization module to aid the process of interpretability, error\nanalysis and bias detection. We demonstrate the effectiveness of iReason using\na two-pronged comparative analysis with language representation learning models\n(BERT, GPT-2) as well as current state-of-the-art multimodal causality models.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 02:56:34 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Chadha", "Aman", ""], ["Jain", "Vinija", ""]]}, {"id": "2107.10332", "submitter": "Abicumaran Uthamacumaran", "authors": "Abicumaran Uthamacumaran, Samir Elouatik, Mohamed Abdouh, Michael\n  Berteau-Rainville, Zhu- Hua Gao, and Goffredo Arena", "title": "Machine Learning Characterization of Cancer Patients-Derived\n  Extracellular Vesicles using Vibrational Spectroscopies", "comments": "50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.OT cs.AI cs.LG physics.bio-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The early detection of cancer is a challenging problem in medicine. The blood\nsera of cancer patients are enriched with heterogeneous secretory lipid bound\nextracellular vesicles (EVs), which present a complex repertoire of information\nand biomarkers, representing their cell of origin, that are being currently\nstudied in the field of liquid biopsy and cancer screening. Vibrational\nspectroscopies provide non-invasive approaches for the assessment of structural\nand biophysical properties in complex biological samples. In this study,\nmultiple Raman spectroscopy measurements were performed on the EVs extracted\nfrom the blood sera of 9 patients consisting of four different cancer subtypes\n(colorectal cancer, hepatocellular carcinoma, breast cancer and pancreatic\ncancer) and five healthy patients (controls). FTIR(Fourier Transform Infrared)\nspectroscopy measurements were performed as a complementary approach to Raman\nanalysis, on two of the four cancer subtypes.\n  The AdaBoost Random Forest Classifier, Decision Trees, and Support Vector\nMachines (SVM) distinguished the baseline corrected Raman spectra of cancer EVs\nfrom those of healthy controls (18 spectra) with a classification accuracy of\ngreater than 90% when reduced to a spectral frequency range of 1800 to 1940\ninverse cm, and subjected to a 0.5 training/testing split. FTIR classification\naccuracy on 14 spectra showed an 80% classification accuracy. Our findings\ndemonstrate that basic machine learning algorithms are powerful tools to\ndistinguish the complex vibrational spectra of cancer patient EVs from those of\nhealthy patients. These experimental methods hold promise as valid and\nefficient liquid biopsy for machine intelligence-assisted early cancer\nscreening.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 19:56:33 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Uthamacumaran", "Abicumaran", ""], ["Elouatik", "Samir", ""], ["Abdouh", "Mohamed", ""], ["Berteau-Rainville", "Michael", ""], ["Gao", "Zhu- Hua", ""], ["Arena", "Goffredo", ""]]}, {"id": "2107.10350", "submitter": "Liang Sun", "authors": "Liang Sun and Leonardo Escamilla", "title": "Uncertainty-Aware Task Allocation for Distributed Autonomous Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses task-allocation problems with uncertainty in situational\nawareness for distributed autonomous robots (DARs). The uncertainty propagation\nover a task-allocation process is done by using the Unscented transform that\nuses the Sigma-Point sampling mechanism. It has great potential to be employed\nfor generic task-allocation schemes, in the sense that there is no need to\nmodify an existing task-allocation method that has been developed without\nconsidering the uncertainty in the situational awareness. The proposed\nframework was tested in a simulated environment where the decision-maker needs\nto determine an optimal allocation of multiple locations assigned to multiple\nmobile flying robots whose locations come as random variables of known mean and\ncovariance. The simulation result shows that the proposed stochastic task\nallocation approach generates an assignment with 30% less overall cost than the\none without considering the uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 20:43:05 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Sun", "Liang", ""], ["Escamilla", "Leonardo", ""]]}, {"id": "2107.10390", "submitter": "Xuan Zhao", "authors": "Xuan Zhao and Marcos Campos", "title": "Reinforcement Learning Agent Training with Goals for Real World Tasks", "comments": "Accepted to Reinforcement Learning for Real Life (RL4RealLife)\n  Workshop in the 38th International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Reinforcement Learning (RL) is a promising approach for solving various\ncontrol, optimization, and sequential decision making tasks. However, designing\nreward functions for complex tasks (e.g., with multiple objectives and safety\nconstraints) can be challenging for most users and usually requires multiple\nexpensive trials (reward function hacking). In this paper we propose a\nspecification language (Inkling Goal Specification) for complex control and\noptimization tasks, which is very close to natural language and allows a\npractitioner to focus on problem specification instead of reward function\nhacking. The core elements of our framework are: (i) mapping the high level\nlanguage to a predicate temporal logic tailored to control and optimization\ntasks, (ii) a novel automaton-guided dense reward generation that can be used\nto drive RL algorithms, and (iii) a set of performance metrics to assess the\nbehavior of the system. We include a set of experiments showing that the\nproposed method provides great ease of use to specify a wide range of real\nworld tasks; and that the reward generated is able to drive the policy training\nto achieve the specified goal.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 23:21:16 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Zhao", "Xuan", ""], ["Campos", "Marcos", ""]]}, {"id": "2107.10410", "submitter": "Kai-Hui Liang", "authors": "Kai-Hui Liang, Patrick Lange, Yoo Jung Oh, Jingwen Zhang, Yoshimi\n  Fukuoka, Zhou Yu", "title": "Evaluation of In-Person Counseling Strategies To Develop Physical\n  Activity Chatbot for Women", "comments": "Accepted by SIGDIAL 2021 as a long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence chatbots are the vanguard in technology-based\nintervention to change people's behavior. To develop intervention chatbots, the\nfirst step is to understand natural language conversation strategies in human\nconversation. This work introduces an intervention conversation dataset\ncollected from a real-world physical activity intervention program for women.\nWe designed comprehensive annotation schemes in four dimensions (domain,\nstrategy, social exchange, and task-focused exchange) and annotated a subset of\ndialogs. We built a strategy classifier with context information to detect\nstrategies from both trainers and participants based on the annotation. To\nunderstand how human intervention induces effective behavior changes, we\nanalyzed the relationships between the intervention strategies and the\nparticipants' changes in the barrier and social support for physical activity.\nWe also analyzed how participant's baseline weight correlates to the amount of\noccurrence of the corresponding strategy. This work lays the foundation for\ndeveloping a personalized physical activity intervention bot. The dataset and\ncode are available at\nhttps://github.com/KaihuiLiang/physical-activity-counseling\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 00:39:21 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Liang", "Kai-Hui", ""], ["Lange", "Patrick", ""], ["Oh", "Yoo Jung", ""], ["Zhang", "Jingwen", ""], ["Fukuoka", "Yoshimi", ""], ["Yu", "Zhou", ""]]}, {"id": "2107.10429", "submitter": "Roberto Perera", "authors": "Libo Sun, James Browning, Roberto Perera", "title": "Shedding some light on Light Up with Artificial Intelligence", "comments": "14 pages, 16 figures, for associated codes, see\n  \\<https://github.com/rperera12/AKARI-LightUp-GameSolver-with-DeepNeuralNetworks-and-HillClimb-or-SimulatedAnnealing>", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Light-Up puzzle, also known as the AKARI puzzle, has never been solved\nusing modern artificial intelligence (AI) methods. Currently, the most widely\nused computational technique to autonomously develop solutions involve\nevolution theory algorithms. This project is an effort to apply new AI\ntechniques for solving the Light-up puzzle faster and more computationally\nefficient. The algorithms explored for producing optimal solutions include hill\nclimbing, simulated annealing, feed-forward neural network (FNN), and\nconvolutional neural network (CNN). Two algorithms were developed for hill\nclimbing and simulated annealing using 2 actions (add and remove light bulb)\nversus 3 actions(add, remove, or move light-bulb to a different cell). Both\nhill climbing and simulated annealing algorithms showed a higher accuracy for\nthe case of 3 actions. The simulated annealing showed to significantly\noutperform hill climbing, FNN, CNN, and an evolutionary theory algorithm\nachieving 100% accuracy in 30 unique board configurations. Lastly, while FNN\nand CNN algorithms showed low accuracies, computational times were\nsignificantly faster compared to the remaining algorithms. The GitHub\nrepository for this project can be found at\nhttps://github.com/rperera12/AKARI-LightUp-GameSolver-with-DeepNeuralNetworks-and-HillClimb-or-SimulatedAnnealing.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 03:03:57 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Sun", "Libo", ""], ["Browning", "James", ""], ["Perera", "Roberto", ""]]}, {"id": "2107.10433", "submitter": "Xiao Wang", "authors": "Xiao Wang, Xiujun Shu, Shiliang Zhang, Bo Jiang, Yaowei Wang, Yonghong\n  Tian, Feng Wu", "title": "MFGNet: Dynamic Modality-Aware Filter Generation for RGB-T Tracking", "comments": "In Peer Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many RGB-T trackers attempt to attain robust feature representation by\nutilizing an adaptive weighting scheme (or attention mechanism). Different from\nthese works, we propose a new dynamic modality-aware filter generation module\n(named MFGNet) to boost the message communication between visible and thermal\ndata by adaptively adjusting the convolutional kernels for various input images\nin practical tracking. Given the image pairs as input, we first encode their\nfeatures with the backbone network. Then, we concatenate these feature maps and\ngenerate dynamic modality-aware filters with two independent networks. The\nvisible and thermal filters will be used to conduct a dynamic convolutional\noperation on their corresponding input feature maps respectively. Inspired by\nresidual connection, both the generated visible and thermal feature maps will\nbe summarized with input feature maps. The augmented feature maps will be fed\ninto the RoI align module to generate instance-level features for subsequent\nclassification. To address issues caused by heavy occlusion, fast motion, and\nout-of-view, we propose to conduct a joint local and global search by\nexploiting a new direction-aware target-driven attention mechanism. The spatial\nand temporal recurrent neural network is used to capture the direction-aware\ncontext for accurate global attention prediction. Extensive experiments on\nthree large-scale RGB-T tracking benchmark datasets validated the effectiveness\nof our proposed algorithm. The project page of this paper is available at\nhttps://sites.google.com/view/mfgrgbttrack/.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 03:10:51 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Wang", "Xiao", ""], ["Shu", "Xiujun", ""], ["Zhang", "Shiliang", ""], ["Jiang", "Bo", ""], ["Wang", "Yaowei", ""], ["Tian", "Yonghong", ""], ["Wu", "Feng", ""]]}, {"id": "2107.10469", "submitter": "Karn Watcharasupat", "authors": "Thi Ngoc Tho Nguyen and Karn N. Watcharasupat and Zhen Jian Lee and\n  Ngoc Khanh Nguyen and Douglas L. Jones and Woon Seng Gan", "title": "What Makes Sound Event Localization and Detection Difficult? Insights\n  from Error Analysis", "comments": "Under review for the 6th Workshop on Detection and Classification of\n  Acoustic Scenes and Events (DCASE), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sound event localization and detection (SELD) is an emerging research topic\nthat aims to unify the tasks of sound event detection and direction-of-arrival\nestimation. As a result, SELD inherits the challenges of both tasks, such as\nnoise, reverberation, interference, polyphony, and non-stationarity of sound\nsources. Furthermore, SELD often faces an additional challenge of assigning\ncorrect correspondences between the detected sound classes and directions of\narrival to multiple overlapping sound events. Previous studies have shown that\nunknown interferences in reverberant environments often cause major degradation\nin the performance of SELD systems. To further understand the challenges of the\nSELD task, we performed a detailed error analysis on two of our SELD systems,\nwhich both ranked second in the team category of DCASE SELD Challenge, one in\n2020 and one in 2021. Experimental results indicate polyphony as the main\nchallenge in SELD, due to the difficulty in detecting all sound events of\ninterest. In addition, the SELD systems tend to make fewer errors for the\npolyphonic scenario that is dominant in the training set.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 06:01:49 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Nguyen", "Thi Ngoc Tho", ""], ["Watcharasupat", "Karn N.", ""], ["Lee", "Zhen Jian", ""], ["Nguyen", "Ngoc Khanh", ""], ["Jones", "Douglas L.", ""], ["Gan", "Woon Seng", ""]]}, {"id": "2107.10471", "submitter": "Karn Watcharasupat", "authors": "Karn N. Watcharasupat and Thi Ngoc Tho Nguyen and Ngoc Khanh Nguyen\n  and Zhen Jian Lee and Douglas L. Jones and Woon Seng Gan", "title": "Improving Polyphonic Sound Event Detection on Multichannel Recordings\n  with the S{\\o}rensen-Dice Coefficient Loss and Transfer Learning", "comments": "Under review for the 6th Workshop on Detection and Classification of\n  Acoustic Scenes and Events (DCASE), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The S{\\o}rensen--Dice Coefficient has recently seen rising popularity as a\nloss function (also known as Dice loss) due to its robustness in tasks where\nthe number of negative samples significantly exceeds that of positive samples,\nsuch as semantic segmentation, natural language processing, and sound event\ndetection. Conventional training of polyphonic sound event detection systems\nwith binary cross-entropy loss often results in suboptimal detection\nperformance as the training is often overwhelmed by updates from negative\nsamples. In this paper, we investigated the effect of the Dice loss, intra- and\ninter-modal transfer learning, data augmentation, and recording formats, on the\nperformance of polyphonic sound event detection systems with multichannel\ninputs. Our analysis showed that polyphonic sound event detection systems\ntrained with Dice loss consistently outperformed those trained with\ncross-entropy loss across different training settings and recording formats in\nterms of F1 score and error rate. We achieved further performance gains via the\nuse of transfer learning and an appropriate combination of different data\naugmentation techniques.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 06:14:23 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Watcharasupat", "Karn N.", ""], ["Nguyen", "Thi Ngoc Tho", ""], ["Nguyen", "Ngoc Khanh", ""], ["Lee", "Zhen Jian", ""], ["Jones", "Douglas L.", ""], ["Gan", "Woon Seng", ""]]}, {"id": "2107.10479", "submitter": "Cheng Yang", "authors": "Cheng Yang", "title": "Copy and Paste method based on Pose for Re-identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Re-identification (ReID) aims at matching objects in surveillance cameras\nwith different viewpoints. It's developing very fast, but there is no\nprocessing method for the ReID task in multiple scenarios at this stage.\nHowever, this dose happen all the time in real life, such as the security\nscenarios. This paper explores a new scenario of Re-identification, which\ndiffers in perspective, background, and pose(walking or cycling). Obviously,\nordinary ReID processing methods cannot handle this scenario well. As we all\nknow, the best way to deal with that it is to introduce image datasets in this\nscanario, But this one is very expensive.\n  To solve this problem, this paper proposes a simple and effective way to\ngenerate images in some new scenario, which is named Copy and Paste method\nbased on Pose(CPP). The CPP is a method based on key point detection, using\ncopy and paste, to composite a new semantic image dataset in two different\nsemantic image datasets. Such as, we can use pedestrians and bicycles to\ngenerate some images that shows the same person rides on different bicycles.\nThe CPP is suitable for ReID tasks in new scenarios and it outperforms\nstate-of-the-art on the original datasets in original ReID tasks. Specifically,\nit can also have better generalization performance for third-party public\ndatasets. Code and Datasets which composited by the CPP will be available in\nthe future.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 06:51:34 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 15:47:00 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Yang", "Cheng", ""]]}, {"id": "2107.10483", "submitter": "Phillip Lippe", "authors": "Phillip Lippe, Taco Cohen, Efstratios Gavves", "title": "Efficient Neural Causal Discovery without Acyclicity Constraints", "comments": "8th Causal Inference Workshop at UAI 2021 (contributed talk). 34\n  pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning the structure of a causal graphical model using both observational\nand interventional data is a fundamental problem in many scientific fields. A\npromising direction is continuous optimization for score-based methods, which\nefficiently learn the causal graph in a data-driven manner. However, to date,\nthose methods require constrained optimization to enforce acyclicity or lack\nconvergence guarantees. In this paper, we present ENCO, an efficient structure\nlearning method for directed, acyclic causal graphs leveraging observational\nand interventional data. ENCO formulates the graph search as an optimization of\nindependent edge likelihoods, with the edge orientation being modeled as a\nseparate parameter. Consequently, we can provide convergence guarantees of ENCO\nunder mild conditions without constraining the score function with respect to\nacyclicity. In experiments, we show that ENCO can efficiently recover graphs\nwith hundreds of nodes, an order of magnitude larger than what was previously\npossible, while handling deterministic variables and latent confounders.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 07:01:41 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Lippe", "Phillip", ""], ["Cohen", "Taco", ""], ["Gavves", "Efstratios", ""]]}, {"id": "2107.10484", "submitter": "Mingyuan Bai", "authors": "Mingyuan Bai, S.T. Boris Choy, Junping Zhang, Junbin Gao", "title": "Neural Ordinary Differential Equation Model for Evolutionary Subspace\n  Clustering and Its Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The neural ordinary differential equation (neural ODE) model has attracted\nincreasing attention in time series analysis for its capability to process\nirregular time steps, i.e., data are not observed over equally-spaced time\nintervals. In multi-dimensional time series analysis, a task is to conduct\nevolutionary subspace clustering, aiming at clustering temporal data according\nto their evolving low-dimensional subspace structures. Many existing methods\ncan only process time series with regular time steps while time series are\nunevenly sampled in many situations such as missing data. In this paper, we\npropose a neural ODE model for evolutionary subspace clustering to overcome\nthis limitation and a new objective function with subspace self-expressiveness\nconstraint is introduced. We demonstrate that this method can not only\ninterpolate data at any time step for the evolutionary subspace clustering\ntask, but also achieve higher accuracy than other state-of-the-art evolutionary\nsubspace clustering methods. Both synthetic and real-world data are used to\nillustrate the efficacy of our proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 07:02:03 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Bai", "Mingyuan", ""], ["Choy", "S. T. Boris", ""], ["Zhang", "Junping", ""], ["Gao", "Junbin", ""]]}, {"id": "2107.10493", "submitter": "Sihyun Yu", "authors": "Sihyun Yu, Sangwoo Mo, Sungsoo Ahn, Jinwoo Shin", "title": "Abstract Reasoning via Logic-guided Generation", "comments": "ICML 2021 Workshop on Self-Supervised Learning for Reasoning and\n  Perception (Spotlight Talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract reasoning, i.e., inferring complicated patterns from given\nobservations, is a central building block of artificial general intelligence.\nWhile humans find the answer by either eliminating wrong candidates or first\nconstructing the answer, prior deep neural network (DNN)-based methods focus on\nthe former discriminative approach. This paper aims to design a framework for\nthe latter approach and bridge the gap between artificial and human\nintelligence. To this end, we propose logic-guided generation (LoGe), a novel\ngenerative DNN framework that reduces abstract reasoning as an optimization\nproblem in propositional logic. LoGe is composed of three steps: extract\npropositional variables from images, reason the answer variables with a logic\nlayer, and reconstruct the answer image from the variables. We demonstrate that\nLoGe outperforms the black box DNN frameworks for generative abstract reasoning\nunder the RAVEN benchmark, i.e., reconstructing answers based on capturing\ncorrect rules of various attributes from observations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 07:28:24 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Yu", "Sihyun", ""], ["Mo", "Sangwoo", ""], ["Ahn", "Sungsoo", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2107.10508", "submitter": "Marc E. Sol\\`er", "authors": "Tobias Fankhauser, Marc E. Sol\\`er, Rudolf M. F\\\"uchslin, Kurt\n  Stockinger", "title": "Multiple Query Optimization using a Hybrid Approach of Classical and\n  Quantum Computing", "comments": "18 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantum computing promises to solve difficult optimization problems in\nchemistry, physics and mathematics more efficiently than classical computers,\nbut requires fault-tolerant quantum computers with millions of qubits. To\novercome errors introduced by today's quantum computers, hybrid algorithms\ncombining classical and quantum computers are used. In this paper we tackle the\nmultiple query optimization problem (MQO) which is an important NP-hard problem\nin the area of data-intensive problems. We propose a novel hybrid\nclassical-quantum algorithm to solve the MQO on a gate-based quantum computer.\nWe perform a detailed experimental evaluation of our algorithm and compare its\nperformance against a competing approach that employs a quantum annealer --\nanother type of quantum computer. Our experimental results demonstrate that our\nalgorithm currently can only handle small problem sizes due to the limited\nnumber of qubits available on a gate-based quantum computer compared to a\nquantum computer based on quantum annealing. However, our algorithm shows a\nqubit efficiency of close to 99% which is almost a factor of 2 higher compared\nto the state of the art implementation. Finally, we analyze how our algorithm\nscales with larger problem sizes and conclude that our approach shows promising\nresults for near-term quantum computers.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 08:12:49 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Fankhauser", "Tobias", ""], ["Sol\u00e8r", "Marc E.", ""], ["F\u00fcchslin", "Rudolf M.", ""], ["Stockinger", "Kurt", ""]]}, {"id": "2107.10602", "submitter": "Yanwen Fang", "authors": "Yanwen Fang, Philip L. H. Yu, Yaohua Tang", "title": "CNN-based Realized Covariance Matrix Forecasting", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is well known that modeling and forecasting realized covariance matrices\nof asset returns play a crucial role in the field of finance. The availability\nof high frequency intraday data enables the modeling of the realized covariance\nmatrices directly. However, most of the models available in the literature\ndepend on strong structural assumptions and they often suffer from the curse of\ndimensionality. We propose an end-to-end trainable model built on the CNN and\nConvolutional LSTM (ConvLSTM) which does not require to make any distributional\nor structural assumption but could handle high-dimensional realized covariance\nmatrices consistently. The proposed model focuses on local structures and\nspatiotemporal correlations. It learns a nonlinear mapping that connect the\nhistorical realized covariance matrices to the future one. Our empirical\nstudies on synthetic and real-world datasets demonstrate its excellent\nforecasting ability compared with several advanced volatility models.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 12:02:24 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Fang", "Yanwen", ""], ["Yu", "Philip L. H.", ""], ["Tang", "Yaohua", ""]]}, {"id": "2107.10624", "submitter": "Pavlo Molchanov", "authors": "Pavlo Molchanov and Jimmy Hall and Hongxu Yin and Jan Kautz and Nicolo\n  Fusi and Arash Vahdat", "title": "HANT: Hardware-Aware Network Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a trained network, how can we accelerate it to meet efficiency needs\nfor deployment on particular hardware? The commonly used hardware-aware network\ncompression techniques address this question with pruning, kernel fusion,\nquantization and lowering precision. However, these approaches do not change\nthe underlying network operations. In this paper, we propose hardware-aware\nnetwork transformation (HANT), which accelerates a network by replacing\ninefficient operations with more efficient alternatives using a neural\narchitecture search like approach. HANT tackles the problem in two phase: In\nthe first phase, a large number of alternative operations per every layer of\nthe teacher model is trained using layer-wise feature map distillation. In the\nsecond phase, the combinatorial selection of efficient operations is relaxed to\nan integer optimization problem that can be solved in a few seconds. We extend\nHANT with kernel fusion and quantization to improve throughput even further.\nOur experimental results on accelerating the EfficientNet family show that HANT\ncan accelerate them by up to 3.6x with <0.4% drop in the top-1 accuracy on the\nImageNet dataset. When comparing the same latency level, HANT can accelerate\nEfficientNet-B4 to the same latency as EfficientNet-B1 while having 3% higher\naccuracy. We examine a large pool of operations, up to 197 per layer, and we\nprovide insights into the selected operations and final architectures.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 18:46:34 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Molchanov", "Pavlo", ""], ["Hall", "Jimmy", ""], ["Yin", "Hongxu", ""], ["Kautz", "Jan", ""], ["Fusi", "Nicolo", ""], ["Vahdat", "Arash", ""]]}, {"id": "2107.10648", "submitter": "Shakshi Sharma", "authors": "Mohit Mayank, Shakshi Sharma, Rajesh Sharma", "title": "DEAP-FAKED: Knowledge Graph based Approach for Fake News Detection", "comments": "8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake News on social media platforms has attracted a lot of attention in\nrecent times, primarily for events related to politics (2016 US Presidential\nelections), healthcare (infodemic during COVID-19), to name a few. Various\nmethods have been proposed for detecting Fake News. The approaches span from\nexploiting techniques related to network analysis, Natural Language Processing\n(NLP), and the usage of Graph Neural Networks (GNNs). In this work, we propose\nDEAP-FAKED, a knowleDgE grAPh FAKe nEws Detection framework for identifying\nFake News. Our approach is a combination of the NLP -- where we encode the news\ncontent, and the GNN technique -- where we encode the Knowledge Graph (KG). A\nvariety of these encodings provides a complementary advantage to our detector.\nWe evaluate our framework using two publicly available datasets containing\narticles from domains such as politics, business, technology, and healthcare.\nAs part of dataset pre-processing, we also remove the bias, such as the source\nof the articles, which could impact the performance of the models. DEAP-FAKED\nobtains an F1-score of 88% and 78% for the two datasets, which is an\nimprovement of 21%, and 3% respectively, which shows the effectiveness of the\napproach.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 07:09:59 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Mayank", "Mohit", ""], ["Sharma", "Shakshi", ""], ["Sharma", "Rajesh", ""]]}, {"id": "2107.10653", "submitter": "Kaiyu Zheng", "authors": "Monica Roy, Kaiyu Zheng, Jason Liu, Stefanie Tellex", "title": "Dialogue Object Search", "comments": "3 pages, 1 figure. Robotics: Science and Systems (RSS) 2021 Workshop\n  on Robotics for People (R4P): Perspectives on Interaction, Learning and\n  Safety. Extended Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We envision robots that can collaborate and communicate seamlessly with\nhumans. It is necessary for such robots to decide both what to say and how to\nact, while interacting with humans. To this end, we introduce a new task,\ndialogue object search: A robot is tasked to search for a target object (e.g.\nfork) in a human environment (e.g., kitchen), while engaging in a \"video call\"\nwith a remote human who has additional but inexact knowledge about the target's\nlocation. That is, the robot conducts speech-based dialogue with the human,\nwhile sharing the image from its mounted camera. This task is challenging at\nmultiple levels, from data collection, algorithm and system development,to\nevaluation. Despite these challenges, we believe such a task blocks the path\ntowards more intelligent and collaborative robots. In this extended abstract,\nwe motivate and introduce the dialogue object search task and analyze examples\ncollected from a pilot study. We then discuss our next steps and conclude with\nseveral challenges on which we hope to receive feedback.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 13:32:14 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Roy", "Monica", ""], ["Zheng", "Kaiyu", ""], ["Liu", "Jason", ""], ["Tellex", "Stefanie", ""]]}, {"id": "2107.10658", "submitter": "Joanna Rownicka", "authors": "Joanna Rownicka, Kilian Sprenkamp, Antonio Tripiana, Volodymyr\n  Gromoglasov, Timo P Kunz", "title": "Digital Einstein Experience: Fast Text-to-Speech for Conversational AI", "comments": "accepted at Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our approach to create and deliver a custom voice for a\nconversational AI use-case. More specifically, we provide a voice for a Digital\nEinstein character, to enable human-computer interaction within the digital\nconversation experience. To create the voice which fits the context well, we\nfirst design a voice character and we produce the recordings which correspond\nto the desired speech attributes. We then model the voice. Our solution\nutilizes Fastspeech 2 for log-scaled mel-spectrogram prediction from phonemes\nand Parallel WaveGAN to generate the waveforms. The system supports a character\ninput and gives a speech waveform at the output. We use a custom dictionary for\nselected words to ensure their proper pronunciation. Our proposed cloud\narchitecture enables for fast voice delivery, making it possible to talk to the\ndigital version of Albert Einstein in real-time.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 12:03:27 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Rownicka", "Joanna", ""], ["Sprenkamp", "Kilian", ""], ["Tripiana", "Antonio", ""], ["Gromoglasov", "Volodymyr", ""], ["Kunz", "Timo P", ""]]}, {"id": "2107.10703", "submitter": "Alexandre Drouin", "authors": "Philippe Brouillard, Perouz Taslakian, Alexandre Lacoste, Sebastien\n  Lachapelle, Alexandre Drouin", "title": "Typing assumptions improve identification in causal discovery", "comments": "Accepted for presentation as a contributed talk at the Workshop on\n  the Neglected Assumptions in Causal Inference (NACI) at the 38th\n  International Conference on Machine Learning, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal discovery from observational data is a challenging task to which an\nexact solution cannot always be identified. Under assumptions about the\ndata-generative process, the causal graph can often be identified up to an\nequivalence class. Proposing new realistic assumptions to circumscribe such\nequivalence classes is an active field of research. In this work, we propose a\nnew set of assumptions that constrain possible causal relationships based on\nthe nature of the variables. We thus introduce typed directed acyclic graphs,\nin which variable types are used to determine the validity of causal\nrelationships. We demonstrate, both theoretically and empirically, that the\nproposed assumptions can result in significant gains in the identification of\nthe causal graph.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 14:23:08 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Brouillard", "Philippe", ""], ["Taslakian", "Perouz", ""], ["Lacoste", "Alexandre", ""], ["Lachapelle", "Sebastien", ""], ["Drouin", "Alexandre", ""]]}, {"id": "2107.10709", "submitter": "Leonardos Pantiskas", "authors": "Luis P. Silvestrin, Leonardos Pantiskas, Mark Hoogendoorn", "title": "A Framework for Imbalanced Time-series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time-series forecasting plays an important role in many domains. Boosted by\nthe advances in Deep Learning algorithms, it has for instance been used to\npredict wind power for eolic energy production, stock market fluctuations, or\nmotor overheating. In some of these tasks, we are interested in predicting\naccurately some particular moments which often are underrepresented in the\ndataset, resulting in a problem known as imbalanced regression. In the\nliterature, while recognized as a challenging problem, limited attention has\nbeen devoted on how to handle the problem in a practical setting. In this\npaper, we put forward a general approach to analyze time-series forecasting\nproblems focusing on those underrepresented moments to reduce imbalances. Our\napproach has been developed based on a case study in a large industrial\ncompany, which we use to exemplify the approach.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 14:32:30 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Silvestrin", "Luis P.", ""], ["Pantiskas", "Leonardos", ""], ["Hoogendoorn", "Mark", ""]]}, {"id": "2107.10715", "submitter": "Michael Timothy Bennett", "authors": "Michael Timothy Bennett, Yoshihiro Maruyama", "title": "Philosophical Specification of Empathetic Ethical Artificial\n  Intelligence", "comments": "To appear in IEEE Transactions in Cognitive and Developmental Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In order to construct an ethical artificial intelligence (AI) two complex\nproblems must be overcome. Firstly, humans do not consistently agree on what is\nor is not ethical. Second, contemporary AI and machine learning methods tend to\nbe blunt instruments which either search for solutions within the bounds of\npredefined rules, or mimic behaviour. An ethical AI must be capable of\ninferring unspoken rules, interpreting nuance and context, possess and be able\nto infer intent, and explain not just its actions but its intent. Using\nenactivism, semiotics, perceptual symbol systems and symbol emergence, we\nspecify an agent that learns not just arbitrary relations between signs but\ntheir meaning in terms of the perceptual states of its sensorimotor system.\nSubsequently it can learn what is meant by a sentence and infer the intent of\nothers in terms of its own experiences. It has malleable intent because the\nmeaning of symbols changes as it learns, and its intent is represented\nsymbolically as a goal. As such it may learn a concept of what is most likely\nto be considered ethical by the majority within a population of humans, which\nmay then be used as a goal. The meaning of abstract symbols is expressed using\nperceptual symbols of raw sensorimotor stimuli as the weakest (consistent with\nOckham's Razor) necessary and sufficient concept, an intensional definition\nlearned from an ostensive definition, from which the extensional definition or\ncategory of all ethical decisions may be obtained. Because these abstract\nsymbols are the same for both situation and response, the same symbol is used\nwhen either performing or observing an action. This is akin to mirror neurons\nin the human brain. Mirror symbols may allow the agent to empathise, because\nits own experiences are associated with the symbol, which is also associated\nwith the observation of another agent experiencing something that symbol\nrepresents.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 14:37:46 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Bennett", "Michael Timothy", ""], ["Maruyama", "Yoshihiro", ""]]}, {"id": "2107.10742", "submitter": "Xin Chang", "authors": "Xin Chang and W{\\l}adys{\\l}aw Skarbek", "title": "Multi-modal Residual Perceptron Network for Audio-Video Emotion\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.SD eess.AS eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emotion recognition is an important research field for Human-Computer\nInteraction(HCI). Audio-Video Emotion Recognition (AVER) is now attacked with\nDeep Neural Network (DNN) modeling tools. In published papers, as a rule, the\nauthors show only cases of the superiority of multi modalities over audio-only\nor video-only modalities. However, there are cases superiority in single\nmodality can be found. In our research, we hypothesize that for fuzzy\ncategories of emotional events, the higher noise of one modality can amplify\nthe lower noise of the second modality represented indirectly in the parameters\nof the modeling neural network. To avoid such cross-modal information\ninterference we define a multi-modal Residual Perceptron Network (MRPN) which\nlearns from multi-modal network branches creating deep feature representation\nwith reduced noise. For the proposed MRPN model and the novel time augmentation\nfor streamed digital movies, the state-of-art average recognition rate was\nimproved to 91.4% for The Ryerson Audio-Visual Database of Emotional Speech and\nSong(RAVDESS) dataset and to 83.15% for Crowd-sourced Emotional multi-modal\nActors Dataset(Crema-d). Moreover, the MRPN concept shows its potential for\nmulti-modal classifiers dealing with signal sources not only of optical and\nacoustical type.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 13:11:37 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Chang", "Xin", ""], ["Skarbek", "W\u0142adys\u0142aw", ""]]}, {"id": "2107.10790", "submitter": "Juan Manuel Mayor Torres", "authors": "Juan Manuel Mayor-Torres, Mirco Ravanelli, Sara E. Medina-DeVilliers,\n  Matthew D. Lerner and Giuseppe Riccardi", "title": "Interpretable SincNet-based Deep Learning for Emotion Recognition from\n  EEG brain activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning methods, such as deep learning, show promising results in\nthe medical domain. However, the lack of interpretability of these algorithms\nmay hinder their applicability to medical decision support systems. This paper\nstudies an interpretable deep learning technique, called SincNet. SincNet is a\nconvolutional neural network that efficiently learns customized band-pass\nfilters through trainable sinc-functions. In this study, we use SincNet to\nanalyze the neural activity of individuals with Autism Spectrum Disorder (ASD),\nwho experience characteristic differences in neural oscillatory activity. In\nparticular, we propose a novel SincNet-based neural network for detecting\nemotions in ASD patients using EEG signals. The learned filters can be easily\ninspected to detect which part of the EEG spectrum is used for predicting\nemotions. We found that our system automatically learns the high-$\\alpha$ (9-13\nHz) and $\\beta$ (13-30 Hz) band suppression often present in individuals with\nASD. This result is consistent with recent neuroscience studies on emotion\nrecognition, which found an association between these band suppressions and the\nbehavioral deficits observed in individuals with ASD. The improved\ninterpretability of SincNet is achieved without sacrificing performance in\nemotion recognition.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 14:44:53 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Mayor-Torres", "Juan Manuel", ""], ["Ravanelli", "Mirco", ""], ["Medina-DeVilliers", "Sara E.", ""], ["Lerner", "Matthew D.", ""], ["Riccardi", "Giuseppe", ""]]}, {"id": "2107.10832", "submitter": "Joseph Singleton", "authors": "Joseph Singleton", "title": "A Logic of Expertise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we introduce a simple modal logic framework to reason about the\nexpertise of an information source. In the framework, a source is an expert on\na proposition $p$ if they are able to correctly determine the truth value of\n$p$ in any possible world. We also consider how information may be false, but\ntrue after accounting for the lack of expertise of the source. This is relevant\nfor modelling situations in which information sources make claims beyond their\ndomain of expertise. We use non-standard semantics for the language based on an\nexpertise set with certain closure properties. It turns out there is a close\nconnection between our semantics and S5 epistemic logic, so that expertise can\nbe expressed in terms of knowledge at all possible states. We use this\nconnection to obtain a sound and complete axiomatisation.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 17:42:38 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Singleton", "Joseph", ""]]}, {"id": "2107.10843", "submitter": "Darius Petermann", "authors": "Darius Petermann, Seungkwon Beack, Minje Kim", "title": "HARP-Net: Hyper-Autoencoded Reconstruction Propagation for Scalable\n  Neural Audio Coding", "comments": "Accepted to the IEEE Workshop on Applications of Signal Processing to\n  Audio and Acoustics (WASPAA) 2021, Mohonk Mountain House, New Paltz, NY", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An autoencoder-based codec employs quantization to turn its bottleneck layer\nactivation into bitstrings, a process that hinders information flow between the\nencoder and decoder parts. To circumvent this issue, we employ additional skip\nconnections between the corresponding pair of encoder-decoder layers. The\nassumption is that, in a mirrored autoencoder topology, a decoder layer\nreconstructs the intermediate feature representation of its corresponding\nencoder layer. Hence, any additional information directly propagated from the\ncorresponding encoder layer helps the reconstruction. We implement this kind of\nskip connections in the form of additional autoencoders, each of which is a\nsmall codec that compresses the massive data transfer between the paired\nencoder-decoder layers. We empirically verify that the proposed\nhyper-autoencoded architecture improves perceptual audio quality compared to an\nordinary autoencoder baseline.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 17:57:53 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 14:33:04 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Petermann", "Darius", ""], ["Beack", "Seungkwon", ""], ["Kim", "Minje", ""]]}, {"id": "2107.10873", "submitter": "Linyi Li", "authors": "Zhuolin Yang, Linyi Li, Xiaojun Xu, Bhavya Kailkhura, Tao Xie, Bo Li", "title": "On the Certified Robustness for Ensemble Models and Beyond", "comments": "57 pages, 11 pages for main text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent studies show that deep neural networks (DNN) are vulnerable to\nadversarial examples, which aim to mislead DNNs by adding perturbations with\nsmall magnitude. To defend against such attacks, both empirical and theoretical\ndefense approaches have been extensively studied for a single ML model. In this\nwork, we aim to analyze and provide the certified robustness for ensemble ML\nmodels, together with the sufficient and necessary conditions of robustness for\ndifferent ensemble protocols. Although ensemble models are shown more robust\nthan a single model empirically; surprisingly, we find that in terms of the\ncertified robustness the standard ensemble models only achieve marginal\nimprovement compared to a single model. Thus, to explore the conditions that\nguarantee to provide certifiably robust ensemble ML models, we first prove that\ndiversified gradient and large confidence margin are sufficient and necessary\nconditions for certifiably robust ensemble models under the model-smoothness\nassumption. We then provide the bounded model-smoothness analysis based on the\nproposed Ensemble-before-Smoothing strategy. We also prove that an ensemble\nmodel can always achieve higher certified robustness than a single base model\nunder mild conditions. Inspired by the theoretical findings, we propose the\nlightweight Diversity Regularized Training (DRT) to train certifiably robust\nensemble ML models. Extensive experiments show that our DRT enhanced ensembles\ncan consistently achieve higher certified robustness than existing single and\nensemble ML models, demonstrating the state-of-the-art certified L2-robustness\non MNIST, CIFAR-10, and ImageNet datasets.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 18:10:41 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Yang", "Zhuolin", ""], ["Li", "Linyi", ""], ["Xu", "Xiaojun", ""], ["Kailkhura", "Bhavya", ""], ["Xie", "Tao", ""], ["Li", "Bo", ""]]}, {"id": "2107.10901", "submitter": "Saba Moeinizade", "authors": "Saba Moeinizade, Guiping Hu, Lizhi Wang", "title": "A reinforcement learning approach to resource allocation in genomic\n  selection", "comments": "18 pages,5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.AI cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Genomic selection (GS) is a technique that plant breeders use to select\nindividuals to mate and produce new generations of species. Allocation of\nresources is a key factor in GS. At each selection cycle, breeders are facing\nthe choice of budget allocation to make crosses and produce the next generation\nof breeding parents. Inspired by recent advances in reinforcement learning for\nAI problems, we develop a reinforcement learning-based algorithm to\nautomatically learn to allocate limited resources across different generations\nof breeding. We mathematically formulate the problem in the framework of Markov\nDecision Process (MDP) by defining state and action spaces. To avoid the\nexplosion of the state space, an integer linear program is proposed that\nquantifies the trade-off between resources and time. Finally, we propose a\nvalue function approximation method to estimate the action-value function and\nthen develop a greedy policy improvement technique to find the optimal\nresources. We demonstrate the effectiveness of the proposed method in enhancing\ngenetic gain using a case study with realistic data.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 19:55:16 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Moeinizade", "Saba", ""], ["Hu", "Guiping", ""], ["Wang", "Lizhi", ""]]}, {"id": "2107.10931", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, Bo Hu, Linghao Jin, Xu Han, Fangxu Xing, Jinsong Ouyang,\n  Jun Lu, Georges EL Fakhri, Jonghye Woo", "title": "Domain Generalization under Conditional and Label Shifts via Variational\n  Bayesian Inference", "comments": "30th International Joint Conference on Artificial Intelligence\n  (IJCAI) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose a domain generalization (DG) approach to learn on\nseveral labeled source domains and transfer knowledge to a target domain that\nis inaccessible in training. Considering the inherent conditional and label\nshifts, we would expect the alignment of $p(x|y)$ and $p(y)$. However, the\nwidely used domain invariant feature learning (IFL) methods relies on aligning\nthe marginal concept shift w.r.t. $p(x)$, which rests on an unrealistic\nassumption that $p(y)$ is invariant across domains. We thereby propose a novel\nvariational Bayesian inference framework to enforce the conditional\ndistribution alignment w.r.t. $p(x|y)$ via the prior distribution matching in a\nlatent space, which also takes the marginal label shift w.r.t. $p(y)$ into\nconsideration with the posterior alignment. Extensive experiments on various\nbenchmarks demonstrate that our framework is robust to the label shift and the\ncross-domain accuracy is significantly improved, thereby achieving superior\nperformance over the conventional IFL counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 21:19:12 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Hu", "Bo", ""], ["Jin", "Linghao", ""], ["Han", "Xu", ""], ["Xing", "Fangxu", ""], ["Ouyang", "Jinsong", ""], ["Lu", "Jun", ""], ["Fakhri", "Georges EL", ""], ["Woo", "Jonghye", ""]]}, {"id": "2107.10969", "submitter": "David DeFazio", "authors": "David DeFazio and Shiqi Zhang", "title": "Learning Quadruped Locomotion Policies with Reward Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Legged robots have been shown to be effective in navigating unstructured\nenvironments. Although there has been much success in learning locomotion\npolicies for quadruped robots, there is little research on how to incorporate\nhuman knowledge to facilitate this learning process. In this paper, we\ndemonstrate that human knowledge in the form of LTL formulas can be applied to\nquadruped locomotion learning within a Reward Machine (RM) framework.\nExperimental results in simulation show that our RM-based approach enables\neasily defining diverse locomotion styles, and efficiently learning locomotion\npolicies of the defined styles.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 00:37:32 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["DeFazio", "David", ""], ["Zhang", "Shiqi", ""]]}, {"id": "2107.10997", "submitter": "Touqeer Ahmad", "authors": "Touqeer Ahmad, Ebrahim Emami, Martin \\v{C}ad\\'ik, George Bebis", "title": "Resource Efficient Mountainous Skyline Extraction using Shallow Learning", "comments": "Accepted at International Joint Conference on Neural Networks, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skyline plays a pivotal role in mountainous visual geo-localization and\nlocalization/navigation of planetary rovers/UAVs and virtual/augmented reality\napplications. We present a novel mountainous skyline detection approach where\nwe adapt a shallow learning approach to learn a set of filters to discriminate\nbetween edges belonging to sky-mountain boundary and others coming from\ndifferent regions. Unlike earlier approaches, which either rely on extraction\nof explicit feature descriptors and their classification, or fine-tuning\ngeneral scene parsing deep networks for sky segmentation, our approach learns\nlinear filters based on local structure analysis. At test time, for every\ncandidate edge pixel, a single filter is chosen from the set of learned filters\nbased on pixel's structure tensor, and then applied to the patch around it. We\nthen employ dynamic programming to solve the shortest path problem for the\nresultant multistage graph to get the sky-mountain boundary. The proposed\napproach is computationally faster than earlier methods while providing\ncomparable performance and is more suitable for resource constrained platforms\ne.g., mobile devices, planetary rovers and UAVs. We compare our proposed\napproach against earlier skyline detection methods using four different data\nsets. Our code is available at\n\\url{https://github.com/TouqeerAhmad/skyline_detection}.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 02:14:17 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Ahmad", "Touqeer", ""], ["Emami", "Ebrahim", ""], ["\u010cad\u00edk", "Martin", ""], ["Bebis", "George", ""]]}, {"id": "2107.10998", "submitter": "Dan Liu", "authors": "Dan Liu, Xi Chen, Jie Fu, Xue Liu", "title": "Pruning Ternary Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose pruning ternary quantization (PTQ), a simple, yet effective,\nsymmetric ternary quantization method. The method significantly compresses\nneural network weights to a sparse ternary of [-1,0,1] and thus reduces\ncomputational, storage, and memory footprints. We show that PTQ can convert\nregular weights to ternary orthonormal bases by simply using pruning and L2\nprojection. In addition, we introduce a refined straight-through estimator to\nfinalize and stabilize the quantized weights. Our method can provide at most\n46x compression ratio on the ResNet-18 structure, with an acceptable accuracy\nof 65.36%, outperforming leading methods. Furthermore, PTQ can compress a\nResNet-18 model from 46 MB to 955KB (~48x) and a ResNet-50 model from 99 MB to\n3.3MB (~30x), while the top-1 accuracy on ImageNet drops slightly from 69.7% to\n65.3% and from 76.15% to 74.47%, respectively. Our method unifies pruning and\nquantization and thus provides a range of size-accuracy trade-off.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 02:18:00 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Liu", "Dan", ""], ["Chen", "Xi", ""], ["Fu", "Jie", ""], ["Liu", "Xue", ""]]}, {"id": "2107.11019", "submitter": "Danial Yazdani", "authors": "Mohammad Nabi Omidvar, Danial Yazdani, Juergen Branke, Xiaodong Li,\n  Shengxiang Yang, Xin Yao", "title": "Generating Large-scale Dynamic Optimization Problem Instances Using the\n  Generalized Moving Peaks Benchmark", "comments": "arXiv admin note: text overlap with arXiv:2106.06174", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This document describes the generalized moving peaks benchmark (GMPB) and how\nit can be used to generate problem instances for continuous large-scale dynamic\noptimization problems. It presents a set of 15 benchmark problems, the relevant\nsource code, and a performance indicator, designed for comparative studies and\ncompetitions in large-scale dynamic optimization. Although its primary purpose\nis to provide a coherent basis for running competitions, its generality allows\nthe interested reader to use this document as a guide to design customized\nproblem instances to investigate issues beyond the scope of the presented\nbenchmark suite. To this end, we explain the modular structure of the GMPB and\nhow its constituents can be assembled to form problem instances with a variety\nof controllable characteristics ranging from unimodal to highly multimodal,\nsymmetric to highly asymmetric, smooth to highly irregular, and various degrees\nof variable interaction and ill-conditioning.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 03:57:50 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Omidvar", "Mohammad Nabi", ""], ["Yazdani", "Danial", ""], ["Branke", "Juergen", ""], ["Li", "Xiaodong", ""], ["Yang", "Shengxiang", ""], ["Yao", "Xin", ""]]}, {"id": "2107.11049", "submitter": "Jae Won Cho", "authors": "Jae Won Cho, Dong-Jin Kim, Yunjae Jung, In So Kweon", "title": "MCDAL: Maximum Classifier Discrepancy for Active Learning", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent state-of-the-art active learning methods have mostly leveraged\nGenerative Adversarial Networks (GAN) for sample acquisition; however, GAN is\nusually known to suffer from instability and sensitivity to hyper-parameters.\nIn contrast to these methods, we propose in this paper a novel active learning\nframework that we call Maximum Classifier Discrepancy for Active Learning\n(MCDAL) which takes the prediction discrepancies between multiple classifiers.\nIn particular, we utilize two auxiliary classification layers that learn\ntighter decision boundaries by maximizing the discrepancies among them.\nIntuitively, the discrepancies in the auxiliary classification layers'\npredictions indicate the uncertainty in the prediction. In this regard, we\npropose a novel method to leverage the classifier discrepancies for the\nacquisition function for active learning. We also provide an interpretation of\nour idea in relation to existing GAN based active learning methods and domain\nadaptation frameworks. Moreover, we empirically demonstrate the utility of our\napproach where the performance of our approach exceeds the state-of-the-art\nmethods on several image classification and semantic segmentation datasets in\nactive learning setups.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 06:57:08 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Cho", "Jae Won", ""], ["Kim", "Dong-Jin", ""], ["Jung", "Yunjae", ""], ["Kweon", "In So", ""]]}, {"id": "2107.11059", "submitter": "Mario W\\\"uthrich V.", "authors": "Ronald Richman and Mario V. W\\\"uthrich", "title": "LocalGLMnet: interpretable deep learning for tabular data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-fin.ST stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep learning models have gained great popularity in statistical modeling\nbecause they lead to very competitive regression models, often outperforming\nclassical statistical models such as generalized linear models. The\ndisadvantage of deep learning models is that their solutions are difficult to\ninterpret and explain, and variable selection is not easily possible because\ndeep learning models solve feature engineering and variable selection\ninternally in a nontransparent way. Inspired by the appealing structure of\ngeneralized linear models, we propose a new network architecture that shares\nsimilar features as generalized linear models, but provides superior predictive\npower benefiting from the art of representation learning. This new architecture\nallows for variable selection of tabular data and for interpretation of the\ncalibrated deep learning model, in fact, our approach provides an additive\ndecomposition in the spirit of Shapley values and integrated gradients.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 07:38:33 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Richman", "Ronald", ""], ["W\u00fcthrich", "Mario V.", ""]]}, {"id": "2107.11078", "submitter": "Jose Manuel Navarro", "authors": "Jose M. Navarro, Dario Rossi", "title": "HURRA! Human readable router anomaly detection", "comments": null, "journal-ref": "2020 32nd International Teletraffic Congress (ITC 32), Electronic\n  ISBN:978-3-948377-02-1, Print on Demand(PoD) ISBN:978-1-7281-9073-0", "doi": "10.1109/ITC3249928.2020.00011", "report-no": null, "categories": "cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents HURRA, a system that aims to reduce the time spent by\nhuman operators in the process of network troubleshooting. To do so, it\ncomprises two modules that are plugged after any anomaly detection algorithm:\n(i) a first attention mechanism, that ranks the present features in terms of\ntheir relation with the anomaly and (ii) a second module able to incorporates\nprevious expert knowledge seamlessly, without any need of human interaction nor\ndecisions. We show the efficacy of these simple processes on a collection of\nreal router datasets obtained from tens of ISPs which exhibit a rich variety of\nanomalies and very heterogeneous set of KPIs, on which we gather manually\nannotated ground truth by the operator solving the troubleshooting ticket. Our\nexperimental evaluation shows that (i) the proposed system is effective in\nachieving high levels of agreement with the expert, that (ii) even a simple\nstatistical approach is able to extracting useful information from expert\nknowledge gained in past cases to further improve performance and finally that\n(iii) the main difficulty in live deployment concerns the automated selection\nof the anomaly detection algorithm and the tuning of its hyper-parameters.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 08:38:29 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Navarro", "Jose M.", ""], ["Rossi", "Dario", ""]]}, {"id": "2107.11098", "submitter": "Eoin Brophy", "authors": "Eoin Brophy, Zhengwei Wang, Qi She, Tomas Ward", "title": "Generative adversarial networks in time series: A survey and taxonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative adversarial networks (GANs) studies have grown exponentially in\nthe past few years. Their impact has been seen mainly in the computer vision\nfield with realistic image and video manipulation, especially generation,\nmaking significant advancements. While these computer vision advances have\ngarnered much attention, GAN applications have diversified across disciplines\nsuch as time series and sequence generation. As a relatively new niche for\nGANs, fieldwork is ongoing to develop high quality, diverse and private time\nseries data. In this paper, we review GAN variants designed for time series\nrelated applications. We propose a taxonomy of discrete-variant GANs and\ncontinuous-variant GANs, in which GANs deal with discrete time series and\ncontinuous time series data. Here we showcase the latest and most popular\nliterature in this field; their architectures, results, and applications. We\nalso provide a list of the most popular evaluation metrics and their\nsuitability across applications. Also presented is a discussion of privacy\nmeasures for these GANs and further protections and directions for dealing with\nsensitive data. We aim to frame clearly and concisely the latest and\nstate-of-the-art research in this area and their applications to real-world\ntechnologies.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 09:38:51 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Brophy", "Eoin", ""], ["Wang", "Zhengwei", ""], ["She", "Qi", ""], ["Ward", "Tomas", ""]]}, {"id": "2107.11100", "submitter": "Benjamin Marais", "authors": "Benjamin Marais, Tony Quertier, Christophe Chesneau", "title": "Malware Analysis with Artificial Intelligence and a Particular Attention\n  on Results Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Malware detection and analysis are active research subjects in cybersecurity\nover the last years. Indeed, the development of obfuscation techniques, as\npacking, for example, requires special attention to detect recent variants of\nmalware. The usual detection methods do not necessarily provide tools to\ninterpret the results. Therefore, we propose a model based on the\ntransformation of binary files into grayscale image, which achieves an accuracy\nrate of 88%. Furthermore, the proposed model can determine if a sample is\npacked or encrypted with a precision of 85%. It allows us to analyze results\nand act appropriately. Also, by applying attention mechanisms on detection\nmodels, we have the possibility to identify which part of the files looks\nsuspicious. This kind of tool should be very useful for data analysts, it\ncompensates for the lack of interpretability of the common detection models,\nand it can help to understand why some malicious files are undetected.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 09:40:05 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Marais", "Benjamin", ""], ["Quertier", "Tony", ""], ["Chesneau", "Christophe", ""]]}, {"id": "2107.11150", "submitter": "Bernd Ludwig", "authors": "Isabella Kreller and Bernd Ludwig", "title": "User Preferences and the Shortest Path", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Indoor navigation systems leverage shortest path algorithms to calculate\nroutes. In order to define the \"shortest path\", a cost function has to be\nspecified based on theories and heuristics in the application domain. For the\ndomain of indoor routing, we survey theories and criteria identified in the\nliterature as essential for human path planning. We drive quantitative\ndefinitions and integrate them into a cost function that weights each of the\ncriteria separately. We then apply an exhaustive grid search to find weights\nthat lead to an ideal cost function. \"Ideal\" here is defined as guiding the\nalgorithm to plan routes that are most similar to those chosen by humans. To\nexplore which criteria should be taken into account in an improved pathfinding\nalgorithm, eleven different factors whose favorable impact on route selection\nhas been established in past research were considered. Each factor was included\nseparately in the Dijkstra algorithm and the similarity of thus calculated\nroutes to the actual routes chosen by students at the University of Regensburg\nwas determined. This allows for a quantitative assessment of the factors'\nimpact and further constitutes a way to directly compare them. A reduction of\nthe number of turns, streets, revolving doors, entryways, elevators as well as\nthe combination of the aforementioned factors was found to have a positive\neffect and generate paths that were favored over the shortest path. Turns and\nthe combination of criteria turned out to be most impactful.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 11:54:15 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Kreller", "Isabella", ""], ["Ludwig", "Bernd", ""]]}, {"id": "2107.11153", "submitter": "James Whittington", "authors": "James C.R. Whittington, Rishabh Kabra, Loic Matthey, Christopher P.\n  Burgess, Alexander Lerchner", "title": "Constellation: Learning relational abstractions over objects for\n  compositional imagination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning structured representations of visual scenes is currently a major\nbottleneck to bridging perception with reasoning. While there has been exciting\nprogress with slot-based models, which learn to segment scenes into sets of\nobjects, learning configurational properties of entire groups of objects is\nstill under-explored. To address this problem, we introduce Constellation, a\nnetwork that learns relational abstractions of static visual scenes, and\ngeneralises these abstractions over sensory particularities, thus offering a\npotential basis for abstract relational reasoning. We further show that this\nbasis, along with language association, provides a means to imagine sensory\ncontent in new ways. This work is a first step in the explicit representation\nof visual relationships and using them for complex cognitive procedures.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 11:59:40 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Whittington", "James C. R.", ""], ["Kabra", "Rishabh", ""], ["Matthey", "Loic", ""], ["Burgess", "Christopher P.", ""], ["Lerchner", "Alexander", ""]]}, {"id": "2107.11170", "submitter": "Lusine Abrahamyan", "authors": "Lusine Abrahamyan, Valentin Ziatchin, Yiming Chen and Nikos\n  Deligiannis", "title": "Bias Loss for Mobile Neural Networks", "comments": "Accepted at ICCV2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compact convolutional neural networks (CNNs) have witnessed exceptional\nimprovements in performance in recent years. However, they still fail to\nprovide the same predictive power as CNNs with a large number of parameters.\nThe diverse and even abundant features captured by the layers is an important\ncharacteristic of these successful CNNs. However, differences in this\ncharacteristic between large CNNs and their compact counterparts have rarely\nbeen investigated. In compact CNNs, due to the limited number of parameters,\nabundant features are unlikely to be obtained, and feature diversity becomes an\nessential characteristic. Diverse features present in the activation maps\nderived from a data point during model inference may indicate the presence of a\nset of unique descriptors necessary to distinguish between objects of different\nclasses. In contrast, data points with low feature diversity may not provide a\nsufficient amount of unique descriptors to make a valid prediction; we refer to\nthem as random predictions. Random predictions can negatively impact the\noptimization process and harm the final performance. This paper proposes\naddressing the problem raised by random predictions by reshaping the standard\ncross-entropy to make it biased toward data points with a limited number of\nunique descriptive features. Our novel Bias Loss focuses the training on a set\nof valuable data points and prevents the vast number of samples with poor\nlearning features from misleading the optimization process. Furthermore, to\nshow the importance of diversity, we present a family of SkipNet models whose\narchitectures are brought to boost the number of unique descriptors in the last\nlayers. Our Skipnet-M can achieve 1% higher classification accuracy than\nMobileNetV3 Large.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 12:37:56 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 14:41:21 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Abrahamyan", "Lusine", ""], ["Ziatchin", "Valentin", ""], ["Chen", "Yiming", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "2107.11201", "submitter": "Sebastien Verel", "authors": "Mathieu Muniglia, S\\'ebastien Verel (LISIC), Jean-Charles Le Pallec,\n  Jean-Michel Do", "title": "A Fitness Landscape View on the Tuning of an Asynchronous Master-Worker\n  EA for Nuclear Reactor Design", "comments": null, "journal-ref": "International Conference on Artificial Evolution (Evolution\n  Artificielle), Oct 2017, Paris, France. pp.30-46", "doi": "10.1007/978-3-319-78133-4_3", "report-no": null, "categories": "eess.SY cs.AI cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of the introduction of intermittent renewable energies, we\npropose to optimize the main variables of the control rods of a nuclear power\nplant to improve its capability to load-follow. The design problem is a\nblack-box combinatorial optimization problem with expensive evaluation based on\na multi-physics simulator. Therefore, we use a parallel asynchronous\nmaster-worker Evolutionary Algorithm scaling up to thousand computing units.\nOne main issue is the tuning of the algorithm parameters. A fitness landscape\nanalysis is conducted on this expensive real-world problem to show that it\nwould be possible to tune the mutation parameters according to the low-cost\nestimation of the fitness landscape features.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 14:35:25 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Muniglia", "Mathieu", "", "LISIC"], ["Verel", "S\u00e9bastien", "", "LISIC"], ["Pallec", "Jean-Charles Le", ""], ["Do", "Jean-Michel", ""]]}, {"id": "2107.11238", "submitter": "Th\\'eo Estienne", "authors": "Th\\'eo Estienne, Maria Vakalopoulou, Stergios Christodoulidis, Enzo\n  Battistella, Th\\'eophraste Henry, Marvin Lerousseau, Amaury Leroy, Guillaume\n  Chassagnon, Marie-Pierre Revel, Nikos Paragios and Eric Deutsch", "title": "Exploring Deep Registration Latent Spaces", "comments": "13 pages, 5 figures + 3 figures in supplementary materials Accepted\n  to DART 2021 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Explainability of deep neural networks is one of the most challenging and\ninteresting problems in the field. In this study, we investigate the topic\nfocusing on the interpretability of deep learning-based registration methods.\nIn particular, with the appropriate model architecture and using a simple\nlinear projection, we decompose the encoding space, generating a new basis, and\nwe empirically show that this basis captures various decomposed anatomically\naware geometrical transformations. We perform experiments using two different\ndatasets focusing on lungs and hippocampus MRI. We show that such an approach\ncan decompose the highly convoluted latent spaces of registration pipelines in\nan orthogonal space with several interesting properties. We hope that this work\ncould shed some light on a better understanding of deep learning-based\nregistration methods.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 13:54:21 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Estienne", "Th\u00e9o", ""], ["Vakalopoulou", "Maria", ""], ["Christodoulidis", "Stergios", ""], ["Battistella", "Enzo", ""], ["Henry", "Th\u00e9ophraste", ""], ["Lerousseau", "Marvin", ""], ["Leroy", "Amaury", ""], ["Chassagnon", "Guillaume", ""], ["Revel", "Marie-Pierre", ""], ["Paragios", "Nikos", ""], ["Deutsch", "Eric", ""]]}, {"id": "2107.11245", "submitter": "Fei Zhang", "authors": "Fei Zhang, Chaochen Gu, and Feng Yang", "title": "An Improved Algorithm of Robot Path Planning in Complex Environment\n  Based on Double DQN", "comments": "Accepted in International Conference on Guidance, Navigation and\n  Control,2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Q Network (DQN) has several limitations when applied in planning a path\nin environment with a number of dilemmas according to our experiment. The\nreward function may be hard to model, and successful experience transitions are\ndifficult to find in experience replay. In this context, this paper proposes an\nimproved Double DQN (DDQN) to solve the problem by reference to A* and\nRapidly-Exploring Random Tree (RRT). In order to achieve the rich experiments\nin experience replay, the initialization of robot in each training round is\nredefined based on RRT strategy. In addition, reward for the free positions is\nspecially designed to accelerate the learning process according to the\ndefinition of position cost in A*. The simulation experimental results validate\nthe efficiency of the improved DDQN, and robot could successfully learn the\nability of obstacle avoidance and optimal path planning in which DQN or DDQN\nhas no effect.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 14:03:04 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Zhang", "Fei", ""], ["Gu", "Chaochen", ""], ["Yang", "Feng", ""]]}, {"id": "2107.11252", "submitter": "Bingqian Lin", "authors": "Bingqian Lin, Yi Zhu, Yanxin Long, Xiaodan Liang, Qixiang Ye, Liang\n  Lin", "title": "Adversarial Reinforced Instruction Attacker for Robust Vision-Language\n  Navigation", "comments": "Accepted by TPAMI 2021", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2021", "doi": "10.1109/TPAMI.2021.3097435", "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language instruction plays an essential role in the natural language grounded\nnavigation tasks. However, navigators trained with limited human-annotated\ninstructions may have difficulties in accurately capturing key information from\nthe complicated instruction at different timesteps, leading to poor navigation\nperformance. In this paper, we exploit to train a more robust navigator which\nis capable of dynamically extracting crucial factors from the long instruction,\nby using an adversarial attacking paradigm. Specifically, we propose a Dynamic\nReinforced Instruction Attacker (DR-Attacker), which learns to mislead the\nnavigator to move to the wrong target by destroying the most instructive\ninformation in instructions at different timesteps. By formulating the\nperturbation generation as a Markov Decision Process, DR-Attacker is optimized\nby the reinforcement learning algorithm to generate perturbed instructions\nsequentially during the navigation, according to a learnable attack score.\nThen, the perturbed instructions, which serve as hard samples, are used for\nimproving the robustness of the navigator with an effective adversarial\ntraining strategy and an auxiliary self-supervised reasoning task. Experimental\nresults on both Vision-and-Language Navigation (VLN) and Navigation from Dialog\nHistory (NDH) tasks show the superiority of our proposed method over\nstate-of-the-art methods. Moreover, the visualization analysis shows the\neffectiveness of the proposed DR-Attacker, which can successfully attack\ncrucial information in the instructions at different timesteps. Code is\navailable at https://github.com/expectorlin/DR-Attacker.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 14:11:31 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Lin", "Bingqian", ""], ["Zhu", "Yi", ""], ["Long", "Yanxin", ""], ["Liang", "Xiaodan", ""], ["Ye", "Qixiang", ""], ["Lin", "Liang", ""]]}, {"id": "2107.11277", "submitter": "Kilian Hendrickx", "authors": "Kilian Hendrickx, Lorenzo Perini, Dries Van der Plas, Wannes Meert,\n  Jesse Davis", "title": "Machine Learning with a Reject Option: A survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning models always make a prediction, even when it is likely to\nbe inaccurate. This behavior should be avoided in many decision support\napplications, where mistakes can have severe consequences. Albeit already\nstudied in 1970, machine learning with a reject option recently gained\ninterest. This machine learning subfield enables machine learning models to\nabstain from making a prediction when likely to make a mistake.\n  This survey aims to provide an overview on machine learning with a reject\noption. We introduce the conditions leading to two types of rejection,\nambiguity and novelty rejection. Moreover, we define the existing architectures\nfor models with a reject option, describe the standard learning strategies to\ntrain such models and relate traditional machine learning techniques to\nrejection. Additionally, we review strategies to evaluate a model's predictive\nand rejective quality. Finally, we provide examples of relevant application\ndomains and show how machine learning with rejection relates to other machine\nlearning research areas.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 14:43:56 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Hendrickx", "Kilian", ""], ["Perini", "Lorenzo", ""], ["Van der Plas", "Dries", ""], ["Meert", "Wannes", ""], ["Davis", "Jesse", ""]]}, {"id": "2107.11350", "submitter": "Satya Narayan Shukla", "authors": "Satya Narayan Shukla, Benjamin M. Marlin", "title": "Heteroscedastic Temporal Variational Autoencoder For Irregularly Sampled\n  Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Irregularly sampled time series commonly occur in several domains where they\npresent a significant challenge to standard deep learning models. In this\npaper, we propose a new deep learning framework for probabilistic interpolation\nof irregularly sampled time series that we call the Heteroscedastic Temporal\nVariational Autoencoder (HeTVAE). HeTVAE includes a novel input layer to encode\ninformation about input observation sparsity, a temporal VAE architecture to\npropagate uncertainty due to input sparsity, and a heteroscedastic output layer\nto enable variable uncertainty in output interpolations. Our results show that\nthe proposed architecture is better able to reflect variable uncertainty\nthrough time due to sparse and irregular sampling than a range of baseline and\ntraditional models, as well as recently proposed deep latent variable models\nthat use homoscedastic output layers.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 16:59:21 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Shukla", "Satya Narayan", ""], ["Marlin", "Benjamin M.", ""]]}, {"id": "2107.11357", "submitter": "Richard Pymar", "authors": "Chris Harris, Richard Pymar, Colin Rowat", "title": "Joint Shapley values: a measure of joint feature importance", "comments": "Source code available at\n  https://github.com/harris-chris/joint-shapley-values", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Shapley value is one of the most widely used model-agnostic measures of\nfeature importance in explainable AI: it has clear axiomatic foundations, is\nguaranteed to uniquely exist, and has a clear interpretation as a feature's\naverage effect on a model's prediction. We introduce joint Shapley values,\nwhich directly extend the Shapley axioms. This preserves the classic Shapley\nvalue's intuitions: joint Shapley values measure a set of features' average\neffect on a model's prediction. We prove the uniqueness of joint Shapley\nvalues, for any order of explanation. Results for games show that joint Shapley\nvalues present different insights from existing interaction indices, which\nassess the effect of a feature within a set of features. Deriving joint Shapley\nvalues in ML attribution problems thus gives us the first measure of the joint\neffect of sets of features on model predictions. In a dataset with binary\nfeatures, we present a presence-adjusted method for calculating global values\nthat retains the efficiency property.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 17:22:37 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Harris", "Chris", ""], ["Pymar", "Richard", ""], ["Rowat", "Colin", ""]]}, {"id": "2107.11381", "submitter": "Seonwoo Min", "authors": "Seonwoo Min, Byunghan Lee, and Sungroh Yoon", "title": "TargetNet: Functional microRNA Target Prediction with Deep Neural\n  Networks", "comments": "7 pages, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  MicroRNAs (miRNAs) play pivotal roles in gene expression regulation by\nbinding to target sites of messenger RNAs (mRNAs). While identifying functional\ntargets of miRNAs is of utmost importance, their prediction remains a great\nchallenge. Previous computational algorithms have major limitations. They use\nconservative candidate target site (CTS) selection criteria mainly focusing on\ncanonical site types, rely on laborious and time-consuming manual feature\nextraction, and do not fully capitalize on the information underlying miRNA-CTS\ninteractions. In this paper, we introduce TargetNet, a novel deep\nlearning-based algorithm for functional miRNA target prediction. To address the\nlimitations of previous approaches, TargetNet has three key components: (1)\nrelaxed CTS selection criteria accommodating irregularities in the seed region,\n(2) a novel miRNA-CTS sequence encoding scheme incorporating extended seed\nregion alignments, and (3) a deep residual network-based prediction model. The\nproposed model was trained with miRNA-CTS pair datasets and evaluated with\nmiRNA-mRNA pair datasets. TargetNet advances the previous state-of-the-art\nalgorithms used in functional miRNA target classification. Furthermore, it\ndemonstrates great potential for distinguishing high-functional miRNA targets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 07:31:23 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Min", "Seonwoo", ""], ["Lee", "Byunghan", ""], ["Yoon", "Sungroh", ""]]}, {"id": "2107.11400", "submitter": "Ian Nielsen", "authors": "Ian E. Nielsen, Dimah Dera, Ghulam Rasool, Nidhal Bouaynaya, Ravi P.\n  Ramachandran", "title": "Robust Explainability: A Tutorial on Gradient-Based Attribution Methods\n  for Deep Neural Networks", "comments": "21 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of deep neural networks, the challenge of explaining the\npredictions of these networks has become increasingly recognized. While many\nmethods for explaining the decisions of deep neural networks exist, there is\ncurrently no consensus on how to evaluate them. On the other hand, robustness\nis a popular topic for deep learning research; however, it is hardly talked\nabout in explainability until very recently. In this tutorial paper, we start\nby presenting gradient-based interpretability methods. These techniques use\ngradient signals to assign the burden of the decision on the input features.\nLater, we discuss how gradient-based methods can be evaluated for their\nrobustness and the role that adversarial robustness plays in having meaningful\nexplanations. We also discuss the limitations of gradient-based methods.\nFinally, we present the best practices and attributes that should be examined\nbefore choosing an explainability method. We conclude with the future\ndirections for research in the area at the convergence of robustness and\nexplainability.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 18:06:29 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 17:18:31 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Nielsen", "Ian E.", ""], ["Dera", "Dimah", ""], ["Rasool", "Ghulam", ""], ["Bouaynaya", "Nidhal", ""], ["Ramachandran", "Ravi P.", ""]]}, {"id": "2107.11435", "submitter": "Jingxiao Liu", "authors": "Jingxiao Liu, Susu Xu, Mario Berg\\'es, Hae Young Noh", "title": "HierMUD: Hierarchical Multi-task Unsupervised Domain Adaptation between\n  Bridges for Drive-by Damage Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Monitoring bridge health using vibrations of drive-by vehicles has various\nbenefits, such as no need for directly installing and maintaining sensors on\nthe bridge. However, many of the existing drive-by monitoring approaches are\nbased on supervised learning models that require labeled data from every bridge\nof interest, which is expensive and time-consuming, if not impossible, to\nobtain. To this end, we introduce a new framework that transfers the model\nlearned from one bridge to diagnose damage in another bridge without any labels\nfrom the target bridge. Our framework trains a hierarchical neural network\nmodel in an adversarial way to extract task-shared and task-specific features\nthat are informative to multiple diagnostic tasks and invariant across multiple\nbridges. We evaluate our framework on experimental data collected from 2\nbridges and 3 vehicles. We achieve accuracies of 95% for damage detection, 93%\nfor localization, and up to 72% for quantification, which are ~2 times\nimprovements from baseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 19:39:32 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Liu", "Jingxiao", ""], ["Xu", "Susu", ""], ["Berg\u00e9s", "Mario", ""], ["Noh", "Hae Young", ""]]}, {"id": "2107.11442", "submitter": "Lucas Liebenwein", "authors": "Lucas Liebenwein, Alaa Maalouf, Oren Gal, Dan Feldman, Daniela Rus", "title": "Compressing Neural Networks: Towards Determining the Optimal Layer-wise\n  Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel global compression framework for deep neural networks that\nautomatically analyzes each layer to identify the optimal per-layer compression\nratio, while simultaneously achieving the desired overall compression. Our\nalgorithm hinges on the idea of compressing each convolutional (or\nfully-connected) layer by slicing its channels into multiple groups and\ndecomposing each group via low-rank decomposition. At the core of our algorithm\nis the derivation of layer-wise error bounds from the Eckart Young Mirsky\ntheorem. We then leverage these bounds to frame the compression problem as an\noptimization problem where we wish to minimize the maximum compression error\nacross layers and propose an efficient algorithm towards a solution. Our\nexperiments indicate that our method outperforms existing low-rank compression\napproaches across a wide range of networks and data sets. We believe that our\nresults open up new avenues for future research into the global\nperformance-size trade-offs of modern neural networks. Our code is available at\nhttps://github.com/lucaslie/torchprune.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 20:01:30 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Liebenwein", "Lucas", ""], ["Maalouf", "Alaa", ""], ["Gal", "Oren", ""], ["Feldman", "Dan", ""], ["Rus", "Daniela", ""]]}, {"id": "2107.11444", "submitter": "Iou-Jen Liu", "authors": "Iou-Jen Liu, Unnat Jain, Raymond A. Yeh, Alexander G. Schwing", "title": "Cooperative Exploration for Multi-Agent Deep Reinforcement Learning", "comments": "ICML 2021; Project Page: https://ioujenliu.github.io/CMAE/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is critical for good results in deep reinforcement learning and\nhas attracted much attention. However, existing multi-agent deep reinforcement\nlearning algorithms still use mostly noise-based techniques. Very recently,\nexploration methods that consider cooperation among multiple agents have been\ndeveloped. However, existing methods suffer from a common challenge: agents\nstruggle to identify states that are worth exploring, and hardly coordinate\nexploration efforts toward those states. To address this shortcoming, in this\npaper, we propose cooperative multi-agent exploration (CMAE): agents share a\ncommon goal while exploring. The goal is selected from multiple projected state\nspaces via a normalized entropy-based technique. Then, agents are trained to\nreach this goal in a coordinated manner. We demonstrate that CMAE consistently\noutperforms baselines on various tasks, including a sparse-reward version of\nthe multiple-particle environment (MPE) and the Starcraft multi-agent challenge\n(SMAC).\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 20:06:32 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Liu", "Iou-Jen", ""], ["Jain", "Unnat", ""], ["Yeh", "Raymond A.", ""], ["Schwing", "Alexander G.", ""]]}, {"id": "2107.11447", "submitter": "Youssef Skandarani", "authors": "Youssef Skandarani, Pierre-Marc Jodoin and Alain Lalande", "title": "Deep Learning Based Cardiac MRI Segmentation: Do We Need Experts?", "comments": null, "journal-ref": "Algorithms 2021, 14(7), 212", "doi": "10.3390/a14070212", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning methods are the de-facto solutions to a multitude of medical\nimage analysis tasks. Cardiac MRI segmentation is one such application which,\nlike many others, requires a large number of annotated data so a trained\nnetwork can generalize well. Unfortunately, the process of having a large\nnumber of manually curated images by medical experts is both slow and utterly\nexpensive. In this paper, we set out to explore whether expert knowledge is a\nstrict requirement for the creation of annotated datasets that machine learning\ncan successfully train on. To do so, we gauged the performance of three\nsegmentation models, namely U-Net, Attention U-Net, and ENet, trained with\ndifferent loss functions on expert and non-expert groundtruth for cardiac\ncine-MRI segmentation. Evaluation was done with classic segmentation metrics\n(Dice index and Hausdorff distance) as well as clinical measurements, such as\nthe ventricular ejection fractions and the myocardial mass. Results reveal that\ngeneralization performances of a segmentation neural network trained on\nnon-expert groundtruth data is, to all practical purposes, as good as on expert\ngroundtruth data, in particular when the non-expert gets a decent level of\ntraining, highlighting an opportunity for the efficient and cheap creation of\nannotations for cardiac datasets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 20:10:58 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Skandarani", "Youssef", ""], ["Jodoin", "Pierre-Marc", ""], ["Lalande", "Alain", ""]]}, {"id": "2107.11477", "submitter": "Peter A. V. DiBerardino", "authors": "Peter A. V. DiBerardino, Alexandre L. S. Filipowicz, James Danckert,\n  Britt Anderson", "title": "Plinko: A Theory-Free Behavioral Measure of Priors for Statistical\n  Learning and Mental Model Updating", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Probability distributions are central to Bayesian accounts of cognition, but\nbehavioral assessments do not directly measure them. Posterior distributions\nare typically computed from collections of individual participant actions, yet\nare used to draw conclusions about the internal structure of participant\nbeliefs. Also not explicitly measured are the prior distributions that\ndistinguish Bayesian models from others by representing initial states of\nbelief. Instead, priors are usually derived from experimenters' intuitions or\nmodel assumptions and applied equally to all participants. Here we present\nthree experiments using \"Plinko\", a behavioral task in which participants\nestimate distributions of ball drops over all available outcomes and where\ndistributions are explicitly measured before any observations. In Experiment 1,\nwe show that participant priors cluster around prototypical probability\ndistributions (Gaussian, bimodal, etc.), and that prior cluster membership may\nindicate learning ability. In Experiment 2, we highlight participants' ability\nto update to unannounced changes of presented distributions and how this\nability is affected by environmental manipulation. Finally, in Experiment 3, we\nverify that individual participant priors are reliable representations and that\nlearning is not impeded when faced with a physically implausible ball drop\ndistribution that is dynamically defined according to individual participant\ninput. This task will prove useful in more closely examining mechanisms of\nstatistical learning and mental model updating without requiring many of the\nassumptions made by more traditional computational modeling methodologies.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 22:27:30 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["DiBerardino", "Peter A. V.", ""], ["Filipowicz", "Alexandre L. S.", ""], ["Danckert", "James", ""], ["Anderson", "Britt", ""]]}, {"id": "2107.11481", "submitter": "Sougata Saha", "authors": "Sougata Saha, Souvik Das, Rohini Srihari", "title": "Similarity Based Label Smoothing For Dialogue Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative neural conversational systems are generally trained with the\nobjective of minimizing the entropy loss between the training \"hard\" targets\nand the predicted logits. Often, performance gains and improved generalization\ncan be achieved by using regularization techniques like label smoothing, which\nconverts the training \"hard\" targets to \"soft\" targets. However, label\nsmoothing enforces a data independent uniform distribution on the incorrect\ntraining targets, which leads to an incorrect assumption of equi-probable\nincorrect targets for each correct target. In this paper we propose and\nexperiment with incorporating data dependent word similarity based weighing\nmethods to transforms the uniform distribution of the incorrect target\nprobabilities in label smoothing, to a more natural distribution based on\nsemantics. We introduce hyperparameters to control the incorrect target\ndistribution, and report significant performance gains over networks trained\nusing standard label smoothing based loss, on two standard open domain dialogue\ncorpora.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 23:25:19 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Saha", "Sougata", ""], ["Das", "Souvik", ""], ["Srihari", "Rohini", ""]]}, {"id": "2107.11500", "submitter": "Biswadeep Chakraborty", "authors": "Biswadeep Chakraborty and Saibal Mukhopadhyay", "title": "$\\mu$DARTS: Model Uncertainty-Aware Differentiable Architecture Search", "comments": "10 pages, 7 Tables, 6 Figures, Submitted in TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a Model Uncertainty-aware Differentiable ARchiTecture Search\n($\\mu$DARTS) that optimizes neural networks to simultaneously achieve high\naccuracy and low uncertainty. We introduce concrete dropout within DARTS cells\nand include a Monte-Carlo regularizer within the training loss to optimize the\nconcrete dropout probabilities. A predictive variance term is introduced in the\nvalidation loss to enable searching for architecture with minimal model\nuncertainty. The experiments on CIFAR10, CIFAR100, SVHN, and ImageNet verify\nthe effectiveness of $\\mu$DARTS in improving accuracy and reducing uncertainty\ncompared to existing DARTS methods. Moreover, the final architecture obtained\nfrom $\\mu$DARTS shows higher robustness to noise at the input image and model\nparameters compared to the architecture obtained from existing DARTS methods.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 01:09:20 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Chakraborty", "Biswadeep", ""], ["Mukhopadhyay", "Saibal", ""]]}, {"id": "2107.11509", "submitter": "Youngjae Yu", "authors": "Jongseok Kim, Youngjae Yu, Seunghwan Lee, GunheeKim", "title": "Cycled Compositional Learning between Images and Text", "comments": "Fashion IQ 2020 challenge winner. Workshop tech report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an approach named the Cycled Composition Network that can measure\nthe semantic distance of the composition of image-text embedding. First, the\nComposition Network transit a reference image to target image in an embedding\nspace using relative caption. Second, the Correction Network calculates a\ndifference between reference and retrieved target images in the embedding space\nand match it with a relative caption. Our goal is to learn a Composition\nmapping with the Composition Network. Since this one-way mapping is highly\nunder-constrained, we couple it with an inverse relation learning with the\nCorrection Network and introduce a cycled relation for given Image We\nparticipate in Fashion IQ 2020 challenge and have won the first place with the\nensemble of our model.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 01:59:11 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Kim", "Jongseok", ""], ["Yu", "Youngjae", ""], ["Lee", "Seunghwan", ""], ["GunheeKim", "", ""]]}, {"id": "2107.11514", "submitter": "Li Yang", "authors": "Li Yang, Abdallah Moubayed, Abdallah Shami, Parisa Heidari, Amine\n  Boukhtouta, Adel Larabi, Richard Brunner, Stere Preda, Daniel Migault", "title": "Multi-Perspective Content Delivery Networks Security Framework Using\n  Optimized Unsupervised Anomaly Detection", "comments": "Accepted and to Appear in IEEE Transactions on Network and Service\n  Management", "journal-ref": null, "doi": "10.1109/TNSM.2021.3100308", "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content delivery networks (CDNs) provide efficient content distribution over\nthe Internet. CDNs improve the connectivity and efficiency of global\ncommunications, but their caching mechanisms may be breached by\ncyber-attackers. Among the security mechanisms, effective anomaly detection\nforms an important part of CDN security enhancement. In this work, we propose a\nmulti-perspective unsupervised learning framework for anomaly detection in\nCDNs. In the proposed framework, a multi-perspective feature engineering\napproach, an optimized unsupervised anomaly detection model that utilizes an\nisolation forest and a Gaussian mixture model, and a multi-perspective\nvalidation method, are developed to detect abnormal behaviors in CDNs mainly\nfrom the client Internet Protocol (IP) and node perspectives, therefore to\nidentify the denial of service (DoS) and cache pollution attack (CPA) patterns.\nExperimental results are presented based on the analytics of eight days of\nreal-world CDN log data provided by a major CDN operator. Through experiments,\nthe abnormal contents, compromised nodes, malicious IPs, as well as their\ncorresponding attack types, are identified effectively by the proposed\nframework and validated by multiple cybersecurity experts. This shows the\neffectiveness of the proposed method when applied to real-world CDN data.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 02:43:23 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Yang", "Li", ""], ["Moubayed", "Abdallah", ""], ["Shami", "Abdallah", ""], ["Heidari", "Parisa", ""], ["Boukhtouta", "Amine", ""], ["Larabi", "Adel", ""], ["Brunner", "Richard", ""], ["Preda", "Stere", ""], ["Migault", "Daniel", ""]]}, {"id": "2107.11517", "submitter": "Yinghuan Shi", "authors": "Qian Yu, Lei Qi, Luping Zhou, Lei Wang, Yilong Yin, Yinghuan Shi,\n  Wuzhang Wang, Yang Gao", "title": "Crosslink-Net: Double-branch Encoder Segmentation Network via Fusing\n  Vertical and Horizontal Convolutions", "comments": "13 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate image segmentation plays a crucial role in medical image analysis,\nyet it faces great challenges of various shapes, diverse sizes, and blurry\nboundaries. To address these difficulties, square kernel-based encoder-decoder\narchitecture has been proposed and widely used, but its performance remains\nstill unsatisfactory. To further cope with these challenges, we present a novel\ndouble-branch encoder architecture. Our architecture is inspired by two\nobservations: 1) Since the discrimination of features learned via square\nconvolutional kernels needs to be further improved, we propose to utilize\nnon-square vertical and horizontal convolutional kernels in the double-branch\nencoder, so features learned by the two branches can be expected to complement\neach other. 2) Considering that spatial attention can help models to better\nfocus on the target region in a large-sized image, we develop an attention loss\nto further emphasize the segmentation on small-sized targets. Together, the\nabove two schemes give rise to a novel double-branch encoder segmentation\nframework for medical image segmentation, namely Crosslink-Net. The experiments\nvalidate the effectiveness of our model on four datasets. The code is released\nat https://github.com/Qianyu1226/Crosslink-Net.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 02:58:32 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Yu", "Qian", ""], ["Qi", "Lei", ""], ["Zhou", "Luping", ""], ["Wang", "Lei", ""], ["Yin", "Yilong", ""], ["Shi", "Yinghuan", ""], ["Wang", "Wuzhang", ""], ["Gao", "Yang", ""]]}, {"id": "2107.11521", "submitter": "Weishu Liu", "authors": "Weishu Liu", "title": "Caveats for the use of Web of Science Core Collection in old literature\n  retrieval and historical bibliometric analysis", "comments": null, "journal-ref": "Technological Forecasting and Social Change(2021)", "doi": "10.1016/j.techfore.2021.121023", "report-no": null, "categories": "cs.DL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By using publications from Web of Science Core Collection (WoSCC), Fosso\nWamba and his colleagues published an interesting and comprehensive paper in\nTechnological Forecasting and Social Change to explore the structure and\ndynamics of artificial intelligence (AI) scholarship. Data demonstrated in\nFosso Wamba's study implied that the year 1991 seemed to be a \"watershed\" of AI\nresearch. This research note tried to uncover the 1991 phenomenon from the\nperspective of database limitation by probing the limitations of search in\nabstract/author keywords/keywords plus fields of WoSCC empirically. The low\navailability rates of abstract/author keywords/keywords plus information in\nWoSCC found in this study can explain the \"watershed\" phenomenon of AI\nscholarship in 1991 to a large extent. Some other caveats for the use of WoSCC\nin old literature retrieval and historical bibliometric analysis were also\nmentioned in the discussion section. This research note complements Fosso Wamba\nand his colleagues' study and also helps avoid improper interpretation in the\nuse of WoSCC in old literature retrieval and historical bibliometric analysis.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 03:39:19 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Liu", "Weishu", ""]]}, {"id": "2107.11522", "submitter": "Xiujun Shu", "authors": "Xiujun Shu, Ge Li, Xiao Wang, Weijian Ruan, Qi Tian", "title": "Semantic-guided Pixel Sampling for Cloth-Changing Person\n  Re-identification", "comments": "This paper has been published on IEEE Signal Processing Letters", "journal-ref": null, "doi": "10.1109/LSP.2021.3091924", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloth-changing person re-identification (re-ID) is a new rising research\ntopic that aims at retrieving pedestrians whose clothes are changed. This task\nis quite challenging and has not been fully studied to date. Current works\nmainly focus on body shape or contour sketch, but they are not robust enough\ndue to view and posture variations. The key to this task is to exploit\ncloth-irrelevant cues. This paper proposes a semantic-guided pixel sampling\napproach for the cloth-changing person re-ID task. We do not explicitly define\nwhich feature to extract but force the model to automatically learn\ncloth-irrelevant cues. Specifically, we first recognize the pedestrian's upper\nclothes and pants, then randomly change them by sampling pixels from other\npedestrians. The changed samples retain the identity labels but exchange the\npixels of clothes or pants among different pedestrians. Besides, we adopt a\nloss function to constrain the learned features to keep consistent before and\nafter changes. In this way, the model is forced to learn cues that are\nirrelevant to upper clothes and pants. We conduct extensive experiments on the\nlatest released PRCC dataset. Our method achieved 65.8% on Rank1 accuracy,\nwhich outperforms previous methods with a large margin. The code is available\nat https://github.com/shuxjweb/pixel_sampling.git.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 03:41:00 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Shu", "Xiujun", ""], ["Li", "Ge", ""], ["Wang", "Xiao", ""], ["Ruan", "Weijian", ""], ["Tian", "Qi", ""]]}, {"id": "2107.11572", "submitter": "Liang Ding", "authors": "Liang Ding, Di Wu, Dacheng Tao", "title": "The USYD-JD Speech Translation System for IWSLT 2021", "comments": "IWSLT 2021 winning system of the low-resource speech translation\n  track", "journal-ref": null, "doi": null, "report-no": "usyd-jd-01", "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper describes the University of Sydney& JD's joint submission of the\nIWSLT 2021 low resource speech translation task. We participated in the\nSwahili-English direction and got the best scareBLEU (25.3) score among all the\nparticipants. Our constrained system is based on a pipeline framework, i.e. ASR\nand NMT. We trained our models with the officially provided ASR and MT\ndatasets. The ASR system is based on the open-sourced tool Kaldi and this work\nmainly explores how to make the most of the NMT models. To reduce the\npunctuation errors generated by the ASR model, we employ our previous work\nSlotRefine to train a punctuation correction model. To achieve better\ntranslation performance, we explored the most recent effective strategies,\nincluding back translation, knowledge distillation, multi-feature reranking and\ntransductive finetuning. For model structure, we tried auto-regressive and\nnon-autoregressive models, respectively. In addition, we proposed two novel\npre-train approaches, i.e. \\textit{de-noising training} and\n\\textit{bidirectional training} to fully exploit the data. Extensive\nexperiments show that adding the above techniques consistently improves the\nBLEU scores, and the final submission system outperforms the baseline\n(Transformer ensemble model trained with the original parallel data) by\napproximately 10.8 BLEU score, achieving the SOTA performance.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 09:53:34 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Ding", "Liang", ""], ["Wu", "Di", ""], ["Tao", "Dacheng", ""]]}, {"id": "2107.11609", "submitter": "Umberto Michelucci", "authors": "Umberto Michelucci, Michela Sperti, Dario Piga, Francesca Venturini,\n  Marco A. Deriu", "title": "A Model-Agnostic Algorithm for Bayes Error Determination in Binary\n  Classification", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents the intrinsic limit determination algorithm (ILD\nAlgorithm), a novel technique to determine the best possible performance,\nmeasured in terms of the AUC (area under the ROC curve) and accuracy, that can\nbe obtained from a specific dataset in a binary classification problem with\ncategorical features {\\sl regardless} of the model used. This limit, namely the\nBayes error, is completely independent of any model used and describes an\nintrinsic property of the dataset. The ILD algorithm thus provides important\ninformation regarding the prediction limits of any binary classification\nalgorithm when applied to the considered dataset. In this paper the algorithm\nis described in detail, its entire mathematical framework is presented and the\npseudocode is given to facilitate its implementation. Finally, an example with\na real dataset is given.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 13:55:31 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Michelucci", "Umberto", ""], ["Sperti", "Michela", ""], ["Piga", "Dario", ""], ["Venturini", "Francesca", ""], ["Deriu", "Marco A.", ""]]}, {"id": "2107.11614", "submitter": "Luca Martino", "authors": "L. Martino, F. Llorente, E. Curbelo, J. Lopez-Santiago, J. Miguez", "title": "Automatic tempered posterior distributions for Bayesian inversion\n  problems", "comments": null, "journal-ref": "Mathematics. 2021; 9(7):784", "doi": "10.3390/math9070784", "report-no": null, "categories": "stat.CO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel adaptive importance sampling scheme for Bayesian inversion\nproblems where the inference of the variables of interest and the power of the\ndata noise is split. More specifically, we consider a Bayesian analysis for the\nvariables of interest (i.e., the parameters of the model to invert), whereas we\nemploy a maximum likelihood approach for the estimation of the noise power. The\nwhole technique is implemented by means of an iterative procedure, alternating\nsampling and optimization steps. Moreover, the noise power is also used as a\ntempered parameter for the posterior distribution of the the variables of\ninterest. Therefore, a sequence of tempered posterior densities is generated,\nwhere the tempered parameter is automatically selected according to the actual\nestimation of the noise power. A complete Bayesian study over the model\nparameters and the scale parameter can be also performed. Numerical experiments\nshow the benefits of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 14:06:00 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Martino", "L.", ""], ["Llorente", "F.", ""], ["Curbelo", "E.", ""], ["Lopez-Santiago", "J.", ""], ["Miguez", "J.", ""]]}, {"id": "2107.11621", "submitter": "Dun Zeng", "authors": "Dun Zeng, Siqi Liang, Xiangjing Hu, Zenglin Xu", "title": "FedLab: A Flexible Federated Learning Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning (FL) is a solution for privacy challenge, which allows\nmultiparty to train a shared model without violating privacy protection\nregulations. Many excellent works of FL have been proposed in recent years. To\nhelp researchers verify their ideas in FL, we designed and developed FedLab, a\nflexible and modular FL framework based on PyTorch. In this paper, we will\nintroduce architecture and features of FedLab. For current popular research\npoints: optimization and communication compression, FedLab provides functional\ninterfaces and a series of baseline implementation are available, making\nresearchers quickly implement ideas. In addition, FedLab is scale-able in both\nclient simulation and distributed communication.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 14:34:02 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zeng", "Dun", ""], ["Liang", "Siqi", ""], ["Hu", "Xiangjing", ""], ["Xu", "Zenglin", ""]]}, {"id": "2107.11635", "submitter": "Kien Do", "authors": "Kien Do, Truyen Tran, Svetha Venkatesh", "title": "Clustering by Maximizing Mutual Information Across Views", "comments": "Accepted at ICCV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel framework for image clustering that incorporates joint\nrepresentation learning and clustering. Our method consists of two heads that\nshare the same backbone network - a \"representation learning\" head and a\n\"clustering\" head. The \"representation learning\" head captures fine-grained\npatterns of objects at the instance level which serve as clues for the\n\"clustering\" head to extract coarse-grain information that separates objects\ninto clusters. The whole model is trained in an end-to-end manner by minimizing\nthe weighted sum of two sample-oriented contrastive losses applied to the\noutputs of the two heads. To ensure that the contrastive loss corresponding to\nthe \"clustering\" head is optimal, we introduce a novel critic function called\n\"log-of-dot-product\". Extensive experimental results demonstrate that our\nmethod significantly outperforms state-of-the-art single-stage clustering\nmethods across a variety of image datasets, improving over the best baseline by\nabout 5-7% in accuracy on CIFAR10/20, STL10, and ImageNet-Dogs. Further, the\n\"two-stage\" variant of our method also achieves better results than baselines\non three challenging ImageNet subsets.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 15:36:49 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Do", "Kien", ""], ["Tran", "Truyen", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2107.11652", "submitter": "Vladimir Araujo", "authors": "Vladimir Araujo, Andr\\'es Carvallo, Carlos Aspillaga, Camilo Thorne,\n  Denis Parra", "title": "Stress Test Evaluation of Biomedical Word Embeddings", "comments": "Accepted paper BioNLP2021", "journal-ref": null, "doi": "10.18653/v1/2021.bionlp-1.13", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of pretrained word embeddings has motivated their use in the\nbiomedical domain, with contextualized embeddings yielding remarkable results\nin several biomedical NLP tasks. However, there is a lack of research on\nquantifying their behavior under severe \"stress\" scenarios. In this work, we\nsystematically evaluate three language models with adversarial examples --\nautomatically constructed tests that allow us to examine how robust the models\nare. We propose two types of stress scenarios focused on the biomedical named\nentity recognition (NER) task, one inspired by spelling errors and another\nbased on the use of synonyms for medical terms. Our experiments with three\nbenchmarks show that the performance of the original models decreases\nconsiderably, in addition to revealing their weaknesses and strengths. Finally,\nwe show that adversarial training causes the models to improve their robustness\nand even to exceed the original performance in some cases.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 16:45:03 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Araujo", "Vladimir", ""], ["Carvallo", "Andr\u00e9s", ""], ["Aspillaga", "Carlos", ""], ["Thorne", "Camilo", ""], ["Parra", "Denis", ""]]}, {"id": "2107.11666", "submitter": "Piotr Koniusz", "authors": "Hao Zhu, Piotr Koniusz", "title": "Graph Convolutional Network with Generalized Factorized Bilinear\n  Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Graph Convolutional Networks (GCNs) have demonstrated their power in\nvarious applications, the graph convolutional layers, as the most important\ncomponent of GCN, are still using linear transformations and a simple pooling\nstep. In this paper, we propose a novel generalization of Factorized Bilinear\n(FB) layer to model the feature interactions in GCNs. FB performs two\nmatrix-vector multiplications, that is, the weight matrix is multiplied with\nthe outer product of the vector of hidden features from both sides. However,\nthe FB layer suffers from the quadratic number of coefficients, overfitting and\nthe spurious correlations due to correlations between channels of hidden\nrepresentations that violate the i.i.d. assumption. Thus, we propose a compact\nFB layer by defining a family of summarizing operators applied over the\nquadratic term. We analyze proposed pooling operators and motivate their use.\nOur experimental results on multiple datasets demonstrate that the GFB-GCN is\ncompetitive with other methods for text classification.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 17:57:06 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zhu", "Hao", ""], ["Koniusz", "Piotr", ""]]}, {"id": "2107.11695", "submitter": "Amit Verma Dr.", "authors": "Amit Verma, Mark Lewis, Gary Kochenberger", "title": "Efficient QUBO transformation for Higher Degree Pseudo Boolean Functions", "comments": "Preprint submitted to Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quadratic Unconstrained Binary Optimization (QUBO) is recognized as a\nunifying framework for modeling a wide range of problems. Problems can be\nsolved with commercial solvers customized for solving QUBO and since QUBO have\ndegree two, it is useful to have a method for transforming higher degree\npseudo-Boolean problems to QUBO format. The standard transformation approach\nrequires additional auxiliary variables supported by penalty terms for each\nhigher degree term. This paper improves on the existing cubic-to-quadratic\ntransformation approach by minimizing the number of additional variables as\nwell as penalty coefficient. Extensive experimental testing on Max 3-SAT\nmodeled as QUBO shows a near 100% reduction in the subproblem size used for\nminimization of the number of auxiliary variables.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 22:13:42 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Verma", "Amit", ""], ["Lewis", "Mark", ""], ["Kochenberger", "Gary", ""]]}, {"id": "2107.11722", "submitter": "David D. Fan", "authors": "David D. Fan, Ali-akbar Agha-mohammadi, Evangelos A. Theodorou", "title": "Learning Risk-aware Costmaps for Traversability in Challenging\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges in autonomous robotic exploration and navigation\nin unknown and unstructured environments is determining where the robot can or\ncannot safely move. A significant source of difficulty in this determination\narises from stochasticity and uncertainty, coming from localization error,\nsensor sparsity and noise, difficult-to-model robot-ground interactions, and\ndisturbances to the motion of the vehicle. Classical approaches to this problem\nrely on geometric analysis of the surrounding terrain, which can be prone to\nmodeling errors and can be computationally expensive. Moreover, modeling the\ndistribution of uncertain traversability costs is a difficult task, compounded\nby the various error sources mentioned above. In this work, we take a\nprincipled learning approach to this problem. We introduce a neural network\narchitecture for robustly learning the distribution of traversability costs.\nBecause we are motivated by preserving the life of the robot, we tackle this\nlearning problem from the perspective of learning tail-risks, i.e. the\nConditional Value-at-Risk (CVaR). We show that this approach reliably learns\nthe expected tail risk given a desired probability risk threshold between 0 and\n1, producing a traversability costmap which is more robust to outliers, more\naccurately captures tail risks, and is more computationally efficient, when\ncompared against baselines. We validate our method on data collected a legged\nrobot navigating challenging, unstructured environments including an abandoned\nsubway, limestone caves, and lava tube caves.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 04:12:03 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Fan", "David D.", ""], ["Agha-mohammadi", "Ali-akbar", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "2107.11762", "submitter": "Haoyi Niu", "authors": "Haoyi Niu, Jianming Hu, Zheyu Cui and Yi Zhang", "title": "DR2L: Surfacing Corner Cases to Robustify Autonomous Driving via Domain\n  Randomization Reinforcement Learning", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to explore corner cases as efficiently and thoroughly as possible has\nlong been one of the top concerns in the context of deep reinforcement learning\n(DeepRL) autonomous driving. Training with simulated data is less costly and\ndangerous than utilizing real-world data, but the inconsistency of parameter\ndistribution and the incorrect system modeling in simulators always lead to an\ninevitable Sim2real gap, which probably accounts for the underperformance in\nnovel, anomalous and risky cases that simulators can hardly generate. Domain\nRandomization(DR) is a methodology that can bridge this gap with little or no\nreal-world data. Consequently, in this research, an adversarial model is put\nforward to robustify DeepRL-based autonomous vehicles trained in simulation to\ngradually surfacing harder events, so that the models could readily transfer to\nthe real world.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 09:15:46 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Niu", "Haoyi", ""], ["Hu", "Jianming", ""], ["Cui", "Zheyu", ""], ["Zhang", "Yi", ""]]}, {"id": "2107.11768", "submitter": "Linhao Zhang", "authors": "Linhao Zhang, Yu Shi, Linjun Shou, Ming Gong, Houfeng Wang, Michael\n  Zeng", "title": "A Joint and Domain-Adaptive Approach to Spoken Language Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spoken Language Understanding (SLU) is composed of two subtasks: intent\ndetection (ID) and slot filling (SF). There are two lines of research on SLU.\nOne jointly tackles these two subtasks to improve their prediction accuracy,\nand the other focuses on the domain-adaptation ability of one of the subtasks.\nIn this paper, we attempt to bridge these two lines of research and propose a\njoint and domain adaptive approach to SLU. We formulate SLU as a constrained\ngeneration task and utilize a dynamic vocabulary based on domain-specific\nontology. We conduct experiments on the ASMixed and MTOD datasets and achieve\ncompetitive performance with previous state-of-the-art joint models. Besides,\nresults show that our joint model can be effectively adapted to a new domain.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 09:38:42 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zhang", "Linhao", ""], ["Shi", "Yu", ""], ["Shou", "Linjun", ""], ["Gong", "Ming", ""], ["Wang", "Houfeng", ""], ["Zeng", "Michael", ""]]}, {"id": "2107.11778", "submitter": "Linhao Zhang", "authors": "Linhao Zhang, Houfeng Wang", "title": "Learn to Focus: Hierarchical Dynamic Copy Network for Dialogue State\n  Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, researchers have explored using the encoder-decoder framework to\ntackle dialogue state tracking (DST), which is a key component of task-oriented\ndialogue systems. However, they regard a multi-turn dialogue as a flat\nsequence, failing to focus on useful information when the sequence is long. In\nthis paper, we propose a Hierarchical Dynamic Copy Network (HDCN) to facilitate\nfocusing on the most informative turn, making it easier to extract slot values\nfrom the dialogue context. Based on the encoder-decoder framework, we adopt a\nhierarchical copy approach that calculates two levels of attention at the word-\nand turn-level, which are then renormalized to obtain the final copy\ndistribution. A focus loss term is employed to encourage the model to assign\nthe highest turn-level attention weight to the most informative turn.\nExperimental results show that our model achieves 46.76% joint accuracy on the\nMultiWOZ 2.1 dataset.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 10:43:28 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zhang", "Linhao", ""], ["Wang", "Houfeng", ""]]}, {"id": "2107.11785", "submitter": "Manuele Leonelli", "authors": "Manuele Leonelli, Ramsiya Ramanathan, Rachel L. Wilkerson", "title": "Sensitivity and robustness analysis in Bayesian networks with the\n  bnmonitor R package", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian networks are a class of models that are widely used for risk\nassessment of complex operational systems. There are now multiple approaches,\nas well as implemented software, that guide their construction via data\nlearning or expert elicitation. However, a constructed Bayesian network needs\nto be validated before it can be used for practical risk assessment. Here, we\nillustrate the usage of the bnmonitor R package: the first comprehensive\nsoftware for the validation of a Bayesian network. An applied data analysis\nusing bnmonitor is carried out over a medical dataset to illustrate the use of\nits wide array of functions.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 11:23:43 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Leonelli", "Manuele", ""], ["Ramanathan", "Ramsiya", ""], ["Wilkerson", "Rachel L.", ""]]}, {"id": "2107.11789", "submitter": "Wentao Zhang", "authors": "Wentao Zhang, Yuezihan Jiang, Yang Li, Zeang Sheng, Yu Shen, Xupeng\n  Miao, Liang Wang, Zhi Yang, Bin Cui", "title": "ROD: Reception-aware Online Distillation for Sparse Graphs", "comments": null, "journal-ref": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD-2021)", "doi": "10.1145/3447548.3467221", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have been widely used in many graph-based tasks\nsuch as node classification, link prediction, and node clustering. However,\nGNNs gain their performance benefits mainly from performing the feature\npropagation and smoothing across the edges of the graph, thus requiring\nsufficient connectivity and label information for effective propagation.\nUnfortunately, many real-world networks are sparse in terms of both edges and\nlabels, leading to sub-optimal performance of GNNs. Recent interest in this\nsparse problem has focused on the self-training approach, which expands\nsupervised signals with pseudo labels. Nevertheless, the self-training approach\ninherently cannot realize the full potential of refining the learning\nperformance on sparse graphs due to the unsatisfactory quality and quantity of\npseudo labels.\n  In this paper, we propose ROD, a novel reception-aware online knowledge\ndistillation approach for sparse graph learning. We design three supervision\nsignals for ROD: multi-scale reception-aware graph knowledge, task-based\nsupervision, and rich distilled knowledge, allowing online knowledge transfer\nin a peer-teaching manner. To extract knowledge concealed in the multi-scale\nreception fields, ROD explicitly requires individual student models to preserve\ndifferent levels of locality information. For a given task, each student would\npredict based on its reception-scale knowledge, while simultaneously a strong\nteacher is established on-the-fly by combining multi-scale knowledge. Our\napproach has been extensively evaluated on 9 datasets and a variety of\ngraph-based tasks, including node classification, link prediction, and node\nclustering. The result demonstrates that ROD achieves state-of-art performance\nand is more robust for the graph sparsity.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 11:55:47 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zhang", "Wentao", ""], ["Jiang", "Yuezihan", ""], ["Li", "Yang", ""], ["Sheng", "Zeang", ""], ["Shen", "Yu", ""], ["Miao", "Xupeng", ""], ["Wang", "Liang", ""], ["Yang", "Zhi", ""], ["Cui", "Bin", ""]]}, {"id": "2107.11795", "submitter": "Hrishikesh Viswanath", "authors": "P Preethi and Hrishikesh Viswanath", "title": "Character Spotting Using Machine Learning Techniques", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.24999.88485", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This work presents a comparison of machine learning algorithms that are\nimplemented to segment the characters of text presented as an image. The\nalgorithms are designed to work on degraded documents with text that is not\naligned in an organized fashion. The paper investigates the use of Support\nVector Machines, K-Nearest Neighbor algorithm and an Encoder Network to perform\nthe operation of character spotting. Character Spotting involves extracting\npotential characters from a stream of text by selecting regions bound by white\nspace.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 12:36:57 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 07:15:15 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Preethi", "P", ""], ["Viswanath", "Hrishikesh", ""]]}, {"id": "2107.11811", "submitter": "Ryoya Ogishima", "authors": "Ryoya Ogishima, Izumi Karino, Yasuo Kuniyoshi", "title": "Reinforced Imitation Learning by Free Energy Principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement Learning (RL) requires a large amount of exploration especially\nin sparse-reward settings. Imitation Learning (IL) can learn from expert\ndemonstrations without exploration, but it never exceeds the expert's\nperformance and is also vulnerable to distributional shift between\ndemonstration and execution. In this paper, we radically unify RL and IL based\non Free Energy Principle (FEP). FEP is a unified Bayesian theory of the brain\nthat explains perception, action and model learning by a common fundamental\nprinciple. We present a theoretical extension of FEP and derive an algorithm in\nwhich an agent learns the world model that internalizes expert demonstrations\nand at the same time uses the model to infer the current and future states and\nactions that maximize rewards. The algorithm thus reduces exploration costs by\npartially imitating experts as well as maximizing its return in a seamless way,\nresulting in a higher performance than the suboptimal expert. Our experimental\nresults show that this approach is promising in visual control tasks especially\nin sparse-reward environments.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 14:19:29 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Ogishima", "Ryoya", ""], ["Karino", "Izumi", ""], ["Kuniyoshi", "Yasuo", ""]]}, {"id": "2107.11817", "submitter": "Fuzhao Xue", "authors": "Fuzhao Xue, Ziji Shi, Futao Wei, Yuxuan Lou, Yong Liu, Yang You", "title": "Go Wider Instead of Deeper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transformer has recently achieved impressive results on various tasks. To\nfurther improve the effectiveness and efficiency of the transformer, there are\ntwo trains of thought among existing works: (1) going wider by scaling to more\ntrainable parameters; (2) going shallower by parameter sharing or model\ncompressing along with the depth. However, larger models usually do not scale\nwell when fewer tokens are available to train, and advanced parallelisms are\nrequired when the model is extremely large. Smaller models usually achieve\ninferior performance compared to the original transformer model due to the loss\nof representation power. In this paper, to achieve better performance with\nfewer trainable parameters, we propose a framework to deploy trainable\nparameters efficiently, by going wider instead of deeper. Specially, we scale\nalong model width by replacing feed-forward network (FFN) with\nmixture-of-experts (MoE). We then share the MoE layers across transformer\nblocks using individual layer normalization. Such deployment plays the role to\ntransform various semantic representations, which makes the model more\nparameter-efficient and effective. To evaluate our framework, we design WideNet\nand evaluate it on ImageNet-1K. Our best model outperforms Vision Transformer\n(ViT) by $1.46\\%$ with $0.72 \\times$ trainable parameters. Using $0.46 \\times$\nand $0.13 \\times$ parameters, our WideNet can still surpass ViT and ViT-MoE by\n$0.83\\%$ and $2.08\\%$, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 14:44:24 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 10:17:23 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Xue", "Fuzhao", ""], ["Shi", "Ziji", ""], ["Wei", "Futao", ""], ["Lou", "Yuxuan", ""], ["Liu", "Yong", ""], ["You", "Yang", ""]]}, {"id": "2107.11818", "submitter": "Thasin Abedin", "authors": "Thasin Abedin, Khondokar S. S. Prottoy, Ayana Moshruba and Safayat Bin\n  Hakim", "title": "Bangla sign language recognition using concatenated BdSL network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sign language is the only medium of communication for the hearing impaired\nand the deaf and dumb community. Communication with the general mass is thus\nalways a challenge for this minority group. Especially in Bangla sign language\n(BdSL), there are 38 alphabets with some having nearly identical symbols. As a\nresult, in BdSL recognition, the posture of hand is an important factor in\naddition to visual features extracted from traditional Convolutional Neural\nNetwork (CNN). In this paper, a novel architecture \"Concatenated BdSL Network\"\nis proposed which consists of a CNN based image network and a pose estimation\nnetwork. While the image network gets the visual features, the relative\npositions of hand keypoints are taken by the pose estimation network to obtain\nthe additional features to deal with the complexity of the BdSL symbols. A\nscore of 91.51% was achieved by this novel approach in test set and the\neffectiveness of the additional pose estimation network is suggested by the\nexperimental results.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 14:47:30 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Abedin", "Thasin", ""], ["Prottoy", "Khondokar S. S.", ""], ["Moshruba", "Ayana", ""], ["Hakim", "Safayat Bin", ""]]}, {"id": "2107.11820", "submitter": "Luca Martino", "authors": "D. Luengo, L. Martino, M. Bugallo, V. Elvira, S. S\u007f\\\"arkk\\\"a", "title": "A Survey of Monte Carlo Methods for Parameter Estimation", "comments": null, "journal-ref": "EURASIP Journal on Advances in Signal Processing, Volume 2020,\n  Article number: 25 (2020)", "doi": "10.1186/s13634-020-00675-6", "report-no": null, "categories": "stat.CO cs.AI cs.NA eess.SP math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical signal processing applications usually require the estimation of\nsome parameters of interest given a set of observed data. These estimates are\ntypically obtained either by solving a multi-variate optimization problem, as\nin the maximum likelihood (ML) or maximum a posteriori (MAP) estimators, or by\nperforming a multi-dimensional integration, as in the minimum mean squared\nerror (MMSE) estimators. Unfortunately, analytical expressions for these\nestimators cannot be found in most real-world applications, and the Monte Carlo\n(MC) methodology is one feasible approach. MC methods proceed by drawing random\nsamples, either from the desired distribution or from a simpler one, and using\nthem to compute consistent estimators. The most important families of MC\nalgorithms are Markov chain MC (MCMC) and importance sampling (IS). On the one\nhand, MCMC methods draw samples from a proposal density, building then an\nergodic Markov chain whose stationary distribution is the desired distribution\nby accepting or rejecting those candidate samples as the new state of the\nchain. On the other hand, IS techniques draw samples from a simple proposal\ndensity, and then assign them suitable weights that measure their quality in\nsome appropriate way. In this paper, we perform a thorough review of MC methods\nfor the estimation of static parameters in signal processing applications. A\nhistorical note on the development of MC schemes is also provided, followed by\nthe basic MC method and a brief description of the rejection sampling (RS)\nalgorithm, as well as three sections describing many of the most relevant MCMC\nand IS algorithms, and their combined use.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 14:57:58 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Luengo", "D.", ""], ["Martino", "L.", ""], ["Bugallo", "M.", ""], ["Elvira", "V.", ""], ["S\u007f\u00e4rkk\u00e4", "S.", ""]]}, {"id": "2107.11822", "submitter": "Jay Nandy", "authors": "Jay Nandy and Wynne Hsu and Mong Li Lee", "title": "Distributional Shifts in Automated Diabetic Retinopathy Screening", "comments": "Accepted at IEEE ICIP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning-based models are developed to automatically detect if a retina\nimage is `referable' in diabetic retinopathy (DR) screening. However, their\nclassification accuracy degrades as the input images distributionally shift\nfrom their training distribution. Further, even if the input is not a retina\nimage, a standard DR classifier produces a high confident prediction that the\nimage is `referable'. Our paper presents a Dirichlet Prior Network-based\nframework to address this issue. It utilizes an out-of-distribution (OOD)\ndetector model and a DR classification model to improve generalizability by\nidentifying OOD images. Experiments on real-world datasets indicate that the\nproposed framework can eliminate the unknown non-retina images and identify the\ndistributionally shifted retina images for human intervention.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 15:03:12 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Nandy", "Jay", ""], ["Hsu", "Wynne", ""], ["Lee", "Mong Li", ""]]}, {"id": "2107.11838", "submitter": "Ali Farjami", "authors": "Ali Farjami", "title": "New Algebraic Normative Theories for Ethical and Legal Reasoning in the\n  LogiKEy Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  To design and engineer ethical and legal reasoners and responsible systems,\nBenzm\\\"{u}ller, Parent and van der Torre introduce LogiKEy methodology based on\nthe semantical embedding of deontic logics into classic higher-order logic. In\nthis paper, we considerably extend the LogiKEy deontic logics and dataset using\nan algebraic approach. We develop theory of input/output operations for\nnormative reasoning on top of Boolean algebras.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 16:33:07 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Farjami", "Ali", ""]]}, {"id": "2107.11844", "submitter": "Jagdish Chand Bansal Ph.D.", "authors": "Susheel Kumar Joshi, Jagdish Chand Bansal", "title": "A binary variant of gravitational search algorithm and its application\n  to windfarm layout optimization problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the binary search space, GSA framework encounters the shortcomings of\nstagnation, diversity loss, premature convergence and high time complexity. To\naddress these issues, a novel binary variant of GSA called `A novel\nneighbourhood archives embedded gravitational constant in GSA for binary search\nspace (BNAGGSA)' is proposed in this paper. In BNAGGSA, the novel\nfitness-distance based social interaction strategy produces a self-adaptive\nstep size mechanism through which the agent moves towards the optimal direction\nwith the optimal step size, as per its current search requirement. The\nperformance of the proposed algorithm is compared with the two binary variants\nof GSA over 23 well-known benchmark test problems. The experimental results and\nstatistical analyses prove the supremacy of BNAGGSA over the compared\nalgorithms. Furthermore, to check the applicability of the proposed algorithm\nin solving real-world applications, a windfarm layout optimization problem is\nconsidered. Two case studies with two different wind data sets of two different\nwind sites is considered for experiments.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 16:56:19 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Joshi", "Susheel Kumar", ""], ["Bansal", "Jagdish Chand", ""]]}, {"id": "2107.11845", "submitter": "Debi Prasanna Mohanty Mr", "authors": "Anchal Pandey, Sukumar Moharana, Debi Prasanna Mohanty, Archit Panwar,\n  Dewang Agarwal, Siva Prasad Thota", "title": "On-Device Content Moderation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the advent of internet, not safe for work(NSFW) content moderation is a\nmajor problem today. Since,smartphones are now part of daily life of billions\nof people,it becomes even more important to have a solution which coulddetect\nand suggest user about potential NSFW content present ontheir phone. In this\npaper we present a novel on-device solutionfor detecting NSFW images. In\naddition to conventional porno-graphic content moderation, we have also\nincluded semi-nudecontent moderation as it is still NSFW in a large\ndemography.We have curated a dataset comprising of three major\ncategories,namely nude, semi-nude and safe images. We have created anensemble\nof object detector and classifier for filtering of nudeand semi-nude contents.\nThe solution provides unsafe body partannotations along with identification of\nsemi-nude images. Weextensively tested our proposed solution on several public\ndatasetand also on our custom dataset. The model achieves F1 scoreof 0.91 with\n95% precision and 88% recall on our customNSFW16k dataset and 0.92 MAP on NPDI\ndataset. Moreover itachieves average 0.002 false positive rate on a collection\nof safeimage open datasets.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 17:06:01 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Pandey", "Anchal", ""], ["Moharana", "Sukumar", ""], ["Mohanty", "Debi Prasanna", ""], ["Panwar", "Archit", ""], ["Agarwal", "Dewang", ""], ["Thota", "Siva Prasad", ""]]}, {"id": "2107.11879", "submitter": "Marco Valentino", "authors": "Marco Valentino, Mokanarangan Thayaparan, Deborah Ferreira, Andr\\'e\n  Freitas", "title": "Hybrid Autoregressive Solver for Scalable Abductive Natural Language\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regenerating natural language explanations for science questions is a\nchallenging task for evaluating complex multi-hop and abductive inference\ncapabilities. In this setting, Transformers trained on human-annotated\nexplanations achieve state-of-the-art performance when adopted as cross-encoder\narchitectures. However, while much attention has been devoted to the quality of\nthe constructed explanations, the problem of performing abductive inference at\nscale is still under-studied. As intrinsically not scalable, the cross-encoder\narchitectural paradigm is not suitable for efficient multi-hop inference on\nmassive facts banks. To maximise both accuracy and inference time, we propose a\nhybrid abductive solver that autoregressively combines a dense bi-encoder with\na sparse model of explanatory power, computed leveraging explicit patterns in\nthe explanations. Our experiments demonstrate that the proposed framework can\nachieve performance comparable with the state-of-the-art cross-encoder while\nbeing $\\approx 50$ times faster and scalable to corpora of millions of facts.\nMoreover, we study the impact of the hybridisation on semantic drift and\nscience question answering without additional training, showing that it boosts\nthe quality of the explanations and contributes to improved downstream\ninference performance.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 19:29:53 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Valentino", "Marco", ""], ["Thayaparan", "Mokanarangan", ""], ["Ferreira", "Deborah", ""], ["Freitas", "Andr\u00e9", ""]]}, {"id": "2107.11904", "submitter": "Bo-Hsiang (Andy) Tseng", "authors": "Bo-Hsiang Tseng, Yinpei Dai, Florian Kreyssig, Bill Byrne", "title": "Transferable Dialogue Systems and User Simulators", "comments": "Accepted by ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the difficulties in training dialogue systems is the lack of training\ndata. We explore the possibility of creating dialogue data through the\ninteraction between a dialogue system and a user simulator. Our goal is to\ndevelop a modelling framework that can incorporate new dialogue scenarios\nthrough self-play between the two agents. In this framework, we first pre-train\nthe two agents on a collection of source domain dialogues, which equips the\nagents to converse with each other via natural language. With further\nfine-tuning on a small amount of target domain data, the agents continue to\ninteract with the aim of improving their behaviors using reinforcement learning\nwith structured reward functions. In experiments on the MultiWOZ dataset, two\npractical transfer learning problems are investigated: 1) domain adaptation and\n2) single-to-multiple domain transfer. We demonstrate that the proposed\nframework is highly effective in bootstrapping the performance of the two\nagents in transfer learning. We also show that our method leads to improvements\nin dialogue system performance on complete datasets.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 22:59:09 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Tseng", "Bo-Hsiang", ""], ["Dai", "Yinpei", ""], ["Kreyssig", "Florian", ""], ["Byrne", "Bill", ""]]}, {"id": "2107.11913", "submitter": "Luis Lamb", "authors": "Pedro H.C. Avelar and Rafael B. Audibert and Anderson R. Tavares and\n  Lu\\'is C. Lamb", "title": "Measuring Ethics in AI with AI: A Methodology and Dataset Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently, the use of sound measures and metrics in Artificial Intelligence\nhas become the subject of interest of academia, government, and industry.\nEfforts towards measuring different phenomena have gained traction in the AI\ncommunity, as illustrated by the publication of several influential field\nreports and policy documents. These metrics are designed to help decision\ntakers to inform themselves about the fast-moving and impacting influences of\nkey advances in Artificial Intelligence in general and Machine Learning in\nparticular. In this paper we propose to use such newfound capabilities of AI\ntechnologies to augment our AI measuring capabilities. We do so by training a\nmodel to classify publications related to ethical issues and concerns. In our\nmethodology we use an expert, manually curated dataset as the training set and\nthen evaluate a large set of research papers. Finally, we highlight the\nimplications of AI metrics, in particular their contribution towards developing\ntrustful and fair AI-based tools and technologies. Keywords: AI Ethics; AI\nFairness; AI Measurement. Ethics in Computer Science.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 00:26:12 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Avelar", "Pedro H. C.", ""], ["Audibert", "Rafael B.", ""], ["Tavares", "Anderson R.", ""], ["Lamb", "Lu\u00eds C.", ""]]}, {"id": "2107.11927", "submitter": "Goran Radanovic", "authors": "Stelios Triantafyllou, Adish Singla, Goran Radanovic", "title": "On Blame Attribution for Accountable Multi-Agent Sequential Decision\n  Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blame attribution is one of the key aspects of accountable decision making,\nas it provides means to quantify the responsibility of an agent for a decision\nmaking outcome. In this paper, we study blame attribution in the context of\ncooperative multi-agent sequential decision making. As a particular setting of\ninterest, we focus on cooperative decision making formalized by Multi-Agent\nMarkov Decision Processes (MMDP), and we analyze different blame attribution\nmethods derived from or inspired by existing concepts in cooperative game\ntheory. We formalize desirable properties of blame attribution in the setting\nof interest, and we analyze the relationship between these properties and the\nstudied blame attribution methods. Interestingly, we show that some of the well\nknown blame attribution methods, such as Shapley value, are not\nperformance-incentivizing, while others, such as Banzhaf index, may over-blame\nagents. To mitigate these value misalignment and fairness issues, we introduce\na novel blame attribution method, unique in the set of properties it satisfies,\nwhich trade-offs explanatory power (by under-blaming agents) for the\naforementioned properties. We further show how to account for uncertainty about\nagents' decision making policies, and we experimentally: a) validate the\nqualitative properties of the studied blame attribution methods, and b) analyze\ntheir robustness to uncertainty.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 02:22:23 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Triantafyllou", "Stelios", ""], ["Singla", "Adish", ""], ["Radanovic", "Goran", ""]]}, {"id": "2107.11934", "submitter": "Lingwei Wei", "authors": "Lingwei Wei, Dou Hu, Wei Zhou, Zhaojuan Yue, Songlin Hu", "title": "Towards Propagation Uncertainty: Edge-enhanced Bayesian Graph\n  Convolutional Networks for Rumor Detection", "comments": "Accepted by ACL 2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting rumors on social media is a very critical task with significant\nimplications to the economy, public health, etc. Previous works generally\ncapture effective features from texts and the propagation structure. However,\nthe uncertainty caused by unreliable relations in the propagation structure is\ncommon and inevitable due to wily rumor producers and the limited collection of\nspread data. Most approaches neglect it and may seriously limit the learning of\nfeatures. Towards this issue, this paper makes the first attempt to explore\npropagation uncertainty for rumor detection. Specifically, we propose a novel\nEdge-enhanced Bayesian Graph Convolutional Network (EBGCN) to capture robust\nstructural features. The model adaptively rethinks the reliability of latent\nrelations by adopting a Bayesian approach. Besides, we design a new edge-wise\nconsistency training framework to optimize the model by enforcing consistency\non relations. Experiments on three public benchmark datasets demonstrate that\nthe proposed model achieves better performance than baseline methods on both\nrumor detection and early rumor detection tasks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 03:07:07 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Wei", "Lingwei", ""], ["Hu", "Dou", ""], ["Zhou", "Wei", ""], ["Yue", "Zhaojuan", ""], ["Hu", "Songlin", ""]]}, {"id": "2107.11965", "submitter": "Elif Surer", "authors": "Sinan Ariyurek, Elif Surer, Aysu Betin-Can", "title": "Playtesting: What is Beyond Personas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Playtesting is an essential step in the game design process. Game designers\nuse the feedback from playtests to refine their design. Game designers may\nemploy procedural personas to automate the playtesting process. In this paper,\nwe present two approaches to improve automated playtesting. First, we propose a\ngoal-based persona model, which we call developing persona -- developing\npersona proposes a dynamic persona model, whereas the current persona models\nare static. Game designers can use the developing persona to model the changes\nthat a player undergoes while playing a game. Additionally, a human playtester\nknows which paths she has tested before, and during the consequent tests, she\nmay test different paths. However, RL agents disregard the previously generated\ntrajectories. We propose a novel methodology that helps Reinforcement Learning\n(RL) agents to generate distinct trajectories than the previous trajectories.\nWe refer to this methodology as Alternative Path Finder (APF). We present a\ngeneric APF framework that can be applied to all RL agents. APF is trained with\nthe previous trajectories, and APF distinguishes the novel states from similar\nstates. We use the General Video Game Artificial Intelligence (GVG-AI) and\nVizDoom frameworks to test our proposed methodologies. We use Proximal Policy\nOptimization (PPO) RL agent during experiments. First, we show that the\nplaytest data generated by the developing persona cannot be generated using the\nprocedural personas. Second, we present the alternative paths found using APF.\nWe show that the APF penalizes the previous paths and rewards the distinct\npaths.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 05:23:45 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Ariyurek", "Sinan", ""], ["Surer", "Elif", ""], ["Betin-Can", "Aysu", ""]]}, {"id": "2107.11972", "submitter": "Liang Zeng", "authors": "Liang Zeng, Lei Wang, Hui Niu, Jian Li, Ruchen Zhang, Zhonghao Dai,\n  Dewei Zhu, Ling Wang", "title": "Trade When Opportunity Comes: Price Movement Forecasting via\n  Locality-Aware Attention and Adaptive Refined Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CE q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Price movement forecasting aims at predicting the future trends of financial\nassets based on the current market conditions and other relevant information.\nRecently, machine learning(ML) methods have become increasingly popular and\nachieved promising results for price movement forecasting in both academia and\nindustry. Most existing ML solutions formulate the forecasting problem as a\nclassification(to predict the direction) or a regression(to predict the return)\nproblem in the entire set of training data. However, due to the extremely low\nsignal-to-noise ratio and stochastic nature of financial data, good trading\nopportunities are extremely scarce. As a result, without careful selection of\npotentially profitable samples, such ML methods are prone to capture the\npatterns of noises instead of real signals. To address the above issues, we\npropose a novel framework-LARA(Locality-Aware Attention and Adaptive Refined\nLabeling), which contains the following three components: 1)Locality-aware\nattention automatically extracts the potentially profitable samples by\nattending to their label information in order to construct a more accurate\nclassifier on these selected samples. 2)Adaptive refined labeling further\niteratively refines the labels, alleviating the noise of samples. 3)Equipped\nwith metric learning techniques, Locality-aware attention enjoys task-specific\ndistance metrics and distributes attention on potentially profitable samples in\na more effective way. To validate our method, we conduct comprehensive\nexperiments on three real-world financial markets: ETFs, the China's A-share\nstock market, and the cryptocurrency market. LARA achieves superior performance\ncompared with the time-series analysis methods and a set of machine learning\nbased competitors on the Qlib platform. Extensive ablation studies and\nexperiments demonstrate that LARA indeed captures more reliable trading\nopportunities.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 05:52:42 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zeng", "Liang", ""], ["Wang", "Lei", ""], ["Niu", "Hui", ""], ["Li", "Jian", ""], ["Zhang", "Ruchen", ""], ["Dai", "Zhonghao", ""], ["Zhu", "Dewei", ""], ["Wang", "Ling", ""]]}, {"id": "2107.11986", "submitter": "Xian Zhao", "authors": "Xian Zhao, Jiaming Zhang, Zhiyu Lin and Jitao Sang", "title": "Benign Adversarial Attack: Tricking Algorithm for Goodness", "comments": "Preprint. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the successful application in many fields, machine learning\nalgorithms today suffer from notorious problems like vulnerability to\nadversarial examples. Beyond falling into the cat-and-mouse game between\nadversarial attack and defense, this paper provides alternative perspective to\nconsider adversarial example and explore whether we can exploit it in benign\napplications. We first propose a novel taxonomy of visual information along\ntask-relevance and semantic-orientation. The emergence of adversarial example\nis attributed to algorithm's utilization of task-relevant non-semantic\ninformation. While largely ignored in classical machine learning mechanisms,\ntask-relevant non-semantic information enjoys three interesting characteristics\nas (1) exclusive to algorithm, (2) reflecting common weakness, and (3)\nutilizable as features. Inspired by this, we present brave new idea called\nbenign adversarial attack to exploit adversarial examples for goodness in three\ndirections: (1) adversarial Turing test, (2) rejecting malicious algorithm, and\n(3) adversarial data augmentation. Each direction is positioned with motivation\nelaboration, justification analysis and prototype applications to showcase its\npotential.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 06:46:19 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zhao", "Xian", ""], ["Zhang", "Jiaming", ""], ["Lin", "Zhiyu", ""], ["Sang", "Jitao", ""]]}, {"id": "2107.12024", "submitter": "Zhang Junlin", "authors": "Qingyun She, Zhiqiang Wang, Junlin Zhang", "title": "Leaf-FM: A Learnable Feature Generation Factorization Machine for\n  Click-Through Rate Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Click-through rate (CTR) prediction plays important role in personalized\nadvertising and recommender systems. Though many models have been proposed such\nas FM, FFM and DeepFM in recent years, feature engineering is still a very\nimportant way to improve the model performance in many applications because\nusing raw features can rarely lead to optimal results. For example, the\ncontinuous features are usually transformed to the power forms by adding a new\nfeature to allow it to easily form non-linear functions of the feature.\nHowever, this kind of feature engineering heavily relies on peoples experience\nand it is both time consuming and labor consuming. On the other side, concise\nCTR model with both fast online serving speed and good model performance is\ncritical for many real life applications. In this paper, we propose LeafFM\nmodel based on FM to generate new features from the original feature embedding\nby learning the transformation functions automatically. We also design three\nconcrete Leaf-FM models according to the different strategies of combing the\noriginal and the generated features. Extensive experiments are conducted on\nthree real-world datasets and the results show Leaf-FM model outperforms\nstandard FMs by a large margin. Compared with FFMs, Leaf-FM can achieve\nsignificantly better performance with much less parameters. In Avazu and\nMalware dataset, add version Leaf-FM achieves comparable performance with some\ndeep learning based models such as DNN and AutoInt. As an improved FM model,\nLeaf-FM has the same computation complexity with FM in online serving phase and\nit means Leaf-FM is applicable in many industry applications because of its\nbetter performance and high computation efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 08:29:18 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["She", "Qingyun", ""], ["Wang", "Zhiqiang", ""], ["Zhang", "Junlin", ""]]}, {"id": "2107.12025", "submitter": "Zhang Junlin", "authors": "Zhiqiang Wang, Qingyun She, PengTao Zhang, Junlin Zhang", "title": "ContextNet: A Click-Through Rate Prediction Framework Using Contextual\n  information to Refine Feature Embedding", "comments": "arXiv admin note: text overlap with arXiv:2102.07619", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Click-through rate (CTR) estimation is a fundamental task in personalized\nadvertising and recommender systems and it's important for ranking models to\neffectively capture complex high-order features.Inspired by the success of ELMO\nand Bert in NLP field, which dynamically refine word embedding according to the\ncontext sentence information where the word appears, we think it's also\nimportant to dynamically refine each feature's embedding layer by layer\naccording to the context information contained in input instance in CTR\nestimation tasks. We can effectively capture the useful feature interactions\nfor each feature in this way. In this paper, We propose a novel CTR Framework\nnamed ContextNet that implicitly models high-order feature interactions by\ndynamically refining each feature's embedding according to the input context.\nSpecifically, ContextNet consists of two key components: contextual embedding\nmodule and ContextNet block. Contextual embedding module aggregates contextual\ninformation for each feature from input instance and ContextNet block maintains\neach feature's embedding layer by layer and dynamically refines its\nrepresentation by merging contextual high-order interaction information into\nfeature embedding. To make the framework specific, we also propose two\nmodels(ContextNet-PFFN and ContextNet-SFFN) under this framework by introducing\nlinear contextual embedding network and two non-linear mapping sub-network in\nContextNet block. We conduct extensive experiments on four real-world datasets\nand the experiment results demonstrate that our proposed ContextNet-PFFN and\nContextNet-SFFN model outperform state-of-the-art models such as DeepFM and\nxDeepFM significantly.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 08:29:40 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Wang", "Zhiqiang", ""], ["She", "Qingyun", ""], ["Zhang", "PengTao", ""], ["Zhang", "Junlin", ""]]}, {"id": "2107.12046", "submitter": "Guang Yang", "authors": "Xi Guan, Guang Yang, Jianming Ye, Weiji Yang, Xiaomei Xu, Weiwei\n  Jiang, Xiaobo Lai", "title": "3D AGSE-VNet: An Automatic Brain Tumor MRI Data Segmentation Framework", "comments": "34 pages, 12 figure, Accepted by BMC Medical Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Background: Glioma is the most common brain malignant tumor, with a high\nmorbidity rate and a mortality rate of more than three percent, which seriously\nendangers human health. The main method of acquiring brain tumors in the clinic\nis MRI. Segmentation of brain tumor regions from multi-modal MRI scan images is\nhelpful for treatment inspection, post-diagnosis monitoring, and effect\nevaluation of patients. However, the common operation in clinical brain tumor\nsegmentation is still manual segmentation, lead to its time-consuming and large\nperformance difference between different operators, a consistent and accurate\nautomatic segmentation method is urgently needed. Methods: To meet the above\nchallenges, we propose an automatic brain tumor MRI data segmentation framework\nwhich is called AGSE-VNet. In our study, the Squeeze and Excite (SE) module is\nadded to each encoder, the Attention Guide Filter (AG) module is added to each\ndecoder, using the channel relationship to automatically enhance the useful\ninformation in the channel to suppress the useless information, and use the\nattention mechanism to guide the edge information and remove the influence of\nirrelevant information such as noise. Results: We used the BraTS2020 challenge\nonline verification tool to evaluate our approach. The focus of verification is\nthat the Dice scores of the whole tumor (WT), tumor core (TC) and enhanced\ntumor (ET) are 0.68, 0.85 and 0.70, respectively. Conclusion: Although MRI\nimages have different intensities, AGSE-VNet is not affected by the size of the\ntumor, and can more accurately extract the features of the three regions, it\nhas achieved impressive results and made outstanding contributions to the\nclinical diagnosis and treatment of brain tumor patients.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:04:59 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Guan", "Xi", ""], ["Yang", "Guang", ""], ["Ye", "Jianming", ""], ["Yang", "Weiji", ""], ["Xu", "Xiaomei", ""], ["Jiang", "Weiwei", ""], ["Lai", "Xiaobo", ""]]}, {"id": "2107.12049", "submitter": "Wiebke Toussaint", "authors": "Wiebke Toussaint and Aaron Yi Ding", "title": "SVEva Fair: A Framework for Evaluating Fairness in Speaker Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the success of deep neural networks (DNNs) in enabling on-device\nvoice assistants, increasing evidence of bias and discrimination in machine\nlearning is raising the urgency of investigating the fairness of these systems.\nSpeaker verification is a form of biometric identification that gives access to\nvoice assistants. Due to a lack of fairness metrics and evaluation frameworks\nthat are appropriate for testing the fairness of speaker verification\ncomponents, little is known about how model performance varies across\nsubgroups, and what factors influence performance variation. To tackle this\nemerging challenge, we design and develop SVEva Fair, an accessible, actionable\nand model-agnostic framework for evaluating the fairness of speaker\nverification components. The framework provides evaluation measures and\nvisualisations to interrogate model performance across speaker subgroups and\ncompare fairness between models. We demonstrate SVEva Fair in a case study with\nend-to-end DNNs trained on the VoxCeleb datasets to reveal potential bias in\nexisting embedded speech recognition systems based on the demographic\nattributes of speakers. Our evaluation shows that publicly accessible benchmark\nmodels are not fair and consistently produce worse predictions for some\nnationalities, and for female speakers of most nationalities. To pave the way\nfor fair and reliable embedded speaker verification, SVEva Fair has been\nimplemented as an open-source python library and can be integrated into the\nembedded ML development pipeline to facilitate developers and researchers in\ntroubleshooting unreliable speaker verification performance, and selecting high\nimpact approaches for mitigating fairness challenges\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:15:46 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Toussaint", "Wiebke", ""], ["Ding", "Aaron Yi", ""]]}, {"id": "2107.12051", "submitter": "Tam\\'as G\\'abor Csap\\'o", "authors": "Csaba Zaink\\'o, L\\'aszl\\'o T\\'oth, Amin Honarmandi Shandiz, G\\'abor\n  Gosztolya, Alexandra Mark\\'o, G\\'eza N\\'emeth, Tam\\'as G\\'abor Csap\\'o", "title": "Adaptation of Tacotron2-based Text-To-Speech for\n  Articulatory-to-Acoustic Mapping using Ultrasound Tongue Imaging", "comments": "accepted at SSW11. arXiv admin note: text overlap with\n  arXiv:2008.03152", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For articulatory-to-acoustic mapping, typically only limited parallel\ntraining data is available, making it impossible to apply fully end-to-end\nsolutions like Tacotron2. In this paper, we experimented with transfer learning\nand adaptation of a Tacotron2 text-to-speech model to improve the final\nsynthesis quality of ultrasound-based articulatory-to-acoustic mapping with a\nlimited database. We use a multi-speaker pre-trained Tacotron2 TTS model and a\npre-trained WaveGlow neural vocoder. The articulatory-to-acoustic conversion\ncontains three steps: 1) from a sequence of ultrasound tongue image recordings,\na 3D convolutional neural network predicts the inputs of the pre-trained\nTacotron2 model, 2) the Tacotron2 model converts this intermediate\nrepresentation to an 80-dimensional mel-spectrogram, and 3) the WaveGlow model\nis applied for final inference. This generated speech contains the timing of\nthe original articulatory data from the ultrasound recording, but the F0\ncontour and the spectral information is predicted by the Tacotron2 model. The\nF0 values are independent of the original ultrasound images, but represent the\ntarget speaker, as they are inferred from the pre-trained Tacotron2 model. In\nour experiments, we demonstrated that the synthesized speech quality is more\nnatural with the proposed solutions than with our earlier model.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:19:20 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zaink\u00f3", "Csaba", ""], ["T\u00f3th", "L\u00e1szl\u00f3", ""], ["Shandiz", "Amin Honarmandi", ""], ["Gosztolya", "G\u00e1bor", ""], ["Mark\u00f3", "Alexandra", ""], ["N\u00e9meth", "G\u00e9za", ""], ["Csap\u00f3", "Tam\u00e1s G\u00e1bor", ""]]}, {"id": "2107.12061", "submitter": "Christian Guckelsberger", "authors": "Shaghayegh Roohi and Christian Guckelsberger and Asko Relas and Henri\n  Heiskanen and Jari Takatalo and Perttu H\\\"am\\\"al\\\"ainen", "title": "Predicting Game Engagement and Difficulty Using AI Players", "comments": "18 pages, 5 figures, 2 tables. In Proceedings ACM Human-Computer\n  Interaction, Vol. 5, CHIPLAY, Article 231. Publication date: September 2021", "journal-ref": null, "doi": "10.1145/3474658", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to automated playtesting for the\nprediction of human player behavior and experience. It has previously been\ndemonstrated that Deep Reinforcement Learning (DRL) game-playing agents can\npredict both game difficulty and player engagement, operationalized as average\npass and churn rates. We improve this approach by enhancing DRL with Monte\nCarlo Tree Search (MCTS). We also motivate an enhanced selection strategy for\npredictor features, based on the observation that an AI agent's best-case\nperformance can yield stronger correlations with human data than the agent's\naverage performance. Both additions consistently improve the prediction\naccuracy, and the DRL-enhanced MCTS outperforms both DRL and vanilla MCTS in\nthe hardest levels. We conclude that player modelling via automated playtesting\ncan benefit from combining DRL and MCTS. Moreover, it can be worthwhile to\ninvestigate a subset of repeated best AI agent runs, if AI gameplay does not\nyield good predictions on average.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:31:57 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Roohi", "Shaghayegh", ""], ["Guckelsberger", "Christian", ""], ["Relas", "Asko", ""], ["Heiskanen", "Henri", ""], ["Takatalo", "Jari", ""], ["H\u00e4m\u00e4l\u00e4inen", "Perttu", ""]]}, {"id": "2107.12064", "submitter": "Zikun Hu", "authors": "Zikun Hu, Yixin Cao, Lifu Huang, Tat-Seng Chua", "title": "How Knowledge Graph and Attention Help? A Quantitative Analysis into\n  Bag-level Relation Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge Graph (KG) and attention mechanism have been demonstrated effective\nin introducing and selecting useful information for weakly supervised methods.\nHowever, only qualitative analysis and ablation study are provided as evidence.\nIn this paper, we contribute a dataset and propose a paradigm to quantitatively\nevaluate the effect of attention and KG on bag-level relation extraction (RE).\nWe find that (1) higher attention accuracy may lead to worse performance as it\nmay harm the model's ability to extract entity mention features; (2) the\nperformance of attention is largely influenced by various noise distribution\npatterns, which is closely related to real-world datasets; (3) KG-enhanced\nattention indeed improves RE performance, while not through enhanced attention\nbut by incorporating entity prior; and (4) attention mechanism may exacerbate\nthe issue of insufficient training data. Based on these findings, we show that\na straightforward variant of RE model can achieve significant improvements (6%\nAUC on average) on two real-world datasets as compared with three\nstate-of-the-art baselines. Our codes and datasets are available at\nhttps://github.com/zig-kwin-hu/how-KG-ATT-help.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:38:28 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Hu", "Zikun", ""], ["Cao", "Yixin", ""], ["Huang", "Lifu", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "2107.12079", "submitter": "Andrea Galassi", "authors": "Bettina Fazzinga, Andrea Galassi, Paolo Torroni", "title": "An Argumentative Dialogue System for COVID-19 Vaccine Information", "comments": "20 pages, 2 figures, currently under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Dialogue systems are widely used in AI to support timely and interactive\ncommunication with users. We propose a general-purpose dialogue system\narchitecture that leverages computational argumentation and state-of-the-art\nlanguage technologies. We illustrate and evaluate the system using a COVID-19\nvaccine information case study.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:58:39 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Fazzinga", "Bettina", ""], ["Galassi", "Andrea", ""], ["Torroni", "Paolo", ""]]}, {"id": "2107.12085", "submitter": "Qing Guo", "authors": "Qing Guo and Ziyi Cheng and Felix Juefei-Xu and Lei Ma and Xiaofei Xie\n  and Yang Liu and Jianjun Zhao", "title": "Learning to Adversarially Blur Visual Object Tracking", "comments": "This work has been accepted to ICCV2021. 12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion blur caused by the moving of the object or camera during the exposure\ncan be a key challenge for visual object tracking, affecting tracking accuracy\nsignificantly. In this work, we explore the robustness of visual object\ntrackers against motion blur from a new angle, i.e., adversarial blur attack\n(ABA). Our main objective is to online transfer input frames to their natural\nmotion-blurred counterparts while misleading the state-of-the-art trackers\nduring the tracking process. To this end, we first design the motion blur\nsynthesizing method for visual tracking based on the generation principle of\nmotion blur, considering the motion information and the light accumulation\nprocess. With this synthetic method, we propose \\textit{optimization-based ABA\n(OP-ABA)} by iteratively optimizing an adversarial objective function against\nthe tracking w.r.t. the motion and light accumulation parameters. The OP-ABA is\nable to produce natural adversarial examples but the iteration can cause heavy\ntime cost, making it unsuitable for attacking real-time trackers. To alleviate\nthis issue, we further propose \\textit{one-step ABA (OS-ABA)} where we design\nand train a joint adversarial motion and accumulation predictive network\n(JAMANet) with the guidance of OP-ABA, which is able to efficiently estimate\nthe adversarial motion and accumulation parameters in a one-step way. The\nexperiments on four popular datasets (\\eg, OTB100, VOT2018, UAV123, and LaSOT)\ndemonstrate that our methods are able to cause significant accuracy drops on\nfour state-of-the-art trackers with high transferability. Please find the\nsource code at https://github.com/tsingqguo/ABA\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 10:09:47 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Guo", "Qing", ""], ["Cheng", "Ziyi", ""], ["Juefei-Xu", "Felix", ""], ["Ma", "Lei", ""], ["Xie", "Xiaofei", ""], ["Liu", "Yang", ""], ["Zhao", "Jianjun", ""]]}, {"id": "2107.12130", "submitter": "Alessandro Antonucci", "authors": "Alessandro Antonucci and Alessandro Facchini and Lilith Mattei", "title": "Structural Learning of Probabilistic Sentential Decision Diagrams under\n  Partial Closed-World Assumption", "comments": null, "journal-ref": "4th Workshop on Tractable Probabilistic Modeling (TPM 2021)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic sentential decision diagrams are a class of\nstructured-decomposable probabilistic circuits especially designed to embed\nlogical constraints. To adapt the classical LearnSPN scheme to learn the\nstructure of these models, we propose a new scheme based on a partial\nclosed-world assumption: data implicitly provide the logical base of the\ncircuit. Sum nodes are thus learned by recursively clustering batches in the\ninitial data base, while the partitioning of the variables obeys a given input\nvtree. Preliminary experiments show that the proposed approach might properly\nfit training data, and generalize well to test data, provided that these remain\nconsistent with the underlying logical base, that is a relaxation of the\ntraining data base.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 12:01:56 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Antonucci", "Alessandro", ""], ["Facchini", "Alessandro", ""], ["Mattei", "Lilith", ""]]}, {"id": "2107.12135", "submitter": "Ashutosh Modi", "authors": "Gargi Singh and Dhanajit Brahma and Piyush Rai and Ashutosh Modi", "title": "Fine-Grained Emotion Prediction by Modeling Emotion Definitions", "comments": "8 Pages, accepted at ACII 2021 for Orals", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a new framework for fine-grained emotion prediction\nin the text through emotion definition modeling. Our approach involves a\nmulti-task learning framework that models definitions of emotions as an\nauxiliary task while being trained on the primary task of emotion prediction.\nWe model definitions using masked language modeling and class definition\nprediction tasks. Our models outperform existing state-of-the-art for\nfine-grained emotion dataset GoEmotions. We further show that this trained\nmodel can be used for transfer learning on other benchmark datasets in emotion\nprediction with varying emotion label sets, domains, and sizes. The proposed\nmodels outperform the baselines on transfer learning experiments demonstrating\nthe generalization capability of the models.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 12:11:18 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Singh", "Gargi", ""], ["Brahma", "Dhanajit", ""], ["Rai", "Piyush", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2107.12143", "submitter": "Alara Zindanc{\\i}o\\u{g}lu", "authors": "Alara Zindanc{\\i}o\\u{g}lu and T. Metin Sezgin", "title": "Perceptually Validated Precise Local Editing for Facial Action Units\n  with StyleGAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to edit facial expressions has a wide range of applications in\ncomputer graphics. The ideal facial expression editing algorithm needs to\nsatisfy two important criteria. First, it should allow precise and targeted\nediting of individual facial actions. Second, it should generate high fidelity\noutputs without artifacts. We build a solution based on StyleGAN, which has\nbeen used extensively for semantic manipulation of faces. As we do so, we add\nto our understanding of how various semantic attributes are encoded in\nStyleGAN. In particular, we show that a naive strategy to perform editing in\nthe latent space results in undesired coupling between certain action units,\neven if they are conceptually distinct. For example, although brow lowerer and\nlip tightener are distinct action units, they appear correlated in the training\ndata. Hence, StyleGAN has difficulty in disentangling them. We allow\ndisentangled editing of such action units by computing detached regions of\ninfluence for each action unit, and restrict editing to these regions. We\nvalidate the effectiveness of our local editing method through perception\nexperiments conducted with 23 subjects. The results show that our method\nprovides higher control over local editing and produces images with superior\nfidelity compared to the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 12:21:37 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 09:05:22 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zindanc\u0131o\u011flu", "Alara", ""], ["Sezgin", "T. Metin", ""]]}, {"id": "2107.12178", "submitter": "Nidhika Yadav", "authors": "Nidhika Yadav", "title": "Novel Span Measure, Spanning Sets and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rough Set based Spanning Sets were recently proposed to deal with\nuncertainties arising in the problem in domain of natural language processing\nproblems. This paper presents a novel span measure using upper approximations.\nThe key contribution of this paper is to propose another uncertainty measure of\nspan and spanning sets. Firstly, this paper proposes a new definition of\ncomputing span which use upper approximation instead of boundary regions. This\nis useful in situations where computing upper approximations are much more\nconvenient that computing boundary region. Secondly, properties of novel span\nand relation with earlier span measure are discussed. Thirdly, the paper\npresents application areas where the proposed span measure can be utilized.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 20:20:19 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Yadav", "Nidhika", ""]]}, {"id": "2107.12183", "submitter": "Jicong Fan", "authors": "Jicong Fan, Yiheng Tu, Zhao Zhang, Mingbo Zhao", "title": "EGGS: Eigen-Gap Guided Search Making Subspace Clustering Easy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of spectral clustering heavily relies on the quality of\naffinity matrix. A variety of affinity-matrix-construction methods have been\nproposed but they have hyper-parameters to determine beforehand, which requires\nstrong experience and lead to difficulty in real applications especially when\nthe inter-cluster similarity is high or/and the dataset is large. On the other\nhand, we often have to determine to use a linear model or a nonlinear model,\nwhich still depends on experience. To solve these two problems, in this paper,\nwe present an eigen-gap guided search method for subspace clustering. The main\nidea is to find the most reliable affinity matrix among a set of candidates\nconstructed by linear and kernel regressions, where the reliability is\nquantified by the \\textit{relative-eigen-gap} of graph Laplacian defined in\nthis paper. We show, theoretically and numerically, that the Laplacian matrix\nwith a larger relative-eigen-gap often yields a higher clustering accuracy and\nstability. Our method is able to automatically search the best model and\nhyper-parameters in a pre-defined space. The search space is very easy to\ndetermine and can be arbitrarily large, though a relatively compact search\nspace can reduce the highly unnecessary computation. Our method has high\nflexibility and convenience in real applications, and also has low\ncomputational cost because the affinity matrix is not computed by iterative\noptimization. We extend the method to large-scale datasets such as MNIST, on\nwhich the time cost is less than 90s and the clustering accuracy is\nstate-of-the-art. Extensive experiments of natural image clustering show that\nour method is more stable, accurate, and efficient than baseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 08:53:36 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 01:38:14 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Fan", "Jicong", ""], ["Tu", "Yiheng", ""], ["Zhang", "Zhao", ""], ["Zhao", "Mingbo", ""]]}, {"id": "2107.12189", "submitter": "Thanh Binh Nguyen", "authors": "Hieu T. Ung, Huy Q. Ung, Binh T. Nguyen", "title": "An Efficient Insect Pest Classification Using Multiple Convolutional\n  Neural Network Based Models", "comments": "22 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Accurate insect pest recognition is significant to protect the crop or take\nthe early treatment on the infected yield, and it helps reduce the loss for the\nagriculture economy. Design an automatic pest recognition system is necessary\nbecause manual recognition is slow, time-consuming, and expensive. The\nImage-based pest classifier using the traditional computer vision method is not\nefficient due to the complexity. Insect pest classification is a difficult task\nbecause of various kinds, scales, shapes, complex backgrounds in the field, and\nhigh appearance similarity among insect species. With the rapid development of\ndeep learning technology, the CNN-based method is the best way to develop a\nfast and accurate insect pest classifier. We present different convolutional\nneural network-based models in this work, including attention, feature pyramid,\nand fine-grained models. We evaluate our methods on two public datasets: the\nlarge-scale insect pest dataset, the IP102 benchmark dataset, and a smaller\ndataset, namely D0 in terms of the macro-average precision (MPre), the\nmacro-average recall (MRec), the macro-average F1- score (MF1), the accuracy\n(Acc), and the geometric mean (GM). The experimental results show that\ncombining these convolutional neural network-based models can better perform\nthan the state-of-the-art methods on these two datasets. For instance, the\nhighest accuracy we obtained on IP102 and D0 is $74.13\\%$ and $99.78\\%$,\nrespectively, bypassing the corresponding state-of-the-art accuracy: $67.1\\%$\n(IP102) and $98.8\\%$ (D0). We also publish our codes for contributing to the\ncurrent research related to the insect pest classification problem.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 12:53:28 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Ung", "Hieu T.", ""], ["Ung", "Huy Q.", ""], ["Nguyen", "Binh T.", ""]]}, {"id": "2107.12211", "submitter": "Yann Fraboni", "authors": "Yann Fraboni, Richard Vidal, Laetitia Kameni, Marco Lorenzi", "title": "On The Impact of Client Sampling on Federated Learning Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While clients' sampling is a central operation of current state-of-the-art\nfederated learning (FL) approaches, the impact of this procedure on the\nconvergence and speed of FL remains to date under-investigated. In this work we\nintroduce a novel decomposition theorem for the convergence of FL, allowing to\nclearly quantify the impact of client sampling on the global model update.\nContrarily to previous convergence analyses, our theorem provides the exact\ndecomposition of a given convergence step, thus enabling accurate\nconsiderations about the role of client sampling and heterogeneity. First, we\nprovide a theoretical ground for previously reported results on the\nrelationship between FL convergence and the variance of the aggregation\nweights. Second, we prove for the first time that the quality of FL convergence\nis also impacted by the resulting covariance between aggregation weights.\nThird, we establish that the sum of the aggregation weights is another source\nof slow-down and should be equal to 1 to improve FL convergence speed. Our\ntheory is general, and is here applied to Multinomial Distribution (MD) and\nUniform sampling, the two default client sampling in FL, and demonstrated\nthrough a series of experiments in non-iid and unbalanced scenarios. Our\nresults suggest that MD sampling should be used as default sampling scheme, due\nto the resilience to the changes in data ratio during the learning process,\nwhile Uniform sampling is superior only in the special case when clients have\nthe same amount of data.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 13:36:06 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Fraboni", "Yann", ""], ["Vidal", "Richard", ""], ["Kameni", "Laetitia", ""], ["Lorenzi", "Marco", ""]]}, {"id": "2107.12216", "submitter": "Jiaming Guo", "authors": "Jiaming Guo, Rui Zhang, Xishan Zhang, Shaohui Peng, Qi Yi, Zidong Du,\n  Xing Hu, Qi Guo, Yunji Chen", "title": "Hindsight Value Function for Variance Reduction in Stochastic Dynamic\n  Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods are appealing in deep reinforcement learning but\nsuffer from high variance of gradient estimate. To reduce the variance, the\nstate value function is applied commonly. However, the effect of the state\nvalue function becomes limited in stochastic dynamic environments, where the\nunexpected state dynamics and rewards will increase the variance. In this\npaper, we propose to replace the state value function with a novel hindsight\nvalue function, which leverages the information from the future to reduce the\nvariance of the gradient estimate for stochastic dynamic environments.\n  Particularly, to obtain an ideally unbiased gradient estimate, we propose an\ninformation-theoretic approach, which optimizes the embeddings of the future to\nbe independent of previous actions. In our experiments, we apply the proposed\nhindsight value function in stochastic dynamic environments, including\ndiscrete-action environments and continuous-action environments. Compared with\nthe standard state value function, the proposed hindsight value function\nconsistently reduces the variance, stabilizes the training, and improves the\neventual policy.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 13:48:23 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Guo", "Jiaming", ""], ["Zhang", "Rui", ""], ["Zhang", "Xishan", ""], ["Peng", "Shaohui", ""], ["Yi", "Qi", ""], ["Du", "Zidong", ""], ["Hu", "Xing", ""], ["Guo", "Qi", ""], ["Chen", "Yunji", ""]]}, {"id": "2107.12220", "submitter": "Hendrik Schuff", "authors": "Hendrik Schuff, Heike Adel, Ngoc Thang Vu", "title": "Thought Flow Nets: From Single Predictions to Trains of Model Thought", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When humans solve complex problems, they rarely come up with a decision\nright-away. Instead, they start with an intuitive decision, reflect upon it,\nspot mistakes, resolve contradictions and jump between different hypotheses.\nThus, they create a sequence of ideas and follow a train of thought that\nultimately reaches a conclusive decision. Contrary to this, today's neural\nclassification models are mostly trained to map an input to one single and\nfixed output. In this paper, we investigate how we can give models the\nopportunity of a second, third and $k$-th thought. We take inspiration from\nHegel's dialectics and propose a method that turns an existing classifier's\nclass prediction (such as the image class forest) into a sequence of\npredictions (such as forest $\\rightarrow$ tree $\\rightarrow$ mushroom).\nConcretely, we propose a correction module that is trained to estimate the\nmodel's correctness as well as an iterative prediction update based on the\nprediction's gradient. Our approach results in a dynamic system over class\nprobability distributions $\\unicode{x2014}$ the thought flow. We evaluate our\nmethod on diverse datasets and tasks from computer vision and natural language\nprocessing. We observe surprisingly complex but intuitive behavior and\ndemonstrate that our method (i) can correct misclassifications, (ii)\nstrengthens model performance, (iii) is robust to high levels of adversarial\nattacks, (iv) can increase accuracy up to 4% in a label-distribution-shift\nsetting and (iv) provides a tool for model interpretability that uncovers model\nknowledge which otherwise remains invisible in a single distribution\nprediction.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 13:56:37 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Schuff", "Hendrik", ""], ["Adel", "Heike", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "2107.12226", "submitter": "Ivan P Yamshchikov", "authors": "Anastasia Malysheva, Alexey Tikhonov, Ivan P. Yamshchikov", "title": "DYPLODOC: Dynamic Plots for Document Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Narrative generation and analysis are still on the fringe of modern natural\nlanguage processing yet are crucial in a variety of applications. This paper\nproposes a feature extraction method for plot dynamics. We present a dataset\nthat consists of the plot descriptions for thirteen thousand TV shows alongside\nmeta-information on their genres and dynamic plots extracted from them. We\nvalidate the proposed tool for plot dynamics extraction and discuss possible\napplications of this method to the tasks of narrative analysis and generation.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 14:12:45 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Malysheva", "Anastasia", ""], ["Tikhonov", "Alexey", ""], ["Yamshchikov", "Ivan P.", ""]]}, {"id": "2107.12230", "submitter": "Olivier Peltre", "authors": "Olivier Peltre", "title": "Belief Propagation as Diffusion", "comments": "10 pages, 3 figures, GSI'21 conference", "journal-ref": "Geometric Science of Information, 5th International Conference GSI\n  2021 Paris France July 21-23 2021 Proceedings, Frank Nielsen and Frederic\n  Barbaresco, Springer International Publishing", "doi": "10.1007/978-3-030-80209-7", "report-no": null, "categories": "math.AT cs.AI math-ph math.MP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce novel belief propagation algorithms to estimate the marginals of\na high dimensional probability distribution. They involve natural\n(co)homological constructions relevant for a localised description of\nstatistical systems.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 14:17:26 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Peltre", "Olivier", ""]]}, {"id": "2107.12262", "submitter": "Chengcheng Han", "authors": "ChengCheng Han, Zeqiu Fan, Dongxiang Zhang, Minghui Qiu, Ming Gao,\n  Aoying Zhou", "title": "Meta-Learning Adversarial Domain Adaptation Network for Few-Shot Text\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning has emerged as a trending technique to tackle few-shot text\nclassification and achieved state-of-the-art performance. However, existing\nsolutions heavily rely on the exploitation of lexical features and their\ndistributional signatures on training data, while neglecting to strengthen the\nmodel's ability to adapt to new tasks. In this paper, we propose a novel\nmeta-learning framework integrated with an adversarial domain adaptation\nnetwork, aiming to improve the adaptive ability of the model and generate\nhigh-quality text embedding for new classes. Extensive experiments are\nconducted on four benchmark datasets and our method demonstrates clear\nsuperiority over the state-of-the-art models in all the datasets. In\nparticular, the accuracy of 1-shot and 5-shot classification on the dataset of\n20 Newsgroups is boosted from 52.1% to 59.6%, and from 68.3% to 77.8%,\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 15:09:40 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Han", "ChengCheng", ""], ["Fan", "Zeqiu", ""], ["Zhang", "Dongxiang", ""], ["Qiu", "Minghui", ""], ["Gao", "Ming", ""], ["Zhou", "Aoying", ""]]}, {"id": "2107.12292", "submitter": "Ting Yao", "authors": "Yehao Li and Ting Yao and Yingwei Pan and Tao Mei", "title": "Contextual Transformer Networks for Visual Recognition", "comments": "Rank 1 in open-set image classification task of Open World Vision\n  Challenge @ CVPR 2021; The source code and models are publicly available at:\n  \\url{https://github.com/JDAI-CV/CoTNet}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer with self-attention has led to the revolutionizing of natural\nlanguage processing field, and recently inspires the emergence of\nTransformer-style architecture design with competitive results in numerous\ncomputer vision tasks. Nevertheless, most of existing designs directly employ\nself-attention over a 2D feature map to obtain the attention matrix based on\npairs of isolated queries and keys at each spatial location, but leave the rich\ncontexts among neighbor keys under-exploited. In this work, we design a novel\nTransformer-style module, i.e., Contextual Transformer (CoT) block, for visual\nrecognition. Such design fully capitalizes on the contextual information among\ninput keys to guide the learning of dynamic attention matrix and thus\nstrengthens the capacity of visual representation. Technically, CoT block first\ncontextually encodes input keys via a $3\\times3$ convolution, leading to a\nstatic contextual representation of inputs. We further concatenate the encoded\nkeys with input queries to learn the dynamic multi-head attention matrix\nthrough two consecutive $1\\times1$ convolutions. The learnt attention matrix is\nmultiplied by input values to achieve the dynamic contextual representation of\ninputs. The fusion of the static and dynamic contextual representations are\nfinally taken as outputs. Our CoT block is appealing in the view that it can\nreadily replace each $3\\times3$ convolution in ResNet architectures, yielding a\nTransformer-style backbone named as Contextual Transformer Networks (CoTNet).\nThrough extensive experiments over a wide range of applications (e.g., image\nrecognition, object detection and instance segmentation), we validate the\nsuperiority of CoTNet as a stronger backbone. Source code is available at\n\\url{https://github.com/JDAI-CV/CoTNet}.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 16:00:21 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Li", "Yehao", ""], ["Yao", "Ting", ""], ["Pan", "Yingwei", ""], ["Mei", "Tao", ""]]}, {"id": "2107.12375", "submitter": "Kenneth Atz", "authors": "Kenneth Atz, Francesca Grisoni, Gisbert Schneider", "title": "Geometric Deep Learning on Molecular Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.AI cs.LG q-bio.BM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Geometric deep learning (GDL), which is based on neural network architectures\nthat incorporate and process symmetry information, has emerged as a recent\nparadigm in artificial intelligence. GDL bears particular promise in molecular\nmodeling applications, in which various molecular representations with\ndifferent symmetry properties and levels of abstraction exist. This review\nprovides a structured and harmonized overview of molecular GDL, highlighting\nits applications in drug discovery, chemical synthesis prediction, and quantum\nchemistry. Emphasis is placed on the relevance of the learned molecular\nfeatures and their complementarity to well-established molecular descriptors.\nThis review provides an overview of current challenges and opportunities, and\npresents a forecast of the future of GDL for molecular sciences.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:23:43 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Atz", "Kenneth", ""], ["Grisoni", "Francesca", ""], ["Schneider", "Gisbert", ""]]}, {"id": "2107.12416", "submitter": "Gangshan Jing", "authors": "Gangshan Jing, He Bai, Jemin George, Aranya Chakrabortty, Piyush K.\n  Sharma", "title": "Asynchronous Distributed Reinforcement Learning for LQR Control via\n  Zeroth-Order Block Coordinate Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently introduced distributed zeroth-order optimization (ZOO) algorithms\nhave shown their utility in distributed reinforcement learning (RL).\nUnfortunately, in the gradient estimation process, almost all of them require\nrandom samples with the same dimension as the global variable and/or require\nevaluation of the global cost function, which may induce high estimation\nvariance for large-scale networks. In this paper, we propose a novel\ndistributed zeroth-order algorithm by leveraging the network structure inherent\nin the optimization objective, which allows each agent to estimate its local\ngradient by local cost evaluation independently, without use of any consensus\nprotocol. The proposed algorithm exhibits an asynchronous update scheme, and is\ndesigned for stochastic non-convex optimization with a possibly non-convex\nfeasible domain based on the block coordinate descent method. The algorithm is\nlater employed as a distributed model-free RL algorithm for distributed linear\nquadratic regulator design, where a learning graph is designed to describe the\nrequired interaction relationship among agents in distributed learning. We\nprovide an empirical validation of the proposed algorithm to benchmark its\nperformance on convergence rate and variance against a centralized ZOO\nalgorithm.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 18:11:07 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 14:42:19 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Jing", "Gangshan", ""], ["Bai", "He", ""], ["George", "Jemin", ""], ["Chakrabortty", "Aranya", ""], ["Sharma", "Piyush K.", ""]]}, {"id": "2107.12422", "submitter": "Miao Yin", "authors": "Miao Yin, Yang Sui, Siyu Liao and Bo Yuan", "title": "Towards Efficient Tensor Decomposition-Based DNN Model Compression with\n  Optimization Framework", "comments": "This paper was accepted to CVPR'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Advanced tensor decomposition, such as Tensor train (TT) and Tensor ring\n(TR), has been widely studied for deep neural network (DNN) model compression,\nespecially for recurrent neural networks (RNNs). However, compressing\nconvolutional neural networks (CNNs) using TT/TR always suffers significant\naccuracy loss. In this paper, we propose a systematic framework for tensor\ndecomposition-based model compression using Alternating Direction Method of\nMultipliers (ADMM). By formulating TT decomposition-based model compression to\nan optimization problem with constraints on tensor ranks, we leverage ADMM\ntechnique to systemically solve this optimization problem in an iterative way.\nDuring this procedure, the entire DNN model is trained in the original\nstructure instead of TT format, but gradually enjoys the desired low tensor\nrank characteristics. We then decompose this uncompressed model to TT format\nand fine-tune it to finally obtain a high-accuracy TT-format DNN model. Our\nframework is very general, and it works for both CNNs and RNNs, and can be\neasily modified to fit other tensor decomposition approaches. We evaluate our\nproposed framework on different DNN models for image classification and video\nrecognition tasks. Experimental results show that our ADMM-based TT-format\nmodels demonstrate very high compression performance with high accuracy.\nNotably, on CIFAR-100, with 2.3X and 2.4X compression ratios, our models have\n1.96% and 2.21% higher top-1 accuracy than the original ResNet-20 and\nResNet-32, respectively. For compressing ResNet-18 on ImageNet, our model\nachieves 2.47X FLOPs reduction without accuracy loss.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 18:31:33 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Yin", "Miao", ""], ["Sui", "Yang", ""], ["Liao", "Siyu", ""], ["Yuan", "Bo", ""]]}, {"id": "2107.12433", "submitter": "Jos\\'e Su\\'arez-Varela", "authors": "Jos\\'e Su\\'arez-Varela, Miquel Ferriol-Galm\\'es, Albert L\\'opez, Paul\n  Almasan, Guillermo Bern\\'ardez, David Pujol-Perich, Krzysztof Rusek, Lo\\\"ick\n  Bonniot, Christoph Neumann, Fran\\c{c}ois Schnitzler, Fran\\c{c}ois Ta\\\"iani,\n  Martin Happ, Christian Maier, Jia Lei Du, Matthias Herlich, Peter Dorfinger,\n  Nick Vincent Hainke, Stefan Venz, Johannes Wegener, Henrike Wissing, Bo Wu,\n  Shihan Xiao, Pere Barlet-Ros, Albert Cabellos-Aparicio", "title": "The Graph Neural Networking Challenge: A Worldwide Competition for\n  Education in AI/ML for Networks", "comments": null, "journal-ref": "ACM SIGCOMM Computer Communication Review, Vol. 51, No. 3, pp.\n  9-16, 2021", "doi": "10.1145/3477482.3477485", "report-no": null, "categories": "cs.NI cs.AI cs.GL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  During the last decade, Machine Learning (ML) has increasingly become a hot\ntopic in the field of Computer Networks and is expected to be gradually adopted\nfor a plethora of control, monitoring and management tasks in real-world\ndeployments. This poses the need to count on new generations of students,\nresearchers and practitioners with a solid background in ML applied to\nnetworks. During 2020, the International Telecommunication Union (ITU) has\norganized the \"ITU AI/ML in 5G challenge'', an open global competition that has\nintroduced to a broad audience some of the current main challenges in ML for\nnetworks. This large-scale initiative has gathered 23 different challenges\nproposed by network operators, equipment manufacturers and academia, and has\nattracted a total of 1300+ participants from 60+ countries. This paper narrates\nour experience organizing one of the proposed challenges: the \"Graph Neural\nNetworking Challenge 2020''. We describe the problem presented to participants,\nthe tools and resources provided, some organization aspects and participation\nstatistics, an outline of the top-3 awarded solutions, and a summary with some\nlessons learned during all this journey. As a result, this challenge leaves a\ncurated set of educational resources openly available to anyone interested in\nthe topic.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 18:52:00 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Su\u00e1rez-Varela", "Jos\u00e9", ""], ["Ferriol-Galm\u00e9s", "Miquel", ""], ["L\u00f3pez", "Albert", ""], ["Almasan", "Paul", ""], ["Bern\u00e1rdez", "Guillermo", ""], ["Pujol-Perich", "David", ""], ["Rusek", "Krzysztof", ""], ["Bonniot", "Lo\u00efck", ""], ["Neumann", "Christoph", ""], ["Schnitzler", "Fran\u00e7ois", ""], ["Ta\u00efani", "Fran\u00e7ois", ""], ["Happ", "Martin", ""], ["Maier", "Christian", ""], ["Du", "Jia Lei", ""], ["Herlich", "Matthias", ""], ["Dorfinger", "Peter", ""], ["Hainke", "Nick Vincent", ""], ["Venz", "Stefan", ""], ["Wegener", "Johannes", ""], ["Wissing", "Henrike", ""], ["Wu", "Bo", ""], ["Xiao", "Shihan", ""], ["Barlet-Ros", "Pere", ""], ["Cabellos-Aparicio", "Albert", ""]]}, {"id": "2107.12436", "submitter": "{\\L}ukasz Bolikowski", "authors": "Jan Ittner, Lukasz Bolikowski, Konstantin Hemker and Ricardo Kennedy", "title": "Feature Synergy, Redundancy, and Independence in Global Model\n  Explanations using SHAP Vector Decomposition", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We offer a new formalism for global explanations of pairwise feature\ndependencies and interactions in supervised models. Building upon SHAP values\nand SHAP interaction values, our approach decomposes feature contributions into\nsynergistic, redundant and independent components (S-R-I decomposition of SHAP\nvectors). We propose a geometric interpretation of the components and formally\nprove its basic properties. Finally, we demonstrate the utility of synergy,\nredundancy and independence by applying them to a constructed data set and\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 18:56:31 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Ittner", "Jan", ""], ["Bolikowski", "Lukasz", ""], ["Hemker", "Konstantin", ""], ["Kennedy", "Ricardo", ""]]}, {"id": "2107.12460", "submitter": "Danielle Rothermel", "authors": "Danielle Rothermel, Margaret Li, Tim Rockt\\\"aschel, Jakob Foerster", "title": "Don't Sweep your Learning Rate under the Rug: A Closer Look at\n  Cross-modal Transfer of Pretrained Transformers", "comments": "Accepted to ICML 2021 Workshop: Self-Supervised Learning for\n  Reasoning and Perception", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-supervised pre-training of large-scale transformer models on text\ncorpora followed by finetuning has achieved state-of-the-art on a number of\nnatural language processing tasks. Recently, Lu et al. (2021, arXiv:2103.05247)\nclaimed that frozen pretrained transformers (FPTs) match or outperform training\nfrom scratch as well as unfrozen (fine-tuned) pretrained transformers in a set\nof transfer tasks to other modalities. In our work, we find that this result\nis, in fact, an artifact of not tuning the learning rates. After carefully\nredesigning the empirical setup, we find that when tuning learning rates\nproperly, pretrained transformers do outperform or match training from scratch\nin all of our tasks, but only as long as the entire model is finetuned. Thus,\nwhile transfer from pretrained language models to other modalities does indeed\nprovide gains and hints at exciting possibilities for future work, properly\ntuning hyperparameters is important for arriving at robust findings.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 20:20:48 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Rothermel", "Danielle", ""], ["Li", "Margaret", ""], ["Rockt\u00e4schel", "Tim", ""], ["Foerster", "Jakob", ""]]}, {"id": "2107.12473", "submitter": "Aritra Chowdhury", "authors": "Alberto Santamaria-Pang, Jianwei Qiu, Aritra Chowdhury, James\n  Kubricht, Peter Tu, Iyer Naresh, Nurali Virani", "title": "Adversarial Attacks with Time-Scale Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel framework for real-time black-box universal attacks which\ndisrupts activations of early convolutional layers in deep learning models. Our\nhypothesis is that perturbations produced in the wavelet space disrupt early\nconvolutional layers more effectively than perturbations performed in the time\ndomain. The main challenge in adversarial attacks is to preserve low frequency\nimage content while minimally changing the most meaningful high frequency\ncontent. To address this, we formulate an optimization problem using time-scale\n(wavelet) representations as a dual space in three steps. First, we project\noriginal images into orthonormal sub-spaces for low and high scales via wavelet\ncoefficients. Second, we perturb wavelet coefficients for high scale projection\nusing a generator network. Third, we generate new adversarial images by\nprojecting back the original coefficients from the low scale and the perturbed\ncoefficients from the high scale sub-space. We provide a theoretical framework\nthat guarantees a dual mapping from time and time-scale domain representations.\nWe compare our results with state-of-the-art black-box attacks from\ngenerative-based and gradient-based models. We also verify efficacy against\nmultiple defense methods such as JPEG compression, Guided Denoiser and\nComdefend. Our results show that wavelet-based perturbations consistently\noutperform time-based attacks thus providing new insights into vulnerabilities\nof deep learning models and could potentially lead to robust architectures or\nnew defense and attack mechanisms by leveraging time-scale representations.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 20:58:57 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Santamaria-Pang", "Alberto", ""], ["Qiu", "Jianwei", ""], ["Chowdhury", "Aritra", ""], ["Kubricht", "James", ""], ["Tu", "Peter", ""], ["Naresh", "Iyer", ""], ["Virani", "Nurali", ""]]}, {"id": "2107.12477", "submitter": "Nidhika Yadav", "authors": "Nidhika Yadav", "title": "Decision Making Using Rough Set based Spanning Sets for a Decision\n  System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rough Set based concepts of Span and Spanning Sets were recently proposed to\ndeal with uncertainties in data. Here, this paper, presents novel concepts for\ngeneric decision-making process using Rough Set based span for a decision\ntable. Majority of problems in Artificial Intelligence deal with decision\nmaking. This paper provides real life applications of proposed Rough Set based\nspan for decision tables. Here, novel concept of span for a decision table is\nproposed, illustrated with real life example of flood relief and rescue team\nassignment. Its uses, applications and properties are explored. The key\ncontribution of paper is primarily to study decision making using Rough Set\nbased Span for a decision tables, as against an information system in prior\nworks. Here, the main contribution is that decision classes are automatically\nlearned by the technique of Rough Set based span, for a particular problem,\nhence automating the decision-making process. These decision-making tools based\non span can guide an expert in taking decisions in tough and time-bound\nsituations.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 20:58:52 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Yadav", "Nidhika", ""]]}, {"id": "2107.12501", "submitter": "Matthew Guzdial", "authors": "Thomas Maurer and Matthew Guzdial", "title": "Adversarial Random Forest Classifier for Automated Game Design", "comments": "6 pages, 3 figures, Reflections Track of the 2021 ACM Foundations of\n  Digital Games Conference", "journal-ref": "Proceedings of the 16th International Conference on the\n  Foundations of Digital Games (FDG) 2021", "doi": "10.1145/3472538.3472587", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous game design, generating games algorithmically, has been a longtime\ngoal within the technical games research field. However, existing autonomous\ngame design systems have relied in large part on human-authoring for game\ndesign knowledge, such as fitness functions in search-based methods. In this\npaper, we describe an experiment to attempt to learn a human-like fitness\nfunction for autonomous game design in an adversarial manner. While our\nexperimental work did not meet our expectations, we present an analysis of our\nsystem and results that we hope will be informative to future autonomous game\ndesign research.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 22:30:38 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Maurer", "Thomas", ""], ["Guzdial", "Matthew", ""]]}, {"id": "2107.12512", "submitter": "Eduard Ramon", "authors": "Eduard Ramon, Gil Triginer, Janna Escur, Albert Pumarola, Jaime\n  Garcia, Xavier Giro-i-Nieto, Francesc Moreno-Noguer", "title": "H3D-Net: Few-Shot High-Fidelity 3D Head Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent learning approaches that implicitly represent surface geometry using\ncoordinate-based neural representations have shown impressive results in the\nproblem of multi-view 3D reconstruction. The effectiveness of these techniques\nis, however, subject to the availability of a large number (several tens) of\ninput views of the scene, and computationally demanding optimizations. In this\npaper, we tackle these limitations for the specific problem of few-shot full 3D\nhead reconstruction, by endowing coordinate-based representations with a\nprobabilistic shape prior that enables faster convergence and better\ngeneralization when using few input images (down to three). First, we learn a\nshape model of 3D heads from thousands of incomplete raw scans using implicit\nrepresentations. At test time, we jointly overfit two coordinate-based neural\nnetworks to the scene, one modeling the geometry and another estimating the\nsurface radiance, using implicit differentiable rendering. We devise a\ntwo-stage optimization strategy in which the learned prior is used to\ninitialize and constrain the geometry during an initial optimization phase.\nThen, the prior is unfrozen and fine-tuned to the scene. By doing this, we\nachieve high-fidelity head reconstructions, including hair and shoulders, and\nwith a high level of detail that consistently outperforms both state-of-the-art\n3D Morphable Models methods in the few-shot scenario, and non-parametric\nmethods when large sets of views are available.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 23:04:18 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Ramon", "Eduard", ""], ["Triginer", "Gil", ""], ["Escur", "Janna", ""], ["Pumarola", "Albert", ""], ["Garcia", "Jaime", ""], ["Giro-i-Nieto", "Xavier", ""], ["Moreno-Noguer", "Francesc", ""]]}, {"id": "2107.12514", "submitter": "Jesse Thomason", "authors": "Jesse Thomason, Mohit Shridhar, Yonatan Bisk, Chris Paxton, Luke\n  Zettlemoyer", "title": "Language Grounding with 3D Objects", "comments": "https://github.com/snaredataset/snare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seemingly simple natural language requests to a robot are generally\nunderspecified, for example \"Can you bring me the wireless mouse?\" When viewing\nmice on the shelf, the number of buttons or presence of a wire may not be\nvisible from certain angles or positions. Flat images of candidate mice may not\nprovide the discriminative information needed for \"wireless\". The world, and\nobjects in it, are not flat images but complex 3D shapes. If a human requests\nan object based on any of its basic properties, such as color, shape, or\ntexture, robots should perform the necessary exploration to accomplish the\ntask. In particular, while substantial effort and progress has been made on\nunderstanding explicitly visual attributes like color and category,\ncomparatively little progress has been made on understanding language about\nshapes and contours. In this work, we introduce a novel reasoning task that\ntargets both visual and non-visual language about 3D objects. Our new\nbenchmark, ShapeNet Annotated with Referring Expressions (SNARE), requires a\nmodel to choose which of two objects is being referenced by a natural language\ndescription. We introduce several CLIP-based models for distinguishing objects\nand demonstrate that while recent advances in jointly modeling vision and\nlanguage are useful for robotic language understanding, it is still the case\nthat these models are weaker at understanding the 3D nature of objects --\nproperties which play a key role in manipulation. In particular, we find that\nadding view estimation to language grounding models improves accuracy on both\nSNARE and when identifying objects referred to in language on a robot platform.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 23:35:58 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Thomason", "Jesse", ""], ["Shridhar", "Mohit", ""], ["Bisk", "Yonatan", ""], ["Paxton", "Chris", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "2107.12533", "submitter": "Matthew Guzdial", "authors": "Zisen Zhou and Matthew Guzdial", "title": "Toward Co-creative Dungeon Generation via Transfer Learning", "comments": "7 pages, 6 figures, Workshop on Procedural Content Generation", "journal-ref": "Proceedings of the Twelfth Workshop on Procedural Content\n  Generation 2021", "doi": "10.1145/3472538.3472601", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Co-creative Procedural Content Generation via Machine Learning (PCGML) refers\nto systems where a PCGML agent and a human work together to produce output\ncontent. One of the limitations of co-creative PCGML is that it requires\nco-creative training data for a PCGML agent to learn to interact with humans.\nHowever, acquiring this data is a difficult and time-consuming process. In this\nwork, we propose approximating human-AI interaction data and employing transfer\nlearning to adapt learned co-creative knowledge from one game to a different\ngame. We explore this approach for co-creative Zelda dungeon room generation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 00:54:55 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zhou", "Zisen", ""], ["Guzdial", "Matthew", ""]]}, {"id": "2107.12536", "submitter": "Caetano Mazzoni Ranieri", "authors": "Caetano M. Ranieri, Jhielson M. Pimentel, Marcelo R. Romano, Leonardo\n  A. Elias, Roseli A. F. Romero, Michael A. Lones, Mariana F. P. Araujo,\n  Patricia A. Vargas, Renan C. Moioli", "title": "A Data-Driven Biophysical Computational Model of Parkinson's Disease\n  based on Marmoset Monkeys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we propose a new biophysical computational model of brain\nregions relevant to Parkinson's Disease based on local field potential data\ncollected from the brain of marmoset monkeys. Parkinson's disease is a\nneurodegenerative disorder, linked to the death of dopaminergic neurons at the\nsubstantia nigra pars compacta, which affects the normal dynamics of the basal\nganglia-thalamus-cortex neuronal circuit of the brain. Although there are\nmultiple mechanisms underlying the disease, a complete description of those\nmechanisms and molecular pathogenesis are still missing, and there is still no\ncure. To address this gap, computational models that resemble neurobiological\naspects found in animal models have been proposed. In our model, we performed a\ndata-driven approach in which a set of biologically constrained parameters is\noptimised using differential evolution. Evolved models successfully resembled\nsingle-neuron mean firing rates and spectral signatures of local field\npotentials from healthy and parkinsonian marmoset brain data. As far as we are\nconcerned, this is the first computational model of Parkinson's Disease based\non simultaneous electrophysiological recordings from seven brain regions of\nMarmoset monkeys. Results show that the proposed model could facilitate the\ninvestigation of the mechanisms of PD and support the development of techniques\nthat can indicate new therapies. It could also be applied to other\ncomputational neuroscience problems in which biological data could be used to\nfit multi-scale models of brain circuits.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 01:09:11 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Ranieri", "Caetano M.", ""], ["Pimentel", "Jhielson M.", ""], ["Romano", "Marcelo R.", ""], ["Elias", "Leonardo A.", ""], ["Romero", "Roseli A. F.", ""], ["Lones", "Michael A.", ""], ["Araujo", "Mariana F. P.", ""], ["Vargas", "Patricia A.", ""], ["Moioli", "Renan C.", ""]]}, {"id": "2107.12540", "submitter": "Caetano Mazzoni Ranieri", "authors": "Caetano M. Ranieri, Renan C. Moioli, Patricia A. Vargas, Roseli A. F.\n  Romero", "title": "A Neurorobotics Approach to Behaviour Selection based on Human Activity\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Behaviour selection has been an active research topic for robotics, in\nparticular in the field of human-robot interaction. For a robot to interact\neffectively and autonomously with humans, the coupling between techniques for\nhuman activity recognition, based on sensing information, and robot behaviour\nselection, based on decision-making mechanisms, is of paramount importance.\nHowever, most approaches to date consist of deterministic associations between\nthe recognised activities and the robot behaviours, neglecting the uncertainty\ninherent to sequential predictions in real-time applications. In this paper, we\naddress this gap by presenting a neurorobotics approach based on computational\nmodels that resemble neurophysiological aspects of living beings. This\nneurorobotics approach was compared to a non-bioinspired, heuristics-based\napproach. To evaluate both approaches, a robot simulation is developed, in\nwhich a mobile robot has to accomplish tasks according to the activity being\nperformed by the inhabitant of an intelligent home. The outcomes of each\napproach were evaluated according to the number of correct outcomes provided by\nthe robot. Results revealed that the neurorobotics approach is advantageous,\nespecially considering the computational models based on more complex animals.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 01:25:58 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Ranieri", "Caetano M.", ""], ["Moioli", "Renan C.", ""], ["Vargas", "Patricia A.", ""], ["Romero", "Roseli A. F.", ""]]}, {"id": "2107.12544", "submitter": "Pedro Tsividis", "authors": "Pedro A. Tsividis, Joao Loula, Jake Burga, Nathan Foss, Andres\n  Campero, Thomas Pouncy, Samuel J. Gershman, Joshua B. Tenenbaum", "title": "Human-Level Reinforcement Learning through Theory-Based Modeling,\n  Exploration, and Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) studies how an agent comes to achieve reward in\nan environment through interactions over time. Recent advances in machine RL\nhave surpassed human expertise at the world's oldest board games and many\nclassic video games, but they require vast quantities of experience to learn\nsuccessfully -- none of today's algorithms account for the human ability to\nlearn so many different tasks, so quickly. Here we propose a new approach to\nthis challenge based on a particularly strong form of model-based RL which we\ncall Theory-Based Reinforcement Learning, because it uses human-like intuitive\ntheories -- rich, abstract, causal models of physical objects, intentional\nagents, and their interactions -- to explore and model an environment, and plan\neffectively to achieve task goals. We instantiate the approach in a video game\nplaying agent called EMPA (the Exploring, Modeling, and Planning Agent), which\nperforms Bayesian inference to learn probabilistic generative models expressed\nas programs for a game-engine simulator, and runs internal simulations over\nthese models to support efficient object-based, relational exploration and\nheuristic planning. EMPA closely matches human learning efficiency on a suite\nof 90 challenging Atari-style video games, learning new games in just minutes\nof game play and generalizing robustly to new game situations and new levels.\nThe model also captures fine-grained structure in people's exploration\ntrajectories and learning dynamics. Its design and behavior suggest a way\nforward for building more general human-like AI systems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 01:38:13 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Tsividis", "Pedro A.", ""], ["Loula", "Joao", ""], ["Burga", "Jake", ""], ["Foss", "Nathan", ""], ["Campero", "Andres", ""], ["Pouncy", "Thomas", ""], ["Gershman", "Samuel J.", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "2107.12547", "submitter": "Art Owen", "authors": "Christopher R. Hoyt and Art B. Owen", "title": "Probing neural networks with t-SNE, class-specific projections and a\n  guided tour", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We use graphical methods to probe neural nets that classify images. Plots of\nt-SNE outputs at successive layers in a network reveal increasingly organized\narrangement of the data points. They can also reveal how a network can diminish\nor even forget about within-class structure as the data proceeds through\nlayers. We use class-specific analogues of principal components to visualize\nhow succeeding layers separate the classes. These allow us to sort images from\na given class from most typical to least typical (in the data) and they also\nserve as very useful projection coordinates for data visualization. We find\nthem especially useful when defining versions guided tours for animated data\nvisualization.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 01:42:07 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Hoyt", "Christopher R.", ""], ["Owen", "Art B.", ""]]}, {"id": "2107.12571", "submitter": "Denis Gudovskiy", "authors": "Denis Gudovskiy, Shun Ishizaka, Kazuki Kozuka", "title": "CFLOW-AD: Real-Time Unsupervised Anomaly Detection with Localization via\n  Conditional Normalizing Flows", "comments": "Accepted to WACV 2022. Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised anomaly detection with localization has many practical\napplications when labeling is infeasible and, moreover, when anomaly examples\nare completely missing in the train data. While recently proposed models for\nsuch data setup achieve high accuracy metrics, their complexity is a limiting\nfactor for real-time processing. In this paper, we propose a real-time model\nand analytically derive its relationship to prior methods. Our CFLOW-AD model\nis based on a conditional normalizing flow framework adopted for anomaly\ndetection with localization. In particular, CFLOW-AD consists of a\ndiscriminatively pretrained encoder followed by a multi-scale generative\ndecoders where the latter explicitly estimate likelihood of the encoded\nfeatures. Our approach results in a computationally and memory-efficient model:\nCFLOW-AD is faster and smaller by a factor of 10x than prior state-of-the-art\nwith the same input setting. Our experiments on the MVTec dataset show that\nCFLOW-AD outperforms previous methods by 0.36% AUROC in detection task, by\n1.12% AUROC and 2.5% AUPRO in localization task, respectively. We open-source\nour code with fully reproducible experiments.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 03:10:38 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Gudovskiy", "Denis", ""], ["Ishizaka", "Shun", ""], ["Kozuka", "Kazuki", ""]]}, {"id": "2107.12576", "submitter": "Xovee Xu", "authors": "Xovee Xu, Fan Zhou, Kunpeng Zhang, Siyuan Liu", "title": "CCGL: Contrastive Cascade Graph Learning", "comments": "Submitted to IEEE, including 14 pages, 7 figures, and 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning, while prevalent for information cascade modeling, often\nrequires abundant labeled data in training, and the trained model is not easy\nto generalize across tasks and datasets. Semi-supervised learning facilitates\nunlabeled data for cascade understanding in pre-training. It often learns\nfine-grained feature-level representations, which can easily result in\noverfitting for downstream tasks. Recently, contrastive self-supervised\nlearning is designed to alleviate these two fundamental issues in linguistic\nand visual tasks. However, its direct applicability for cascade modeling,\nespecially graph cascade related tasks, remains underexplored. In this work, we\npresent Contrastive Cascade Graph Learning (CCGL), a novel framework for\ncascade graph representation learning in a contrastive, self-supervised, and\ntask-agnostic way. In particular, CCGL first designs an effective data\naugmentation strategy to capture variation and uncertainty. Second, it learns a\ngeneric model for graph cascade tasks via self-supervised contrastive\npre-training using both unlabeled and labeled data. Third, CCGL learns a\ntask-specific cascade model via fine-tuning using labeled data. Finally, to\nmake the model transferable across datasets and cascade applications, CCGL\nfurther enhances the model via distillation using a teacher-student\narchitecture. We demonstrate that CCGL significantly outperforms its supervised\nand semi-supervised counterpartsfor several downstream tasks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 03:37:50 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Xu", "Xovee", ""], ["Zhou", "Fan", ""], ["Zhang", "Kunpeng", ""], ["Liu", "Siyuan", ""]]}, {"id": "2107.12578", "submitter": "Jinyu Guo", "authors": "Jinyu Guo, Kai Shuang, Jijie Li and Zihan Wang", "title": "Dual Slot Selector via Local Reliability Verification for Dialogue State\n  Tracking", "comments": "Accepted by ACL-IJCNLP 2021 main conference (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of dialogue state tracking (DST) is to predict the current dialogue\nstate given all previous dialogue contexts. Existing approaches generally\npredict the dialogue state at every turn from scratch. However, the\noverwhelming majority of the slots in each turn should simply inherit the slot\nvalues from the previous turn. Therefore, the mechanism of treating slots\nequally in each turn not only is inefficient but also may lead to additional\nerrors because of the redundant slot value generation. To address this problem,\nwe devise the two-stage DSS-DST which consists of the Dual Slot Selector based\non the current turn dialogue, and the Slot Value Generator based on the\ndialogue history. The Dual Slot Selector determines each slot whether to update\nslot value or to inherit the slot value from the previous turn from two\naspects: (1) if there is a strong relationship between it and the current turn\ndialogue utterances; (2) if a slot value with high reliability can be obtained\nfor it through the current turn dialogue. The slots selected to be updated are\npermitted to enter the Slot Value Generator to update values by a hybrid\nmethod, while the other slots directly inherit the values from the previous\nturn. Empirical results show that our method achieves 56.93%, 60.73%, and\n58.04% joint accuracy on MultiWOZ 2.0, MultiWOZ 2.1, and MultiWOZ 2.2 datasets\nrespectively and achieves a new state-of-the-art performance with significant\nimprovements.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 03:40:05 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Guo", "Jinyu", ""], ["Shuang", "Kai", ""], ["Li", "Jijie", ""], ["Wang", "Zihan", ""]]}, {"id": "2107.12580", "submitter": "Maithra Raghu", "authors": "Chiyuan Zhang, Maithra Raghu, Jon Kleinberg, Samy Bengio", "title": "Pointer Value Retrieval: A new benchmark for understanding the limits of\n  neural network generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The successes of deep learning critically rely on the ability of neural\nnetworks to output meaningful predictions on unseen data -- generalization. Yet\ndespite its criticality, there remain fundamental open questions on how neural\nnetworks generalize. How much do neural networks rely on memorization -- seeing\nhighly similar training examples -- and how much are they capable of\nhuman-intelligence styled reasoning -- identifying abstract rules underlying\nthe data? In this paper we introduce a novel benchmark, Pointer Value Retrieval\n(PVR) tasks, that explore the limits of neural network generalization. While\nPVR tasks can consist of visual as well as symbolic inputs, each with varying\nlevels of difficulty, they all have a simple underlying rule. One part of the\nPVR task input acts as a pointer, giving the location of a different part of\nthe input, which forms the value (and output). We demonstrate that this task\nstructure provides a rich testbed for understanding generalization, with our\nempirical study showing large variations in neural network performance based on\ndataset size, task complexity and model architecture. The interaction of\nposition, values and the pointer rule also allow the development of nuanced\ntests of generalization, by introducing distribution shift and increasing\nfunctional complexity. These reveal both subtle failures and surprising\nsuccesses, suggesting many promising directions of exploration on this\nbenchmark.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 03:50:31 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zhang", "Chiyuan", ""], ["Raghu", "Maithra", ""], ["Kleinberg", "Jon", ""], ["Bengio", "Samy", ""]]}, {"id": "2107.12585", "submitter": "Song Tang", "authors": "Song Tang, Yan Yang, Zhiyuan Ma, Norman Hendrich, Fanyu Zeng, Shuzhi\n  Sam Ge, Changshui Zhang, Jianwei Zhang", "title": "Nearest Neighborhood-Based Deep Clustering for Source Data-absent\n  Unsupervised Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the classic setting of unsupervised domain adaptation (UDA), the labeled\nsource data are available in the training phase. However, in many real-world\nscenarios, owing to some reasons such as privacy protection and information\nsecurity, the source data is inaccessible, and only a model trained on the\nsource domain is available. This paper proposes a novel deep clustering method\nfor this challenging task. Aiming at the dynamical clustering at feature-level,\nwe introduce extra constraints hidden in the geometric structure between data\nto assist the process. Concretely, we propose a geometry-based constraint,\nnamed semantic consistency on the nearest neighborhood (SCNNH), and use it to\nencourage robust clustering. To reach this goal, we construct the nearest\nneighborhood for every target data and take it as the fundamental clustering\nunit by building our objective on the geometry. Also, we develop a more\nSCNNH-compliant structure with an additional semantic credibility constraint,\nnamed semantic hyper-nearest neighborhood (SHNNH). After that, we extend our\nmethod to this new geometry. Extensive experiments on three challenging UDA\ndatasets indicate that our method achieves state-of-the-art results. The\nproposed method has significant improvement on all datasets (as we adopt SHNNH,\nthe average accuracy increases by over 3.0\\% on the large-scaled dataset). Code\nis available at https://github.com/tntek/N2DCX.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 04:13:59 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Tang", "Song", ""], ["Yang", "Yan", ""], ["Ma", "Zhiyuan", ""], ["Hendrich", "Norman", ""], ["Zeng", "Fanyu", ""], ["Ge", "Shuzhi Sam", ""], ["Zhang", "Changshui", ""], ["Zhang", "Jianwei", ""]]}, {"id": "2107.12591", "submitter": "Hai Wang", "authors": "Hoifung Poon, Hai Wang, Hunter Lang", "title": "Combining Probabilistic Logic and Deep Learning for Self-Supervised\n  Learning", "comments": "Book chapter. arXiv admin note: substantial text overlap with\n  arXiv:2012.12474, arXiv:1808.08485, arXiv:2008.12878", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning has proven effective for various application tasks, but its\napplicability is limited by the reliance on annotated examples. Self-supervised\nlearning has emerged as a promising direction to alleviate the supervision\nbottleneck, but existing work focuses on leveraging co-occurrences in unlabeled\ndata for task-agnostic representation learning, as exemplified by masked\nlanguage model pretraining. In this chapter, we explore task-specific\nself-supervision, which leverages domain knowledge to automatically annotate\nnoisy training examples for end applications, either by introducing labeling\nfunctions for annotating individual instances, or by imposing constraints over\ninterdependent label decisions. We first present deep probabilistic logic(DPL),\nwhich offers a unifying framework for task-specific self-supervision by\ncomposing probabilistic logic with deep learning. DPL represents unknown labels\nas latent variables and incorporates diverse self-supervision using\nprobabilistic logic to train a deep neural network end-to-end using variational\nEM. Next, we present self-supervised self-supervision(S4), which adds to DPL\nthe capability to learn new self-supervision automatically. Starting from an\ninitial seed self-supervision, S4 iteratively uses the deep neural network to\npropose new self supervision. These are either added directly (a form of\nstructured self-training) or verified by a human expert (as in feature-based\nactive learning). Experiments on real-world applications such as biomedical\nmachine reading and various text classification tasks show that task-specific\nself-supervision can effectively leverage domain expertise and often match the\naccuracy of supervised methods with a tiny fraction of human effort.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 04:25:56 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Poon", "Hoifung", ""], ["Wang", "Hai", ""], ["Lang", "Hunter", ""]]}, {"id": "2107.12595", "submitter": "Daping Zhang", "authors": "Daping Zhang, Xin Chen, Yujia Zhang, Shihan Qin", "title": "Template-based Chatbot for Agriculture Related FAQs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agriculture is the fundamental industry of the society, which is the basis of\nfood supply and an important source of employment and GDP increase. However,\nthe insufficient expert can not fulfill the demand of farmers. To address this\nproblem, we design a chatbot to answer frequently asked questions in the\nAgriculture field. Template-based questions will be answered by AIML while LSA\nis used for other service-based questions. This chatbot will assist farmers by\ndealing with industry problems conveniently and efficiently.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 04:46:29 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zhang", "Daping", ""], ["Chen", "Xin", ""], ["Zhang", "Yujia", ""], ["Qin", "Shihan", ""]]}, {"id": "2107.12598", "submitter": "Daping Zhang", "authors": "Daping Zhang, Hongyu Yang, Jiayu Cao", "title": "Identify Apple Leaf Diseases Using Deep Learning Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agriculture is an essential industry in the both society and economy of a\ncountry. However, the pests and diseases cause a great amount of reduction in\nagricultural production while there is not sufficient guidance for farmers to\navoid this disaster. To address this problem, we apply CNNs to plant disease\nrecognition by building a classification model. Within the dataset of 3,642\nimages of apple leaves, We use a pre-trained image classification model\nRestnet34 based on a Convolutional neural network (CNN) with the Fastai\nframework in order to save the training time. Overall, the accuracy of\nclassification is 93.765%.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 04:55:16 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zhang", "Daping", ""], ["Yang", "Hongyu", ""], ["Cao", "Jiayu", ""]]}, {"id": "2107.12603", "submitter": "Ming Liu Dr", "authors": "Ming Liu, Stella Ho, Mengqi Wang, Longxiang Gao, Yuan Jin, He Zhang", "title": "Federated Learning Meets Natural Language Processing: A Survey", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated Learning aims to learn machine learning models from multiple\ndecentralized edge devices (e.g. mobiles) or servers without sacrificing local\ndata privacy. Recent Natural Language Processing techniques rely on deep\nlearning and large pre-trained language models. However, both big deep neural\nand language models are trained with huge amounts of data which often lies on\nthe server side. Since text data is widely originated from end users, in this\nwork, we look into recent NLP models and techniques which use federated\nlearning as the learning framework. Our survey discusses major challenges in\nfederated natural language processing, including the algorithm challenges,\nsystem challenges as well as the privacy issues. We also provide a critical\nreview of the existing Federated NLP evaluation methods and tools. Finally, we\nhighlight the current research gaps and future directions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 05:07:48 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Liu", "Ming", ""], ["Ho", "Stella", ""], ["Wang", "Mengqi", ""], ["Gao", "Longxiang", ""], ["Jin", "Yuan", ""], ["Zhang", "He", ""]]}, {"id": "2107.12626", "submitter": "Jindong Wang", "authors": "Yuxin Zhang, Yiqiang Chen, Jindong Wang, Zhiwen Pan", "title": "Unsupervised Deep Anomaly Detection for Multi-Sensor Time-Series Signals", "comments": "Accepted to IEEE Transactions on Knowledge and Data Engineering (IEEE\n  TKDE) as a regular paper; 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, multi-sensor technologies are applied in many fields, e.g., Health\nCare (HC), Human Activity Recognition (HAR), and Industrial Control System\n(ICS). These sensors can generate a substantial amount of multivariate\ntime-series data. Unsupervised anomaly detection on multi-sensor time-series\ndata has been proven critical in machine learning researches. The key challenge\nis to discover generalized normal patterns by capturing spatial-temporal\ncorrelation in multi-sensor data. Beyond this challenge, the noisy data is\noften intertwined with the training data, which is likely to mislead the model\nby making it hard to distinguish between the normal, abnormal, and noisy data.\nFew of previous researches can jointly address these two challenges. In this\npaper, we propose a novel deep learning-based anomaly detection algorithm\ncalled Deep Convolutional Autoencoding Memory network (CAE-M). We first build a\nDeep Convolutional Autoencoder to characterize spatial dependence of\nmulti-sensor data with a Maximum Mean Discrepancy (MMD) to better distinguish\nbetween the noisy, normal, and abnormal data. Then, we construct a Memory\nNetwork consisting of linear (Autoregressive Model) and non-linear predictions\n(Bidirectional LSTM with Attention) to capture temporal dependence from\ntime-series data. Finally, CAE-M jointly optimizes these two subnetworks. We\nempirically compare the proposed approach with several state-of-the-art anomaly\ndetection methods on HAR and HC datasets. Experimental results demonstrate that\nour proposed model outperforms these existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 06:48:20 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zhang", "Yuxin", ""], ["Chen", "Yiqiang", ""], ["Wang", "Jindong", ""], ["Pan", "Zhiwen", ""]]}, {"id": "2107.12708", "submitter": "Anna Rogers", "authors": "Anna Rogers, Matt Gardner, and Isabelle Augenstein", "title": "QA Dataset Explosion: A Taxonomy of NLP Resources for Question Answering\n  and Reading Comprehension", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alongside huge volumes of research on deep learning models in NLP in the\nrecent years, there has been also much work on benchmark datasets needed to\ntrack modeling progress. Question answering and reading comprehension have been\nparticularly prolific in this regard, with over 80 new datasets appearing in\nthe past two years. This study is the largest survey of the field to date. We\nprovide an overview of the various formats and domains of the current\nresources, highlighting the current lacunae for future work. We further discuss\nthe current classifications of ``reasoning types\" in question answering and\npropose a new taxonomy. We also discuss the implications of over-focusing on\nEnglish, and survey the current monolingual resources for other languages and\nmultilingual resources. The study is aimed at both practitioners looking for\npointers to the wealth of existing data, and at researchers working on new\nresources.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 10:09:13 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Rogers", "Anna", ""], ["Gardner", "Matt", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2107.12711", "submitter": "Michiel Van Der Meer", "authors": "Ruth Shortall, Anatol Itten, Michiel van der Meer, Pradeep K.\n  Murukannaiah, Catholijn M. Jonker", "title": "Inclusion, equality and bias in designing online mass deliberative\n  platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Designers of online deliberative platforms aim to counter the degrading\nquality of online debates and eliminate online discrimination based on class,\nrace or gender. Support technologies such as machine learning and natural\nlanguage processing open avenues for widening the circle of people involved in\ndeliberation, moving from small groups to ``crowd'' scale. Some design features\nof large-scale online discussion systems allow larger numbers of people to\ndiscuss shared problems, enhance critical thinking, and formulate solutions.\nHowever, scaling up deliberation is challenging. We review the\ntransdisciplinary literature on the design of digital mass-deliberation\nplatforms and examine the commonly featured design aspects (e.g., argumentation\nsupport, automated facilitation, and gamification). We find that the literature\nis heavily focused on developing technical fixes for scaling up deliberation,\nwith a heavy western influence on design and test users skew young and highly\neducated. Contrastingly, there is a distinct lack of discussion on the nature\nof the design process, the inclusion of stakeholders and issues relating to\ninclusion, which may unwittingly perpetuate bias. Another tendency of\ndeliberation platforms is to nudge participants to desired forms of\nargumentation, and simplifying definitions of good and bad arguments to fit\nalgorithmic purposes. Few studies bridge disciplines between deliberative\ntheory, design and engineering. As a result, scaling up deliberation will\nlikely advance in separate systemic siloes. We make design and process\nrecommendations to correct this course and suggest avenues for future research.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 10:13:57 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Shortall", "Ruth", ""], ["Itten", "Anatol", ""], ["van der Meer", "Michiel", ""], ["Murukannaiah", "Pradeep K.", ""], ["Jonker", "Catholijn M.", ""]]}, {"id": "2107.12806", "submitter": "Sunder Ali Khowaja", "authors": "Sunder Ali Khowaja, Kapal Dev, Nawab Muhammad Faseeh Qureshi, Parus\n  Khuwaja, Luca Foschini", "title": "Towards Industrial Private AI: A two-tier framework for data and model\n  security", "comments": "9 pages, 4 figures, 1 table, Magazine article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With the advances in 5G and IoT devices, the industries are vastly adopting\nartificial intelligence (AI) techniques for improving classification and\nprediction-based services. However, the use of AI also raises concerns\nregarding data privacy and security that can be misused or leaked. Private AI\nwas recently coined to address the data security issue by combining AI with\nencryption techniques but existing studies have shown that model inversion\nattacks can be used to reverse engineer the images from model parameters. In\nthis regard, we propose a federated learning and encryption-based private\n(FLEP) AI framework that provides two-tier security for data and model\nparameters in an IIoT environment. We proposed a three-layer encryption method\nfor data security and provided a hypothetical method to secure the model\nparameters. Experimental results show that the proposed method achieves better\nencryption quality at the expense of slightly increased execution time. We also\nhighlighted several open issues and challenges regarding the FLEP AI\nframework's realization.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 13:28:07 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Khowaja", "Sunder Ali", ""], ["Dev", "Kapal", ""], ["Qureshi", "Nawab Muhammad Faseeh", ""], ["Khuwaja", "Parus", ""], ["Foschini", "Luca", ""]]}, {"id": "2107.12807", "submitter": "Supun Kamburugamuve", "authors": "Supun Kamburugamuve, Chathura Widanage, Niranda Perera, Vibhatha\n  Abeykoon, Ahmet Uyar, Thejaka Amila Kanewala, Gregor von Laszewski, and\n  Geoffrey Fox", "title": "HPTMT: Operator-Based Architecture for ScalableHigh-Performance\n  Data-Intensive Frameworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data-intensive applications impact many domains, and their steadily\nincreasing size and complexity demands high-performance, highly usable\nenvironments. We integrate a set of ideas developed in various data science and\ndata engineering frameworks. They employ a set of operators on specific data\nabstractions that include vectors, matrices, tensors, graphs, and tables. Our\nkey concepts are inspired from systems like MPI, HPF (High-Performance\nFortran), NumPy, Pandas, Spark, Modin, PyTorch, TensorFlow, RAPIDS(NVIDIA), and\nOneAPI (Intel). Further, it is crucial to support different languages in\neveryday use in the Big Data arena, including Python, R, C++, and Java. We note\nthe importance of Apache Arrow and Parquet for enabling language agnostic high\nperformance and interoperability. In this paper, we propose High-Performance\nTensors, Matrices and Tables (HPTMT), an operator-based architecture for\ndata-intensive applications, and identify the fundamental principles needed for\nperformance and usability success. We illustrate these principles by a\ndiscussion of examples using our software environments, Cylon and Twister2 that\nembody HPTMT.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 13:28:34 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kamburugamuve", "Supun", ""], ["Widanage", "Chathura", ""], ["Perera", "Niranda", ""], ["Abeykoon", "Vibhatha", ""], ["Uyar", "Ahmet", ""], ["Kanewala", "Thejaka Amila", ""], ["von Laszewski", "Gregor", ""], ["Fox", "Geoffrey", ""]]}, {"id": "2107.12808", "submitter": "Wojciech Czarnecki", "authors": "Open-Ended Learning Team, Adam Stooke, Anuj Mahajan, Catarina Barros,\n  Charlie Deck, Jakob Bauer, Jakub Sygnowski, Maja Trebacz, Max Jaderberg,\n  Michael Mathieu, Nat McAleese, Nathalie Bradley-Schmieg, Nathaniel Wong,\n  Nicolas Porcel, Roberta Raileanu, Steph Hughes-Fitt, Valentin Dalibard,\n  Wojciech Marian Czarnecki", "title": "Open-Ended Learning Leads to Generally Capable Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we create agents that can perform well beyond a single,\nindividual task, that exhibit much wider generalisation of behaviour to a\nmassive, rich space of challenges. We define a universe of tasks within an\nenvironment domain and demonstrate the ability to train agents that are\ngenerally capable across this vast space and beyond. The environment is\nnatively multi-agent, spanning the continuum of competitive, cooperative, and\nindependent games, which are situated within procedurally generated physical 3D\nworlds. The resulting space is exceptionally diverse in terms of the challenges\nposed to agents, and as such, even measuring the learning progress of an agent\nis an open research problem. We propose an iterative notion of improvement\nbetween successive generations of agents, rather than seeking to maximise a\nsingular objective, allowing us to quantify progress despite tasks being\nincomparable in terms of achievable rewards. We show that through constructing\nan open-ended learning process, which dynamically changes the training task\ndistributions and training objectives such that the agent never stops learning,\nwe achieve consistent learning of new behaviours. The resulting agent is able\nto score reward in every one of our humanly solvable evaluation levels, with\nbehaviour generalising to many held-out points in the universe of tasks.\nExamples of this zero-shot generalisation include good performance on Hide and\nSeek, Capture the Flag, and Tag. Through analysis and hand-authored probe tasks\nwe characterise the behaviour of our agent, and find interesting emergent\nheuristic behaviours such as trial-and-error experimentation, simple tool use,\noption switching, and cooperation. Finally, we demonstrate that the general\ncapabilities of this agent could unlock larger scale transfer of behaviour\nthrough cheap finetuning.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 13:30:07 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Ended Learning Team", "", ""], ["Stooke", "Adam", ""], ["Mahajan", "Anuj", ""], ["Barros", "Catarina", ""], ["Deck", "Charlie", ""], ["Bauer", "Jakob", ""], ["Sygnowski", "Jakub", ""], ["Trebacz", "Maja", ""], ["Jaderberg", "Max", ""], ["Mathieu", "Michael", ""], ["McAleese", "Nat", ""], ["Bradley-Schmieg", "Nathalie", ""], ["Wong", "Nathaniel", ""], ["Porcel", "Nicolas", ""], ["Raileanu", "Roberta", ""], ["Hughes-Fitt", "Steph", ""], ["Dalibard", "Valentin", ""], ["Czarnecki", "Wojciech Marian", ""]]}, {"id": "2107.12826", "submitter": "Patrik Joslin Kenfack", "authors": "Patrik Joslin Kenfack, Adil Mehmood Khan, Rasheed Hussain, S.M. Ahsan\n  Kazmi,", "title": "Adversarial Stacked Auto-Encoders for Fair Representation Learning", "comments": "ICML2021 ML4data Workshop Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training machine learning models with the only accuracy as a final goal may\npromote prejudices and discriminatory behaviors embedded in the data. One\nsolution is to learn latent representations that fulfill specific fairness\nmetrics. Different types of learning methods are employed to map data into the\nfair representational space. The main purpose is to learn a latent\nrepresentation of data that scores well on a fairness metric while maintaining\nthe usability for the downstream task. In this paper, we propose a new fair\nrepresentation learning approach that leverages different levels of\nrepresentation of data to tighten the fairness bounds of the learned\nrepresentation. Our results show that stacking different auto-encoders and\nenforcing fairness at different latent spaces result in an improvement of\nfairness compared to other existing approaches.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 13:49:18 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kenfack", "Patrik Joslin", ""], ["Khan", "Adil Mehmood", ""], ["Hussain", "Rasheed", ""], ["Kazmi", "S. M. Ahsan", ""]]}, {"id": "2107.12838", "submitter": "Fuad Noman", "authors": "Fuad Noman, Chee-Ming Ting, Hakmook Kang, Raphael C.-W. Phan, Brian D.\n  Boyd, Warren D. Taylor, and Hernando Ombao", "title": "Graph Autoencoders for Embedding Learning in Brain Networks and Major\n  Depressive Disorder Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Brain functional connectivity (FC) reveals biomarkers for identification of\nvarious neuropsychiatric disorders. Recent application of deep neural networks\n(DNNs) to connectome-based classification mostly relies on traditional\nconvolutional neural networks using input connectivity matrices on a regular\nEuclidean grid. We propose a graph deep learning framework to incorporate the\nnon-Euclidean information about graph structure for classifying functional\nmagnetic resonance imaging (fMRI)- derived brain networks in major depressive\ndisorder (MDD). We design a novel graph autoencoder (GAE) architecture based on\nthe graph convolutional networks (GCNs) to embed the topological structure and\nnode content of large-sized fMRI networks into low-dimensional latent\nrepresentations. In network construction, we employ the Ledoit-Wolf (LDW)\nshrinkage method to estimate the high-dimensional FC metrics efficiently from\nfMRI data. We consider both supervised and unsupervised approaches for the\ngraph embedded learning. The learned embeddings are then used as feature inputs\nfor a deep fully-connected neural network (FCNN) to discriminate MDD from\nhealthy controls. Evaluated on a resting-state fMRI MDD dataset with 43\nsubjects, results show that the proposed GAE-FCNN model significantly\noutperforms several state-of-the-art DNN methods for brain connectome\nclassification, achieving accuracy of 72.50% using the LDW-FC metrics as node\nfeatures. The graph embeddings of fMRI FC networks learned by the GAE also\nreveal apparent group differences between MDD and HC. Our new framework\ndemonstrates feasibility of learning graph embeddings on brain networks to\nprovide discriminative information for diagnosis of brain disorders.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 14:12:39 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Noman", "Fuad", ""], ["Ting", "Chee-Ming", ""], ["Kang", "Hakmook", ""], ["Phan", "Raphael C. -W.", ""], ["Boyd", "Brian D.", ""], ["Taylor", "Warren D.", ""], ["Ombao", "Hernando", ""]]}, {"id": "2107.12845", "submitter": "Antonio Lieto", "authors": "Agnese Augello, Giuseppe Citt\\`a, Manuel Gentile, Antonio Lieto", "title": "A Storytelling Robot managing Persuasive and Ethical Stances via ACT-R:\n  an Exploratory Study", "comments": "20 pages, 7 figures", "journal-ref": "International Journal of Social Robotics, 2021", "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a storytelling robot, controlled via the ACT-R cognitive\narchitecture, able to adopt different persuasive techniques and ethical stances\nwhile conversing about some topics concerning COVID-19. The main contribution\nof the paper consists in the proposal of a needs-driven model that guides and\nevaluates, during the dialogue, the use (if any) of persuasive techniques\navailable in the agent procedural memory. The portfolio of persuasive\ntechniques tested in such a model ranges from the use of storytelling, to\nframing techniques and rhetorical-based arguments. To the best of our\nknowledge, this represents the first attempt of building a persuasive agent\nable to integrate a mix of explicitly grounded cognitive assumptions about\ndialogue management, storytelling and persuasive techniques as well as ethical\nattitudes. The paper presents the results of an exploratory evaluation of the\nsystem on 63 participants\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 14:27:58 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Augello", "Agnese", ""], ["Citt\u00e0", "Giuseppe", ""], ["Gentile", "Manuel", ""], ["Lieto", "Antonio", ""]]}, {"id": "2107.12851", "submitter": "Shiqi Zhang", "authors": "Hao Yang and Tavan Eftekhar and Chad Esselink and Yan Ding and Shiqi\n  Zhang", "title": "Task and Situation Structures for Service Agent Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Everyday tasks are characterized by their varieties and variations, and\nfrequently are not clearly specified to service agents. This paper presents a\ncomprehensive approach to enable a service agent to deal with everyday tasks in\nopen, uncontrolled environments. We introduce a generic structure for\nrepresenting tasks, and another structure for representing situations. Based on\nthe two newly introduced structures, we present a methodology of situation\nhandling that avoids hard-coding domain rules while improving the scalability\nof real-world task planning systems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 14:33:49 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Yang", "Hao", ""], ["Eftekhar", "Tavan", ""], ["Esselink", "Chad", ""], ["Ding", "Yan", ""], ["Zhang", "Shiqi", ""]]}, {"id": "2107.12855", "submitter": "Florian Jaeckle", "authors": "Florian Jaeckle and Jingyue Lu and M. Pawan Kumar", "title": "Neural Network Branch-and-Bound for Neural Network Verification", "comments": "arXiv admin note: substantial text overlap with arXiv:1912.01329", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many available formal verification methods have been shown to be instances of\na unified Branch-and-Bound (BaB) formulation. We propose a novel machine\nlearning framework that can be used for designing an effective branching\nstrategy as well as for computing better lower bounds. Specifically, we learn\ntwo graph neural networks (GNN) that both directly treat the network we want to\nverify as a graph input and perform forward-backward passes through the GNN\nlayers. We use one GNN to simulate the strong branching heuristic behaviour and\nanother to compute a feasible dual solution of the convex relaxation, thereby\nproviding a valid lower bound.\n  We provide a new verification dataset that is more challenging than those\nused in the literature, thereby providing an effective alternative for testing\nalgorithmic improvements for verification. Whilst using just one of the GNNs\nleads to a reduction in verification time, we get optimal performance when\ncombining the two GNN approaches. Our combined framework achieves a 50\\%\nreduction in both the number of branches and the time required for verification\non various convolutional networks when compared to several state-of-the-art\nverification methods. In addition, we show that our GNN models generalize well\nto harder properties on larger unseen networks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 14:42:57 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Jaeckle", "Florian", ""], ["Lu", "Jingyue", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "2107.12869", "submitter": "Quan Duong", "authors": "Quan Duong, Tan Tran, Duc-Thinh Pham, An Mai", "title": "A Simplified Framework for Air Route Clustering Based on ADS-B Data", "comments": null, "journal-ref": "2019 IEEE-RIVF International Conference on Computing and\n  Communication Technologies (RIVF)", "doi": "10.1109/RIVF.2019.8713685", "report-no": null, "categories": "physics.soc-ph cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The volume of flight traffic gets increasing over the time, which makes the\nstrategic traffic flow management become one of the challenging problems since\nit requires a lot of computational resources to model entire traffic data. On\nthe other hand, Automatic Dependent Surveillance - Broadcast (ADS-B) technology\nhas been considered as a promising data technology to provide both flight crews\nand ground control staff the necessary information safely and efficiently about\nthe position and velocity of the airplanes in a specific area. In the attempt\nto tackle this problem, we presented in this paper a simplified framework that\ncan support to detect the typical air routes between airports based on ADS-B\ndata. Specifically, the flight traffic will be classified into major groups\nbased on similarity measures, which helps to reduce the number of flight paths\nbetween airports. As a matter of fact, our framework can be taken into account\nto reduce practically the computational cost for air flow optimization and\nevaluate the operational performance. Finally, in order to illustrate the\npotential applications of our proposed framework, an experiment was performed\nusing ADS-B traffic flight data of three different pairs of airports. The\ndetected typical routes between each couple of airports show promising results\nby virtue of combining two indices for measuring the clustering performance and\nincorporating human judgment into the visual inspection.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 08:55:31 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Duong", "Quan", ""], ["Tran", "Tan", ""], ["Pham", "Duc-Thinh", ""], ["Mai", "An", ""]]}, {"id": "2107.12873", "submitter": "Ihsen Alouani", "authors": "Nicolas Fleury, Theo Dubrunquez and Ihsen Alouani", "title": "PDF-Malware: An Overview on Threats, Detection and Evasion Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent years, Portable Document Format, commonly known as PDF, has\nbecome a democratized standard for document exchange and dissemination. This\ntrend has been due to its characteristics such as its flexibility and\nportability across platforms. The widespread use of PDF has installed a false\nimpression of inherent safety among benign users. However, the characteristics\nof PDF motivated hackers to exploit various types of vulnerabilities, overcome\nsecurity safeguards, thereby making the PDF format one of the most efficient\nmalicious code attack vectors. Therefore, efficiently detecting malicious PDF\nfiles is crucial for information security. Several analysis techniques has been\nproposed in the literature, be it static or dynamic, to extract the main\nfeatures that allow the discrimination of malware files from benign ones. Since\nclassical analysis techniques may be limited in case of zero-days,\nmachine-learning based techniques have emerged recently as an automatic\nPDF-malware detection method that is able to generalize from a set of training\nsamples. These techniques are themselves facing the challenge of evasion\nattacks where a malicious PDF is transformed to look benign. In this work, we\ngive an overview on the PDF-malware detection problem. We give a perspective on\nthe new challenges and emerging solutions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 15:15:20 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Fleury", "Nicolas", ""], ["Dubrunquez", "Theo", ""], ["Alouani", "Ihsen", ""]]}, {"id": "2107.12877", "submitter": "Anni-Yasmin Turhan", "authors": "Franz Baader, Patrick Koopmann, Friedrich Michel, Anni-Yasmin Turhan,\n  Benjamin Zarrie{\\ss}", "title": "Efficient TBox Reasoning with Value Restrictions using the\n  $\\mathcal{FL}_{o}$wer reasoner", "comments": "This paper is under consideration in Theory and Practice of Logic\n  Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inexpressive Description Logic (DL) $\\mathcal{FL}_0$, which has\nconjunction and value restriction as its only concept constructors, had fallen\ninto disrepute when it turned out that reasoning in $\\mathcal{FL}_0$ w.r.t.\ngeneral TBoxes is ExpTime-complete, i.e., as hard as in the considerably more\nexpressive logic $\\mathcal{ALC}$. In this paper, we rehabilitate\n$\\mathcal{FL}_0$ by presenting a dedicated subsumption algorithm for\n$\\mathcal{FL}_0$, which is much simpler than the tableau-based algorithms\nemployed by highly optimized DL reasoners. Our experiments show that the\nperformance of our novel algorithm, as prototypically implemented in our\n$\\mathcal{FL}_o$wer reasoner, compares very well with that of the highly\noptimized reasoners. $\\mathcal{FL}_o$wer can also deal with ontologies written\nin the extension $\\mathcal{FL}_{\\bot}$ of $\\mathcal{FL}_0$ with the top and the\nbottom concept by employing a polynomial-time reduction, shown in this paper,\nwhich eliminates top and bottom. We also investigate the complexity of\nreasoning in DLs related to the Horn-fragments of $\\mathcal{FL}_0$ and\n$\\mathcal{FL}_{\\bot}$.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 15:20:53 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Baader", "Franz", ""], ["Koopmann", "Patrick", ""], ["Michel", "Friedrich", ""], ["Turhan", "Anni-Yasmin", ""], ["Zarrie\u00df", "Benjamin", ""]]}, {"id": "2107.12895", "submitter": "Roman Klinger", "authors": "Felix Casel and Amelie Heindl and Roman Klinger", "title": "Emotion Recognition under Consideration of the Emotion Component Process\n  Model", "comments": "accepted at KONVENS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Emotion classification in text is typically performed with neural network\nmodels which learn to associate linguistic units with emotions. While this\noften leads to good predictive performance, it does only help to a limited\ndegree to understand how emotions are communicated in various domains. The\nemotion component process model (CPM) by Scherer (2005) is an interesting\napproach to explain emotion communication. It states that emotions are a\ncoordinated process of various subcomponents, in reaction to an event, namely\nthe subjective feeling, the cognitive appraisal, the expression, a\nphysiological bodily reaction, and a motivational action tendency. We\nhypothesize that these components are associated with linguistic realizations:\nan emotion can be expressed by describing a physiological bodily reaction (\"he\nwas trembling\"), or the expression (\"she smiled\"), etc. We annotate existing\nliterature and Twitter emotion corpora with emotion component classes and find\nthat emotions on Twitter are predominantly expressed by event descriptions or\nsubjective reports of the feeling, while in literature, authors prefer to\ndescribe what characters do, and leave the interpretation to the reader. We\nfurther include the CPM in a multitask learning model and find that this\nsupports the emotion categorization. The annotated corpora are available at\nhttps://www.ims.uni-stuttgart.de/data/emotion.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 15:53:25 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Casel", "Felix", ""], ["Heindl", "Amelie", ""], ["Klinger", "Roman", ""]]}, {"id": "2107.12917", "submitter": "Julian Stier", "authors": "Julian Stier, Harshil Darji, Michael Granitzer", "title": "Experiments on Properties of Hidden Structures of Sparse Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity in the structure of Neural Networks can lead to less energy\nconsumption, less memory usage, faster computation times on convenient\nhardware, and automated machine learning. If sparsity gives rise to certain\nkinds of structure, it can explain automatically obtained features during\nlearning.\n  We provide insights into experiments in which we show how sparsity can be\nachieved through prior initialization, pruning, and during learning, and answer\nquestions on the relationship between the structure of Neural Networks and\ntheir performance. This includes the first work of inducing priors from network\ntheory into Recurrent Neural Networks and an architectural performance\nprediction during a Neural Architecture Search. Within our experiments, we show\nhow magnitude class blinded pruning achieves 97.5% on MNIST with 80%\ncompression and re-training, which is 0.5 points more than without compression,\nthat magnitude class uniform pruning is significantly inferior to it and how a\ngenetic search enhanced with performance prediction achieves 82.4% on CIFAR10.\nFurther, performance prediction for Recurrent Networks learning the Reber\ngrammar shows an $R^2$ of up to 0.81 given only structural information.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 16:18:13 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Stier", "Julian", ""], ["Darji", "Harshil", ""], ["Granitzer", "Michael", ""]]}, {"id": "2107.12921", "submitter": "Menghan Hu", "authors": "Hang Liu, Menghan Hu, Yuzhen Chen, Qingli Li, Guangtao Zhai, Simon X.\n  Yang, Xiao-Ping Zhang, Xiaokang Yang", "title": "Angel's Girl for Blind Painters: an Efficient Painting Navigation System\n  Validated by Multimodal Evaluation Approach", "comments": "13 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For people who ardently love painting but unfortunately have visual\nimpairments, holding a paintbrush to create a work is a very difficult task.\nPeople in this special group are eager to pick up the paintbrush, like Leonardo\nda Vinci, to create and make full use of their own talents. Therefore, to\nmaximally bridge this gap, we propose a painting navigation system to assist\nblind people in painting and artistic creation. The proposed system is composed\nof cognitive system and guidance system. The system adopts drawing board\npositioning based on QR code, brush navigation based on target detection and\nbush real-time positioning. Meanwhile, this paper uses human-computer\ninteraction on the basis of voice and a simple but efficient position\ninformation coding rule. In addition, we design a criterion to efficiently\njudge whether the brush reaches the target or not. According to the\nexperimental results, the thermal curves extracted from the faces of testers\nshow that it is relatively well accepted by blindfolded and even blind testers.\nWith the prompt frequency of 1s, the painting navigation system performs best\nwith the completion degree of 89% with SD of 8.37% and overflow degree of 347%\nwith SD of 162.14%. Meanwhile, the excellent and good types of brush tip\ntrajectory account for 74%, and the relative movement distance is 4.21 with SD\nof 2.51. This work demonstrates that it is practicable for the blind people to\nfeel the world through the brush in their hands. In the future, we plan to\ndeploy Angle's Eyes on the phone to make it more portable. The demo video of\nthe proposed painting navigation system is available at:\nhttps://doi.org/10.6084/m9.figshare.9760004.v1.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 16:23:47 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Liu", "Hang", ""], ["Hu", "Menghan", ""], ["Chen", "Yuzhen", ""], ["Li", "Qingli", ""], ["Zhai", "Guangtao", ""], ["Yang", "Simon X.", ""], ["Zhang", "Xiao-Ping", ""], ["Yang", "Xiaokang", ""]]}, {"id": "2107.12931", "submitter": "Archit Sharma", "authors": "Archit Sharma, Abhishek Gupta, Sergey Levine, Karol Hausman, Chelsea\n  Finn", "title": "Persistent Reinforcement Learning via Subgoal Curricula", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) promises to enable autonomous acquisition of\ncomplex behaviors for diverse agents. However, the success of current\nreinforcement learning algorithms is predicated on an often under-emphasised\nrequirement -- each trial needs to start from a fixed initial state\ndistribution. Unfortunately, resetting the environment to its initial state\nafter each trial requires substantial amount of human supervision and extensive\ninstrumentation of the environment which defeats the purpose of autonomous\nreinforcement learning. In this work, we propose Value-accelerated Persistent\nReinforcement Learning (VaPRL), which generates a curriculum of initial states\nsuch that the agent can bootstrap on the success of easier tasks to efficiently\nlearn harder tasks. The agent also learns to reach the initial states proposed\nby the curriculum, minimizing the reliance on human interventions into the\nlearning. We observe that VaPRL reduces the interventions required by three\norders of magnitude compared to episodic RL while outperforming prior\nstate-of-the art methods for reset-free RL both in terms of sample efficiency\nand asymptotic performance on a variety of simulated robotics problems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 16:39:45 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Sharma", "Archit", ""], ["Gupta", "Abhishek", ""], ["Levine", "Sergey", ""], ["Hausman", "Karol", ""], ["Finn", "Chelsea", ""]]}, {"id": "2107.12942", "submitter": "Eric Goubault", "authors": "Nicola Bernini, Mikhail Bessa, R\\'emi Delmas, Arthur Gold, Eric\n  Goubault, Romain Pennec, Sylvie Putot, Fran\\c{c}ois Sillion", "title": "Reinforcement Learning with Formal Performance Metrics for Quadcopter\n  Attitude Control under Non-nominal Contexts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore the reinforcement learning approach to designing controllers by\nextensively discussing the case of a quadcopter attitude controller. We provide\nall details allowing to reproduce our approach, starting with a model of the\ndynamics of a crazyflie 2.0 under various nominal and non-nominal conditions,\nincluding partial motor failures and wind gusts. We develop a robust form of a\nsignal temporal logic to quantitatively evaluate the vehicle's behavior and\nmeasure the performance of controllers. The paper thoroughly describes the\nchoices in training algorithms, neural net architecture, hyperparameters,\nobservation space in view of the different performance metrics we have\nintroduced. We discuss the robustness of the obtained controllers, both to\npartial loss of power for one rotor and to wind gusts and finish by drawing\nconclusions on practical controller design by reinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 16:58:19 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Bernini", "Nicola", ""], ["Bessa", "Mikhail", ""], ["Delmas", "R\u00e9mi", ""], ["Gold", "Arthur", ""], ["Goubault", "Eric", ""], ["Pennec", "Romain", ""], ["Putot", "Sylvie", ""], ["Sillion", "Fran\u00e7ois", ""]]}, {"id": "2107.12977", "submitter": "Inga Str\\\"umke", "authors": "Inga Str\\\"umke, Marija Slavkovik, Vince I. Madai", "title": "The social dilemma in AI development and why we have to solve it", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the demand for ethical artificial intelligence (AI) systems increases,\nthe number of unethical uses of AI accelerates, even though there is no\nshortage of ethical guidelines. We argue that a main underlying cause for this\nis that AI developers face a social dilemma in AI development ethics,\npreventing the widespread adaptation of ethical best practices. We define the\nsocial dilemma for AI development and describe why the current crisis in AI\ndevelopment ethics cannot be solved without relieving AI developers of their\nsocial dilemma. We argue that AI development must be professionalised to\novercome the social dilemma, and discuss how medicine can be used as a template\nin this process.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:43:48 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 15:44:49 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Str\u00fcmke", "Inga", ""], ["Slavkovik", "Marija", ""], ["Madai", "Vince I.", ""]]}, {"id": "2107.12979", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge, Anil Seth, Christopher L Buckley", "title": "Predictive Coding: a Theoretical and Experimental Review", "comments": "27/07/21 initial upload", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive coding offers a potentially unifying account of cortical function\n-- postulating that the core function of the brain is to minimize prediction\nerrors with respect to a generative model of the world. The theory is closely\nrelated to the Bayesian brain framework and, over the last two decades, has\ngained substantial influence in the fields of theoretical and cognitive\nneuroscience. A large body of research has arisen based on both empirically\ntesting improved and extended theoretical and mathematical models of predictive\ncoding, as well as in evaluating their potential biological plausibility for\nimplementation in the brain and the concrete neurophysiological and\npsychological predictions made by the theory. Despite this enduring popularity,\nhowever, no comprehensive review of predictive coding theory, and especially of\nrecent developments in this field, exists. Here, we provide a comprehensive\nreview both of the core mathematical structure and logic of predictive coding,\nthus complementing recent tutorials in the literature. We also review a wide\nrange of classic and recent work within the framework, ranging from the\nneurobiologically realistic microcircuits that could implement predictive\ncoding, to the close relationship between predictive coding and the widely-used\nbackpropagation of error algorithm, as well as surveying the close\nrelationships between predictive coding and modern machine learning techniques.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:44:21 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Millidge", "Beren", ""], ["Seth", "Anil", ""], ["Buckley", "Christopher L", ""]]}, {"id": "2107.13031", "submitter": "Martin Andrews", "authors": "Vivek Kalyan and Sam Witteveen and Martin Andrews", "title": "Red Dragon AI at TextGraphs 2021 Shared Task: Multi-Hop Inference\n  Explanation Regeneration by Matching Expert Ratings", "comments": "Accepted paper for TextGraphs-15 workshop at NAACL 2021. (5 pages\n  including references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating explanations for answers to science questions is a challenging task\nthat requires multi-hop inference over a large set of fact sentences. This\nyear, to refocus the Textgraphs Shared Task on the problem of gathering\nrelevant statements (rather than solely finding a single 'correct path'), the\nWorldTree dataset was augmented with expert ratings of 'relevance' of\nstatements to each overall explanation. Our system, which achieved second place\non the Shared Task leaderboard, combines initial statement retrieval; language\nmodels trained to predict the relevance scores; and ensembling of a number of\nthe resulting rankings. Our code implementation is made available at\nhttps://github.com/mdda/worldtree_corpus/tree/textgraphs_2021\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 18:29:51 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Kalyan", "Vivek", ""], ["Witteveen", "Sam", ""], ["Andrews", "Martin", ""]]}, {"id": "2107.13054", "submitter": "Cameron R. Wolfe", "authors": "Cameron R. Wolfe and Keld T. Lundgaard", "title": "Exceeding the Limits of Visual-Linguistic Multi-Task Learning", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  By leveraging large amounts of product data collected across hundreds of live\ne-commerce websites, we construct 1000 unique classification tasks that share\nsimilarly-structured input data, comprised of both text and images. These\nclassification tasks focus on learning the product hierarchy of different\ne-commerce websites, causing many of them to be correlated. Adopting a\nmulti-modal transformer model, we solve these tasks in unison using multi-task\nlearning (MTL). Extensive experiments are presented over an initial 100-task\ndataset to reveal best practices for \"large-scale MTL\" (i.e., MTL with more\nthan 100 tasks). From these experiments, a final, unified methodology is\nderived, which is composed of both best practices and new proposals such as\nDyPa, a simple heuristic for automatically allocating task-specific parameters\nto tasks that could benefit from extra capacity. Using our large-scale MTL\nmethodology, we successfully train a single model across all 1000 tasks in our\ndataset while using minimal task specific parameters, thereby showing that it\nis possible to extend several orders of magnitude beyond current efforts in\nMTL.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 19:42:14 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Wolfe", "Cameron R.", ""], ["Lundgaard", "Keld T.", ""]]}, {"id": "2107.13074", "submitter": "Sebastiaan De Peuter", "authors": "Sebastiaan De Peuter (1), Antti Oulasvirta (2), Samuel Kaski (1 and 3)\n  ((1) Department of Computer Science, Aalto University, Finland, (2)\n  Department of Communications and Networking, Aalto University, Finland, (3)\n  Department of Computer Science, University of Manchester, UK)", "title": "Toward AI Assistants That Let Designers Design", "comments": "9 pages, 3 figures, submitted to IEEE Computer magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  AI for supporting designers needs to be rethought. It should aim to\ncooperate, not automate, by supporting and leveraging the creativity and\nproblem-solving of designers. The challenge for such AI is how to infer\ndesigners' goals and then help them without being needlessly disruptive. We\npresent AI-assisted design: a framework for creating such AI, built around\ngenerative user models which enable reasoning about designers' goals,\nreasoning, and capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 10:29:36 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["De Peuter", "Sebastiaan", "", "1 and 3"], ["Oulasvirta", "Antti", "", "1 and 3"], ["Kaski", "Samuel", "", "1 and 3"]]}, {"id": "2107.13078", "submitter": "Muhammad Ammad-Ud-Din Ph.D.", "authors": "Farwa K. Khan, Adrian Flanagan, Kuan E. Tan, Zareen Alamgir, Muhammad\n  Ammad-Ud-Din", "title": "A Payload Optimization Method for Federated Recommender Systems", "comments": "15 pages, 3 figures, 4 tables", "journal-ref": "Fifteenth ACM Conference on Recommender Systems (RecSys 2021),\n  September 27-October 1, 2021, Amsterdam, Netherlands. ACM, New York, NY, USA", "doi": "10.1145/3460231.3474257", "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We introduce the payload optimization method for federated recommender\nsystems (FRS). In federated learning (FL), the global model payload that is\nmoved between the server and users depends on the number of items to recommend.\nThe model payload grows when there is an increasing number of items. This\nbecomes challenging for an FRS if it is running in production mode. To tackle\nthe payload challenge, we formulated a multi-arm bandit solution that selected\npart of the global model and transmitted it to all users. The selection process\nwas guided by a novel reward function suitable for FL systems. So far as we are\naware, this is the first optimization method that seeks to address item\ndependent payloads. The method was evaluated using three benchmark\nrecommendation datasets. The empirical validation confirmed that the proposed\nmethod outperforms the simpler methods that do not benefit from the bandits for\nthe purpose of item selection. In addition, we have demonstrated the usefulness\nof our proposed method by rigorously evaluating the effects of a payload\nreduction on the recommendation performance degradation. Our method achieved up\nto a 90\\% reduction in model payload, yielding only a $\\sim$4\\% - 8\\% loss in\nthe recommendation performance for highly sparse datasets\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 20:44:30 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Khan", "Farwa K.", ""], ["Flanagan", "Adrian", ""], ["Tan", "Kuan E.", ""], ["Alamgir", "Zareen", ""], ["Ammad-Ud-Din", "Muhammad", ""]]}, {"id": "2107.13083", "submitter": "Ying Jin", "authors": "Ying Jin, Yinpeng Chen, Lijuan Wang, Jianfeng Wang, Pei Yu, Zicheng\n  Liu, Jenq-Neng Hwang", "title": "Is Object Detection Necessary for Human-Object Interaction Recognition?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper revisits human-object interaction (HOI) recognition at image level\nwithout using supervisions of object location and human pose. We name it\ndetection-free HOI recognition, in contrast to the existing\ndetection-supervised approaches which rely on object and keypoint detections to\nachieve state of the art. With our method, not only the detection supervision\nis evitable, but superior performance can be achieved by properly using\nimage-text pre-training (such as CLIP) and the proposed Log-Sum-Exp Sign\n(LSE-Sign) loss function. Specifically, using text embeddings of class labels\nto initialize the linear classifier is essential for leveraging the CLIP\npre-trained image encoder. In addition, LSE-Sign loss facilitates learning from\nmultiple labels on an imbalanced dataset by normalizing gradients over all\nclasses in a softmax format. Surprisingly, our detection-free solution achieves\n60.5 mAP on the HICO dataset, outperforming the detection-supervised state of\nthe art by 13.4 mAP\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 21:15:00 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Jin", "Ying", ""], ["Chen", "Yinpeng", ""], ["Wang", "Lijuan", ""], ["Wang", "Jianfeng", ""], ["Yu", "Pei", ""], ["Liu", "Zicheng", ""], ["Hwang", "Jenq-Neng", ""]]}, {"id": "2107.13085", "submitter": "Romain Wallon", "authors": "Romain Wallon", "title": "On Improving the Backjump Level in PB Solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current PB solvers implement many techniques inspired by the CDCL\narchitecture of modern SAT solvers, so as to benefit from its practical\nefficiency. However, they also need to deal with the fact that many of the\nproperties leveraged by this architecture are no longer true when considering\nPB constraints. In this paper, we focus on one of these properties, namely the\noptimality of the so-called first unique implication point (1-UIP). While it is\nwell known that learning the first assertive clause produced during conflict\nanalysis ensures to perform the highest possible backjump in a SAT solver, we\nshow that there is no such guarantee in the presence of PB constraints. We also\nintroduce and evaluate different approaches designed to improve the backjump\nlevel identified during conflict analysis by allowing to continue the analysis\nafter reaching the 1-UIP. Our experiments show that sub-optimal backjumps are\nfairly common in PB solvers, even though their impact on the solver is not\nclear.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 21:23:03 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Wallon", "Romain", ""]]}, {"id": "2107.13093", "submitter": "Reece Walsh", "authors": "Reece Walsh, Mohamed H. Abdelpakey, Mohamed S. Shehata, Mostafa\n  M.Mohamed", "title": "Automated Human Cell Classification in Sparse Datasets using Few-Shot\n  Learning", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifying and analyzing human cells is a lengthy procedure, often involving\na trained professional. In an attempt to expedite this process, an active area\nof research involves automating cell classification through use of deep\nlearning-based techniques. In practice, a large amount of data is required to\naccurately train these deep learning models. However, due to the sparse human\ncell datasets currently available, the performance of these models is typically\nlow. This study investigates the feasibility of using few-shot learning-based\ntechniques to mitigate the data requirements for accurate training. The study\nis comprised of three parts: First, current state-of-the-art few-shot learning\ntechniques are evaluated on human cell classification. The selected techniques\nare trained on a non-medical dataset and then tested on two out-of-domain,\nhuman cell datasets. The results indicate that, overall, the test accuracy of\nstate-of-the-art techniques decreased by at least 30% when transitioning from a\nnon-medical dataset to a medical dataset. Second, this study evaluates the\npotential benefits, if any, to varying the backbone architecture and training\nschemes in current state-of-the-art few-shot learning techniques when used in\nhuman cell classification. Even with these variations, the overall test\naccuracy decreased from 88.66% on non-medical datasets to 44.13% at best on the\nmedical datasets. Third, this study presents future directions for using\nfew-shot learning in human cell classification. In general, few-shot learning\nin its current state performs poorly on human cell classification. The study\nproves that attempts to modify existing network architectures are not effective\nand concludes that future research effort should be focused on improving\nrobustness towards out-of-domain testing using optimization-based or\nself-supervised few-shot learning techniques.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 22:26:08 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Walsh", "Reece", ""], ["Abdelpakey", "Mohamed H.", ""], ["Shehata", "Mohamed S.", ""], ["Mohamed", "Mostafa M.", ""]]}, {"id": "2107.13132", "submitter": "Eric Zhan", "authors": "Eric Zhan, Jennifer J. Sun, Ann Kennedy, Yisong Yue, Swarat Chaudhuri", "title": "Unsupervised Learning of Neurosymbolic Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for the unsupervised learning of neurosymbolic\nencoders, i.e., encoders obtained by composing neural networks with symbolic\nprograms from a domain-specific language. Such a framework can naturally\nincorporate symbolic expert knowledge into the learning process and lead to\nmore interpretable and factorized latent representations than fully neural\nencoders. Also, models learned this way can have downstream impact, as many\nanalysis workflows can benefit from having clean programmatic descriptions. We\nground our learning algorithm in the variational autoencoding (VAE) framework,\nwhere we aim to learn a neurosymbolic encoder in conjunction with a standard\ndecoder. Our algorithm integrates standard VAE-style training with modern\nprogram synthesis techniques. We evaluate our method on learning latent\nrepresentations for real-world trajectory data from animal biology and sports\nanalytics. We show that our approach offers significantly better separation\nthan standard VAEs and leads to practical gains on downstream tasks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 02:16:14 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Zhan", "Eric", ""], ["Sun", "Jennifer J.", ""], ["Kennedy", "Ann", ""], ["Yue", "Yisong", ""], ["Chaudhuri", "Swarat", ""]]}, {"id": "2107.13144", "submitter": "Min-Cheol Sagong", "authors": "Min-Cheol Sagong, Yoon-Jae Yeo, Seung-Won Jung, and Sung-Jea Ko", "title": "Content-aware Directed Propagation Network with Pixel Adaptive Kernel\n  Attention", "comments": "submitted to IEEE transactions on Neural Networks and Learning System", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional neural networks (CNNs) have been not only widespread but also\nachieved noticeable results on numerous applications including image\nclassification, restoration, and generation. Although the weight-sharing\nproperty of convolutions makes them widely adopted in various tasks, its\ncontent-agnostic characteristic can also be considered a major drawback. To\nsolve this problem, in this paper, we propose a novel operation, called pixel\nadaptive kernel attention (PAKA). PAKA provides directivity to the filter\nweights by multiplying spatially varying attention from learnable features. The\nproposed method infers pixel-adaptive attention maps along the channel and\nspatial directions separately to address the decomposed model with fewer\nparameters. Our method is trainable in an end-to-end manner and applicable to\nany CNN-based models. In addition, we propose an improved information\naggregation module with PAKA, called the hierarchical PAKA module (HPM). We\ndemonstrate the superiority of our HPM by presenting state-of-the-art\nperformance on semantic segmentation compared to the conventional information\naggregation modules. We validate the proposed method through additional\nablation studies and visualizing the effect of PAKA providing directivity to\nthe weights of convolutions. We also show the generalizability of the proposed\nmethod by applying it to multi-modal tasks especially color-guided depth map\nsuper-resolution.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 02:59:19 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Sagong", "Min-Cheol", ""], ["Yeo", "Yoon-Jae", ""], ["Jung", "Seung-Won", ""], ["Ko", "Sung-Jea", ""]]}, {"id": "2107.13165", "submitter": "Kushal Chawla", "authors": "Kushal Chawla, Rene Clever, Jaysa Ramirez, Gale Lucas, Jonathan Gratch", "title": "Towards Emotion-Aware Agents For Negotiation Dialogues", "comments": "Accepted at 9th International Conference on Affective Computing &\n  Intelligent Interaction (ACII 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Negotiation is a complex social interaction that encapsulates emotional\nencounters in human decision-making. Virtual agents that can negotiate with\nhumans are useful in pedagogy and conversational AI. To advance the development\nof such agents, we explore the prediction of two important subjective goals in\na negotiation - outcome satisfaction and partner perception. Specifically, we\nanalyze the extent to which emotion attributes extracted from the negotiation\nhelp in the prediction, above and beyond the individual difference variables.\nWe focus on a recent dataset in chat-based negotiations, grounded in a\nrealistic camping scenario. We study three degrees of emotion dimensions -\nemoticons, lexical, and contextual by leveraging affective lexicons and a\nstate-of-the-art deep learning architecture. Our insights will be helpful in\ndesigning adaptive negotiation agents that interact through realistic\ncommunication interfaces.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 04:42:36 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Chawla", "Kushal", ""], ["Clever", "Rene", ""], ["Ramirez", "Jaysa", ""], ["Lucas", "Gale", ""], ["Gratch", "Jonathan", ""]]}, {"id": "2107.13179", "submitter": "Bing Huang", "authors": "Bing Huang, Hai Dong, Athman Bouguettaya", "title": "Conflict Detection in IoT-based Smart Homes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework that detects conflicts in IoT-based smart homes.\nConflicts may arise during interactions between the resident and IoT services\nin smart homes. We propose a generic knowledge graph to represent the relations\nbetween IoT services and environment entities. We also profile a generic\nknowledge graph to a specific smart home setting based on the context\ninformation. We propose a conflict taxonomy to capture different types of\nconflicts in a single resident smart home setting. A conflict detection\nalgorithm is proposed to identify potential conflicts using the profiled\nknowledge graph. We conduct a set of experiments on real datasets and\nsynthesized datasets to validate the effectiveness and efficiency of our\nproposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 06:09:02 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Huang", "Bing", ""], ["Dong", "Hai", ""], ["Bouguettaya", "Athman", ""]]}, {"id": "2107.13181", "submitter": "Xuan Mai", "authors": "Xuan Mai, Quanzhi Fu, Yi Chen", "title": "Packet Routing with Graph Attention Multi-agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Packet routing is a fundamental problem in communication networks that\ndecides how the packets are directed from their source nodes to their\ndestination nodes through some intermediate nodes. With the increasing\ncomplexity of network topology and highly dynamic traffic demand, conventional\nmodel-based and rule-based routing schemes show significant limitations, due to\nthe simplified and unrealistic model assumptions, and lack of flexibility and\nadaption. Adding intelligence to the network control is becoming a trend and\nthe key to achieving high-efficiency network operation. In this paper, we\ndevelop a model-free and data-driven routing strategy by leveraging\nreinforcement learning (RL), where routers interact with the network and learn\nfrom the experience to make some good routing configurations for the future.\nConsidering the graph nature of the network topology, we design a multi-agent\nRL framework in combination with Graph Neural Network (GNN), tailored to the\nrouting problem. Three deployment paradigms, centralized, federated, and\ncooperated learning, are explored respectively. Simulation results demonstrate\nthat our algorithm outperforms some existing benchmark algorithms in terms of\npacket transmission delay and affordable load.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 06:20:34 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Mai", "Xuan", ""], ["Fu", "Quanzhi", ""], ["Chen", "Yi", ""]]}, {"id": "2107.13214", "submitter": "{\\L}ukasz Struski", "authors": "{\\L}ukasz Struski, Tomasz Danel, Marek \\'Smieja, Jacek Tabor, Bartosz\n  Zieli\\'nski", "title": "SONG: Self-Organizing Neural Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen a surge in research on deep interpretable neural\nnetworks with decision trees as one of the most commonly incorporated tools.\nThere are at least three advantages of using decision trees over logistic\nregression classification models: they are easy to interpret since they are\nbased on binary decisions, they can make decisions faster, and they provide a\nhierarchy of classes. However, one of the well-known drawbacks of decision\ntrees, as compared to decision graphs, is that decision trees cannot reuse the\ndecision nodes. Nevertheless, decision graphs were not commonly used in deep\nlearning due to the lack of efficient gradient-based training techniques. In\nthis paper, we fill this gap and provide a general paradigm based on Markov\nprocesses, which allows for efficient training of the special type of decision\ngraphs, which we call Self-Organizing Neural Graphs (SONG). We provide an\nextensive theoretical study of SONG, complemented by experiments conducted on\nLetter, Connect4, MNIST, CIFAR, and TinyImageNet datasets, showing that our\nmethod performs on par or better than existing decision models.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 07:53:53 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Struski", "\u0141ukasz", ""], ["Danel", "Tomasz", ""], ["\u015amieja", "Marek", ""], ["Tabor", "Jacek", ""], ["Zieli\u0144ski", "Bartosz", ""]]}, {"id": "2107.13257", "submitter": "Alishiba Dsouza", "authors": "Alishiba Dsouza and Nicolas Tempelmeier and Elena Demidova", "title": "Towards Neural Schema Alignment for OpenStreetMap and Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenStreetMap (OSM) is one of the richest openly available sources of\nvolunteered geographic information. Although OSM includes various geographical\nentities, their descriptions are highly heterogeneous, incomplete, and do not\nfollow any well-defined ontology. Knowledge graphs can potentially provide\nvaluable semantic information to enrich OSM entities. However, interlinking OSM\nentities with knowledge graphs is inherently difficult due to the large,\nheterogeneous, ambiguous, and flat OSM schema and the annotation sparsity. This\npaper tackles the alignment of OSM tags with the corresponding knowledge graph\nclasses holistically by jointly considering the schema and instance layers. We\npropose a novel neural architecture that capitalizes upon a shared latent space\nfor tag-to-class alignment created using linked entities in OSM and knowledge\ngraphs. Our experiments performed to align OSM datasets for several countries\nwith two of the most prominent openly available knowledge graphs, namely,\nWikidata and DBpedia, demonstrate that the proposed approach outperforms the\nstate-of-the-art schema alignment baselines by up to 53 percentage points in\nterms of F1-score. The resulting alignment facilitates new semantic annotations\nfor over 10 million OSM entities worldwide, which is more than a 400% increase\ncompared to the existing semantic annotations in OSM.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 10:40:35 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Dsouza", "Alishiba", ""], ["Tempelmeier", "Nicolas", ""], ["Demidova", "Elena", ""]]}, {"id": "2107.13261", "submitter": "Eugenio Lomurno", "authors": "Eugenio Lomurno, Andrea Romanoni, Matteo Matteucci", "title": "Improving Multi-View Stereo via Super-Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Today, Multi-View Stereo techniques are able to reconstruct robust and\ndetailed 3D models, especially when starting from high-resolution images.\nHowever, there are cases in which the resolution of input images is relatively\nlow, for instance, when dealing with old photos, or when hardware constrains\nthe amount of data that can be acquired. In this paper, we investigate if, how,\nand how much increasing the resolution of such input images through\nSuper-Resolution techniques reflects in quality improvements of the\nreconstructed 3D models, despite the artifacts that sometimes this may\ngenerate. We show that applying a Super-Resolution step before recovering the\ndepth maps in most cases leads to a better 3D model both in the case of\nPatchMatch-based and deep-learning-based algorithms. The use of\nSuper-Resolution improves especially the completeness of reconstructed models\nand turns out to be particularly effective in the case of textured scenes.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 10:45:05 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Lomurno", "Eugenio", ""], ["Romanoni", "Andrea", ""], ["Matteucci", "Matteo", ""]]}, {"id": "2107.13270", "submitter": "Ahmad Hammoudeh", "authors": "Ahmad Hammoudeh, Sara Tedmori and Nadim Obeid", "title": "A Reflection on Learning from Data: Epistemology Issues and Limitations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although learning from data is effective and has achieved significant\nmilestones, it has many challenges and limitations. Learning from data starts\nfrom observations and then proceeds to broader generalizations. This framework\nis controversial in science, yet it has achieved remarkable engineering\nsuccesses. This paper reflects on some epistemological issues and some of the\nlimitations of the knowledge discovered in data. The document discusses the\ncommon perception that getting more data is the key to achieving better machine\nlearning models from theoretical and practical perspectives. The paper sheds\nsome light on the shortcomings of using generic mathematical theories to\ndescribe the process. It further highlights the need for theories specialized\nin learning from data. While more data leverages the performance of machine\nlearning models in general, the relation in practice is shown to be logarithmic\nat its best; After a specific limit, more data stabilize or degrade the machine\nlearning models. Recent work in reinforcement learning showed that the trend is\nshifting away from data-oriented approaches and relying more on algorithms. The\npaper concludes that learning from data is hindered by many limitations. Hence\nan approach that has an intensional orientation is needed.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 11:05:34 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Hammoudeh", "Ahmad", ""], ["Tedmori", "Sara", ""], ["Obeid", "Nadim", ""]]}, {"id": "2107.13271", "submitter": "Yanda Meng", "authors": "Yanda Meng, Hongrun Zhang, Yitian Zhao, Xiaoyun Yang, Xuesheng Qian,\n  Xiaowei Huang, Yalin Zheng", "title": "Spatial Uncertainty-Aware Semi-Supervised Crowd Counting", "comments": "Accepted by ICCV2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised approaches for crowd counting attract attention, as the fully\nsupervised paradigm is expensive and laborious due to its request for a large\nnumber of images of dense crowd scenarios and their annotations. This paper\nproposes a spatial uncertainty-aware semi-supervised approach via regularized\nsurrogate task (binary segmentation) for crowd counting problems. Different\nfrom existing semi-supervised learning-based crowd counting methods, to exploit\nthe unlabeled data, our proposed spatial uncertainty-aware teacher-student\nframework focuses on high confident regions' information while addressing the\nnoisy supervision from the unlabeled data in an end-to-end manner.\nSpecifically, we estimate the spatial uncertainty maps from the teacher model's\nsurrogate task to guide the feature learning of the main task (density\nregression) and the surrogate task of the student model at the same time.\nBesides, we introduce a simple yet effective differential transformation layer\nto enforce the inherent spatial consistency regularization between the main\ntask and the surrogate task in the student model, which helps the surrogate\ntask to yield more reliable predictions and generates high-quality uncertainty\nmaps. Thus, our model can also address the task-level perturbation problems\nthat occur spatial inconsistency between the primary and surrogate tasks in the\nstudent model. Experimental results on four challenging crowd counting datasets\ndemonstrate that our method achieves superior performance to the\nstate-of-the-art semi-supervised methods.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 11:06:52 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Meng", "Yanda", ""], ["Zhang", "Hongrun", ""], ["Zhao", "Yitian", ""], ["Yang", "Xiaoyun", ""], ["Qian", "Xuesheng", ""], ["Huang", "Xiaowei", ""], ["Zheng", "Yalin", ""]]}, {"id": "2107.13296", "submitter": "Haoye Tian", "authors": "Haoye Tian, Yinghua Li, Weiguo Pian, Abdoul Kader Kabor\\'e, Kui Liu,\n  Jacques Klein, Tegawend\\'e F. Bissyande", "title": "Checking Patch Behaviour against Test Specification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Towards predicting patch correctness in APR, we propose a simple, but novel\nhypothesis on how the link between the patch behaviour and failing test\nspecifications can be drawn: similar failing test cases should require similar\npatches. We then propose BATS, an unsupervised learning-based system to predict\npatch correctness by checking patch Behaviour Against failing Test\nSpecification. BATS exploits deep representation learning models for code and\npatches: for a given failing test case, the yielded embedding is used to\ncompute similarity metrics in the search for historical similar test cases in\norder to identify the associated applied patches, which are then used as a\nproxy for assessing generated patch correctness. Experimentally, we first\nvalidate our hypothesis by assessing whether ground-truth developer patches\ncluster together in the same way that their associated failing test cases are\nclustered. Then, after collecting a large dataset of 1278 plausible patches\n(written by developers or generated by some 32 APR tools), we use BATS to\npredict correctness: BATS achieves an AUC between 0.557 to 0.718 and a recall\nbetween 0.562 and 0.854 in identifying correct patches. Compared against\nprevious work, we demonstrate that our approach outperforms state-of-the-art\nperformance in patch correctness prediction, without the need for large labeled\npatch datasets in contrast with prior machine learning-based approaches. While\nBATS is constrained by the availability of similar test cases, we show that it\ncan still be complementary to existing approaches: used in conjunction with a\nrecent approach implementing supervised learning, BATS improves the overall\nrecall in detecting correct patches. We finally show that BATS can be\ncomplementary to the state-of-the-art PATCH-SIM dynamic approach of identifying\nthe correct patches for APR tools.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 11:39:06 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Tian", "Haoye", ""], ["Li", "Yinghua", ""], ["Pian", "Weiguo", ""], ["Kabor\u00e9", "Abdoul Kader", ""], ["Liu", "Kui", ""], ["Klein", "Jacques", ""], ["Bissyande", "Tegawend\u00e9 F.", ""]]}, {"id": "2107.13306", "submitter": "Hongyu He", "authors": "Benno Kruit, Hongyu He, Jacopo Urbani", "title": "Tab2Know: Building a Knowledge Base from Tables in Scientific Papers", "comments": "17 pages, 4 figures, conference: The Semantic Web -- ISWC 2020", "journal-ref": "International Semantic Web Conference 2020 Nov 2 (pp. 349-365)", "doi": "10.1007/978-3-030-62419-4_20", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tables in scientific papers contain a wealth of valuable knowledge for the\nscientific enterprise. To help the many of us who frequently consult this type\nof knowledge, we present Tab2Know, a new end-to-end system to build a Knowledge\nBase (KB) from tables in scientific papers. Tab2Know addresses the challenge of\nautomatically interpreting the tables in papers and of disambiguating the\nentities that they contain. To solve these problems, we propose a pipeline that\nemploys both statistical-based classifiers and logic-based reasoning. First,\nour pipeline applies weakly supervised classifiers to recognize the type of\ntables and columns, with the help of a data labeling system and an ontology\nspecifically designed for our purpose. Then, logic-based reasoning is used to\nlink equivalent entities (via sameAs links) in different tables. An empirical\nevaluation of our approach using a corpus of papers in the Computer Science\ndomain has returned satisfactory performance. This suggests that ours is a\npromising step to create a large-scale KB of scientific knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 11:56:53 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Kruit", "Benno", ""], ["He", "Hongyu", ""], ["Urbani", "Jacopo", ""]]}, {"id": "2107.13329", "submitter": "Tiphaine Viard", "authors": "Tiphaine Viard, Henry Soldano, Guillaume Santini", "title": "Exploring and mining attributed sequences of interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We are faced with data comprised of entities interacting over time: this can\nbe individuals meeting, customers buying products, machines exchanging packets\non the IP network, among others. Capturing the dynamics as well as the\nstructure of these interactions is of crucial importance for analysis. These\ninteractions can almost always be labeled with content: group belonging,\nreviews of products, abstracts, etc. We model these stream of interactions as\nstream graphs, a recent framework to model interactions over time. Formal\nConcept Analysis provides a framework for analyzing concepts evolving within a\ncontext. Considering graphs as the context, it has recently been applied to\nperform closed pattern mining on social graphs. In this paper, we are\ninterested in pattern mining in sequences of interactions. After recalling and\nextending notions from formal concept analysis on graphs to stream graphs, we\nintroduce algorithms to enumerate closed patterns on a labeled stream graph,\nand introduce a way to select relevant closed patterns. We run experiments on\ntwo real-world datasets of interactions among students and citations between\nauthors, and show both the feasibility and the relevance of our method.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 12:53:46 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Viard", "Tiphaine", ""], ["Soldano", "Henry", ""], ["Santini", "Guillaume", ""]]}, {"id": "2107.13349", "submitter": "David Ruhe", "authors": "David Ruhe, Patrick Forr\\'e", "title": "Self-Supervised Hybrid Inference in State-Space Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform approximate inference in state-space models that allow for\nnonlinear higher-order Markov chains in latent space. The conditional\nindependencies of the generative model enable us to parameterize only an\ninference model, which learns to estimate clean states in a self-supervised\nmanner using maximum likelihood. First, we propose a recurrent method that is\ntrained directly on noisy observations. Afterward, we cast the model such that\nthe optimization problem leads to an update scheme that backpropagates through\na recursion similar to the classical Kalman filter and smoother. In scientific\napplications, domain knowledge can give a linear approximation of the latent\ntransition maps. We can easily incorporate this knowledge into our model,\nleading to a hybrid inference approach. In contrast to other methods,\nexperiments show that the hybrid method makes the inferred latent states\nphysically more interpretable and accurate, especially in low-data regimes.\nFurthermore, we do not rely on an additional parameterization of the generative\nmodel or supervision via uncorrupted observations or ground truth latent\nstates. Despite our model's simplicity, we obtain competitive results on the\nchaotic Lorenz system compared to a fully supervised approach and outperform a\nmethod based on variational inference.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 13:26:14 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Ruhe", "David", ""], ["Forr\u00e9", "Patrick", ""]]}, {"id": "2107.13353", "submitter": "Chao Yan", "authors": "Yihong Yang, Sheng Ding, Yuwen Liu, Shunmei Meng, Xiaoxiao Chi, Rui\n  Ma, Chao Yan", "title": "Fast Wireless Sensor Anomaly Detection based on Data Stream in Edge\n  Computing Enabled Smart Greenhouse", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge computing enabled smart greenhouse is a representative application of\nInternet of Things technology, which can monitor the environmental information\nin real time and employ the information to contribute to intelligent\ndecision-making. In the process, anomaly detection for wireless sensor data\nplays an important role. However, traditional anomaly detection algorithms\noriginally designed for anomaly detection in static data have not properly\nconsidered the inherent characteristics of data stream produced by wireless\nsensor such as infiniteness, correlations and concept drift, which may pose a\nconsiderable challenge on anomaly detection based on data stream, and lead to\nlow detection accuracy and efficiency. First, data stream usually generates\nquickly which means that it is infinite and enormous, so any traditional\noff-line anomaly detection algorithm that attempts to store the whole dataset\nor to scan the dataset multiple times for anomaly detection will run out of\nmemory space. Second, there exist correlations among different data streams,\nwhich traditional algorithms hardly consider. Third, the underlying data\ngeneration process or data distribution may change over time. Thus, traditional\nanomaly detection algorithms with no model update will lose their effects.\nConsidering these issues, a novel method (called DLSHiForest) on basis of\nLocality-Sensitive Hashing and time window technique in this paper is proposed\nto solve these problems while achieving accurate and efficient detection.\nComprehensive experiments are executed using real-world agricultural greenhouse\ndataset to demonstrate the feasibility of our approach. Experimental results\nshow that our proposal is practicable in addressing challenges of traditional\nanomaly detection while ensuring accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 13:32:12 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Yang", "Yihong", ""], ["Ding", "Sheng", ""], ["Liu", "Yuwen", ""], ["Meng", "Shunmei", ""], ["Chi", "Xiaoxiao", ""], ["Ma", "Rui", ""], ["Yan", "Chao", ""]]}, {"id": "2107.13355", "submitter": "Ashlesha Kumar Ms.", "authors": "Ashlesha Kumar, Kuldip Singh Sangwan and Dhiraj", "title": "A Computer Vision-Based Approach for Driver Distraction Recognition\n  using Deep Learning and Genetic Algorithm Based Ensemble", "comments": "12 pages, Presented in 20th International Conference on Artificial\n  Intelligence and Soft Computing (ICAISC 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  As the proportion of road accidents increases each year, driver distraction\ncontinues to be an important risk component in road traffic injuries and\ndeaths. The distractions caused by the increasing use of mobile phones and\nother wireless devices pose a potential risk to road safety. Our current study\naims to aid the already existing techniques in driver posture recognition by\nimproving the performance in the driver distraction classification problem. We\npresent an approach using a genetic algorithm-based ensemble of six independent\ndeep neural architectures, namely, AlexNet, VGG-16, EfficientNet B0, Vanilla\nCNN, Modified DenseNet, and InceptionV3 + BiLSTM. We test it on two\ncomprehensive datasets, the AUC Distracted Driver Dataset, on which our\ntechnique achieves an accuracy of 96.37%, surpassing the previously obtained\n95.98%, and on the State Farm Driver Distraction Dataset, on which we attain an\naccuracy of 99.75%. The 6-Model Ensemble gave an inference time of 0.024\nseconds as measured on our machine with Ubuntu 20.04(64-bit) and GPU as GeForce\nGTX 1080.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 13:39:31 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Kumar", "Ashlesha", ""], ["Sangwan", "Kuldip Singh", ""], ["Dhiraj", "", ""]]}, {"id": "2107.13356", "submitter": "Eric Rosen", "authors": "Sreehari Rammohan, Shangqun Yu, Bowen He, Eric Hsiung, Eric Rosen,\n  Stefanie Tellex, George Konidaris", "title": "Value-Based Reinforcement Learning for Continuous Control Robotic\n  Manipulation in Multi-Task Sparse Reward Settings", "comments": "5 pages, 2 figures, published at RSS 2021 workshop: Advancing\n  Artificial Intelligence and Manipulation for Robotics: Understanding Gaps,\n  Industry and Academic Perspectives, and Community Building", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning continuous control in high-dimensional sparse reward settings, such\nas robotic manipulation, is a challenging problem due to the number of samples\noften required to obtain accurate optimal value and policy estimates. While\nmany deep reinforcement learning methods have aimed at improving sample\nefficiency through replay or improved exploration techniques, state of the art\nactor-critic and policy gradient methods still suffer from the hard exploration\nproblem in sparse reward settings. Motivated by recent successes of value-based\nmethods for approximating state-action values, like RBF-DQN, we explore the\npotential of value-based reinforcement learning for learning continuous robotic\nmanipulation tasks in multi-task sparse reward settings. On robotic\nmanipulation tasks, we empirically show RBF-DQN converges faster than current\nstate of the art algorithms such as TD3, SAC, and PPO. We also perform ablation\nstudies with RBF-DQN and have shown that some enhancement techniques for\nvanilla Deep Q learning such as Hindsight Experience Replay (HER) and\nPrioritized Experience Replay (PER) can also be applied to RBF-DQN. Our\nexperimental analysis suggests that value-based approaches may be more\nsensitive to data augmentation and replay buffer sample techniques than\npolicy-gradient methods, and that the benefits of these methods for robot\nmanipulation are heavily dependent on the transition dynamics of generated\nsubgoal states.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 13:40:08 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Rammohan", "Sreehari", ""], ["Yu", "Shangqun", ""], ["He", "Bowen", ""], ["Hsiung", "Eric", ""], ["Rosen", "Eric", ""], ["Tellex", "Stefanie", ""], ["Konidaris", "George", ""]]}, {"id": "2107.13377", "submitter": "Michael Tessler", "authors": "Michael Henry Tessler, Pedro A. Tsividis, Jason Madeano, Brin Harper,\n  and Joshua B. Tenenbaum", "title": "Growing knowledge culturally across generations to solve novel, complex\n  tasks", "comments": "Poster presentation at the 43rd Annual Meeting of the Cognitive\n  Science Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge built culturally across generations allows humans to learn far more\nthan an individual could glean from their own experience in a lifetime.\nCultural knowledge in turn rests on language: language is the richest record of\nwhat previous generations believed, valued, and practiced. The power and\nmechanisms of language as a means of cultural learning, however, are not well\nunderstood. We take a first step towards reverse-engineering cultural learning\nthrough language. We developed a suite of complex high-stakes tasks in the form\nof minimalist-style video games, which we deployed in an iterated learning\nparadigm. Game participants were limited to only two attempts (two lives) to\nbeat each game and were allowed to write a message to a future participant who\nread the message before playing. Knowledge accumulated gradually across\ngenerations, allowing later generations to advance further in the games and\nperform more efficient actions. Multigenerational learning followed a\nstrikingly similar trajectory to individuals learning alone with an unlimited\nnumber of lives. These results suggest that language provides a sufficient\nmedium to express and accumulate the knowledge people acquire in these diverse\ntasks: the dynamics of the environment, valuable goals, dangerous risks, and\nstrategies for success. The video game paradigm we pioneer here is thus a rich\ntest bed for theories of cultural transmission and learning from language.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 14:09:40 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Tessler", "Michael Henry", ""], ["Tsividis", "Pedro A.", ""], ["Madeano", "Jason", ""], ["Harper", "Brin", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "2107.13389", "submitter": "Rindra Ramamonjison", "authors": "Rindra Ramamonjison, Amin Banitalebi-Dehkordi, Xinyu Kang, Xiaolong\n  Bai, Yong Zhang", "title": "SimROD: A Simple Adaptation Method for Robust Object Detection", "comments": "Accepted to ICCV 2021 conference for full oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Simple and effective unsupervised adaptation method for\nRobust Object Detection (SimROD). To overcome the challenging issues of domain\nshift and pseudo-label noise, our method integrates a novel domain-centric\naugmentation method, a gradual self-labeling adaptation procedure, and a\nteacher-guided fine-tuning mechanism. Using our method, target domain samples\ncan be leveraged to adapt object detection models without changing the model\narchitecture or generating synthetic data. When applied to image corruptions\nand high-level cross-domain adaptation benchmarks, our method outperforms prior\nbaselines on multiple domain adaptation benchmarks. SimROD achieves new\nstate-of-the-art on standard real-to-synthetic and cross-camera setup\nbenchmarks. On the image corruption benchmark, models adapted with our method\nachieved a relative robustness improvement of 15-25% AP50 on Pascal-C and 5-6%\nAP on COCO-C and Cityscapes-C. On the cross-domain benchmark, our method\noutperformed the best baseline performance by up to 8% AP50 on Comic dataset\nand up to 4% on Watercolor dataset.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 14:28:32 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Ramamonjison", "Rindra", ""], ["Banitalebi-Dehkordi", "Amin", ""], ["Kang", "Xinyu", ""], ["Bai", "Xiaolong", ""], ["Zhang", "Yong", ""]]}, {"id": "2107.13393", "submitter": "Yoonsuck Choe", "authors": "Yoonsuck Choe", "title": "Meaning Versus Information, Prediction Versus Memory, and Question\n  Versus Answer", "comments": "14 pages", "journal-ref": null, "doi": "10.1016/B978-0-12-815480-9.00014-1", "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Brain science and artificial intelligence have made great progress toward the\nunderstanding and engineering of the human mind. The progress has accelerated\nsignificantly since the turn of the century thanks to new methods for probing\nthe brain (both structure and function), and rapid development in deep learning\nresearch. However, despite these new developments, there are still many open\nquestions, such as how to understand the brain at the system level, and various\nrobustness issues and limitations of deep learning. In this informal essay, I\nwill talk about some of the concepts that are central to brain science and\nartificial intelligence, such as information and memory, and discuss how a\ndifferent view on these concepts can help us move forward, beyond current\nlimits of our understanding in these fields.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 18:22:49 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Choe", "Yoonsuck", ""]]}, {"id": "2107.13435", "submitter": "Zhenwen Liang", "authors": "Zhenwen Liang, Jipeng Zhang, Jie Shao, Xiangliang Zhang", "title": "MWP-BERT: A Strong Baseline for Math Word Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Math word problem (MWP) solving is the task of transforming a sequence of\nnatural language problem descriptions to executable math equations. An MWP\nsolver not only needs to understand complex scenarios described in the problem\ntexts, but also identify the key mathematical variables and associate text\ndescriptions with math equation logic. Although recent sequence modeling MWP\nsolvers have gained credits on the math-text contextual understanding,\npre-trained language models (PLM) have not been explored for solving MWP,\nconsidering that PLM trained over free-form texts is limited in representing\ntext references to mathematical logic. In this work, we introduce MWP-BERT to\nobtain pre-trained token representations that capture the alignment between\ntext description and mathematical logic. Additionally, we introduce a\nkeyword-based prompt matching method to address the MWPs requiring common-sense\nknowledge. On a benchmark Math23K dataset and a new Ape210k dataset, we show\nthat MWP-BERT outperforms the strongest baseline model by 5-10% improvement on\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 15:28:41 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Liang", "Zhenwen", ""], ["Zhang", "Jipeng", ""], ["Shao", "Jie", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "2107.13454", "submitter": "Vince Istvan Madai", "authors": "Vince I. Madai and David C. Higgins", "title": "Artificial Intelligence in Healthcare: Lost In Translation?", "comments": "10 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Artificial intelligence (AI) in healthcare is a potentially revolutionary\ntool to achieve improved healthcare outcomes while reducing overall health\ncosts. While many exploratory results hit the headlines in recent years there\nare only few certified and even fewer clinically validated products available\nin the clinical setting. This is a clear indication of failing translation due\nto shortcomings of the current approach to AI in healthcare. In this work, we\nhighlight the major areas, where we observe current challenges for translation\nin AI in healthcare, namely precision medicine, reproducible science, data\nissues and algorithms, causality, and product development. For each field, we\noutline possible solutions for these challenges. Our work will lead to improved\ntranslation of AI in healthcare products into the clinical setting\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:10:40 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Madai", "Vince I.", ""], ["Higgins", "David C.", ""]]}, {"id": "2107.13461", "submitter": "Ignacio Carlucho", "authors": "Ignacio Carlucho, Manuel F. Bailey, Mariano De Paula, Corina Barbalata", "title": "Marine Vehicles Localization Using Grid Cells for Path Integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous Underwater Vehicles (AUVs) are platforms used for research and\nexploration of marine environments. However, these types of vehicles face many\nchallenges that hinder their widespread use in the industry. One of the main\nlimitations is obtaining accurate position estimation, due to the lack of GPS\nsignal underwater. This estimation is usually done with Kalman filters.\nHowever, new developments in the neuroscience field have shed light on the\nmechanisms by which mammals are able to obtain a reliable estimation of their\ncurrent position based on external and internal motion cues. A new type of\nneuron, called Grid cells, has been shown to be part of path integration system\nin the brain. In this article, we show how grid cells can be used for obtaining\na position estimation of underwater vehicles. The model of grid cells used\nrequires only the linear velocities together with heading orientation and\nprovides a reliable estimation of the vehicle's position. We provide simulation\nresults for an AUV which show the feasibility of our proposed methodology.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:13:56 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Carlucho", "Ignacio", ""], ["Bailey", "Manuel F.", ""], ["De Paula", "Mariano", ""], ["Barbalata", "Corina", ""]]}, {"id": "2107.13467", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, Site Li, Yubin Ge, Pengyi Ye, Jane You, Jun Lu", "title": "Recursively Conditional Gaussian for Ordinal Unsupervised Domain\n  Adaptation", "comments": "Accepted to ICCV 2021 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been a growing interest in unsupervised domain adaptation (UDA) to\nalleviate the data scalability issue, while the existing works usually focus on\nclassifying independently discrete labels. However, in many tasks (e.g.,\nmedical diagnosis), the labels are discrete and successively distributed. The\nUDA for ordinal classification requires inducing non-trivial ordinal\ndistribution prior to the latent space. Target for this, the partially ordered\nset (poset) is defined for constraining the latent vector. Instead of the\ntypically i.i.d. Gaussian latent prior, in this work, a recursively conditional\nGaussian (RCG) set is proposed for ordered constraint modeling, which admits a\ntractable joint distribution prior. Furthermore, we are able to control the\ndensity of content vectors that violate the poset constraint by a simple\n\"three-sigma rule\". We explicitly disentangle the cross-domain images into a\nshared ordinal prior induced ordinal content space and two separate\nsource/target ordinal-unrelated spaces, and the self-training is worked on the\nshared space exclusively for ordinal-aware domain alignment. Extensive\nexperiments on UDA medical diagnoses and facial age estimation demonstrate its\neffectiveness.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:26:46 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Li", "Site", ""], ["Ge", "Yubin", ""], ["Ye", "Pengyi", ""], ["You", "Jane", ""], ["Lu", "Jun", ""]]}, {"id": "2107.13469", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, Zhenhua Guo, Site Li, Fangxu Xing, Jane You, C.-C. Jay\n  Kuo, Georges El Fakhri, Jonghye Woo", "title": "Adversarial Unsupervised Domain Adaptation with Conditional and Label\n  Shift: Infer, Align and Iterate", "comments": "Accepted to ICCV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose an adversarial unsupervised domain adaptation (UDA)\napproach with the inherent conditional and label shifts, in which we aim to\nalign the distributions w.r.t. both $p(x|y)$ and $p(y)$. Since the label is\ninaccessible in the target domain, the conventional adversarial UDA assumes\n$p(y)$ is invariant across domains, and relies on aligning $p(x)$ as an\nalternative to the $p(x|y)$ alignment. To address this, we provide a thorough\ntheoretical and empirical analysis of the conventional adversarial UDA methods\nunder both conditional and label shifts, and propose a novel and practical\nalternative optimization scheme for adversarial UDA. Specifically, we infer the\nmarginal $p(y)$ and align $p(x|y)$ iteratively in the training, and precisely\nalign the posterior $p(y|x)$ in testing. Our experimental results demonstrate\nits effectiveness on both classification and segmentation UDA, and partial UDA.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:28:01 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Guo", "Zhenhua", ""], ["Li", "Site", ""], ["Xing", "Fangxu", ""], ["You", "Jane", ""], ["Kuo", "C. -C. Jay", ""], ["Fakhri", "Georges El", ""], ["Woo", "Jonghye", ""]]}, {"id": "2107.13490", "submitter": "Lorenz Kummer BSc", "authors": "Lorenz Kummer, Kevin Sidak, Tabea Reichmann, Wilfried Gansterer", "title": "MARViN -- Multiple Arithmetic Resolutions Vacillating in Neural Networks", "comments": "10 pages, 5 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantization is a technique for reducing deep neural networks (DNNs) training\nand inference times, which is crucial for training in resource constrained\nenvironments or time critical inference applications. State-of-the-art (SOTA)\nquantization approaches focus on post-training quantization, i.e. quantization\nof pre-trained DNNs for speeding up inference. Very little work on quantized\ntraining exists, which neither al-lows dynamic intra-epoch precision switches\nnor em-ploys an information theory based switching heuristic. Usually, existing\napproaches require full precision refinement afterwards and enforce a global\nword length across the whole DNN. This leads to suboptimal quantization\nmappings and resource usage. Recognizing these limits, we introduce MARViN, a\nnew quantized training strategy using information theory-based intra-epoch\nprecision switching, which decides on a per-layer basis which precision should\nbe used in order to minimize quantization-induced information loss. Note that\nany quantization must leave enough precision such that future learning steps do\nnot suffer from vanishing gradients. We achieve an average speedup of 1.86\ncompared to a float32 basis while limiting mean accuracy degradation on\nAlexNet/ResNet to only -0.075%.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:57:05 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Kummer", "Lorenz", ""], ["Sidak", "Kevin", ""], ["Reichmann", "Tabea", ""], ["Gansterer", "Wilfried", ""]]}, {"id": "2107.13498", "submitter": "Cheng Zhang", "authors": "Cheng Zhang, Jinwoo Kim, JungHo Jeon, Jinding Xing, Changbum Ahn,\n  Pingbo Tang, and Hubo Cai", "title": "Toward Integrated Human-machine Intelligence for Civil Engineering: An\n  Interdisciplinary Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The purpose of this paper is to examine the opportunities and barriers of\nIntegrated Human-Machine Intelligence (IHMI) in civil engineering. Integrating\nartificial intelligence's high efficiency and repeatability with humans'\nadaptability in various contexts can advance timely and reliable\ndecision-making during civil engineering projects and emergencies. Successful\ncases in other domains, such as biomedical science, healthcare, and\ntransportation, showed the potential of IHMI in data-driven, knowledge-based\ndecision-making in numerous civil engineering applications. However, whether\nthe industry and academia are ready to embrace the era of IHMI and maximize its\nbenefit to the industry is still questionable due to several knowledge gaps.\nThis paper thus calls for future studies in exploring the value, method, and\nchallenges of applying IHMI in civil engineering. Our systematic review of the\nliterature and motivating cases has identified four knowledge gaps in achieving\neffective IHMI in civil engineering. First, it is unknown what types of tasks\nin the civil engineering domain can be assisted by AI and to what extent.\nSecond, the interface between human and AI in civil engineering-related tasks\nneed more precise and formal definition. Third, the barriers that impede\ncollecting detailed behavioral data from humans and contextual environments\ndeserve systematic classification and prototyping. Lastly, it is unknown what\nexpected and unexpected impacts will IHMI have on the AEC industry and\nentrepreneurship. Analyzing these knowledge gaps led to a list of identified\nresearch questions. This paper will lay the foundation for identifying relevant\nstudies to form a research roadmap to address the four knowledge gaps\nidentified.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 17:10:12 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Zhang", "Cheng", ""], ["Kim", "Jinwoo", ""], ["Jeon", "JungHo", ""], ["Xing", "Jinding", ""], ["Ahn", "Changbum", ""], ["Tang", "Pingbo", ""], ["Cai", "Hubo", ""]]}, {"id": "2107.13508", "submitter": "Abbas Khosravi", "authors": "Maryam Habibpour, Hassan Gharoun, Mohammadreza Mehdipour, AmirReza\n  Tajally, Hamzeh Asgharnezhad, Afshar Shamsi, Abbas Khosravi, Miadreza\n  Shafie-Khah, Saeid Nahavandi, and Joao P.S. Catalao", "title": "Uncertainty-Aware Credit Card Fraud Detection Using Deep Learning", "comments": "10 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Countless research works of deep neural networks (DNNs) in the task of credit\ncard fraud detection have focused on improving the accuracy of point\npredictions and mitigating unwanted biases by building different network\narchitectures or learning models. Quantifying uncertainty accompanied by point\nestimation is essential because it mitigates model unfairness and permits\npractitioners to develop trustworthy systems which abstain from suboptimal\ndecisions due to low confidence. Explicitly, assessing uncertainties associated\nwith DNNs predictions is critical in real-world card fraud detection settings\nfor characteristic reasons, including (a) fraudsters constantly change their\nstrategies, and accordingly, DNNs encounter observations that are not generated\nby the same process as the training distribution, (b) owing to the\ntime-consuming process, very few transactions are timely checked by\nprofessional experts to update DNNs. Therefore, this study proposes three\nuncertainty quantification (UQ) techniques named Monte Carlo dropout, ensemble,\nand ensemble Monte Carlo dropout for card fraud detection applied on\ntransaction data. Moreover, to evaluate the predictive uncertainty estimates,\nUQ confusion matrix and several performance metrics are utilized. Through\nexperimental results, we show that the ensemble is more effective in capturing\nuncertainty corresponding to generated predictions. Additionally, we\ndemonstrate that the proposed UQ methods provide extra insight to the point\npredictions, leading to elevate the fraud prevention process.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 17:30:46 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Habibpour", "Maryam", ""], ["Gharoun", "Hassan", ""], ["Mehdipour", "Mohammadreza", ""], ["Tajally", "AmirReza", ""], ["Asgharnezhad", "Hamzeh", ""], ["Shamsi", "Afshar", ""], ["Khosravi", "Abbas", ""], ["Shafie-Khah", "Miadreza", ""], ["Nahavandi", "Saeid", ""], ["Catalao", "Joao P. S.", ""]]}, {"id": "2107.13509", "submitter": "Upol Ehsan", "authors": "Upol Ehsan, Samir Passi, Q. Vera Liao, Larry Chan, I-Hsiang Lee,\n  Michael Muller, Mark O. Riedl", "title": "The Who in Explainable AI: How AI Background Shapes Perceptions of AI\n  Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability of AI systems is critical for users to take informed actions\nand hold systems accountable. While \"opening the opaque box\" is important,\nunderstanding who opens the box can govern if the Human-AI interaction is\neffective. In this paper, we conduct a mixed-methods study of how two different\ngroups of whos--people with and without a background in AI--perceive different\ntypes of AI explanations. These groups were chosen to look at how disparities\nin AI backgrounds can exacerbate the creator-consumer gap. We quantitatively\nshare what the perceptions are along five dimensions: confidence, intelligence,\nunderstandability, second chance, and friendliness. Qualitatively, we highlight\nhow the AI background influences each group's interpretations and elucidate why\nthe differences might exist through the lenses of appropriation and cognitive\nheuristics. We find that (1) both groups had unwarranted faith in numbers, to\ndifferent extents and for different reasons, (2) each group found explanatory\nvalues in different explanations that went beyond the usage we designed them\nfor, and (3) each group had different requirements of what counts as humanlike\nexplanations. Using our findings, we discuss potential negative consequences\nsuch as harmful manipulation of user trust and propose design interventions to\nmitigate them. By bringing conscious awareness to how and why AI backgrounds\nshape perceptions of potential creators and consumers in XAI, our work takes a\nformative step in advancing a pluralistic Human-centered Explainable AI\ndiscourse.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 17:32:04 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Ehsan", "Upol", ""], ["Passi", "Samir", ""], ["Liao", "Q. Vera", ""], ["Chan", "Larry", ""], ["Lee", "I-Hsiang", ""], ["Muller", "Michael", ""], ["Riedl", "Mark O.", ""]]}, {"id": "2107.13586", "submitter": "Pengfei Liu", "authors": "Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi,\n  Graham Neubig", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods\n  in Natural Language Processing", "comments": "Website: http://pretrain.nlpedia.ai/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper surveys and organizes research works in a new paradigm in natural\nlanguage processing, which we dub \"prompt-based learning\". Unlike traditional\nsupervised learning, which trains a model to take in an input x and predict an\noutput y as P(y|x), prompt-based learning is based on language models that\nmodel the probability of text directly. To use these models to perform\nprediction tasks, the original input x is modified using a template into a\ntextual string prompt x' that has some unfilled slots, and then the language\nmodel is used to probabilistically fill the unfilled information to obtain a\nfinal string x, from which the final output y can be derived. This framework is\npowerful and attractive for a number of reasons: it allows the language model\nto be pre-trained on massive amounts of raw text, and by defining a new\nprompting function the model is able to perform few-shot or even zero-shot\nlearning, adapting to new scenarios with few or no labeled data. In this paper\nwe introduce the basics of this promising paradigm, describe a unified set of\nmathematical notations that can cover a wide variety of existing work, and\norganize existing work along several dimensions, e.g.the choice of pre-trained\nmodels, prompts, and tuning strategies. To make the field more accessible to\ninterested beginners, we not only make a systematic review of existing works\nand a highly structured typology of prompt-based concepts, but also release\nother resources, e.g., a website http://pretrain.nlpedia.ai/ including\nconstantly-updated survey, and paperlist.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 18:09:46 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Liu", "Pengfei", ""], ["Yuan", "Weizhe", ""], ["Fu", "Jinlan", ""], ["Jiang", "Zhengbao", ""], ["Hayashi", "Hiroaki", ""], ["Neubig", "Graham", ""]]}, {"id": "2107.13587", "submitter": "Faisal Mahmood", "authors": "Chengkuan Chen, Ming Y. Lu, Drew F. K. Williamson, Tiffany Y. Chen,\n  Andrew J. Schaumberg, Faisal Mahmood", "title": "Fast and Scalable Image Search For Histology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI q-bio.TO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The expanding adoption of digital pathology has enabled the curation of large\nrepositories of histology whole slide images (WSIs), which contain a wealth of\ninformation. Similar pathology image search offers the opportunity to comb\nthrough large historical repositories of gigapixel WSIs to identify cases with\nsimilar morphological features and can be particularly useful for diagnosing\nrare diseases, identifying similar cases for predicting prognosis, treatment\noutcomes, and potential clinical trial success. A critical challenge in\ndeveloping a WSI search and retrieval system is scalability, which is uniquely\nchallenging given the need to search a growing number of slides that each can\nconsist of billions of pixels and are several gigabytes in size. Such systems\nare typically slow and retrieval speed often scales with the size of the\nrepository they search through, making their clinical adoption tedious and are\nnot feasible for repositories that are constantly growing. Here we present Fast\nImage Search for Histopathology (FISH), a histology image search pipeline that\nis infinitely scalable and achieves constant search speed that is independent\nof the image database size while being interpretable and without requiring\ndetailed annotations. FISH uses self-supervised deep learning to encode\nmeaningful representations from WSIs and a Van Emde Boas tree for fast search,\nfollowed by an uncertainty-based ranking algorithm to retrieve similar WSIs. We\nevaluated FISH on multiple tasks and datasets with over 22,000 patient cases\nspanning 56 disease subtypes. We additionally demonstrate that FISH can be used\nto assist with the diagnosis of rare cancer types where sufficient cases may\nnot be available to train traditional supervised deep models. FISH is available\nas an easy-to-use, open-source software package\n(https://github.com/mahmoodlab/FISH).\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 18:15:03 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Chen", "Chengkuan", ""], ["Lu", "Ming Y.", ""], ["Williamson", "Drew F. K.", ""], ["Chen", "Tiffany Y.", ""], ["Schaumberg", "Andrew J.", ""], ["Mahmood", "Faisal", ""]]}, {"id": "2107.13619", "submitter": "Stefanos Antaris", "authors": "Stefanos Antaris, Dimitrios Rafailidis, Sarunas Girdzijauskas", "title": "A Deep Graph Reinforcement Learning Model for Improving User Experience\n  in Live Video Streaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present a deep graph reinforcement learning model to predict\nand improve the user experience during a live video streaming event,\norchestrated by an agent/tracker. We first formulate the user experience\nprediction problem as a classification task, accounting for the fact that most\nof the viewers at the beginning of an event have poor quality of experience due\nto low-bandwidth connections and limited interactions with the tracker. In our\nmodel we consider different factors that influence the quality of user\nexperience and train the proposed model on diverse state-action transitions\nwhen viewers interact with the tracker. In addition, provided that past events\nhave various user experience characteristics we follow a gradient boosting\nstrategy to compute a global model that learns from different events. Our\nexperiments with three real-world datasets of live video streaming events\ndemonstrate the superiority of the proposed model against several baseline\nstrategies. Moreover, as the majority of the viewers at the beginning of an\nevent has poor experience, we show that our model can significantly increase\nthe number of viewers with high quality experience by at least 75% over the\nfirst streaming minutes. Our evaluation datasets and implementation are\npublicly available at https://publicresearch.z13.web.core.windows.net\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 19:53:05 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Antaris", "Stefanos", ""], ["Rafailidis", "Dimitrios", ""], ["Girdzijauskas", "Sarunas", ""]]}, {"id": "2107.13625", "submitter": "William Paul", "authors": "William Paul, Philippe Burlina", "title": "Generalizing Fairness: Discovery and Mitigation of Unknown Sensitive\n  Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When deploying artificial intelligence (AI) in the real world, being able to\ntrust the operation of the AI by characterizing how it performs is an\never-present and important topic. An important and still largely unexplored\ntask in this characterization is determining major factors within the real\nworld that affect the AI's behavior, such as weather conditions or lighting,\nand either a) being able to give justification for why it may have failed or b)\neliminating the influence the factor has. Determining these sensitive factors\nheavily relies on collected data that is diverse enough to cover numerous\ncombinations of these factors, which becomes more onerous when having many\npotential sensitive factors or operating in complex environments. This paper\ninvestigates methods that discover and separate out individual semantic\nsensitive factors from a given dataset to conduct this characterization as well\nas addressing mitigation of these factors' sensitivity. We also broaden\nremediation of fairness, which normally only addresses socially relevant\nfactors, and widen it to deal with the desensitization of AI with regard to all\npossible aspects of variation in the domain. The proposed methods which\ndiscover these major factors reduce the potentially onerous demands of\ncollecting a sufficiently diverse dataset. In experiments using the road sign\n(GTSRB) and facial imagery (CelebA) datasets, we show the promise of using this\nscheme to perform this characterization and remediation and demonstrate that\nour approach outperforms state of the art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 20:18:08 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Paul", "William", ""], ["Burlina", "Philippe", ""]]}, {"id": "2107.13640", "submitter": "Amit Chaulwar", "authors": "Amit Chaulwar and Michael Huth", "title": "Secure Bayesian Federated Analytics for Privacy-Preserving Trend\n  Detection", "comments": "10 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated analytics has many applications in edge computing, its use can lead\nto better decision making for service provision, product development, and user\nexperience. We propose a Bayesian approach to trend detection in which the\nprobability of a keyword being trendy, given a dataset, is computed via Bayes'\nTheorem; the probability of a dataset, given that a keyword is trendy, is\ncomputed through secure aggregation of such conditional probabilities over\nlocal datasets of users. We propose a protocol, named SAFE, for Bayesian\nfederated analytics that offers sufficient privacy for production grade use\ncases and reduces the computational burden of users and an aggregator. We\nillustrate this approach with a trend detection experiment and discuss how this\napproach could be extended further to make it production-ready.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 20:52:28 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Chaulwar", "Amit", ""], ["Huth", "Michael", ""]]}, {"id": "2107.13641", "submitter": "Emanuela Guerriero Prof", "authors": "Tommaso Adamo and Gianpaolo Ghiani and Pierpaolo Greco and Emanuela\n  Guerriero", "title": "Learned upper bounds for the Time-Dependent Travelling Salesman Problem", "comments": "arXiv admin note: text overlap with arXiv:2009.07588", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Given a graph whose arc traversal times vary over time, the Time-Dependent\nTravelling Salesman Problem consists in finding a Hamiltonian tour of least\ntotal duration covering the vertices of the graph. The main goal of this work\nis to define tight upper bounds for this problem by reusing the information\ngained when solving instances with similar features. This is customary in\ndistribution management, where vehicle routes have to be generated over and\nover again with similar input data. To this aim, we devise an upper bounding\ntechnique based on the solution of a classical (and simpler) time-independent\nAsymmetric Travelling Salesman Problem, where the constant arc costs are\nsuitably defined by the combined use of a Linear Program and a mix of\nunsupervised and supervised Machine Learning techniques. The effectiveness of\nthis approach has been assessed through a computational campaign on the real\ntravel time functions of two European cities: Paris and London. The overall\naverage gap between our heuristic and the best-known solutions is about\n0.001\\%. For 31 instances, new best solutions have been obtained.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 20:54:59 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Adamo", "Tommaso", ""], ["Ghiani", "Gianpaolo", ""], ["Greco", "Pierpaolo", ""], ["Guerriero", "Emanuela", ""]]}, {"id": "2107.13646", "submitter": "Mattia Medina Grespan", "authors": "Mattia Medina Grespan, Ashim Gupta and Vivek Srikumar", "title": "Evaluating Relaxations of Logic for Neural Networks: A Comprehensive\n  Study", "comments": "IJCAI 2021 paper (Extended Version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic knowledge can provide crucial inductive bias for training neural\nmodels, especially in low data regimes. A successful strategy for incorporating\nsuch knowledge involves relaxing logical statements into sub-differentiable\nlosses for optimization. In this paper, we study the question of how best to\nrelax logical expressions that represent labeled examples and knowledge about a\nproblem; we focus on sub-differentiable t-norm relaxations of logic. We present\ntheoretical and empirical criteria for characterizing which relaxation would\nperform best in various scenarios. In our theoretical study driven by the goal\nof preserving tautologies, the Lukasiewicz t-norm performs best. However, in\nour empirical analysis on the text chunking and digit recognition tasks, the\nproduct t-norm achieves best predictive performance. We analyze this apparent\ndiscrepancy, and conclude with a list of best practices for defining loss\nfunctions via logic.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 21:16:58 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Grespan", "Mattia Medina", ""], ["Gupta", "Ashim", ""], ["Srikumar", "Vivek", ""]]}, {"id": "2107.13668", "submitter": "Pulkit Verma", "authors": "Pulkit Verma, Shashank Rao Marpally, Siddharth Srivastava", "title": "Learning User-Interpretable Descriptions of Black-Box AI System\n  Capabilities", "comments": "ICAPS 2021 Workshop on Knowledge Engineering for Planning and\n  Scheduling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several approaches have been developed to answer specific questions that a\nuser may have about an AI system that can plan and act. However, the problems\nof identifying which questions to ask and that of computing a\nuser-interpretable symbolic description of the overall capabilities of the\nsystem have remained largely unaddressed. This paper presents an approach for\naddressing these problems by learning user-interpretable symbolic descriptions\nof the limits and capabilities of a black-box AI system using low-level\nsimulators. It uses a hierarchical active querying paradigm to generate\nquestions and to learn a user-interpretable model of the AI system based on its\nresponses. In contrast to prior work, we consider settings where imprecision of\nthe user's conceptual vocabulary precludes a direct expression of the agent's\ncapabilities. Furthermore, our approach does not require assumptions about the\ninternal design of the target AI system or about the methods that it may use to\ncompute or learn task solutions. Empirical evaluation on several game-based\nsimulator domains shows that this approach can efficiently learn symbolic\nmodels of AI systems that use a deterministic black-box policy in fully\nobservable scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 23:33:31 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Verma", "Pulkit", ""], ["Marpally", "Shashank Rao", ""], ["Srivastava", "Siddharth", ""]]}, {"id": "2107.13669", "submitter": "Soujanya Poria", "authors": "Wei Han, Hui Chen, Alexander Gelbukh, Amir Zadeh, Louis-philippe\n  Morency, and Soujanya Poria", "title": "Bi-Bimodal Modality Fusion for Correlation-Controlled Multimodal\n  Sentiment Analysis", "comments": "Accepted at ICMI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Multimodal sentiment analysis aims to extract and integrate semantic\ninformation collected from multiple modalities to recognize the expressed\nemotions and sentiment in multimodal data. This research area's major concern\nlies in developing an extraordinary fusion scheme that can extract and\nintegrate key information from various modalities. However, one issue that may\nrestrict previous work to achieve a higher level is the lack of proper modeling\nfor the dynamics of the competition between the independence and relevance\namong modalities, which could deteriorate fusion outcomes by causing the\ncollapse of modality-specific feature space or introducing extra noise. To\nmitigate this, we propose the Bi-Bimodal Fusion Network (BBFN), a novel\nend-to-end network that performs fusion (relevance increment) and separation\n(difference increment) on pairwise modality representations. The two parts are\ntrained simultaneously such that the combat between them is simulated. The\nmodel takes two bimodal pairs as input due to the known information imbalance\namong modalities. In addition, we leverage a gated control mechanism in the\nTransformer architecture to further improve the final output. Experimental\nresults on three datasets (CMU-MOSI, CMU-MOSEI, and UR-FUNNY) verifies that our\nmodel significantly outperforms the SOTA. The implementation of this work is\navailable at https://github.com/declare-lab/BBFN.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 23:33:42 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Han", "Wei", ""], ["Chen", "Hui", ""], ["Gelbukh", "Alexander", ""], ["Zadeh", "Amir", ""], ["Morency", "Louis-philippe", ""], ["Poria", "Soujanya", ""]]}, {"id": "2107.13684", "submitter": "Shuangyong Song", "authors": "Shuangyong Song", "title": "An Online Question Answering System based on Sub-graph Searching", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge graphs (KGs) have been widely used for question answering (QA)\napplications, especially the entity based QA. However, searching an-swers from\nan entire large-scale knowledge graph is very time-consuming and it is hard to\nmeet the speed need of real online QA systems. In this pa-per, we design a\nsub-graph searching mechanism to solve this problem by creating sub-graph\nindex, and each answer generation step is restricted in the sub-graph level. We\nuse this mechanism into a real online QA chat system, and it can bring obvious\nimprovement on question coverage by well answer-ing entity based questions, and\nit can be with a very high speed, which en-sures the user experience of online\nQA.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 00:44:58 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Song", "Shuangyong", ""]]}, {"id": "2107.13704", "submitter": "Lenore Blum", "authors": "Lenore Blum, Manuel Blum", "title": "A Theory of Consciousness from a Theoretical Computer Science\n  Perspective 2: Insights from the Conscious Turing Machine", "comments": "arXiv admin note: text overlap with arXiv:2011.09850", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The quest to understand consciousness, once the purview of philosophers and\ntheologians, is now actively pursued by scientists of many stripes. We examine\nconsciousness from the perspective of theoretical computer science (TCS), a\nbranch of mathematics concerned with understanding the underlying principles of\ncomputation and complexity, including the implications and surprising\nconsequences of resource limitations. In the spirit of Alan Turing's simple yet\npowerful definition of a computer, the Turing Machine (TM), and perspective of\ncomputational complexity theory, we formalize a modified version of the Global\nWorkspace Theory (GWT) of consciousness originated by cognitive neuroscientist\nBernard Baars and further developed by him, Stanislas Dehaene, Jean-Pierre\nChangeaux and others. We are not looking for a complex model of the brain nor\nof cognition, but for a simple computational model of (the admittedly complex\nconcept of) consciousness. We do this by defining the Conscious Turing Machine\n(CTM), also called a conscious AI, and then we define consciousness and related\nnotions in the CTM. While these are only mathematical (TCS) definitions, we\nsuggest why the CTM has the feeling of consciousness. The TCS perspective\nprovides a simple formal framework to employ tools from computational\ncomplexity theory and machine learning to help us understand consciousness and\nrelated concepts. Previously we explored high level explanations for the\nfeelings of pain and pleasure in the CTM. Here we consider three examples\nrelated to vision (blindsight, inattentional blindness, and change blindness),\nfollowed by discussions of dreams, free will, and altered states of\nconsciousness.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 01:47:52 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Blum", "Lenore", ""], ["Blum", "Manuel", ""]]}, {"id": "2107.13720", "submitter": "Xinyang Feng", "authors": "Xinyang Feng, Dongjin Song, Yuncong Chen, Zhengzhang Chen, Jingchao\n  Ni, Haifeng Chen", "title": "Convolutional Transformer based Dual Discriminator Generative\n  Adversarial Networks for Video Anomaly Detection", "comments": "Accepted for publication in the 29th ACM International Conference on\n  Multimedia (ACMMM '21)", "journal-ref": null, "doi": "10.1145/3474085.3475693", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting abnormal activities in real-world surveillance videos is an\nimportant yet challenging task as the prior knowledge about video anomalies is\nusually limited or unavailable. Despite that many approaches have been\ndeveloped to resolve this problem, few of them can capture the normal\nspatio-temporal patterns effectively and efficiently. Moreover, existing works\nseldom explicitly consider the local consistency at frame level and global\ncoherence of temporal dynamics in video sequences. To this end, we propose\nConvolutional Transformer based Dual Discriminator Generative Adversarial\nNetworks (CT-D2GAN) to perform unsupervised video anomaly detection.\nSpecifically, we first present a convolutional transformer to perform future\nframe prediction. It contains three key components, i.e., a convolutional\nencoder to capture the spatial information of the input video clips, a temporal\nself-attention module to encode the temporal dynamics, and a convolutional\ndecoder to integrate spatio-temporal features and predict the future frame.\nNext, a dual discriminator based adversarial training procedure, which jointly\nconsiders an image discriminator that can maintain the local consistency at\nframe-level and a video discriminator that can enforce the global coherence of\ntemporal dynamics, is employed to enhance the future frame prediction. Finally,\nthe prediction error is used to identify abnormal video frames. Thoroughly\nempirical studies on three public video anomaly detection datasets, i.e., UCSD\nPed2, CUHK Avenue, and Shanghai Tech Campus, demonstrate the effectiveness of\nthe proposed adversarial spatio-temporal modeling framework.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 03:07:25 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Feng", "Xinyang", ""], ["Song", "Dongjin", ""], ["Chen", "Yuncong", ""], ["Chen", "Zhengzhang", ""], ["Ni", "Jingchao", ""], ["Chen", "Haifeng", ""]]}, {"id": "2107.13731", "submitter": "Xiaoxue Zang", "authors": "Chongyang Bai, Xiaoxue Zang, Ying Xu, Srinivas Sunkara, Abhinav\n  Rastogi, Jindong Chen, Blaise Aguera y Arcas", "title": "UIBert: Learning Generic Multimodal Representations for UI Understanding", "comments": "8 pages, IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To improve the accessibility of smart devices and to simplify their usage,\nbuilding models which understand user interfaces (UIs) and assist users to\ncomplete their tasks is critical. However, unique challenges are proposed by\nUI-specific characteristics, such as how to effectively leverage multimodal UI\nfeatures that involve image, text, and structural metadata and how to achieve\ngood performance when high-quality labeled data is unavailable. To address such\nchallenges we introduce UIBert, a transformer-based joint image-text model\ntrained through novel pre-training tasks on large-scale unlabeled UI data to\nlearn generic feature representations for a UI and its components. Our key\nintuition is that the heterogeneous features in a UI are self-aligned, i.e.,\nthe image and text features of UI components, are predictive of each other. We\npropose five pretraining tasks utilizing this self-alignment among different\nfeatures of a UI component and across various components in the same UI. We\nevaluate our method on nine real-world downstream UI tasks where UIBert\noutperforms strong multimodal baselines by up to 9.26% accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 03:51:36 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Bai", "Chongyang", ""], ["Zang", "Xiaoxue", ""], ["Xu", "Ying", ""], ["Sunkara", "Srinivas", ""], ["Rastogi", "Abhinav", ""], ["Chen", "Jindong", ""], ["Arcas", "Blaise Aguera y", ""]]}, {"id": "2107.13734", "submitter": "Desmond Ong", "authors": "Desmond C. Ong", "title": "An Ethical Framework for Guiding the Development of Affectively-Aware\n  Artificial Intelligence", "comments": "Accepted at IEEE Affective Computing and Intelligent Interaction 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The recent rapid advancements in artificial intelligence research and\ndeployment have sparked more discussion about the potential ramifications of\nsocially- and emotionally-intelligent AI. The question is not if research can\nproduce such affectively-aware AI, but when it will. What will it mean for\nsociety when machines -- and the corporations and governments they serve -- can\n\"read\" people's minds and emotions? What should developers and operators of\nsuch AI do, and what should they not do? The goal of this article is to\npre-empt some of the potential implications of these developments, and propose\na set of guidelines for evaluating the (moral and) ethical consequences of\naffectively-aware AI, in order to guide researchers, industry professionals,\nand policy-makers. We propose a multi-stakeholder analysis framework that\nseparates the ethical responsibilities of AI Developers vis-\\`a-vis the\nentities that deploy such AI -- which we term Operators. Our analysis produces\ntwo pillars that clarify the responsibilities of each of these stakeholders:\nProvable Beneficence, which rests on proving the effectiveness of the AI, and\nResponsible Stewardship, which governs responsible collection, use, and storage\nof data and the decisions made from such data. We end with recommendations for\nresearchers, developers, operators, as well as regulators and law-makers.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 03:57:53 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Ong", "Desmond C.", ""]]}, {"id": "2107.13738", "submitter": "Nathan Partlan", "authors": "Nathan Partlan, Erica Kleinman, Jim Howe, Sabbir Ahmad, Stacy\n  Marsella, Magy Seif El-Nasr", "title": "Design-Driven Requirements for Computationally Co-Creative Game AI\n  Design Tools", "comments": "12 pages, 1 figure. Accepted for publication in Foundations of\n  Digital Games (FDG) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game AI designers must manage complex interactions between the AI character,\nthe game world, and the player, while achieving their design visions.\nComputational co-creativity tools can aid them, but first, AI and HCI\nresearchers must gather requirements and determine design heuristics to build\neffective co-creative tools. In this work, we present a participatory design\nstudy that categorizes and analyzes game AI designers' workflows, goals, and\nexpectations for such tools. We evince deep connections between game AI design\nand the design of co-creative tools, and present implications for future\nco-creativity tool research and development.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 04:14:53 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Partlan", "Nathan", ""], ["Kleinman", "Erica", ""], ["Howe", "Jim", ""], ["Ahmad", "Sabbir", ""], ["Marsella", "Stacy", ""], ["El-Nasr", "Magy Seif", ""]]}, {"id": "2107.13742", "submitter": "Veeru Talreja", "authors": "Fariborz Taherkhani, Veeru Talreja, Jeremy Dawson, Matthew C. Valenti,\n  and Nasser M. Nasrabadi", "title": "Profile to Frontal Face Recognition in the Wild Using Coupled\n  Conditional GAN", "comments": "arXiv admin note: substantial text overlap with arXiv:2005.02166", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, with the advent of deep-learning, face recognition has\nachieved exceptional success. However, many of these deep face recognition\nmodels perform much better in handling frontal faces compared to profile faces.\nThe major reason for poor performance in handling of profile faces is that it\nis inherently difficult to learn pose-invariant deep representations that are\nuseful for profile face recognition. In this paper, we hypothesize that the\nprofile face domain possesses a latent connection with the frontal face domain\nin a latent feature subspace. We look to exploit this latent connection by\nprojecting the profile faces and frontal faces into a common latent subspace\nand perform verification or retrieval in the latent domain. We leverage a\ncoupled conditional generative adversarial network (cpGAN) structure to find\nthe hidden relationship between the profile and frontal images in a latent\ncommon embedding subspace. Specifically, the cpGAN framework consists of two\nconditional GAN-based sub-networks, one dedicated to the frontal domain and the\nother dedicated to the profile domain. Each sub-network tends to find a\nprojection that maximizes the pair-wise correlation between the two feature\ndomains in a common embedding feature subspace. The efficacy of our approach\ncompared with the state-of-the-art is demonstrated using the CFP, CMU\nMulti-PIE, IJB-A, and IJB-C datasets. Additionally, we have also implemented a\ncoupled convolutional neural network (cpCNN) and an adversarial discriminative\ndomain adaptation network (ADDA) for profile to frontal face recognition. We\nhave evaluated the performance of cpCNN and ADDA and compared it with the\nproposed cpGAN. Finally, we have also evaluated our cpGAN for reconstruction of\nfrontal faces from input profile faces contained in the VGGFace2 dataset.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 04:33:43 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Taherkhani", "Fariborz", ""], ["Talreja", "Veeru", ""], ["Dawson", "Jeremy", ""], ["Valenti", "Matthew C.", ""], ["Nasrabadi", "Nasser M.", ""]]}, {"id": "2107.13782", "submitter": "Anil Rahate", "authors": "Anil Rahate, Rahee Walambe, Sheela Ramanna, Ketan Kotecha", "title": "Multimodal Co-learning: Challenges, Applications with Datasets, Recent\n  Advances and Future Directions", "comments": "This is under review with a scientific journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Multimodal deep learning systems which employ multiple modalities like text,\nimage, audio, video, etc., are showing better performance in comparison with\nindividual modalities (i.e., unimodal) systems. Multimodal machine learning\ninvolves multiple aspects: representation, translation, alignment, fusion, and\nco-learning. In the current state of multimodal machine learning, the\nassumptions are that all modalities are present, aligned, and noiseless during\ntraining and testing time. However, in real-world tasks, typically, it is\nobserved that one or more modalities are missing, noisy, lacking annotated\ndata, have unreliable labels, and are scarce in training or testing and or\nboth. This challenge is addressed by a learning paradigm called multimodal\nco-learning. The modeling of a (resource-poor) modality is aided by exploiting\nknowledge from another (resource-rich) modality using transfer of knowledge\nbetween modalities, including their representations and predictive models.\nCo-learning being an emerging area, there are no dedicated reviews explicitly\nfocusing on all challenges addressed by co-learning. To that end, in this work,\nwe provide a comprehensive survey on the emerging area of multimodal\nco-learning that has not been explored in its entirety yet. We review\nimplementations that overcome one or more co-learning challenges without\nexplicitly considering them as co-learning challenges. We present the\ncomprehensive taxonomy of multimodal co-learning based on the challenges\naddressed by co-learning and associated implementations. The various techniques\nemployed to include the latest ones are reviewed along with some of the\napplications and datasets. Our final goal is to discuss challenges and\nperspectives along with the important ideas and directions for future work that\nwe hope to be beneficial for the entire research community focusing on this\nexciting domain.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 07:25:21 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Rahate", "Anil", ""], ["Walambe", "Rahee", ""], ["Ramanna", "Sheela", ""], ["Kotecha", "Ketan", ""]]}, {"id": "2107.13807", "submitter": "Shiming Chen", "authors": "Shiming Chen, Wenjie Wang, Beihao Xia, Qinmu Peng, Xinge You, Feng\n  Zheng, Ling Shao", "title": "FREE: Feature Refinement for Generalized Zero-Shot Learning", "comments": "ICCV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized zero-shot learning (GZSL) has achieved significant progress, with\nmany efforts dedicated to overcoming the problems of visual-semantic domain gap\nand seen-unseen bias. However, most existing methods directly use feature\nextraction models trained on ImageNet alone, ignoring the cross-dataset bias\nbetween ImageNet and GZSL benchmarks. Such a bias inevitably results in\npoor-quality visual features for GZSL tasks, which potentially limits the\nrecognition performance on both seen and unseen classes. In this paper, we\npropose a simple yet effective GZSL method, termed feature refinement for\ngeneralized zero-shot learning (FREE), to tackle the above problem. FREE\nemploys a feature refinement (FR) module that incorporates\n\\textit{semantic$\\rightarrow$visual} mapping into a unified generative model to\nrefine the visual features of seen and unseen class samples. Furthermore, we\npropose a self-adaptive margin center loss (SAMC-loss) that cooperates with a\nsemantic cycle-consistency loss to guide FR to learn class- and\nsemantically-relevant representations, and concatenate the features in FR to\nextract the fully refined features. Extensive experiments on five benchmark\ndatasets demonstrate the significant performance gain of FREE over its baseline\nand current state-of-the-art methods. Our codes are available at\nhttps://github.com/shiming-chen/FREE .\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 08:11:01 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Chen", "Shiming", ""], ["Wang", "Wenjie", ""], ["Xia", "Beihao", ""], ["Peng", "Qinmu", ""], ["You", "Xinge", ""], ["Zheng", "Feng", ""], ["Shao", "Ling", ""]]}, {"id": "2107.13876", "submitter": "Felice Antonio Merra", "authors": "Vito Walter Anelli, Yashar Deldjoo, Tommaso Di Noia, Felice Antonio\n  Merra", "title": "Understanding the Effects of Adversarial Personalized Ranking\n  Optimization Method on Recommendation Quality", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recommender systems (RSs) employ user-item feedback, e.g., ratings, to match\ncustomers to personalized lists of products. Approaches to top-k recommendation\nmainly rely on Learning-To-Rank algorithms and, among them, the most widely\nadopted is Bayesian Personalized Ranking (BPR), which bases on a pair-wise\noptimization approach. Recently, BPR has been found vulnerable against\nadversarial perturbations of its model parameters. Adversarial Personalized\nRanking (APR) mitigates this issue by robustifying BPR via an adversarial\ntraining procedure. The empirical improvements of APR's accuracy performance on\nBPR have led to its wide use in several recommender models. However, a key\noverlooked aspect has been the beyond-accuracy performance of APR, i.e.,\nnovelty, coverage, and amplification of popularity bias, considering that\nrecent results suggest that BPR, the building block of APR, is sensitive to the\nintensification of biases and reduction of recommendation novelty. In this\nwork, we model the learning characteristics of the BPR and APR optimization\nframeworks to give mathematical evidence that, when the feedback data have a\ntailed distribution, APR amplifies the popularity bias more than BPR due to an\nunbalanced number of received positive updates from short-head items. Using\nmatrix factorization (MF), we empirically validate the theoretical results by\nperforming preliminary experiments on two public datasets to compare BPR-MF and\nAPR-MF performance on accuracy and beyond-accuracy metrics. The experimental\nresults consistently show the degradation of novelty and coverage measures and\na worrying amplification of bias.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 10:22:20 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Anelli", "Vito Walter", ""], ["Deldjoo", "Yashar", ""], ["Di Noia", "Tommaso", ""], ["Merra", "Felice Antonio", ""]]}, {"id": "2107.13904", "submitter": "Wenhang Ge", "authors": "Wenhang Ge, Chunyan Pan, Ancong Wu, Hongwei Zheng, Wei-Shi Zheng", "title": "Cross-Camera Feature Prediction for Intra-Camera Supervised Person\n  Re-identification across Distant Scenes", "comments": "10 pages, 6 figures, accepted by ACM International Conference on\n  Multimedia", "journal-ref": null, "doi": "10.1145/3474085.3475382", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person re-identification (Re-ID) aims to match person images across\nnon-overlapping camera views. The majority of Re-ID methods focus on\nsmall-scale surveillance systems in which each pedestrian is captured in\ndifferent camera views of adjacent scenes. However, in large-scale surveillance\nsystems that cover larger areas, it is required to track a pedestrian of\ninterest across distant scenes (e.g., a criminal suspect escapes from one city\nto another). Since most pedestrians appear in limited local areas, it is\ndifficult to collect training data with cross-camera pairs of the same person.\nIn this work, we study intra-camera supervised person re-identification across\ndistant scenes (ICS-DS Re-ID), which uses cross-camera unpaired data with\nintra-camera identity labels for training. It is challenging as cross-camera\npaired data plays a crucial role for learning camera-invariant features in most\nexisting Re-ID methods. To learn camera-invariant representation from\ncross-camera unpaired training data, we propose a cross-camera feature\nprediction method to mine cross-camera self supervision information from\ncamera-specific feature distribution by transforming fake cross-camera positive\nfeature pairs and minimize the distances of the fake pairs. Furthermore, we\nautomatically localize and extract local-level feature by a transformer. Joint\nlearning of global-level and local-level features forms a global-local\ncross-camera feature prediction scheme for mining fine-grained cross-camera\nself supervision information. Finally, cross-camera self supervision and\nintra-camera supervision are aggregated in a framework. The experiments are\nconducted in the ICS-DS setting on Market-SCT, Duke-SCT and MSMT17-SCT\ndatasets. The evaluation results demonstrate the superiority of our method,\nwhich gains significant improvements of 15.4 Rank-1 and 22.3 mAP on Market-SCT\nas compared to the second best method.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 11:27:50 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Ge", "Wenhang", ""], ["Pan", "Chunyan", ""], ["Wu", "Ancong", ""], ["Zheng", "Hongwei", ""], ["Zheng", "Wei-Shi", ""]]}, {"id": "2107.13944", "submitter": "Ashkan Bagheri Jeddi", "authors": "Ashkan B. Jeddi, Nariman L. Dehghani, Abdollah Shafieezadeh", "title": "Lyapunov-based uncertainty-aware safe reinforcement learning", "comments": "Submitted to IEEE Transactions on Neural Networks and Learning\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has shown a promising performance in learning\noptimal policies for a variety of sequential decision-making tasks. However, in\nmany real-world RL problems, besides optimizing the main objectives, the agent\nis expected to satisfy a certain level of safety (e.g., avoiding collisions in\nautonomous driving). While RL problems are commonly formalized as Markov\ndecision processes (MDPs), safety constraints are incorporated via constrained\nMarkov decision processes (CMDPs). Although recent advances in safe RL have\nenabled learning safe policies in CMDPs, these safety requirements should be\nsatisfied during both training and in the deployment process. Furthermore, it\nis shown that in memory-based and partially observable environments, these\nmethods fail to maintain safety over unseen out-of-distribution observations.\nTo address these limitations, we propose a Lyapunov-based uncertainty-aware\nsafe RL model. The introduced model adopts a Lyapunov function that converts\ntrajectory-based constraints to a set of local linear constraints. Furthermore,\nto ensure the safety of the agent in highly uncertain environments, an\nuncertainty quantification method is developed that enables identifying\nrisk-averse actions through estimating the probability of constraint\nviolations. Moreover, a Transformers model is integrated to provide the agent\nwith memory to process long time horizons of information via the self-attention\nmechanism. The proposed model is evaluated in grid-world navigation tasks where\nsafety is defined as avoiding static and dynamic obstacles in fully and\npartially observable environments. The results of these experiments show a\nsignificant improvement in the performance of the agent both in achieving\noptimality and satisfying safety constraints.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 13:08:15 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Jeddi", "Ashkan B.", ""], ["Dehghani", "Nariman L.", ""], ["Shafieezadeh", "Abdollah", ""]]}, {"id": "2107.13955", "submitter": "Louis Clouatre", "authors": "Louis Clouatre, Prasanna Parthasarathi, Amal Zouaq, Sarath Chandar", "title": "Demystifying Neural Language Models' Insensitivity to Word-Order", "comments": "11 pages, 13 figure + appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent research analyzing the sensitivity of natural language understanding\nmodels to word-order perturbations have shown that the state-of-the-art models\nin several language tasks may have a unique way to understand the text that\ncould seldom be explained with conventional syntax and semantics. In this\npaper, we investigate the insensitivity of natural language models to\nword-order by quantifying perturbations and analysing their effect on neural\nmodels' performance on language understanding tasks in GLUE benchmark. Towards\nthat end, we propose two metrics - the Direct Neighbour Displacement (DND) and\nthe Index Displacement Count (IDC) - that score the local and global ordering\nof tokens in the perturbed texts and observe that perturbation functions found\nin prior literature affect only the global ordering while the local ordering\nremains relatively unperturbed. We propose perturbations at the granularity of\nsub-words and characters to study the correlation between DND, IDC and the\nperformance of neural language models on natural language tasks. We find that\nneural language models - pretrained and non-pretrained Transformers, LSTMs, and\nConvolutional architectures - require local ordering more so than the global\nordering of tokens. The proposed metrics and the suite of perturbations allow a\nsystematic way to study the (in)sensitivity of neural language understanding\nmodels to varying degree of perturbations.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 13:34:20 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Clouatre", "Louis", ""], ["Parthasarathi", "Prasanna", ""], ["Zouaq", "Amal", ""], ["Chandar", "Sarath", ""]]}, {"id": "2107.13973", "submitter": "Rushali Grandhe", "authors": "Farha Al Breiki, Muhammad Ridzuan, Rushali Grandhe", "title": "Self-Supervised Learning for Fine-Grained Image Classification", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-grained image classification involves identifying different\nsubcategories of a class which possess very subtle discriminatory features.\nFine-grained datasets usually provide bounding box annotations along with class\nlabels to aid the process of classification. However, building large scale\ndatasets with such annotations is a mammoth task. Moreover, this extensive\nannotation is time-consuming and often requires expertise, which is a huge\nbottleneck in building large datasets. On the other hand, self-supervised\nlearning (SSL) exploits the freely available data to generate supervisory\nsignals which act as labels. The features learnt by performing some pretext\ntasks on huge unlabelled data proves to be very helpful for multiple downstream\ntasks.\n  Our idea is to leverage self-supervision such that the model learns useful\nrepresentations of fine-grained image classes. We experimented with 3 kinds of\nmodels: Jigsaw solving as pretext task, adversarial learning (SRGAN) and\ncontrastive learning based (SimCLR) model. The learned features are used for\ndownstream tasks such as fine-grained image classification. Our code is\navailable at\nhttp://github.com/rush2406/Self-Supervised-Learning-for-Fine-grained-Image-Classification\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 14:01:31 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Breiki", "Farha Al", ""], ["Ridzuan", "Muhammad", ""], ["Grandhe", "Rushali", ""]]}, {"id": "2107.13977", "submitter": "Martin Zaefferer", "authors": "J\\\"org Stork, Philip Wenzel, Severin Landwein, Maria-Elena Algorri,\n  Martin Zaefferer, Wolfgang Kusch, Martin Staubach, Thomas Bartz-Beielstein,\n  Hartmut K\\\"ohn, Hermann Dejager, Christian Wolf", "title": "Underwater Acoustic Networks for Security Risk Assessment in Public\n  Drinking Water Reservoirs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have built a novel system for the surveillance of drinking water\nreservoirs using underwater sensor networks. We implement an innovative\nAI-based approach to detect, classify and localize underwater events. In this\npaper, we describe the technology and cognitive AI architecture of the system\nbased on one of the sensor networks, the hydrophone network. We discuss the\nchallenges of installing and using the hydrophone network in a water reservoir\nwhere traffic, visitors, and variable water conditions create a complex,\nvarying environment. Our AI solution uses an autoencoder for unsupervised\nlearning of latent encodings for classification and anomaly detection, and time\ndelay estimates for sound localization. Finally, we present the results of\nexperiments carried out in a laboratory pool and the water reservoir and\ndiscuss the system's potential.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 14:02:51 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Stork", "J\u00f6rg", ""], ["Wenzel", "Philip", ""], ["Landwein", "Severin", ""], ["Algorri", "Maria-Elena", ""], ["Zaefferer", "Martin", ""], ["Kusch", "Wolfgang", ""], ["Staubach", "Martin", ""], ["Bartz-Beielstein", "Thomas", ""], ["K\u00f6hn", "Hartmut", ""], ["Dejager", "Hermann", ""], ["Wolf", "Christian", ""]]}, {"id": "2107.13994", "submitter": "Wenkang Shan", "authors": "Wenkang Shan, Haopeng Lu, Shanshe Wang, Xinfeng Zhang, Wen Gao", "title": "Improving Robustness and Accuracy via Relative Information Encoding in\n  3D Human Pose Estimation", "comments": "In Proceedings of the 29th ACM International Conference on Multimedia\n  (MM '21)", "journal-ref": null, "doi": "10.1145/3474085.3475504", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing 3D human pose estimation approaches mainly focus on\npredicting 3D positional relationships between the root joint and other human\njoints (local motion) instead of the overall trajectory of the human body\n(global motion). Despite the great progress achieved by these approaches, they\nare not robust to global motion, and lack the ability to accurately predict\nlocal motion with a small movement range. To alleviate these two problems, we\npropose a relative information encoding method that yields positional and\ntemporal enhanced representations. Firstly, we encode positional information by\nutilizing relative coordinates of 2D poses to enhance the consistency between\nthe input and output distribution. The same posture with different absolute 2D\npositions can be mapped to a common representation. It is beneficial to resist\nthe interference of global motion on the prediction results. Second, we encode\ntemporal information by establishing the connection between the current pose\nand other poses of the same person within a period of time. More attention will\nbe paid to the movement changes before and after the current pose, resulting in\nbetter prediction performance on local motion with a small movement range. The\nablation studies validate the effectiveness of the proposed relative\ninformation encoding method. Besides, we introduce a multi-stage optimization\nmethod to the whole framework to further exploit the positional and temporal\nenhanced representations. Our method outperforms state-of-the-art methods on\ntwo public datasets. Code is available at\nhttps://github.com/paTRICK-swk/Pose3D-RIE.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 14:12:19 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Shan", "Wenkang", ""], ["Lu", "Haopeng", ""], ["Wang", "Shanshe", ""], ["Zhang", "Xinfeng", ""], ["Gao", "Wen", ""]]}, {"id": "2107.13998", "submitter": "Michael Lyons", "authors": "Michael J. Lyons", "title": "\"Excavating AI\" Re-excavated: Debunking a Fallacious Account of the\n  JAFFE Dataset", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twenty-five years ago, my colleagues Miyuki Kamachi and Jiro Gyoba and I\ndesigned and photographed JAFFE, a set of facial expression images intended for\nuse in a study of face perception. In 2019, without seeking permission or\ninforming us, Kate Crawford and Trevor Paglen exhibited JAFFE in two widely\npublicized art shows. In addition, they published a nonfactual account of the\nimages in the essay \"Excavating AI: The Politics of Images in Machine Learning\nTraining Sets.\" The present article recounts the creation of the JAFFE dataset\nand unravels each of Crawford and Paglen's fallacious statements. I also\ndiscuss JAFFE more broadly in connection with research on facial expression,\naffective computing, and human-computer interaction.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 01:31:59 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Lyons", "Michael J.", ""]]}, {"id": "2107.14000", "submitter": "Luyu Qiu", "authors": "Luyu Qiu, Yi Yang, Caleb Chen Cao, Jing Liu, Yueyuan Zheng, Hilary Hei\n  Ting Ngai, Janet Hsiao, Lei Chen", "title": "Resisting Out-of-Distribution Data Problem in Perturbation of XAI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of eXplainable Artificial Intelligence (XAI),\nperturbation-based XAI algorithms have become quite popular due to their\neffectiveness and ease of implementation. The vast majority of\nperturbation-based XAI techniques face the challenge of Out-of-Distribution\n(OoD) data -- an artifact of randomly perturbed data becoming inconsistent with\nthe original dataset. OoD data leads to the over-confidence problem in model\npredictions, making the existing XAI approaches unreliable. To our best\nknowledge, the OoD data problem in perturbation-based XAI algorithms has not\nbeen adequately addressed in the literature. In this work, we address this OoD\ndata problem by designing an additional module quantifying the affinity between\nthe perturbed data and the original dataset distribution, which is integrated\ninto the process of aggregation. Our solution is shown to be compatible with\nthe most popular perturbation-based XAI algorithms, such as RISE, OCCLUSION,\nand LIME. Experiments have confirmed that our methods demonstrate a significant\nimprovement in general cases using both computational and cognitive metrics.\nEspecially in the case of degradation, our proposed approach demonstrates\noutstanding performance comparing to baselines. Besides, our solution also\nresolves a fundamental problem with the faithfulness indicator, a commonly used\nevaluation metric of XAI algorithms that appears to be sensitive to the OoD\nissue.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 08:29:46 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Qiu", "Luyu", ""], ["Yang", "Yi", ""], ["Cao", "Caleb Chen", ""], ["Liu", "Jing", ""], ["Zheng", "Yueyuan", ""], ["Ngai", "Hilary Hei Ting", ""], ["Hsiao", "Janet", ""], ["Chen", "Lei", ""]]}, {"id": "2107.14028", "submitter": "Agni Kumar", "authors": "Agni Kumar, Vikramjit Mitra, Carolyn Oliver, Adeeti Ullal, Matt\n  Biddulph, Irida Mance", "title": "Estimating Respiratory Rate From Breath Audio Obtained Through Wearable\n  Microphones", "comments": "International Conference of the IEEE Engineering in Medicine and\n  Biology Society (EMBC) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Respiratory rate (RR) is a clinical metric used to assess overall health and\nphysical fitness. An individual's RR can change from their baseline due to\nchronic illness symptoms (e.g., asthma, congestive heart failure), acute\nillness (e.g., breathlessness due to infection), and over the course of the day\ndue to physical exhaustion during heightened exertion. Remote estimation of RR\ncan offer a cost-effective method to track disease progression and\ncardio-respiratory fitness over time. This work investigates a model-driven\napproach to estimate RR from short audio segments obtained after physical\nexertion in healthy adults. Data was collected from 21 individuals using\nmicrophone-enabled, near-field headphones before, during, and after strenuous\nexercise. RR was manually annotated by counting perceived inhalations and\nexhalations. A multi-task Long-Short Term Memory (LSTM) network with\nconvolutional layers was implemented to process mel-filterbank energies,\nestimate RR in varying background noise conditions, and predict heavy\nbreathing, indicated by an RR of more than 25 breaths per minute. The\nmulti-task model performs both classification and regression tasks and\nleverages a mixture of loss functions. It was observed that RR can be estimated\nwith a concordance correlation coefficient (CCC) of 0.76 and a mean squared\nerror (MSE) of 0.2, demonstrating that audio can be a viable signal for\napproximating RR.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 17:24:44 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Kumar", "Agni", ""], ["Mitra", "Vikramjit", ""], ["Oliver", "Carolyn", ""], ["Ullal", "Adeeti", ""], ["Biddulph", "Matt", ""], ["Mance", "Irida", ""]]}, {"id": "2107.14037", "submitter": "Gutta Jignesh Chowdary Mr", "authors": "G Jignesh Chowdary, Suganya G, Premalatha M, Asnath Victy Phamila Y,\n  Karunamurthy K", "title": "Machine Learning and Deep Learning Methods for Building Intelligent\n  Systems in Medicine and Drug Discovery: A Comprehensive Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  With the advancements in computer technology, there is a rapid development of\nintelligent systems to understand the complex relationships in data to make\npredictions and classifications. Artificail Intelligence based framework is\nrapidly revolutionizing the healthcare industry. These intelligent systems are\nbuilt with machine learning and deep learning based robust models for early\ndiagnosis of diseases and demonstrates a promising supplementary diagnostic\nmethod for frontline clinical doctors and surgeons. Machine Learning and Deep\nLearning based systems can streamline and simplify the steps involved in\ndiagnosis of diseases from clinical and image-based data, thus providing\nsignificant clinician support and workflow optimization. They mimic human\ncognition and are even capable of diagnosing diseases that cannot be diagnosed\nwith human intelligence. This paper focuses on the survey of machine learning\nand deep learning applications in across 16 medical specialties, namely Dental\nmedicine, Haematology, Surgery, Cardiology, Pulmonology, Orthopedics,\nRadiology, Oncology, General medicine, Psychiatry, Endocrinology, Neurology,\nDermatology, Hepatology, Nephrology, Ophthalmology, and Drug discovery. In this\npaper along with the survey, we discuss the advancements of medical practices\nwith these systems and also the impact of these systems on medical\nprofessionals.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:26:03 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Chowdary", "G Jignesh", ""], ["G", "Suganya", ""], ["M", "Premalatha", ""], ["Y", "Asnath Victy Phamila", ""], ["K", "Karunamurthy", ""]]}, {"id": "2107.14042", "submitter": "Alexis Baria", "authors": "Alexis T. Baria (1) and Keith Cross (2) ((1) Society of Spoken Art,\n  New York, USA, (2) University of Hawai`i at Manoa, Honolulu, USA)", "title": "The brain is a computer is a brain: neuroscience's internal debate and\n  the social significance of the Computational Metaphor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Computational Metaphor, comparing the brain to the computer and vice\nversa, is the most prominent metaphor in neuroscience and artificial\nintelligence (AI). Its appropriateness is highly debated in both fields,\nparticularly with regards to whether it is useful for the advancement of\nscience and technology. Considerably less attention, however, has been devoted\nto how the Computational Metaphor is used outside of the lab, and particularly\nhow it may shape society's interactions with AI. As such, recently publicized\nconcerns over AI's role in perpetuating racism, genderism, and ableism suggest\nthat the term \"artificial intelligence\" is misplaced, and that a new lexicon is\nneeded to describe these computational systems. Thus, there is an essential\nquestion about the Computational Metaphor that is rarely asked by\nneuroscientists: whom does it help and whom does it harm? This essay invites\nthe neuroscience community to consider the social implications of the field's\nmost controversial metaphor.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 12:13:05 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Baria", "Alexis T.", ""], ["Cross", "Keith", ""]]}, {"id": "2107.14044", "submitter": "Ramya Akula", "authors": "Ramya Akula and Ivan Garibay", "title": "Ethical AI for Social Good", "comments": null, "journal-ref": "International Conference on Human-Computer Interaction, 2021", "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The concept of AI for Social Good(AI4SG) is gaining momentum in both\ninformation societies and the AI community. Through all the advancement of\nAI-based solutions, it can solve societal issues effectively. To date, however,\nthere is only a rudimentary grasp of what constitutes AI socially beneficial in\nprinciple, what constitutes AI4SG in reality, and what are the policies and\nregulations needed to ensure it. This paper fills the vacuum by addressing the\nethical aspects that are critical for future AI4SG efforts. Some of these\ncharacteristics are new to AI, while others have greater importance due to its\nusage.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 15:16:51 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Akula", "Ramya", ""], ["Garibay", "Ivan", ""]]}, {"id": "2107.14052", "submitter": "Susan Von Struensee", "authors": "Susan von Struensee", "title": "The Role of Social Movements, Coalitions, and Workers in Resisting\n  Harmful Artificial Intelligence and Contributing to the Development of\n  Responsible AI", "comments": "184 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is mounting public concern over the influence that AI based systems has\nin our society. Coalitions in all sectors are acting worldwide to resist hamful\napplications of AI. From indigenous people addressing the lack of reliable\ndata, to smart city stakeholders, to students protesting the academic\nrelationships with sex trafficker and MIT donor Jeffery Epstein, the\nquestionable ethics and values of those heavily investing in and profiting from\nAI are under global scrutiny. There are biased, wrongful, and disturbing\nassumptions embedded in AI algorithms that could get locked in without\nintervention. Our best human judgment is needed to contain AI's harmful impact.\nPerhaps one of the greatest contributions of AI will be to make us ultimately\nunderstand how important human wisdom truly is in life on earth.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 18:51:29 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["von Struensee", "Susan", ""]]}, {"id": "2107.14053", "submitter": "Eugene Lee", "authors": "Eugene Lee, Cheng-Han Huang, Chen-Yi Lee", "title": "Few-Shot and Continual Learning with Attentive Independent Mechanisms", "comments": "20 pages, 44 figures, accepted by International Conference of\n  Computer Vision 2021 (ICCV 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep neural networks (DNNs) are known to perform well when deployed to test\ndistributions that shares high similarity with the training distribution.\nFeeding DNNs with new data sequentially that were unseen in the training\ndistribution has two major challenges -- fast adaptation to new tasks and\ncatastrophic forgetting of old tasks. Such difficulties paved way for the\non-going research on few-shot learning and continual learning. To tackle these\nproblems, we introduce Attentive Independent Mechanisms (AIM). We incorporate\nthe idea of learning using fast and slow weights in conjunction with the\ndecoupling of the feature extraction and higher-order conceptual learning of a\nDNN. AIM is designed for higher-order conceptual learning, modeled by a mixture\nof experts that compete to learn independent concepts to solve a new task. AIM\nis a modular component that can be inserted into existing deep learning\nframeworks. We demonstrate its capability for few-shot learning by adding it to\nSIB and trained on MiniImageNet and CIFAR-FS, showing significant improvement.\nAIM is also applied to ANML and OML trained on Omniglot, CIFAR-100 and\nMiniImageNet to demonstrate its capability in continual learning. Code made\npublicly available at https://github.com/huang50213/AIM-Fewshot-Continual.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 14:43:24 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Lee", "Eugene", ""], ["Huang", "Cheng-Han", ""], ["Lee", "Chen-Yi", ""]]}, {"id": "2107.14061", "submitter": "Aditya Jyoti Paul", "authors": "Aditya Jyoti Paul", "title": "The Need and Status of Sea Turtle Conservation and Survey of Associated\n  Computer Vision Advances", "comments": "Currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For over hundreds of millions of years, sea turtles and their ancestors have\nswum in the vast expanses of the ocean. They have undergone a number of\nevolutionary changes, leading to speciation and sub-speciation. However, in the\npast few decades, some of the most notable forces driving the genetic variance\nand population decline have been global warming and anthropogenic impact\nranging from large-scale poaching, collecting turtle eggs for food, besides\ndumping trash including plastic waste into the ocean. This leads to severe\ndetrimental effects in the sea turtle population, driving them to extinction.\nThis research focusses on the forces causing the decline in sea turtle\npopulation, the necessity for the global conservation efforts along with its\nsuccesses and failures, followed by an in-depth analysis of the modern advances\nin detection and recognition of sea turtles, involving Machine Learning and\nComputer Vision systems, aiding the conservation efforts.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 14:53:47 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Paul", "Aditya Jyoti", ""]]}, {"id": "2107.14062", "submitter": "Leonardo Scabini", "authors": "Leonardo F. S. Scabini and Odemir M. Bruno", "title": "Structure and Performance of Fully Connected Neural Networks: Emerging\n  Complex Network Properties", "comments": "18 pages, 7 figures, and 2 tables. Submitted to a peer-review journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV physics.app-ph physics.comp-ph", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Understanding the behavior of Artificial Neural Networks is one of the main\ntopics in the field recently, as black-box approaches have become usual since\nthe widespread of deep learning. Such high-dimensional models may manifest\ninstabilities and weird properties that resemble complex systems. Therefore, we\npropose Complex Network (CN) techniques to analyze the structure and\nperformance of fully connected neural networks. For that, we build a dataset\nwith 4 thousand models and their respective CN properties. They are employed in\na supervised classification setup considering four vision benchmarks. Each\nneural network is approached as a weighted and undirected graph of neurons and\nsynapses, and centrality measures are computed after training. Results show\nthat these measures are highly related to the network classification\nperformance. We also propose the concept of Bag-Of-Neurons (BoN), a CN-based\napproach for finding topological signatures linking similar neurons. Results\nsuggest that six neuronal types emerge in such networks, independently of the\ntarget domain, and are distributed differently according to classification\naccuracy. We also tackle specific CN properties related to performance, such as\nhigher subgraph centrality on lower-performing models. Our findings suggest\nthat CN properties play a critical role in the performance of fully connected\nneural networks, with topological patterns emerging independently on a wide\nrange of models.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 14:53:52 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Scabini", "Leonardo F. S.", ""], ["Bruno", "Odemir M.", ""]]}, {"id": "2107.14070", "submitter": "Aditya Jyoti Paul", "authors": "Aditya Jyoti Paul, Smaranjit Ghose, Kanishka Aggarwal, Niketha\n  Nethaji, Shivam Pal, Arnab Dutta Purkayastha", "title": "Machine Learning Advances aiding Recognition and Classification of\n  Indian Monuments and Landmarks", "comments": "Currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CY cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tourism in India plays a quintessential role in the country's economy with an\nestimated 9.2% GDP share for the year 2018. With a yearly growth rate of 6.2%,\nthe industry holds a huge potential for being the primary driver of the economy\nas observed in the nations of the Middle East like the United Arab Emirates.\nThe historical and cultural diversity exhibited throughout the geography of the\nnation is a unique spectacle for people around the world and therefore serves\nto attract tourists in tens of millions in number every year. Traditionally,\ntour guides or academic professionals who study these heritage monuments were\nresponsible for providing information to the visitors regarding their\narchitectural and historical significance. However, unfortunately this system\nhas several caveats when considered on a large scale such as unavailability of\nsufficient trained people, lack of accurate information, failure to convey the\nrichness of details in an attractive format etc. Recently, machine learning\napproaches revolving around the usage of monument pictures have been shown to\nbe useful for rudimentary analysis of heritage sights. This paper serves as a\nsurvey of the research endeavors undertaken in this direction which would\neventually provide insights for building an automated decision system that\ncould be utilized to make the experience of tourism in India more modernized\nfor visitors.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 15:01:02 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Paul", "Aditya Jyoti", ""], ["Ghose", "Smaranjit", ""], ["Aggarwal", "Kanishka", ""], ["Nethaji", "Niketha", ""], ["Pal", "Shivam", ""], ["Purkayastha", "Arnab Dutta", ""]]}, {"id": "2107.14077", "submitter": "Soaad Hossain Mr", "authors": "Soraia Oueida, Soaad Hossain, Yehia Kotb, Syed Ishtiaque Ahmed", "title": "A Fair and Ethical Healthcare Artificial Intelligence System for\n  Monitoring Driver Behavior and Preventing Road Accidents", "comments": "12 pages, 2 figures, accepted to Future Technologies Conference (FTC\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach to prevent transportation accidents and\nmonitor driver's behavior using a healthcare AI system that incorporates\nfairness and ethics. Dangerous medical cases and unusual behavior of the driver\nare detected. Fairness algorithm is approached in order to improve\ndecision-making and address ethical issues such as privacy issues, and to\nconsider challenges that appear in the wild within AI in healthcare and\ndriving. A healthcare professional will be alerted about any unusual activity,\nand the driver's location when necessary, is provided in order to enable the\nhealthcare professional to immediately help to the unstable driver. Therefore,\nusing the healthcare AI system allows for accidents to be predicted and thus\nprevented and lives may be saved based on the built-in AI system inside the\nvehicle which interacts with the ER system.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 20:23:42 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Oueida", "Soraia", ""], ["Hossain", "Soaad", ""], ["Kotb", "Yehia", ""], ["Ahmed", "Syed Ishtiaque", ""]]}, {"id": "2107.14093", "submitter": "Elena Baninemeh", "authors": "Elena Baninemeh (1), Siamak Farshidi (2), Slinger Jansen (1) ((1)\n  Department of Information and Computer Science at Utrecht University,\n  Utrecht, the Netherlands, (2) Informatics Institute at University of\n  Amsterdam, Amsterdam, the Netherlands)", "title": "A Decision Model for Decentralized Autonomous Organization Platform\n  Selection: Three Industry Case Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized autonomous organizations as a new form of online governance\narecollections of smart contracts deployed on a blockchain platform that\nintercede groupsof people. A growing number of Decentralized Autonomous\nOrganization Platforms,such as Aragon and Colony, have been introduced in the\nmarket to facilitate thedevelopment process of such organizations. Selecting\nthe best fitting platform ischallenging for the organizations, as a significant\nnumber of decision criteria, such aspopularity, developer availability,\ngovernance issues, and consistent documentation ofsuch platforms, should be\nconsidered. Additionally, decision-makers at theorganizations are not experts\nin every domain, so they must continuously acquirevolatile knowledge regarding\nsuch platforms and keep themselves updated.Accordingly, a decision model is\nrequired to analyze the decision criteria usingsystematic identification and\nevaluation of potential alternative solutions for adevelopment project. We have\ndeveloped a theoretical framework to assist softwareengineers with a set of\nMulti-Criteria Decision-Making problems in software production.This study\npresents a decision model as a Multi-Criteria Decision-Making problem forthe\ndecentralized autonomous organization platform selection problem. Weconducted\nthree industry case studies in the context of three decentralizedautonomous\norganizations to evaluate the effectiveness and efficiency of the decisionmodel\nin assisting decision-makers.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 10:05:56 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Baninemeh", "Elena", ""], ["Farshidi", "Siamak", ""], ["Jansen", "Slinger", ""]]}, {"id": "2107.14199", "submitter": "Hritam Basak", "authors": "Hritam Basak, Mayukhmali Das, Susmita Modak", "title": "RSO: A Novel Reinforced Swarm Optimization Algorithm for Feature\n  Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Swarm optimization algorithms are widely used for feature selection before\ndata mining and machine learning applications. The metaheuristic\nnature-inspired feature selection approaches are used for single-objective\noptimization tasks, though the major problem is their frequent premature\nconvergence, leading to weak contribution to data mining. In this paper, we\npropose a novel feature selection algorithm named Reinforced Swarm Optimization\n(RSO) leveraging some of the existing problems in feature selection. This\nalgorithm embeds the widely used Bee Swarm Optimization (BSO) algorithm along\nwith Reinforcement Learning (RL) to maximize the reward of a superior search\nagent and punish the inferior ones. This hybrid optimization algorithm is more\nadaptive and robust with a good balance between exploitation and exploration of\nthe search space. The proposed method is evaluated on 25 widely known UCI\ndatasets containing a perfect blend of balanced and imbalanced data. The\nobtained results are compared with several other popular and recent feature\nselection algorithms with similar classifier configurations. The experimental\noutcome shows that our proposed model outperforms BSO in 22 out of 25 instances\n(88%). Moreover, experimental results also show that RSO performs the best\namong all the methods compared in this paper in 19 out of 25 cases (76%),\nestablishing the superiority of our proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 17:38:04 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Basak", "Hritam", ""], ["Das", "Mayukhmali", ""], ["Modak", "Susmita", ""]]}, {"id": "2107.14203", "submitter": "Lingjiao Chen", "authors": "Lingjiao Chen, Tracy Cai, Matei Zaharia, James Zou", "title": "Did the Model Change? Efficiently Assessing Machine Learning API Shifts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) prediction APIs are increasingly widely used. An ML API\ncan change over time due to model updates or retraining. This presents a key\nchallenge in the usage of the API because it is often not clear to the user if\nand how the ML model has changed. Model shifts can affect downstream\napplication performance and also create oversight issues (e.g. if consistency\nis desired). In this paper, we initiate a systematic investigation of ML API\nshifts. We first quantify the performance shifts from 2020 to 2021 of popular\nML APIs from Google, Microsoft, Amazon, and others on a variety of datasets. We\nidentified significant model shifts in 12 out of 36 cases we investigated.\nInterestingly, we found several datasets where the API's predictions became\nsignificantly worse over time. This motivated us to formulate the API shift\nassessment problem at a more fine-grained level as estimating how the API\nmodel's confusion matrix changes over time when the data distribution is\nconstant. Monitoring confusion matrix shifts using standard random sampling can\nrequire a large number of samples, which is expensive as each API call costs a\nfee. We propose a principled adaptive sampling algorithm, MASA, to efficiently\nestimate confusion matrix shifts. MASA can accurately estimate the confusion\nmatrix shifts in commercial ML APIs using up to 90% fewer samples compared to\nrandom sampling. This work establishes ML API shifts as an important problem to\nstudy and provides a cost-effective approach to monitor such shifts.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 17:41:53 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Chen", "Lingjiao", ""], ["Cai", "Tracy", ""], ["Zaharia", "Matei", ""], ["Zou", "James", ""]]}, {"id": "2107.14226", "submitter": "Dj Strouse", "authors": "DJ Strouse, Kate Baumli, David Warde-Farley, Vlad Mnih, Steven Hansen", "title": "Learning more skills through optimistic exploration", "comments": "Steven Hansen and DJ Strouse contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised skill learning objectives (Gregor et al., 2016, Eysenbach et\nal., 2018) allow agents to learn rich repertoires of behavior in the absence of\nextrinsic rewards. They work by simultaneously training a policy to produce\ndistinguishable latent-conditioned trajectories, and a discriminator to\nevaluate distinguishability by trying to infer latents from trajectories. The\nhope is for the agent to explore and master the environment by encouraging each\nskill (latent) to reliably reach different states. However, an inherent\nexploration problem lingers: when a novel state is actually encountered, the\ndiscriminator will necessarily not have seen enough training data to produce\naccurate and confident skill classifications, leading to low intrinsic reward\nfor the agent and effective penalization of the sort of exploration needed to\nactually maximize the objective. To combat this inherent pessimism towards\nexploration, we derive an information gain auxiliary objective that involves\ntraining an ensemble of discriminators and rewarding the policy for their\ndisagreement. Our objective directly estimates the epistemic uncertainty that\ncomes from the discriminator not having seen enough training examples, thus\nproviding an intrinsic reward more tailored to the true objective compared to\npseudocount-based methods (Burda et al., 2019). We call this exploration bonus\ndiscriminator disagreement intrinsic reward, or DISDAIN. We demonstrate\nempirically that DISDAIN improves skill learning both in a tabular grid world\n(Four Rooms) and the 57 games of the Atari Suite (from pixels). Thus, we\nencourage researchers to treat pessimism with DISDAIN.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 17:58:04 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Strouse", "DJ", ""], ["Baumli", "Kate", ""], ["Warde-Farley", "David", ""], ["Mnih", "Vlad", ""], ["Hansen", "Steven", ""]]}, {"id": "2107.14229", "submitter": "Fabio Pizzati", "authors": "Fabio Pizzati, Pietro Cerri, Raoul de Charette", "title": "Guided Disentanglement in Generative Networks", "comments": "Journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image-to-image translation (i2i) networks suffer from entanglement effects in\npresence of physics-related phenomena in target domain (such as occlusions,\nfog, etc), thus lowering the translation quality and variability. In this\npaper, we present a comprehensive method for disentangling physics-based traits\nin the translation, guiding the learning process with neural or physical\nmodels. For the latter, we integrate adversarial estimation and genetic\nalgorithms to correctly achieve disentanglement. The results show our approach\ndramatically increase performances in many challenging scenarios for image\ntranslation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 17:59:31 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Pizzati", "Fabio", ""], ["Cerri", "Pietro", ""], ["de Charette", "Raoul", ""]]}]