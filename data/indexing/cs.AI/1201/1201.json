[{"id": "1201.0216", "submitter": "Feng Xia", "authors": "Feng Xia and Jianhua Ma", "title": "Building Smart Communities with Cyber-Physical Systems", "comments": "ACM UBICOMP Symposium on Social and Community Intelligence (SCI),\n  Beijing, China, September 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing trend towards the convergence of cyber-physical systems\n(CPS) and social computing, which will lead to the emergence of smart\ncommunities composed of various objects (including both human individuals and\nphysical things) that interact and cooperate with each other. These smart\ncommunities promise to enable a number of innovative applications and services\nthat will improve the quality of life. This position paper addresses some\nopportunities and challenges of building smart communities characterized by\ncyber-physical and social intelligence.\n", "versions": [{"version": "v1", "created": "Sat, 31 Dec 2011 03:19:14 GMT"}], "update_date": "2012-01-04", "authors_parsed": [["Xia", "Feng", ""], ["Ma", "Jianhua", ""]]}, {"id": "1201.0328", "submitter": "Emanuel Diamant", "authors": "Emanuel Diamant", "title": "Let us first agree on what the term \"semantics\" means: An unorthodox\n  approach to an age-old debate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, semantics has been seen as a feature of human language. The\nadvent of the information era has led to its widespread redefinition as an\ninformation feature. Contrary to this praxis, I define semantics as a special\nkind of information. Revitalizing the ideas of Bar-Hillel and Carnap I have\nrecreated and re-established the notion of semantics as the notion of Semantic\nInformation. I have proposed a new definition of information (as a description,\na linguistic text, a piece of a story or a tale) and a clear segregation\nbetween two different types of information - physical and semantic information.\nI hope, I have clearly explained the (usually obscured and mysterious)\ninterrelations between data and physical information as well as the relation\nbetween physical information and semantic information. Consequently, usually\nindefinable notions of \"information\", \"knowledge\", \"memory\", \"learning\" and\n\"semantics\" have also received their suitable illumination and explanation.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jan 2012 04:25:20 GMT"}], "update_date": "2012-01-05", "authors_parsed": [["Diamant", "Emanuel", ""]]}, {"id": "1201.0414", "submitter": "Xuechong Guan", "authors": "Xuechong Guan and Yongming Li", "title": "Continuity in Information Algebras", "comments": null, "journal-ref": null, "doi": "10.1142/S0218488512500304", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper, the continuity and strong continuity in domain-free\ninformation algebras and labeled information algebras are introduced\nrespectively. A more general concept of continuous function which is defined\nbetween two domain-free continuous information algebras is presented. It is\nshown that, with the operations combination and focusing, the set of all\ncontinuous functions between two domain-free s-continuous information algebras\nforms a new s-continuous information algebra. By studying the relationship\nbetween domain-free information algebras and labeled information algebras, it\nis demonstrated that they do correspond to each other on s-compactness.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2012 02:40:12 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["Guan", "Xuechong", ""], ["Li", "Yongming", ""]]}, {"id": "1201.0478", "submitter": "Wolfgang Dvo\\v{r}\\'ak", "authors": "Wolfgang Dvo\\v{r}\\'ak", "title": "Technical Note: Exploring \\Sigma^P_2 / \\Pi^P_2-hardness for\n  Argumentation Problems with fixed distance to tractable classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of reasoning in abstracts argumentation frameworks\nclose to graph classes that allow for efficient reasoning methods, i.e.\\ to one\nof the classes of acyclic, noeven, biparite and symmetric AFs. In this work we\nshow that certain reasoning problems on the second level of the polynomial\nhierarchy still maintain their full complexity when restricted to instances of\nfixed distance to one of the above graph classes.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2012 14:59:11 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Dvo\u0159\u00e1k", "Wolfgang", ""]]}, {"id": "1201.0564", "submitter": "Toby Walsh", "authors": "Ronald de Haan, Nina Narodytska, Toby Walsh", "title": "The RegularGcc Matrix Constraint", "comments": "Submitted to CPAIOR 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study propagation of the RegularGcc global constraint. This ensures that\neach row of a matrix of decision variables satisfies a Regular constraint, and\neach column satisfies a Gcc constraint. On the negative side, we prove that\npropagation is NP-hard even under some strong restrictions (e.g. just 3 values,\njust 4 states in the automaton, or just 5 columns to the matrix). On the\npositive side, we identify two cases where propagation is fixed parameter\ntractable. In addition, we show how to improve propagation over a simple\ndecomposition into separate Regular and Gcc constraints by identifying some\nnecessary but insufficient conditions for a solution. We enforce these\nconditions with some additional weighted row automata. Experimental results\ndemonstrate the potential of these methods on some standard benchmark problems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2012 03:30:18 GMT"}], "update_date": "2016-11-26", "authors_parsed": [["de Haan", "Ronald", ""], ["Narodytska", "Nina", ""], ["Walsh", "Toby", ""]]}, {"id": "1201.0856", "submitter": "Manuel Bodirsky", "authors": "Manuel Bodirsky", "title": "Complexity Classification in Infinite-Domain Constraint Satisfaction", "comments": "M\\'emoire pour l'obtention d'une HDR \\`a l'universit\\'e Paris 7. 265\n  pages. Version 2 has been prepared after the defence, and contains the\n  official header with information about the HDR jury. Version 10: some more\n  mistakes have been removed. This is the final version of the text, it will no\n  longer be updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.DM cs.LO math.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A constraint satisfaction problem (CSP) is a computational problem where the\ninput consists of a finite set of variables and a finite set of constraints,\nand where the task is to decide whether there exists a satisfying assignment of\nvalues to the variables. Depending on the type of constraints that we allow in\nthe input, a CSP might be tractable, or computationally hard. In recent years,\ngeneral criteria have been discovered that imply that a CSP is polynomial-time\ntractable, or that it is NP-hard. Finite-domain CSPs have become a major common\nresearch focus of graph theory, artificial intelligence, and finite model\ntheory. It turned out that the key questions for complexity classification of\nCSPs are closely linked to central questions in universal algebra.\n  This thesis studies CSPs where the variables can take values from an infinite\ndomain. This generalization enhances dramatically the range of computational\nproblems that can be modeled as a CSP. Many problems from areas that have so\nfar seen no interaction with constraint satisfaction theory can be formulated\nusing infinite domains, e.g. problems from temporal and spatial reasoning,\nphylogenetic reconstruction, and operations research.\n  It turns out that the universal-algebraic approach can also be applied to\nstudy large classes of infinite-domain CSPs, yielding elegant complexity\nclassification results. A new tool in this thesis that becomes relevant\nparticularly for infinite domains is Ramsey theory. We demonstrate the\nfeasibility of our approach with two complete complexity classification\nresults: one on CSPs in temporal reasoning, the other on a generalization of\nSchaefer's theorem for propositional logic to logic over graphs. We also study\nthe limits of complexity classification, and present classes of computational\nproblems provably do not exhibit a complexity dichotomy into hard and easy\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2012 09:39:46 GMT"}, {"version": "v10", "created": "Sat, 20 Apr 2019 07:03:06 GMT"}, {"version": "v2", "created": "Mon, 20 Feb 2012 22:21:28 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2012 08:40:59 GMT"}, {"version": "v4", "created": "Thu, 20 Jun 2013 21:36:07 GMT"}, {"version": "v5", "created": "Sat, 13 Jun 2015 06:56:24 GMT"}, {"version": "v6", "created": "Sat, 29 Aug 2015 06:57:29 GMT"}, {"version": "v7", "created": "Mon, 7 Dec 2015 15:33:28 GMT"}, {"version": "v8", "created": "Wed, 14 Sep 2016 14:41:07 GMT"}, {"version": "v9", "created": "Tue, 5 Sep 2017 11:20:55 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Bodirsky", "Manuel", ""]]}, {"id": "1201.0979", "submitter": "Sanjit Seshia", "authors": "Sanjit A. Seshia", "title": "Sciduction: Combining Induction, Deduction, and Structure for\n  Verification and Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even with impressive advances in automated formal methods, certain problems\nin system verification and synthesis remain challenging. Examples include the\nverification of quantitative properties of software involving constraints on\ntiming and energy consumption, and the automatic synthesis of systems from\nspecifications. The major challenges include environment modeling,\nincompleteness in specifications, and the complexity of underlying decision\nproblems.\n  This position paper proposes sciduction, an approach to tackle these\nchallenges by integrating inductive inference, deductive reasoning, and\nstructure hypotheses. Deductive reasoning, which leads from general rules or\nconcepts to conclusions about specific problem instances, includes techniques\nsuch as logical inference and constraint solving. Inductive inference, which\ngeneralizes from specific instances to yield a concept, includes algorithmic\nlearning from examples. Structure hypotheses are used to define the class of\nartifacts, such as invariants or program fragments, generated during\nverification or synthesis. Sciduction constrains inductive and deductive\nreasoning using structure hypotheses, and actively combines inductive and\ndeductive reasoning: for instance, deductive techniques generate examples for\nlearning, and inductive reasoning is used to guide the deductive engines.\n  We illustrate this approach with three applications: (i) timing analysis of\nsoftware; (ii) synthesis of loop-free programs, and (iii) controller synthesis\nfor hybrid systems. Some future applications are also discussed.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2012 19:58:41 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Seshia", "Sanjit A.", ""]]}, {"id": "1201.1409", "submitter": "Yongquan Lai", "authors": "Ranch Y.Q. Lai, Pong C. Yuen, K.W. Lee, J.H. Lai", "title": "Interactive Character Posing by Sparse Coding", "comments": "Submitted to Computer Graphics Forum", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Character posing is of interest in computer animation. It is difficult due to\nits dependence on inverse kinematics (IK) techniques and articulate property of\nhuman characters . To solve the IK problem, classical methods that rely on\nnumerical solutions often suffer from the under-determination problem and can\nnot guarantee naturalness. Existing data-driven methods address this problem by\nlearning from motion capture data. When facing a large variety of poses\nhowever, these methods may not be able to capture the pose styles or be\napplicable in real-time environment. Inspired from the low-rank motion\nde-noising and completion model in \\cite{lai2011motion}, we propose a novel\nmodel for character posing based on sparse coding. Unlike conventional\napproaches, our model directly captures the pose styles in Euclidean space to\nprovide intuitive training error measurements and facilitate pose synthesis. A\npose dictionary is learned in training stage and based on it natural poses are\nsynthesized to satisfy users' constraints . We compare our model with existing\nmodels for tasks of pose de-noising and completion. Experiments show our model\nobtains lower de-noising and completion error. We also provide User\nInterface(UI) examples illustrating that our model is effective for interactive\ncharacter posing.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jan 2012 13:11:01 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Lai", "Ranch Y. Q.", ""], ["Yuen", "Pong C.", ""], ["Lee", "K. W.", ""], ["Lai", "J. H.", ""]]}, {"id": "1201.1657", "submitter": "Chong Wang", "authors": "Chong Wang and David M. Blei", "title": "A Split-Merge MCMC Algorithm for the Hierarchical Dirichlet Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hierarchical Dirichlet process (HDP) has become an important Bayesian\nnonparametric model for grouped data, such as document collections. The HDP is\nused to construct a flexible mixed-membership model where the number of\ncomponents is determined by the data. As for most Bayesian nonparametric\nmodels, exact posterior inference is intractable---practitioners use Markov\nchain Monte Carlo (MCMC) or variational inference. Inspired by the split-merge\nMCMC algorithm for the Dirichlet process (DP) mixture model, we describe a\nnovel split-merge MCMC sampling algorithm for posterior inference in the HDP.\nWe study its properties on both synthetic data and text corpora. We find that\nsplit-merge MCMC for the HDP can provide significant improvements over\ntraditional Gibbs sampling, and we give some understanding of the data\nproperties that give rise to larger improvements.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jan 2012 20:28:42 GMT"}], "update_date": "2012-01-10", "authors_parsed": [["Wang", "Chong", ""], ["Blei", "David M.", ""]]}, {"id": "1201.2004", "submitter": "Md. Amjad Hossain", "authors": "Md. Amjad Hossain, Pintu Chandra Shill, Bishnu Sarker, and Kazuyuki\n  Murase", "title": "Optimal Fuzzy Model Construction with Statistical Information using\n  Genetic Algorithm", "comments": null, "journal-ref": null, "doi": "10.5121/ijcsit.2011.3619", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy rule based models have a capability to approximate any continuous\nfunction to any degree of accuracy on a compact domain. The majority of FLC\ndesign process relies on heuristic knowledge of experience operators. In order\nto make the design process automatic we present a genetic approach to learn\nfuzzy rules as well as membership function parameters. Moreover, several\nstatistical information criteria such as the Akaike information criterion\n(AIC), the Bhansali-Downham information criterion (BDIC), and the\nSchwarz-Rissanen information criterion (SRIC) are used to construct optimal\nfuzzy models by reducing fuzzy rules. A genetic scheme is used to design\nTakagi-Sugeno-Kang (TSK) model for identification of the antecedent rule\nparameters and the identification of the consequent parameters. Computer\nsimulations are presented confirming the performance of the constructed fuzzy\nlogic controller.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2012 10:14:33 GMT"}], "update_date": "2012-01-11", "authors_parsed": [["Hossain", "Md. Amjad", ""], ["Shill", "Pintu Chandra", ""], ["Sarker", "Bishnu", ""], ["Murase", "Kazuyuki", ""]]}, {"id": "1201.2073", "submitter": "Rafi Muhammad", "authors": "Mehwish Aziz, Muhammad Rafi", "title": "Pbm: A new dataset for blog mining", "comments": "6; Internet and Web Engineering from: International Conference on\n  Computer Engineering and Technology, 3rd (ICCET 2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text mining is becoming vital as Web 2.0 offers collaborative content\ncreation and sharing. Now Researchers have growing interest in text mining\nmethods for discovering knowledge. Text mining researchers come from variety of\nareas like: Natural Language Processing, Computational Linguistic, Machine\nLearning, and Statistics. A typical text mining application involves\npreprocessing of text, stemming and lemmatization, tagging and annotation,\nderiving knowledge patterns, evaluating and interpreting the results. There are\nnumerous approaches for performing text mining tasks, like: clustering,\ncategorization, sentimental analysis, and summarization. There is a growing\nneed to standardize the evaluation of these tasks. One major component of\nestablishing standardization is to provide standard datasets for these tasks.\nAlthough there are various standard datasets available for traditional text\nmining tasks, but there are very few and expensive datasets for blog-mining\ntask. Blogs, a new genre in web 2.0 is a digital diary of web user, which has\nchronological entries and contains a lot of useful knowledge, thus offers a lot\nof challenges and opportunities for text mining. In this paper, we report a new\nindigenous dataset for Pakistani Political Blogosphere. The paper describes the\nprocess of data collection, organization, and standardization. We have used\nthis dataset for carrying out various text mining tasks for blogosphere, like:\nblog-search, political sentiments analysis and tracking, identification of\ninfluential blogger, and clustering of the blog-posts. We wish to offer this\ndataset free for others who aspire to pursue further in this domain.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2012 15:18:38 GMT"}], "update_date": "2012-01-11", "authors_parsed": [["Aziz", "Mehwish", ""], ["Rafi", "Muhammad", ""]]}, {"id": "1201.2084", "submitter": "Rafi Muhammad", "authors": "Mehwish Aziz, Muhammad Rafi", "title": "Sentence based semantic similarity measure for blog-posts", "comments": "6th International Conference on Digital Content, Multimedia\n  Technology and its Applications (IDC), 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blogs-Online digital diary like application on web 2.0 has opened new and\neasy way to voice opinion, thoughts, and like-dislike of every Internet user to\nthe World. Blogosphere has no doubt the largest user-generated content\nrepository full of knowledge. The potential of this knowledge is still to be\nexplored. Knowledge discovery from this new genre is quite difficult and\nchallenging as it is totally different from other popular genre of\nweb-applications like World Wide Web (WWW). Blog-posts unlike web documents are\nsmall in size, thus lack in context and contain relaxed grammatical structures.\nHence, standard text similarity measure fails to provide good results. In this\npaper, specialized requirements for comparing a pair of blog-posts is\nthoroughly investigated. Based on this we proposed a novel algorithm for\nsentence oriented semantic similarity measure of a pair of blog-posts. We\napplied this algorithm on a subset of political blogosphere of Pakistan, to\ncluster the blogs on different issues of political realm and to identify the\ninfluential bloggers.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2012 15:33:32 GMT"}], "update_date": "2012-01-11", "authors_parsed": [["Aziz", "Mehwish", ""], ["Rafi", "Muhammad", ""]]}, {"id": "1201.2241", "submitter": "Martin Pelikan", "authors": "Martin Pelikan and Mark W. Hauschild", "title": "Distance-Based Bias in Model-Directed Optimization of Additively\n  Decomposable Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": "MEDAL Report No. 2012001", "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many optimization problems it is possible to define a distance metric\nbetween problem variables that correlates with the likelihood and strength of\ninteractions between the variables. For example, one may define a metric so\nthat the dependencies between variables that are closer to each other with\nrespect to the metric are expected to be stronger than the dependencies between\nvariables that are further apart. The purpose of this paper is to describe a\nmethod that combines such a problem-specific distance metric with information\nmined from probabilistic models obtained in previous runs of estimation of\ndistribution algorithms with the goal of solving future problem instances of\nsimilar type with increased speed, accuracy and reliability. While the focus of\nthe paper is on additively decomposable problems and the hierarchical Bayesian\noptimization algorithm, it should be straightforward to generalize the approach\nto other model-directed optimization techniques and other problem classes.\nCompared to other techniques for learning from experience put forward in the\npast, the proposed technique is both more practical and more broadly\napplicable.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jan 2012 04:59:57 GMT"}], "update_date": "2012-01-12", "authors_parsed": [["Pelikan", "Martin", ""], ["Hauschild", "Mark W.", ""]]}, {"id": "1201.2430", "submitter": "Li Tan", "authors": "Li Tan", "title": "A Well-typed Lightweight Situation Calculus", "comments": "In Proceedings of the 21st Workshop on Logic-based methods in\n  Programming Environments (WLPE'11), ICLP 2011 Workshop, pp. 62-73, Lexington,\n  Kentucky, USA, July 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Situation calculus has been widely applied in Artificial Intelligence related\nfields. This formalism is considered as a dialect of logic programming language\nand mostly used in dynamic domain modeling. However, type systems are hardly\ndeployed in situation calculus in the literature. To achieve a correct and\nsound typed program written in situation calculus, adding typing elements into\nthe current situation calculus will be quite helpful. In this paper, we propose\nto add more typing mechanisms to the current version of situation calculus,\nespecially for three basic elements in situation calculus: situations, actions\nand objects, and then perform rigid type checking for existing situation\ncalculus programs to find out the well-typed and ill-typed ones. In this way,\ntype correctness and soundness in situation calculus programs can be guaranteed\nby type checking based on our type system. This modified version of a\nlightweight situation calculus is proved to be a robust and well-typed system.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jan 2012 21:44:18 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2012 23:18:40 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Tan", "Li", ""]]}, {"id": "1201.2630", "submitter": "Mohammad Al-Khedher", "authors": "Mohammad A. Al-Khedher", "title": "Hybrid GPS-GSM Localization of Automobile Tracking System", "comments": "11 pages, 11 figures, 23 references", "journal-ref": "International Journal of Computer Science and Information\n  Technology, Vol. 3, No. 6, pp. 75-85, 2011", "doi": "10.5121/ijcsit.2011.3606", "report-no": null, "categories": "cs.SY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An integrated GPS-GSM system is proposed to track vehicles using Google Earth\napplication. The remote module has a GPS mounted on the moving vehicle to\nidentify its current position, and to be transferred by GSM with other\nparameters acquired by the automobile's data port as an SMS to a recipient\nstation. The received GPS coordinates are filtered using a Kalman filter to\nenhance the accuracy of measured position. After data processing, Google Earth\napplication is used to view the current location and status of each vehicle.\nThis goal of this system is to manage fleet, police automobiles distribution\nand car theft cautions.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2012 17:54:00 GMT"}], "update_date": "2012-01-13", "authors_parsed": [["Al-Khedher", "Mohammad A.", ""]]}, {"id": "1201.2711", "submitter": "Fionn Murtagh", "authors": "Fionn Murtagh", "title": "Ultrametric Model of Mind, I: Review", "comments": "20 pages, 2 figures, 46 references. arXiv admin note: substantial\n  text overlap with arXiv:0709.0116, arXiv:0805.2744, and arXiv:1105.0121 (V3:\n  2 typos corrected)", "journal-ref": "p-Adic Numbers, Ultrametric Analysis and Applications, 4, 193-206,\n  2012", "doi": "10.1134/S2070046612030041", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We mathematically model Ignacio Matte Blanco's principles of symmetric and\nasymmetric being through use of an ultrametric topology. We use for this the\nhighly regarded 1975 book of this Chilean psychiatrist and pyschoanalyst (born\n1908, died 1995). Such an ultrametric model corresponds to hierarchical\nclustering in the empirical data, e.g. text. We show how an ultrametric\ntopology can be used as a mathematical model for the structure of the logic\nthat reflects or expresses Matte Blanco's symmetric being, and hence of the\nreasoning and thought processes involved in conscious reasoning or in reasoning\nthat is lacking, perhaps entirely, in consciousness or awareness of itself. In\na companion paper we study how symmetric (in the sense of Matte Blanco's)\nreasoning can be demarcated in a context of symmetric and asymmetric reasoning\nprovided by narrative text.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2012 00:17:17 GMT"}, {"version": "v2", "created": "Mon, 6 Feb 2012 19:47:26 GMT"}, {"version": "v3", "created": "Mon, 16 Jul 2012 12:43:58 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Murtagh", "Fionn", ""]]}, {"id": "1201.2719", "submitter": "Fionn Murtagh", "authors": "Fionn Murtagh", "title": "Ultrametric Model of Mind, II: Application to Text Content Analysis", "comments": "21 pages, 6 tables. arXiv admin note: substantial text overlap with\n  arXiv:cs/0701181 (V3: minor corrections)", "journal-ref": "p-Adic Numbers, Ultrametric Analysis and Applications, 4, 207-221,\n  2012", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a companion paper, Murtagh (2012), we discussed how Matte Blanco's work\nlinked the unrepressed unconscious (in the human) to symmetric logic and\nthought processes. We showed how ultrametric topology provides a most useful\nrepresentational and computational framework for this. Now we look at the\nextent to which we can find ultrametricity in text. We use coherent and\nmeaningful collections of nearly 1000 texts to show how we can measure inherent\nultrametricity. On the basis of our findings we hypothesize that inherent\nultrametricty is a basis for further exploring unconscious thought processes.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2012 01:00:41 GMT"}, {"version": "v2", "created": "Mon, 6 Feb 2012 19:49:54 GMT"}, {"version": "v3", "created": "Mon, 16 Jul 2012 12:48:24 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Murtagh", "Fionn", ""]]}, {"id": "1201.3107", "submitter": "Li Yang", "authors": "Li Yang, Yuhui Wang", "title": "Tacit knowledge mining algorithm based on linguistic truth-valued\n  concept lattice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper is the continuation of our research work about linguistic\ntruth-valued concept lattice. In order to provide a mathematical tool for\nmining tacit knowledge, we establish a concrete model of 6-ary linguistic\ntruth-valued concept lattice and introduce a mining algorithm through the\nstructure consistency. Specifically, we utilize the attributes to depict\nknowledge, propose the 6-ary linguistic truth-valued attribute extended context\nand congener context to characterize tacit knowledge, and research the\nnecessary and sufficient conditions of forming tacit knowledge. We respectively\ngive the algorithms of generating the linguistic truth-valued congener context\nand constructing the linguistic truth-valued concept lattice.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2012 17:33:28 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Yang", "Li", ""], ["Wang", "Yuhui", ""]]}, {"id": "1201.3117", "submitter": "Jose Alberto Garc\\'ia Guti\\'errez Sr.", "authors": "Jos\\'e A. Garc\\'ia Guti\\'errez, Carlos Cotta, and Antonio J.\n  Fern\\'andez-Leiva", "title": "Design of Emergent and Adaptive Virtual Players in a War RTS Game", "comments": "IWINAC International Work-conference on the Interplay between Natural\n  and Artificial Computation 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Basically, in (one-player) war Real Time Strategy (wRTS) games a human player\ncontrols, in real time, an army consisting of a number of soldiers and her aim\nis to destroy the opponent's assets where the opponent is a virtual (i.e.,\nnon-human player controlled) player that usually consists of a pre-programmed\ndecision-making script. These scripts have usually associated some well-known\nproblems (e.g., predictability, non-rationality, repetitive behaviors, and\nsensation of artificial stupidity among others). This paper describes a method\nfor the automatic generation of virtual players that adapt to the player\nskills; this is done by building initially a model of the player behavior in\nreal time during the game, and further evolving the virtual player via this\nmodel in-between two games. The paper also shows preliminary results obtained\non a one player wRTS game constructed specifically for experimentation.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2012 20:06:07 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Guti\u00e9rrez", "Jos\u00e9 A. Garc\u00eda", ""], ["Cotta", "Carlos", ""], ["Fern\u00e1ndez-Leiva", "Antonio J.", ""]]}, {"id": "1201.3204", "submitter": "Alex Fukunaga", "authors": "Akihiro Kishimoto, Alex Fukunaga, Adi Botea", "title": "Evaluation of a Simple, Scalable, Parallel Best-First Search Strategy", "comments": "in press, to appear in Artificial Intelligence", "journal-ref": "Artificial Intelligence (2013), vol. 195, pp. 222-248", "doi": "10.1016/j.artint.2012.10.007", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale, parallel clusters composed of commodity processors are\nincreasingly available, enabling the use of vast processing capabilities and\ndistributed RAM to solve hard search problems. We investigate Hash-Distributed\nA* (HDA*), a simple approach to parallel best-first search that asynchronously\ndistributes and schedules work among processors based on a hash function of the\nsearch state. We use this approach to parallelize the A* algorithm in an\noptimal sequential version of the Fast Downward planner, as well as a 24-puzzle\nsolver. The scaling behavior of HDA* is evaluated experimentally on a shared\nmemory, multicore machine with 8 cores, a cluster of commodity machines using\nup to 64 cores, and large-scale high-performance clusters, using up to 2400\nprocessors. We show that this approach scales well, allowing the effective\nutilization of large amounts of distributed memory to optimally solve problems\nwhich require terabytes of RAM. We also compare HDA* to Transposition-table\nDriven Scheduling (TDS), a hash-based parallelization of IDA*, and show that,\nin planning, HDA* significantly outperforms TDS. A simple hybrid which combines\nHDA* and TDS to exploit strengths of both algorithms is proposed and evaluated.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2012 10:31:47 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2012 03:39:16 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Kishimoto", "Akihiro", ""], ["Fukunaga", "Alex", ""], ["Botea", "Adi", ""]]}, {"id": "1201.3408", "submitter": "Velimir Ilic", "authors": "Milos B. Djuric, Velimir M. Ilic and Miomir S. Stankovic", "title": "The computation of first order moments on junction trees", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review some existing methods for the computation of first order moments on\njunction trees using Shafer-Shenoy algorithm. First, we consider the problem of\nfirst order moments computation as vertices problem in junction trees. In this\nway, the problem is solved using the memory space of an order of the junction\ntree edge-set cardinality. After that, we consider two algorithms,\nLauritzen-Nilsson algorithm, and Mau\\'a et al. algorithm, which computes the\nfirst order moments as the normalization problem in junction tree, using the\nmemory space of an order of the junction tree leaf-set cardinality.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2012 01:28:55 GMT"}], "update_date": "2012-01-18", "authors_parsed": [["Djuric", "Milos B.", ""], ["Ilic", "Velimir M.", ""], ["Stankovic", "Miomir S.", ""]]}, {"id": "1201.3851", "submitter": "Jinli Hu Mr", "authors": "Jinli Hu", "title": "Combinatorial Modelling and Learning with Prediction Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining models in appropriate ways to achieve high performance is commonly\nseen in machine learning fields today. Although a large amount of combinatorial\nmodels have been created, little attention is drawn to the commons in different\nmodels and their connections. A general modelling technique is thus worth\nstudying to understand model combination deeply and shed light on creating new\nmodels. Prediction markets show a promise of becoming such a generic, flexible\ncombinatorial model. By reviewing on several popular combinatorial models and\nprediction market models, this paper aims to show how the market models can\ngeneralise different combinatorial stuctures and how they implement these\npopular combinatorial models in specific conditions. Besides, we will see among\ndifferent market models, Storkey's \\emph{Machine Learning Markets} provide more\nfundamental, generic modelling mechanisms than the others, and it has a\nsignificant appeal for both theoretical study and application.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2012 17:03:19 GMT"}], "update_date": "2012-01-19", "authors_parsed": [["Hu", "Jinli", ""]]}, {"id": "1201.3868", "submitter": "Martin Cooper", "authors": "Martin C. Cooper and Guillaume Escamocher", "title": "A Dichotomy for 2-Constraint Forbidden CSP Patterns", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the CSP (constraint satisfaction problem) is NP-complete, even in\nthe case when all constraints are binary, certain classes of instances are\ntractable. We study classes of instances defined by excluding subproblems. This\napproach has recently led to the discovery of novel tractable classes. The\ncomplete characterisation of all tractable classes defined by forbidding\npatterns (where a pattern is simply a compact representation of a set of\nsubproblems) is a challenging problem. We demonstrate a dichotomy in the case\nof forbidden patterns consisting of either one or two constraints. This has\nallowed us to discover new tractable classes including, for example, a novel\ngeneralisation of 2SAT.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2012 18:09:36 GMT"}], "update_date": "2012-01-19", "authors_parsed": [["Cooper", "Martin C.", ""], ["Escamocher", "Guillaume", ""]]}, {"id": "1201.3880", "submitter": "Alain-J\\'er\\^ome Foug\\`eres", "authors": "Alain-J\\'er\\^ome Foug\\`eres", "title": "Modelling and simulation of complex systems: an approach based on\n  multi-level agents", "comments": "10 pages; IJCSI International Journal of Computer Science Issues,\n  Vol. 8, Issue 6, No 1, November 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A complex system is made up of many components with many interactions. So the\ndesign of systems such as simulation systems, cooperative systems or assistance\nsystems includes a very accurate modelling of interactional and communicational\nlevels. The agent-based approach provides an adapted abstraction level for this\nproblem. After having studied the organizational context and communicative\ncapacities of agentbased systems, to simulate the reorganization of a flexible\nmanufacturing, to regulate an urban transport system, and to simulate an\nepidemic detection system, our thoughts on the interactional level were\ninspired by human-machine interface models, especially those in \"cognitive\nengineering\". To provide a general framework for agent-based complex systems\nmodelling, we then proposed a scale of four behaviours that agents may adopt in\ntheir complex systems (reactive, routine, cognitive, and collective). To\ncomplete the description of multi-level agent models, which is the focus of\nthis paper, we illustrate our modelling and discuss our ongoing work on each\nlevel.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2012 19:02:11 GMT"}], "update_date": "2012-01-19", "authors_parsed": [["Foug\u00e8res", "Alain-J\u00e9r\u00f4me", ""]]}, {"id": "1201.3883", "submitter": "Alain-J\\'er\\^ome Foug\\`eres", "authors": "Jing Peng, Alain-J\\'er\\^ome Foug\\`eres, Samuel Deniaud and Michel\n  Ferney", "title": "Dynamic Shared Context Processing in an E-Collaborative Learning\n  Environment", "comments": "9 pages; IJCSI International Journal of Computer Science Issues, Vol.\n  7, Issue 5, September 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a dynamic shared context processing method based on\nDSC (Dynamic Shared Context) model, applied in an e-collaborative learning\nenvironment. Firstly, we present the model. This is a way to measure the\nrelevance between events and roles in collaborative environments. With this\nmethod, we can share the most appropriate event information for each role\ninstead of sharing all information to all roles in a collaborative work\nenvironment. Then, we apply and verify this method in our project with Google\nApp supported e-learning collaborative environment. During this experiment, we\ncompared DSC method measured relevance of events and roles to manual measured\nrelevance. And we describe the favorable points from this comparison and our\nfinding. Finally, we discuss our future research of a hybrid DSC method to make\ndynamical information shared more effective in a collaborative work\nenvironment.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2012 19:14:30 GMT"}], "update_date": "2012-01-19", "authors_parsed": [["Peng", "Jing", ""], ["Foug\u00e8res", "Alain-J\u00e9r\u00f4me", ""], ["Deniaud", "Samuel", ""], ["Ferney", "Michel", ""]]}, {"id": "1201.4080", "submitter": "Ingmar Steiner", "authors": "Ingmar Steiner (INRIA Lorraine - LORIA), Slim Ouni (INRIA Lorraine -\n  LORIA)", "title": "Progress in animation of an EMA-controlled tongue model for\n  acoustic-visual speech synthesis", "comments": null, "journal-ref": "Elektronische Sprachsignalverarbeitung 2011 TUDpress (Ed.) (2011)\n  245-252", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a technique for the animation of a 3D kinematic tongue model, one\ncomponent of the talking head of an acoustic-visual (AV) speech synthesizer.\nThe skeletal animation approach is adapted to make use of a deformable rig\ncontrolled by tongue motion capture data obtained with electromagnetic\narticulography (EMA), while the tongue surface is extracted from volumetric\nmagnetic resonance imaging (MRI) data. Initial results are shown and future\nwork outlined.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2012 15:29:56 GMT"}], "update_date": "2012-01-20", "authors_parsed": [["Steiner", "Ingmar", "", "INRIA Lorraine - LORIA"], ["Ouni", "Slim", "", "INRIA Lorraine -\n  LORIA"]]}, {"id": "1201.4089", "submitter": "Markus Kr\\\"otzsch", "authors": "Markus Kr\\\"otzsch, Frantisek Simancik, Ian Horrocks", "title": "A Description Logic Primer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper provides a self-contained first introduction to description logics\n(DLs). The main concepts and features are explained with examples before syntax\nand semantics of the DL SROIQ are defined in detail. Additional sections review\nlight-weight DL languages, discuss the relationship to the Web Ontology\nLanguage OWL and give pointers to further reading.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2012 15:51:01 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2013 07:17:05 GMT"}, {"version": "v3", "created": "Mon, 3 Jun 2013 13:09:48 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Kr\u00f6tzsch", "Markus", ""], ["Simancik", "Frantisek", ""], ["Horrocks", "Ian", ""]]}, {"id": "1201.4210", "submitter": "Harita Mehta", "authors": "Harita Mehta, Shveta Kundra Bhatia, Punam Bedi and V. S. Dixit", "title": "Collaborative Personalized Web Recommender System using Entropy based\n  Similarity Measure", "comments": "10 pages", "journal-ref": "IJCSI, Vol 8, Issue 6, No 3, Nov 2011", "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  On the internet, web surfers, in the search of information, always strive for\nrecommendations. The solutions for generating recommendations become more\ndifficult because of exponential increase in information domain day by day. In\nthis paper, we have calculated entropy based similarity between users to\nachieve solution for scalability problem. Using this concept, we have\nimplemented an online user based collaborative web recommender system. In this\nmodel based collaborative system, the user session is divided into two levels.\nEntropy is calculated at both the levels. It is shown that from the set of\nvaluable recommenders obtained at level I; only those recommenders having lower\nentropy at level II than entropy at level I, served as trustworthy\nrecommenders. Finally, top N recommendations are generated from such\ntrustworthy recommenders for an online user.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jan 2012 05:46:02 GMT"}], "update_date": "2012-01-23", "authors_parsed": [["Mehta", "Harita", ""], ["Bhatia", "Shveta Kundra", ""], ["Bedi", "Punam", ""], ["Dixit", "V. S.", ""]]}, {"id": "1201.4239", "submitter": "Gabriele Martinelli", "authors": "Gabriele Martinelli, Jo Eidsvik and Ragnar Hauge", "title": "Dynamic Decision Making for Graphical Models Applied to Oil Exploration", "comments": "This paper has been withdrawn by the authors. 22 pages, 7 figures,\n  submitted", "journal-ref": null, "doi": "10.1016/j.ejor.2013.04.057", "report-no": "Technical Report in Statistics N. 12/2011, Dept. of Mathematical\n  Sciences, NTNU", "categories": "stat.AP cs.AI stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper has been withdrawn by the authors. We present a framework for\nsequential decision making in problems described by graphical models. The\nsetting is given by dependent discrete random variables with associated costs\nor revenues. In our examples, the dependent variables are the potential\noutcomes (oil, gas or dry) when drilling a petroleum well. The goal is to\ndevelop an optimal selection strategy that incorporates a chosen utility\nfunction within an approximated dynamic programming scheme. We propose and\ncompare different approximations, from simple heuristics to more complex\niterative schemes, and we discuss their computational properties. We apply our\nstrategies to oil exploration over multiple prospects modeled by a directed\nacyclic graph, and to a reservoir drilling decision problem modeled by a Markov\nrandom field. The results show that the suggested strategies clearly improve\nthe simpler intuitive constructions, and this is useful when selecting\nexploration policies.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jan 2012 09:46:59 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2013 14:31:37 GMT"}], "update_date": "2013-07-01", "authors_parsed": [["Martinelli", "Gabriele", ""], ["Eidsvik", "Jo", ""], ["Hauge", "Ragnar", ""]]}, {"id": "1201.4342", "submitter": "Tobias Buer", "authors": "Tobias Buer and Herbert Kopfer", "title": "A Pareto-metaheuristic for a bi-objective winner determination problem\n  in a combinatorial reverse auction", "comments": "Accepted for publication in Computers & Operations Research,\n  available online, Computers & Operations Research, 2013", "journal-ref": "Computers & Operations Research 41 (2014), 208-220", "doi": "10.1016/j.cor.2013.04.004", "report-no": null, "categories": "cs.GT cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bi-objective winner determination problem (2WDP-SC) of a combinatorial\nprocurement auction for transport contracts is characterized by a set B of\nbundle bids, with each bundle bid b in B consisting of a bidding carrier c_b, a\nbid price p_b, and a set tau_b transport contracts which is a subset of the set\nT of tendered transport contracts. Additionally, the transport quality\nq_{t,c_b} is given which is expected to be realized when a transport contract t\nis executed by a carrier c_b. The task of the auctioneer is to find a set X of\nwinning bids (X subset B), such that each transport contract is part of at\nleast one winning bid, the total procurement costs are minimized, and the total\ntransport quality is maximized. This article presents a metaheuristic approach\nfor the 2WDP-SC which integrates the greedy randomized adaptive search\nprocedure with a two-stage candidate component selection procedure, large\nneighborhood search, and self-adaptive parameter setting in order to find a\ncompetitive set of non-dominated solutions. The heuristic outperforms all\nexisting approaches. For seven small benchmark instances, the heuristic is the\nsole approach that finds all Pareto-optimal solutions. For 28 out of 30 large\ninstances, none of the existing approaches is able to compute a solution that\ndominates a solution found by the proposed heuristic.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jan 2012 17:09:22 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2013 12:25:42 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Buer", "Tobias", ""], ["Kopfer", "Herbert", ""]]}, {"id": "1201.4777", "submitter": "Alfonso E. Romero PhD", "authors": "Alfonso E. Romero, Luis M. de Campos", "title": "A probabilistic methodology for multilabel classification", "comments": "14 pages, 1 figure, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilabel classification is a relatively recent subfield of machine\nlearning. Unlike to the classical approach, where instances are labeled with\nonly one category, in multilabel classification, an arbitrary number of\ncategories is chosen to label an instance. Due to the problem complexity (the\nsolution is one among an exponential number of alternatives), a very common\nsolution (the binary method) is frequently used, learning a binary classifier\nfor every category, and combining them all afterwards. The assumption taken in\nthis solution is not realistic, and in this work we give examples where the\ndecisions for all the labels are not taken independently, and thus, a\nsupervised approach should learn those existing relationships among categories\nto make a better classification. Therefore, we show here a generic methodology\nthat can improve the results obtained by a set of independent probabilistic\nbinary classifiers, by using a combination procedure with a classifier trained\non the co-occurrences of the labels. We show an exhaustive experimentation in\nthree different standard corpora of labeled documents (Reuters-21578,\nOhsumed-23 and RCV1), which present noticeable improvements in all of them,\nwhen using our methodology, in three probabilistic base classifiers.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2012 17:25:34 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2013 20:22:47 GMT"}], "update_date": "2013-03-01", "authors_parsed": [["Romero", "Alfonso E.", ""], ["de Campos", "Luis M.", ""]]}, {"id": "1201.5217", "submitter": "Mohammad Tarek Al-Muallim M.Sc.", "authors": "M. T. Al-Muallim, R. El-Kouatly", "title": "Unsupervised Classification Using Immune Algorithm", "comments": null, "journal-ref": null, "doi": "10.5120/677-952", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised classification algorithm based on clonal selection principle\nnamed Unsupervised Clonal Selection Classification (UCSC) is proposed in this\npaper. The new proposed algorithm is data driven and self-adaptive, it adjusts\nits parameters to the data to make the classification operation as fast as\npossible. The performance of UCSC is evaluated by comparing it with the well\nknown K-means algorithm using several artificial and real-life data sets. The\nexperiments show that the proposed UCSC algorithm is more reliable and has high\nclassification precision comparing to traditional classification methods such\nas K-means.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2012 09:44:06 GMT"}], "update_date": "2012-01-26", "authors_parsed": [["Al-Muallim", "M. T.", ""], ["El-Kouatly", "R.", ""]]}, {"id": "1201.5346", "submitter": "Valentin Goranko", "authors": "Mai Ajspur and Valentin Goranko and Dmitry Shkatov", "title": "Tableau-based decision procedure for the multi-agent epistemic logic\n  with all coalitional operators for common and distributed knowledge", "comments": "Substantially extended and corrected version of arXiv:0902.2125. To\n  appear in: Logic Journal of the IGPL, special issue on Formal Aspects of\n  Multi-Agent Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a conceptually clear, intuitive, and feasible decision procedure\nfor testing satisfiability in the full multi-agent epistemic logic CMAEL(CD)\nwith operators for common and distributed knowledge for all coalitions of\nagents mentioned in the language. To that end, we introduce Hintikka structures\nfor CMAEL(CD) and prove that satisfiability in such structures is equivalent to\nsatisfiability in standard models. Using that result, we design an incremental\ntableau-building procedure that eventually constructs a satisfying Hintikka\nstructure for every satisfiable input set of formulae of CMAEL(CD) and closes\nfor every unsatisfiable input set of formulae.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2012 19:18:00 GMT"}], "update_date": "2016-11-27", "authors_parsed": [["Ajspur", "Mai", ""], ["Goranko", "Valentin", ""], ["Shkatov", "Dmitry", ""]]}, {"id": "1201.5426", "submitter": "M. H. van Emden", "authors": "A. Nait Abdallah and M.H. van Emden", "title": "Constraint Propagation as Information Maximization", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": "Research Report 746, Dept. of Computer Science, University of\n  Western Ontario, Canada", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper draws on diverse areas of computer science to develop a unified\nview of computation:\n  (1) Optimization in operations research, where a numerical objective function\nis maximized under constraints, is generalized from the numerical total order\nto a non-numerical partial order that can be interpreted in terms of\ninformation. (2) Relations are generalized so that there are relations of which\nthe constituent tuples have numerical indexes, whereas in other relations these\nindexes are variables. The distinction is essential in our definition of\nconstraint satisfaction problems. (3) Constraint satisfaction problems are\nformulated in terms of semantics of conjunctions of atomic formulas of\npredicate logic. (4) Approximation structures, which are available for several\nimportant domains, are applied to solutions of constraint satisfaction\nproblems.\n  As application we treat constraint satisfaction problems over reals. These\ncover a large part of numerical analysis, most significantly nonlinear\nequations and inequalities. The chaotic algorithm analyzed in the paper\ncombines the efficiency of floating-point computation with the correctness\nguarantees of arising from our logico-mathematical model of\nconstraint-satisfaction problems.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2012 01:42:18 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2013 23:05:29 GMT"}], "update_date": "2013-02-11", "authors_parsed": [["Abdallah", "A. Nait", ""], ["van Emden", "M. H.", ""]]}, {"id": "1201.5472", "submitter": "Pierrick Tranouez", "authors": "Pierrick Tranouez (LITIS), Eric Daud\\'e (IDEES), Patrice Langlois\n  (IDEES)", "title": "A multiagent urban traffic simulation", "comments": "arXiv admin note: significant text overlap with arXiv:0909.1021 and\n  arXiv:0910.1026", "journal-ref": "Journal of Nonlinear Systems and Applications 1, 3 (2010) 9 pp (in\n  print)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We built a multiagent simulation of urban traffic to model both ordinary\ntraffic and emergency or crisis mode traffic. This simulation first builds a\nmodeled road network based on detailed geographical information. On this\nnetwork, the simulation creates two populations of agents: the Transporters and\nthe Mobiles. Transporters embody the roads themselves; they are utilitarian and\nmeant to handle the low level realism of the simulation. Mobile agents embody\nthe vehicles that circulate on the network. They have one or several\ndestinations they try to reach using initially their beliefs of the structure\nof the network (length of the edges, speed limits, number of lanes etc.).\nNonetheless, when confronted to a dynamic, emergent prone environment (other\nvehicles, unexpectedly closed ways or lanes, traffic jams etc.), the rather\nreactive agent will activate more cognitive modules to adapt its beliefs,\ndesires and intentions. It may change its destination(s), change the tactics\nused to reach the destination (favoring less used roads, following other\nagents, using general headings), etc. We describe our current validation of our\nmodel and the next planned improvements, both in validation and in\nfunctionalities.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2012 10:15:09 GMT"}], "update_date": "2012-01-27", "authors_parsed": [["Tranouez", "Pierrick", "", "LITIS"], ["Daud\u00e9", "Eric", "", "IDEES"], ["Langlois", "Patrice", "", "IDEES"]]}, {"id": "1201.5604", "submitter": "Richard Preen", "authors": "Richard J. Preen and Larry Bull", "title": "Discrete and fuzzy dynamical genetic programming in the XCSF learning\n  classifier system", "comments": null, "journal-ref": "Soft Computing (2014), 18(1):153-167", "doi": "10.1007/s00500-013-1044-4", "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of representation schemes have been presented for use within\nlearning classifier systems, ranging from binary encodings to neural networks.\nThis paper presents results from an investigation into using discrete and fuzzy\ndynamical system representations within the XCSF learning classifier system. In\nparticular, asynchronous random Boolean networks are used to represent the\ntraditional condition-action production system rules in the discrete case and\nasynchronous fuzzy logic networks in the continuous-valued case. It is shown\npossible to use self-adaptive, open-ended evolution to design an ensemble of\nsuch dynamical systems within XCSF to solve a number of well-known test\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2012 18:54:42 GMT"}, {"version": "v2", "created": "Sun, 25 Jan 2015 15:34:57 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Preen", "Richard J.", ""], ["Bull", "Larry", ""]]}, {"id": "1201.5841", "submitter": "Alexandre Castro", "authors": "Alexandre de Castro", "title": "The thermodynamic cost of fast thought", "comments": null, "journal-ref": null, "doi": "10.1007/s11023-013-9302-x", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After more than sixty years, Shannon's research [1-3] continues to raise\nfundamental questions, such as the one formulated by Luce [4,5], which is still\nunanswered: \"Why is information theory not very applicable to psychological\nproblems, despite apparent similarities of concepts?\" On this topic, Pinker\n[6], one of the foremost defenders of the computational theory of mind [6], has\nargued that thought is simply a type of computation, and that the gap between\nhuman cognition and computational models may be illusory. In this context, in\nhis latest book, titled Thinking Fast and Slow [8], Kahneman [7,8] provides\nfurther theoretical interpretation by differentiating the two assumed systems\nof the cognitive functioning of the human mind. He calls them intuition (system\n1) determined to be an associative (automatic, fast and perceptual) machine,\nand reasoning (system 2) required to be voluntary and to operate logical-\ndeductively. In this paper, we propose an ansatz inspired by Ausubel's learning\ntheory for investigating, from the constructivist perspective [9-12],\ninformation processing in the working memory of cognizers. Specifically, a\nthought experiment is performed utilizing the mind of a dual-natured creature\nknown as Maxwell's demon: a tiny \"man-machine\" solely equipped with the\ncharacteristics of system 1, which prevents it from reasoning. The calculation\npresented here shows that [...]. This result indicates that when the system 2\nis shut down, both an intelligent being, as well as a binary machine, incur the\nsame energy cost per unit of information processed, which mathematically proves\nthe computational attribute of the system 1, as Kahneman [7,8] theorized. This\nfinding links information theory to human psychological features and opens a\nnew path toward the conception of a multi-bit reasoning machine.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2012 17:25:29 GMT"}, {"version": "v2", "created": "Fri, 10 Feb 2012 03:11:06 GMT"}, {"version": "v3", "created": "Mon, 12 Nov 2012 12:44:49 GMT"}, {"version": "v4", "created": "Sat, 26 Jan 2013 14:37:56 GMT"}], "update_date": "2016-08-14", "authors_parsed": [["de Castro", "Alexandre", ""]]}, {"id": "1201.5943", "submitter": "Alex James Dr", "authors": "Alex Pappachen James and Sima Dimitrijev", "title": "Cognitive Memory Network", "comments": null, "journal-ref": "Electronics Letters,46, 10, 677 - 678, 2010", "doi": "10.1049/el.2010.0279", "report-no": null, "categories": "cs.AI cs.CV cs.ET", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  A resistive memory network that has no crossover wiring is proposed to\novercome the hardware limitations to size and functional complexity that is\nassociated with conventional analogue neural networks. The proposed memory\nnetwork is based on simple network cells that are arranged in a hierarchical\nmodular architecture. Cognitive functionality of this network is demonstrated\nby an example of character recognition. The network is trained by an\nevolutionary process to completely recognise characters deformed by random\nnoise, rotation, scaling and shifting\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2012 11:05:26 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["James", "Alex Pappachen", ""], ["Dimitrijev", "Sima", ""]]}, {"id": "1201.5946", "submitter": "Alex James Dr", "authors": "Alex Pappachen James and Sima Dimitrijev", "title": "Feature selection using nearest attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is an important problem in high-dimensional data analysis\nand classification. Conventional feature selection approaches focus on\ndetecting the features based on a redundancy criterion using learning and\nfeature searching schemes. In contrast, we present an approach that identifies\nthe need to select features based on their discriminatory ability among\nclasses. Area of overlap between inter-class and intra-class distances\nresulting from feature to feature comparison of an attribute is used as a\nmeasure of discriminatory ability of the feature. A set of nearest attributes\nin a pattern having the lowest area of overlap within a degree of tolerance\ndefined by a selection threshold is selected to represent the best available\ndiscriminable features. State of the art recognition results are reported for\npattern classification problems by using the proposed feature selection scheme\nwith the nearest neighbour classifier. These results are reported with\nbenchmark databases having high dimensional feature vectors in the problems\ninvolving images and micro array data.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2012 11:37:40 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["James", "Alex Pappachen", ""], ["Dimitrijev", "Sima", ""]]}, {"id": "1201.5947", "submitter": "Alex James Dr", "authors": "Alex Pappachen James and Sima Dimitrijev", "title": "Examplers based image fusion features for face recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Examplers of a face are formed from multiple gallery images of a person and\nare used in the process of classification of a test image. We incorporate such\nexamplers in forming a biologically inspired local binary decisions on\nsimilarity based face recognition method. As opposed to single model approaches\nsuch as face averages the exampler based approach results in higher recognition\naccu- racies and stability. Using multiple training samples per person, the\nmethod shows the following recognition accuracies: 99.0% on AR, 99.5% on FERET,\n99.5% on ORL, 99.3% on EYALE, 100.0% on YALE and 100.0% on CALTECH face\ndatabases. In addition to face recognition, the method also detects the natural\nvariability in the face images which can find application in automatic tagging\nof face images.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2012 11:45:07 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["James", "Alex Pappachen", ""], ["Dimitrijev", "Sima", ""]]}, {"id": "1201.5959", "submitter": "Alex James Dr", "authors": "Alex Pappachen James", "title": "Memory Based Machine Intelligence Techniques in VLSI hardware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We briefly introduce the memory based approaches to emulate machine\nintelligence in VLSI hardware, describing the challenges and advantages.\nImplementation of artificial intelligence techniques in VLSI hardware is a\npractical and difficult problem. Deep architectures, hierarchical temporal\nmemories and memory networks are some of the contemporary approaches in this\narea of research. The techniques attempt to emulate low level intelligence\ntasks and aim at providing scalable solutions to high level intelligence\nproblems such as sparse coding and contextual processing.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2012 13:38:08 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["James", "Alex Pappachen", ""]]}, {"id": "1201.6511", "submitter": "Gilles Falquet", "authors": "Claudine M\\'etral, Gilles Falquet, Kostas Karatzas", "title": "Ontologies for the Integration of Air Quality Models and 3D City Models", "comments": null, "journal-ref": "In Conceptual Models for Practitioners, J. Teller, C. Tweed, G.\n  Rabino (Eds.), Societ\\`a Editrice Esculapio, Bologna, 2008", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The holistic approach to sustainable urban planning implies using different\nmodels in an integrated way that is capable of simulating the urban system. As\nthe interconnection of such models is not a trivial task, one of the key\nelements that may be applied is the description of the urban geometric\nproperties in an \"interoperable\" way. Focusing on air quality as one of the\nmost pronounced urban problems, the geometric aspects of a city may be\ndescribed by objects such as those defined in CityGML, so that an appropriate\nair quality model can be applied for estimating the quality of the urban air on\nthe basis of atmospheric flow and chemistry equations.\n  In this paper we first present theoretical background and motivations for the\ninterconnection of 3D city models and other models related to sustainable\ndevelopment and urban planning. Then we present a practical experiment based on\nthe interconnection of CityGML with an air quality model. Our approach is based\non the creation of an ontology of air quality models and on the extension of an\nontology of urban planning process (OUPP) that acts as an ontology mediator.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2012 11:31:50 GMT"}], "update_date": "2012-02-01", "authors_parsed": [["M\u00e9tral", "Claudine", ""], ["Falquet", "Gilles", ""], ["Karatzas", "Kostas", ""]]}, {"id": "1201.6583", "submitter": "Tobias Jung", "authors": "Tobias Jung and Daniel Polani and Peter Stone", "title": "Empowerment for Continuous Agent-Environment Systems", "comments": null, "journal-ref": "Adaptive Behavior 19(1),2011", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops generalizations of empowerment to continuous states.\nEmpowerment is a recently introduced information-theoretic quantity motivated\nby hypotheses about the efficiency of the sensorimotor loop in biological\norganisms, but also from considerations stemming from curiosity-driven\nlearning. Empowemerment measures, for agent-environment systems with stochastic\ntransitions, how much influence an agent has on its environment, but only that\ninfluence that can be sensed by the agent sensors. It is an\ninformation-theoretic generalization of joint controllability (influence on\nenvironment) and observability (measurement by sensors) of the environment by\nthe agent, both controllability and observability being usually defined in\ncontrol theory as the dimensionality of the control/observation spaces. Earlier\nwork has shown that empowerment has various interesting and relevant\nproperties, e.g., it allows us to identify salient states using only the\ndynamics, and it can act as intrinsic reward without requiring an external\nreward. However, in this previous work empowerment was limited to the case of\nsmall-scale and discrete domains and furthermore state transition probabilities\nwere assumed to be known. The goal of this paper is to extend empowerment to\nthe significantly more important and relevant case of continuous vector-valued\nstate spaces and initially unknown state transition probabilities. The\ncontinuous state space is addressed by Monte-Carlo approximation; the unknown\ntransitions are addressed by model learning and prediction for which we apply\nGaussian processes regression with iterated forecasting. In a number of\nwell-known continuous control tasks we examine the dynamics induced by\nempowerment and include an application to exploration and online model\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2012 15:46:27 GMT"}], "update_date": "2012-02-01", "authors_parsed": [["Jung", "Tobias", ""], ["Polani", "Daniel", ""], ["Stone", "Peter", ""]]}, {"id": "1201.6604", "submitter": "Tobias Jung", "authors": "Tobias Jung and Peter Stone", "title": "Gaussian Processes for Sample Efficient Reinforcement Learning with\n  RMAX-like Exploration", "comments": "European Conference on Machine Learning (ECML'2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an implementation of model-based online reinforcement learning\n(RL) for continuous domains with deterministic transitions that is specifically\ndesigned to achieve low sample complexity. To achieve low sample complexity,\nsince the environment is unknown, an agent must intelligently balance\nexploration and exploitation, and must be able to rapidly generalize from\nobservations. While in the past a number of related sample efficient RL\nalgorithms have been proposed, to allow theoretical analysis, mainly\nmodel-learners with weak generalization capabilities were considered. Here, we\nseparate function approximation in the model learner (which does require\nsamples) from the interpolation in the planner (which does not require\nsamples). For model-learning we apply Gaussian processes regression (GP) which\nis able to automatically adjust itself to the complexity of the problem (via\nBayesian hyperparameter selection) and, in practice, often able to learn a\nhighly accurate model from very little data. In addition, a GP provides a\nnatural way to determine the uncertainty of its predictions, which allows us to\nimplement the \"optimism in the face of uncertainty\" principle used to\nefficiently control exploration. Our method is evaluated on four common\nbenchmark domains.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2012 16:36:51 GMT"}], "update_date": "2012-02-01", "authors_parsed": [["Jung", "Tobias", ""], ["Stone", "Peter", ""]]}, {"id": "1201.6615", "submitter": "Tobias Jung", "authors": "Tobias Jung and Peter Stone", "title": "Feature Selection for Value Function Approximation Using Bayesian Model\n  Selection", "comments": "European Conference on Machine Learning (ECML'09)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection in reinforcement learning (RL), i.e. choosing basis\nfunctions such that useful approximations of the unkown value function can be\nobtained, is one of the main challenges in scaling RL to real-world\napplications. Here we consider the Gaussian process based framework GPTD for\napproximate policy evaluation, and propose feature selection through marginal\nlikelihood optimization of the associated hyperparameters. Our approach has two\nappealing benefits: (1) given just sample transitions, we can solve the policy\nevaluation problem fully automatically (without looking at the learning task,\nand, in theory, independent of the dimensionality of the state space), and (2)\nmodel selection allows us to consider more sophisticated kernels, which in turn\nenable us to identify relevant subspaces and eliminate irrelevant state\nvariables such that we can achieve substantial computational savings and\nimproved prediction performance.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2012 16:57:55 GMT"}], "update_date": "2012-02-01", "authors_parsed": [["Jung", "Tobias", ""], ["Stone", "Peter", ""]]}, {"id": "1201.6626", "submitter": "Tobias Jung", "authors": "Tobias Jung and Daniel Polani", "title": "Learning RoboCup-Keepaway with Kernels", "comments": null, "journal-ref": "JMLR Workshop and Conference Proceedings (1st Gaussian Processes\n  in Practice Workshop, 2006)", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply kernel-based methods to solve the difficult reinforcement learning\nproblem of 3vs2 keepaway in RoboCup simulated soccer. Key challenges in\nkeepaway are the high-dimensionality of the state space (rendering conventional\ndiscretization-based function approximation like tilecoding infeasible), the\nstochasticity due to noise and multiple learning agents needing to cooperate\n(meaning that the exact dynamics of the environment are unknown) and real-time\nlearning (meaning that an efficient online implementation is required). We\nemploy the general framework of approximate policy iteration with\nleast-squares-based policy evaluation. As underlying function approximator we\nconsider the family of regularization networks with subset of regressors\napproximation. The core of our proposed solution is an efficient recursive\nimplementation with automatic supervised selection of relevant basis functions.\nSimulation results indicate that the behavior learned through our approach\nclearly outperforms the best results obtained earlier with tilecoding by Stone\net al. (2005).\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2012 17:26:17 GMT"}], "update_date": "2012-02-01", "authors_parsed": [["Jung", "Tobias", ""], ["Polani", "Daniel", ""]]}, {"id": "1201.6655", "submitter": "Alina Beygelzimer", "authors": "Alina Beygelzimer, John Langford, David Pennock", "title": "Learning Performance of Prediction Markets with Kelly Bettors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In evaluating prediction markets (and other crowd-prediction mechanisms),\ninvestigators have repeatedly observed a so-called \"wisdom of crowds\" effect,\nwhich roughly says that the average of participants performs much better than\nthe average participant. The market price---an average or at least aggregate of\ntraders' beliefs---offers a better estimate than most any individual trader's\nopinion. In this paper, we ask a stronger question: how does the market price\ncompare to the best trader's belief, not just the average trader. We measure\nthe market's worst-case log regret, a notion common in machine learning theory.\nTo arrive at a meaningful answer, we need to assume something about how traders\nbehave. We suppose that every trader optimizes according to the Kelly criteria,\na strategy that provably maximizes the compound growth of wealth over an\n(infinite) sequence of market interactions. We show several consequences.\nFirst, the market prediction is a wealth-weighted average of the individual\nparticipants' beliefs. Second, the market learns at the optimal rate, the\nmarket price reacts exactly as if updating according to Bayes' Law, and the\nmarket prediction has low worst-case log regret to the best individual\nparticipant. We simulate a sequence of markets where an underlying true\nprobability exists, showing that the market converges to the true objective\nfrequency as if updating a Beta distribution, as the theory predicts. If agents\nadopt a fractional Kelly criteria, a common practical variant, we show that\nagents behave like full-Kelly agents with beliefs weighted between their own\nand the market's, and that the market price converges to a time-discounted\nfrequency. Our analysis provides a new justification for fractional Kelly\nbetting, a strategy widely used in practice for ad-hoc reasons. Finally, we\npropose a method for an agent to learn her own optimal Kelly fraction.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2012 19:21:39 GMT"}], "update_date": "2012-02-01", "authors_parsed": [["Beygelzimer", "Alina", ""], ["Langford", "John", ""], ["Pennock", "David", ""]]}]