[{"id": "1810.00024", "submitter": "Washington Garcia", "authors": "Washington Garcia, Joseph I. Choi, Suman K. Adari, Somesh Jha, Kevin\n  R. B. Butler", "title": "Explainable Black-Box Attacks Against Model-based Authentication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Establishing unique identities for both humans and end systems has been an\nactive research problem in the security community, giving rise to innovative\nmachine learning-based authentication techniques. Although such techniques\noffer an automated method to establish identity, they have not been vetted\nagainst sophisticated attacks that target their core machine learning\ntechnique. This paper demonstrates that mimicking the unique signatures\ngenerated by host fingerprinting and biometric authentication systems is\npossible. We expose the ineffectiveness of underlying machine learning\nclassification models by constructing a blind attack based around the query\nsynthesis framework and utilizing Explainable-AI (XAI) techniques. We launch an\nattack in under 130 queries on a state-of-the-art face authentication system,\nand under 100 queries on a host authentication system. We examine how these\nattacks can be defended against and explore their limitations. XAI provides an\neffective means for adversaries to infer decision boundaries and provides a new\nway forward in constructing attacks against systems using machine learning\nmodels for authentication.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 18:13:26 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Garcia", "Washington", ""], ["Choi", "Joseph I.", ""], ["Adari", "Suman K.", ""], ["Jha", "Somesh", ""], ["Butler", "Kevin R. B.", ""]]}, {"id": "1810.00031", "submitter": "Alejandro Noriega-Campero", "authors": "Alejandro Noriega-Campero, Michiel A. Bakker, Bernardo Garcia-Bulle,\n  Alex Pentland", "title": "Active Fairness in Algorithmic Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Society increasingly relies on machine learning models for automated decision\nmaking. Yet, efficiency gains from automation have come paired with concern for\nalgorithmic discrimination that can systematize inequality. Recent work has\nproposed optimal post-processing methods that randomize classification\ndecisions for a fraction of individuals, in order to achieve fairness measures\nrelated to parity in errors and calibration. These methods, however, have\nraised concern due to the information inefficiency, intra-group unfairness, and\nPareto sub-optimality they entail. The present work proposes an alternative\nactive framework for fair classification, where, in deployment, a\ndecision-maker adaptively acquires information according to the needs of\ndifferent groups or individuals, towards balancing disparities in\nclassification performance. We propose two such methods, where information\ncollection is adapted to group- and individual-level needs respectively. We\nshow on real-world datasets that these can achieve: 1) calibration and single\nerror parity (e.g., equal opportunity); and 2) parity in both false positive\nand false negative rates (i.e., equal odds). Moreover, we show that by\nleveraging their additional degree of freedom, active approaches can\nsubstantially outperform randomization-based classifiers previously considered\noptimal, while avoiding limitations such as intra-group unfairness.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 18:28:26 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 16:42:51 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Noriega-Campero", "Alejandro", ""], ["Bakker", "Michiel A.", ""], ["Garcia-Bulle", "Bernardo", ""], ["Pentland", "Alex", ""]]}, {"id": "1810.00090", "submitter": "Emanuel Onica", "authors": "Ciprian Amariei, Paul Diac, Emanuel Onica, Valentin Ro\\c{s}ca", "title": "Cell Grid Architecture for Maritime Route Prediction on AIS Data Streams", "comments": null, "journal-ref": "DEBS 2018, Proceedings of the 12th ACM International Conference on\n  Distributed and Event-based Systems, Pages 202-204", "doi": "10.1145/3210284.3220503", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 2018 Grand Challenge targets the problem of accurate predictions on data\nstreams produced by automatic identification system (AIS) equipment, describing\nnaval traffic. This paper reports the technical details of a custom solution,\nwhich exposes multiple tuning parameters, making its configurability one of the\nmain strengths. Our solution employs a cell grid architecture essentially based\non a sequence of hash tables, specifically built for the targeted use case.\nThis makes it particularly effective in prediction on AIS data, obtaining a\nhigh accuracy and scalable performance results. Moreover, the architecture\nproposed accommodates also an optionally semi-supervised learning process\nbesides the basic supervised mode.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 21:42:17 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Amariei", "Ciprian", ""], ["Diac", "Paul", ""], ["Onica", "Emanuel", ""], ["Ro\u015fca", "Valentin", ""]]}, {"id": "1810.00092", "submitter": "Murat Cubuktepe", "authors": "Mohamadreza Ahmadi, Murat Cubuktepe, Nils Jansen, Sebastian Junges,\n  Joost-Pieter Katoen, Ufuk Topcu", "title": "The Partially Observable Games We Play for Cyber Deception", "comments": "8 pages, 5 figures, 2 table; submitted to American Control Conference\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progressively intricate cyber infiltration mechanisms have made conventional\nmeans of defense, such as firewalls and malware detectors, incompetent. These\nsophisticated infiltration mechanisms can study the defender's behavior,\nidentify security caveats, and modify their actions adaptively. To tackle these\nsecurity challenges, cyber-infrastructures require active defense techniques\nthat incorporate cyber deception, in which the defender (deceiver) implements a\nstrategy to mislead the infiltrator. To this end, we use a two-player partially\nobservable stochastic game (POSG) framework, wherein the deceiver has full\nobservability over the states of the POSG, and the infiltrator has partial\nobservability. Then, the deception problem is to compute a strategy for the\ndeceiver that minimizes the expected cost of deception against all strategies\nof the infiltrator. We first show that the underlying problem is a robust\nmixed-integer linear program, which is intractable to solve in general. Towards\na scalable approach, we compute optimal finite-memory strategies for the\ninfiltrator by a reduction to a series of synthesis problems for parametric\nMarkov decision processes. We use these infiltration strategies to find robust\nstrategies for the deceiver using mixed-integer linear programming. We\nillustrate the performance of our technique on a POSG model for network\nsecurity. Our experiments demonstrate that the proposed approach handles\nscenarios considerably larger than those of the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 21:42:41 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Ahmadi", "Mohamadreza", ""], ["Cubuktepe", "Murat", ""], ["Jansen", "Nils", ""], ["Junges", "Sebastian", ""], ["Katoen", "Joost-Pieter", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1810.00123", "submitter": "Marlos C. Machado", "authors": "Jesse Farebrother, Marlos C. Machado, Michael Bowling", "title": "Generalization and Regularization in DQN", "comments": "Earlier versions of this work were presented both at the NeurIPS'18\n  Deep Reinforcement Learning Workshop and the 4th Multidisciplinary Conference\n  on Reinforcement Learning and Decision Making (RLDM'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning algorithms have shown an impressive ability to\nlearn complex control policies in high-dimensional tasks. However, despite the\never-increasing performance on popular benchmarks, policies learned by deep\nreinforcement learning algorithms can struggle to generalize when evaluated in\nremarkably similar environments. In this paper we propose a protocol to\nevaluate generalization in reinforcement learning through different modes of\nAtari 2600 games. With that protocol we assess the generalization capabilities\nof DQN, one of the most traditional deep reinforcement learning algorithms, and\nwe provide evidence suggesting that DQN overspecializes to the training\nenvironment. We then comprehensively evaluate the impact of dropout and\n$\\ell_2$ regularization, as well as the impact of reusing learned\nrepresentations to improve the generalization capabilities of DQN. Despite\nregularization being largely underutilized in deep reinforcement learning, we\nshow that it can, in fact, help DQN learn more general features. These features\ncan be reused and fine-tuned on similar tasks, considerably improving DQN's\nsample efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 00:52:34 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 17:59:21 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 23:25:22 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Farebrother", "Jesse", ""], ["Machado", "Marlos C.", ""], ["Bowling", "Michael", ""]]}, {"id": "1810.00144", "submitter": "Fuxun Yu", "authors": "Fuxun Yu, Chenchen Liu, Yanzhi Wang, Liang Zhao, Xiang Chen", "title": "Interpreting Adversarial Robustness: A View from Decision Surface in\n  Input Space", "comments": "15 pages, submitted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One popular hypothesis of neural network generalization is that the flat\nlocal minima of loss surface in parameter space leads to good generalization.\nHowever, we demonstrate that loss surface in parameter space has no obvious\nrelationship with generalization, especially under adversarial settings.\nThrough visualizing decision surfaces in both parameter space and input space,\nwe instead show that the geometry property of decision surface in input space\ncorrelates well with the adversarial robustness. We then propose an adversarial\nrobustness indicator, which can evaluate a neural network's intrinsic\nrobustness property without testing its accuracy under adversarial attacks.\nGuided by it, we further propose our robust training method. Without involving\nadversarial training, our method could enhance network's intrinsic adversarial\nrobustness against various adversarial attacks.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 04:03:08 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 20:54:40 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Yu", "Fuxun", ""], ["Liu", "Chenchen", ""], ["Wang", "Yanzhi", ""], ["Zhao", "Liang", ""], ["Chen", "Xiang", ""]]}, {"id": "1810.00147", "submitter": "Tianmin Shu", "authors": "Tianmin Shu, Yuandong Tian", "title": "M$^3$RL: Mind-aware Multi-agent Management Reinforcement Learning", "comments": "ICLR 2019; 18 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the prior work on multi-agent reinforcement learning (MARL) achieves\noptimal collaboration by directly controlling the agents to maximize a common\nreward. In this paper, we aim to address this from a different angle. In\nparticular, we consider scenarios where there are self-interested agents (i.e.,\nworker agents) which have their own minds (preferences, intentions, skills,\netc.) and can not be dictated to perform tasks they do not wish to do. For\nachieving optimal coordination among these agents, we train a super agent\n(i.e., the manager) to manage them by first inferring their minds based on both\ncurrent and past observations and then initiating contracts to assign suitable\ntasks to workers and promise to reward them with corresponding bonuses so that\nthey will agree to work together. The objective of the manager is maximizing\nthe overall productivity as well as minimizing payments made to the workers for\nad-hoc worker teaming. To train the manager, we propose Mind-aware Multi-agent\nManagement Reinforcement Learning (M^3RL), which consists of agent modeling and\npolicy learning. We have evaluated our approach in two environments, Resource\nCollection and Crafting, to simulate multi-agent management problems with\nvarious task settings and multiple designs for the worker agents. The\nexperimental results have validated the effectiveness of our approach in\nmodeling worker agents' minds online, and in achieving optimal ad-hoc teaming\nwith good generalization and fast adaptation.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 04:33:15 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 21:56:03 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 06:02:40 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Shu", "Tianmin", ""], ["Tian", "Yuandong", ""]]}, {"id": "1810.00177", "submitter": "Takuya Hiraoka", "authors": "Takuya Hiraoka, Takashi Onishi, Takahisa Imagawa, Yoshimasa Tsuruoka", "title": "Refining Manually-Designed Symbol Grounding and High-Level Planning by\n  Policy Gradients", "comments": "presented at the IJCAI-ICAI 2018 workshop on Learning & Reasoning\n  (L&R 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical planners that produce interpretable and appropriate plans are\ndesired, especially in its application to supporting human decision making. In\nthe typical development of the hierarchical planners, higher-level planners and\nsymbol grounding functions are manually created, and this manual creation\nrequires much human effort. In this paper, we propose a framework that can\nautomatically refine symbol grounding functions and a high-level planner to\nreduce human effort for designing these modules. In our framework, symbol\ngrounding and high-level planning, which are based on manually-designed\nknowledge bases, are modeled with semi-Markov decision processes. A policy\ngradient method is then applied to refine the modules, in which two terms for\nupdating the modules are considered. The first term, called a reinforcement\nterm, contributes to updating the modules to improve the overall performance of\na hierarchical planner to produce appropriate plans. The second term, called a\npenalty term, contributes to keeping refined modules consistent with the\nmanually-designed original modules. Namely, it keeps the planner, which uses\nthe refined modules, producing interpretable plans. We perform preliminary\nexperiments to solve the Mountain car problem, and its results show that a\nmanually-designed high-level planner and symbol grounding function were\nsuccessfully refined by our framework.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 09:15:27 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Hiraoka", "Takuya", ""], ["Onishi", "Takashi", ""], ["Imagawa", "Takahisa", ""], ["Tsuruoka", "Yoshimasa", ""]]}, {"id": "1810.00184", "submitter": "Alun Preece", "authors": "Alun Preece, Dan Harborne, Dave Braines, Richard Tomsett and Supriyo\n  Chakraborty", "title": "Stakeholders in Explainable AI", "comments": "Presented at AAAI FSS-18: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is general consensus that it is important for artificial intelligence\n(AI) and machine learning systems to be explainable and/or interpretable.\nHowever, there is no general consensus over what is meant by 'explainable' and\n'interpretable'. In this paper, we argue that this lack of consensus is due to\nthere being several distinct stakeholder communities. We note that, while the\nconcerns of the individual communities are broadly compatible, they are not\nidentical, which gives rise to different intents and requirements for\nexplainability/interpretability. We use the software engineering distinction\nbetween validation and verification, and the epistemological distinctions\nbetween knowns/unknowns, to tease apart the concerns of the stakeholder\ncommunities and highlight the areas where their foci overlap or diverge. It is\nnot the purpose of the authors of this paper to 'take sides' - we count\nourselves as members, to varying degrees, of multiple communities - but rather\nto help disambiguate what stakeholders mean when they ask 'Why?' of an AI.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 10:15:18 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Preece", "Alun", ""], ["Harborne", "Dan", ""], ["Braines", "Dave", ""], ["Tomsett", "Richard", ""], ["Chakraborty", "Supriyo", ""]]}, {"id": "1810.00324", "submitter": "Walid Saba", "authors": "Walid S. Saba", "title": "On the Winograd Schema: Situating Language Understanding in the\n  Data-Information-Knowledge Continuum", "comments": "6 pages, 1 figure", "journal-ref": "Proceedings of the 32nd International FLAIRS Conference, 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Winograd Schema (WS) challenge, proposed as an al-ternative to the Turing\nTest, has become the new standard for evaluating progress in natural language\nunderstanding (NLU). In this paper we will not however be concerned with how\nthis challenge might be addressed. Instead, our aim here is threefold: (i) we\nwill first formally 'situate' the WS challenge in the\ndata-information-knowledge continuum, suggesting where in that continuum a good\nWS resides; (ii) we will show that a WS is just special case of a more general\nphenomenon in language understanding, namely the missing text phenomenon\n(henceforth, MTP) - in particular, we will argue that what we usually call\nthinking in the process of language understanding involves discovering a\nsignificant amount of 'missing text' - text that is not explicitly stated, but\nis often implicitly assumed as shared background knowledge; and (iii) we\nconclude by a brief discussion on why MTP is inconsistent with the data-driven\nand machine learning approach to language understanding.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 06:25:31 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 16:28:32 GMT"}, {"version": "v3", "created": "Tue, 12 Feb 2019 18:03:51 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Saba", "Walid S.", ""]]}, {"id": "1810.00329", "submitter": "Lu\\'is Alexandre", "authors": "Vasco Lopes and Lu\\'is A. Alexandre", "title": "An Overview of Blockchain Integration with Robotics and Artificial\n  Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain technology is growing everyday at a fast-passed rhythm and it's\npossible to integrate it with many systems, namely Robotics with AI services.\nHowever, this is still a recent field and there isn't yet a clear understanding\nof what it could potentially become. In this paper, we conduct an overview of\nmany different methods and platforms that try to leverage the power of\nblockchain into robotic systems, to improve AI services or to solve problems\nthat are present in the major blockchains, which can lead to the ability of\ncreating robotic systems with increased capabilities and security. We present\nan overview, discuss the methods and conclude the paper with our view on the\nfuture of the integration of these technologies.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 07:34:20 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Lopes", "Vasco", ""], ["Alexandre", "Lu\u00eds A.", ""]]}, {"id": "1810.00337", "submitter": "Xinyun Chen", "authors": "Xinyun Chen, Yuandong Tian", "title": "Learning to Perform Local Rewriting for Combinatorial Optimization", "comments": "Published in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search-based methods for hard combinatorial optimization are often guided by\nheuristics. Tuning heuristics in various conditions and situations is often\ntime-consuming. In this paper, we propose NeuRewriter that learns a policy to\npick heuristics and rewrite the local components of the current solution to\niteratively improve it until convergence. The policy factorizes into a\nregion-picking and a rule-picking component, each parameterized by a neural\nnetwork trained with actor-critic methods in reinforcement learning.\nNeuRewriter captures the general structure of combinatorial problems and shows\nstrong performance in three versatile tasks: expression simplification, online\njob scheduling and vehicle routing problems. NeuRewriter outperforms the\nexpression simplification component in Z3; outperforms DeepRM and Google\nOR-tools in online job scheduling; and outperforms recent neural baselines and\nGoogle OR-tools in vehicle routing problems.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 08:12:43 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 06:34:28 GMT"}, {"version": "v3", "created": "Thu, 31 Jan 2019 15:09:06 GMT"}, {"version": "v4", "created": "Fri, 24 May 2019 10:10:15 GMT"}, {"version": "v5", "created": "Wed, 30 Oct 2019 03:10:40 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Chen", "Xinyun", ""], ["Tian", "Yuandong", ""]]}, {"id": "1810.00347", "submitter": "Xiaoxiao Yin", "authors": "Xiaoxiao Yin, Daqi Zheng, Zhengdong Lu, Ruifang Liu", "title": "Neural Entity Reasoner for Global Consistency in NER", "comments": "8 pages, 3 figures, submitted to AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Neural Entity Reasoner (NE-Reasoner), a framework to introduce\nglobal consistency of recognized entities into Neural Reasoner over Named\nEntity Recognition (NER) task. Given an input sentence, the NE-Reasoner layer\ncan infer over multiple entities to increase the global consistency of output\nlabels, which then be transfered into entities for the input of next layer.\nNE-Reasoner inherits and develops some features from Neural Reasoner 1) a\nsymbolic memory, allowing it to exchange entities between layers. 2) the\nspecific interaction-pooling mechanism, allowing it to connect each local word\nto multiple global entities, and 3) the deep architecture, allowing it to\nbootstrap the recognized entity set from coarse to fine. Like human beings,\nNE-Reasoner is able to accommodate ambiguous words and Name Entities that\nrarely or never met before. Despite the symbolic information the model\nintroduced, NE-Reasoner can still be trained effectively in an end-to-end\nmanner via parameter sharing strategy. NE-Reasoner can outperform conventional\nNER models in most cases on both English and Chinese NER datasets. For example,\nit achieves state-of-art on CoNLL-2003 English NER dataset.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 09:28:57 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Yin", "Xiaoxiao", ""], ["Zheng", "Daqi", ""], ["Lu", "Zhengdong", ""], ["Liu", "Ruifang", ""]]}, {"id": "1810.00361", "submitter": "Manuel Fritsche", "authors": "Gino Brunner, Manuel Fritsche, Oliver Richter, Roger Wattenhofer", "title": "Using State Predictions for Value Regularization in Curiosity Driven\n  Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in sparse reward settings remains a challenge in Reinforcement\nLearning, which is often addressed by using intrinsic rewards. One promising\nstrategy is inspired by human curiosity, requiring the agent to learn to\npredict the future. In this paper a curiosity-driven agent is extended to use\nthese predictions directly for training. To achieve this, the agent predicts\nthe value function of the next state at any point in time. Subsequently, the\nconsistency of this prediction with the current value function is measured,\nwhich is then used as a regularization term in the loss function of the\nalgorithm. Experiments were made on grid-world environments as well as on a 3D\nnavigation task, both with sparse rewards. In the first case the extended agent\nis able to learn significantly faster than the baselines.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 11:29:55 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Brunner", "Gino", ""], ["Fritsche", "Manuel", ""], ["Richter", "Oliver", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1810.00424", "submitter": "Alexander Tong", "authors": "Alexander Tong, David van Dijk, Jay S. Stanley III, Matthew Amodio,\n  Kristina Yim, Rebecca Muhle, James Noonan, Guy Wolf, and Smita Krishnaswamy", "title": "Interpretable Neuron Structuring with Graph Spectral Regularization", "comments": "12 pages, 6 figures, presented at IDA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks are powerful approximators used to classify or embed\ndata into lower dimensional spaces, they are often regarded as black boxes with\nuninterpretable features. Here we propose Graph Spectral Regularization for\nmaking hidden layers more interpretable without significantly impacting\nperformance on the primary task. Taking inspiration from spatial organization\nand localization of neuron activations in biological networks, we use a graph\nLaplacian penalty to structure the activations within a layer. This penalty\nencourages activations to be smooth either on a predetermined graph or on a\nfeature-space graph learned from the data via co-activations of a hidden layer\nof the neural network. We show numerous uses for this additional structure\nincluding cluster indication and visualization in biological and image data\nsets.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 17:18:35 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 02:00:39 GMT"}, {"version": "v3", "created": "Thu, 24 Jan 2019 00:13:46 GMT"}, {"version": "v4", "created": "Mon, 27 May 2019 12:18:58 GMT"}, {"version": "v5", "created": "Fri, 14 Feb 2020 19:55:11 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Tong", "Alexander", ""], ["van Dijk", "David", ""], ["Stanley", "Jay S.", "III"], ["Amodio", "Matthew", ""], ["Yim", "Kristina", ""], ["Muhle", "Rebecca", ""], ["Noonan", "James", ""], ["Wolf", "Guy", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "1810.00428", "submitter": "Saeed Najafi", "authors": "Saeed Najafi, Colin Cherry, Grzegorz Kondrak", "title": "Efficient Sequence Labeling with Actor-Critic Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural approaches to sequence labeling often use a Conditional Random Field\n(CRF) to model their output dependencies, while Recurrent Neural Networks (RNN)\nare used for the same purpose in other tasks. We set out to establish RNNs as\nan attractive alternative to CRFs for sequence labeling. To do so, we address\none of the RNN's most prominent shortcomings, the fact that it is not exposed\nto its own errors with the maximum-likelihood training. We frame the prediction\nof the output sequence as a sequential decision-making process, where we train\nthe network with an adjusted actor-critic algorithm (AC-RNN). We\ncomprehensively compare this strategy with maximum-likelihood training for both\nRNNs and CRFs on three structured-output tasks. The proposed AC-RNN efficiently\nmatches the performance of the CRF on NER and CCG tagging, and outperforms it\non Machine Transliteration. We also show that our training strategy is\nsignificantly better than other techniques for addressing RNN's exposure bias,\nsuch as Scheduled Sampling, and Self-Critical policy training.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 17:31:52 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Najafi", "Saeed", ""], ["Cherry", "Colin", ""], ["Kondrak", "Grzegorz", ""]]}, {"id": "1810.00445", "submitter": "Daniela Inclezan", "authors": "Qinglin Zhang and Chris Benton and Daniela Inclezan", "title": "An Application of ASP Theories of Intentions to Understanding Restaurant\n  Scenarios: Insights and Narrative Corpus", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a practical application of Answer Set Programming to the\nunderstanding of narratives about restaurants. While this task was investigated\nin depth by Erik Mueller, exceptional scenarios remained a serious challenge\nfor his script-based story comprehension system. We present a methodology that\nremedies this issue by modeling characters in a restaurant episode as\nintentional agents. We focus especially on the refinement of certain components\nof this methodology in order to increase coverage and performance. We present a\nrestaurant story corpus that we created to design and evaluate our methodology.\nUnder consideration in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 18:39:23 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Zhang", "Qinglin", ""], ["Benton", "Chris", ""], ["Inclezan", "Daniela", ""]]}, {"id": "1810.00482", "submitter": "Annie Xie", "authors": "Annie Xie, Avi Singh, Sergey Levine, Chelsea Finn", "title": "Few-Shot Goal Inference for Visuomotor Learning and Planning", "comments": "Videos available at https://sites.google.com/view/few-shot-goals", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning and planning methods require an objective or reward\nfunction that encodes the desired behavior. Yet, in practice, there is a wide\nrange of scenarios where an objective is difficult to provide programmatically,\nsuch as tasks with visual observations involving unknown object positions or\ndeformable objects. In these cases, prior methods use engineered\nproblem-specific solutions, e.g., by instrumenting the environment with\nadditional sensors to measure a proxy for the objective. Such solutions require\na significant engineering effort on a per-task basis, and make it impractical\nfor robots to continuously learn complex skills outside of laboratory settings.\nWe aim to find a more general and scalable solution for specifying goals for\nrobot learning in unconstrained environments. To that end, we formulate the\nfew-shot objective learning problem, where the goal is to learn a task\nobjective from only a few example images of successful end states for that\ntask. We propose a simple solution to this problem: meta-learn a classifier\nthat can recognize new goals from a few examples. We show how this approach can\nbe used with both model-free reinforcement learning and visual model-based\nplanning and show results in three domains: rope manipulation from images in\nsimulation, visual navigation in a simulated 3D environment, and object\narrangement into user-specified configurations on a real robot.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 22:57:58 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Xie", "Annie", ""], ["Singh", "Avi", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1810.00510", "submitter": "Tianmin Shu", "authors": "Tianmin Shu, Caiming Xiong, Ying Nian Wu, Song-Chun Zhu", "title": "Interactive Agent Modeling by Learning to Probe", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of modeling the other agents, such as understanding their\nintentions and skills, is essential to an agent's interactions with other\nagents. Conventional agent modeling relies on passive observation from\ndemonstrations. In this work, we propose an interactive agent modeling scheme\nenabled by encouraging an agent to learn to probe. In particular, the probing\nagent (i.e. a learner) learns to interact with the environment and with a\ntarget agent (i.e., a demonstrator) to maximize the change in the observed\nbehaviors of that agent. Through probing, rich behaviors can be observed and\nare used for enhancing the agent modeling to learn a more accurate mind model\nof the target agent. Our framework consists of two learning processes: i)\nimitation learning for an approximated agent model and ii) pure\ncuriosity-driven reinforcement learning for an efficient probing policy to\ndiscover new behaviors that otherwise can not be observed. We have validated\nour approach in four different tasks. The experimental results suggest that the\nagent model learned by our approach i) generalizes better in novel scenarios\nthan the ones learned by passive observation, random probing, and other\ncuriosity-driven approaches do, and ii) can be used for enhancing performance\nin multiple applications including distilling optimal planning to a policy net,\ncollaboration, and competition. A video demo is available at\nhttps://www.dropbox.com/s/8mz6rd3349tso67/Probing_Demo.mov?dl=0\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 02:55:07 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Shu", "Tianmin", ""], ["Xiong", "Caiming", ""], ["Wu", "Ying Nian", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1810.00521", "submitter": "Walid Saba", "authors": "Walid S. Saba", "title": "A Simple Machine Learning Method for Commonsense Reasoning? A Short\n  Commentary on Trinh & Le (2018)", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a short Commentary on Trinh & Le (2018) (\"A Simple Method for\nCommonsense Reasoning\") that outlines three serious flaws in the cited paper\nand discusses why data-driven approaches cannot be considered as serious models\nfor the commonsense reasoning needed in natural language understanding in\ngeneral, and in reference resolution, in particular.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 03:58:00 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Saba", "Walid S.", ""]]}, {"id": "1810.00555", "submitter": "Theofanis Karaletsos", "authors": "Theofanis Karaletsos, Peter Dayan, Zoubin Ghahramani", "title": "Probabilistic Meta-Representations Of Neural Networks", "comments": "presented at UAI 2018 Uncertainty In Deep Learning Workshop (UDL AUG.\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Bayesian treatments of neural networks are typically characterized\nby weak prior and approximate posterior distributions according to which all\nthe weights are drawn independently. Here, we consider a richer prior\ndistribution in which units in the network are represented by latent variables,\nand the weights between units are drawn conditionally on the values of the\ncollection of those variables. This allows rich correlations between related\nweights, and can be seen as realizing a function prior with a Bayesian\ncomplexity regularizer ensuring simple solutions. We illustrate the resulting\nmeta-representations and representations, elucidating the power of this prior.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 07:15:32 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Karaletsos", "Theofanis", ""], ["Dayan", "Peter", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1810.00602", "submitter": "Shruti Tople", "authors": "Karan Grover, Shruti Tople, Shweta Shinde, Ranjita Bhagwan and\n  Ramachandran Ramjee", "title": "Privado: Practical and Secure DNN Inference with Enclaves", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud providers are extending support for trusted hardware primitives such as\nIntel SGX. Simultaneously, the field of deep learning is seeing enormous\ninnovation as well as an increase in adoption. In this paper, we ask a timely\nquestion: \"Can third-party cloud services use Intel SGX enclaves to provide\npractical, yet secure DNN Inference-as-a-service?\" We first demonstrate that\nDNN models executing inside enclaves are vulnerable to access pattern based\nattacks. We show that by simply observing access patterns, an attacker can\nclassify encrypted inputs with 97% and 71% attack accuracy for MNIST and\nCIFAR10 datasets on models trained to achieve 99% and 79% original accuracy\nrespectively. This motivates the need for PRIVADO, a system we have designed\nfor secure, easy-to-use, and performance efficient inference-as-a-service.\nPRIVADO is input-oblivious: it transforms any deep learning framework that is\nwritten in C/C++ to be free of input-dependent access patterns thus eliminating\nthe leakage. PRIVADO is fully-automated and has a low TCB: with zero developer\neffort, given an ONNX description of a model, it generates compact and\nenclave-compatible code which can be deployed on an SGX cloud platform. PRIVADO\nincurs low performance overhead: we use PRIVADO with Torch framework and show\nits overhead to be 17.18% on average on 11 different contemporary neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 10:13:42 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 15:03:14 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Grover", "Karan", ""], ["Tople", "Shruti", ""], ["Shinde", "Shweta", ""], ["Bhagwan", "Ranjita", ""], ["Ramjee", "Ramachandran", ""]]}, {"id": "1810.00660", "submitter": "Sina Ahmadi", "authors": "Sina Ahmadi", "title": "Attention-based Encoder-Decoder Networks for Spelling and Grammatical\n  Error Correction", "comments": "75 pages, 20 figures, submitted as a Master's thesis at the\n  University of Paris Descartes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic spelling and grammatical correction systems are one of the most\nwidely used tools within natural language applications. In this thesis, we\nassume the task of error correction as a type of monolingual machine\ntranslation where the source sentence is potentially erroneous and the target\nsentence should be the corrected form of the input. Our main focus in this\nproject is building neural network models for the task of error correction. In\nparticular, we investigate sequence-to-sequence and attention-based models\nwhich have recently shown a higher performance than the state-of-the-art of\nmany language processing problems. We demonstrate that neural machine\ntranslation models can be successfully applied to the task of error correction.\n  While the experiments of this research are performed on an Arabic corpus, our\nmethods in this thesis can be easily applied to any language.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 23:47:42 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Ahmadi", "Sina", ""]]}, {"id": "1810.00663", "submitter": "Xiaoxue Zang", "authors": "Xiaoxue Zang, Ashwini Pokle, Marynel V\\'azquez, Kevin Chen, Juan\n  Carlos Niebles, Alvaro Soto and Silvio Savarese", "title": "Translating Navigation Instructions in Natural Language to a High-Level\n  Plan for Behavioral Robot Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end deep learning model for translating free-form\nnatural language instructions to a high-level plan for behavioral robot\nnavigation. We use attention models to connect information from both the user\ninstructions and a topological representation of the environment. We evaluate\nour model's performance on a new dataset containing 10,050 pairs of navigation\ninstructions. Our model significantly outperforms baseline approaches.\nFurthermore, our results suggest that it is possible to leverage the\nenvironment map as a relevant knowledge base to facilitate the translation of\nfree-form navigational instruction.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 06:09:20 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Zang", "Xiaoxue", ""], ["Pokle", "Ashwini", ""], ["V\u00e1zquez", "Marynel", ""], ["Chen", "Kevin", ""], ["Niebles", "Juan Carlos", ""], ["Soto", "Alvaro", ""], ["Savarese", "Silvio", ""]]}, {"id": "1810.00671", "submitter": "Hui Su", "authors": "Hui Su, Xiaoyu Shen, Wenjie Li and Dietrich Klakow", "title": "NEXUS Network: Connecting the Preceding and the Following in Dialogue\n  Generation", "comments": "Accepted by EMNLP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-Sequence (seq2seq) models have become overwhelmingly popular in\nbuilding end-to-end trainable dialogue systems. Though highly efficient in\nlearning the backbone of human-computer communications, they suffer from the\nproblem of strongly favoring short generic responses. In this paper, we argue\nthat a good response should smoothly connect both the preceding dialogue\nhistory and the following conversations. We strengthen this connection through\nmutual information maximization. To sidestep the non-differentiability of\ndiscrete natural language tokens, we introduce an auxiliary continuous code\nspace and map such code space to a learnable prior distribution for generation\npurpose. Experiments on two dialogue datasets validate the effectiveness of our\nmodel, where the generated responses are closely related to the dialogue\ncontext and lead to more interactive conversations.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 10:09:44 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2018 16:13:02 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Su", "Hui", ""], ["Shen", "Xiaoyu", ""], ["Li", "Wenjie", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1810.00685", "submitter": "Arnaud Martin", "authors": "Kuang Zhou (NPU), Arnaud Martin (DRUID), Quan Pan (NPU)", "title": "A belief combination rule for a large number of sources", "comments": "arXiv admin note: substantial text overlap with arXiv:1707.07999", "journal-ref": "Journal of Advances in Information Fusion, 2018, 13 (2)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of belief functions is widely used for data from multiple sources.\nDifferent evidence combination rules have been proposed in this framework\naccording to the properties of the sources to combine. However, most of these\ncombination rules are not efficient when there are a large number of sources.\nThis is due to either the complexity or the existence of an absorbing element\nsuch as the total conflict mass function for the conjunctive based rules when\napplied on unreliable evidence. In this paper, based on the assumption that the\nmajority of sources are reliable, a combination rule for a large number of\nsources is proposed using a simple idea: the more common ideas the sources\nshare, the more reliable these sources are supposed to be. This rule is\nadaptable for aggregating a large number of sources which may not all be\nreliable. It will keep the spirit of the conjunctive rule to reinforce the\nbelief on the focal elements with which the sources are in agreement. The mass\non the emptyset will be kept as an indicator of the conflict. The proposed\nrule, called LNS-CR (Conjunctive combinationRule for a Large Number of\nSources), is evaluated on synthetic mass functions. The experimental results\nverify that the rule can be effectively used to combine a large number of mass\nfunctions and to elicit the major opinion.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 08:24:26 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Zhou", "Kuang", "", "NPU"], ["Martin", "Arnaud", "", "DRUID"], ["Pan", "Quan", "", "NPU"]]}, {"id": "1810.00694", "submitter": "Fabio Massimo Zennaro", "authors": "Fabio Massimo Zennaro, Magdalena Ivanovska", "title": "Counterfactually Fair Prediction Using Multiple Causal Models", "comments": "18 pages, 5 figures, conference paper. arXiv admin note: text overlap\n  with arXiv:1805.09866", "journal-ref": null, "doi": "10.1007/978-3-030-14174-5_17", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the problem of making predictions using multiple\nstructural casual models defined by different agents, under the constraint that\nthe prediction satisfies the criterion of counterfactual fairness. Relying on\nthe frameworks of causality, fairness and opinion pooling, we build upon and\nextend previous work focusing on the qualitative aggregation of causal Bayesian\nnetworks and causal models. In order to complement previous qualitative\nresults, we devise a method based on Monte Carlo simulations. This method\nenables a decision-maker to aggregate the outputs of the causal models provided\nby different experts while guaranteeing the counterfactual fairness of the\nresult. We demonstrate our approach on a simple, yet illustrative, toy case\nstudy.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 13:11:27 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Zennaro", "Fabio Massimo", ""], ["Ivanovska", "Magdalena", ""]]}, {"id": "1810.00697", "submitter": "Ye Yuan", "authors": "Ye Yuan, Xiuchuan Tang, Wei Pan, Xiuting Li, Wei Zhou, Hai-Tao Zhang,\n  Han Ding, and Jorge Goncalves", "title": "Data-driven Discovery of Cyber-Physical Systems", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-019-12490-1", "report-no": null, "categories": "cs.SY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems (CPSs) embed software into the physical world. They\nappear in a wide range of applications such as smart grids, robotics,\nintelligent manufacture and medical monitoring. CPSs have proved resistant to\nmodeling due to their intrinsic complexity arising from the combination of\nphysical components and cyber components and the interaction between them. This\nstudy proposes a general framework for reverse engineering CPSs directly from\ndata. The method involves the identification of physical systems as well as the\ninference of transition logic. It has been applied successfully to a number of\nreal-world examples ranging from mechanical and electrical systems to medical\napplications. The novel framework seeks to enable researchers to make\npredictions concerning the trajectory of CPSs based on the discovered model.\nSuch information has been proven essential for the assessment of the\nperformance of CPS, the design of failure-proof CPS and the creation of design\nguidelines for new CPSs.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 13:22:41 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Yuan", "Ye", ""], ["Tang", "Xiuchuan", ""], ["Pan", "Wei", ""], ["Li", "Xiuting", ""], ["Zhou", "Wei", ""], ["Zhang", "Hai-Tao", ""], ["Ding", "Han", ""], ["Goncalves", "Jorge", ""]]}, {"id": "1810.00748", "submitter": "Vasile Patrascu", "authors": "Vasile Patrascu", "title": "Shannon Entropy for Neutrosophic Information", "comments": "Submitted for publication", "journal-ref": null, "doi": "10.13140/RG.2.2.32352.74244", "report-no": "R.C.E.I.T-1.9.18", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents an extension of Shannon entropy for neutrosophic\ninformation. This extension uses a new formula for distance between two\nneutrosophic triplets. In addition, the obtained results are particularized for\nbifuzzy, intuitionistic and paraconsistent fuzzy information.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 03:42:53 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Patrascu", "Vasile", ""]]}, {"id": "1810.00771", "submitter": "Theofrastos Mantadelis", "authors": "Theofrastos Mantadelis, Stefano Bistarelli", "title": "A Preliminary Report on Probabilistic Attack Normal Form for\n  Constellation Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  After Dung's founding work in Abstract Argumentation Frameworks there has\nbeen a growing interest in extending the Dung's semantics in order to describe\nmore complex or real life situations. Several of these approaches take the\ndirection of weighted or probabilistic extensions. One of the most prominent\nprobabilistic approaches is that of constellation Probabilistic Abstract\nArgumentation Frameworks from Li~et~al. In this paper, we present a normal form\nfor constellation probabilistic abstract argumentation frameworks. Furthermore,\nwe present a transformation from general constellation probabilistic abstract\nargumentation frameworks to the presented normal form. In this way we\nillustrate that the simpler normal form has equal representation power with the\ngeneral one.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 13:42:13 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Mantadelis", "Theofrastos", ""], ["Bistarelli", "Stefano", ""]]}, {"id": "1810.00782", "submitter": "Filip Ilievski", "authors": "Filip Ilievski, Eduard Hovy, Qizhe Xie, Piek Vossen", "title": "The Profiling Machine: Active Generalization over Knowledge", "comments": "AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human mind is a powerful multifunctional knowledge storage and management\nsystem that performs generalization, type inference, anomaly detection,\nstereotyping, and other tasks. A dynamic KR system that appropriately profiles\nover sparse inputs to provide complete expectations for unknown facets can help\nwith all these tasks. In this paper, we introduce the task of profiling,\ninspired by theories and findings in social psychology about the potential of\nprofiles for reasoning and information processing. We describe two generic\nstate-of-the-art neural architectures that can be easily instantiated as\nprofiling machines to generate expectations and applied to any kind of\nknowledge to fill gaps. We evaluate these methods against Wikidata and crowd\nexpectations, and compare the results to gain insight in the nature of\nknowledge captured by various profiling methods. We make all code and data\navailable to facilitate future research.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 16:03:49 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Ilievski", "Filip", ""], ["Hovy", "Eduard", ""], ["Xie", "Qizhe", ""], ["Vossen", "Piek", ""]]}, {"id": "1810.00869", "submitter": "Andrew Ross", "authors": "Andrew Slavin Ross", "title": "Training Machine Learning Models by Regularizing their Explanations", "comments": "Harvard CSE master's thesis; includes portions of arxiv:1703.03717\n  and arxiv:1711.09404", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are among the most accurate supervised learning methods in\nuse today. However, their opacity makes them difficult to trust in critical\napplications, especially when conditions in training may differ from those in\npractice. Recent efforts to develop explanations for neural networks and\nmachine learning models more generally have produced tools to shed light on the\nimplicit rules behind predictions. These tools can help us identify when models\nare right for the wrong reasons. However, they do not always scale to\nexplaining predictions for entire datasets, are not always at the right level\nof abstraction, and most importantly cannot correct the problems they reveal.\nIn this thesis, we explore the possibility of training machine learning models\n(with a particular focus on neural networks) using explanations themselves. We\nconsider approaches where models are penalized not only for making incorrect\npredictions but also for providing explanations that are either inconsistent\nwith domain knowledge or overly complex. These methods let us train models\nwhich can not only provide more interpretable rationales for their predictions\nbut also generalize better when training data is confounded or meaningfully\ndifferent from test data (even adversarially so).\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 17:43:21 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Ross", "Andrew Slavin", ""]]}, {"id": "1810.00873", "submitter": "Louis Mandel", "authors": "Guillaume Baudart, Javier Burroni, Martin Hirzel, Louis Mandel,\n  Avraham Shinnar", "title": "Compiling Stan to Generative Probabilistic Languages and Extension to\n  Deep Probabilistic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stan is a probabilistic programming language that is popular in the\nstatistics community, with a high-level syntax for expressing probabilistic\nmodels. Stan differs by nature from generative probabilistic programming\nlanguages like Church, Anglican, or Pyro. This paper presents a comprehensive\ncompilation scheme to compile any Stan model to a generative language and\nproves its correctness. We use our compilation scheme to build two new backends\nfor the Stanc3 compiler targeting Pyro and NumPyro. Experimental results show\nthat the NumPyro backend yields a 2.3x speedup compared to Stan in geometric\nmean over 26 benchmarks. Building on Pyro we extend Stan with support for\nexplicit variational inference guides and deep probabilistic models. That way,\nusers familiar with Stan get access to new features without having to learn a\nfundamentally new language.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 15:39:53 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 20:45:47 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 16:29:27 GMT"}, {"version": "v4", "created": "Tue, 12 Jan 2021 20:51:14 GMT"}, {"version": "v5", "created": "Sun, 11 Apr 2021 15:34:02 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Baudart", "Guillaume", ""], ["Burroni", "Javier", ""], ["Hirzel", "Martin", ""], ["Mandel", "Louis", ""], ["Shinnar", "Avraham", ""]]}, {"id": "1810.00912", "submitter": "Jianwei Yang", "authors": "Jianwei Yang, Jiasen Lu, Stefan Lee, Dhruv Batra, Devi Parikh", "title": "Visual Curiosity: Learning to Ask Questions to Learn Visual Recognition", "comments": "18 pages, 10 figures, Oral Presentation in Conference on Robot\n  Learning (CoRL) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an open-world setting, it is inevitable that an intelligent agent (e.g., a\nrobot) will encounter visual objects, attributes or relationships it does not\nrecognize. In this work, we develop an agent empowered with visual curiosity,\ni.e. the ability to ask questions to an Oracle (e.g., human) about the contents\nin images (e.g., What is the object on the left side of the red cube?) and\nbuild visual recognition model based on the answers received (e.g., Cylinder).\nIn order to do this, the agent must (1) understand what it recognizes and what\nit does not, (2) formulate a valid, unambiguous and informative language query\n(a question) to ask the Oracle, (3) derive the parameters of visual classifiers\nfrom the Oracle response and (4) leverage the updated visual classifiers to ask\nmore clarified questions. Specifically, we propose a novel framework and\nformulate the learning of visual curiosity as a reinforcement learning problem.\nIn this framework, all components of our agent, visual recognition module (to\nsee), question generation policy (to ask), answer digestion module (to\nunderstand) and graph memory module (to memorize), are learned entirely\nend-to-end to maximize the reward derived from the scene graph obtained by the\nagent as a consequence of the dialog with the Oracle. Importantly, the question\ngeneration policy is disentangled from the visual recognition system and\nspecifics of the environment. Consequently, we demonstrate a sort of double\ngeneralization. Our question generation policy generalizes to new environments\nand a new pair of eyes, i.e., new visual system. Trained on a synthetic\ndataset, our results show that our agent learns new visual concepts\nsignificantly faster than several heuristic baselines, even when tested on\nsynthetic environments with novel objects, as well as in a realistic\nenvironment.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 18:37:05 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Yang", "Jianwei", ""], ["Lu", "Jiasen", ""], ["Lee", "Stefan", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""]]}, {"id": "1810.00916", "submitter": "Volker Haarslev", "authors": "Humaira Farid and Volker Haarslev", "title": "Handling Nominals and Inverse Roles using Algebraic Reasoning", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel SHOI tableau calculus which incorporates\nalgebraic reasoning for deciding ontology consistency. Numerical restrictions\nimposed by nominals, existential and universal restrictions are encoded into a\nset of linear inequalities. Column generation and branch-and-price algorithms\nare used to solve these inequalities. Our preliminary experiments indicate that\nthis calculus performs better on SHOI ontologies than standard tableau methods.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 18:40:57 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Farid", "Humaira", ""], ["Haarslev", "Volker", ""]]}, {"id": "1810.01021", "submitter": "Amir Gholami", "authors": "Zhewei Yao, Amir Gholami, Daiyaan Arfeen, Richard Liaw, Joseph\n  Gonzalez, Kurt Keutzer, Michael Mahoney", "title": "Large batch size training of neural networks with adversarial training\n  and second-order information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most straightforward method to accelerate Stochastic Gradient Descent\n(SGD) computation is to distribute the randomly selected batch of inputs over\nmultiple processors. To keep the distributed processors fully utilized requires\ncommensurately growing the batch size. However, large batch training often\nleads to poorer generalization. A recently proposed solution for this problem\nis to use adaptive batch sizes in SGD. In this case, one starts with a small\nnumber of processes and scales the processes as training progresses. Two major\nchallenges with this approach are (i) that dynamically resizing the cluster can\nadd non-trivial overhead, in part since it is currently not supported, and (ii)\nthat the overall speed up is limited by the initial phase with smaller batches.\nIn this work, we address both challenges by developing a new adaptive batch\nsize framework, with autoscaling based on the Ray framework. This allows very\nefficient elastic scaling with negligible resizing overhead (0.32\\% of time for\nResNet18 ImageNet training). Furthermore, we propose a new adaptive batch size\ntraining scheme using second order methods and adversarial training. These\nenable increasing batch sizes earlier during training, which leads to better\ntraining time. We extensively evaluate our method on Cifar-10/100, SVHN,\nTinyImageNet, and ImageNet datasets, using multiple neural networks, including\nResNets and smaller networks such as SqueezeNext. Our method exceeds the\nperformance of existing solutions in terms of both accuracy and the number of\nSGD iterations (up to 1\\% and $5\\times$, respectively). Importantly, this is\nachieved without any additional hyper-parameter tuning to tailor our method in\nany of these experiments.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 00:31:46 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 20:56:27 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2020 00:16:36 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Yao", "Zhewei", ""], ["Gholami", "Amir", ""], ["Arfeen", "Daiyaan", ""], ["Liaw", "Richard", ""], ["Gonzalez", "Joseph", ""], ["Keutzer", "Kurt", ""], ["Mahoney", "Michael", ""]]}, {"id": "1810.01054", "submitter": "Yuanming Hu", "authors": "Yuanming Hu, Jiancheng Liu, Andrew Spielberg, Joshua B. Tenenbaum,\n  William T. Freeman, Jiajun Wu, Daniela Rus, Wojciech Matusik", "title": "ChainQueen: A Real-Time Differentiable Physical Simulator for Soft\n  Robotics", "comments": "In submission to ICRA 2019. Supplemental Video:\n  https://www.youtube.com/watch?v=4IWD4iGIsB4 Project Page:\n  https://github.com/yuanming-hu/ChainQueen", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical simulators have been widely used in robot planning and control.\nAmong them, differentiable simulators are particularly favored, as they can be\nincorporated into gradient-based optimization algorithms that are efficient in\nsolving inverse problems such as optimal control and motion planning.\nSimulating deformable objects is, however, more challenging compared to rigid\nbody dynamics. The underlying physical laws of deformable objects are more\ncomplex, and the resulting systems have orders of magnitude more degrees of\nfreedom and therefore they are significantly more computationally expensive to\nsimulate. Computing gradients with respect to physical design or controller\nparameters is typically even more computationally challenging. In this paper,\nwe propose a real-time, differentiable hybrid Lagrangian-Eulerian physical\nsimulator for deformable objects, ChainQueen, based on the Moving Least Squares\nMaterial Point Method (MLS-MPM). MLS-MPM can simulate deformable objects\nincluding contact and can be seamlessly incorporated into inference, control\nand co-design systems. We demonstrate that our simulator achieves high\nprecision in both forward simulation and backward gradient computation. We have\nsuccessfully employed it in a diverse set of control tasks for soft robots,\nincluding problems with nearly 3,000 decision variables.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 03:48:42 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Hu", "Yuanming", ""], ["Liu", "Jiancheng", ""], ["Spielberg", "Andrew", ""], ["Tenenbaum", "Joshua B.", ""], ["Freeman", "William T.", ""], ["Wu", "Jiajun", ""], ["Rus", "Daniela", ""], ["Matusik", "Wojciech", ""]]}, {"id": "1810.01104", "submitter": "Yang Zhong", "authors": "Yang Zhong, Vladimir Li, Ryuzo Okada, Atsuto Maki", "title": "Target Aware Network Adaptation for Efficient Representation Learning", "comments": "Accepted by the ECCV'18 Workshops (2nd International Workshop on\n  Compact and Efficient Feature Representation and Learning in Computer Vision)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an automatic network adaptation method that finds a\nConvNet structure well-suited to a given target task, e.g., image\nclassification, for efficiency as well as accuracy in transfer learning. We\ncall the concept target-aware transfer learning. Given only small-scale labeled\ndata, and starting from an ImageNet pre-trained network, we exploit a scheme of\nremoving its potential redundancy for the target task through iterative\noperations of filter-wise pruning and network optimization. The basic\nmotivation is that compact networks are on one hand more efficient and should\nalso be more tolerant, being less complex, against the risk of overfitting\nwhich would hinder the generalization of learned representations in the context\nof transfer learning. Further, unlike existing methods involving network\nsimplification, we also let the scheme identify redundant portions across the\nentire network, which automatically results in a network structure adapted to\nthe task at hand. We achieve this with a few novel ideas: (i) cumulative sum of\nactivation statistics for each layer, and (ii) a priority evaluation of pruning\nacross multiple layers. Experimental results by the method on five datasets\n(Flower102, CUB200-2011, Dog120, MIT67, and Stanford40) show favorable\naccuracies over the related state-of-the-art techniques while enhancing the\ncomputational and storage efficiency of the transferred model.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 08:01:48 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Zhong", "Yang", ""], ["Li", "Vladimir", ""], ["Okada", "Ryuzo", ""], ["Maki", "Atsuto", ""]]}, {"id": "1810.01109", "submitter": "Andrey Ignatov", "authors": "Andrey Ignatov, Radu Timofte, William Chou, Ke Wang, Max Wu, Tim\n  Hartley, Luc Van Gool", "title": "AI Benchmark: Running Deep Neural Networks on Android Smartphones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last years, the computational power of mobile devices such as\nsmartphones and tablets has grown dramatically, reaching the level of desktop\ncomputers available not long ago. While standard smartphone apps are no longer\na problem for them, there is still a group of tasks that can easily challenge\neven high-end devices, namely running artificial intelligence algorithms. In\nthis paper, we present a study of the current state of deep learning in the\nAndroid ecosystem and describe available frameworks, programming models and the\nlimitations of running AI on smartphones. We give an overview of the hardware\nacceleration resources available on four main mobile chipset platforms:\nQualcomm, HiSilicon, MediaTek and Samsung. Additionally, we present the\nreal-world performance results of different mobile SoCs collected with AI\nBenchmark that are covering all main existing hardware configurations.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 08:24:09 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 08:09:24 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Ignatov", "Andrey", ""], ["Timofte", "Radu", ""], ["Chou", "William", ""], ["Wang", "Ke", ""], ["Wu", "Max", ""], ["Hartley", "Tim", ""], ["Van Gool", "Luc", ""]]}, {"id": "1810.01112", "submitter": "Per-Arne Andersen", "authors": "Per-Arne Andersen, Morten Goodwin, Ole-Christoffer Granmo", "title": "The Dreaming Variational Autoencoder for Reinforcement Learning\n  Environments", "comments": "Best Student Paper Award, Proceedings of the 38th SGAI International\n  Conference on Artificial Intelligence, Cambridge, UK, 2018, Artificial\n  Intelligence XXXV, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has shown great potential in generalizing over raw\nsensory data using only a single neural network for value optimization. There\nare several challenges in the current state-of-the-art reinforcement learning\nalgorithms that prevent them from converging towards the global optima. It is\nlikely that the solution to these problems lies in short- and long-term\nplanning, exploration and memory management for reinforcement learning\nalgorithms. Games are often used to benchmark reinforcement learning algorithms\nas they provide a flexible, reproducible, and easy to control environment.\nRegardless, few games feature a state-space where results in exploration,\nmemory, and planning are easily perceived. This paper presents The Dreaming\nVariational Autoencoder (DVAE), a neural network based generative modeling\narchitecture for exploration in environments with sparse feedback. We further\npresent Deep Maze, a novel and flexible maze engine that challenges DVAE in\npartial and fully-observable state-spaces, long-horizon tasks, and\ndeterministic and stochastic problems. We show initial findings and encourage\nfurther work in reinforcement learning driven by generative exploration.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 08:31:39 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Andersen", "Per-Arne", ""], ["Goodwin", "Morten", ""], ["Granmo", "Ole-Christoffer", ""]]}, {"id": "1810.01127", "submitter": "Andrea Martin", "authors": "Andrea E. Martin, Leonidas A. A. Doumas", "title": "Predicate learning in neural systems: Discovering latent generative\n  structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans learn complex latent structures from their environments (e.g., natural\nlanguage, mathematics, music, social hierarchies). In cognitive science and\ncognitive neuroscience, models that infer higher-order structures from sensory\nor first-order representations have been proposed to account for the complexity\nand flexibility of human behavior. But how do the structures that these models\ninvoke arise in neural systems in the first place? To answer this question, we\nexplain how a system can learn latent representational structures (i.e.,\npredicates) from experience with wholly unstructured data. During the process\nof predicate learning, an artificial neural network exploits the naturally\noccurring dynamic properties of distributed computing across neuronal\nassemblies in order to learn predicates, but also to combine them\ncompositionally, two computational aspects which appear to be necessary for\nhuman behavior as per formal theories in multiple domains. We describe how\npredicates can be combined generatively using neural oscillations to achieve\nhuman-like extrapolation and compositionality in an artificial neural network.\nThe ability to learn predicates from experience, to represent structures\ncompositionally, and to extrapolate to unseen data offers an inroads to\nunderstanding and modeling the most complex human behaviors.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 09:15:00 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Martin", "Andrea E.", ""], ["Doumas", "Leonidas A. A.", ""]]}, {"id": "1810.01128", "submitter": "Vikash Kumar", "authors": "Suraj Nair, Mohammad Babaeizadeh, Chelsea Finn, Sergey Levine, Vikash\n  Kumar", "title": "Time Reversal as Self-Supervision", "comments": "7 pages, 10 figures", "journal-ref": "International Conference on Robotics and Automation, 2020", "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A longstanding challenge in robot learning for manipulation tasks has been\nthe ability to generalize to varying initial conditions, diverse objects, and\nchanging objectives. Learning based approaches have shown promise in producing\nrobust policies, but require heavy supervision to efficiently learn precise\ncontrol, especially from visual inputs. We propose a novel self-supervision\ntechnique that uses time-reversal to learn goals and provide a high level plan\nto reach them. In particular, we introduce the time-reversal model (TRM), a\nself-supervised model which explores outward from a set of goal states and\nlearns to predict these trajectories in reverse. This provides a high level\nplan towards goals, allowing us to learn complex manipulation tasks with no\ndemonstrations or exploration at test time. We test our method on the domain of\nassembly, specifically the mating of tetris-style block pairs. Using our method\noperating atop visual model predictive control, we are able to assemble tetris\nblocks on a physical robot using only uncalibrated RGB camera input, and\ngeneralize to unseen block pairs. sites.google.com/view/time-reversal\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 09:15:58 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 19:04:24 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Nair", "Suraj", ""], ["Babaeizadeh", "Mohammad", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""], ["Kumar", "Vikash", ""]]}, {"id": "1810.01165", "submitter": "Tao Li", "authors": "Tao Li, Xudong Liu, Shihan Su", "title": "Semi-supervised Text Regression with Conditional Generative Adversarial\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1109/BigData.2018.8622140", "report-no": null, "categories": "cs.CL cs.AI q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enormous online textual information provides intriguing opportunities for\nunderstandings of social and economic semantics. In this paper, we propose a\nnovel text regression model based on a conditional generative adversarial\nnetwork (GAN), with an attempt to associate textual data and social outcomes in\na semi-supervised manner. Besides promising potential of predicting\ncapabilities, our superiorities are twofold: (i) the model works with\nunbalanced datasets of limited labelled data, which align with real-world\nscenarios; and (ii) predictions are obtained by an end-to-end framework,\nwithout explicitly selecting high-level representations. Finally we point out\nrelated datasets for experiments and future research directions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 10:35:13 GMT"}, {"version": "v2", "created": "Sun, 11 Nov 2018 05:37:37 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Li", "Tao", ""], ["Liu", "Xudong", ""], ["Su", "Shihan", ""]]}, {"id": "1810.01176", "submitter": "Hyoungseok Kim", "authors": "Hyoungseok Kim, Jaekyeom Kim, Yeonwoo Jeong, Sergey Levine, Hyun Oh\n  Song", "title": "EMI: Exploration with Mutual Information", "comments": "Accepted and to appear at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms struggle when the reward signal is very\nsparse. In these cases, naive random exploration methods essentially rely on a\nrandom walk to stumble onto a rewarding state. Recent works utilize intrinsic\nmotivation to guide the exploration via generative models, predictive forward\nmodels, or discriminative modeling of novelty. We propose EMI, which is an\nexploration method that constructs embedding representation of states and\nactions that does not rely on generative decoding of the full observation but\nextracts predictive signals that can be used to guide exploration based on\nforward prediction in the representation space. Our experiments show\ncompetitive results on challenging locomotion tasks with continuous control and\non image-based exploration tasks with discrete actions on Atari. The source\ncode is available at https://github.com/snu-mllab/EMI .\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 11:33:57 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 15:26:16 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 13:50:56 GMT"}, {"version": "v4", "created": "Thu, 24 Jan 2019 01:07:50 GMT"}, {"version": "v5", "created": "Tue, 14 May 2019 07:06:05 GMT"}, {"version": "v6", "created": "Thu, 13 Jun 2019 05:41:38 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Kim", "Hyoungseok", ""], ["Kim", "Jaekyeom", ""], ["Jeong", "Yeonwoo", ""], ["Levine", "Sergey", ""], ["Song", "Hyun Oh", ""]]}, {"id": "1810.01256", "submitter": "Yang Chen", "authors": "Guanxiong Zeng, Yang Chen, Bo Cui, Shan Yu", "title": "Continual Learning of Context-dependent Processing in Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1038/s42256-019-0080-x", "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are powerful tools in learning sophisticated but\nfixed mapping rules between inputs and outputs, thereby limiting their\napplication in more complex and dynamic situations in which the mapping rules\nare not kept the same but changing according to different contexts. To lift\nsuch limits, we developed a novel approach involving a learning algorithm,\ncalled orthogonal weights modification (OWM), with the addition of a\ncontext-dependent processing (CDP) module. We demonstrated that with OWM to\novercome the problem of catastrophic forgetting, and the CDP module to learn\nhow to reuse a feature representation and a classifier for different contexts,\na single network can acquire numerous context-dependent mapping rules in an\nonline and continual manner, with as few as $\\sim$10 samples to learn each.\nThis should enable highly compact systems to gradually learn myriad\nregularities of the real world and eventually behave appropriately within it.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 09:45:08 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 15:36:51 GMT"}, {"version": "v3", "created": "Sun, 27 Jun 2021 13:38:39 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zeng", "Guanxiong", ""], ["Chen", "Yang", ""], ["Cui", "Bo", ""], ["Yu", "Shan", ""]]}, {"id": "1810.01257", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Shixiang Gu, Honglak Lee, Sergey Levine", "title": "Near-Optimal Representation Learning for Hierarchical Reinforcement\n  Learning", "comments": "ICLR 2019 Conference Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of representation learning in goal-conditioned\nhierarchical reinforcement learning. In such hierarchical structures, a\nhigher-level controller solves tasks by iteratively communicating goals which a\nlower-level policy is trained to reach. Accordingly, the choice of\nrepresentation -- the mapping of observation space to goal space -- is crucial.\nTo study this problem, we develop a notion of sub-optimality of a\nrepresentation, defined in terms of expected reward of the optimal hierarchical\npolicy using this representation. We derive expressions which bound the\nsub-optimality and show how these expressions can be translated to\nrepresentation learning objectives which may be optimized in practice. Results\non a number of difficult continuous-control tasks show that our approach to\nrepresentation learning yields qualitatively better representations as well as\nquantitatively better hierarchical policies, compared to existing methods (see\nvideos at https://sites.google.com/view/representation-hrl).\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 14:00:14 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 16:00:49 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Nachum", "Ofir", ""], ["Gu", "Shixiang", ""], ["Lee", "Honglak", ""], ["Levine", "Sergey", ""]]}, {"id": "1810.01266", "submitter": "Mohit Sharma", "authors": "Arjun Sharma, Mohit Sharma, Nicholas Rhinehart, Kris M. Kitani", "title": "Directed-Info GAIL: Learning Hierarchical Policies from Unsegmented\n  Demonstrations using Directed Information", "comments": "Accepted as conference paper at ICLR'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of imitation learning to learn a single policy for a complex task\nthat has multiple modes or hierarchical structure can be challenging. In fact,\nprevious work has shown that when the modes are known, learning separate\npolicies for each mode or sub-task can greatly improve the performance of\nimitation learning. In this work, we discover the interaction between sub-tasks\nfrom their resulting state-action trajectory sequences using a directed\ngraphical model. We propose a new algorithm based on the generative adversarial\nimitation learning framework which automatically learns sub-task policies from\nunsegmented demonstrations. Our approach maximizes the directed information\nflow in the graphical model between sub-task latent variables and their\ngenerated trajectories. We also show how our approach connects with the\nexisting Options framework, which is commonly used to learn hierarchical\npolicies.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 18:40:13 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 02:06:19 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Sharma", "Arjun", ""], ["Sharma", "Mohit", ""], ["Rhinehart", "Nicholas", ""], ["Kitani", "Kris M.", ""]]}, {"id": "1810.01268", "submitter": "Yash Sharma", "authors": "Yash Sharma, Tien-Dung Le, Moustafa Alzantot", "title": "CAAD 2018: Generating Transferable Adversarial Examples", "comments": "1st place attack solutions and 3rd place defense in CAAD 2018\n  Competition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to adversarial examples,\nperturbations carefully crafted to fool the targeted DNN, in both the\nnon-targeted and targeted case. In the non-targeted case, the attacker simply\naims to induce misclassification. In the targeted case, the attacker aims to\ninduce classification to a specified target class. In addition, it has been\nobserved that strong adversarial examples can transfer to unknown models,\nyielding a serious security concern. The NIPS 2017 competition was organized to\naccelerate research in adversarial attacks and defenses, taking place in the\nrealistic setting where submitted adversarial attacks attempt to transfer to\nsubmitted defenses. The CAAD 2018 competition took place with nearly identical\nrules to the NIPS 2017 one. Given the requirement that the NIPS 2017\nsubmissions were to be open-sourced, participants in the CAAD 2018 competition\nwere able to directly build upon previous solutions, and thus improve the\nstate-of-the-art in this setting. Our team participated in the CAAD 2018\ncompetition, and won 1st place in both attack subtracks, non-targeted and\ntargeted adversarial attacks, and 3rd place in defense. We outline our\nsolutions and development results in this article. We hope our results can\ninform researchers in both generating and defending against adversarial\nexamples.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 17:57:24 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 08:32:51 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Sharma", "Yash", ""], ["Le", "Tien-Dung", ""], ["Alzantot", "Moustafa", ""]]}, {"id": "1810.01270", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Rafael M. O. Cruz, Robert Sabourin, George D. C. Cavalcanti and Tsang\n  Ing Ren", "title": "META-DES: A Dynamic Ensemble Selection Framework using Meta-Learning", "comments": "Article published on Pattern Recognition. arXiv admin note: text\n  overlap with arXiv:1509.00825", "journal-ref": "Pattern Recognition Volume 48, Issue 5, Pages 1925-1935", "doi": "10.1016/j.patcog.2014.12.003", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic ensemble selection systems work by estimating the level of competence\nof each classifier from a pool of classifiers. Only the most competent ones are\nselected to classify a given test sample. This is achieved by defining a\ncriterion to measure the level of competence of a base classifier, such as, its\naccuracy in local regions of the feature space around the query instance.\nHowever, using only one criterion about the behavior of a base classifier is\nnot sufficient to accurately estimate its level of competence. In this paper,\nwe present a novel dynamic ensemble selection framework using meta-learning. We\npropose five distinct sets of meta-features, each one corresponding to a\ndifferent criterion to measure the level of competence of a classifier for the\nclassification of input samples. The meta-features are extracted from the\ntraining data and used to train a meta-classifier to predict whether or not a\nbase classifier is competent enough to classify an input instance. During the\ngeneralization phase, the meta-features are extracted from the query instance\nand passed down as input to the meta-classifier. The meta-classifier estimates,\nwhether a base classifier is competent enough to be added to the ensemble.\nExperiments are conducted over several small sample size classification\nproblems, i.e., problems with a high degree of uncertainty due to the lack of\ntraining data. Experimental results show the proposed meta-learning framework\ngreatly improves classification accuracy when compared against current\nstate-of-the-art dynamic ensemble selection techniques.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 00:27:49 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""], ["Cavalcanti", "George D. C.", ""], ["Ren", "Tsang Ing", ""]]}, {"id": "1810.01279", "submitter": "Xuanqing Liu", "authors": "Xuanqing Liu, Yao Li, Chongruo Wu, Cho-Jui Hsieh", "title": "Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural\n  Network", "comments": "Code will be made available at\n  https://github.com/xuanqing94/BayesianDefense", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm to train a robust neural network against\nadversarial attacks. Our algorithm is motivated by the following two ideas.\nFirst, although recent work has demonstrated that fusing randomness can improve\nthe robustness of neural networks (Liu 2017), we noticed that adding noise\nblindly to all the layers is not the optimal way to incorporate randomness.\nInstead, we model randomness under the framework of Bayesian Neural Network\n(BNN) to formally learn the posterior distribution of models in a scalable way.\nSecond, we formulate the mini-max problem in BNN to learn the best model\ndistribution under adversarial attacks, leading to an adversarial-trained\nBayesian neural net. Experiment results demonstrate that the proposed algorithm\nachieves state-of-the-art performance under strong attacks. On CIFAR-10 with\nVGG network, our model leads to 14\\% accuracy improvement compared with\nadversarial training (Madry 2017) and random self-ensemble (Liu 2017) under PGD\nattack with $0.035$ distortion, and the gap becomes even larger on a subset of\nImageNet.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 05:23:15 GMT"}, {"version": "v2", "created": "Sat, 4 May 2019 06:39:11 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Liu", "Xuanqing", ""], ["Li", "Yao", ""], ["Wu", "Chongruo", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1810.01363", "submitter": "Rui Zhao", "authors": "Rui Zhao and Volker Tresp", "title": "Energy-Based Hindsight Experience Prioritization", "comments": "Published in Conference on Robot Learning (CoRL 2018) as oral\n  presentation (7%), Zurich, Switzerland", "journal-ref": "PMLR 87:113-122, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Hindsight Experience Replay (HER), a reinforcement learning agent is\ntrained by treating whatever it has achieved as virtual goals. However, in\nprevious work, the experience was replayed at random, without considering which\nepisode might be the most valuable for learning. In this paper, we develop an\nenergy-based framework for prioritizing hindsight experience in robotic\nmanipulation tasks. Our approach is inspired by the work-energy principle in\nphysics. We define a trajectory energy function as the sum of the transition\nenergy of the target object over the trajectory. We hypothesize that replaying\nepisodes that have high trajectory energy is more effective for reinforcement\nlearning in robotics. To verify our hypothesis, we designed a framework for\nhindsight experience prioritization based on the trajectory energy of goal\nstates. The trajectory energy function takes the potential, kinetic, and\nrotational energy into consideration. We evaluate our Energy-Based\nPrioritization (EBP) approach on four challenging robotic manipulation tasks in\nsimulation. Our empirical results show that our proposed method surpasses\nstate-of-the-art approaches in terms of both performance and sample-efficiency\non all four tasks, without increasing computational time. A video showing\nexperimental results is available at https://youtu.be/jtsF2tTeUGQ\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 16:42:35 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 08:04:51 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2018 14:44:40 GMT"}, {"version": "v4", "created": "Wed, 20 Feb 2019 10:15:33 GMT"}, {"version": "v5", "created": "Sun, 24 May 2020 07:57:13 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhao", "Rui", ""], ["Tresp", "Volker", ""]]}, {"id": "1810.01371", "submitter": "Rui Zhao", "authors": "Rui Zhao, Volker Tresp", "title": "Efficient Dialog Policy Learning via Positive Memory Retention", "comments": "Published in IEEE Spoken Language Technology (SLT 2018), Athens,\n  Greece", "journal-ref": null, "doi": "10.1109/SLT.2018.8639617", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the training of recurrent neural networks as\ngoal-oriented dialog agents using reinforcement learning. Training such agents\nwith policy gradients typically requires a large amount of samples. However,\nthe collection of the required data in form of conversations between chat-bots\nand human agents is time-consuming and expensive. To mitigate this problem, we\ndescribe an efficient policy gradient method using positive memory retention,\nwhich significantly increases the sample-efficiency. We show that our method is\n10 times more sample-efficient than policy gradients in extensive experiments\non a new synthetic number guessing game. Moreover, in a real-word visual object\ndiscovery game, the proposed method is twice as sample-efficient as policy\ngradients and shows state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:01:28 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 10:26:56 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 08:08:15 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhao", "Rui", ""], ["Tresp", "Volker", ""]]}, {"id": "1810.01398", "submitter": "Sara Sabour", "authors": "Sara Sabour, William Chan, Mohammad Norouzi", "title": "Optimal Completion Distillation for Sequence Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Optimal Completion Distillation (OCD), a training procedure for\noptimizing sequence to sequence models based on edit distance. OCD is\nefficient, has no hyper-parameters of its own, and does not require pretraining\nor joint optimization with conditional log-likelihood. Given a partial sequence\ngenerated by the model, we first identify the set of optimal suffixes that\nminimize the total edit distance, using an efficient dynamic programming\nalgorithm. Then, for each position of the generated sequence, we use a target\ndistribution that puts equal probability on the first token of all the optimal\nsuffixes. OCD achieves the state-of-the-art performance on end-to-end speech\nrecognition, on both Wall Street Journal and Librispeech datasets, achieving\n$9.3\\%$ WER and $4.5\\%$ WER respectively.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:44:44 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 21:30:20 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Sabour", "Sara", ""], ["Chan", "William", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1810.01541", "submitter": "Mihai Boicu", "authors": "Mihai Boicu, Dorin Marcu, Gheorghe Tecuci, Lou Kaiser, Chirag\n  Uttamsingh, Navya Kalale", "title": "Co-Arg: Cogent Argumentation with Crowd Elicitation", "comments": "Presented at AAAI FSS-18: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Co-Arg, a new type of cognitive assistant to an\nintelligence analyst that enables the synergistic integration of analyst\nimagination and expertise, computer knowledge and critical reasoning, and crowd\nwisdom, to draw defensible and persuasive conclusions from masses of evidence\nof all types, in a world that is changing all the time. Co-Arg's goal is to\nimprove the quality of the analytic results and enhance their understandability\nfor both experts and novices. The performed analysis is based on a sound and\ntransparent argumentation that links evidence to conclusions in a way that\nshows very clearly how the conclusions have been reached, what evidence was\nused and how, what is not known, and what assumptions have been made. The\nanalytic results are presented in a report describes the analytic conclusion\nand its probability, the main favoring and disfavoring arguments, the\njustification of the key judgments and assumptions, and the missing information\nthat might increase the accuracy of the solution.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 23:41:43 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Boicu", "Mihai", ""], ["Marcu", "Dorin", ""], ["Tecuci", "Gheorghe", ""], ["Kaiser", "Lou", ""], ["Uttamsingh", "Chirag", ""], ["Kalale", "Navya", ""]]}, {"id": "1810.01560", "submitter": "Debarpita Santra", "authors": "Debarpita Santra, Swapan Kumar Basu, Jyotsna Kumar Mandal, Subrata\n  Goswami", "title": "Rough set based lattice structure for knowledge representation in\n  medical expert systems: low back pain management case study", "comments": "34 pages, 2 figures, International Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of medical knowledge representation is to capture the detailed domain\nknowledge in a clinically efficient manner and to offer a reliable resolution\nwith the acquired knowledge. The knowledge base to be used by a medical expert\nsystem should allow incremental growth with inclusion of updated knowledge over\nthe time. As knowledge are gathered from a variety of knowledge sources by\ndifferent knowledge engineers, the problem of redundancy is an important\nconcern here due to increased processing time of knowledge and occupancy of\nlarge computational storage to accommodate all the gathered knowledge. Also\nthere may exist many inconsistent knowledge in the knowledge base. In this\npaper, we have proposed a rough set based lattice structure for knowledge\nrepresentation in medical expert systems which overcomes the problem of\nredundancy and inconsistency in knowledge and offers computational efficiency\nwith respect to both time and space. We have also generated an optimal set of\ndecision rules that would be used directly by the inference engine. The\nreliability of each rule has been measured using a new metric called\ncredibility factor, and the certainty and coverage factors of a decision rule\nhave been re-defined. With a set of decisions rules arranged in descending\norder according to their reliability measures, the medical expert system will\nconsider the highly reliable and certain rules at first, then it would search\nfor the possible and uncertain rules at later stage, if recommended by\nphysicians. The proposed knowledge representation technique has been\nillustrated using an example from the domain of low back pain. The proposed\nscheme ensures completeness, consistency, integrity, non-redundancy, and ease\nof access.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:44:16 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Santra", "Debarpita", ""], ["Basu", "Swapan Kumar", ""], ["Mandal", "Jyotsna Kumar", ""], ["Goswami", "Subrata", ""]]}, {"id": "1810.01566", "submitter": "Yunzhu Li", "authors": "Yunzhu Li, Jiajun Wu, Russ Tedrake, Joshua B. Tenenbaum, Antonio\n  Torralba", "title": "Learning Particle Dynamics for Manipulating Rigid Bodies, Deformable\n  Objects, and Fluids", "comments": "Accepted to ICLR 2019. Project Page: http://dpi.csail.mit.edu Video:\n  https://www.youtube.com/watch?v=FrPpP7aW3Lg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-life control tasks involve matters of various substances---rigid or soft\nbodies, liquid, gas---each with distinct physical behaviors. This poses\nchallenges to traditional rigid-body physics engines. Particle-based simulators\nhave been developed to model the dynamics of these complex scenes; however,\nrelying on approximation techniques, their simulation often deviates from\nreal-world physics, especially in the long term. In this paper, we propose to\nlearn a particle-based simulator for complex control tasks. Combining learning\nwith particle-based systems brings in two major benefits: first, the learned\nsimulator, just like other particle-based systems, acts widely on objects of\ndifferent materials; second, the particle-based representation poses strong\ninductive bias for learning: particles of the same type have the same dynamics\nwithin. This enables the model to quickly adapt to new environments of unknown\ndynamics within a few observations. We demonstrate robots achieving complex\nmanipulation tasks using the learned simulator, such as manipulating fluids and\ndeformable foam, with experiments both in simulation and in the real world. Our\nstudy helps lay the foundation for robot learning of dynamic scenes with\nparticle-based representations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 02:10:16 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 00:37:03 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Li", "Yunzhu", ""], ["Wu", "Jiajun", ""], ["Tedrake", "Russ", ""], ["Tenenbaum", "Joshua B.", ""], ["Torralba", "Antonio", ""]]}, {"id": "1810.01620", "submitter": "Wendi Xu", "authors": "Wendi Xu, Ming Zhang", "title": "Towards WARSHIP: Combining Components of Brain-Inspired Computing of RSH\n  for Image Super Resolution", "comments": "2018 5th IEEE International Conference on Cloud Computing and\n  Intelligence Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution of deep learning shows that some algorithmic tricks are more\ndurable , while others are not. To the best of our knowledge, we firstly\nsummarize 5 more durable and complete deep learning components for vision, that\nis, WARSHIP. Moreover, we give a biological overview of WARSHIP, emphasizing\nbrain-inspired computing of WARSHIP. As a step towards WARSHIP, our case study\nof image super resolution combines 3 components of RSH to deploy a CNN model of\nWARSHIP-XZNet, which performs a happy medium between speed and performance.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 08:10:03 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Xu", "Wendi", ""], ["Zhang", "Ming", ""]]}, {"id": "1810.01729", "submitter": "Jean Michel Loubes", "authors": "Philippe Besse, Celine Castets-Renard, Aurelien Garivier, Jean-Michel\n  Loubes", "title": "Can everyday AI be ethical. Fairness of Machine Learning Algorithms", "comments": "in French. L'IA du quotidien peut-elle \\^etre \\'ethique. Loyaut\\'e\n  des Algorithmes d'apprentissage automatique", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining big data and machine learning algorithms, the power of automatic\ndecision tools induces as much hope as fear. Many recently enacted European\nlegislation (GDPR) and French laws attempt to regulate the use of these tools.\nLeaving aside the well-identified problems of data confidentiality and\nimpediments to competition, we focus on the risks of discrimination, the\nproblems of transparency and the quality of algorithmic decisions. The detailed\nperspective of the legal texts, faced with the complexity and opacity of the\nlearning algorithms, reveals the need for important technological disruptions\nfor the detection or reduction of the discrimination risk, and for addressing\nthe right to obtain an explanation of the auto- matic decision. Since trust of\nthe developers and above all of the users (citizens, litigants, customers) is\nessential, algorithms exploiting personal data must be deployed in a strict\nethical framework. In conclusion, to answer this need, we list some ways of\ncontrols to be developed: institutional control, ethical charter, external\naudit attached to the issue of a label.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:30:47 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Besse", "Philippe", ""], ["Castets-Renard", "Celine", ""], ["Garivier", "Aurelien", ""], ["Loubes", "Jean-Michel", ""]]}, {"id": "1810.01763", "submitter": "Andrzej Kaczmarczyk", "authors": "Andrzej Kaczmarczyk, Piotr Faliszewski", "title": "Algorithms for Destructive Shift Bribery", "comments": "A short version of this paper appeared in the proceedings of AAMAS\n  '16", "journal-ref": "Autonomous Agents and Multi-Agent Systems volume 33, pages\n  275--297 (2019)", "doi": "10.1007/s10458-019-09403-3", "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of Destructive Shift Bribery. In this problem, we are\ngiven an election with a set of candidates and a set of voters (each ranking\nthe candidates from the best to the worst), a despised candidate $d$, a budget\n$B$, and prices for shifting $d$ back in the voters' rankings. The goal is to\nensure that $d$ is not a winner of the election. We show that this problem is\npolynomial-time solvable for scoring protocols (encoded in unary), the Bucklin\nand Simplified Bucklin rules, and the Maximin rule, but is NP-hard for the\nCopeland rule. This stands in contrast to the results for the constructive\nsetting (known from the literature), for which the problem is polynomial-time\nsolvable for $k$-Approval family of rules, but is NP-hard for the Borda,\nCopeland, and Maximin rules. We complement the analysis of the Copeland rule\nshowing W-hardness for the parameterization by the budget value, and by the\nnumber of affected voters. We prove that the problem is W-hard when\nparameterized by the number of voters even for unit prices. From the positive\nperspective we provide an efficient algorithm for solving the problem\nparameterized by the combined parameter the number of candidates and the\nmaximum bribery price (alternatively the number of different bribery prices).\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 14:30:48 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Kaczmarczyk", "Andrzej", ""], ["Faliszewski", "Piotr", ""]]}, {"id": "1810.01776", "submitter": "Renjie Chen", "authors": "Renjie Chen and Craig Gotsman", "title": "Efficient Fastest-Path Computations in Road Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the age of real-time online traffic information and GPS-enabled devices,\nfastest-path computations between two points in a road network modeled as a\ndirected graph, where each directed edge is weighted by a \"travel time\" value,\nare becoming a standard feature of many navigation-related applications. To\nsupport this, very efficient computation of these paths in very large road\nnetworks is critical. Fastest paths may be computed as minimal-cost paths in a\nweighted directed graph, but traditional minimal-cost path algorithms based on\nvariants of the classic Dijkstra algorithm do not scale well, as in the worst\ncase they may traverse the entire graph. A common improvement, which can\ndramatically reduce the number of traversed graph vertices, is the A*\nalgorithm, which requires a good heuristic lower bound on the minimal cost. We\nintroduce a simple, but very effective, heuristic function based on a small\nnumber of values assigned to each graph vertex. The values are based on graph\nseparators and computed efficiently in a preprocessing stage. We present\nexperimental results demonstrating that our heuristic provides estimates of the\nminimal cost which are superior to those of other heuristics. Our experiments\nshow that when used in the A* algorithm, this heuristic can reduce the number\nof vertices traversed by an order of magnitude compared to other heuristics.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 13:47:04 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Chen", "Renjie", ""], ["Gotsman", "Craig", ""]]}, {"id": "1810.01807", "submitter": "Romain Hennequin", "authors": "Jimena Royo-Letelier, Romain Hennequin, Viet-Anh Tran, Manuel\n  Moussallam", "title": "Disambiguating Music Artists at Scale with Audio Metric Learning", "comments": "published in ISMIR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of disambiguating large scale catalogs through the\ndefinition of an unknown artist clustering task. We explore the use of metric\nlearning techniques to learn artist embeddings directly from audio, and using a\ndedicated homonym artists dataset, we compare our method with a recent approach\nthat learn similar embeddings using artist classifiers. While both systems have\nthe ability to disambiguate unknown artists relying exclusively on audio, we\nshow that our system is more suitable in the case when enough audio data is\navailable for each artist in the train dataset. We also propose a new negative\nsampling method for metric learning that takes advantage of side information\nsuch as music genre during the learning phase and shows promising results for\nthe artist clustering task.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 15:49:43 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Royo-Letelier", "Jimena", ""], ["Hennequin", "Romain", ""], ["Tran", "Viet-Anh", ""], ["Moussallam", "Manuel", ""]]}, {"id": "1810.01811", "submitter": "Pratik Jawanpuria", "authors": "Mayank Meghwanshi, Pratik Jawanpuria, Anoop Kunchukuttan, Hiroyuki\n  Kasai, Bamdev Mishra", "title": "McTorch, a manifold optimization library for deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce McTorch, a manifold optimization library for deep\nlearning that extends PyTorch. It aims to lower the barrier for users wishing\nto use manifold constraints in deep learning applications, i.e., when the\nparameters are constrained to lie on a manifold. Such constraints include the\npopular orthogonality and rank constraints, and have been recently used in a\nnumber of applications in deep learning. McTorch follows PyTorch's architecture\nand decouples manifold definitions and optimizers, i.e., once a new manifold is\nadded it can be used with any existing optimizer and vice-versa. McTorch is\navailable at https://github.com/mctorch .\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 16:02:20 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 04:12:12 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Meghwanshi", "Mayank", ""], ["Jawanpuria", "Pratik", ""], ["Kunchukuttan", "Anoop", ""], ["Kasai", "Hiroyuki", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1810.01835", "submitter": "Lex Fridman", "authors": "Lex Fridman", "title": "Human-Centered Autonomous Vehicle Systems: Principles of Effective\n  Shared Autonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.HC cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building effective, enjoyable, and safe autonomous vehicles is a lot harder\nthan has historically been considered. The reason is that, simply put, an\nautonomous vehicle must interact with human beings. This interaction is not a\nrobotics problem nor a machine learning problem nor a psychology problem nor an\neconomics problem nor a policy problem. It is all of these problems put into\none. It challenges our assumptions about the limitations of human beings at\ntheir worst and the capabilities of artificial intelligence systems at their\nbest. This work proposes a set of principles for designing and building\nautonomous vehicles in a human-centered way that does not run away from the\ncomplexity of human nature but instead embraces it. We describe our development\nof the Human-Centered Autonomous Vehicle (HCAV) as an illustrative case study\nof implementing these principles in practice.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 16:36:22 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Fridman", "Lex", ""]]}, {"id": "1810.01836", "submitter": "Roberto Alonso", "authors": "Roberto Alonso and Stephan G\\\"unnemann", "title": "Mining Contrasting Quasi-Clique Patterns", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining dense quasi-cliques is a well-known clustering task with applications\nranging from social networks over collaboration graphs to document analysis.\nRecent work has extended this task to multiple graphs; i.e. the goal is to find\ngroups of vertices highly dense among multiple graphs. In this paper, we argue\nthat in a multi-graph scenario the sparsity is valuable for knowledge\nextraction as well. We introduce the concept of contrasting quasi-clique\npatterns: a collection of vertices highly dense in one graph but highly sparse\n(i.e. less connected) in a second graph. Thus, these patterns specifically\nhighlight the difference/contrast between the considered graphs. Based on our\nnovel model, we propose an algorithm that enables fast computation of\ncontrasting patterns by exploiting intelligent traversal and pruning\ntechniques. We showcase the potential of contrasting patterns on a variety of\nsynthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 16:42:33 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Alonso", "Roberto", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1810.01849", "submitter": "Sudeep Pillai", "authors": "Sudeep Pillai, Rares Ambrus, Adrien Gaidon", "title": "SuperDepth: Self-Supervised, Super-Resolved Monocular Depth Estimation", "comments": "6 pages, 5 figures, 2 tables, ICRA 2019 Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent techniques in self-supervised monocular depth estimation are\napproaching the performance of supervised methods, but operate in low\nresolution only. We show that high resolution is key towards high-fidelity\nself-supervised monocular depth prediction. Inspired by recent deep learning\nmethods for Single-Image Super-Resolution, we propose a sub-pixel convolutional\nlayer extension for depth super-resolution that accurately synthesizes\nhigh-resolution disparities from their corresponding low-resolution\nconvolutional features. In addition, we introduce a differentiable\nflip-augmentation layer that accurately fuses predictions from the image and\nits horizontally flipped version, reducing the effect of left and right shadow\nregions generated in the disparity map due to occlusions. Both contributions\nprovide significant performance gains over the state-of-the-art in\nself-supervised depth and pose estimation on the public KITTI benchmark. A\nvideo of our approach can be found at https://youtu.be/jKNgBeBMx0I.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 17:24:06 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Pillai", "Sudeep", ""], ["Ambrus", "Rares", ""], ["Gaidon", "Adrien", ""]]}, {"id": "1810.01868", "submitter": "{\\L}ukasz Maziarka", "authors": "{\\L}ukasz Maziarka, Marek \\'Smieja, Aleksandra Nowak, Jacek Tabor,\n  {\\L}ukasz Struski, Przemys{\\l}aw Spurek", "title": "Set Aggregation Network as a Trainable Pooling Layer", "comments": "ICONIP 2019", "journal-ref": "Neural Information Processing. ICONIP 2019", "doi": "10.1007/978-3-030-36711-4_35", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global pooling, such as max- or sum-pooling, is one of the key ingredients in\ndeep neural networks used for processing images, texts, graphs and other types\nof structured data. Based on the recent DeepSets architecture proposed by\nZaheer et al. (NIPS 2017), we introduce a Set Aggregation Network (SAN) as an\nalternative global pooling layer. In contrast to typical pooling operators, SAN\nallows to embed a given set of features to a vector representation of arbitrary\nsize. We show that by adjusting the size of embedding, SAN is capable of\npreserving the whole information from the input. In experiments, we demonstrate\nthat replacing global pooling layer by SAN leads to the improvement of\nclassification accuracy. Moreover, it is less prone to overfitting and can be\nused as a regularizer.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:20:13 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 08:44:25 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 10:25:02 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Maziarka", "\u0141ukasz", ""], ["\u015amieja", "Marek", ""], ["Nowak", "Aleksandra", ""], ["Tabor", "Jacek", ""], ["Struski", "\u0141ukasz", ""], ["Spurek", "Przemys\u0142aw", ""]]}, {"id": "1810.01870", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere, Nikolas Hemion, Micha\\\"el Garcia Ortiz,\n  Jean-Christophe Baillie", "title": "Grounding Perception: A Developmental Approach to Sensorimotor\n  Contingencies", "comments": "8 pages, 4 figures, workshop at IROS 2015 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensorimotor contingency theory offers a promising account of the nature of\nperception, a topic rarely addressed in the robotics community. We propose a\ndevelopmental framework to address the problem of the autonomous acquisition of\nsensorimotor contingencies by a naive robot. While exploring the world, the\nrobot internally encodes contingencies as predictive models that capture the\nstructure they imply in its sensorimotor experience. Three preliminary\napplications are presented to illustrate our approach to the acquisition of\nperceptive abilities: discovering the environment, discovering objects, and\ndiscovering a visual field.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:31:41 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""], ["Hemion", "Nikolas", ""], ["Ortiz", "Micha\u00ebl Garcia", ""], ["Baillie", "Jean-Christophe", ""]]}, {"id": "1810.01871", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere", "title": "Grounding the Experience of a Visual Field through Sensorimotor\n  Contingencies", "comments": "23 pages, 7 figures, published in Neurocomputing", "journal-ref": "Neurocomputing, Volume 268, 13 December 2017, Pages 142-152", "doi": "10.1016/j.neucom.2016.11.085", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial perception is traditionally handled by hand-designing task\nspecific algorithms. However, a truly autonomous robot should develop\nperceptive abilities on its own, by interacting with its environment, and\nadapting to new situations. The sensorimotor contingencies theory proposes to\nground the development of those perceptive abilities in the way the agent can\nactively transform its sensory inputs. We propose a sensorimotor approach,\ninspired by this theory, in which the agent explores the world and discovers\nits properties by capturing the sensorimotor regularities they induce. This\nwork presents an application of this approach to the discovery of a so-called\nvisual field as the set of regularities that a visual sensor imposes on a naive\nagent's experience. A formalism is proposed to describe how those regularities\ncan be captured in a sensorimotor predictive model. Finally, the approach is\nevaluated on a simulated system coarsely inspired from the human retina.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:42:43 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""]]}, {"id": "1810.01926", "submitter": "Mark Goadrich", "authors": "Mark Goadrich and James Droscha", "title": "Improving Solvability for Procedurally Generated Challenges in Physical\n  Solitaire Games Through Entangled Components", "comments": "10 pages, 19 figures. Accepted to IEEE Transactions on Games, Early\n  Access 5/24/2019", "journal-ref": null, "doi": "10.1109/TG.2019.2918223", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Challenges for physical solitaire puzzle games are typically designed in\nadvance by humans and limited in number. Alternatively, some games incorporate\nrules for stochastic setup, where the human solver randomly sets up the game\nboard before solving the challenge. These setup rules greatly increase the\nnumber of possible challenges, but can often generate unsolvable or\nuninteresting challenges. To better understand the compromises involved in\nminimizing undesirable challenges, we examine three games where component\ndesign choices can influence the stochastic nature of the resulting challenge\ngeneration algorithms. We evaluate the effect of these components and\nalgorithms on challenge solvability and challenge engagement. We find that\nalgorithms which control randomness through entangling components based on\nsub-elements of the puzzle mechanics can generate interesting challenges with a\nhigh probability of being solvable.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 19:35:44 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 20:21:11 GMT"}, {"version": "v3", "created": "Sun, 26 May 2019 03:09:43 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Goadrich", "Mark", ""], ["Droscha", "James", ""]]}, {"id": "1810.01937", "submitter": "Daniel Kang", "authors": "Animesh Koratana, Daniel Kang, Peter Bailis, Matei Zaharia", "title": "LIT: Block-wise Intermediate Representation Training for Model\n  Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) is a popular method for reducing the\ncomputational overhead of deep network inference, in which the output of a\nteacher model is used to train a smaller, faster student model. Hint training\n(i.e., FitNets) extends KD by regressing a student model's intermediate\nrepresentation to a teacher model's intermediate representation. In this work,\nwe introduce bLock-wise Intermediate representation Training (LIT), a novel\nmodel compression technique that extends the use of intermediate\nrepresentations in deep network compression, outperforming KD and hint\ntraining. LIT has two key ideas: 1) LIT trains a student of the same width (but\nshallower depth) as the teacher by directly comparing the intermediate\nrepresentations, and 2) LIT uses the intermediate representation from the\nprevious block in the teacher model as an input to the current student block\nduring training, avoiding unstable intermediate representations in the student\nnetwork. We show that LIT provides substantial reductions in network depth\nwithout loss in accuracy -- for example, LIT can compress a ResNeXt-110 to a\nResNeXt-20 (5.5x) on CIFAR10 and a VDCNN-29 to a VDCNN-9 (3.2x) on Amazon\nReviews without loss in accuracy, outperforming KD and hint training in network\nsize for a given accuracy. We also show that applying LIT to identical\nstudent/teacher architectures increases the accuracy of the student model above\nthe teacher model, outperforming the recently-proposed Born Again Networks\nprocedure on ResNet, ResNeXt, and VDCNN. Finally, we show that LIT can\neffectively compress GAN generators, which are not supported in the KD\nframework because GANs output pixels as opposed to probabilities.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 03:27:41 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Koratana", "Animesh", ""], ["Kang", "Daniel", ""], ["Bailis", "Peter", ""], ["Zaharia", "Matei", ""]]}, {"id": "1810.01943", "submitter": "Michael Hind", "authors": "Rachel K. E. Bellamy, Kuntal Dey, Michael Hind, Samuel C. Hoffman,\n  Stephanie Houde, Kalapriya Kannan, Pranay Lohia, Jacquelyn Martino, Sameep\n  Mehta, Aleksandra Mojsilovic, Seema Nagar, Karthikeyan Natesan Ramamurthy,\n  John Richards, Diptikalyan Saha, Prasanna Sattigeri, Moninder Singh, Kush R.\n  Varshney, Yunfeng Zhang", "title": "AI Fairness 360: An Extensible Toolkit for Detecting, Understanding, and\n  Mitigating Unwanted Algorithmic Bias", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness is an increasingly important concern as machine learning models are\nused to support decision making in high-stakes applications such as mortgage\nlending, hiring, and prison sentencing. This paper introduces a new open source\nPython toolkit for algorithmic fairness, AI Fairness 360 (AIF360), released\nunder an Apache v2.0 license {https://github.com/ibm/aif360). The main\nobjectives of this toolkit are to help facilitate the transition of fairness\nresearch algorithms to use in an industrial setting and to provide a common\nframework for fairness researchers to share and evaluate algorithms.\n  The package includes a comprehensive set of fairness metrics for datasets and\nmodels, explanations for these metrics, and algorithms to mitigate bias in\ndatasets and models. It also includes an interactive Web experience\n(https://aif360.mybluemix.net) that provides a gentle introduction to the\nconcepts and capabilities for line-of-business users, as well as extensive\ndocumentation, usage guidance, and industry-specific tutorials to enable data\nscientists and practitioners to incorporate the most appropriate tool for their\nproblem into their work products. The architecture of the package has been\nengineered to conform to a standard paradigm used in data science, thereby\nfurther improving usability for practitioners. Such architectural design and\nabstractions enable researchers and developers to extend the toolkit with their\nnew algorithms and improvements, and to use it for performance benchmarking. A\nbuilt-in testing infrastructure maintains code quality.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 20:18:35 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Bellamy", "Rachel K. E.", ""], ["Dey", "Kuntal", ""], ["Hind", "Michael", ""], ["Hoffman", "Samuel C.", ""], ["Houde", "Stephanie", ""], ["Kannan", "Kalapriya", ""], ["Lohia", "Pranay", ""], ["Martino", "Jacquelyn", ""], ["Mehta", "Sameep", ""], ["Mojsilovic", "Aleksandra", ""], ["Nagar", "Seema", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Richards", "John", ""], ["Saha", "Diptikalyan", ""], ["Sattigeri", "Prasanna", ""], ["Singh", "Moninder", ""], ["Varshney", "Kush R.", ""], ["Zhang", "Yunfeng", ""]]}, {"id": "1810.01973", "submitter": "Feng Shi", "authors": "Feng Shi, Haochen Li, Yuhe Gao, Benjamin Kuschner, Song-Chun Zhu", "title": "Sparse Winograd Convolutional neural networks on small-scale systolic\n  arrays", "comments": "submitted to FPGA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reconfigurability, energy-efficiency, and massive parallelism on FPGAs\nmake them one of the best choices for implementing efficient deep learning\naccelerators. However, state-of-art implementations seldom consider the balance\nbetween high throughput of computation power and the ability of the memory\nsubsystem to support it. In this paper, we implement an accelerator on FPGA by\ncombining the sparse Winograd convolution, clusters of small-scale systolic\narrays, and a tailored memory layout design. We also provide an analytical\nmodel analysis for the general Winograd convolution algorithm as a design\nreference. Experimental results on VGG16 show that it achieves very high\ncomputational resource utilization, 20x ~ 30x energy efficiency, and more than\n5x speedup compared with the dense implementation.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 21:01:51 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Shi", "Feng", ""], ["Li", "Haochen", ""], ["Gao", "Yuhe", ""], ["Kuschner", "Benjamin", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1810.01982", "submitter": "Junxuan Li", "authors": "Junxuan Li and Yung-wen Liu and Yuting Jia and Jay Nanduri", "title": "Discriminative Data-driven Self-adaptive Fraud Control Decision System\n  with Incomplete Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While E-commerce has been growing explosively and online shopping has become\npopular and even dominant in the present era, online transaction fraud control\nhas drawn considerable attention in business practice and academic research.\nConventional fraud control considers mainly the interactions of two major\ninvolved decision parties, i.e. merchants and fraudsters, to make fraud\nclassification decision without paying much attention to dynamic looping effect\narose from the decisions made by other profit-related parties. This paper\nproposes a novel fraud control framework that can quantify interactive effects\nof decisions made by different parties and can adjust fraud control strategies\nusing data analytics, artificial intelligence, and dynamic optimization\ntechniques. Three control models, Naive, Myopic and Prospective Controls, were\ndeveloped based on the availability of data attributes and levels of label\nmaturity. The proposed models are purely data-driven and self-adaptive in a\nreal-time manner. The field test on Microsoft real online transaction data\nsuggested that new systems could sizably improve the company's profit.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 21:40:32 GMT"}, {"version": "v2", "created": "Sat, 27 Jul 2019 23:20:55 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Li", "Junxuan", ""], ["Liu", "Yung-wen", ""], ["Jia", "Yuting", ""], ["Nanduri", "Jay", ""]]}, {"id": "1810.01989", "submitter": "Taylor T Johnson", "authors": "Weiming Xiang and Patrick Musau and Ayana A. Wild and Diego Manzanas\n  Lopez and Nathaniel Hamilton and Xiaodong Yang and Joel Rosenfeld and Taylor\n  T. Johnson", "title": "Verification for Machine Learning, Autonomy, and Neural Networks Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey presents an overview of verification techniques for autonomous\nsystems, with a focus on safety-critical autonomous cyber-physical systems\n(CPS) and subcomponents thereof. Autonomy in CPS is enabling by recent advances\nin artificial intelligence (AI) and machine learning (ML) through approaches\nsuch as deep neural networks (DNNs), embedded in so-called learning enabled\ncomponents (LECs) that accomplish tasks from classification to control.\nRecently, the formal methods and formal verification community has developed\nmethods to characterize behaviors in these LECs with eventual goals of formally\nverifying specifications for LECs, and this article presents a survey of many\nof these recent approaches.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 22:12:05 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Xiang", "Weiming", ""], ["Musau", "Patrick", ""], ["Wild", "Ayana A.", ""], ["Lopez", "Diego Manzanas", ""], ["Hamilton", "Nathaniel", ""], ["Yang", "Xiaodong", ""], ["Rosenfeld", "Joel", ""], ["Johnson", "Taylor T.", ""]]}, {"id": "1810.01992", "submitter": "Ankuj Arora Mr", "authors": "Ankuj Arora, Humbert Fiorino, Damien Pellier, Sylvie Pesty", "title": "Action Model Acquisition using LSTM", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of Automated Planning and Scheduling (APS), intelligent agents\nby virtue require an action model (blueprints of actions whose interleaved\nexecutions effectuates transitions of the system state) in order to plan and\nsolve real world problems. It is, however, becoming increasingly cumbersome to\ncodify this model, and is more efficient to learn it from observed plan\nexecution sequences (training data). While the underlying objective is to\nsubsequently plan from this learnt model, most approaches fall short as\nanything less than a flawless reconstruction of the underlying model renders it\nunusable in certain domains. This work presents a novel approach using long\nshort-term memory (LSTM) techniques for the acquisition of the underlying\naction model. We use the sequence labelling capabilities of LSTMs to isolate\nfrom an exhaustive model set a model identical to the one responsible for\nproducing the training data. This isolation capability renders our approach as\nan effective one.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 22:30:44 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Arora", "Ankuj", ""], ["Fiorino", "Humbert", ""], ["Pellier", "Damien", ""], ["Pesty", "Sylvie", ""]]}, {"id": "1810.02068", "submitter": "Cheng Fu", "authors": "Cheng Fu, Shilin Zhu, Hao Su, Ching-En Lee, Jishen Zhao", "title": "Towards Fast and Energy-Efficient Binarized Neural Network Inference on\n  FPGA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binarized Neural Network (BNN) removes bitwidth redundancy in classical CNN\nby using a single bit (-1/+1) for network parameters and intermediate\nrepresentations, which has greatly reduced the off-chip data transfer and\nstorage overhead. However, a large amount of computation redundancy still\nexists in BNN inference. By analyzing local properties of images and the\nlearned BNN kernel weights, we observe an average of $\\sim$78% input similarity\nand $\\sim$59% weight similarity among weight kernels, measured by our proposed\nmetric in common network architectures. Thus there does exist redundancy that\ncan be exploited to further reduce the amount of on-chip computations.\n  Motivated by the observation, in this paper, we proposed two types of fast\nand energy-efficient architectures for BNN inference. We also provide analysis\nand insights to pick the better strategy of these two for different datasets\nand network models. By reusing the results from previous computation, much\ncycles for data buffer access and computations can be skipped. By experiments,\nwe demonstrate that 80% of the computation and 40% of the buffer access can be\nskipped by exploiting BNN similarity. Thus, our design can achieve 17%\nreduction in total power consumption, 54% reduction in on-chip power\nconsumption and 2.4$\\times$ maximum speedup, compared to the baseline without\napplying our reuse technique. Our design also shows 1.9$\\times$ more\narea-efficiency compared to state-of-the-art BNN inference design. We believe\nour deployment of BNN on FPGA leads to a promising future of running deep\nlearning models on mobile devices.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 06:29:59 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Fu", "Cheng", ""], ["Zhu", "Shilin", ""], ["Su", "Hao", ""], ["Lee", "Ching-En", ""], ["Zhao", "Jishen", ""]]}, {"id": "1810.02126", "submitter": "Youssef Tamaazousti", "authors": "Julien Girard, Youssef Tamaazousti, Herv\\'e Le Borgne, C\\'eline\n  Hudelot", "title": "Learning Finer-class Networks for Universal Representations", "comments": "British Machine Vision Conference (BMVC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world visual recognition use-cases can not directly benefit from\nstate-of-the-art CNN-based approaches because of the lack of many annotated\ndata. The usual approach to deal with this is to transfer a representation\npre-learned on a large annotated source-task onto a target-task of interest.\nThis raises the question of how well the original representation is\n\"universal\", that is to say directly adapted to many different target-tasks. To\nimprove such universality, the state-of-the-art consists in training networks\non a diversified source problem, that is modified either by adding generic or\nspecific categories to the initial set of categories. In this vein, we proposed\na method that exploits finer-classes than the most specific ones existing, for\nwhich no annotation is available. We rely on unsupervised learning and a\nbottom-up split and merge strategy. We show that our method learns more\nuniversal representations than state-of-the-art, leading to significantly\nbetter results on 10 target-tasks from multiple domains, using several network\narchitectures, either alone or combined with networks learned at a coarser\nsemantic level.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 09:58:34 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Girard", "Julien", ""], ["Tamaazousti", "Youssef", ""], ["Borgne", "Herv\u00e9 Le", ""], ["Hudelot", "C\u00e9line", ""]]}, {"id": "1810.02196", "submitter": "Andrea Mazza", "authors": "Gianfranco Chicco and Andrea Mazza", "title": "Heuristic Optimization of Electrical Energy Systems: Refined Metrics to\n  Compare the Solutions", "comments": "Previous title: Heuristic Optimization of Electrical Energy Systems:\n  A Perpetual Motion Scheme and Refined Metrics to Compare the Solutions", "journal-ref": null, "doi": "10.1016/j.segan.2019.100197", "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many optimization problems admit a number of local optima, among which there\nis the global optimum. For these problems, various heuristic optimization\nmethods have been proposed. Comparing the results of these solvers requires the\ndefinition of suitable metrics. In the electrical energy systems literature,\nsimple metrics such as best value obtained, the mean value, the median or the\nstandard deviation of the solutions are still used. However, the comparisons\ncarried out with these metrics are rather weak, and on these bases a somehow\nuncontrolled proliferation of heuristic solvers is taking place. This paper\naddresses the overall issue of understanding the reasons of this proliferation,\nshowing a conceptual scheme that indicates how the assessment of the best\nsolver may result in the unlimited formulation of new solvers. Moreover, this\npaper shows how the use of more refined metrics defined to compare the\noptimization result, associated with the definition of appropriate benchmarks,\nmay make the comparisons among the solvers more robust. The proposed metrics\nare based on the concept of first-order stochastic dominance and are defined\nfor the cases in which: (i) the globally optimal solution can be found (for\ntesting purposes); and (ii) the number of possible solutions is so large that\npractically it cannot be guaranteed that the global optimum has been found.\nIllustrative examples are provided for a typical problem in the electrical\nenergy systems area-distribution network reconfiguration. The conceptual\nresults obtained are generally valid to compare the results of other\noptimization problems.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 12:43:58 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 07:35:19 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Chicco", "Gianfranco", ""], ["Mazza", "Andrea", ""]]}, {"id": "1810.02229", "submitter": "Tommaso Caselli", "authors": "Tommaso Caselli", "title": "Italian Event Detection Goes Deep Learning", "comments": "to appear at CLiC-it 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper reports on a set of experiments with different word embeddings to\ninitialize a state-of-the-art Bi-LSTM-CRF network for event detection and\nclassification in Italian, following the EVENTI evaluation exercise. The net-\nwork obtains a new state-of-the-art result by improving the F1 score for\ndetection of 1.3 points, and of 6.5 points for classification, by using a\nsingle step approach. The results also provide further evidence that embeddings\nhave a major impact on the performance of such architectures.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 14:09:20 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Caselli", "Tommaso", ""]]}, {"id": "1810.02244", "submitter": "Christopher Morris", "authors": "Christopher Morris, Martin Ritzert, Matthias Fey, William L. Hamilton,\n  Jan Eric Lenssen, Gaurav Rattan, Martin Grohe", "title": "Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks", "comments": "Extended version with proofs, accepted at AAAI 2019, added units of\n  measurement of QM9 dataset into appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, graph neural networks (GNNs) have emerged as a powerful\nneural architecture to learn vector representations of nodes and graphs in a\nsupervised, end-to-end fashion. Up to now, GNNs have only been evaluated\nempirically---showing promising results. The following work investigates GNNs\nfrom a theoretical point of view and relates them to the $1$-dimensional\nWeisfeiler-Leman graph isomorphism heuristic ($1$-WL). We show that GNNs have\nthe same expressiveness as the $1$-WL in terms of distinguishing non-isomorphic\n(sub-)graphs. Hence, both algorithms also have the same shortcomings. Based on\nthis, we propose a generalization of GNNs, so-called $k$-dimensional GNNs\n($k$-GNNs), which can take higher-order graph structures at multiple scales\ninto account. These higher-order structures play an essential role in the\ncharacterization of social networks and molecule graphs. Our experimental\nevaluation confirms our theoretical findings as well as confirms that\nhigher-order information is useful in the task of graph classification and\nregression.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 14:31:57 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 12:52:37 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 15:55:24 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Morris", "Christopher", ""], ["Ritzert", "Martin", ""], ["Fey", "Matthias", ""], ["Hamilton", "William L.", ""], ["Lenssen", "Jan Eric", ""], ["Rattan", "Gaurav", ""], ["Grohe", "Martin", ""]]}, {"id": "1810.02251", "submitter": "Michael Green", "authors": "Michael Cerny Green, Gabriella A.B. Barros, Antonios Liapis, Julian\n  Togelius", "title": "DATA Agent", "comments": "8 pages, 4 images, 3 tables", "journal-ref": "Foundations of Digital Games (FDG) 2018", "doi": "10.1145/3235765.3235792", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces DATA Agent, a system which creates murder mystery\nadventures from open data. In the game, the player takes on the role of a\ndetective tasked with finding the culprit of a murder. All characters, places,\nand items in DATA Agent games are generated using open data as source content.\nThe paper discusses the general game design and user interface of DATA Agent,\nand provides details on the generative algorithms which transform linked data\ninto different game objects. Findings from a user study with 30 participants\nplaying through two games of DATA Agent show that the game is easy and fun to\nplay, and that the mysteries it generates are straightforward to solve.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 15:36:19 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Green", "Michael Cerny", ""], ["Barros", "Gabriella A. B.", ""], ["Liapis", "Antonios", ""], ["Togelius", "Julian", ""]]}, {"id": "1810.02274", "submitter": "Nikolay Savinov", "authors": "Nikolay Savinov, Anton Raichuk, Rapha\\\"el Marinier, Damien Vincent,\n  Marc Pollefeys, Timothy Lillicrap, Sylvain Gelly", "title": "Episodic Curiosity through Reachability", "comments": "Accepted to ICLR 2019. Code at\n  https://github.com/google-research/episodic-curiosity/. Videos at\n  https://sites.google.com/view/episodic-curiosity/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rewards are sparse in the real world and most of today's reinforcement\nlearning algorithms struggle with such sparsity. One solution to this problem\nis to allow the agent to create rewards for itself - thus making rewards dense\nand more suitable for learning. In particular, inspired by curious behaviour in\nanimals, observing something novel could be rewarded with a bonus. Such bonus\nis summed up with the real task reward - making it possible for RL algorithms\nto learn from the combined reward. We propose a new curiosity method which uses\nepisodic memory to form the novelty bonus. To determine the bonus, the current\nobservation is compared with the observations in memory. Crucially, the\ncomparison is done based on how many environment steps it takes to reach the\ncurrent observation from those in memory - which incorporates rich information\nabout environment dynamics. This allows us to overcome the known \"couch-potato\"\nissues of prior work - when the agent finds a way to instantly gratify itself\nby exploiting actions which lead to hardly predictable consequences. We test\nour approach in visually rich 3D environments in ViZDoom, DMLab and MuJoCo. In\nnavigational tasks from ViZDoom and DMLab, our agent outperforms the\nstate-of-the-art curiosity method ICM. In MuJoCo, an ant equipped with our\ncuriosity module learns locomotion out of the first-person-view curiosity only.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 15:24:06 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 17:39:39 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 17:02:58 GMT"}, {"version": "v4", "created": "Thu, 9 May 2019 13:10:33 GMT"}, {"version": "v5", "created": "Tue, 6 Aug 2019 17:54:03 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Savinov", "Nikolay", ""], ["Raichuk", "Anton", ""], ["Marinier", "Rapha\u00ebl", ""], ["Vincent", "Damien", ""], ["Pollefeys", "Marc", ""], ["Lillicrap", "Timothy", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1810.02320", "submitter": "Ehsan Farahbakhsh", "authors": "Ehsan Farahbakhsh, Rohitash Chandra, Hugo K. H. Olierook, Richard\n  Scalzo, Chris Clark, Steven M. Reddy, R. Dietmar Muller", "title": "Computer vision-based framework for extracting geological lineaments\n  from optical remote sensing data", "comments": "17 pages, 10 figures, 2 tables", "journal-ref": null, "doi": "10.1080/01431161.2019.1674462", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The extraction of geological lineaments from digital satellite data is a\nfundamental application in remote sensing. The location of geological\nlineaments such as faults and dykes are of interest for a range of\napplications, particularly because of their association with hydrothermal\nmineralization. Although a wide range of applications have utilized computer\nvision techniques, a standard workflow for application of these techniques to\nmineral exploration is lacking. We present a framework for extracting\ngeological lineaments using computer vision techniques which is a combination\nof edge detection and line extraction algorithms for extracting geological\nlineaments using optical remote sensing data. It features ancillary computer\nvision techniques for reducing data dimensionality, removing noise and\nenhancing the expression of lineaments. We test the proposed framework on\nLandsat 8 data of a mineral-rich portion of the Gascoyne Province in Western\nAustralia using different dimension reduction techniques and convolutional\nfilters. To validate the results, the extracted lineaments are compared to our\nmanual photointerpretation and geologically mapped structures by the Geological\nSurvey of Western Australia (GSWA). The results show that the best correlation\nbetween our extracted geological lineaments and the GSWA geological lineament\nmap is achieved by applying a minimum noise fraction transformation and a\nLaplacian filter. Application of a directional filter instead shows a stronger\ncorrelation with the output of our manual photointerpretation and known sites\nof hydrothermal mineralization. Hence, our framework using either filter can be\nused for mineral prospectivity mapping in other regions where faults are\nexposed and observable in optical remote sensing data.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 17:09:04 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Farahbakhsh", "Ehsan", ""], ["Chandra", "Rohitash", ""], ["Olierook", "Hugo K. H.", ""], ["Scalzo", "Richard", ""], ["Clark", "Chris", ""], ["Reddy", "Steven M.", ""], ["Muller", "R. Dietmar", ""]]}, {"id": "1810.02328", "submitter": "Gerald Friedland", "authors": "Gerald Friedland, Alfredo Metere, Mario Krell", "title": "A Practical Approach to Sizing Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "LLNL Technical Report 758456", "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memorization is worst-case generalization. Based on MacKay's information\ntheoretic model of supervised machine learning, this article discusses how to\npractically estimate the maximum size of a neural network given a training data\nset. First, we present four easily applicable rules to analytically determine\nthe capacity of neural network architectures. This allows the comparison of the\nefficiency of different network architectures independently of a task. Second,\nwe introduce and experimentally validate a heuristic method to estimate the\nneural network capacity requirement for a given dataset and labeling. This\nallows an estimate of the required size of a neural network for a given\nproblem. We conclude the article with a discussion on the consequences of\nsizing the network wrongly, which includes both increased computation effort\nfor training as well as reduced generalization capability.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 17:20:39 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Friedland", "Gerald", ""], ["Metere", "Alfredo", ""], ["Krell", "Mario", ""]]}, {"id": "1810.02334", "submitter": "Kyle Hsu", "authors": "Kyle Hsu and Sergey Levine and Chelsea Finn", "title": "Unsupervised Learning via Meta-Learning", "comments": "ICLR 2019 camera-ready. 24 pages, 2 figures, links to code available\n  at https://sites.google.com/view/unsupervised-via-meta", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central goal of unsupervised learning is to acquire representations from\nunlabeled data or experience that can be used for more effective learning of\ndownstream tasks from modest amounts of labeled data. Many prior unsupervised\nlearning works aim to do so by developing proxy objectives based on\nreconstruction, disentanglement, prediction, and other metrics. Instead, we\ndevelop an unsupervised meta-learning method that explicitly optimizes for the\nability to learn a variety of tasks from small amounts of data. To do so, we\nconstruct tasks from unlabeled data in an automatic way and run meta-learning\nover the constructed tasks. Surprisingly, we find that, when integrated with\nmeta-learning, relatively simple task construction mechanisms, such as\nclustering embeddings, lead to good performance on a variety of downstream,\nhuman-specified tasks. Our experiments across four image datasets indicate that\nour unsupervised meta-learning approach acquires a learning algorithm without\nany labeled data that is applicable to a wide range of downstream\nclassification tasks, improving upon the embedding learned by four prior\nunsupervised learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 17:29:17 GMT"}, {"version": "v2", "created": "Sat, 6 Oct 2018 23:39:52 GMT"}, {"version": "v3", "created": "Sat, 13 Oct 2018 23:57:36 GMT"}, {"version": "v4", "created": "Thu, 22 Nov 2018 20:47:45 GMT"}, {"version": "v5", "created": "Fri, 7 Dec 2018 20:38:03 GMT"}, {"version": "v6", "created": "Thu, 21 Mar 2019 23:43:47 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Hsu", "Kyle", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1810.02338", "submitter": "Kexin Yi", "authors": "Kexin Yi, Jiajun Wu, Chuang Gan, Antonio Torralba, Pushmeet Kohli,\n  Joshua B. Tenenbaum", "title": "Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language\n  Understanding", "comments": "NeurIPS 2018 (spotlight). The first two authors contributed equally\n  to this work. Project page: http://nsvqa.csail.mit.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We marry two powerful ideas: deep representation learning for visual\nrecognition and language understanding, and symbolic program execution for\nreasoning. Our neural-symbolic visual question answering (NS-VQA) system first\nrecovers a structural scene representation from the image and a program trace\nfrom the question. It then executes the program on the scene representation to\nobtain an answer. Incorporating symbolic structure as prior knowledge offers\nthree unique advantages. First, executing programs on a symbolic space is more\nrobust to long program traces; our model can solve complex reasoning tasks\nbetter, achieving an accuracy of 99.8% on the CLEVR dataset. Second, the model\nis more data- and memory-efficient: it performs well after learning on a small\nnumber of training data; it can also encode an image into a compact\nrepresentation, requiring less storage than existing methods for offline\nquestion answering. Third, symbolic program execution offers full transparency\nto the reasoning process; we are thus able to interpret and diagnose each\nexecution step.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 17:38:50 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 23:07:12 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Yi", "Kexin", ""], ["Wu", "Jiajun", ""], ["Gan", "Chuang", ""], ["Torralba", "Antonio", ""], ["Kohli", "Pushmeet", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1810.02355", "submitter": "Filipe Mutz", "authors": "Thomas Teixeira, Filipe Mutz, Karin Satie Komati, Lucas Veronese,\n  Vinicius B. Cardoso, Claudine Badue, Thiago Oliveira-Santos, Alberto F. De\n  Souza", "title": "Memory-like Map Decay for Autonomous Vehicles based on Grid Maps", "comments": "This is a preprint. Published in American journal of Engineering\n  Research (AJER) Available at\n  http://www.ajer.org/papers/Vol-9-issue-9/J09096371.pdf", "journal-ref": "American Journal of Engineering Research (AJER), vol. 9(9), 2020,\n  pp. 63-71", "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a novel strategy for correcting imperfections in\noccupancy grid maps called map decay. The objective of map decay is to correct\ninvalid occupancy probabilities of map cells that are unobservable by sensors.\nThe strategy was inspired by an analogy between the memory architecture\nbelieved to exist in the human brain and the maps maintained by an autonomous\nvehicle. It consists in merging sensory information obtained during runtime\n(online) with a priori data from a high-precision map constructed offline. In\nmap decay, cells observed by sensors are updated using traditional occupancy\ngrid mapping techniques and unobserved cells are adjusted so that their\noccupancy probabilities tend to the values found in the offline map. This\nstrategy is grounded in the idea that the most precise information available\nabout an unobservable cell is the value found in the high-precision offline\nmap. Map decay was successfully tested and is still in use in the IARA\nautonomous vehicle from Universidade Federal do Esp\\'irito Santo.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 17:58:58 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 18:44:22 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 22:01:40 GMT"}, {"version": "v4", "created": "Tue, 27 Apr 2021 21:44:58 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Teixeira", "Thomas", ""], ["Mutz", "Filipe", ""], ["Komati", "Karin Satie", ""], ["Veronese", "Lucas", ""], ["Cardoso", "Vinicius B.", ""], ["Badue", "Claudine", ""], ["Oliveira-Santos", "Thiago", ""], ["De Souza", "Alberto F.", ""]]}, {"id": "1810.02419", "submitter": "Zhiwu Huang", "authors": "Dinesh Acharya, Zhiwu Huang, Danda Pani Paudel, Luc Van Gool", "title": "Towards High Resolution Video Generation with Progressive Growing of\n  Sliced Wasserstein GANs", "comments": "Master Thesis from ETH Zurich, May 22, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extension of image generation to video generation turns out to be a very\ndifficult task, since the temporal dimension of videos introduces an extra\nchallenge during the generation process. Besides, due to the limitation of\nmemory and training stability, the generation becomes increasingly challenging\nwith the increase of the resolution/duration of videos. In this work, we\nexploit the idea of progressive growing of Generative Adversarial Networks\n(GANs) for higher resolution video generation. In particular, we begin to\nproduce video samples of low-resolution and short-duration, and then\nprogressively increase both resolution and duration alone (or jointly) by\nadding new spatiotemporal convolutional layers to the current networks.\nStarting from the learning on a very raw-level spatial appearance and temporal\nmovement of the video distribution, the proposed progressive method learns\nspatiotemporal information incrementally to generate higher resolution videos.\nFurthermore, we introduce a sliced version of Wasserstein GAN (SWGAN) loss to\nimprove the distribution learning on the video data of high-dimension and\nmixed-spatiotemporal distribution. SWGAN loss replaces the distance between\njoint distributions by that of one-dimensional marginal distributions, making\nthe loss easier to compute. We evaluate the proposed model on our collected\nface video dataset of 10,900 videos to generate photorealistic face videos of\n256x256x32 resolution. In addition, our model also reaches a record inception\nscore of 14.57 in unsupervised action recognition dataset UCF-101.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 20:41:48 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 15:57:41 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Acharya", "Dinesh", ""], ["Huang", "Zhiwu", ""], ["Paudel", "Danda Pani", ""], ["Van Gool", "Luc", ""]]}, {"id": "1810.02422", "submitter": "Ryan Julian", "authors": "Zhanpeng He, Ryan Julian, Eric Heiden, Hejia Zhang, Stefan Schaal,\n  Joseph J. Lim, Gaurav Sukhatme, Karol Hausman", "title": "Simulator Predictive Control: Using Learned Task Representations and MPC\n  for Zero-Shot Generalization and Sequencing", "comments": "Presented at NeurIPS 2018 Workshop: Deep Reinforcement Learning. See\n  https://youtu.be/te4JWe7LPKw for supplemental video", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation-to-real transfer is an important strategy for making reinforcement\nlearning practical with real robots. Successful sim-to-real transfer systems\nhave difficulty producing policies which generalize across tasks, despite\ntraining for thousands of hours equivalent real robot time. To address this\nshortcoming, we present a novel approach to efficiently learning new robotic\nskills directly on a real robot, based on model-predictive control (MPC) and an\nalgorithm for learning task representations. In short, we show how to reuse the\nsimulation from the pre-training step of sim-to-real methods as a tool for\nforesight, allowing the sim-to-real policy adapt to unseen tasks. Rather than\nend-to-end learning policies for single tasks and attempting to transfer them,\nwe first use simulation to simultaneously learn (1) a continuous\nparameterization (i.e. a skill embedding or latent) of task-appropriate\nprimitive skills, and (2) a single policy for these skills which is conditioned\non this representation. We then directly transfer our multi-skill policy to a\nreal robot, and actuate the robot by choosing sequences of skill latents which\nactuate the policy, with each latent corresponding to a pre-learned primitive\nskill controller. We complete unseen tasks by choosing new sequences of skill\nlatents to control the robot using MPC, where our MPC model is composed of the\npre-trained skill policy executed in the simulation environment, run in\nparallel with the real robot. We discuss the background and principles of our\nmethod, detail its practical implementation, and evaluate its performance by\nusing our method to train a real Sawyer Robot to achieve motion tasks such as\ndrawing and block pushing.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 20:59:35 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 21:35:14 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 21:59:18 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["He", "Zhanpeng", ""], ["Julian", "Ryan", ""], ["Heiden", "Eric", ""], ["Zhang", "Hejia", ""], ["Schaal", "Stefan", ""], ["Lim", "Joseph J.", ""], ["Sukhatme", "Gaurav", ""], ["Hausman", "Karol", ""]]}, {"id": "1810.02434", "submitter": "Vaishak Belle", "authors": "Vaishak Belle", "title": "Abstracting Probabilistic Models: A Logical Perspective", "comments": "In AAAI Workshop: Statistical Relational Artificial Intelligence,\n  2020. (This is the extended version.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstraction is a powerful idea widely used in science, to model, reason and\nexplain the behavior of systems in a more tractable search space, by omitting\nirrelevant details. While notions of abstraction have matured for deterministic\nsystems, the case for abstracting probabilistic models is not yet fully\nunderstood.\n  In this paper, we provide a semantical framework for analyzing such\nabstractions from first principles. We develop the framework in a general way,\nallowing for expressive languages, including logic-based ones that admit\nrelational and hierarchical constructs with stochastic primitives. We motivate\na definition of consistency between a high-level model and its low-level\ncounterpart, but also treat the case when the high-level model is missing\ncritical information present in the low-level model. We prove properties of\nabstractions, both at the level of the parameter as well as the structure of\nthe models. We conclude with some observations about how abstractions can be\nderived automatically.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 21:39:38 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 18:25:44 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 13:44:46 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Belle", "Vaishak", ""]]}, {"id": "1810.02440", "submitter": "Alessandro Achille", "authors": "Alessandro Achille, Glen Mbeng, Stefano Soatto", "title": "Dynamics and Reachability of Learning Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compute the transition probability between two learning tasks, and show\nthat it decomposes into two factors. The first depends on the geometry of the\nloss landscape of a model trained on each task, independent of any particular\nmodel used. This is related to an information theoretic distance function, but\nis insufficient to predict success in transfer learning, as nearby tasks can be\nunreachable via fine-tuning. The second factor depends on the ease of\ntraversing the path between two tasks. With this dynamic component, we derive\nstrict lower bounds on the complexity necessary to learn a task starting from\nthe solution to another, which is one of the most common forms of transfer\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 22:14:40 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 04:49:00 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Achille", "Alessandro", ""], ["Mbeng", "Glen", ""], ["Soatto", "Stefano", ""]]}, {"id": "1810.02455", "submitter": "Kyle Julian", "authors": "Kyle D. Julian and Mykel J. Kochenderfer", "title": "Image-based Guidance of Autonomous Aircraft for Wildfire Surveillance\n  and Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small unmanned aircraft can help firefighters combat wildfires by providing\nreal-time surveillance of the growing fires. However, guiding the aircraft\nautonomously given only wildfire images is a challenging problem. This work\nmodels noisy images obtained from on-board cameras and proposes two approaches\nto filtering the wildfire images. The first approach uses a simple Kalman\nfilter to reduce noise and update a belief map in observed areas. The second\napproach uses a particle filter to predict wildfire growth and uses\nobservations to estimate uncertainties relating to wildfire expansion. The\nbelief maps are used to train a deep reinforcement learning controller, which\nlearns a policy to navigate the aircraft to survey the wildfire while avoiding\nflight directly over the fire. Simulation results show that the proposed\ncontrollers precisely guide the aircraft and accurately estimate wildfire\ngrowth, and a study of observation noise demonstrates the robustness of the\nparticle filter approach.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 23:27:26 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 21:47:49 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Julian", "Kyle D.", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1810.02497", "submitter": "Xuan Liu", "authors": "Xuan Liu and Jie Fu", "title": "Compositional planning in Markov decision processes: Temporal\n  abstraction meets generalized logic composition", "comments": "8 pages, 4 figures, 2 tables, accepted as a conference paper for\n  presentation at American Control Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In hierarchical planning for Markov decision processes (MDPs), temporal\nabstraction allows planning with macro-actions that take place at different\ntime scale in form of sequential composition. In this paper, we propose a novel\napproach to compositional reasoning and hierarchical planning for MDPs under\ntemporal logic constraints. In addition to sequential composition, we introduce\na composition of policies based on generalized logic composition: Given\nsub-policies for sub-tasks and a new task expressed as logic compositions of\nsubtasks, a semi-optimal policy, which is optimal in planning with only\nsub-policies, can be obtained by simply composing sub-polices. Thus, a\nsynthesis algorithm is developed to compute optimal policies efficiently by\nplanning with primitive actions, policies for sub-tasks, and the compositions\nof sub-policies, for maximizing the probability of satisfying temporal logic\nspecifications. We demonstrate the correctness and efficiency of the proposed\nmethod in stochastic planning examples with a single agent and multiple task\nspecifications.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 02:48:20 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 20:39:23 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Liu", "Xuan", ""], ["Fu", "Jie", ""]]}, {"id": "1810.02525", "submitter": "Peter Henderson", "authors": "Peter Henderson, Joshua Romoff, Joelle Pineau", "title": "Where Did My Optimum Go?: An Empirical Analysis of Gradient Descent\n  Optimization in Policy Gradient Methods", "comments": "Accepted at the European Workshop on Reinforcement Learning 2018\n  (EWRL14)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent analyses of certain gradient descent optimization methods have shown\nthat performance can degrade in some settings - such as with stochasticity or\nimplicit momentum. In deep reinforcement learning (Deep RL), such optimization\nmethods are often used for training neural networks via the temporal difference\nerror or policy gradient. As an agent improves over time, the optimization\ntarget changes and thus the loss landscape (and local optima) change. Due to\nthe failure modes of those methods, the ideal choice of optimizer for Deep RL\nremains unclear. As such, we provide an empirical analysis of the effects that\na wide range of gradient descent optimizers and their hyperparameters have on\npolicy gradient methods, a subset of Deep RL algorithms, for benchmark\ncontinuous control tasks. We find that adaptive optimizers have a narrow window\nof effective learning rates, diverging in other cases, and that the\neffectiveness of momentum varies depending on the properties of the\nenvironment. Our analysis suggests that there is significant interplay between\nthe dynamics of the environment and Deep RL algorithm properties which aren't\nnecessarily accounted for by traditional adaptive gradient methods. We provide\nsuggestions for optimal settings of current methods and further lines of\nresearch based on our findings.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 05:52:49 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Henderson", "Peter", ""], ["Romoff", "Joshua", ""], ["Pineau", "Joelle", ""]]}, {"id": "1810.02607", "submitter": "Daiki Kimura", "authors": "Minori Narita, Daiki Kimura, Ryuki Tachibana", "title": "Spatially-weighted Anomaly Detection", "comments": "4 pages, SSII 2018 (original paper was written in Japanese)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many types of anomaly detection methods have been proposed recently, and\napplied to a wide variety of fields including medical screening and production\nquality checking. Some methods have utilized images, and, in some cases, a part\nof the anomaly images is known beforehand. However, this kind of information is\ndismissed by previous methods, because the methods can only utilize a normal\npattern. Moreover, the previous methods suffer a decrease in accuracy due to\nnegative effects from surrounding noises. In this study, we propose a\nspatially-weighted anomaly detection method (SPADE) that utilizes all of the\nknown patterns and lessens the vulnerability to ambient noises by applying\nGrad-CAM, which is the visualization method of a CNN. We evaluated our method\nquantitatively using two datasets, the MNIST dataset with noise and a dataset\nbased on a brief screening test for dementia.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 11:04:06 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Narita", "Minori", ""], ["Kimura", "Daiki", ""], ["Tachibana", "Ryuki", ""]]}, {"id": "1810.02612", "submitter": "Brian Paden", "authors": "Brian Paden, Peng Liu, Schuyler Cullen", "title": "Accelerated Labeling of Discrete Abstractions for Autonomous Driving\n  Subject to LTL Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear temporal logic and automaton-based run-time verification provide a\npowerful framework for designing task and motion planning algorithms for\nautonomous agents. The drawback to this approach is the computational cost of\noperating on high resolution discrete abstractions of continuous dynamical\nsystems. In particular, the computational bottleneck that arises is converting\nperceived environment variables into a labeling function on the states of a\nKripke structure or analogously the transitions of a labeled transition system.\nThis paper presents the design and empirical evaluation of an approach to\nconstructing the labeling function that exposes a large degree of parallelism\nin the operation as well as efficient memory access patterns. The approach is\nimplemented on a commodity GPU and empirical results demonstrate the efficacy\nof the labeling technique for real-time planning and decision-making.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 11:15:27 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 18:07:51 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Paden", "Brian", ""], ["Liu", "Peng", ""], ["Cullen", "Schuyler", ""]]}, {"id": "1810.02647", "submitter": "Sebastian Stober", "authors": "Andr\\'e Ofner, Sebastian Stober", "title": "Hybrid Active Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a framework of hybrid cognition by formulating a hybrid cognitive\nagent that performs hierarchical active inference across a human and a machine\npart. We suggest that, in addition to enhancing human cognitive functions with\nan intelligent and adaptive interface, integrated cognitive processing could\naccelerate emergent properties within artificial intelligence. To establish\nthis, a machine learning part learns to integrate into human cognition by\nexplaining away multi-modal sensory measurements from the environment and\nphysiology simultaneously with the brain signal. With ongoing training, the\namount of predictable brain signal increases. This lends the agent the ability\nto self-supervise on increasingly high levels of cognitive processing in order\nto further minimize surprise in predicting the brain signal. Furthermore, with\nincreasing level of integration, the access to sensory information about\nenvironment and physiology is substituted with access to their representation\nin the brain. While integrating into a joint embodiment of human and machine,\nhuman action and perception are treated as the machine's own. The framework can\nbe implemented with invasive as well as non-invasive sensors for environment,\nbody and brain interfacing. Online and offline training with different machine\nlearning approaches are thinkable. Building on previous research on shared\nrepresentation learning, we suggest a first implementation leading towards\nhybrid active inference with non-invasive brain interfacing and state of the\nart probabilistic deep learning methods. We further discuss how implementation\nmight have effect on the meta-cognitive abilities of the described agent and\nsuggest that with adequate implementation the machine part can continue to\nexecute and build upon the learned cognitive processes autonomously.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 12:32:55 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Ofner", "Andr\u00e9", ""], ["Stober", "Sebastian", ""]]}, {"id": "1810.02688", "submitter": "Philippe Besse", "authors": "Philippe Besse (IMT), Brendan Guillouet (IMT), B\\'eatrice Laurent\n  (IMT)", "title": "Wikistat 2.0: Educational Resources for Artificial Intelligence", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data, data science, deep learning, artificial intelligence are the key\nwords of intense hype related with a job market in full evolution, that impose\nto adapt the contents of our university professional trainings. Which\nartificial intelligence is mostly concerned by the job offers? Which\nmethodologies and technologies should be favored in the training programs?\nWhich objectives, tools and educational resources do we needed to put in place\nto meet these pressing needs? We answer these questions in describing the\ncontents and operational resources in the Data Science orientation of the\nspecialty Applied Mathematics at INSA Toulouse. We focus on basic mathematics\ntraining (Optimization, Probability, Statistics), associated with the practical\nimplementation of the most performing statistical learning algorithms, with the\nmost appropriate technologies and on real examples. Considering the huge\nvolatility of the technologies, it is imperative to train students in\nseft-training, this will be their technological watch tool when they will be in\nprofessional activity. This explains the structuring of the educational site\ngithub.com/wikistat into a set of tutorials. Finally, to motivate the thorough\npractice of these tutorials, a serious game is organized each year in the form\nof a prediction contest between students of Master degrees in Applied\nMathematics for IA.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 08:27:59 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 13:07:57 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Besse", "Philippe", "", "IMT"], ["Guillouet", "Brendan", "", "IMT"], ["Laurent", "B\u00e9atrice", "", "IMT"]]}, {"id": "1810.02689", "submitter": "Alun Preece", "authors": "Alun Preece, Rob Ashelford, Harry Armstrong and Dave Braines", "title": "Hows and Whys of Artificial Intelligence for Public Sector Decisions:\n  Explanation and Evaluation", "comments": "Presented at AAAI FSS-18: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA; corrected typos in this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation has always been a key challenge in the development of artificial\nintelligence (AI) based software, due to the technical complexity of the\nsoftware artifact and, often, its embedding in complex sociotechnical\nprocesses. Recent advances in machine learning (ML) enabled by deep neural\nnetworks has exacerbated the challenge of evaluating such software due to the\nopaque nature of these ML-based artifacts. A key related issue is the\n(in)ability of such systems to generate useful explanations of their outputs,\nand we argue that the explanation and evaluation problems are closely linked.\nThe paper models the elements of a ML-based AI system in the context of public\nsector decision (PSD) applications involving both artificial and human\nintelligence, and maps these elements against issues in both evaluation and\nexplanation, showing how the two are related. We consider a number of common\nPSD application patterns in the light of our model, and identify a set of key\nissues connected to explanation and evaluation in each case. Finally, we\npropose multiple strategies to promote wider adoption of AI/ML technologies in\nPSD, where each is distinguished by a focus on different elements of our model,\nallowing PSD policy makers to adopt an approach that best fits their context\nand concerns.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 09:38:13 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 21:41:57 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Preece", "Alun", ""], ["Ashelford", "Rob", ""], ["Armstrong", "Harry", ""], ["Braines", "Dave", ""]]}, {"id": "1810.02724", "submitter": "Roman Yampolskiy", "authors": "Roman V. Yampolskiy", "title": "Human Indignity: From Legal AI Personhood to Selfish Memes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is possible to rely on current corporate law to grant legal personhood to\nArtificially Intelligent (AI) agents. In this paper, after introducing pathways\nto AI personhood, we analyze consequences of such AI empowerment on human\ndignity, human safety and AI rights. We emphasize possibility of creating\nselfish memes and legal system hacking in the context of artificial entities.\nFinally, we consider some potential solutions for addressing described\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 20:01:43 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Yampolskiy", "Roman V.", ""]]}, {"id": "1810.02797", "submitter": "Shiv Ram Dubey", "authors": "S H Shabbeer Basha, Soumen Ghosh, Kancharagunta Kishan Babu, Shiv Ram\n  Dubey, Viswanath Pulabaigari, Snehasis Mukherjee", "title": "RCCNet: An Efficient Convolutional Neural Network for Histological\n  Routine Colon Cancer Nuclei Classification", "comments": "Published in ICARCV 2018", "journal-ref": null, "doi": "10.1109/ICARCV.2018.8581147", "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient and precise classification of histological cell nuclei is of utmost\nimportance due to its potential applications in the field of medical image\nanalysis. It would facilitate the medical practitioners to better understand\nand explore various factors for cancer treatment. The classification of\nhistological cell nuclei is a challenging task due to the cellular\nheterogeneity. This paper proposes an efficient Convolutional Neural Network\n(CNN) based architecture for classification of histological routine colon\ncancer nuclei named as RCCNet. The main objective of this network is to keep\nthe CNN model as simple as possible. The proposed RCCNet model consists of only\n1,512,868 learnable parameters which are significantly less compared to the\npopular CNN models such as AlexNet, CIFARVGG, GoogLeNet, and WRN. The\nexperiments are conducted over publicly available routine colon cancer\nhistological dataset \"CRCHistoPhenotypes\". The results of the proposed RCCNet\nmodel are compared with five state-of-the-art CNN models in terms of the\naccuracy, weighted average F1 score and training time. The proposed method has\nachieved a classification accuracy of 80.61% and 0.7887 weighted average F1\nscore. The proposed RCCNet is more efficient and generalized terms of the\ntraining time and data over-fitting, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 07:18:58 GMT"}, {"version": "v2", "created": "Sat, 20 Oct 2018 12:09:31 GMT"}, {"version": "v3", "created": "Sat, 8 Jun 2019 05:19:12 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Basha", "S H Shabbeer", ""], ["Ghosh", "Soumen", ""], ["Babu", "Kancharagunta Kishan", ""], ["Dubey", "Shiv Ram", ""], ["Pulabaigari", "Viswanath", ""], ["Mukherjee", "Snehasis", ""]]}, {"id": "1810.02802", "submitter": "Ni Lao", "authors": "Gengchen Mai, Krzysztof Janowicz, Cheng He, Sumang Liu, Ni Lao", "title": "POIReviewQA: A Semantically Enriched POI Retrieval and Question\n  Answering Dataset", "comments": null, "journal-ref": "12th Workshop on Geographic Information Retrieval (GIR 2018)", "doi": "10.1145/3281354.3281359", "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many services that perform information retrieval for Points of Interest (POI)\nutilize a Lucene-based setup with spatial filtering. While this type of system\nis easy to implement it does not make use of semantics but relies on direct\nword matches between a query and reviews leading to a loss in both precision\nand recall. To study the challenging task of semantically enriching POIs from\nunstructured data in order to support open-domain search and question answering\n(QA), we introduce a new dataset POIReviewQA. It consists of 20k questions\n(e.g.\"is this restaurant dog friendly?\") for 1022 Yelp business types. For each\nquestion we sampled 10 reviews, and annotated each sentence in the reviews\nwhether it answers the question and what the corresponding answer is. To test a\nsystem's ability to understand the text we adopt an information retrieval\nevaluation by ranking all the review sentences for a question based on the\nlikelihood that they answer this question. We build a Lucene-based baseline\nmodel, which achieves 77.0% AUC and 48.8% MAP. A sentence embedding-based model\nachieves 79.2% AUC and 41.8% MAP, indicating that the dataset presents a\nchallenging problem for future research by the GIR community. The result\ntechnology can help exploit the thematic content of web documents and social\nmedia for characterisation of locations.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 17:37:37 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Mai", "Gengchen", ""], ["Janowicz", "Krzysztof", ""], ["He", "Cheng", ""], ["Liu", "Sumang", ""], ["Lao", "Ni", ""]]}, {"id": "1810.02869", "submitter": "In\\`es Osman", "authors": "In\\`es Osman", "title": "A New Method for the Semantic Integration of Multiple OWL Ontologies\n  using Alignments", "comments": "supervised by Marouen Kachroudi and Sadok Ben Yahia, in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is done as part of a master's thesis project. The goal is to\nintegrate two or more ontologies (of the same or close domains) in a new\nconsistent and coherent OWL ontology to insure semantic interoperability\nbetween them. To do this, we have chosen to create a bridge ontology that\nincludes all source ontologies and their bridging axioms in a customized way.\nIn addition, we introduced a new criterion for obtaining an ontology of better\nquality (having the minimum of semantic/logical conflicts). We have also\nproposed new terminology and definitions that clarify the unclear and misplaced\n\"integration\" and \"merging\" notions that are randomly used in state-of-the-art\nworks. Finally, we tested and evaluated our OIA2R tool using ontologies and\nreference alignments of the OAEI campaign. It turned out that it is generic,\nefficient and powerful enough.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 20:03:00 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Osman", "In\u00e8s", ""]]}, {"id": "1810.02897", "submitter": "Ye Zhu PhD", "authors": "Ye Zhu, Kai Ming Ting, Mark Carman, Maia Angelova", "title": "CDF Transform-and-Shift: An effective way to deal with datasets of\n  inhomogeneous cluster densities", "comments": "Pattern Recognition (2021)", "journal-ref": null, "doi": "10.1016/j.patcog.2021.107977", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of inhomogeneous cluster densities has been a long-standing issue\nfor distance-based and density-based algorithms in clustering and anomaly\ndetection. These algorithms implicitly assume that all clusters have\napproximately the same density. As a result, they often exhibit a bias towards\ndense clusters in the presence of sparse clusters. Many remedies have been\nsuggested; yet, we show that they are partial solutions which do not address\nthe issue satisfactorily. To match the implicit assumption, we propose to\ntransform a given dataset such that the transformed clusters have approximately\nthe same density while all regions of locally low density become globally low\ndensity -- homogenising cluster density while preserving the cluster structure\nof the dataset. We show that this can be achieved by using a new\nmulti-dimensional Cumulative Distribution Function in a transform-and-shift\nmethod. The method can be applied to every dataset, before the dataset is used\nin many existing algorithms to match their implicit assumption without\nalgorithmic modification. We show that the proposed method performs better than\nexisting remedies.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 22:32:51 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 08:53:59 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 04:27:35 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zhu", "Ye", ""], ["Ting", "Kai Ming", ""], ["Carman", "Mark", ""], ["Angelova", "Maia", ""]]}, {"id": "1810.02912", "submitter": "Shariq Iqbal", "authors": "Shariq Iqbal, Fei Sha", "title": "Actor-Attention-Critic for Multi-Agent Reinforcement Learning", "comments": "ICML 2019 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning in multi-agent scenarios is important for real-world\napplications but presents challenges beyond those seen in single-agent\nsettings. We present an actor-critic algorithm that trains decentralized\npolicies in multi-agent settings, using centrally computed critics that share\nan attention mechanism which selects relevant information for each agent at\nevery timestep. This attention mechanism enables more effective and scalable\nlearning in complex multi-agent environments, when compared to recent\napproaches. Our approach is applicable not only to cooperative settings with\nshared rewards, but also individualized reward settings, including adversarial\nsettings, as well as settings that do not provide global states, and it makes\nno assumptions about the action spaces of the agents. As such, it is flexible\nenough to be applied to most multi-agent learning problems.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 23:45:14 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 23:28:13 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Iqbal", "Shariq", ""], ["Sha", "Fei", ""]]}, {"id": "1810.02923", "submitter": "Baihan Lin", "authors": "Baihan Lin, Nikolaus Kriegeskorte", "title": "Adaptive Geo-Topological Independence Criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.ST q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing two potentially multivariate variables for statistical dependence on\nthe basis finite samples is a fundamental statistical challenge. Here we\nexplore a family of tests that adapt to the complexity of the relationship\nbetween the variables, promising robust power across scenarios. Building on the\ndistance correlation, we introduce a family of adaptive independence criteria\nbased on nonlinear monotonic transformations of distances. We show that these\ncriteria, like the distance correlation and RKHS-based criteria, provide\ndependence indicators. We propose a class of adaptive (multi-threshold) test\nstatistics, which form the basis for permutation tests. These tests empirically\noutperform some of the established tests in average and worst-case statistical\nsensitivity across a range of univariate and multivariate relationships, offer\nuseful insights to the data and may deserve further exploration.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 02:12:21 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 08:21:04 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 07:14:42 GMT"}, {"version": "v4", "created": "Tue, 9 Jun 2020 05:18:55 GMT"}, {"version": "v5", "created": "Thu, 18 Jun 2020 01:30:58 GMT"}, {"version": "v6", "created": "Thu, 22 Oct 2020 03:44:58 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Lin", "Baihan", ""], ["Kriegeskorte", "Nikolaus", ""]]}, {"id": "1810.02938", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui", "title": "Co-Stack Residual Affinity Networks with Multi-level Attention\n  Refinement for Matching Text Sequences", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a matching function between two text sequences is a long standing\nproblem in NLP research. This task enables many potential applications such as\nquestion answering and paraphrase identification. This paper proposes Co-Stack\nResidual Affinity Networks (CSRAN), a new and universal neural architecture for\nthis problem. CSRAN is a deep architecture, involving stacked (multi-layered)\nrecurrent encoders. Stacked/Deep architectures are traditionally difficult to\ntrain, due to the inherent weaknesses such as difficulty with feature\npropagation and vanishing gradients. CSRAN incorporates two novel components to\ntake advantage of the stacked architecture. Firstly, it introduces a new\nbidirectional alignment mechanism that learns affinity weights by fusing\nsequence pairs across stacked hierarchies. Secondly, it leverages a multi-level\nattention refinement component between stacked recurrent layers. The key\nintuition is that, by leveraging information across all network hierarchies, we\ncan not only improve gradient flow but also improve overall performance. We\nconduct extensive experiments on six well-studied text sequence matching\ndatasets, achieving state-of-the-art performance on all.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 05:25:24 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1810.02980", "submitter": "Ivandr\\'e Paraboni", "authors": "Wesley Ramos dos Santos and Ivandre Paraboni", "title": "Personality facets recognition from text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fundamental Big Five personality traits (e.g., Extraversion) and their facets\n(e.g., Activity) are known to correlate with a broad range of linguistic\nfeatures and, accordingly, the recognition of personality traits from text is a\nwell-known Natural Language Processing task. Labelling text data with facets\ninformation, however, may require the use of lengthy personality inventories,\nand perhaps for that reason existing computational models of this kind are\nusually limited to the recognition of the fundamental traits. Based on these\nobservations, this paper investigates the issue of personality facets\nrecognition from text labelled only with information available from a shorter\npersonality inventory. In doing so, we provide a low-cost model for the\nrecognition of certain personality facets, and present reference results for\nfurther studies in this field.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 11:09:54 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 11:29:53 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Santos", "Wesley Ramos dos", ""], ["Paraboni", "Ivandre", ""]]}, {"id": "1810.03002", "submitter": "Eric Sancho Adamson", "authors": "Bj{\\o}rn Jespersen, Ana de Almeida Borges, Jorge del Castillo Tierz,\n  Juan Jos\\'e Conejero Rodr\\'iguez, Eric Sancho Adamson, Aleix Sol\\'e\n  S\\'anchez, Nika Pona, Joost J. Joosten", "title": "When logic lays down the law", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse so-called computable laws, i.e., laws that can be enforced by\nautomatic procedures. These laws should be logically perfect and unambiguous,\nbut sometimes they are not. We use a regulation on road transport to illustrate\nthis issue, and show what some fragments of this regulation would look like if\nrewritten in the image of logic. We further propose desiderata to be fulfilled\nby computable laws, and provide a critical platform from which to assess\nexisting laws and a guideline for composing future ones.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 13:25:54 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Jespersen", "Bj\u00f8rn", ""], ["Borges", "Ana de Almeida", ""], ["Tierz", "Jorge del Castillo", ""], ["Rodr\u00edguez", "Juan Jos\u00e9 Conejero", ""], ["Adamson", "Eric Sancho", ""], ["S\u00e1nchez", "Aleix Sol\u00e9", ""], ["Pona", "Nika", ""], ["Joosten", "Joost J.", ""]]}, {"id": "1810.03025", "submitter": "Peter Schulam", "authors": "Peter Schulam and Suchi Saria", "title": "Discretizing Logged Interaction Data Biases Learning for Decision-Making", "comments": "This is a standalone short paper describing a new type of bias that\n  can arise when learning from time series data for sequential decision-making\n  problems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series data that are not measured at regular intervals are commonly\ndiscretized as a preprocessing step. For example, data about customer arrival\ntimes might be simplified by summing the number of arrivals within hourly\nintervals, which produces a discrete-time time series that is easier to model.\nIn this abstract, we show that discretization introduces a bias that affects\nmodels trained for decision-making. We refer to this phenomenon as\ndiscretization bias, and show that we can avoid it by using continuous-time\nmodels instead.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 17:08:47 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Schulam", "Peter", ""], ["Saria", "Suchi", ""]]}, {"id": "1810.03043", "submitter": "Frederik Ebert", "authors": "Frederik Ebert, Sudeep Dasari, Alex X. Lee, Sergey Levine and Chelsea\n  Finn", "title": "Robustness via Retrying: Closed-Loop Robotic Manipulation with\n  Self-Supervised Learning", "comments": "accepted at the Conference on Robot Learning (CoRL) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction is an appealing objective for self-supervised learning of\nbehavioral skills, particularly for autonomous robots. However, effectively\nutilizing predictive models for control, especially with raw image inputs,\nposes a number of major challenges. How should the predictions be used? What\nhappens when they are inaccurate? In this paper, we tackle these questions by\nproposing a method for learning robotic skills from raw image observations,\nusing only autonomously collected experience. We show that even an imperfect\nmodel can complete complex tasks if it can continuously retry, but this\nrequires the model to not lose track of the objective (e.g., the object of\ninterest). To enable a robot to continuously retry a task, we devise a\nself-supervised algorithm for learning image registration, which can keep track\nof objects of interest for the duration of the trial. We demonstrate that this\nidea can be combined with a video-prediction based controller to enable complex\nbehaviors to be learned from scratch using only raw visual inputs, including\ngrasping, repositioning objects, and non-prehensile manipulation. Our\nreal-world experiments demonstrate that a model trained with 160 robot hours of\nautonomously collected, unlabeled data is able to successfully perform complex\nmanipulation tasks with a wide range of objects not seen during training.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 19:51:46 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Ebert", "Frederik", ""], ["Dasari", "Sudeep", ""], ["Lee", "Alex X.", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1810.03044", "submitter": "Casey Bennett", "authors": "Casey C. Bennett", "title": "Artificial Intelligence for Diabetes Case Management: The Intersection\n  of Physical and Mental Health", "comments": "arXiv admin note: This version has been removed by arXiv\n  administrators due to copyright infringement", "journal-ref": "Informatics in Medicine Unlocked, 2019", "doi": "10.1016/j.imu.2019.100191", "report-no": null, "categories": "q-bio.QM cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diabetes is a major public health problem in the United States, affecting\nroughly 30 million people. Diabetes complications, along with the mental health\ncomorbidities that often co-occur with them, are major drivers of high\nhealthcare costs, poor outcomes, and reduced treatment adherence in diabetes.\nHere, we evaluate in a large state-wide population whether we can use\nartificial intelligence (AI) techniques to identify clusters of patient\ntrajectories within the broader diabetes population in order to create\ncost-effective, narrowly-focused case management intervention strategies to\nreduce development of complications. This approach combined data from: 1)\nclaims, 2) case management notes, and 3) social determinants of health from\n~300,000 real patients between 2014 and 2016. We categorized complications as\nfive types: Cardiovascular, Neuropathy, Opthalmic, Renal, and Other. Modeling\nwas performed combining a variety of machine learning algorithms, including\nsupervised classification, unsupervised clustering, natural language processing\nof unstructured care notes, and feature engineering. The results showed that we\ncan predict development of diabetes complications roughly 83.5% of the time\nusing claims data or social determinants of health data. They also showed we\ncan reveal meaningful clusters in the patient population related to\ncomplications and mental health that can be used to cost-effective screening\nprogram, reducing the number of patients to be screened down by 85%. This study\noutlines creation of an AI framework to develop protocols to better address\nmental health comorbidities that lead to complications development in the\ndiabetes population. Future work is described that outlines potential lines of\nresearch and the need for better addressing the 'people side' of the equation.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 19:59:56 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 19:12:44 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 18:59:06 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Bennett", "Casey C.", ""]]}, {"id": "1810.03063", "submitter": "Christian Kroer", "authors": "Christian Kroer, Gabriele Farina, and Tuomas Sandholm", "title": "Solving Large Sequential Games with the Excessive Gap Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been tremendous recent progress on equilibrium-finding algorithms\nfor zero-sum imperfect-information extensive-form games, but there has been a\npuzzling gap between theory and practice. First-order methods have\nsignificantly better theoretical convergence rates than any\ncounterfactual-regret minimization (CFR) variant. Despite this, CFR variants\nhave been favored in practice. Experiments with first-order methods have only\nbeen conducted on small- and medium-sized games because those methods are\ncomplicated to implement in this setting, and because CFR variants have been\nenhanced extensively for over a decade they perform well in practice. In this\npaper we show that a particular first-order method, a state-of-the-art variant\nof the excessive gap technique---instantiated with the dilated entropy distance\nfunction---can efficiently solve large real-world problems competitively with\nCFR and its variants. We show this on large endgames encountered by the\nLibratus poker AI, which recently beat top human poker specialist professionals\nat no-limit Texas hold'em. We show experimental results on our variant of the\nexcessive gap technique as well as a prior version. We introduce a numerically\nfriendly implementation of the smoothed best response computation associated\nwith first-order methods for extensive-form game solving. We present, to our\nknowledge, the first GPU implementation of a first-order method for\nextensive-form games. We present comparisons of several excessive gap technique\nand CFR variants.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 00:16:43 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Kroer", "Christian", ""], ["Farina", "Gabriele", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1810.03064", "submitter": "Fei Wang", "authors": "Fei Wang, Jinsong Han, Shiyuan Zhang, Xu He, Dong Huang", "title": "CSI-Net: Unified Human Body Characterization and Pose Recognition", "comments": "14 pages, 6 figures and 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build CSI-Net, a unified Deep Neural Network~(DNN), to learn the\nrepresentation of WiFi signals. Using CSI-Net, we jointly solved two body\ncharacterization problems: biometrics estimation (including body fat, muscle,\nwater, and bone rates) and person recognition. We also demonstrated the\napplication of CSI-Net on two distinctive pose recognition tasks: the hand sign\nrecognition (fine-scaled action of the hand) and falling detection\n(coarse-scaled motion of the body).\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 00:51:14 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 18:10:23 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Wang", "Fei", ""], ["Han", "Jinsong", ""], ["Zhang", "Shiyuan", ""], ["He", "Xu", ""], ["Huang", "Dong", ""]]}, {"id": "1810.03069", "submitter": "Lixing Chen", "authors": "Lixing Chen, Jie Xu, Shaolei Ren, Pan Zhou", "title": "Spatio-temporal Edge Service Placement: A Bandit Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shared edge computing platforms deployed at the radio access network are\nexpected to significantly improve quality of service delivered by Application\nService Providers (ASPs) in a flexible and economic way. However, placing edge\nservice in every possible edge site by an ASP is practically infeasible due to\nthe ASP's prohibitive budget requirement. In this paper, we investigate the\nedge service placement problem of an ASP under a limited budget, where the ASP\ndynamically rents computing/storage resources in edge sites to host its\napplications in close proximity to end users. Since the benefit of placing edge\nservice in a specific site is usually unknown to the ASP a priori, optimal\nplacement decisions must be made while learning this benefit. We pose this\nproblem as a novel combinatorial contextual bandit learning problem. It is\n\"combinatorial\" because only a limited number of edge sites can be rented to\nprovide the edge service given the ASP's budget. It is \"contextual\" because we\nutilize user context information to enable finer-grained learning and decision\nmaking. To solve this problem and optimize the edge computing performance, we\npropose SEEN, a Spatial-temporal Edge sErvice placemeNt algorithm. Furthermore,\nSEEN is extended to scenarios with overlapping service coverage by\nincorporating a disjunctively constrained knapsack problem. In both cases, we\nprove that our algorithm achieves a sublinear regret bound when it is compared\nto an oracle algorithm that knows the exact benefit information. Simulations\nare carried out on a real-world dataset, whose results show that SEEN\nsignificantly outperforms benchmark solutions.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 01:54:50 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Chen", "Lixing", ""], ["Xu", "Jie", ""], ["Ren", "Shaolei", ""], ["Zhou", "Pan", ""]]}, {"id": "1810.03078", "submitter": "Yu-Zhen Janice Chen", "authors": "Xutong Liu, Yu-Zhen Janice Chen, John C.S. Lui, Konstantin Avrachenkov", "title": "Graphlet Count Estimation via Convolutional Neural Networks", "comments": "Extended Abstract Accepted by Complex Networks 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphlets are defined as k-node connected induced subgraph patterns. For an\nundirected graph, 3-node graphlets include close triangle and open triangle.\nWhen k = 4, there are six types of graphlets, e.g., tailed-triangle and clique\nare two possible 4-node graphlets. The number of each graphlet, called graphlet\ncount, is a signature which characterizes the local network structure of a\ngiven graph. Graphlet count plays a prominent role in network analysis of many\nfields, most notably bioinformatics and social science.\n  However, computing exact graphlet count is inherently difficult and\ncomputational expensive because the number of graphlets grows exponentially\nlarge as the graph size and/or graphlet size k grow. To deal with this\ndifficulty, many sampling methods were proposed to estimate graphlet count with\nbounded error. Nevertheless, these methods require large number of samples to\nbe statistically reliable, which is still computationally demanding. Moreover,\nthey have to repeat laborious counting procedure even if a new graph is similar\nor exactly the same as previous studied graphs.\n  Intuitively, learning from historic graphs can make estimation more accurate\nand avoid many repetitive counting to reduce computational cost. Based on this\nidea, we propose a convolutional neural network (CNN) framework and two\npreprocessing techniques to estimate graphlet count. Extensive experiments on\ntwo types of random graphs and real world biochemistry graphs show that our\nframework can offer substantial speedup on estimating graphlet count of new\ngraphs with high accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 03:31:10 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Liu", "Xutong", ""], ["Chen", "Yu-Zhen Janice", ""], ["Lui", "John C. S.", ""], ["Avrachenkov", "Konstantin", ""]]}, {"id": "1810.03105", "submitter": "Fanhua Shang", "authors": "Fanhua Shang, Licheng Jiao, Kaiwen Zhou, James Cheng, Yan Ren, Yufei\n  Jin", "title": "ASVRG: Accelerated Proximal SVRG", "comments": "32 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an accelerated proximal stochastic variance reduced\ngradient (ASVRG) method, in which we design a simple and effective momentum\nacceleration trick. Unlike most existing accelerated stochastic variance\nreduction methods such as Katyusha, ASVRG has only one additional variable and\none momentum parameter. Thus, ASVRG is much simpler than those methods, and has\nmuch lower per-iteration complexity. We prove that ASVRG achieves the best\nknown oracle complexities for both strongly convex and non-strongly convex\nobjectives. In addition, we extend ASVRG to mini-batch and non-smooth settings.\nWe also empirically verify our theoretical results and show that the\nperformance of ASVRG is comparable with, and sometimes even better than that of\nthe state-of-the-art stochastic methods.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 08:43:05 GMT"}, {"version": "v2", "created": "Sat, 17 Nov 2018 17:38:34 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Shang", "Fanhua", ""], ["Jiao", "Licheng", ""], ["Zhou", "Kaiwen", ""], ["Cheng", "James", ""], ["Ren", "Yan", ""], ["Jin", "Yufei", ""]]}, {"id": "1810.03151", "submitter": "Yimin Tang", "authors": "Yimin Tang, Tian Jiang, Yanpeng Hu", "title": "A Minesweeper Solver Using Logic Inference, CSP and Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minesweeper as a puzzle video game and is proved that it is an NPC problem.\nWe use CSP, Logic Inference and Sampling to make a minesweeper solver and we\nlimit us each select in 5 seconds.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 14:26:11 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Tang", "Yimin", ""], ["Jiang", "Tian", ""], ["Hu", "Yanpeng", ""]]}, {"id": "1810.03237", "submitter": "Stephen James", "authors": "Stephen James, Michael Bloesch, Andrew J. Davison", "title": "Task-Embedded Control Networks for Few-Shot Imitation Learning", "comments": "Published at the Conference on Robot Learning (CoRL) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much like humans, robots should have the ability to leverage knowledge from\npreviously learned tasks in order to learn new tasks quickly in new and\nunfamiliar environments. Despite this, most robot learning approaches have\nfocused on learning a single task, from scratch, with a limited notion of\ngeneralisation, and no way of leveraging the knowledge to learn other tasks\nmore efficiently. One possible solution is meta-learning, but many of the\nrelated approaches are limited in their ability to scale to a large number of\ntasks and to learn further tasks without forgetting previously learned ones.\nWith this in mind, we introduce Task-Embedded Control Networks, which employ\nideas from metric learning in order to create a task embedding that can be used\nby a robot to learn new tasks from one or more demonstrations. In the area of\nvisually-guided manipulation, we present simulation results in which we surpass\nthe performance of a state-of-the-art method when using only visual information\nfrom each demonstration. Additionally, we demonstrate that our approach can\nalso be used in conjunction with domain randomisation to train our few-shot\nlearning ability in simulation and then deploy in the real world without any\nadditional training. Once deployed, the robot can learn new tasks from a single\nreal-world demonstration.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 00:57:24 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["James", "Stephen", ""], ["Bloesch", "Michael", ""], ["Davison", "Andrew J.", ""]]}, {"id": "1810.03370", "submitter": "Thiago Serra", "authors": "Thiago Serra, Srikumar Ramalingam", "title": "Empirical Bounds on Linear Regions of Deep Rectifier Networks", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We can compare the expressiveness of neural networks that use rectified\nlinear units (ReLUs) by the number of linear regions, which reflect the number\nof pieces of the piecewise linear functions modeled by such networks. However,\nenumerating these regions is prohibitive and the known analytical bounds are\nidentical for networks with same dimensions. In this work, we approximate the\nnumber of linear regions through empirical bounds based on features of the\ntrained network and probabilistic inference. Our first contribution is a method\nto sample the activation patterns defined by ReLUs using universal hash\nfunctions. This method is based on a Mixed-Integer Linear Programming (MILP)\nformulation of the network and an algorithm for probabilistic lower bounds of\nMILP solution sets that we call MIPBound, which is considerably faster than\nexact counting and reaches values in similar orders of magnitude. Our second\ncontribution is a tighter activation-based bound for the maximum number of\nlinear regions, which is particularly stronger in networks with narrow layers.\nCombined, these bounds yield a fast proxy for the number of linear regions of a\ndeep neural network.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 11:06:50 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 02:42:04 GMT"}, {"version": "v3", "created": "Sat, 14 Dec 2019 11:34:01 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Serra", "Thiago", ""], ["Ramalingam", "Srikumar", ""]]}, {"id": "1810.03393", "submitter": "Ye Zhu PhD", "authors": "Ye Zhu, Kai Ming Ting, Yuan Jin, Maia Angelova", "title": "Hierarchical clustering that takes advantage of both density-peak and\n  density-connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on density-based clustering, particularly the Density Peak\n(DP) algorithm and the one based on density-connectivity DBSCAN; and proposes a\nnew method which takes advantage of the individual strengths of these two\nmethods to yield a density-based hierarchical clustering algorithm. Our\ninvestigation begins with formally defining the types of clusters DP and DBSCAN\nare designed to detect; and then identifies the kinds of distributions that DP\nand DBSCAN individually fail to detect all clusters in a dataset. These\nidentified weaknesses inspire us to formally define a new kind of clusters and\npropose a new method called DC-HDP to overcome these weaknesses to identify\nclusters with arbitrary shapes and varied densities. In addition, the new\nmethod produces a richer clustering result in terms of hierarchy or dendrogram\nfor better cluster structures understanding. Our empirical evaluation results\nshow that DC-HDP produces the best clustering results on 14 datasets in\ncomparison with 7 state-of-the-art clustering algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 12:12:42 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Zhu", "Ye", ""], ["Ting", "Kai Ming", ""], ["Jin", "Yuan", ""], ["Angelova", "Maia", ""]]}, {"id": "1810.03449", "submitter": "Shaobo Liu", "authors": "Shaobo Liu and Rui Cheng and Xiaoming Yu and Xueqi Cheng", "title": "Exploiting Contextual Information via Dynamic Memory Network for Event\n  Detection", "comments": "Accepted as short paper by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of event detection involves identifying and categorizing event\ntriggers. Contextual information has been shown effective on the task. However,\nexisting methods which utilize contextual information only process the context\nonce. We argue that the context can be better exploited by processing the\ncontext multiple times, allowing the model to perform complex reasoning and to\ngenerate better context representation, thus improving the overall performance.\nMeanwhile, dynamic memory network (DMN) has demonstrated promising capability\nin capturing contextual information and has been applied successfully to\nvarious tasks. In light of the multi-hop mechanism of the DMN to model the\ncontext, we propose the trigger detection dynamic memory network (TD-DMN) to\ntackle the event detection problem. We performed a five-fold cross-validation\non the ACE-2005 dataset and experimental results show that the multi-hop\nmechanism does improve the performance and the proposed model achieves best\n$F_1$ score compared to the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 08:43:11 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Liu", "Shaobo", ""], ["Cheng", "Rui", ""], ["Yu", "Xiaoming", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1810.03450", "submitter": "Stanislav Peshterliev", "authors": "Stanislav Peshterliev, John Kearney, Abhyuday Jagannatha, Imre Kiss,\n  Spyros Matsoukas", "title": "Active Learning for New Domains in Natural Language Understanding", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore active learning (AL) for improving the accuracy of new domains in\na natural language understanding (NLU) system. We propose an algorithm called\nMajority-CRF that uses an ensemble of classification models to guide the\nselection of relevant utterances, as well as a sequence labeling model to help\nprioritize informative examples. Experiments with three domains show that\nMajority-CRF achieves 6.6%-9% relative error rate reduction compared to random\nsampling with the same annotation budget, and statistically significant\nimprovements compared to other AL approaches. Additionally, case studies with\nhuman-in-the-loop AL on six new domains show 4.6%-9% improvement on an existing\nNLU system.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 12:50:56 GMT"}, {"version": "v2", "created": "Sat, 30 Mar 2019 16:04:09 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Peshterliev", "Stanislav", ""], ["Kearney", "John", ""], ["Jagannatha", "Abhyuday", ""], ["Kiss", "Imre", ""], ["Matsoukas", "Spyros", ""]]}, {"id": "1810.03466", "submitter": "Kaveh Bastani", "authors": "Kaveh Bastani, Elham Asgari, Hamed Namavari", "title": "Wide and Deep Learning for Peer-to-Peer Lending", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-fin.RM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a two-stage scoring approach to help lenders decide their\nfund allocations in the peer-to-peer (P2P) lending market. The existing scoring\napproaches focus on only either probability of default (PD) prediction, known\nas credit scoring, or profitability prediction, known as profit scoring, to\nidentify the best loans for investment. Credit scoring fails to deliver the\nmain need of lenders on how much profit they may obtain through their\ninvestment. On the other hand, profit scoring can satisfy that need by\npredicting the investment profitability. However, profit scoring completely\nignores the class imbalance problem where most of the past loans are\nnon-default. Consequently, ignorance of the class imbalance problem\nsignificantly affects the accuracy of profitability prediction. Our proposed\ntwo-stage scoring approach is an integration of credit scoring and profit\nscoring to address the above challenges. More specifically, stage 1 is designed\nas credit scoring to identify non-default loans while the imbalanced nature of\nloan status is considered in PD prediction. The loans identified as non-default\nare then moved to stage 2 for prediction of profitability, measured by internal\nrate of return. Wide and deep learning is used to build the predictive models\nin both stages to achieve both memorization and generalization. Extensive\nnumerical studies are conducted based on real-world data to verify the\neffectiveness of the proposed approach. The numerical studies indicate our\ntwo-stage scoring approach outperforms the existing credit scoring and profit\nscoring approaches.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 00:54:06 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 02:03:13 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Bastani", "Kaveh", ""], ["Asgari", "Elham", ""], ["Namavari", "Hamed", ""]]}, {"id": "1810.03530", "submitter": "Michael Kamp", "authors": "Michael Kamp and Mario Boley and Olana Missura and Thomas G\\\"artner", "title": "Effective Parallelisation for Machine Learning", "comments": "Advances in Neural Information Processing Systems, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel parallelisation scheme that simplifies the adaptation of\nlearning algorithms to growing amounts of data as well as growing needs for\naccurate and confident predictions in critical applications. In contrast to\nother parallelisation techniques, it can be applied to a broad class of\nlearning algorithms without further mathematical derivations and without\nwriting dedicated code, while at the same time maintaining theoretical\nperformance guarantees. Moreover, our parallelisation scheme is able to reduce\nthe runtime of many learning algorithms to polylogarithmic time on\nquasi-polynomially many processing units. This is a significant step towards a\ngeneral answer to an open question on the efficient parallelisation of machine\nlearning algorithms in the sense of Nick's Class (NC). The cost of this\nparallelisation is in the form of a larger sample complexity. Our empirical\nstudy confirms the potential of our parallelisation scheme with fixed numbers\nof processors and instances in realistic application scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 15:35:07 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Kamp", "Michael", ""], ["Boley", "Mario", ""], ["Missura", "Olana", ""], ["G\u00e4rtner", "Thomas", ""]]}, {"id": "1810.03538", "submitter": "Elias Khalil", "authors": "Elias B. Khalil, Amrita Gupta, Bistra Dilkina", "title": "Combinatorial Attacks on Binarized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binarized Neural Networks (BNNs) have recently attracted significant interest\ndue to their computational efficiency. Concurrently, it has been shown that\nneural networks may be overly sensitive to \"attacks\" - tiny adversarial changes\nin the input - which may be detrimental to their use in safety-critical\ndomains. Designing attack algorithms that effectively fool trained models is a\nkey step towards learning robust neural networks. The discrete,\nnon-differentiable nature of BNNs, which distinguishes them from their\nfull-precision counterparts, poses a challenge to gradient-based attacks. In\nthis work, we study the problem of attacking a BNN through the lens of\ncombinatorial and integer optimization. We propose a Mixed Integer Linear\nProgramming (MILP) formulation of the problem. While exact and flexible, the\nMILP quickly becomes intractable as the network and perturbation space grow. To\naddress this issue, we propose IProp, a decomposition-based algorithm that\nsolves a sequence of much smaller MILP problems. Experimentally, we evaluate\nboth proposed methods against the standard gradient-based attack (FGSM) on\nMNIST and Fashion-MNIST, and show that IProp performs favorably compared to\nFGSM, while scaling beyond the limits of the MILP.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 15:51:23 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Khalil", "Elias B.", ""], ["Gupta", "Amrita", ""], ["Dilkina", "Bistra", ""]]}, {"id": "1810.03583", "submitter": "Christian A. Mueller", "authors": "Georg J\\\"ager, Christian A. Mueller, Madhura Thosar, Sebastian Zug and\n  Andreas Birk", "title": "Towards Robot-Centric Conceptual Knowledge Acquisition", "comments": "This work is accepted for the \"Robots that Learn and Reason\" Workshop\n  of the IEEE/RSJ International Conference on Intelligent Robots and Systems\n  (IROS), Madrid, Spain, October, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots require knowledge about objects in order to efficiently perform\nvarious household tasks involving objects. The existing knowledge bases for\nrobots acquire symbolic knowledge about objects from manually-coded external\ncommon sense knowledge bases such as ConceptNet, Word-Net etc. The problem with\nsuch approaches is the discrepancy between human-centric symbolic knowledge and\nrobot-centric object perception due to its limited perception capabilities.\nUltimately, significant portion of knowledge in the knowledge base remains\nungrounded into robot's perception. To overcome this discrepancy, we propose an\napproach to enable robots to generate robot-centric symbolic knowledge about\nobjects from their own sensory data, thus, allowing them to assemble their own\nconceptual understanding of objects. With this goal in mind, the presented\npaper elaborates on the work-in-progress of the proposed approach followed by\nthe preliminary results.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 17:14:58 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["J\u00e4ger", "Georg", ""], ["Mueller", "Christian A.", ""], ["Thosar", "Madhura", ""], ["Zug", "Sebastian", ""], ["Birk", "Andreas", ""]]}, {"id": "1810.03608", "submitter": "Yuan Yao", "authors": "Chendi Huang and Yuan Yao", "title": "A Unified Dynamic Approach to Sparse Model Selection", "comments": "24 pages", "journal-ref": "Proceedings of the 21st International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2018, Lanzarote, Spain. PMLR: Volume 84", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse model selection is ubiquitous from linear regression to graphical\nmodels where regularization paths, as a family of estimators upon the\nregularization parameter varying, are computed when the regularization\nparameter is unknown or decided data-adaptively. Traditional computational\nmethods rely on solving a set of optimization problems where the regularization\nparameters are fixed on a grid that might be inefficient. In this paper, we\nintroduce a simple iterative regularization path, which follows the dynamics of\na sparse Mirror Descent algorithm or a generalization of Linearized Bregman\nIterations with nonlinear loss. Its performance is competitive to\n\\texttt{glmnet} with a further bias reduction. A path consistency theory is\npresented that under the Restricted Strong Convexity (RSC) and the\nIrrepresentable Condition (IRR), the path will first evolve in a subspace with\nno false positives and reach an estimator that is sign-consistent or of minimax\noptimal $\\ell_2$ error rate. Early stopping regularization is required to\nprevent overfitting. Application examples are given in sparse logistic\nregression and Ising models for NIPS coauthorship.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 13:02:02 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Huang", "Chendi", ""], ["Yao", "Yuan", ""]]}, {"id": "1810.03679", "submitter": "Amit Prasad", "authors": "Amit Prasad and Ivana Dusparic", "title": "Multi-agent Deep Reinforcement Learning for Zero Energy Communities", "comments": "Accepted at ISGT Europe 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in renewable energy generation and introduction of the government\ntargets to improve energy efficiency gave rise to a concept of a Zero Energy\nBuilding (ZEB). A ZEB is a building whose net energy usage over a year is zero,\ni.e., its energy use is not larger than its overall renewables generation. A\ncollection of ZEBs forms a Zero Energy Community (ZEC). This paper addresses\nthe problem of energy sharing in such a community. This is different from\npreviously addressed energy sharing between buildings as our focus is on the\nimprovement of community energy status, while traditionally research focused on\nreducing losses due to transmission and storage, or achieving economic gains.\nWe model this problem in a multi-agent environment and propose a Deep\nReinforcement Learning (DRL) based solution. Each building is represented by an\nintelligent agent that learns over time the appropriate behaviour to share\nenergy. We have evaluated the proposed solution in a multi-agent simulation\nbuilt using osBrain. Results indicate that with time agents learn to\ncollaborate and learn a policy comparable to the optimal policy, which in turn\nimproves the ZEC's energy status. Buildings with no renewables preferred to\nrequest energy from their neighbours rather than from the supply grid.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 19:58:46 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 15:10:27 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Prasad", "Amit", ""], ["Dusparic", "Ivana", ""]]}, {"id": "1810.03736", "submitter": "Lewis Hammond", "authors": "Lewis Hammond and Vaishak Belle", "title": "Learning Tractable Probabilistic Models for Moral Responsibility and\n  Blame", "comments": "Published in Data Mining and Knowledge Discovery (2021)", "journal-ref": null, "doi": "10.1007/s10618-020-00726-4", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moral responsibility is a major concern in autonomous systems, with\napplications ranging from self-driving cars to kidney exchanges. Although there\nhave been recent attempts to formalise responsibility and blame, among similar\nnotions, the problem of learning within these formalisms has been unaddressed.\nFrom the viewpoint of such systems, the urgent questions are: (a) How can\nmodels of moral scenarios and blameworthiness be extracted and learnt\nautomatically from data? (b) How can judgements be computed effectively and\nefficiently, given the split-second decision points faced by some systems? By\nbuilding on constrained tractable probabilistic learning, we propose and\nimplement a hybrid (between data-driven and rule-based methods) learning\nframework for inducing models of such scenarios automatically from data and\nreasoning tractably from them. We report on experiments that compare our system\nwith human judgement in three illustrative domains: lung cancer staging,\nteamwork management, and trolley problems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 22:51:17 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 18:09:05 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 19:37:58 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Hammond", "Lewis", ""], ["Belle", "Vaishak", ""]]}, {"id": "1810.03947", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Yatin Chaudhary and Florian Buettner and Hinrich\n  Sch\\\"utze", "title": "textTOvec: Deep Contextualized Neural Autoregressive Topic Models of\n  Language with Distributed Compositional Prior", "comments": "Published in #ICLR2019 International Conference on Learning\n  Representations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address two challenges of probabilistic topic modelling in order to better\nestimate the probability of a word in a given context, i.e., P(word|context):\n(1) No Language Structure in Context: Probabilistic topic models ignore word\norder by summarizing a given context as a \"bag-of-word\" and consequently the\nsemantics of words in the context is lost. The LSTM-LM learns a vector-space\nrepresentation of each word by accounting for word order in local collocation\npatterns and models complex characteristics of language (e.g., syntax and\nsemantics), while the TM simultaneously learns a latent representation from the\nentire document and discovers the underlying thematic structure. We unite two\ncomplementary paradigms of learning the meaning of word occurrences by\ncombining a TM (e.g., DocNADE) and a LM in a unified probabilistic framework,\nnamed as ctx-DocNADE. (2) Limited Context and/or Smaller training corpus of\ndocuments: In settings with a small number of word occurrences (i.e., lack of\ncontext) in short text or data sparsity in a corpus of few documents, the\napplication of TMs is challenging. We address this challenge by incorporating\nexternal knowledge into neural autoregressive topic models via a language\nmodelling approach: we use word embeddings as input of a LSTM-LM with the aim\nto improve the word-topic mapping on a smaller and/or short-text corpus. The\nproposed DocNADE extension is named as ctx-DocNADEe.\n  We present novel neural autoregressive topic model variants coupled with\nneural LMs and embeddings priors that consistently outperform state-of-the-art\ngenerative TMs in terms of generalization (perplexity), interpretability (topic\ncoherence) and applicability (retrieval and classification) over 6 long-text\nand 8 short-text datasets from diverse domains.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 13:04:25 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 11:29:00 GMT"}, {"version": "v3", "created": "Sun, 25 Nov 2018 11:40:26 GMT"}, {"version": "v4", "created": "Sat, 23 Feb 2019 14:14:05 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Gupta", "Pankaj", ""], ["Chaudhary", "Yatin", ""], ["Buettner", "Florian", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1810.03965", "submitter": "Aniket Bera", "authors": "Aniket Bera and Dinesh Manocha", "title": "Interactive Surveillance Technologies for Dense Crowds", "comments": "Presented at AAAI FSS-18: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an algorithm for realtime anomaly detection in low to medium\ndensity crowd videos using trajectory-level behavior learning. Our formulation\ncombines online tracking algorithms from computer vision, non-linear pedestrian\nmotion models from crowd simulation, and Bayesian learning techniques to\nautomatically compute the trajectory-level pedestrian behaviors for each agent\nin the video. These learned behaviors are used to segment the trajectories and\nmotions of different pedestrians or agents and detect anomalies. We demonstrate\nthe interactive performance on the PETS ARENA dataset as well as indoor and\noutdoor crowd video benchmarks consisting of tens of human agents. We also\ndiscuss the implications of recent public policy and law enforcement issues\nrelating to surveillance and our research.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 20:18:25 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Bera", "Aniket", ""], ["Manocha", "Dinesh", ""]]}, {"id": "1810.03967", "submitter": "Mhafuzul Islam", "authors": "Mhafuzul Islam, Mahsrur Chowdhury, Hongda Li, Hongxin Hu", "title": "Vision-based Navigation of Autonomous Vehicle in Roadway Environments\n  with Unexpected Hazards", "comments": "17 pages, 12 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-based navigation of autonomous vehicles primarily depends on the Deep\nNeural Network (DNN) based systems in which the controller obtains input from\nsensors/detectors, such as cameras and produces a vehicle control output, such\nas a steering wheel angle to navigate the vehicle safely in a roadway traffic\nenvironment. Typically, these DNN-based systems of the autonomous vehicle are\ntrained through supervised learning; however, recent studies show that a\ntrained DNN-based system can be compromised by perturbation or adversarial\ninputs. Similarly, this perturbation can be introduced into the DNN-based\nsystems of autonomous vehicle by unexpected roadway hazards, such as debris and\nroadblocks. In this study, we first introduce a roadway hazardous environment\n(both intentional and unintentional roadway hazards) that can compromise the\nDNN-based navigational system of an autonomous vehicle, and produces an\nincorrect steering wheel angle, which can cause crashes resulting in fatality\nand injury. Then, we develop a DNN-based autonomous vehicle driving system\nusing object detection and semantic segmentation to mitigate the adverse effect\nof this type of hazardous environment, which helps the autonomous vehicle to\nnavigate safely around such hazards. We find that our developed DNN-based\nautonomous vehicle driving system including hazardous object detection and\nsemantic segmentation improves the navigational ability of an autonomous\nvehicle to avoid a potential hazard by 21% compared to the traditional\nDNN-based autonomous vehicle driving system.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 02:08:21 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 15:59:24 GMT"}, {"version": "v3", "created": "Mon, 20 May 2019 17:31:59 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Islam", "Mhafuzul", ""], ["Chowdhury", "Mahsrur", ""], ["Li", "Hongda", ""], ["Hu", "Hongxin", ""]]}, {"id": "1810.03970", "submitter": "Alexander Prange", "authors": "Alexander Prange, Michael Barz, Daniel Sonntag", "title": "A categorisation and implementation of digital pen features for\n  behaviour characterisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide a categorisation and implementation of digital ink\nfeatures for behaviour characterisation. Based on four feature sets taken from\nliterature, we provide a categorisation in different classes of syntactic and\nsemantic features. We implemented a publicly available framework to calculate\nthese features and show its deployment in the use case of analysing cognitive\nassessments performed using a digital pen.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 14:24:20 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Prange", "Alexander", ""], ["Barz", "Michael", ""], ["Sonntag", "Daniel", ""]]}, {"id": "1810.03979", "submitter": "Lukas Cavigelli", "authors": "Lukas Cavigelli, Luca Benini", "title": "Extended Bit-Plane Compression for Convolutional Neural Network\n  Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After the tremendous success of convolutional neural networks in image\nclassification, object detection, speech recognition, etc., there is now rising\ndemand for deployment of these compute-intensive ML models on tightly power\nconstrained embedded and mobile systems at low cost as well as for pushing the\nthroughput in data centers. This has triggered a wave of research towards\nspecialized hardware accelerators. Their performance is often constrained by\nI/O bandwidth and the energy consumption is dominated by I/O transfers to\noff-chip memory. We introduce and evaluate a novel, hardware-friendly\ncompression scheme for the feature maps present within convolutional neural\nnetworks. We show that an average compression ratio of 4.4x relative to\nuncompressed data and a gain of 60% over existing method can be achieved for\nResNet-34 with a compression block requiring <300 bit of sequential cells and\nminimal combinational logic.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 21:02:53 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Cavigelli", "Lukas", ""], ["Benini", "Luca", ""]]}, {"id": "1810.03981", "submitter": "Minh Ho\\`ang H\\`a", "authors": "Hoa Nguyen Phuong, Huyen Tran Ngoc Nhat, Minh Ho\\`ang H\\`a, Andr\\'e\n  Langevin, Martin Tr\\'epanier", "title": "Solving the clustered traveling salesman problem with d-relaxed priority\n  rule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Clustered Traveling Salesman Problem with a Prespecified Order on the\nClusters, a variant of the well-known traveling salesman problem is studied in\nliterature. In this problem, delivery locations are divided into clusters with\ndifferent urgency levels and more urgent locations must be visited before less\nurgent ones. However, this could lead to an inefficient route in terms of\ntraveling cost. This priority-oriented constraint can be relaxed by a rule\ncalled d-relaxed priority that provides a trade-off between transportation cost\nand emergency level. Our research proposes two approaches to solve the problem\nwith d-relaxed priority rule. We improve the mathematical formulation proposed\nin the literature to construct an exact solution method. A meta-heuristic\nmethod based on the framework of Iterated Local Search with problem-tailored\noperators is also introduced to find approximate solutions. Experimental\nresults show the effectiveness of our methods.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 17:24:11 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Phuong", "Hoa Nguyen", ""], ["Nhat", "Huyen Tran Ngoc", ""], ["H\u00e0", "Minh Ho\u00e0ng", ""], ["Langevin", "Andr\u00e9", ""], ["Tr\u00e9panier", "Martin", ""]]}, {"id": "1810.03993", "submitter": "Margaret Mitchell", "authors": "Margaret Mitchell and Simone Wu and Andrew Zaldivar and Parker Barnes\n  and Lucy Vasserman and Ben Hutchinson and Elena Spitzer and Inioluwa Deborah\n  Raji and Timnit Gebru", "title": "Model Cards for Model Reporting", "comments": null, "journal-ref": "FAT* '19: Conference on Fairness, Accountability, and\n  Transparency, January 29--31, 2019, Atlanta, GA, USA", "doi": "10.1145/3287560.3287596", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trained machine learning models are increasingly used to perform high-impact\ntasks in areas such as law enforcement, medicine, education, and employment. In\norder to clarify the intended use cases of machine learning models and minimize\ntheir usage in contexts for which they are not well suited, we recommend that\nreleased models be accompanied by documentation detailing their performance\ncharacteristics. In this paper, we propose a framework that we call model\ncards, to encourage such transparent model reporting. Model cards are short\ndocuments accompanying trained machine learning models that provide benchmarked\nevaluation in a variety of conditions, such as across different cultural,\ndemographic, or phenotypic groups (e.g., race, geographic location, sex,\nFitzpatrick skin type) and intersectional groups (e.g., age and race, or sex\nand Fitzpatrick skin type) that are relevant to the intended application\ndomains. Model cards also disclose the context in which models are intended to\nbe used, details of the performance evaluation procedures, and other relevant\ninformation. While we focus primarily on human-centered machine learning models\nin the application fields of computer vision and natural language processing,\nthis framework can be used to document any trained machine learning model. To\nsolidify the concept, we provide cards for two supervised models: One trained\nto detect smiling faces in images, and one trained to detect toxic comments in\ntext. We propose model cards as a step towards the responsible democratization\nof machine learning and related AI technology, increasing transparency into how\nwell AI technology works. We hope this work encourages those releasing trained\nmachine learning models to accompany model releases with similar detailed\nevaluation numbers and other relevant documentation.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 22:33:43 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 20:25:27 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Mitchell", "Margaret", ""], ["Wu", "Simone", ""], ["Zaldivar", "Andrew", ""], ["Barnes", "Parker", ""], ["Vasserman", "Lucy", ""], ["Hutchinson", "Ben", ""], ["Spitzer", "Elena", ""], ["Raji", "Inioluwa Deborah", ""], ["Gebru", "Timnit", ""]]}, {"id": "1810.04000", "submitter": "Lin Li", "authors": "Zhaohui Chao, Lin Li", "title": "The combination of context information to enhance simple question\n  answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of knowledge base,question answering based on\nknowledge base has been a hot research issue. In this paper, we focus on\nanswering singlerelation factoid questions based on knowledge base. We build a\nquestion answering system and study the effect of context information on fact\nselection, such as entity's notable type,outdegree. Experimental results show\nthat context information can improve the result of simple question answering.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 14:02:56 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Chao", "Zhaohui", ""], ["Li", "Lin", ""]]}, {"id": "1810.04038", "submitter": "Ming Zeng", "authors": "Ming Zeng, Haoxiang Gao, Tong Yu, Ole J. Mengshoel, Helge Langseth,\n  Ian Lane, Xiaobing Liu", "title": "Understanding and Improving Recurrent Networks for Human Activity\n  Recognition by Continuous Attention", "comments": "8 pages. published in The International Symposium on Wearable\n  Computers (ISWC) 2018", "journal-ref": "The International Symposium on Wearable Computers (ISWC) 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks, including recurrent networks, have been successfully\napplied to human activity recognition. Unfortunately, the final representation\nlearned by recurrent networks might encode some noise (irrelevant signal\ncomponents, unimportant sensor modalities, etc.). Besides, it is difficult to\ninterpret the recurrent networks to gain insight into the models' behavior. To\naddress these issues, we propose two attention models for human activity\nrecognition: temporal attention and sensor attention. These two mechanisms\nadaptively focus on important signals and sensor modalities. To further improve\nthe understandability and mean F1 score, we add continuity constraints,\nconsidering that continuous sensor signals are more robust than discrete ones.\nWe evaluate the approaches on three datasets and obtain state-of-the-art\nresults. Furthermore, qualitative analysis shows that the attention learned by\nthe models agree well with human intuition.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 21:24:19 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Zeng", "Ming", ""], ["Gao", "Haoxiang", ""], ["Yu", "Tong", ""], ["Mengshoel", "Ole J.", ""], ["Langseth", "Helge", ""], ["Lane", "Ian", ""], ["Liu", "Xiaobing", ""]]}, {"id": "1810.04040", "submitter": "Chen Zhu", "authors": "Chen Zhu, Hengshu Zhu, Hui Xiong, Chao Ma, Fang Xie, Pengliang Ding,\n  Pan Li", "title": "Person-Job Fit: Adapting the Right Talent for the Right Job with Joint\n  Representation Learning", "comments": "16 pages, 5 figures", "journal-ref": "ACM Transactions on Management Information Systems (2018)", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person-Job Fit is the process of matching the right talent for the right job\nby identifying talent competencies that are required for the job. While many\nqualitative efforts have been made in related fields, it still lacks of\nquantitative ways of measuring talent competencies as well as the job's talent\nrequirements. To this end, in this paper, we propose a novel end-to-end\ndata-driven model based on Convolutional Neural Network (CNN), namely\nPerson-Job Fit Neural Network (PJFNN), for matching a talent qualification to\nthe requirements of a job. To be specific, PJFNN is a bipartite neural network\nwhich can effectively learn the joint representation of Person-Job fitness from\nhistorical job applications. In particular, due to the design of a hierarchical\nrepresentation structure, PJFNN can not only estimate whether a candidate fits\na job, but also identify which specific requirement items in the job posting\nare satisfied by the candidate by measuring the distances between corresponding\nlatent representations. Finally, the extensive experiments on a large-scale\nreal-world dataset clearly validate the performance of PJFNN in terms of\nPerson-Job Fit prediction. Also, we provide effective data visualization to\nshow some job and talent benchmark insights obtained by PJFNN.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 04:13:39 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Zhu", "Chen", ""], ["Zhu", "Hengshu", ""], ["Xiong", "Hui", ""], ["Ma", "Chao", ""], ["Xie", "Fang", ""], ["Ding", "Pengliang", ""], ["Li", "Pan", ""]]}, {"id": "1810.04053", "submitter": "J.-M. Chauvet", "authors": "Jean-Marie Chauvet", "title": "The 30-Year Cycle In The AI Debate", "comments": "31 pages, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last couple of years, the rise of Artificial Intelligence and the\nsuccesses of academic breakthroughs in the field have been inescapable. Vast\nsums of money have been thrown at AI start-ups. Many existing tech companies --\nincluding the giants like Google, Amazon, Facebook, and Microsoft -- have\nopened new research labs. The rapid changes in these everyday work and\nentertainment tools have fueled a rising interest in the underlying technology\nitself; journalists write about AI tirelessly, and companies -- of tech nature\nor not -- brand themselves with AI, Machine Learning or Deep Learning whenever\nthey get a chance. Confronting squarely this media coverage, several analysts\nare starting to voice concerns about over-interpretation of AI's blazing\nsuccesses and the sometimes poor public reporting on the topic. This paper\nreviews briefly the track-record in AI and Machine Learning and finds this\npattern of early dramatic successes, followed by philosophical critique and\nunexpected difficulties, if not downright stagnation, returning almost to the\nclock in 30-year cycles since 1958.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 16:35:06 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Chauvet", "Jean-Marie", ""]]}, {"id": "1810.04058", "submitter": "Ian Xiao", "authors": "Ian Xiao", "title": "A Distributed Reinforcement Learning Solution With Knowledge Transfer\n  Capability for A Bike Rebalancing Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rebalancing is a critical service bottleneck for many transportation\nservices, such as Citi Bike. Citi Bike relies on manual orchestrations of\nrebalancing bikes between dispatchers and field agents. Motivated by such\nproblem and the lack of smart autonomous solutions in this area, this project\nexplored a new RL architecture called Distributed RL (DiRL) with Transfer\nLearning (TL) capability. The DiRL solution is adaptive to changing traffic\ndynamics when keeping bike stock under control at the minimum cost. DiRL\nachieved a 350% improvement in bike rebalancing autonomously and TL offered a\n62.4% performance boost in managing an entire bike network. Lastly, a field\ntrip to the dispatch office of Chariot, a ride-sharing service, provided\ninsights to overcome challenges of deploying an RL solution in the real world.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 14:57:55 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Xiao", "Ian", ""]]}, {"id": "1810.04107", "submitter": "Mehdi Mohammadi", "authors": "Mehdi Mohammadi, Ala Al-Fuqaha", "title": "Enabling Cognitive Smart Cities Using Big Data and Machine Learning:\n  Approaches and Challenges", "comments": "7 pages, 5 figures and 1 table. Final version is published in IEEE\n  Communications Magazine", "journal-ref": "IEEE Communications Magazine, Vol. 56, No. 2, pp. 94-101, 2018", "doi": "10.1109/MCOM.2018.1700298", "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of smart cities and their fast-paced deployment is resulting\nin the generation of large quantities of data at unprecedented rates.\nUnfortunately, most of the generated data is wasted without extracting\npotentially useful information and knowledge because of the lack of established\nmechanisms and standards that benefit from the availability of such data.\nMoreover, the high dynamical nature of smart cities calls for new generation of\nmachine learning approaches that are flexible and adaptable to cope with the\ndynamicity of data to perform analytics and learn from real-time data. In this\narticle, we shed the light on the challenge of under utilizing the big data\ngenerated by smart cities from a machine learning perspective. Especially, we\npresent the phenomenon of wasting unlabeled data. We argue that\nsemi-supervision is a must for smart city to address this challenge. We also\npropose a three-level learning framework for smart cities that matches the\nhierarchical nature of big data generated by smart cities with a goal of\nproviding different levels of knowledge abstractions. The proposed framework is\nscalable to meet the needs of smart city services. Fundamentally, the framework\nbenefits from semi-supervised deep reinforcement learning where a small amount\nof data that has users' feedback serves as labeled data while a larger amount\nis without such users' feedback serves as unlabeled data. This paper also\nexplores how deep reinforcement learning and its shift toward semi-supervision\ncan handle the cognitive side of smart city services and improve their\nperformance by providing several use cases spanning the different domains of\nsmart cities. We also highlight several challenges as well as promising future\nresearch directions for incorporating machine learning and high-level\nintelligence into smart city services.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 16:27:46 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Mohammadi", "Mehdi", ""], ["Al-Fuqaha", "Ala", ""]]}, {"id": "1810.04118", "submitter": "Mehdi Mohammadi", "authors": "Mehdi Mohammadi, Ala Al-Fuqaha, Mohsen Guizani, Jun-Seok Oh", "title": "Semi-supervised Deep Reinforcement Learning in Support of IoT and Smart\n  City Services", "comments": "11 pages, 7 figures. Accepted for publication in IEEE Internet of\n  Things Journal", "journal-ref": "IEEE Internet of Things Journal, Volume 5, Issue 2, 2018", "doi": "10.1109/JIOT.2017.2712560", "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart services are an important element of the smart cities and the Internet\nof Things (IoT) ecosystems where the intelligence behind the services is\nobtained and improved through the sensory data. Providing a large amount of\ntraining data is not always feasible; therefore, we need to consider\nalternative ways that incorporate unlabeled data as well. In recent years, Deep\nreinforcement learning (DRL) has gained great success in several application\ndomains. It is an applicable method for IoT and smart city scenarios where\nauto-generated data can be partially labeled by users' feedback for training\npurposes. In this paper, we propose a semi-supervised deep reinforcement\nlearning model that fits smart city applications as it consumes both labeled\nand unlabeled data to improve the performance and accuracy of the learning\nagent. The model utilizes Variational Autoencoders (VAE) as the inference\nengine for generalizing optimal policies. To the best of our knowledge, the\nproposed model is the first investigation that extends deep reinforcement\nlearning to the semi-supervised paradigm. As a case study of smart city\napplications, we focus on smart buildings and apply the proposed model to the\nproblem of indoor localization based on BLE signal strength. Indoor\nlocalization is the main component of smart city services since people spend\nsignificant time in indoor environments. Our model learns the best action\npolicies that lead to a close estimation of the target locations with an\nimprovement of 23% in terms of distance to the target and at least 67% more\nreceived rewards compared to the supervised DRL model.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 16:47:25 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Mohammadi", "Mehdi", ""], ["Al-Fuqaha", "Ala", ""], ["Guizani", "Mohsen", ""], ["Oh", "Jun-Seok", ""]]}, {"id": "1810.04244", "submitter": "Kyle Julian", "authors": "Kyle D. Julian and Mykel J. Kochenderfer", "title": "Distributed Wildfire Surveillance with Autonomous Aircraft using Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teams of autonomous unmanned aircraft can be used to monitor wildfires,\nenabling firefighters to make informed decisions. However, controlling multiple\nautonomous fixed-wing aircraft to maximize forest fire coverage is a complex\nproblem. The state space is high dimensional, the fire propagates\nstochastically, the sensor information is imperfect, and the aircraft must\ncoordinate with each other to accomplish their mission. This work presents two\ndeep reinforcement learning approaches for training decentralized controllers\nthat accommodate the high dimensionality and uncertainty inherent in the\nproblem. The first approach controls the aircraft using immediate observations\nof the individual aircraft. The second approach allows aircraft to collaborate\non a map of the wildfire's state and maintain a time history of locations\nvisited, which are used as inputs to the controller. Simulation results show\nthat both approaches allow the aircraft to accurately track wildfire expansions\nand outperform an online receding horizon controller. Additional simulations\ndemonstrate that the approach scales with different numbers of aircraft and\ngeneralizes to different wildfire shapes.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 21:13:05 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Julian", "Kyle D.", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1810.04276", "submitter": "Mauricio Toro", "authors": "Mauricio Toro", "title": "Current Trends and Future Research Directions for Interactive Music", "comments": null, "journal-ref": "Journal of Theoretical & Applied Information Technologies 96(16),\n  2018", "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this review, it is explained and compared different software and\nformalisms used in music interaction: sequencers, computer-assisted\nimprovisation, meta- instruments, score-following, asynchronous dataflow\nlanguages, synchronous dataflow languages, process calculi, temporal\nconstraints and interactive scores. Formal approaches have the advantage of\nproviding rigorous semantics of the behavior of the model and proving\ncorrectness during execution. The main disadvantage of formal approaches is\nlack of commercial tools.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 02:53:26 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Toro", "Mauricio", ""]]}, {"id": "1810.04303", "submitter": "Erdem B{\\i}y{\\i}k", "authors": "Erdem B{\\i}y{\\i}k, Dorsa Sadigh", "title": "Batch Active Preference-Based Learning of Reward Functions", "comments": "Proceedings of the 2nd Conference on Robot Learning (CoRL), October\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data generation and labeling are usually an expensive part of learning for\nrobotics. While active learning methods are commonly used to tackle the former\nproblem, preference-based learning is a concept that attempts to solve the\nlatter by querying users with preference questions. In this paper, we will\ndevelop a new algorithm, batch active preference-based learning, that enables\nefficient learning of reward functions using as few data samples as possible\nwhile still having short query generation times. We introduce several\napproximations to the batch active learning problem, and provide theoretical\nguarantees for the convergence of our algorithms. Finally, we present our\nexperimental results for a variety of robotics tasks in simulation. Our results\nsuggest that our batch active learning algorithm requires only a few queries\nthat are computed in a short amount of time. We then showcase our algorithm in\na study to learn human users' preferences.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:02:55 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["B\u0131y\u0131k", "Erdem", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "1810.04315", "submitter": "EPTCS", "authors": "Carl Kwan (University of British Columbia), Mark R. Greenstreet\n  (University of British Columbia)", "title": "Real Vector Spaces and the Cauchy-Schwarz Inequality in ACL2(r)", "comments": "In Proceedings ACL2 2018, arXiv:1810.03762", "journal-ref": "EPTCS 280, 2018, pp. 111-127", "doi": "10.4204/EPTCS.280.9", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a mechanical proof of the Cauchy-Schwarz inequality in ACL2(r) and\na formalisation of the necessary mathematics to undertake such a proof. This\nincludes the formalisation of $\\mathbb{R}^n$ as an inner product space. We also\nprovide an application of Cauchy-Schwarz by formalising $\\mathbb R^n$ as a\nmetric space and exhibiting continuity for some simple functions $\\mathbb\nR^n\\to\\mathbb R$. The Cauchy-Schwarz inequality relates the magnitude of a\nvector to its projection (or inner product) with another: \\[|\\langle\nu,v\\rangle| \\leq \\|u\\| \\|v\\|\\] with equality iff the vectors are linearly\ndependent. It finds frequent use in many branches of mathematics including\nlinear algebra, real analysis, functional analysis, probability, etc. Indeed,\nthe inequality is considered to be among \"The Hundred Greatest Theorems\" and is\nlisted in the \"Formalizing 100 Theorems\" project. To the best of our knowledge,\nour formalisation is the first published proof using ACL2(r) or any other\nfirst-order theorem prover.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:37:12 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Kwan", "Carl", "", "University of British Columbia"], ["Greenstreet", "Mark R.", "", "University of British Columbia"]]}, {"id": "1810.04316", "submitter": "EPTCS", "authors": "Carl Kwan (University of British Columbia), Mark R. Greenstreet\n  (University of British Columbia)", "title": "Convex Functions in ACL2(r)", "comments": "In Proceedings ACL2 2018, arXiv:1810.03762", "journal-ref": "EPTCS 280, 2018, pp. 128-142", "doi": "10.4204/EPTCS.280.10", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper builds upon our prior formalisation of R^n in ACL2(r) by\npresenting a set of theorems for reasoning about convex functions. This is a\ndemonstration of the higher-dimensional analytical reasoning possible in our\nmetric space formalisation of R^n. Among the introduced theorems is a set of\nequivalent conditions for convex functions with Lipschitz continuous gradients\nfrom Yurii Nesterov's classic text on convex optimisation. To the best of our\nknowledge a full proof of the theorem has yet to be published in a single piece\nof literature. We also explore \"proof engineering\" issues, such as how to state\nNesterov's theorem in a manner that is both clear and useful.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:37:29 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Kwan", "Carl", "", "University of British Columbia"], ["Greenstreet", "Mark R.", "", "University of British Columbia"]]}, {"id": "1810.04363", "submitter": "Denis Ponomaryov", "authors": "Denis Ponomaryov and Stepan Yakovenko", "title": "DeFind: A Protege Plugin for Computing Concept Definitions in EL\n  Ontologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an extension to the Protege ontology editor, which allows for\ndiscovering concept definitions, which are not explicitly present in axioms,\nbut are logically implied by an ontology. The plugin supports ontologies\nformulated in the Description Logic EL, which underpins the OWL 2 EL profile of\nthe Web Ontology Language and despite its limited expressiveness captures most\nof the biomedical ontologies published on the Web. The developed tool allows to\nverify whether a concept can be defined using a vocabulary of interest\nspecified by a user. In particular, it allows to decide whether some vocabulary\nitems can be omitted in a formulation of a complex concept. The corresponding\ndefinitions are presented to the user and are provided with explanations\ngenerated by an ontology reasoner.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 04:14:59 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Ponomaryov", "Denis", ""], ["Yakovenko", "Stepan", ""]]}, {"id": "1810.04444", "submitter": "Zheng Tian Mr", "authors": "Zheng Tian, Shihao Zou, Ian Davies, Tim Warr, Lisheng Wu, Haitham Bou\n  Ammar, Jun Wang", "title": "Learning to Communicate Implicitly By Actions", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In situations where explicit communication is limited, human collaborators\nact by learning to: (i) infer meaning behind their partner's actions, and (ii)\nconvey private information about the state to their partner implicitly through\nactions. The first component of this learning process has been well-studied in\nmulti-agent systems, whereas the second --- which is equally crucial for\nsuccessful collaboration --- has not. To mimic both components mentioned above,\nthereby completing the learning process, we introduce a novel algorithm: Policy\nBelief Learning (PBL). PBL uses a belief module to model the other agent's\nprivate information and a policy module to form a distribution over actions\ninformed by the belief module. Furthermore, to encourage communication by\nactions, we propose a novel auxiliary reward which incentivizes one agent to\nhelp its partner to make correct inferences about its private information. The\nauxiliary reward for communication is integrated into the learning of the\npolicy module. We evaluate our approach on a set of environments including a\nmatrix game, particle environment and the non-competitive bidding problem from\ncontract bridge. We show empirically that this auxiliary reward is effective\nand easy to generalize. These results demonstrate that our PBL algorithm can\nproduce strong pairs of agents in collaborative games where explicit\ncommunication is disabled.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 10:16:55 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 14:05:21 GMT"}, {"version": "v3", "created": "Sun, 17 Nov 2019 18:43:20 GMT"}, {"version": "v4", "created": "Wed, 20 Nov 2019 20:05:08 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Tian", "Zheng", ""], ["Zou", "Shihao", ""], ["Davies", "Ian", ""], ["Warr", "Tim", ""], ["Wu", "Lisheng", ""], ["Ammar", "Haitham Bou", ""], ["Wang", "Jun", ""]]}, {"id": "1810.04465", "submitter": "Congqing He", "authors": "Congqing He, Li Peng, Yuquan Le, Jiawei He and Xiangyu Zhu", "title": "SECaps: A Sequence Enhanced Capsule Model for Charge Prediction", "comments": "13 pages, 3figures, 5 tables", "journal-ref": "Artificial Neural Networks and Machine Learning - ICANN 2019: Text\n  and Time Series. ICANN 2019. Lecture Notes in Computer Science, vol 11730.\n  Springer, Cham", "doi": "10.1007/978-3-030-30490-4_19", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic charge prediction aims to predict appropriate final charges\naccording to the fact descriptions for a given criminal case. Automatic charge\nprediction plays a critical role in assisting judges and lawyers to improve the\nefficiency of legal decisions, and thus has received much attention.\nNevertheless, most existing works on automatic charge prediction perform\nadequately on high-frequency charges but are not yet capable of predicting\nfew-shot charges with limited cases. In this paper, we propose a Sequence\nEnhanced Capsule model, dubbed as SECaps model, to relieve this problem.\nSpecifically, following the work of capsule networks, we propose the seq-caps\nlayer, which considers sequence information and spatial information of legal\ntexts simultaneously. Then we design a attention residual unit, which provides\nauxiliary information for charge prediction. In addition, our SECaps model\nintroduces focal loss, which relieves the problem of imbalanced charges.\nComparing the state-of-the-art methods, our SECaps model obtains 4.5% and 6.4%\nabsolutely considerable improvements under Macro F1 in Criminal-S and\nCriminal-L respectively. The experimental results consistently demonstrate the\nsuperiorities and competitiveness of our proposed model.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 11:42:59 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 09:16:54 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["He", "Congqing", ""], ["Peng", "Li", ""], ["Le", "Yuquan", ""], ["He", "Jiawei", ""], ["Zhu", "Xiangyu", ""]]}, {"id": "1810.04472", "submitter": "Jiawei Wang", "authors": "Jiawei Wang, Zhaoshui He, Chengjian Feng, Zhouping Zhu, Qinzhuang Lin,\n  Jun Lv, Shengli Xie", "title": "Domain Confusion with Self Ensembling for Unsupervised Adaptation", "comments": "The expression is ambiguous, which is not convenient for readers to\n  understand, and in today's view, the conclusion of the paper is of little\n  significance, so it is no longer open", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data collection and annotation are time-consuming in machine learning,\nexpecially for large scale problem. A common approach for this problem is to\ntransfer knowledge from a related labeled domain to a target one. There are two\npopular ways to achieve this goal: adversarial learning and self training. In\nthis article, we first analyze the training unstablity problem and the mistaken\nconfusion issue in adversarial learning process. Then, inspired by domain\nconfusion and self-ensembling methods, we propose a combined model to learn\nfeature and class jointly invariant representation, namely Domain Confusion\nwith Self Ensembling (DCSE). The experiments verified that our proposed\napproach can offer better performance than empirical art in a variety of\nunsupervised domain adaptation benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 12:09:36 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 11:53:19 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 08:48:09 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Wang", "Jiawei", ""], ["He", "Zhaoshui", ""], ["Feng", "Chengjian", ""], ["Zhu", "Zhouping", ""], ["Lin", "Qinzhuang", ""], ["Lv", "Jun", ""], ["Xie", "Shengli", ""]]}, {"id": "1810.04528", "submitter": "Vinicius Woloszyn", "authors": "Brenda Salenave Santana, Vinicius Woloszyn, Leandro Krug Wives", "title": "Is there Gender bias and stereotype in Portuguese Word Embeddings?", "comments": null, "journal-ref": "The 13th edition of the International Conference on the\n  Computational Processing of Portuguese (PROPOR 2018)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose an analysis of the presence of gender bias\nassociated with professions in Portuguese word embeddings. The objective of\nthis work is to study gender implications related to stereotyped professions\nfor women and men in the context of the Portuguese language.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 13:42:16 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Santana", "Brenda Salenave", ""], ["Woloszyn", "Vinicius", ""], ["Wives", "Leandro Krug", ""]]}, {"id": "1810.04535", "submitter": "Rafik Hadfi Dr", "authors": "Rafik Hadfi", "title": "Investigating Enactive Learning for Autonomous Intelligent Agents", "comments": "6 pages, 5 figures, 1 table, accepted as conference paper but\n  withdrawn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The enactive approach to cognition is typically proposed as a viable\nalternative to traditional cognitive science. Enactive cognition displaces the\nexplanatory focus from the internal representations of the agent to the direct\nsensorimotor interaction with its environment. In this paper, we investigate\nenactive learning through means of artificial agent simulations. We compare the\nperformances of the enactive agent to an agent operating on classical\nreinforcement learning in foraging tasks within maze environments. The\ncharacteristics of the agents are analysed in terms of the accessibility of the\nenvironmental states, goals, and exploration/exploitation tradeoffs. We confirm\nthat the enactive agent can successfully interact with its environment and\nlearn to avoid unfavourable interactions using intrinsically defined goals. The\nperformance of the enactive agent is shown to be limited by the number of\naffordable actions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 03:43:04 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Hadfi", "Rafik", ""]]}, {"id": "1810.04538", "submitter": "Lei Ma", "authors": "Lei Ma, Felix Juefei-Xu, Minhui Xue, Qiang Hu, Sen Chen, Bo Li, Yang\n  Liu, Jianjun Zhao, Jianxiong Yin, and Simon See", "title": "Secure Deep Learning Engineering: A Software Quality Assurance\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decades, deep learning (DL) systems have achieved tremendous\nsuccess and gained great popularity in various applications, such as\nintelligent machines, image processing, speech processing, and medical\ndiagnostics. Deep neural networks are the key driving force behind its recent\nsuccess, but still seem to be a magic black box lacking interpretability and\nunderstanding. This brings up many open safety and security issues with\nenormous and urgent demands on rigorous methodologies and engineering practice\nfor quality enhancement. A plethora of studies have shown that the\nstate-of-the-art DL systems suffer from defects and vulnerabilities that can\nlead to severe loss and tragedies, especially when applied to real-world\nsafety-critical applications. In this paper, we perform a large-scale study and\nconstruct a paper repository of 223 relevant works to the quality assurance,\nsecurity, and interpretation of deep learning. We, from a software quality\nassurance perspective, pinpoint challenges and future opportunities towards\nuniversal secure deep learning engineering. We hope this work and the\naccompanied paper repository can pave the path for the software engineering\ncommunity towards addressing the pressing industrial demand of secure\nintelligent applications.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 14:04:08 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Ma", "Lei", ""], ["Juefei-Xu", "Felix", ""], ["Xue", "Minhui", ""], ["Hu", "Qiang", ""], ["Chen", "Sen", ""], ["Li", "Bo", ""], ["Liu", "Yang", ""], ["Zhao", "Jianjun", ""], ["Yin", "Jianxiong", ""], ["See", "Simon", ""]]}, {"id": "1810.04554", "submitter": "J. G. Wolff", "authors": "J Gerard Wolff", "title": "Interpreting Winograd Schemas Via the SP Theory of Intelligence and Its\n  Realisation in the SP Computer Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 'Winograd Schema' (WS) sentences like \"The city councilmen refused the\ndemonstrators a permit because they feared violence\" and \"The city councilmen\nrefused the demonstrators a permit because they advocated revolution\", it is\neasy for adults to understand what \"they\" refers to but can be difficult for AI\nsystems. This paper describes how the SP System -- outlined in an appendix --\nmay solve this kind of problem of interpretation. The central idea is that a\nknowledge of discontinuous associations amongst linguistic features, and an\nability to recognise such patterns of associations, provides a robust means of\ndetermining what a pronoun like \"they\" refers to. For any AI system to solve\nthis kind of problem, it needs appropriate knowledge of relevant syntax and\nsemantics which, ideally, it should learn for itself. Although the SP System\nhas some strengths in unsupervised learning, its capabilities in this area are\nnot yet good enough to learn the kind of knowledge needed to interpret WS\nexamples, so it must be supplied with such knowledge at the outset. However,\nits existing strengths in unsupervised learning suggest that it has potential\nto learn the kind of knowledge needed for the interpretation of WS examples. In\nparticular, it has potential to learn the kind of discontinuous association of\nlinguistic features mentioned earlier.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 08:30:44 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Wolff", "J Gerard", ""]]}, {"id": "1810.04700", "submitter": "Sebastian Gehrmann", "authors": "Sebastian Gehrmann, Falcon Z. Dai, Henry Elder, Alexander M. Rush", "title": "End-to-End Content and Plan Selection for Data-to-Text Generation", "comments": "INLG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to generate fluent natural language from structured data with neural\nnetworks has become an common approach for NLG. This problem can be challenging\nwhen the form of the structured data varies between examples. This paper\npresents a survey of several extensions to sequence-to-sequence models to\naccount for the latent content selection process, particularly variants of copy\nattention and coverage decoding. We further propose a training method based on\ndiverse ensembling to encourage models to learn distinct sentence templates\nduring training. An empirical evaluation of these techniques shows an increase\nin the quality of generated text across five automated metrics, as well as\nhuman evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 18:36:04 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Gehrmann", "Sebastian", ""], ["Dai", "Falcon Z.", ""], ["Elder", "Henry", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1810.04760", "submitter": "Yaliang Li", "authors": "Yaliang Li, Houping Xiao, Zhan Qin, Chenglin Miao, Lu Su, Jing Gao,\n  Kui Ren, Bolin Ding", "title": "Towards Differentially Private Truth Discovery for Crowd Sensing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, crowd sensing becomes increasingly more popular due to the\nubiquitous usage of mobile devices. However, the quality of such\nhuman-generated sensory data varies significantly among different users. To\nbetter utilize sensory data, the problem of truth discovery, whose goal is to\nestimate user quality and infer reliable aggregated results through\nquality-aware data aggregation, has emerged as a hot topic. Although the\nexisting truth discovery approaches can provide reliable aggregated results,\nthey fail to protect the private information of individual users. Moreover,\ncrowd sensing systems typically involve a large number of participants, making\nencryption or secure multi-party computation based solutions difficult to\ndeploy. To address these challenges, in this paper, we propose an efficient\nprivacy-preserving truth discovery mechanism with theoretical guarantees of\nboth utility and privacy. The key idea of the proposed mechanism is to perturb\ndata from each user independently and then conduct weighted aggregation among\nusers' perturbed data. The proposed approach is able to assign user weights\nbased on information quality, and thus the aggregated results will not deviate\nmuch from the true results even when large noise is added. We adapt local\ndifferential privacy definition to this privacy-preserving task and demonstrate\nthe proposed mechanism can satisfy local differential privacy while preserving\nhigh aggregation accuracy. We formally quantify utility and privacy trade-off\nand further verify the claim by experiments on both synthetic data and a\nreal-world crowd sensing system.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 22:02:11 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Li", "Yaliang", ""], ["Xiao", "Houping", ""], ["Qin", "Zhan", ""], ["Miao", "Chenglin", ""], ["Su", "Lu", ""], ["Gao", "Jing", ""], ["Ren", "Kui", ""], ["Ding", "Bolin", ""]]}, {"id": "1810.04773", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "The IFF Foundation for Ontological Knowledge Organization", "comments": "19 pages, 7 figures", "journal-ref": "In Nancy J. Williamson and Clare Beghtol, eds., Knowledge\n  Organization and Classification in International Information Retrieval, Vol.\n  37 of Cataloging & Classification Quarterly, issue 1-2, pgs. 187-203, 2003.\n  Invited chapter", "doi": null, "report-no": null, "categories": "cs.DL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses an axiomatic approach for the integration of ontologies,\nan approach that extends to first order logic a previous approach (Kent 2000)\nbased on information flow. This axiomatic approach is represented in the\nInformation Flow Framework (IFF), a metalevel framework for organizing the\ninformation that appears in digital libraries, distributed databases and\nontologies (Kent 2001). The paper argues that the integration of ontologies is\nthe two-step process of alignment and unification. Ontological alignment\nconsists of the sharing of common terminology and semantics through a mediating\nontology. Ontological unification, concentrated in a virtual ontology of\ncommunity connections, is fusion of the alignment diagram of participant\ncommunity ontologies - the quotient of the sum of the participant portals\nmodulo the ontological alignment structure.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 23:12:01 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1810.04789", "submitter": "Michael Slawinski", "authors": "Michael A. Slawinski, Andy Wortman", "title": "Applications of Graph Integration to Function Comparison and Malware\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We classify .NET files as either benign or malicious by examining directed\ngraphs derived from the set of functions comprising the given file. Each graph\nis viewed probabilistically as a Markov chain where each node represents a code\nblock of the corresponding function, and by computing the PageRank vector\n(Perron vector with transport), a probability measure can be defined over the\nnodes of the given graph. Each graph is vectorized by computing Lebesgue\nantiderivatives of hand-engineered functions defined on the vertex set of the\ngiven graph against the PageRank measure. Files are subsequently vectorized by\naggregating the set of vectors corresponding to the set of graphs resulting\nfrom decompiling the given file. The result is a fast, intuitive, and\neasy-to-compute glass-box vectorization scheme, which can be leveraged for\ntraining a standalone classifier or to augment an existing feature space. We\nrefer to this vectorization technique as PageRank Measure Integration\nVectorization (PMIV). We demonstrate the efficacy of PMIV by training a vanilla\nrandom forest on 2.5 million samples of decompiled .NET, evenly split between\nbenign and malicious, from our in-house corpus and compare this model to a\nbaseline model which leverages a text-only feature space. The median time\nneeded for decompilation and scoring was 24ms.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 00:14:46 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 17:33:27 GMT"}, {"version": "v3", "created": "Sun, 28 Oct 2018 00:24:16 GMT"}, {"version": "v4", "created": "Wed, 10 Jul 2019 01:22:29 GMT"}, {"version": "v5", "created": "Mon, 19 Aug 2019 23:02:26 GMT"}, {"version": "v6", "created": "Wed, 13 Nov 2019 22:38:05 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Slawinski", "Michael A.", ""], ["Wortman", "Andy", ""]]}, {"id": "1810.04793", "submitter": "Kamran Kowsari", "authors": "Jinghe Zhang, Kamran Kowsari, James H. Harrison, Jennifer M. Lobo,\n  Laura E. Barnes", "title": "Patient2Vec: A Personalized Interpretable Deep Representation of the\n  Longitudinal Electronic Health Record", "comments": "Accepted by IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2018.2875677", "report-no": null, "categories": "q-bio.QM cs.AI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide implementation of electronic health record (EHR) systems facilitates\nthe collection of large-scale health data from real clinical settings. Despite\nthe significant increase in adoption of EHR systems, this data remains largely\nunexplored, but presents a rich data source for knowledge discovery from\npatient health histories in tasks such as understanding disease correlations\nand predicting health outcomes. However, the heterogeneity, sparsity, noise,\nand bias in this data present many complex challenges. This complexity makes it\ndifficult to translate potentially relevant information into machine learning\nalgorithms. In this paper, we propose a computational framework, Patient2Vec,\nto learn an interpretable deep representation of longitudinal EHR data which is\npersonalized for each patient. To evaluate this approach, we apply it to the\nprediction of future hospitalizations using real EHR data and compare its\npredictive performance with baseline methods. Patient2Vec produces a vector\nspace with meaningful structure and it achieves an AUC around 0.799\noutperforming baseline methods. In the end, the learned feature importance can\nbe visualized and interpreted at both the individual and population levels to\nbring clinical insights.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 16:41:05 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 15:13:16 GMT"}, {"version": "v3", "created": "Thu, 25 Oct 2018 13:38:34 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Zhang", "Jinghe", ""], ["Kowsari", "Kamran", ""], ["Harrison", "James H.", ""], ["Lobo", "Jennifer M.", ""], ["Barnes", "Laura E.", ""]]}, {"id": "1810.04859", "submitter": "Ekraam Sabir", "authors": "Dhruva Kartik, Ekraam Sabir, Urbashi Mitra and Prem Natarajan", "title": "Policy Design for Active Sequential Hypothesis Testing using Deep\n  Learning", "comments": "Accepted at 56th Annual Allerton Conference on Communication,\n  Control, and Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG cs.SY math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information theory has been very successful in obtaining performance limits\nfor various problems such as communication, compression and hypothesis testing.\nLikewise, stochastic control theory provides a characterization of optimal\npolicies for Partially Observable Markov Decision Processes (POMDPs) using\ndynamic programming. However, finding optimal policies for these problems is\ncomputationally hard in general and thus, heuristic solutions are employed in\npractice. Deep learning can be used as a tool for designing better heuristics\nin such problems. In this paper, the problem of active sequential hypothesis\ntesting is considered. The goal is to design a policy that can reliably infer\nthe true hypothesis using as few samples as possible by adaptively selecting\nappropriate queries. This problem can be modeled as a POMDP and bounds on its\nvalue function exist in literature. However, optimal policies have not been\nidentified and various heuristics are used. In this paper, two new heuristics\nare proposed: one based on deep reinforcement learning and another based on a\nKL-divergence zero-sum game. These heuristics are compared with\nstate-of-the-art solutions and it is demonstrated using numerical experiments\nthat the proposed heuristics can achieve significantly better performance than\nexisting methods in some scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 06:15:05 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Kartik", "Dhruva", ""], ["Sabir", "Ekraam", ""], ["Mitra", "Urbashi", ""], ["Natarajan", "Prem", ""]]}, {"id": "1810.04871", "submitter": "Homanga Bharadhwaj", "authors": "Homanga Bharadhwaj, Zihan Wang, Yoshua Bengio, Liam Paull", "title": "A Data-Efficient Framework for Training and Sim-to-Real Transfer of\n  Navigation Policies", "comments": "Under review in ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning effective visuomotor policies for robots purely from data is\nchallenging, but also appealing since a learning-based system should not\nrequire manual tuning or calibration. In the case of a robot operating in a\nreal environment the training process can be costly, time-consuming, and even\ndangerous since failures are common at the start of training. For this reason,\nit is desirable to be able to leverage \\textit{simulation} and\n\\textit{off-policy} data to the extent possible to train the robot. In this\nwork, we introduce a robust framework that plans in simulation and transfers\nwell to the real environment. Our model incorporates a gradient-descent based\nplanning module, which, given the initial image and goal image, encodes the\nimages to a lower dimensional latent state and plans a trajectory to reach the\ngoal. The model, consisting of the encoder and planner modules, is trained\nthrough a meta-learning strategy in simulation first. We subsequently perform\nadversarial domain transfer on the encoder by using a bank of unlabelled but\nrandom images from the simulation and real environments to enable the encoder\nto map images from the real and simulated environments to a similarly\ndistributed latent representation. By fine tuning the entire model (encoder +\nplanner) with far fewer real world expert demonstrations, we show successful\nplanning performances in different navigation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 07:22:54 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Bharadhwaj", "Homanga", ""], ["Wang", "Zihan", ""], ["Bengio", "Yoshua", ""], ["Paull", "Liam", ""]]}, {"id": "1810.04877", "submitter": "Sao Mai Nguyen", "authors": "Nicolas Duminy, Sao Mai Nguyen (Lab-STICC, IMT Atlantique), Dominique\n  Duhaut", "title": "Learning a Set of Interrelated Tasks by Using Sequences of Motor\n  Policies for a Strategic Intrinsically Motivated Learner", "comments": null, "journal-ref": "2018 Second IEEE International Conference on Robotic Computing\n  (IRC), Jan 2018, Laguna Hills, France. IEEE, pp.288 - 291, 2018,", "doi": "10.1109/IRC.2018.00061", "report-no": null, "categories": "cs.HC cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an active learning architecture for robots, capable of organizing\nits learning process to achieve a field of complex tasks by learning sequences\nof motor policies, called Intrinsically Motivated Procedure Babbling (IM-PB).\nThe learner can generalize over its experience to continuously learn new tasks.\nIt chooses actively what and how to learn based by empirical measures of its\nown progress. In this paper, we are considering the learning of a set of\ninterrelated tasks outcomes hierarchically organized. We introduce a framework\ncalled 'procedures', which are sequences of policies defined by the combination\nof previously learned skills. Our algorithmic architecture uses the procedures\nto autonomously discover how to combine simple skills to achieve complex goals.\nIt actively chooses between 2 strategies of goal-directed exploration :\nexploration of the policy space or the procedural space. We show on a simulated\nenvironment that our new architecture is capable of tackling the learning of\ncomplex motor policies, to adapt the complexity of its policies to the task at\nhand. We also show that our 'procedures' framework helps the learner to tackle\ndifficult hierarchical tasks.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 07:54:16 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 20:16:56 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Duminy", "Nicolas", "", "Lab-STICC, IMT Atlantique"], ["Nguyen", "Sao Mai", "", "Lab-STICC, IMT Atlantique"], ["Duhaut", "Dominique", ""]]}, {"id": "1810.04879", "submitter": "Sao Mai Nguyen", "authors": "Maxime Devanne (LIFL), Sao Mai Nguyen (Lab-STICC, IMT Atlantique)", "title": "Generating Shared Latent Variables for Robots to Imitate Human Movements\n  and Understand their Physical Limitations", "comments": null, "journal-ref": "Computer Vision -- ECCV 2018 Workshops", "doi": "10.1007/978-3-030-11012-3_15", "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assistive robotics and particularly robot coaches may be very helpful for\nrehabilitation healthcare. In this context, we propose a method based on\nGaussian Process Latent Variable Model (GP-LVM) to transfer knowledge between a\nphysiotherapist, a robot coach and a patient. Our model is able to map visual\nhuman body features to robot data in order to facilitate the robot learning and\nimitation. In addition , we propose to extend the model to adapt robots'\nunderstanding to patient's physical limitations during the assessment of\nrehabilitation exercises. Experimental evaluation demonstrates promising\nresults for both robot imitation and model adaptation according to the\npatients' limitations.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 08:01:08 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 22:09:34 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Devanne", "Maxime", "", "LIFL"], ["Nguyen", "Sao Mai", "", "Lab-STICC, IMT Atlantique"]]}, {"id": "1810.04886", "submitter": "Federico Cerutti", "authors": "Pietro Baroni, Federico Cerutti, Massimiliano Giacomin, Giovanni Guida", "title": "AFRA: Argumentation framework with recursive attacks", "comments": null, "journal-ref": null, "doi": "10.1016/j.ijar.2010.05.004", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The issue of representing attacks to attacks in argumentation is receiving an\nincreasing attention as a useful conceptual modelling tool in several contexts.\nIn this paper we present AFRA, a formalism encompassing unlimited recursive\nattacks within argumentation frameworks. AFRA satisfies the basic requirements\nof definition simplicity and rigorous compatibility with Dung's theory of\nargumentation. This paper provides a complete development of the AFRA formalism\ncomplemented by illustrative examples and a detailed comparison with other\nrecursive attack formalizations.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 08:16:48 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Baroni", "Pietro", ""], ["Cerutti", "Federico", ""], ["Giacomin", "Massimiliano", ""], ["Guida", "Giovanni", ""]]}, {"id": "1810.04892", "submitter": "Federico Cerutti", "authors": "Pietro Baroni, Federico Cerutti, Paul E. Dunne, Massimiliano Giacomin", "title": "Automata for Infinite Argumentation Structures", "comments": null, "journal-ref": null, "doi": "10.1016/j.artint.2013.05.002", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of abstract argumentation frameworks (afs) has, in the main,\nfocused on finite structures, though there are many significant contexts where\nargumentation can be regarded as a process involving infinite objects. To\naddress this limitation, in this paper we propose a novel approach for\ndescribing infinite afs using tools from formal language theory. In particular,\nthe possibly infinite set of arguments is specified through the language\nrecognized by a deterministic finite automaton while a suitable formalism,\ncalled attack expression, is introduced to describe the relation of attack\nbetween arguments. The proposed approach is shown to satisfy some desirable\nproperties which can not be achieved through other \"naive\" uses of formal\nlanguages. In particular, the approach is shown to be expressive enough to\ncapture (besides any arbitrary finite structure) a large variety of infinite\nafs including two major examples from previous literature and two sample cases\nfrom the domains of multi-agent negotiation and ambient intelligence. On the\ncomputational side, we show that several decision and construction problems\nwhich are known to be polynomial time solvable in finite afs are decidable in\nthe context of the proposed formalism and we provide the relevant algorithms.\nMoreover we obtain additional results concerning the case of finitary afs.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 08:26:59 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Baroni", "Pietro", ""], ["Cerutti", "Federico", ""], ["Dunne", "Paul E.", ""], ["Giacomin", "Massimiliano", ""]]}, {"id": "1810.04903", "submitter": "Fatma BenSaid", "authors": "Fatma BenSaid and Adel M. Alimi", "title": "MOANOFS: Multi-Objective Automated Negotiation based Online Feature\n  Selection System for Big Data Classification", "comments": "15 pages, 8 figures, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature Selection (FS) plays an important role in learning and classification\ntasks. The object of FS is to select the relevant and non-redundant features.\nConsidering the huge amount number of features in real-world applications, FS\nmethods using batch learning technique can't resolve big data problem\nespecially when data arrive sequentially. In this paper, we propose an online\nfeature selection system which resolves this problem. More specifically, we\ntreat the problem of online supervised feature selection for binary\nclassification as a decision-making problem. A philosophical vision to this\nproblem leads to a hybridization between two important domains: feature\nselection using online learning technique (OFS) and automated negotiation (AN).\nThe proposed OFS system called MOANOFS (Multi-Objective Automated Negotiation\nbased Online Feature Selection) uses two levels of decision. In the first\nlevel, from n learners (or OFS methods), we decide which are the k trustful\nones (with high confidence or trust value). These elected k learners will\nparticipate in the second level. In this level, we integrate our proposed\nMultilateral Automated Negotiation based OFS (MANOFS) method to decide finally\nwhich is the best solution or which are relevant features. We show that MOANOFS\nsystem is applicable to different domains successfully and achieves high\naccuracy with several real-world applications.\n  Index Terms: Feature selection, online learning, multi-objective automated\nnegotiation, trust, classification, big data.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 08:41:30 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 15:19:17 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["BenSaid", "Fatma", ""], ["Alimi", "Adel M.", ""]]}, {"id": "1810.04943", "submitter": "Daniel Sonntag", "authors": "Daniel Sonntag", "title": "Interactive Cognitive Assessment Tools: A Case Study on Digital Pens for\n  the Clinical Assessment of Dementia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Interactive cognitive assessment tools may be valuable for doctors and\ntherapists to reduce costs and improve quality in healthcare systems. Use cases\nand scenarios include the assessment of dementia. In this paper, we present our\napproach to the semi-automatic assessment of dementia. We describe a case study\nwith digital pens for the patients including background, problem description\nand possible solutions. We conclude with lessons learned when implementing\ndigital tests, and a generalisation for use outside the cognitive impairments\nfield.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 10:32:54 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Sonntag", "Daniel", ""]]}, {"id": "1810.04989", "submitter": "Letizia Marchegiani", "authors": "Letizia Marchegiani and Paul Newman", "title": "Listening for Sirens: Locating and Classifying Acoustic Alarms in City\n  Scenes", "comments": "6 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is about alerting acoustic event detection and sound source\nlocalisation in an urban scenario. Specifically, we are interested in spotting\nthe presence of horns, and sirens of emergency vehicles. In order to obtain a\nreliable system able to operate robustly despite the presence of traffic noise,\nwhich can be copious, unstructured and unpredictable, we propose to treat the\nspectrograms of incoming stereo signals as images, and apply semantic\nsegmentation, based on a Unet architecture, to extract the target sound from\nthe background noise. In a multi-task learning scheme, together with signal\ndenoising, we perform acoustic event classification to identify the nature of\nthe alerting sound. Lastly, we use the denoised signals to localise the\nacoustic source on the horizon plane, by regressing the direction of arrival of\nthe sound through a CNN architecture. Our experimental evaluation shows an\naverage classification rate of 94%, and a median absolute error on the\nlocalisation of 7.5{\\deg} when operating on audio frames of 0.5s, and of\n2.5{\\deg} when operating on frames of 2.5s. The system offers excellent\nperformance in particularly challenging scenarios, where the noise level is\nremarkably high.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 12:56:56 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Marchegiani", "Letizia", ""], ["Newman", "Paul", ""]]}, {"id": "1810.05017", "submitter": "Tom Paine", "authors": "Tom Le Paine, Sergio G\\'omez Colmenarejo, Ziyu Wang, Scott Reed, Yusuf\n  Aytar, Tobias Pfaff, Matt W. Hoffman, Gabriel Barth-Maron, Serkan Cabi, David\n  Budden, Nando de Freitas", "title": "One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are experts at high-fidelity imitation -- closely mimicking a\ndemonstration, often in one attempt. Humans use this ability to quickly solve a\ntask instance, and to bootstrap learning of new tasks. Achieving these\nabilities in autonomous agents is an open problem. In this paper, we introduce\nan off-policy RL algorithm (MetaMimic) to narrow this gap. MetaMimic can learn\nboth (i) policies for high-fidelity one-shot imitation of diverse novel skills,\nand (ii) policies that enable the agent to solve tasks more efficiently than\nthe demonstrators. MetaMimic relies on the principle of storing all experiences\nin a memory and replaying these to learn massive deep neural network policies\nby off-policy RL. This paper introduces, to the best of our knowledge, the\nlargest existing neural networks for deep RL and shows that larger networks\nwith normalization are needed to achieve one-shot high-fidelity imitation on a\nchallenging manipulation task. The results also show that both types of policy\ncan be learned from vision, in spite of the task rewards being sparse, and\nwithout access to demonstrator actions.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 13:46:18 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Paine", "Tom Le", ""], ["Colmenarejo", "Sergio G\u00f3mez", ""], ["Wang", "Ziyu", ""], ["Reed", "Scott", ""], ["Aytar", "Yusuf", ""], ["Pfaff", "Tobias", ""], ["Hoffman", "Matt W.", ""], ["Barth-Maron", "Gabriel", ""], ["Cabi", "Serkan", ""], ["Budden", "David", ""], ["de Freitas", "Nando", ""]]}, {"id": "1810.05025", "submitter": "Zeng-Bing Chen", "authors": "Zeng-Bing Chen", "title": "Quantum Neural Network and Soft Quantum Computing", "comments": "5 pages, 1 figure; comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new paradigm of quantum computing, namely, soft quantum computing, is\nproposed for nonclassical computation using real world quantum systems with\nnaturally occurring environment-induced decoherence and dissipation. As a\nspecific example of soft quantum computing, we suggest a quantum neural\nnetwork, where the neurons connect pairwise via the \"controlled Kraus\noperations\", hoping to pave an easier and more realistic way to quantum\nartificial intelligence and even to better understanding certain functioning of\nthe human brain. Our quantum neuron model mimics as much as possible the\nrealistic neurons and meanwhile, uses quantum laws for processing information.\nThe quantum features of the noisy neural network are uncovered by the presence\nof quantum discord and by non-commutability of quantum operations. We believe\nthat our model puts quantum computing into a wider context and inspires the\nhope to build a soft quantum computer much earlier than the standard one.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 16:51:39 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Chen", "Zeng-Bing", ""]]}, {"id": "1810.05041", "submitter": "Jack Fitzsimons", "authors": "Jack Fitzsimons, AbdulRahman Al Ali, Michael Osborne and Stephen\n  Roberts", "title": "A General Framework for Fair Regression", "comments": "8 pages, 4 figures, 2 pages references", "journal-ref": null, "doi": "10.3390/e21080741", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness, through its many forms and definitions, has become an important\nissue facing the machine learning community. In this work, we consider how to\nincorporate group fairness constraints in kernel regression methods, applicable\nto Gaussian processes, support vector machines, neural network regression and\ndecision tree regression. Further, we focus on examining the effect of\nincorporating these constraints in decision tree regression, with direct\napplications to random forests and boosted trees amongst other widespread\npopular inference techniques. We show that the order of complexity of memory\nand computation is preserved for such models and tightly bound the expected\nperturbations to the model in terms of the number of leaves of the trees.\nImportantly, the approach works on trained models and hence can be easily\napplied to models in current use and group labels are only required on training\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 16:16:03 GMT"}, {"version": "v2", "created": "Sat, 2 Feb 2019 08:09:20 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Fitzsimons", "Jack", ""], ["Ali", "AbdulRahman Al", ""], ["Osborne", "Michael", ""], ["Roberts", "Stephen", ""]]}, {"id": "1810.05057", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Nicolas Le Hir, Olivier Sigaud, Alban Laflaqui\\`ere", "title": "Identification of Invariant Sensorimotor Structures as a Prerequisite\n  for the Discovery of Objects", "comments": "24 pages, 10 figures, published in Frontiers Robotics and AI", "journal-ref": "Front. Robot. AI, 25 June 2018", "doi": "10.3389/frobt.2018.00070", "report-no": null, "categories": "cs.AI cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perceiving the surrounding environment in terms of objects is useful for any\ngeneral purpose intelligent agent. In this paper, we investigate a fundamental\nmechanism making object perception possible, namely the identification of\nspatio-temporally invariant structures in the sensorimotor experience of an\nagent. We take inspiration from the Sensorimotor Contingencies Theory to define\na computational model of this mechanism through a sensorimotor, unsupervised\nand predictive approach. Our model is based on processing the unsupervised\ninteraction of an artificial agent with its environment. We show how\nspatio-temporally invariant structures in the environment induce regularities\nin the sensorimotor experience of an agent, and how this agent, while building\na predictive model of its sensorimotor experience, can capture them as densely\nconnected subgraphs in a graph of sensory states connected by motor commands.\nOur approach is focused on elementary mechanisms, and is illustrated with a set\nof simple experiments in which an agent interacts with an environment. We show\nhow the agent can build an internal model of moving but spatio-temporally\ninvariant structures by performing a Spectral Clustering of the graph modeling\nits overall sensorimotor experiences. We systematically examine properties of\nthe model, shedding light more globally on the specificities of the paradigm\nwith respect to methods based on the supervised processing of collections of\nstatic images.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 14:47:38 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Hir", "Nicolas Le", ""], ["Sigaud", "Olivier", ""], ["Laflaqui\u00e8re", "Alban", ""]]}, {"id": "1810.05102", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Subburam Rajaram and Hinrich Sch\\\"utze and Bernt\n  Andrassy and Thomas Runkler", "title": "Neural Relation Extraction Within and Across Sentence Boundaries", "comments": "AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Past work in relation extraction mostly focuses on binary relation between\nentity pairs within single sentence. Recently, the NLP community has gained\ninterest in relation extraction in entity pairs spanning multiple sentences. In\nthis paper, we propose a novel architecture for this task: inter-sentential\ndependency-based neural networks (iDepNN). iDepNN models the shortest and\naugmented dependency paths via recurrent and recursive neural networks to\nextract relationships within (intra-) and across (inter-) sentence boundaries.\nCompared to SVM and neural network baselines, iDepNN is more robust to false\npositives in relationships spanning sentences.\n  We evaluate our models on four datasets from newswire (MUC6) and medical\n(BioNLP shared task) domains that achieve state-of-the-art performance and show\na better balance in precision and recall for inter-sentential relationships. We\nperform better than 11 teams participating in the BioNLP shared task 2016 and\nachieve a gain of 5.2% (0.587 vs 0.558) in F1 over the winning team. We also\nrelease the crosssentence annotations for MUC6.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 16:07:20 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 16:56:53 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Gupta", "Pankaj", ""], ["Rajaram", "Subburam", ""], ["Sch\u00fctze", "Hinrich", ""], ["Andrassy", "Bernt", ""], ["Runkler", "Thomas", ""]]}, {"id": "1810.05110", "submitter": "Resmiye Nasiboglu", "authors": "Resmiye Nasiboglu, Rahila Abdullayeva", "title": "Analytical Formulations for the Level Based Weighted Average Value of\n  Discrete Trapezoidal Fuzzy Numbers", "comments": "15 pages, 3 figures", "journal-ref": "International Journal on Soft Computing (IJSC) Vol.9, No.2/3,\n  August 2018, pp.1-15", "doi": "10.5121/ijsc.2018.9301", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In fuzzy decision-making processes based on linguistic information,\noperations on discrete fuzzy numbers are commonly performed. Aggregation and\ndefuzzification operations are some of these often used operations. Many\naggregation and defuzzification operators produce results independent to the\ndecision makers strategy. On the other hand, the Weighted Average Based on\nLevels (WABL) approach can take into account the level weights and the decision\nmakers optimism strategy. This gives flexibility to the WABL operator and,\nthrough machine learning, can be trained in the direction of the decision\nmakers strategy, producing more satisfactory results for the decision maker.\nHowever, in order to determine the WABL value, it is necessary to calculate\nsome integrals. In this study, the concept of WABL for discrete trapezoidal\nfuzzy numbers is investigated, and analytical formulas have been proven to\nfacilitate the calculation of WABL value for these fuzzy numbers. Trapezoidal\nand their special form, triangular fuzzy numbers, are the most commonly used\nfuzzy number types in fuzzy modeling, so in this study, such numbers have been\nstudied. Computational examples explaining the theoretical results have been\nperformed.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 13:54:50 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Nasiboglu", "Resmiye", ""], ["Abdullayeva", "Rahila", ""]]}, {"id": "1810.05148", "submitter": "Roman Novak", "authors": "Roman Novak, Lechao Xiao, Jaehoon Lee, Yasaman Bahri, Greg Yang, Jiri\n  Hron, Daniel A. Abolafia, Jeffrey Pennington, Jascha Sohl-Dickstein", "title": "Bayesian Deep Convolutional Networks with Many Channels are Gaussian\n  Processes", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a previously identified equivalence between wide fully connected\nneural networks (FCNs) and Gaussian processes (GPs). This equivalence enables,\nfor instance, test set predictions that would have resulted from a fully\nBayesian, infinitely wide trained FCN to be computed without ever instantiating\nthe FCN, but by instead evaluating the corresponding GP. In this work, we\nderive an analogous equivalence for multi-layer convolutional neural networks\n(CNNs) both with and without pooling layers, and achieve state of the art\nresults on CIFAR10 for GPs without trainable kernels. We also introduce a Monte\nCarlo method to estimate the GP corresponding to a given neural network\narchitecture, even in cases where the analytic form has too many terms to be\ncomputationally feasible.\n  Surprisingly, in the absence of pooling layers, the GPs corresponding to CNNs\nwith and without weight sharing are identical. As a consequence, translation\nequivariance, beneficial in finite channel CNNs trained with stochastic\ngradient descent (SGD), is guaranteed to play no role in the Bayesian treatment\nof the infinite channel limit - a qualitative difference between the two\nregimes that is not present in the FCN case. We confirm experimentally, that\nwhile in some scenarios the performance of SGD-trained finite CNNs approaches\nthat of the corresponding GPs as the channel count increases, with careful\ntuning SGD-trained CNNs can significantly outperform their corresponding GPs,\nsuggesting advantages from SGD training compared to fully Bayesian parameter\nestimation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 17:49:41 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2019 00:38:34 GMT"}, {"version": "v3", "created": "Sun, 24 Feb 2019 04:42:51 GMT"}, {"version": "v4", "created": "Fri, 21 Aug 2020 15:28:27 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Novak", "Roman", ""], ["Xiao", "Lechao", ""], ["Lee", "Jaehoon", ""], ["Bahri", "Yasaman", ""], ["Yang", "Greg", ""], ["Hron", "Jiri", ""], ["Abolafia", "Daniel A.", ""], ["Pennington", "Jeffrey", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1810.05157", "submitter": "Andreea Bobu", "authors": "Andreea Bobu, Andrea Bajcsy, Jaime F. Fisac, Anca D. Dragan", "title": "Learning under Misspecified Objective Spaces", "comments": "Conference on Robot Learning (CoRL) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning robot objective functions from human input has become increasingly\nimportant, but state-of-the-art techniques assume that the human's desired\nobjective lies within the robot's hypothesis space. When this is not true, even\nmethods that keep track of uncertainty over the objective fail because they\nreason about which hypothesis might be correct, and not whether any of the\nhypotheses are correct. We focus specifically on learning from physical human\ncorrections during the robot's task execution, where not having a rich enough\nhypothesis space leads to the robot updating its objective in ways that the\nperson did not actually intend. We observe that such corrections appear\nirrelevant to the robot, because they are not the best way of achieving any of\nthe candidate objectives. Instead of naively trusting and learning from every\nhuman interaction, we propose robots learn conservatively by reasoning in real\ntime about how relevant the human's correction is for the robot's hypothesis\nspace. We test our inference method in an experiment with human interaction\ndata, and demonstrate that this alleviates unintended learning in an in-person\nuser study with a 7DoF robot manipulator.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 17:58:27 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 00:47:32 GMT"}, {"version": "v3", "created": "Thu, 25 Oct 2018 07:09:31 GMT"}, {"version": "v4", "created": "Fri, 26 Oct 2018 05:21:19 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Bobu", "Andreea", ""], ["Bajcsy", "Andrea", ""], ["Fisac", "Jaime F.", ""], ["Dragan", "Anca D.", ""]]}, {"id": "1810.05237", "submitter": "Tao Yu", "authors": "Tao Yu, Michihiro Yasunaga, Kai Yang, Rui Zhang, Dongxu Wang, Zifan\n  Li, Dragomir Radev", "title": "SyntaxSQLNet: Syntax Tree Networks for Complex and\n  Cross-DomainText-to-SQL Task", "comments": "EMNLP 2018, Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing studies in text-to-SQL tasks do not require generating complex\nSQL queries with multiple clauses or sub-queries, and generalizing to new,\nunseen databases. In this paper we propose SyntaxSQLNet, a syntax tree network\nto address the complex and cross-domain text-to-SQL generation task.\nSyntaxSQLNet employs a SQL specific syntax tree-based decoder with SQL\ngeneration path history and table-aware column attention encoders. We evaluate\nSyntaxSQLNet on the Spider text-to-SQL task, which contains databases with\nmultiple tables and complex SQL queries with multiple SQL clauses and nested\nqueries. We use a database split setting where databases in the test set are\nunseen during training. Experimental results show that SyntaxSQLNet can handle\na significantly greater number of complex SQL examples than prior work,\noutperforming the previous state-of-the-art model by 7.3% in exact matching\naccuracy. We also show that SyntaxSQLNet can further improve the performance by\nan additional 7.5% using a cross-domain augmentation method, resulting in a\n14.8% improvement in total. To our knowledge, we are the first to study this\ncomplex and cross-domain text-to-SQL task.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 20:24:13 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 20:33:55 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Yu", "Tao", ""], ["Yasunaga", "Michihiro", ""], ["Yang", "Kai", ""], ["Zhang", "Rui", ""], ["Wang", "Dongxu", ""], ["Li", "Zifan", ""], ["Radev", "Dragomir", ""]]}, {"id": "1810.05291", "submitter": "Jeremy Bernstein", "authors": "Jeremy Bernstein, Jiawei Zhao, Kamyar Azizzadenesheli, Anima\n  Anandkumar", "title": "signSGD with Majority Vote is Communication Efficient And Fault Tolerant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural networks on large datasets can be accelerated by distributing\nthe workload over a network of machines. As datasets grow ever larger, networks\nof hundreds or thousands of machines become economically viable. The time cost\nof communicating gradients limits the effectiveness of using such large machine\ncounts, as may the increased chance of network faults. We explore a\nparticularly simple algorithm for robust, communication-efficient\nlearning---signSGD. Workers transmit only the sign of their gradient vector to\na server, and the overall update is decided by a majority vote. This algorithm\nuses $32\\times$ less communication per iteration than full-precision,\ndistributed SGD. Under natural conditions verified by experiment, we prove that\nsignSGD converges in the large and mini-batch settings, establishing\nconvergence for a parameter regime of Adam as a byproduct. Aggregating sign\ngradients by majority vote means that no individual worker has too much power.\nWe prove that unlike SGD, majority vote is robust when up to 50% of workers\nbehave adversarially. The class of adversaries we consider includes as special\ncases those that invert or randomise their gradient estimate. On the practical\nside, we built our distributed training system in Pytorch. Benchmarking against\nthe state of the art collective communications library (NCCL), our\nframework---with the parameter server housed entirely on one machine---led to a\n25% reduction in time for training resnet50 on Imagenet when using 15 AWS\np3.2xlarge machines.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 23:50:32 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 02:53:43 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 19:55:48 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Bernstein", "Jeremy", ""], ["Zhao", "Jiawei", ""], ["Azizzadenesheli", "Kamyar", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1810.05305", "submitter": "Hunter Lang", "authors": "Hunter Lang, David Sontag, Aravindan Vijayaraghavan", "title": "Block Stability for MAP Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand the empirical success of approximate MAP inference, recent work\n(Lang et al., 2018) has shown that some popular approximation algorithms\nperform very well when the input instance is stable. The simplest stability\ncondition assumes that the MAP solution does not change at all when some of the\npairwise potentials are (adversarially) perturbed. Unfortunately, this strong\ncondition does not seem to be satisfied in practice. In this paper, we\nintroduce a significantly more relaxed condition that only requires blocks\n(portions) of an input instance to be stable. Under this block stability\ncondition, we prove that the pairwise LP relaxation is persistent on the stable\nblocks. We complement our theoretical results with an empirical evaluation of\nreal-world MAP inference instances from computer vision. We design an algorithm\nto find stable blocks, and find that these real instances have large stable\nregions. Our work gives a theoretical explanation for the widespread empirical\nphenomenon of persistency for this LP relaxation.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 01:17:38 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 00:52:41 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Lang", "Hunter", ""], ["Sontag", "David", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1810.05315", "submitter": "Brian Groenke", "authors": "Brian Groenke", "title": "Learning to Reason", "comments": "13 pages, 3 figures Not an official publication. Project report only.\n  Available as reference to interested researchers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated theorem proving has long been a key task of artificial\nintelligence. Proofs form the bedrock of rigorous scientific inquiry. Many\ntools for both partially and fully automating their derivations have been\ndeveloped over the last half a century. Some examples of state-of-the-art\nprovers are E (Schulz, 2013), VAMPIRE (Kov\\'acs & Voronkov, 2013), and Prover9\n(McCune, 2005-2010). Newer theorem provers, such as E, use superposition\ncalculus in place of more traditional resolution and tableau based methods.\nThere have also been a number of past attempts to apply machine learning\nmethods to guiding proof search. Suttner & Ertel proposed a\nmultilayer-perceptron based method using hand-engineered features as far back\nas 1990; Urban et al (2011) apply machine learning to tableau calculus; and\nLoos et al (2017) recently proposed a method for guiding the E theorem prover\nusing deep nerual networks. All of this prior work, however, has one common\nlimitation: they all rely on the axioms of classical first-order logic. Very\nlittle attention has been paid to automated theorem proving for non-classical\nlogics. One of the only recent examples is McLaughlin & Pfenning (2008) who\napplied the polarized inverse method to intuitionistic propositional logic. The\nliterature is otherwise mostly silent. This is truly unfortunate, as there are\nmany reasons to desire non-classical proofs over classical.\nConstructive/intuitionistic proofs should be of particular interest to computer\nscientists thanks to the well-known Curry-Howard correspondence (Howard, 1980)\nwhich tells us that all terminating programs correspond to a proof in\nintuitionistic logic and vice versa. This work explores using Q-learning\n(Watkins, 1989) to inform proof search for a specific system called\nnon-classical logic called Core Logic (Tennant, 2017).\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 01:50:24 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Groenke", "Brian", ""]]}, {"id": "1810.05357", "submitter": "Ian Davidson", "authors": "Chia-Tung Kuo and Ian Davidson", "title": "On The Equivalence of Tries and Dendrograms - Efficient Hierarchical\n  Clustering of Traffic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use of GPS-enabled devices generates voluminous and continuous\namounts of traffic data but analyzing such data for interpretable and\nactionable insights poses challenges. A hierarchical clustering of the trips\nhas many uses such as discovering shortest paths, common routes and often\ntraversed areas. However, hierarchical clustering typically has time complexity\nof $O(n^2 \\log n)$ where $n$ is the number of instances, and is difficult to\nscale to large data sets associated with GPS data. Furthermore, incremental\nhierarchical clustering is still a developing area. Prefix trees (also called\ntries) can be efficiently constructed and updated in linear time (in $n$). We\nshow how a specially constructed trie can compactly store the trips and further\nshow this trie is equivalent to a dendrogram that would have been built by\nclassic agglomerative hierarchical algorithms using a specific distance metric.\nThis allows creating hierarchical clusterings of GPS trip data and updating\nthis hierarchy in linear time. %we can extract a meaningful kernel and can also\ninterpret the structure as clusterings of differing granularity as one\nprogresses down the tree. We demonstrate the usefulness of our proposed\napproach on a real world data set of half a million taxis' GPS traces, well\nbeyond the capabilities of agglomerative clustering methods. Our work is not\nlimited to trip data and can be used with other data with a string\nrepresentation.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 05:02:29 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Kuo", "Chia-Tung", ""], ["Davidson", "Ian", ""]]}, {"id": "1810.05444", "submitter": "Veronika Cheplygina", "authors": "Veronika Cheplygina", "title": "Cats or CAT scans: transfer learning from natural or medical image\n  source datasets?", "comments": "Accepted to Current Opinion in Biomedical Engineering", "journal-ref": null, "doi": "10.1016/j.cobme.2018.12.005", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is a widely used strategy in medical image analysis.\nInstead of only training a network with a limited amount of data from the\ntarget task of interest, we can first train the network with other, potentially\nlarger source datasets, creating a more robust model. The source datasets do\nnot have to be related to the target task. For a classification task in lung CT\nimages, we could use both head CT images, or images of cats, as the source.\nWhile head CT images appear more similar to lung CT images, the number and\ndiversity of cat images might lead to a better model overall. In this survey we\nreview a number of papers that have performed similar comparisons. Although the\nanswer to which strategy is best seems to be \"it depends\", we discuss a number\nof research directions we need to take as a community, to gain more\nunderstanding of this topic.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 10:35:21 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 08:45:08 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Cheplygina", "Veronika", ""]]}, {"id": "1810.05507", "submitter": "Zixing Zhang", "authors": "Zixing Zhang, Jing Han, Eduardo Coutinho, Bj\\\"orn Schuller", "title": "Dynamic Difficulty Awareness Training for Continuous Emotion Prediction", "comments": "accepted by IEEE T-MM", "journal-ref": null, "doi": "10.1109/TMM.2018.2871949", "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-continuous emotion prediction has become an increasingly compelling task\nin machine learning. Considerable efforts have been made to advance the\nperformance of these systems. Nonetheless, the main focus has been the\ndevelopment of more sophisticated models and the incorporation of different\nexpressive modalities (e. g., speech, face, and physiology). In this paper,\nmotivated by the benefit of difficulty awareness in a human learning procedure,\nwe propose a novel machine learning framework, namely, Dynamic Difficulty\nAwareness Training (DDAT), which sheds fresh light on the research -- directly\nexploiting the difficulties in learning to boost the machine learning process.\nThe DDAT framework consists of two stages: information retrieval and\ninformation exploitation. In the first stage, we make use of the reconstruction\nerror of input features or the annotation uncertainty to estimate the\ndifficulty of learning specific information. The obtained difficulty level is\nthen used in tandem with original features to update the model input in a\nsecond learning stage with the expectation that the model can learn to focus on\nhigh difficulty regions of the learning process. We perform extensive\nexperiments on a benchmark database (RECOLA) to evaluate the effectiveness of\nthe proposed framework. The experimental results show that our approach\noutperforms related baselines as well as other well-established time-continuous\nemotion prediction systems, which suggests that dynamically integrating the\ndifficulty information for neural networks can help enhance the learning\nprocess.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 07:30:52 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Zhang", "Zixing", ""], ["Han", "Jing", ""], ["Coutinho", "Eduardo", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1810.05514", "submitter": "Ruslan Krenzler", "authors": "Ruslan Krenzler and Lin Xie and Hanyi Li", "title": "Deterministic Pod Repositioning Problem in Robotic Mobile Fulfillment\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a robotic mobile fulfillment system, robots bring shelves, called pods,\nwith storage items from the storage area to pick stations. At every pick\nstation there is a person -- the picker -- who takes parts from the pod and\npacks them into boxes according to orders. Usually there are multiple shelves\nat the pick station. In this case, they build a queue with the picker at its\nhead. When the picker does not need the pod any more, a robot transports the\npod back to the storage area. At that time, we need to answer a question:\n\"Where is the optimal place in the inventory to put this pod back?\". It is a\ntough question, because there are many uncertainties to consider before\nanswering it. Moreover, each decision made to answer the question influences\nthe subsequent ones. The goal of this paper is to answer the question properly.\nWe call this problem the Pod Repositioning Problem and formulate a\ndeterministic model. This model is tested with different algorithms, including\nbinary integer programming, cheapest place, fixed place, random place, genetic\nalgorithms, and a novel algorithm called tetris.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 18:02:47 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Krenzler", "Ruslan", ""], ["Xie", "Lin", ""], ["Li", "Hanyi", ""]]}, {"id": "1810.05524", "submitter": "Sara Hosseinzadeh Kassani", "authors": "Sara Hosseinzadeh Kassani, Peyman Hosseinzadeh Kassani, Seyed Esmaeel\n  Najafi", "title": "Introducing a hybrid model of DEA and data mining in evaluating\n  efficiency. Case study: Bank Branches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The banking industry is very important for an economic cycle of each country\nand provides some quality of services for us. With the advancement in\ntechnology and rapidly increasing of the complexity of the business\nenvironment, it has become more competitive than the past so that efficiency\nanalysis in the banking industry attracts much attention in recent years. From\nmany aspects, such analyses at the branch level are more desirable. Evaluating\nthe branch performance with the purpose of eliminating deficiency can be a\ncrucial issue for branch managers to measure branch efficiency. This work not\nonly can lead to a better understanding of bank branch performance but also\ngive further information to enhance managerial decisions to recognize\nproblematic areas. To achieve this purpose, this study presents an integrated\napproach based on Data Envelopment Analysis (DEA), Clustering algorithms and\nPolynomial Pattern Classifier for constructing a classifier to identify a class\nof bank branches. First, the efficiency estimates of individual branches are\nevaluated by using the DEA approach. Next, when the range and number of classes\nwere identified by experts, the number of clusters is identified by an\nagglomerative hierarchical clustering algorithm based on some statistical\nmethods. Next, we divide our raw data into k clusters By means of\nself-organizing map (SOM) neural networks. Finally, all clusters are fed into\nthe reduced multivariate polynomial model to predict the classes of data.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 18:59:29 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Kassani", "Sara Hosseinzadeh", ""], ["Kassani", "Peyman Hosseinzadeh", ""], ["Najafi", "Seyed Esmaeel", ""]]}, {"id": "1810.05533", "submitter": "Navneet Kumar", "authors": "Navneet Madhu Kumar", "title": "Empowerment-driven Exploration using Mutual Information Estimation", "comments": "Preprint. Under Development. arXiv admin note: text overlap with\n  arXiv:1807.02078 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is a difficult challenge in reinforcement learning and is of\nprime importance in sparse reward environments. However, many of the state of\nthe art deep reinforcement learning algorithms, that rely on epsilon-greedy,\nfail on these environments. In such cases, empowerment can serve as an\nintrinsic reward signal to enable the agent to maximize the influence it has\nover the near future. We formulate empowerment as the channel capacity between\nstates and actions and is calculated by estimating the mutual information\nbetween the actions and the following states. The mutual information is\nestimated using Mutual Information Neural Estimator and a forward dynamics\nmodel. We demonstrate that an empowerment driven agent is able to improve\nsignificantly the score of a baseline DQN agent on the game of Montezuma's\nRevenge.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 06:34:18 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Kumar", "Navneet Madhu", ""]]}, {"id": "1810.05534", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "Conceptual Knowledge Markup Language: An Introduction", "comments": "26 pages, 8 tables, 4 diagrams", "journal-ref": "Netnomics: Economic research and electronic networking, 2(2), (pp.\n  139-169), 2000. Special Issue on Information and Communication Middleware", "doi": null, "report-no": null, "categories": "cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conceptual Knowledge Markup Language (CKML) is an application of XML. Earlier\nversions of CKML followed rather exclusively the philosophy of Conceptual\nKnowledge Processing (CKP), a principled approach to knowledge representation\nand data analysis that \"advocates methods and instruments of conceptual\nknowledge processing which support people in their rational thinking, judgment\nand acting and promote critical discussion.\" The new version of CKML continues\nto follow this approach, but also incorporates various principles, insights and\ntechniques from Information Flow (IF), the logical design of distributed\nsystems. Among other things, this allows diverse communities of discourse to\ncompare their own information structures, as coded in logical theories, with\nthat of other communities that share a common generic ontology. CKML\nincorporates the CKP ideas of concept lattice and formal context, along with\nthe IF ideas of classification (= formal context), infomorphism, theory,\ninterpretation and local logic. Ontology Markup Language (OML), a subset of\nCKML that is a self-sufficient markup language in its own right, follows the\nprinciples and ideas of Conceptual Graphs (CG). OML is used for structuring the\nspecifications and axiomatics of metadata into ontologies. OML incorporates the\nCG ideas of concept, conceptual relation, conceptual graph, conceptual context,\nparticipants and ontology. The link from OML to CKML is the process of\nconceptual scaling, which is the interpretive transformation of ontologically\nstructured knowledge to conceptual structured knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 23:41:42 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1810.05550", "submitter": "Gabriel Michau Dr.", "authors": "Gabriel Michau, Yang Hu, Thomas Palm\\'e and Olga Fink", "title": "Feature Learning for Fault Detection in High-Dimensional\n  Condition-Monitoring Signals", "comments": null, "journal-ref": "2019, Proceedings of the Institution of Mechanical Engineers, Part\n  O: Journal of Risk and Reliability", "doi": "10.1177/1748006X19868335", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex industrial systems are continuously monitored by a large number of\nheterogeneous sensors. The diversity of their operating conditions and the\npossible fault types make it impossible to collect enough data for learning all\nthe possible fault patterns. The paper proposes an integrated automatic\nunsupervised feature learning and one-class classification for fault detection\nthat uses data on healthy conditions only for its training. The approach is\nbased on stacked Extreme Learning Machines (namely Hierarchical, or HELM) and\ncomprises an autoencoder, performing unsupervised feature learning, stacked\nwith a one-class classifier monitoring the distance of the test data to the\ntraining healthy class, thereby assessing the health of the system.\n  This study provides a comprehensive evaluation of HELM fault detection\ncapability compared to other machine learning approaches, such as stand-alone\none-class classifiers (ELM and SVM), these same one-class classifiers combined\nwith traditional dimensionality reduction methods (PCA) and a Deep Belief\nNetwork. The performance is first evaluated on a synthetic dataset that\nencompasses typical characteristics of condition monitoring data. Subsequently,\nthe approach is evaluated on a real case study of a power plant fault. The\nproposed algorithm for fault detection, combining feature learning with the\none-class classifier, demonstrates a better performance, particularly in cases\nwhere condition monitoring data contain several non-informative signals.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 14:38:18 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 09:52:44 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Michau", "Gabriel", ""], ["Hu", "Yang", ""], ["Palm\u00e9", "Thomas", ""], ["Fink", "Olga", ""]]}, {"id": "1810.05564", "submitter": "Yosuke Fukuchi", "authors": "Yosuke Fukuchi, Masahiko Osawa, Hiroshi Yamakawa, Tatsuji Takahashi,\n  Michita Imai", "title": "Bayesian Inference of Self-intention Attributed by Observer", "comments": null, "journal-ref": "6th International Conference on Human-Agent Interaction (HAI '18),\n  2018", "doi": "10.1145/3284432.3284438", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of agents that learn policy for tasks with reinforcement learning (RL)\nlack the ability to communicate with people, which makes human-agent\ncollaboration challenging. We believe that, in order for RL agents to\ncomprehend utterances from human colleagues, RL agents must infer the mental\nstates that people attribute to them because people sometimes infer an\ninterlocutor's mental states and communicate on the basis of this mental\ninference. This paper proposes PublicSelf model, which is a model of a person\nwho infers how the person's own behavior appears to their colleagues. We\nimplemented the PublicSelf model for an RL agent in a simulated environment and\nexamined the inference of the model by comparing it with people's judgment. The\nresults showed that the agent's intention that people attributed to the agent's\nmovement was correctly inferred by the model in scenes where people could find\ncertain intentionality from the agent's behavior.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 15:04:14 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Fukuchi", "Yosuke", ""], ["Osawa", "Masahiko", ""], ["Yamakawa", "Hiroshi", ""], ["Takahashi", "Tatsuji", ""], ["Imai", "Michita", ""]]}, {"id": "1810.05587", "submitter": "Pablo Hernandez-Leal", "authors": "Pablo Hernandez-Leal, Bilal Kartal and Matthew E. Taylor", "title": "A Survey and Critique of Multiagent Deep Reinforcement Learning", "comments": "Under review since Oct 2018. Earlier versions of this work had the\n  title: \"Is multiagent deep reinforcement learning the answer or the question?\n  A brief survey\"", "journal-ref": null, "doi": "10.1007/s10458-019-09421-1", "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) has achieved outstanding results in recent\nyears. This has led to a dramatic increase in the number of applications and\nmethods. Recent works have explored learning beyond single-agent scenarios and\nhave considered multiagent learning (MAL) scenarios. Initial results report\nsuccesses in complex multiagent domains, although there are several challenges\nto be addressed. The primary goal of this article is to provide a clear\noverview of current multiagent deep reinforcement learning (MDRL) literature.\nAdditionally, we complement the overview with a broader analysis: (i) we\nrevisit previous key components, originally presented in MAL and RL, and\nhighlight how they have been adapted to multiagent deep reinforcement learning\nsettings. (ii) We provide general guidelines to new practitioners in the area:\ndescribing lessons learned from MDRL works, pointing to recent benchmarks, and\noutlining open avenues of research. (iii) We take a more critical tone raising\npractical challenges of MDRL (e.g., implementation and computational demands).\nWe expect this article will help unify and motivate future research to take\nadvantage of the abundant literature that exists (e.g., RL and MAL) in a joint\neffort to promote fruitful research in the multiagent community.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 15:54:05 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 00:54:10 GMT"}, {"version": "v3", "created": "Fri, 30 Aug 2019 19:33:23 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Hernandez-Leal", "Pablo", ""], ["Kartal", "Bilal", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1810.05593", "submitter": "Ivan Y. Tyukin", "authors": "Ivan Y. Tyukin, Alexander N. Gorban, Stephen Green, Danil Prokhorov", "title": "Fast Construction of Correcting Ensembles for Legacy Artificial\n  Intelligence Systems: Algorithms and a Case Study", "comments": null, "journal-ref": "Information Sciences, 2019", "doi": "10.1016/j.ins.2018.11.057", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a technology for simple and computationally efficient\nimprovements of a generic Artificial Intelligence (AI) system, including\nMultilayer and Deep Learning neural networks. The improvements are, in essence,\nsmall network ensembles constructed on top of the existing AI architectures.\nTheoretical foundations of the technology are based on Stochastic Separation\nTheorems and the ideas of the concentration of measure. We show that, subject\nto mild technical assumptions on statistical properties of internal signals in\nthe original AI system, the technology enables instantaneous and\ncomputationally efficient removal of spurious and systematic errors with\nprobability close to one on the datasets which are exponentially large in\ndimension. The method is illustrated with numerical examples and a case study\nof ten digits recognition from American Sign Language.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 16:14:29 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 08:59:55 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Tyukin", "Ivan Y.", ""], ["Gorban", "Alexander N.", ""], ["Green", "Stephen", ""], ["Prokhorov", "Danil", ""]]}, {"id": "1810.05640", "submitter": "Xinshang Wang", "authors": "Wang Chi Cheung and Will Ma and David Simchi-Levi and Xinshang Wang", "title": "Inventory Balancing with Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a general problem of allocating limited resources to heterogeneous\ncustomers over time under model uncertainty. Each type of customer can be\nserviced using different actions, each of which stochastically consumes some\ncombination of resources, and returns different rewards for the resources\nconsumed. We consider a general model where the resource consumption\ndistribution associated with each (customer type, action)-combination is not\nknown, but is consistent and can be learned over time. In addition, the\nsequence of customer types to arrive over time is arbitrary and completely\nunknown.\n  We overcome both the challenges of model uncertainty and customer\nheterogeneity by judiciously synthesizing two algorithmic frameworks from the\nliterature: inventory balancing, which \"reserves\" a portion of each resource\nfor high-reward customer types which could later arrive, and online learning,\nwhich shows how to \"explore\" the resource consumption distributions of each\ncustomer type under different actions. We define an auxiliary problem, which\nallows for existing competitive ratio and regret bounds to be seamlessly\nintegrated. Furthermore, we show that the performance guarantee generated by\nour framework is tight, that is, we provide an information-theoretic lower\nbound which shows that both the loss from competitive ratio and the loss for\nregret are relevant in the combined problem.\n  Finally, we demonstrate the efficacy of our algorithms on a publicly\navailable hotel data set. Our framework is highly practical in that it requires\nno historical data (no fitted customer choice models, nor forecasting of\ncustomer arrival patterns) and can be used to initialize allocation strategies\nin fast-changing environments.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 19:34:13 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Cheung", "Wang Chi", ""], ["Ma", "Will", ""], ["Simchi-Levi", "David", ""], ["Wang", "Xinshang", ""]]}, {"id": "1810.05642", "submitter": "Robert Krajewski", "authors": "Robert Krajewski, Julian Bock, Laurent Kloeker and Lutz Eckstein", "title": "The highD Dataset: A Drone Dataset of Naturalistic Vehicle Trajectories\n  on German Highways for Validation of Highly Automated Driving Systems", "comments": "IEEE International Conference on Intelligent Transportation Systems\n  (ITSC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scenario-based testing for the safety validation of highly automated vehicles\nis a promising approach that is being examined in research and industry. This\napproach heavily relies on data from real-world scenarios to derive the\nnecessary scenario information for testing. Measurement data should be\ncollected at a reasonable effort, contain naturalistic behavior of road users\nand include all data relevant for a description of the identified scenarios in\nsufficient quality. However, the current measurement methods fail to meet at\nleast one of the requirements. Thus, we propose a novel method to measure data\nfrom an aerial perspective for scenario-based validation fulfilling the\nmentioned requirements. Furthermore, we provide a large-scale naturalistic\nvehicle trajectory dataset from German highways called highD. We evaluate the\ndata in terms of quantity, variety and contained scenarios. Our dataset\nconsists of 16.5 hours of measurements from six locations with 110 000\nvehicles, a total driven distance of 45 000 km and 5600 recorded complete lane\nchanges. The highD dataset is available online at: http://www.highD-dataset.com\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 22:47:33 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Krajewski", "Robert", ""], ["Bock", "Julian", ""], ["Kloeker", "Laurent", ""], ["Eckstein", "Lutz", ""]]}, {"id": "1810.05659", "submitter": "Sebastian Knopp", "authors": "Sebastian Knopp, Benjamin Biesinger, Matthias Prandtstetter", "title": "Mobility Offer Allocations for Corporate Mobility as a Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Corporate mobility is often based on a fixed assignment of vehicles to\nemployees. Relaxing this fixation while including alternatives such as public\ntransportation or taxis for business and private trips could increase fleet\nutilization and foster the use of battery electric vehicles. Along this idea we\npropose a flexible booking system, leading to the introduction of the NP-hard\nmobility offer allocation problem which is closely related to multi-interval\nscheduling problems. We describe problem specific conflict graphs for\nrepresenting and exploring the structure of feasible solutions. A\ncharacterization of all maximum cliques in these conflict graphs reveals\nsymmetries which allow to formulate stronger integer linear programming models.\nWe also present an adaptive large neighborhood search based approach which\nmakes use of conflict graphs as well. In a computational study, the approaches\nare evaluated and it is demonstrated that, depending on instances and run-time\nrequirements, either a solver for the integer linear programming model, fast\ngreedy heuristics, or the adaptive large neighborhood search outperforms the\nothers.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 09:18:05 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 20:22:21 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Knopp", "Sebastian", ""], ["Biesinger", "Benjamin", ""], ["Prandtstetter", "Matthias", ""]]}, {"id": "1810.05703", "submitter": "Robert Kent", "authors": "Robert E. Kent and John Brady", "title": "Formal Concept Analysis with Many-sorted Attributes", "comments": "11 pages, 6 tables, Proceedings of the Fifth International Conference\n  on Computing and Information (ICCI'93), Sudbury, Ontario, Canada, May 1993", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper unites two problem-solving traditions in computer science: (1)\nconstraint-based reasoning, and (2) formal concept analysis. For basic\ndefinitions and properties of networks of constraints, we follow the\nfoundational approach of Montanari and Rossi. This paper advocates distributed\nrelations as a more semantic version of networks of constraints. The theory\ndeveloped here uses the theory of formal concept analysis, pioneered by Rudolf\nWille and his colleagues, as a key for unlocking the hidden semantic structure\nwithin distributed relations. Conversely, this paper offers distributed\nrelations as a seamless many-sorted extension to the formal contexts of formal\nconcept analysis. Some of the intuitions underlying our approach were discussed\nin a preliminary fashion by Freuder and Wallace.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 19:54:11 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Kent", "Robert E.", ""], ["Brady", "John", ""]]}, {"id": "1810.05764", "submitter": "Juyang Weng", "authors": "Juyang Weng", "title": "A Model for Auto-Programming for General Purposes", "comments": "22 pages, 2 figures, Much of the work appeared as Juyang Weng, A\n  Theory of the GENISAMA Turing Machines that Automatically Program for General\n  Purposes, Technical Report MSU-CSE-15-13, Oct. 19, 2015, 22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Universal Turing Machine (TM) is a model for VonNeumann computers ---\ngeneral-purpose computers. A human brain can inside-skull-automatically learn a\nuniversal TM so that he acts as a general-purpose computer and writes a\ncomputer program for any practical purposes. It is unknown whether a machine\ncan accomplish the same. This theoretical work shows how the Developmental\nNetwork (DN) can accomplish this. Unlike a traditional TM, the TM learned by DN\nis a super TM --- Grounded, Emergent, Natural, Incremental, Skulled, Attentive,\nMotivated, and Abstractive (GENISAMA). A DN is free of any central controller\n(e.g., Master Map, convolution, or error back-propagation). Its learning from a\nteacher TM is one transition observation at a time, immediate, and error-free\nuntil all its neurons have been initialized by early observed teacher\ntransitions. From that point on, the DN is no longer error-free but is always\noptimal at every time instance in the sense of maximal likelihood, conditioned\non its limited computational resources and the learning experience. This letter\nalso extends the Church-Turing thesis to automatic programming for general\npurposes and sketchily proved it.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 23:58:42 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Weng", "Juyang", ""]]}, {"id": "1810.05766", "submitter": "Jaime Fisac", "authors": "Jaime F. Fisac, Eli Bronstein, Elis Stefansson, Dorsa Sadigh, S.\n  Shankar Sastry, Anca D. Dragan", "title": "Hierarchical Game-Theoretic Planning for Autonomous Vehicles", "comments": "Submitted to ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The actions of an autonomous vehicle on the road affect and are affected by\nthose of other drivers, whether overtaking, negotiating a merge, or avoiding an\naccident. This mutual dependence, best captured by dynamic game theory, creates\na strong coupling between the vehicle's planning and its predictions of other\ndrivers' behavior, and constitutes an open problem with direct implications on\nthe safety and viability of autonomous driving technology. Unfortunately,\ndynamic games are too computationally demanding to meet the real-time\nconstraints of autonomous driving in its continuous state and action space. In\nthis paper, we introduce a novel game-theoretic trajectory planning algorithm\nfor autonomous driving, that enables real-time performance by hierarchically\ndecomposing the underlying dynamic game into a long-horizon \"strategic\" game\nwith simplified dynamics and full information structure, and a short-horizon\n\"tactical\" game with full dynamics and a simplified information structure. The\nvalue of the strategic game is used to guide the tactical planning, implicitly\nextending the planning horizon, pushing the local trajectory optimization\ncloser to global solutions, and, most importantly, quantitatively accounting\nfor the autonomous vehicle and the human driver's ability and incentives to\ninfluence each other. In addition, our approach admits non-deterministic models\nof human decision-making, rather than relying on perfectly rational\npredictions. Our results showcase richer, safer, and more effective autonomous\nbehavior in comparison to existing techniques.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 00:02:54 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Fisac", "Jaime F.", ""], ["Bronstein", "Eli", ""], ["Stefansson", "Elis", ""], ["Sadigh", "Dorsa", ""], ["Sastry", "S. Shankar", ""], ["Dragan", "Anca D.", ""]]}, {"id": "1810.05810", "submitter": "Peng Gao", "authors": "Yipeng Ma, Chun Yuan, Peng Gao, Fei Wang", "title": "Efficient Multi-level Correlating for Visual Tracking", "comments": "Accepted by ACCV'2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correlation filter (CF) based tracking algorithms have demonstrated favorable\nperformance recently. Nevertheless, the top performance trackers always employ\ncomplicated optimization methods which constraint their real-time applications.\nHow to accelerate the tracking speed while retaining the tracking accuracy is a\nsignificant issue. In this paper, we propose a multi-level CF-based tracking\napproach named MLCFT which further explores the potential capacity of CF with\ntwo-stage detection: primal detection and oriented re-detection. The cascaded\ndetection scheme is simple but competent to prevent model drift and accelerate\nthe speed. An effective fusion method based on relative entropy is introduced\nto combine the complementary features extracted from deep and shallow layers of\nconvolutional neural networks (CNN). Moreover, a novel online model update\nstrategy is utilized in our tracker, which enhances the tracking performance\nfurther. Experimental results demonstrate that our proposed approach\noutperforms the most state-of-the-art trackers while tracking at speed of\nexceeded 16 frames per second on challenging benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 06:58:46 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Ma", "Yipeng", ""], ["Yuan", "Chun", ""], ["Gao", "Peng", ""], ["Wang", "Fei", ""]]}, {"id": "1810.05814", "submitter": "Bart Jacobs", "authors": "Bart Jacobs", "title": "Categorical Aspects of Parameter Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter learning is the technique for obtaining the probabilistic\nparameters in conditional probability tables in Bayesian networks from tables\nwith (observed) data --- where it is assumed that the underlying graphical\nstructure is known. There are basically two ways of doing so, referred to as\nmaximal likelihood estimation (MLE) and as Bayesian learning. This paper\nprovides a categorical analysis of these two techniques and describes them in\nterms of basic properties of the multiset monad M, the distribution monad D and\nthe Giry monad G. In essence, learning is about the reltionships between\nmultisets (used for counting) on the one hand and probability distributions on\nthe other. These relationsips will be described as suitable natural\ntransformations.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 07:50:04 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Jacobs", "Bart", ""]]}, {"id": "1810.05851", "submitter": "Cunchao Tu", "authors": "Haoxi Zhong, Chaojun Xiao, Zhipeng Guo, Cunchao Tu, Zhiyuan Liu,\n  Maosong Sun, Yansong Feng, Xianpei Han, Zhen Hu, Heng Wang, Jianfeng Xu", "title": "Overview of CAIL2018: Legal Judgment Prediction Competition", "comments": "6 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give an overview of the Legal Judgment Prediction (LJP)\ncompetition at Chinese AI and Law challenge (CAIL2018). This competition\nfocuses on LJP which aims to predict the judgment results according to the\ngiven facts. Specifically, in CAIL2018 , we proposed three subtasks of LJP for\nthe contestants, i.e., predicting relevant law articles, charges and prison\nterms given the fact descriptions. CAIL2018 has attracted several hundreds\nparticipants (601 teams, 1, 144 contestants from 269 organizations). In this\npaper, we provide a detailed overview of the task definition, related works,\noutstanding methods and competition results in CAIL2018.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 12:18:57 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Zhong", "Haoxi", ""], ["Xiao", "Chaojun", ""], ["Guo", "Zhipeng", ""], ["Tu", "Cunchao", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""], ["Feng", "Yansong", ""], ["Han", "Xianpei", ""], ["Hu", "Zhen", ""], ["Wang", "Heng", ""], ["Xu", "Jianfeng", ""]]}, {"id": "1810.05903", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern and Max Kleiman-Weiner", "title": "Towards Formal Definitions of Blameworthiness, Intention, and Moral\n  Responsibility", "comments": "Appears in AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide formal definitions of degree of blameworthiness and intention\nrelative to an epistemic state (a probability over causal models and a utility\nfunction on outcomes). These, together with a definition of actual causality,\nprovide the key ingredients for moral responsibility judgments. We show that\nthese definitions give insight into commonsense intuitions in a variety of\npuzzling cases from the literature.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 17:56:03 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Halpern", "Joseph Y.", ""], ["Kleiman-Weiner", "Max", ""]]}, {"id": "1810.05921", "submitter": "Arunesh Sinha", "authors": "Ankit Shah, Arunesh Sinha, Rajesh Ganesan, Sushil Jajodia, Hasan Cam", "title": "Two Can Play That Game: An Adversarial Evaluation of a Cyber-alert\n  Inspection System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-security is an important societal concern. Cyber-attacks have increased\nin numbers as well as in the extent of damage caused in every attack. Large\norganizations operate a Cyber Security Operation Center (CSOC), which form the\nfirst line of cyber-defense. The inspection of cyber-alerts is a critical part\nof CSOC operations. A recent work, in collaboration with Army Research Lab, USA\nproposed a reinforcement learning (RL) based approach to prevent the\ncyber-alert queue length from growing large and overwhelming the defender.\nGiven the potential deployment of this approach to CSOCs run by US defense\nagencies, we perform a red team (adversarial) evaluation of this approach.\nFurther, with the recent attacks on learning systems, it is even more important\nto test the limits of this RL approach. Towards that end, we learn an\nadversarial alert generation policy that is a best response to the defender\ninspection policy. Surprisingly, we find the defender policy to be quite robust\nto the best response of the attacker. In order to explain this observation, we\nextend the earlier RL model to a game model and show that there exists defender\npolicies that can be robust against any adversarial policy. We also derive a\ncompetitive baseline from the game theory model and compare it to the RL\napproach. However, we go further to exploit assumptions made in the MDP in the\nRL model and discover an attacker policy that overwhelms the defender. We use a\ndouble oracle approach to retrain the defender with episodes from this\ndiscovered attacker policy. This made the defender robust to the discovered\nattacker policy and no further harmful attacker policies were discovered.\nOverall, the adversarial RL and double oracle approach in RL are general\ntechniques that are applicable to other RL usage in adversarial environments.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 20:01:54 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Shah", "Ankit", ""], ["Sinha", "Arunesh", ""], ["Ganesan", "Rajesh", ""], ["Jajodia", "Sushil", ""], ["Cam", "Hasan", ""]]}, {"id": "1810.05947", "submitter": "Chao Shang", "authors": "Chao Shang, Wei-Han Chen, Abraham Duncan Stroock, Fengqi You", "title": "Robust Model Predictive Control of Irrigation Systems with Active\n  Uncertainty Learning and Data Analytics", "comments": null, "journal-ref": "IEEE Transactions on Control Systems Technology, vol. 28, no. 4,\n  pp. 1493-1504, 2020", "doi": "10.1109/TCST.2019.2916753", "report-no": null, "categories": "cs.SY cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel data-driven robust model predictive control (DDRMPC)\napproach for automatic control of irrigation systems. The fundamental idea is\nto integrate both mechanistic models, which describe dynamics in soil moisture\nvariations, and data-driven models, which characterize uncertainty in forecast\nerrors of evapotranspiration and precipitation, into a holistic systems control\nframework. To better capture the support of uncertainty distribution, we take a\nnew learning-based approach by constructing uncertainty sets from historical\ndata. For evapotranspiration forecast error, the support vector\nclustering-based uncertainty set is adopted, which can be conveniently built\nfrom historical data. As for precipitation forecast errors, we analyze the\ndependence of their distribution on forecast values, and further design a\ntailored uncertainty set based on the properties of this type of uncertainty.\nIn this way, the overall uncertainty distribution can be elaborately described,\nwhich finally contributes to rational and efficient control decisions. To\nassure the quality of data-driven uncertainty sets, a training-calibration\nscheme is used to provide theoretical performance guarantees. A generalized\naffine decision rule is adopted to obtain tractable approximations of optimal\ncontrol problems, thereby ensuring the practicability of DDRMPC. Case studies\nusing real data show that, DDRMPC can reliably maintain soil moisture above the\nsafety level and avoid crop devastation. The proposed DDRMPC approach leads to\na 40% reduction of total water consumption compared to the fine-tuned open-loop\ncontrol strategy. In comparison with the carefully tuned rule-based control and\ncertainty equivalent model predictive control, the proposed DDRMPC approach can\nsignificantly reduce the total water consumption and improve the control\nperformance.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 00:31:22 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 00:09:43 GMT"}, {"version": "v3", "created": "Thu, 23 May 2019 21:37:57 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Shang", "Chao", ""], ["Chen", "Wei-Han", ""], ["Stroock", "Abraham Duncan", ""], ["You", "Fengqi", ""]]}, {"id": "1810.05959", "submitter": "Yu Zhang", "authors": "Yu Zhang, Yan Zhang", "title": "Top-K Influential Nodes in Social Networks: A Game Perspective", "comments": "5 pages; Accepted to SIGIR 2017; Revised Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence maximization, the fundamental of viral marketing, aims to find\ntop-$K$ seed nodes maximizing influence spread under certain spreading models.\nIn this paper, we study influence maximization from a game perspective. We\npropose a Coordination Game model, in which every individual makes its decision\nbased on the benefit of coordination with its network neighbors, to study\ninformation propagation. Our model serves as the generalization of some\nexisting models, such as Majority Vote model and Linear Threshold model. Under\nthe generalized model, we study the hardness of influence maximization and the\napproximation guarantee of the greedy algorithm. We also combine several\nstrategies to accelerate the algorithm. Experimental results show that after\nthe acceleration, our algorithm significantly outperforms other heuristics, and\nit is three orders of magnitude faster than the original greedy method.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 03:15:25 GMT"}, {"version": "v10", "created": "Fri, 1 May 2020 05:51:16 GMT"}, {"version": "v11", "created": "Wed, 3 Jun 2020 05:55:04 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 22:40:56 GMT"}, {"version": "v3", "created": "Mon, 21 Jan 2019 15:39:02 GMT"}, {"version": "v4", "created": "Mon, 8 Apr 2019 01:18:11 GMT"}, {"version": "v5", "created": "Sat, 22 Jun 2019 02:53:14 GMT"}, {"version": "v6", "created": "Thu, 1 Aug 2019 02:26:54 GMT"}, {"version": "v7", "created": "Tue, 19 Nov 2019 23:41:36 GMT"}, {"version": "v8", "created": "Thu, 23 Jan 2020 02:19:31 GMT"}, {"version": "v9", "created": "Sun, 8 Mar 2020 23:49:36 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Zhang", "Yu", ""], ["Zhang", "Yan", ""]]}, {"id": "1810.05983", "submitter": "Yaliang Li", "authors": "Yaliang Li, Liuyi Yao, Nan Du, Jing Gao, Qi Li, Chuishi Meng, Chenwei\n  Zhang, Wei Fan", "title": "Finding Similar Medical Questions from Question Answering Websites", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past few years have witnessed the flourishing of crowdsourced medical\nquestion answering (Q&A) websites. Patients who have medical information\ndemands tend to post questions about their health conditions on these\ncrowdsourced Q&A websites and get answers from other users. However, we observe\nthat a large portion of new medical questions cannot be answered in time or\nreceive only few answers from these websites. On the other hand, we notice that\nsolved questions have great potential to solve this challenge. Motivated by\nthese, we propose an end-to-end system that can automatically find similar\nquestions for unsolved medical questions. By learning the vector presentation\nof unsolved questions and their candidate similar questions, the proposed\nsystem outputs similar questions according to the similarity between vector\nrepresentations. Through the vector representation, the similar questions are\nfound at the question level, and the diversity of medical questions expression\nissue can be addressed. Further, we handle two more important issues, i.e.,\ntraining data generation issue and efficiency issue, associated with the LSTM\ntraining procedure and the retrieval of candidate similar questions. The\neffectiveness of the proposed system is validated on a large-scale real-world\ndataset collected from a crowdsourced maternal-infant Q&A website.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 06:34:18 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Li", "Yaliang", ""], ["Yao", "Liuyi", ""], ["Du", "Nan", ""], ["Gao", "Jing", ""], ["Li", "Qi", ""], ["Meng", "Chuishi", ""], ["Zhang", "Chenwei", ""], ["Fan", "Wei", ""]]}, {"id": "1810.05989", "submitter": "Ophir Gozes", "authors": "Ophir Gozes, Hayit Greenspan", "title": "Lung Structures Enhancement in Chest Radiographs via CT based FCNN\n  Training", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-00946-5_16", "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abundance of overlapping anatomical structures appearing in chest\nradiographs can reduce the performance of lung pathology detection by automated\nalgorithms (CAD) as well as the human reader. In this paper, we present a deep\nlearning based image processing technique for enhancing the contrast of soft\nlung structures in chest radiographs using Fully Convolutional Neural Networks\n(FCNN). Two 2D FCNN architectures were trained to accomplish the task: The\nfirst performs 2D lung segmentation which is used for normalization of the lung\narea. The second FCNN is trained to extract lung structures. To create the\ntraining images, we employed Simulated X-Ray or Digitally Reconstructed\nRadiographs (DRR) derived from 516 scans belonging to the LIDC-IDRI dataset. By\nfirst segmenting the lungs in the CT domain, we are able to create a dataset of\n2D lung masks to be used for training the segmentation FCNN. For training the\nextraction FCNN, we create DRR images of only voxels belonging to the 3D lung\nsegmentation which we call \"Lung X-ray\" and use them as target images. Once the\nlung structures are extracted, the original image can be enhanced by fusing the\noriginal input x-ray and the synthesized \"Lung X-ray\". We show that our\nenhancement technique is applicable to real x-ray data, and display our results\non the recently released NIH Chest X-Ray-14 dataset. We see promising results\nwhen training a DenseNet-121 based architecture to work directly on the lung\nenhanced X-ray images.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 08:04:43 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Gozes", "Ophir", ""], ["Greenspan", "Hayit", ""]]}, {"id": "1810.06018", "submitter": "Alun Preece", "authors": "Frank Stein, Alun Preece, Mihai Boicu", "title": "AAAI FSS-18: Artificial Intelligence in Government and Public Sector\n  Proceedings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proceedings of the AAAI Fall Symposium on Artificial Intelligence in\nGovernment and Public Sector, Arlington, Virginia, USA, October 18-20, 2018\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 11:40:30 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Stein", "Frank", ""], ["Preece", "Alun", ""], ["Boicu", "Mihai", ""]]}, {"id": "1810.06033", "submitter": "Xutan Peng", "authors": "Chen Li, Xutan Peng, Shanghang Zhang, Hao Peng, Philip S. Yu, Min He,\n  Linfeng Du, Lihong Wang", "title": "Modeling relation paths for knowledge base completion via joint\n  adversarial training", "comments": "Accepted by Knowledge-Based Systems", "journal-ref": null, "doi": "10.1016/j.knosys.2020.105865", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Base Completion (KBC), which aims at determining the missing\nrelations between entity pairs, has received increasing attention in recent\nyears. Most existing KBC methods focus on either embedding the Knowledge Base\n(KB) into a specific semantic space or leveraging the joint probability of\nRandom Walks (RWs) on multi-hop paths. Only a few unified models take both\nsemantic and path-related features into consideration with adequacy. In this\npaper, we propose a novel method to explore the intrinsic relationship between\nthe single relation (i.e. 1-hop path) and multi-hop paths between paired\nentities. We use Hierarchical Attention Networks (HANs) to select important\nrelations in multi-hop paths and encode them into low-dimensional vectors. By\ntreating relations and multi-hop paths as two different input sources, we use a\nfeature extractor, which is shared by two downstream components (i.e. relation\nclassifier and source discriminator), to capture shared/similar information\nbetween them. By joint adversarial training, we encourage our model to extract\nfeatures from the multi-hop paths which are representative for relation\ncompletion. We apply the trained model (except for the source discriminator) to\nseveral large-scale KBs for relation completion. Experimental results show that\nour method outperforms existing path information-based approaches. Since each\nsub-module of our model can be well interpreted, our model can be applied to a\nlarge number of relation learning tasks.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 13:26:34 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 08:55:36 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Li", "Chen", ""], ["Peng", "Xutan", ""], ["Zhang", "Shanghang", ""], ["Peng", "Hao", ""], ["Yu", "Philip S.", ""], ["He", "Min", ""], ["Du", "Linfeng", ""], ["Wang", "Lihong", ""]]}, {"id": "1810.06045", "submitter": "Vikash Kumar", "authors": "Henry Zhu, Abhishek Gupta, Aravind Rajeswaran, Sergey Levine and\n  Vikash Kumar", "title": "Dexterous Manipulation with Deep Reinforcement Learning: Efficient,\n  General, and Low-Cost", "comments": "https://sites.google.com/view/deeprl-handmanipulation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dexterous multi-fingered robotic hands can perform a wide range of\nmanipulation skills, making them an appealing component for general-purpose\nrobotic manipulators. However, such hands pose a major challenge for autonomous\ncontrol, due to the high dimensionality of their configuration space and\ncomplex intermittent contact interactions. In this work, we propose deep\nreinforcement learning (deep RL) as a scalable solution for learning complex,\ncontact rich behaviors with multi-fingered hands. Deep RL provides an\nend-to-end approach to directly map sensor readings to actions, without the\nneed for task specific models or policy classes. We show that contact-rich\nmanipulation behavior with multi-fingered hands can be learned by directly\ntraining with model-free deep RL algorithms in the real world, with minimal\nadditional assumption and without the aid of simulation. We learn a variety of\ncomplex behaviors on two different low-cost hardware platforms. We show that\neach task can be learned entirely from scratch, and further study how the\nlearning process can be further accelerated by using a small number of human\ndemonstrations to bootstrap learning. Our experiments demonstrate that complex\nmulti-fingered manipulation skills can be learned in the real world in about\n4-7 hours for most tasks, and that demonstrations can decrease this to 2-3\nhours, indicating that direct deep RL training in the real world is a viable\nand practical alternative to simulation and model-based control.\n\\url{https://sites.google.com/view/deeprl-handmanipulation}\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 15:26:24 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Zhu", "Henry", ""], ["Gupta", "Abhishek", ""], ["Rajeswaran", "Aravind", ""], ["Levine", "Sergey", ""], ["Kumar", "Vikash", ""]]}, {"id": "1810.06049", "submitter": "Dor Bank", "authors": "Dor Bank and Raja Giryes", "title": "An ETF view of Dropout regularization", "comments": "Accepted to BMVC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is a popular regularization technique in deep learning. Yet, the\nreason for its success is still not fully understood. This paper provides a new\ninterpretation of Dropout from a frame theory perspective. By drawing a\nconnection to recent developments in analog channel coding, we suggest that for\na certain family of autoencoders with a linear encoder, optimizing the encoder\nwith dropout regularization leads to an equiangular tight frame (ETF). Since\nthis optimization is non-convex, we add another regularization that promotes\nsuch structures by minimizing the cross-correlation between filters in the\nnetwork. We demonstrate its applicability in convolutional and fully connected\nlayers in both feed-forward and recurrent networks. All these results suggest\nthat there is indeed a relationship between dropout and ETF structure of the\nregularized linear operations.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 15:50:21 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 18:20:17 GMT"}, {"version": "v3", "created": "Fri, 8 Feb 2019 12:40:11 GMT"}, {"version": "v4", "created": "Wed, 19 Aug 2020 09:12:27 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Bank", "Dor", ""], ["Giryes", "Raja", ""]]}, {"id": "1810.06078", "submitter": "Hui Wang", "authors": "Hui Wang, Michael Emmerich, Aske Plaat", "title": "Assessing the Potential of Classical Q-learning in General Game Playing", "comments": "arXiv admin note: substantial text overlap with arXiv:1802.05944", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After the recent groundbreaking results of AlphaGo and AlphaZero, we have\nseen strong interests in deep reinforcement learning and artificial general\nintelligence (AGI) in game playing. However, deep learning is\nresource-intensive and the theory is not yet well developed. For small games,\nsimple classical table-based Q-learning might still be the algorithm of choice.\nGeneral Game Playing (GGP) provides a good testbed for reinforcement learning\nto research AGI. Q-learning is one of the canonical reinforcement learning\nmethods, and has been used by (Banerjee $\\&$ Stone, IJCAI 2007) in GGP. In this\npaper we implement Q-learning in GGP for three small-board games (Tic-Tac-Toe,\nConnect Four, Hex)\\footnote{source code: https://github.com/wh1992v/ggp-rl}, to\nallow comparison to Banerjee et al.. We find that Q-learning converges to a\nhigh win rate in GGP. For the $\\epsilon$-greedy strategy, we propose a first\nenhancement, the dynamic $\\epsilon$ algorithm. In addition, inspired by (Gelly\n$\\&$ Silver, ICML 2007) we combine online search (Monte Carlo Search) to\nenhance offline learning, and propose QM-learning for GGP. Both enhancements\nimprove the performance of classical Q-learning. In this work, GGP allows us to\nshow, if augmented by appropriate enhancements, that classical table-based\nQ-learning can perform well in small games.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 18:49:33 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Wang", "Hui", ""], ["Emmerich", "Michael", ""], ["Plaat", "Aske", ""]]}, {"id": "1810.06120", "submitter": "Enzhi Li", "authors": "Yiwei Li, Enzhi Li", "title": "Variational Neural Networks: Every Layer and Neuron Can Be Unique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of activation function can significantly influence the performance\nof neural networks. The lack of guiding principles for the selection of\nactivation function is lamentable. We try to address this issue by introducing\nour variational neural networks, where the activation function is represented\nas a linear combination of possible candidate functions, and an optimal\nactivation is obtained via minimization of a loss function using gradient\ndescent method. The gradient formulae for the loss function with respect to\nthese expansion coefficients are central for the implementation of gradient\ndescent algorithm, and here we derive these gradient formulae.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 22:41:11 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Li", "Yiwei", ""], ["Li", "Enzhi", ""]]}, {"id": "1810.06284", "submitter": "C\\'edric Colas", "authors": "C\\'edric Colas, Pierre Fournier, Olivier Sigaud, Mohamed Chetouani,\n  Pierre-Yves Oudeyer", "title": "CURIOUS: Intrinsically Motivated Modular Multi-Goal Reinforcement\n  Learning", "comments": "Accepted at ICML 2019", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning 2019", "doi": null, "report-no": "PMLR 97:1331-1340", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In open-ended environments, autonomous learning agents must set their own\ngoals and build their own curriculum through an intrinsically motivated\nexploration. They may consider a large diversity of goals, aiming to discover\nwhat is controllable in their environments, and what is not. Because some goals\nmight prove easy and some impossible, agents must actively select which goal to\npractice at any moment, to maximize their overall mastery on the set of\nlearnable goals. This paper proposes CURIOUS, an algorithm that leverages 1) a\nmodular Universal Value Function Approximator with hindsight learning to\nachieve a diversity of goals of different kinds within a unique policy and 2)\nan automated curriculum learning mechanism that biases the attention of the\nagent towards goals maximizing the absolute learning progress. Agents focus\nsequentially on goals of increasing complexity, and focus back on goals that\nare being forgotten. Experiments conducted in a new modular-goal robotic\nenvironment show the resulting developmental self-organization of a learning\ncurriculum, and demonstrate properties of robustness to distracting goals,\nforgetting and changes in body properties.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 11:40:28 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 09:10:44 GMT"}, {"version": "v3", "created": "Sun, 24 Feb 2019 16:41:17 GMT"}, {"version": "v4", "created": "Wed, 29 May 2019 11:52:20 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Colas", "C\u00e9dric", ""], ["Fournier", "Pierre", ""], ["Sigaud", "Olivier", ""], ["Chetouani", "Mohamed", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1810.06338", "submitter": "Michael Cashmore", "authors": "Rita Borgo, Michael Cashmore, Daniele Magazzeni", "title": "Towards Providing Explanations for AI Planner Decisions", "comments": "Presented at the IJCAI/ECAI 2018 Workshop on Explainable Artificial\n  Intelligence (XAI)\n  (http://home.earthlink.net/~dwaha/research/meetings/faim18-xai). Stockholm,\n  July 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to engender trust in AI, humans must understand what an AI system is\ntrying to achieve, and why. To overcome this problem, the underlying AI process\nmust produce justifications and explanations that are both transparent and\ncomprehensible to the user. AI Planning is well placed to be able to address\nthis challenge. In this paper we present a methodology to provide initial\nexplanations for the decisions made by the planner. Explanations are created by\nallowing the user to suggest alternative actions in plans and then compare the\nresulting plans with the one found by the planner. The methodology is\nimplemented in the new XAI-Plan framework.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 13:13:48 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Borgo", "Rita", ""], ["Cashmore", "Michael", ""], ["Magazzeni", "Daniele", ""]]}, {"id": "1810.06374", "submitter": "Andrea Marrella", "authors": "Andrea Marrella", "title": "SmartPM: Automatic Adaptation of Dynamic Processes at Run-Time", "comments": "Postprint of PhD Thesis of Andrea Marrella, published on October 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research activity outlined in this PhD thesis is devoted to define a\ngeneral approach, a concrete architecture and a prototype Process Management\nSystem (PMS) for the automated adaptation of dynamic processes at run-time, on\nthe basis of a declarative specification of process tasks and relying on\nwell-established reasoning about actions and planning techniques. The purpose\nis to demonstrate that the combination of procedural and imperative models with\ndeclarative elements, along with the exploitation of techniques from the field\nof artificial intelligence (AI), such as Situation Calculus, IndiGolog and\nautomated planning, can increase the ability of existing PMSs of supporting\ndynamic processes. To this end, a prototype PMS named SmartPM, which is\nspecifically tailored for supporting collaborative work of process participants\nduring pervasive scenarios, has been developed. The adaptation mechanism\ndeployed on SmartPM is based on execution monitoring for detecting failures at\nrun-time, which does not require the definition of the adaptation strategy in\nthe process itself (as most of the current approaches do), and on automatic\nplanning techniques for the synthesis of the recovery procedure.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 13:17:35 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Marrella", "Andrea", ""]]}, {"id": "1810.06394", "submitter": "Jiechao Xiong", "authors": "Jiechao Xiong, Qing Wang, Zhuoran Yang, Peng Sun, Lei Han, Yang Zheng,\n  Haobo Fu, Tong Zhang, Ji Liu, and Han Liu", "title": "Parametrized Deep Q-Networks Learning: Reinforcement Learning with\n  Discrete-Continuous Hybrid Action Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing deep reinforcement learning (DRL) frameworks consider either\ndiscrete action space or continuous action space solely. Motivated by\napplications in computer games, we consider the scenario with\ndiscrete-continuous hybrid action space. To handle hybrid action space,\nprevious works either approximate the hybrid space by discretization, or relax\nit into a continuous set. In this paper, we propose a parametrized deep\nQ-network (P- DQN) framework for the hybrid action space without approximation\nor relaxation. Our algorithm combines the spirits of both DQN (dealing with\ndiscrete action space) and DDPG (dealing with continuous action space) by\nseamlessly integrating them. Empirical results on a simulation example, scoring\na goal in simulated RoboCup soccer and the solo mode in game King of Glory\n(KOG) validate the efficiency and effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 07:38:44 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Xiong", "Jiechao", ""], ["Wang", "Qing", ""], ["Yang", "Zhuoran", ""], ["Sun", "Peng", ""], ["Han", "Lei", ""], ["Zheng", "Yang", ""], ["Fu", "Haobo", ""], ["Zhang", "Tong", ""], ["Liu", "Ji", ""], ["Liu", "Han", ""]]}, {"id": "1810.06405", "submitter": "Bob Han", "authors": "Yunheng Han, Weiwei Sun, Baihua Zheng", "title": "Ineffectiveness of Dictionary Coding to Infer Predictability Limits of\n  Human Mobility", "comments": "A technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a series of models have been proposed to predict future movements\nof people. Meanwhile, dictionary coding algorithms are used to estimate the\npredictability limit of human mobility. Although dictionary coding is optimal,\nit takes long time to converge. Consequently, it is ineffective to infer\npredictability through dictionary coding algorithms. In this report, we\nillustrate this ineffectiveness on the basis of human movements in urban space.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 17:34:49 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2018 13:05:02 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Han", "Yunheng", ""], ["Sun", "Weiwei", ""], ["Zheng", "Baihua", ""]]}, {"id": "1810.06519", "submitter": "Brett Israelsen", "authors": "Brett W Israelsen, Nisar R Ahmed, Eric Frew, Dale Lawrence, Brian\n  Argrow", "title": "Factorized Machine Self-Confidence for Decision-Making Agents", "comments": "title change, leaving as stand-alone tech report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic assurances from advanced autonomous systems assist human users in\nunderstanding, trusting, and using such systems appropriately. Designing these\nsystems with the capacity of assessing their own capabilities is one approach\nto creating an algorithmic assurance. The idea of `machine self-confidence' is\nintroduced for autonomous systems. Using a factorization based framework for\nself-confidence assessment, one component of self-confidence, called\n`solver-quality', is discussed in the context of Markov decision processes for\nautonomous systems. Markov decision processes underlie much of the theory of\nreinforcement learning, and are commonly used for planning and decision making\nunder uncertainty in robotics and autonomous systems. A `solver quality' metric\nis formally defined in the context of decision making algorithms based on\nMarkov decision processes. A method for assessing solver quality is then\nderived, drawing inspiration from empirical hardness models. Finally, numerical\nexperiments for an unmanned autonomous vehicle navigation problem under\ndifferent solver, parameter, and environment conditions indicate that the\nself-confidence metric exhibits the desired properties. Discussion of results,\nand avenues for future investigation are included.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 17:06:38 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 18:31:04 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Israelsen", "Brett W", ""], ["Ahmed", "Nisar R", ""], ["Frew", "Eric", ""], ["Lawrence", "Dale", ""], ["Argrow", "Brian", ""]]}, {"id": "1810.06543", "submitter": "Roozbeh Mottaghi", "authors": "Wei Yang, Xiaolong Wang, Ali Farhadi, Abhinav Gupta, Roozbeh Mottaghi", "title": "Visual Semantic Navigation using Scene Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do humans navigate to target objects in novel scenes? Do we use the\nsemantic/functional priors we have built over years to efficiently search and\nnavigate? For example, to search for mugs, we search cabinets near the coffee\nmachine and for fruits we try the fridge. In this work, we focus on\nincorporating semantic priors in the task of semantic navigation. We propose to\nuse Graph Convolutional Networks for incorporating the prior knowledge into a\ndeep reinforcement learning framework. The agent uses the features from the\nknowledge graph to predict the actions. For evaluation, we use the AI2-THOR\nframework. Our experiments show how semantic knowledge improves performance\nsignificantly. More importantly, we show improvement in generalization to\nunseen scenes and/or objects. The supplementary video can be accessed at the\nfollowing link: https://youtu.be/otKjuO805dE .\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 17:45:02 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Yang", "Wei", ""], ["Wang", "Xiaolong", ""], ["Farhadi", "Ali", ""], ["Gupta", "Abhinav", ""], ["Mottaghi", "Roozbeh", ""]]}, {"id": "1810.06544", "submitter": "Nicholas Rhinehart", "authors": "Nicholas Rhinehart, Rowan McAllister, Sergey Levine", "title": "Deep Imitative Models for Flexible Inference, Planning, and Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation Learning (IL) is an appealing approach to learn desirable\nautonomous behavior. However, directing IL to achieve arbitrary goals is\ndifficult. In contrast, planning-based algorithms use dynamics models and\nreward functions to achieve goals. Yet, reward functions that evoke desirable\nbehavior are often difficult to specify. In this paper, we propose Imitative\nModels to combine the benefits of IL and goal-directed planning. Imitative\nModels are probabilistic predictive models of desirable behavior able to plan\ninterpretable expert-like trajectories to achieve specified goals. We derive\nfamilies of flexible goal objectives, including constrained goal regions,\nunconstrained goal sets, and energy-based goals. We show that our method can\nuse these objectives to successfully direct behavior. Our method substantially\noutperforms six IL approaches and a planning-based approach in a dynamic\nsimulated autonomous driving task, and is efficiently learned from expert\ndemonstrations without online data collection. We also show our approach is\nrobust to poorly specified goals, such as goals on the wrong side of the road.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 17:51:03 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2019 20:07:49 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 19:48:56 GMT"}, {"version": "v4", "created": "Tue, 1 Oct 2019 00:13:58 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Rhinehart", "Nicholas", ""], ["McAllister", "Rowan", ""], ["Levine", "Sergey", ""]]}, {"id": "1810.06617", "submitter": "Razieh Mehri", "authors": "Razieh Mehri, Volker Haarslev, Hamidreza Chinaei", "title": "Optimizing Heuristics for Tableau-based OWL Reasoners", "comments": "9 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization techniques play a significant role in improving description\nlogic reasoners covering the Web Ontology Language (OWL). These techniques are\nessential to speed up these reasoners. Many of the optimization techniques are\nbased on heuristic choices. Optimal heuristic selection makes these techniques\nmore effective. The FaCT++ OWL reasoner and its Java version JFact implement an\noptimization technique called ToDo list which is a substitute for a traditional\ntop-down approach in tableau-based reasoners. The ToDo list mechanism allows\none to arrange the order of applying different rules by giving each a priority.\nCompared to a top-down approach, the ToDo list technique has a better control\nover the application of expansion rules. Learning the proper heuristic order\nfor applying rules in ToDo lis} will have a great impact on reasoning speed. We\nuse a binary SVM technique to build our learning model. The model can help to\nchoose ontology-specific order sets to speed up OWL reasoning. On average, our\nlearning approach tested with 40 selected ontologies achieves a speedup of two\norders of magnitude when compared to the worst rule ordering choice.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 19:06:14 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 21:36:43 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Mehri", "Razieh", ""], ["Haarslev", "Volker", ""], ["Chinaei", "Hamidreza", ""]]}, {"id": "1810.06638", "submitter": "Xipeng Qiu", "authors": "Fu Sun, Linyang Li, Xipeng Qiu, Yang Liu", "title": "U-Net: Machine Reading Comprehension with Unanswerable Questions", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading comprehension with unanswerable questions is a new\nchallenging task for natural language processing. A key subtask is to reliably\npredict whether the question is unanswerable. In this paper, we propose a\nunified model, called U-Net, with three important components: answer pointer,\nno-answer pointer, and answer verifier. We introduce a universal node and thus\nprocess the question and its context passage as a single contiguous sequence of\ntokens. The universal node encodes the fused information from both the question\nand passage, and plays an important role to predict whether the question is\nanswerable and also greatly improves the conciseness of the U-Net. Different\nfrom the state-of-art pipeline models, U-Net can be learned in an end-to-end\nfashion. The experimental results on the SQuAD 2.0 dataset show that U-Net can\neffectively predict the unanswerability of questions and achieves an F1 score\nof 71.7 on SQuAD 2.0.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 12:48:34 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Sun", "Fu", ""], ["Li", "Linyang", ""], ["Qiu", "Xipeng", ""], ["Liu", "Yang", ""]]}, {"id": "1810.06645", "submitter": "Lin Li", "authors": "Yunpei Zheng, Lin Li, Luo Zhong, Jianwei Zhang, Jinhang Liu", "title": "Using Sentiment Representation Learning to Enhance Gender Classification\n  for User Profiling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User profiling means exploiting the technology of machine learning to predict\nattributes of users, such as demographic attributes, hobby attributes,\npreference attributes, etc. It's a powerful data support of precision\nmarketing. Existing methods mainly study network behavior, personal\npreferences, post texts to build user profile. Through our data analysis of\nmicro-blog, we find that females show more positive and have richer emotions\nthan males in online social platform. This difference is very conducive to the\ndistinction between genders. Therefore, we argue that sentiment context is\nimportant as well for user profiling.This paper focuses on exploiting microblog\nuser posts to predict one of the demographic labels: gender. We propose a\nSentiment Representation Learning based Multi-Layer Perceptron(SRL-MLP) model\nto classify gender. First we build a sentiment polarity classifier in advance\nby training Long Short-Term Memory(LSTM) model on e-commerce review corpus.\nNext we transfer sentiment representation to a basic MLP network. Last we\nconduct experiments on gender classification by sentiment representation.\nExperimental results show that our approach can improve gender classification\naccuracy by 5.53\\%, from 84.20\\% to 89.73\\%.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 07:01:20 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Zheng", "Yunpei", ""], ["Li", "Lin", ""], ["Zhong", "Luo", ""], ["Zhang", "Jianwei", ""], ["Liu", "Jinhang", ""]]}, {"id": "1810.06673", "submitter": "Ahmed Elnaggar", "authors": "Ahmed Elnaggar, Robin Otto and Florian Matthes", "title": "Named-Entity Linking Using Deep Learning For Legal Documents: A Transfer\n  Learning Approach", "comments": "10 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the legal domain it is important to differentiate between words in\ngeneral, and afterwards to link the occurrences of the same entities. The topic\nto solve these challenges is called Named-Entity Linking (NEL). Current\nsupervised neural networks designed for NEL use publicly available datasets for\ntraining and testing. However, this paper focuses especially on the aspect of\napplying transfer learning approach using networks trained for NEL to legal\ndocuments. Experiments show consistent improvement in the legal datasets that\nwere created from the European Union law in the scope of this research. Using\ntransfer learning approach, we reached F1-score of 98.90\\% and 98.01\\% on the\nlegal small and large test dataset.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 20:38:00 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Elnaggar", "Ahmed", ""], ["Otto", "Robin", ""], ["Matthes", "Florian", ""]]}, {"id": "1810.06682", "submitter": "Shaojie Bai", "authors": "Shaojie Bai, J. Zico Kolter, Vladlen Koltun", "title": "Trellis Networks for Sequence Modeling", "comments": "Published at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present trellis networks, a new architecture for sequence modeling. On the\none hand, a trellis network is a temporal convolutional network with special\nstructure, characterized by weight tying across depth and direct injection of\nthe input into deep layers. On the other hand, we show that truncated recurrent\nnetworks are equivalent to trellis networks with special sparsity structure in\ntheir weight matrices. Thus trellis networks with general weight matrices\ngeneralize truncated recurrent networks. We leverage these connections to\ndesign high-performing trellis networks that absorb structural and algorithmic\nelements from both recurrent and convolutional models. Experiments demonstrate\nthat trellis networks outperform the current state of the art methods on a\nvariety of challenging benchmarks, including word-level language modeling and\ncharacter-level language modeling tasks, and stress tests designed to evaluate\nlong-term memory retention. The code is available at\nhttps://github.com/locuslab/trellisnet .\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 20:50:05 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 21:37:42 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Bai", "Shaojie", ""], ["Kolter", "J. Zico", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1810.06683", "submitter": "Hsin-Yuan Huang", "authors": "Hsin-Yuan Huang, Eunsol Choi, Wen-tau Yih", "title": "FlowQA: Grasping Flow in History for Conversational Machine\n  Comprehension", "comments": "15 pages, Published at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational machine comprehension requires the understanding of the\nconversation history, such as previous question/answer pairs, the document\ncontext, and the current question. To enable traditional, single-turn models to\nencode the history comprehensively, we introduce Flow, a mechanism that can\nincorporate intermediate representations generated during the process of\nanswering previous questions, through an alternating parallel processing\nstructure. Compared to approaches that concatenate previous questions/answers\nas input, Flow integrates the latent semantics of the conversation history more\ndeeply. Our model, FlowQA, shows superior performance on two recently proposed\nconversational challenges (+7.2% F1 on CoQA and +4.0% on QuAC). The\neffectiveness of Flow also shows in other tasks. By reducing sequential\ninstruction understanding to conversational machine comprehension, FlowQA\noutperforms the best models on all three domains in SCONE, with +1.8% to +4.4%\nimprovement in accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 20:46:49 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 23:38:44 GMT"}, {"version": "v3", "created": "Tue, 16 Apr 2019 03:17:47 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Huang", "Hsin-Yuan", ""], ["Choi", "Eunsol", ""], ["Yih", "Wen-tau", ""]]}, {"id": "1810.06710", "submitter": "Ardavan Salehi Nobandegani", "authors": "Ardavan S. Nobandegani, William Campoli, Thomas R. Shultz", "title": "Bringing Order to the Cognitive Fallacy Zoo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the eyes of a rationalist like Descartes or Spinoza, human reasoning is\nflawless, marching toward uncovering ultimate truth. A few centuries later,\nhowever, culminating in the work of Kahneman and Tversky, human reasoning was\nportrayed as anything but flawless, filled with numerous misjudgments, biases,\nand cognitive fallacies. With further investigations, new cognitive fallacies\ncontinually emerged, leading to a state of affairs which can fairly be\ncharacterized as the cognitive fallacy zoo! In this largely methodological\nwork, we formally present a principled way to bring order to this zoo. We\nintroduce the idea of establishing implication relationships (IRs) between\ncognitive fallacies, formally characterizing how one fallacy implies another.\nIR is analogous to, and partly inspired by, the fundamental concept of\nreduction in computational complexity theory. We present several examples of\nIRs involving experimentally well-documented cognitive fallacies: base-rate\nneglect, availability bias, conjunction fallacy, decoy effect, framing effect,\nand Allais paradox. We conclude by discussing how our work: (i) allows for\nidentifying those pivotal cognitive fallacies whose investigation would be the\nmost rewarding research agenda, and importantly (ii) permits a systematized,\nguided research program on cognitive fallacies, motivating influential\ntheoretical as well as experimental avenues of future research.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 21:37:38 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Nobandegani", "Ardavan S.", ""], ["Campoli", "William", ""], ["Shultz", "Thomas R.", ""]]}, {"id": "1810.06721", "submitter": "Greg Wayne", "authors": "Chia-Chun Hung, Timothy Lillicrap, Josh Abramson, Yan Wu, Mehdi Mirza,\n  Federico Carnevale, Arun Ahuja, Greg Wayne", "title": "Optimizing Agent Behavior over Long Time Scales by Transporting Value", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans spend a remarkable fraction of waking life engaged in acts of \"mental\ntime travel\". We dwell on our actions in the past and experience satisfaction\nor regret. More than merely autobiographical storytelling, we use these event\nrecollections to change how we will act in similar scenarios in the future.\nThis process endows us with a computationally important ability to link actions\nand consequences across long spans of time, which figures prominently in\naddressing the problem of long-term temporal credit assignment; in artificial\nintelligence (AI) this is the question of how to evaluate the utility of the\nactions within a long-duration behavioral sequence leading to success or\nfailure in a task. Existing approaches to shorter-term credit assignment in AI\ncannot solve tasks with long delays between actions and consequences. Here, we\nintroduce a new paradigm for reinforcement learning where agents use recall of\nspecific memories to credit actions from the past, allowing them to solve\nproblems that are intractable for existing algorithms. This paradigm broadens\nthe scope of problems that can be investigated in AI and offers a mechanistic\naccount of behaviors that may inspire computational models in neuroscience,\npsychology, and behavioral economics.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 22:01:28 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 13:56:03 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Hung", "Chia-Chun", ""], ["Lillicrap", "Timothy", ""], ["Abramson", "Josh", ""], ["Wu", "Yan", ""], ["Mirza", "Mehdi", ""], ["Carnevale", "Federico", ""], ["Ahuja", "Arun", ""], ["Wayne", "Greg", ""]]}, {"id": "1810.06748", "submitter": "German I. Parisi", "authors": "Di Fu, Pablo Barros, German I. Parisi, Haiyan Wu, Sven Magg, Xun Liu,\n  Stefan Wermter", "title": "Assessing the Contribution of Semantic Congruency to Multisensory\n  Integration and Conflict Resolution", "comments": "Workshop on Crossmodal Learning for Intelligent Robotics at IROS'18,\n  Madrid, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The efficient integration of multisensory observations is a key property of\nthe brain that yields the robust interaction with the environment. However,\nartificial multisensory perception remains an open issue especially in\nsituations of sensory uncertainty and conflicts. In this work, we extend\nprevious studies on audio-visual (AV) conflict resolution in complex\nenvironments. In particular, we focus on quantitatively assessing the\ncontribution of semantic congruency during an AV spatial localization task. In\naddition to conflicts in the spatial domain (i.e. spatially misaligned\nstimuli), we consider gender-specific conflicts with male and female avatars.\nOur results suggest that while semantically related stimuli affect the\nmagnitude of the visual bias (perceptually shifting the location of the sound\ntowards a semantically congruent visual cue), humans still strongly rely on\nenvironmental statistics to solve AV conflicts. Together with previously\nreported results, this work contributes to a better understanding of how\nmultisensory integration and conflict resolution can be modelled in artificial\nagents and robots operating in real-world environments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 23:22:10 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Fu", "Di", ""], ["Barros", "Pablo", ""], ["Parisi", "German I.", ""], ["Wu", "Haiyan", ""], ["Magg", "Sven", ""], ["Liu", "Xun", ""], ["Wermter", "Stefan", ""]]}, {"id": "1810.06765", "submitter": "Vithya Yogarajan", "authors": "Vithya Yogarajan, Michael Mayo and Bernhard Pfahringer", "title": "A survey of automatic de-identification of longitudinal clinical\n  narratives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Use of medical data, also known as electronic health records, in research\nhelps develop and advance medical science. However, protecting patient\nconfidentiality and identity while using medical data for analysis is crucial.\nMedical data can be in the form of tabular structures (i.e. tables), free-form\nnarratives, and images. This study focuses on medical data in the free form\nlongitudinal text. De-identification of electronic health records provides the\nopportunity to use such data for research without it affecting patient privacy,\nand avoids the need for individual patient consent. In recent years there is\nincreasing interest in developing an accurate, robust and adaptable automatic\nde-identification system for electronic health records. This is mainly due to\nthe dilemma between the availability of an abundance of health data, and the\ninability to use such data in research due to legal and ethical restrictions.\nDe-identification tracks in competitions such as the 2014 i2b2 UTHealth and the\n2016 CEGS N-GRID shared tasks have provided a great platform to advance this\narea. The primary reasons for this include the open source nature of the\ndataset and the fact that raw psychiatric data were used for 2016 competitions.\nThis study focuses on noticeable trend changes in the techniques used in the\ndevelopment of automatic de-identification for longitudinal clinical\nnarratives. More specifically, the shift from using conditional random fields\n(CRF) based systems only or rules (regular expressions, dictionary or\ncombinations) based systems only, to hybrid models (combining CRF and rules),\nand more recently to deep learning based systems. We review the literature and\nresults that arose from the 2014 and the 2016 competitions and discuss the\noutcomes of these systems. We also provide a list of research questions that\nemerged from this survey.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 00:26:39 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Yogarajan", "Vithya", ""], ["Mayo", "Michael", ""], ["Pfahringer", "Bernhard", ""]]}, {"id": "1810.06839", "submitter": "Alex Nowak-Vila", "authors": "Alex Nowak-Vila (SIERRA, PSL), Francis Bach (SIERRA, PSL), Alessandro\n  Rudi (SIERRA, PSL)", "title": "Sharp Analysis of Learning with Discrete Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of devising learning strategies for discrete losses (e.g.,\nmultilabeling, ranking) is currently addressed with methods and theoretical\nanalyses ad-hoc for each loss. In this paper we study a least-squares framework\nto systematically design learning algorithms for discrete losses, with\nquantitative characterizations in terms of statistical and computational\ncomplexity. In particular we improve existing results by providing explicit\ndependence on the number of labels for a wide class of losses and faster\nlearning rates in conditions of low-noise. Theoretical results are complemented\nwith experiments on real datasets, showing the effectiveness of the proposed\ngeneral approach.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 06:44:42 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Nowak-Vila", "Alex", "", "SIERRA, PSL"], ["Bach", "Francis", "", "SIERRA, PSL"], ["Rudi", "Alessandro", "", "SIERRA, PSL"]]}, {"id": "1810.06985", "submitter": "Yakov Savelyev", "authors": "Yasha Savelyev", "title": "Non-computability of human intelligence", "comments": "This paper is completely superseded by arXiv:2001.07592. The latter\n  paper is a completely mathematical approach to the problem, fixing issues in\n  formalization of the thought experiment used in the former", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO physics.hist-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the question (most famously) initiated by Turing: can human\nintelligence be completely modeled by a Turing machine? We show that the answer\nis \\emph{no}, assuming a certain weak soundness hypothesis. More specifically\nwe show that at least some meaningful thought processes of the brain cannot be\nTuring computable. In particular some physical processes are not Turing\ncomputable, which is not entirely expected. There are some similarities of our\nargument with the well known Lucas-Penrose argument, but we work purely on the\nlevel of Turing machines, and do not use G\\\"odel's incompleteness theorem or\nany direct analogue. Instead we construct directly and use a weak analogue of a\nG\\\"odel statement for a certain system which involves our human, this allows us\nto side-step some (possible) meta-logical issues with their argument.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 20:16:21 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 20:18:45 GMT"}, {"version": "v3", "created": "Mon, 31 Dec 2018 15:12:29 GMT"}, {"version": "v4", "created": "Mon, 28 Jan 2019 18:49:29 GMT"}, {"version": "v5", "created": "Mon, 4 Feb 2019 20:46:00 GMT"}, {"version": "v6", "created": "Sun, 31 Mar 2019 20:59:56 GMT"}, {"version": "v7", "created": "Tue, 18 Jun 2019 19:52:54 GMT"}, {"version": "v8", "created": "Wed, 22 Jan 2020 14:11:17 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Savelyev", "Yasha", ""]]}, {"id": "1810.06986", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "Rough Concept Analysis", "comments": "10 pages, 3 tables", "journal-ref": "Workshops in Computing: Rough Sets, Fuzzy Sets and Knowledge\n  Discovery, 1994. Conference Proceedings of the International Workshop on\n  Rough Sets and Knowledge Discovery (RSKD'93)", "doi": null, "report-no": null, "categories": "cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory introduced, presented and developed in this paper, is concerned\nwith Rough Concept Analysis. This theory is a synthesis of the theory of Rough\nSets pioneered by Zdzislaw Pawlak with the theory of Formal Concept Analysis\npioneered by Rudolf Wille. The central notion in this paper of a rough formal\nconcept combines in a natural fashion the notion of a rough set with the notion\nof a formal concept: \"rough set + formal concept = rough formal concept\". A\nfollow-up paper will provide a synthesis of the two important data modeling\ntechniques: conceptual scaling of Formal Concept Analysis and\nEntity-Relationship database modeling.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 18:26:04 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1810.07007", "submitter": "Naveen Sundar Govindarajulu", "authors": "Selmer Bringsjord, Naveen Sundar Govindarajulu, Atriya Sen, Matthew\n  Peveler, Biplav Srivastava, Kartik Talamadupula", "title": "Tentacular Artificial Intelligence, and the Architecture Thereof,\n  Introduced", "comments": "FAIM Workshop on Architectures And Evaluation For Generality,\n  Autonomy & Progress in AI July 15, 2018, Stockholm, Sweden, 1st International\n  Workshop Held In Conjunction With IJCAI-ECAI 2018, Aamas 2018 and ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We briefly introduce herein a new form of distributed, multi-agent artificial\nintelligence, which we refer to as \"tentacular.\" Tentacular AI is distinguished\nby six attributes, which among other things entail a capacity for reasoning and\nplanning based in highly expressive calculi (logics), and which enlists\nsubsidiary agents across distances circumscribed only by the reach of one or\nmore given networks.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 02:37:46 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Bringsjord", "Selmer", ""], ["Govindarajulu", "Naveen Sundar", ""], ["Sen", "Atriya", ""], ["Peveler", "Matthew", ""], ["Srivastava", "Biplav", ""], ["Talamadupula", "Kartik", ""]]}, {"id": "1810.07096", "submitter": "Luciano Serafini", "authors": "Luciano Serafini and Paolo Traverso", "title": "Incremental learning abstract discrete planning domains and mappings to\n  continuous perceptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the works on planning and learning, e.g., planning by (model based)\nreinforcement learning, are based on two main assumptions: (i) the set of\nstates of the planning domain is fixed; (ii) the mapping between the\nobservations from the real word and the states is implicitly assumed or learned\noffline, and it is not part of the planning domain. Consequently, the focus is\non learning the transitions between states. In this paper, we drop such\nassumptions. We provide a formal framework in which (i) the agent can learn\ndynamically new states of the planning domain; (ii) the mapping between\nabstract states and the perception from the real world, represented by\ncontinuous variables, is part of the planning domain; (iii) such mapping is\nlearned and updated along the \"life\" of the agent. We define an algorithm that\ninterleaves planning, acting, and learning, and allows the agent to update the\nplanning domain depending on how much it trusts the model w.r.t. the new\nexperiences learned by executing actions. We define a measure of coherence\nbetween the planning domain and the real world as perceived by the agent. We\ntest our approach showing that the agent learns increasingly coherent models,\nand that the system can scale to deal with models with an order of $10^6$\nstates.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 15:53:22 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 10:55:58 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Serafini", "Luciano", ""], ["Traverso", "Paolo", ""]]}, {"id": "1810.07132", "submitter": "Wei Dai", "authors": "Wei Dai, Kenji Yoshigoe, William Parsley", "title": "Improving Data Quality through Deep Learning and Statistical Models", "comments": "8 pages, 6 figures, and 3 tables", "journal-ref": "Dai, Wei, Kenji Yoshigoe, and William Parsley. \"Improving Data\n  Quality Through Deep Learning and Statistical Models.\" In Information\n  Technology-New Generations, pp. 515-522. Springer, Cham, 2018", "doi": "10.1007/978-3-319-54978-1_66", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional data quality control methods are based on users experience or\npreviously established business rules, and this limits performance in addition\nto being a very time consuming process with lower than desirable accuracy.\nUtilizing deep learning, we can leverage computing resources and advanced\ntechniques to overcome these challenges and provide greater value to users. In\nthis paper, we, the authors, first review relevant works and discuss machine\nlearning techniques, tools, and statistical quality models. Second, we offer a\ncreative data quality framework based on deep learning and statistical model\nalgorithm for identifying data quality. Third, we use data involving salary\nlevels from an open dataset published by the state of Arkansas to demonstrate\nhow to identify outlier data and how to improve data quality via deep learning.\nFinally, we discuss future work.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 16:57:07 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Dai", "Wei", ""], ["Yoshigoe", "Kenji", ""], ["Parsley", "William", ""]]}, {"id": "1810.07151", "submitter": "Kirill Neklyudov", "authors": "Kirill Neklyudov, Evgenii Egorov, Pavel Shvechikov, Dmitry Vetrov", "title": "Metropolis-Hastings view on variational inference and adversarial\n  training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant part of MCMC methods can be considered as the\nMetropolis-Hastings (MH) algorithm with different proposal distributions. From\nthis point of view, the problem of constructing a sampler can be reduced to the\nquestion - how to choose a proposal for the MH algorithm? To address this\nquestion, we propose to learn an independent sampler that maximizes the\nacceptance rate of the MH algorithm, which, as we demonstrate, is highly\nrelated to the conventional variational inference. For Bayesian inference, the\nproposed method compares favorably against alternatives to sample from the\nposterior distribution. Under the same approach, we step beyond the scope of\nclassical MCMC methods and deduce the Generative Adversarial Networks (GANs)\nframework from scratch, treating the generator as the proposal and the\ndiscriminator as the acceptance test. On real-world datasets, we improve\nFrechet Inception Distance and Inception Score, using different GANs as a\nproposal distribution for the MH algorithm. In particular, we demonstrate\nimprovements of recently proposed BigGAN model on ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:26:24 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 14:23:34 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Neklyudov", "Kirill", ""], ["Egorov", "Evgenii", ""], ["Shvechikov", "Pavel", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1810.07159", "submitter": "Shuai Zhao", "authors": "Shuai Zhao, Manoop Talasila, Guy Jacobson, Cristian Borcea, Syed Anwar\n  Aftab, John F Murray", "title": "Packaging and Sharing Machine Learning Models via the Acumos AI Open\n  Platform", "comments": "ICMLA 2018: International Conference on Machine Learning and\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying Machine Learning (ML) to business applications for automation\nusually faces difficulties when integrating diverse ML dependencies and\nservices, mainly because of the lack of a common ML framework. In most cases,\nthe ML models are developed for applications which are targeted for specific\nbusiness domain use cases, leading to duplicated effort, and making reuse\nimpossible. This paper presents Acumos, an open platform capable of packaging\nML models into portable containerized microservices which can be easily shared\nvia the platform's catalog, and can be integrated into various business\napplications. We present a case study of packaging sentiment analysis and\nclassification ML models via the Acumos platform, permitting easy sharing with\nothers. We demonstrate that the Acumos platform reduces the technical burden on\napplication developers when applying machine learning models to their business\napplications. Furthermore, the platform allows the reuse of readily available\nML microservices in various business domains.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:39:53 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Zhao", "Shuai", ""], ["Talasila", "Manoop", ""], ["Jacobson", "Guy", ""], ["Borcea", "Cristian", ""], ["Aftab", "Syed Anwar", ""], ["Murray", "John F", ""]]}, {"id": "1810.07167", "submitter": "Gregory Kahn", "authors": "Gregory Kahn, Adam Villaflor, Pieter Abbeel, Sergey Levine", "title": "Composable Action-Conditioned Predictors: Flexible Off-Policy Learning\n  for Robot Navigation", "comments": "Accepted to the Conference on Robot Learning (CoRL) 2018. Video at\n  https://youtu.be/lOLT7zifEkg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general-purpose intelligent robot must be able to learn autonomously and be\nable to accomplish multiple tasks in order to be deployed in the real world.\nHowever, standard reinforcement learning approaches learn separate\ntask-specific policies and assume the reward function for each task is known a\npriori. We propose a framework that learns event cues from off-policy data, and\ncan flexibly combine these event cues at test time to accomplish different\ntasks. These event cue labels are not assumed to be known a priori, but are\ninstead labeled using learned models, such as computer vision detectors, and\nthen `backed up' in time using an action-conditioned predictive model. We show\nthat a simulated robotic car and a real-world RC car can gather data and train\nfully autonomously without any human-provided labels beyond those needed to\ntrain the detectors, and then at test-time be able to accomplish a variety of\ndifferent tasks. Videos of the experiments and code can be found at\nhttps://github.com/gkahn13/CAPs\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:49:43 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Kahn", "Gregory", ""], ["Villaflor", "Adam", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1810.07180", "submitter": "Yanjie Wang", "authors": "Yanjie Wang, Daniel Ruffinelli, Rainer Gemulla, Samuel Broscheit,\n  Christian Meilicke", "title": "On Evaluating Embedding Models for Knowledge Base Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases contribute to many web search and mining tasks, yet they are\noften incomplete. To add missing facts to a given knowledge base, various\nembedding models have been proposed in the recent literature. Perhaps\nsurprisingly, relatively simple models with limited expressiveness often\nperformed remarkably well under today's most commonly used evaluation\nprotocols. In this paper, we explore whether recent models work well for\nknowledge base completion and argue that the current evaluation protocols are\nmore suited for question answering rather than knowledge base completion. We\nshow that when focusing on a different prediction task for evaluating knowledge\nbase completion, the performance of current embedding models is unsatisfactory\neven on datasets previously thought to be too easy. This is especially true\nwhen embedding models are compared against a simple rule-based baseline. This\nwork indicates the need for more research into the embedding models and\nevaluation protocols for knowledge base completion.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 14:09:10 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 13:30:39 GMT"}, {"version": "v3", "created": "Thu, 20 Dec 2018 11:28:19 GMT"}, {"version": "v4", "created": "Thu, 31 Jan 2019 19:22:59 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Wang", "Yanjie", ""], ["Ruffinelli", "Daniel", ""], ["Gemulla", "Rainer", ""], ["Broscheit", "Samuel", ""], ["Meilicke", "Christian", ""]]}, {"id": "1810.07207", "submitter": "Ryan Sweke Mr", "authors": "Ryan Sweke, Markus S. Kesselring, Evert P. L. van Nieuwenburg, Jens\n  Eisert", "title": "Reinforcement Learning Decoders for Fault-Tolerant Quantum Computation", "comments": "15 pages, 11 figures, associated code repository available at\n  https://github.com/R-Sweke/DeepQ-Decoding", "journal-ref": "Mach. Learn. Sci. Technol. 2, 025005 (2021)", "doi": "10.1088/2632-2153/abc609", "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Topological error correcting codes, and particularly the surface code,\ncurrently provide the most feasible roadmap towards large-scale fault-tolerant\nquantum computation. As such, obtaining fast and flexible decoding algorithms\nfor these codes, within the experimentally relevant context of faulty syndrome\nmeasurements, is of critical importance. In this work, we show that the problem\nof decoding such codes, in the full fault-tolerant setting, can be naturally\nreformulated as a process of repeated interactions between a decoding agent and\na code environment, to which the machinery of reinforcement learning can be\napplied to obtain decoding agents. As a demonstration, by using deepQ learning,\nwe obtain fast decoding agents for the surface code, for a variety of\nnoise-models.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 18:01:57 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Sweke", "Ryan", ""], ["Kesselring", "Markus S.", ""], ["van Nieuwenburg", "Evert P. L.", ""], ["Eisert", "Jens", ""]]}, {"id": "1810.07225", "submitter": "Yanfu Zhang", "authors": "Yanfu Zhang, Wenshan Wang, Rogerio Bonatti, Daniel Maturana, Sebastian\n  Scherer", "title": "Integrating kinematics and environment context into deep inverse\n  reinforcement learning for predicting off-road vehicle trajectories", "comments": "CoRL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the motion of a mobile agent from a third-person perspective is an\nimportant component for many robotics applications, such as autonomous\nnavigation and tracking. With accurate motion prediction of other agents,\nrobots can plan for more intelligent behaviors to achieve specified objectives,\ninstead of acting in a purely reactive way. Previous work addresses motion\nprediction by either only filtering kinematics, or using hand-designed and\nlearned representations of the environment. Instead of separating kinematic and\nenvironmental context, we propose a novel approach to integrate both into an\ninverse reinforcement learning (IRL) framework for trajectory prediction.\nInstead of exponentially increasing the state-space complexity with kinematics,\nwe propose a two-stage neural network architecture that considers motion and\nenvironment together to recover the reward function. The first-stage network\nlearns feature representations of the environment using low-level LiDAR\nstatistics and the second-stage network combines those learned features with\nkinematics data. We collected over 30 km of off-road driving data and validated\nexperimentally that our method can effectively extract useful environmental and\nkinematic features. We generate accurate predictions of the distribution of\nfuture trajectories of the vehicle, encoding complex behaviors such as\nmulti-modal distributions at road intersections, and even show different\npredictions at the same intersection depending on the vehicle's speed.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 18:40:34 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Zhang", "Yanfu", ""], ["Wang", "Wenshan", ""], ["Bonatti", "Rogerio", ""], ["Maturana", "Daniel", ""], ["Scherer", "Sebastian", ""]]}, {"id": "1810.07232", "submitter": "Robert Kent", "authors": "Robert E. Kent and Christian Neuss", "title": "Conceptual Analysis of Hypertext", "comments": "19 pages, 3 figures, 5 tables", "journal-ref": "In Charles Nicholas and James Mayfield, editors, Intelligent\n  Hypertext: Advanced Techniques for the World Wide Web, volume 1326 of Lecture\n  Note Computer Science, pages 70-89. Springer, 1997. Invited chapter", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter tools and techniques from the mathematical theory of formal\nconcept analysis are applied to hypertext systems in general, and the World\nWide Web in particular. Various processes for the conceptual structuring of\nhypertext are discussed: summarization, conceptual scaling, and the creation of\nconceptual links. Well-known interchange formats for summarizing networked\ninformation resources as resource meta-information are reviewed, and two new\ninterchange formats originating from formal concept analysis are advocated.\nAlso reviewed is conceptual scaling, which provides a principled approach to\nthe faceted analysis techniques in library science classification. The\nimportant notion of conceptual linkage is introduced as a generalization of a\nhyperlink. The automatic hyperization of the content of legacy data is\ndescribed, and the composite conceptual structuring with hypertext linkage is\ndefined. For the conceptual empowerment of the Web user, a new technique called\nconceptual browsing is advocated. Conceptual browsing, which browses over\nconceptual links, is dual mode (extensional versus intensional) and dual scope\n(global versus local).\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 18:56:33 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Kent", "Robert E.", ""], ["Neuss", "Christian", ""]]}, {"id": "1810.07242", "submitter": "Muhammad Usama", "authors": "Muhammad Usama, Junaid Qadir, Ala Al-Fuqaha", "title": "Adversarial Attacks on Cognitive Self-Organizing Networks: The Challenge\n  and the Way Forward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future communications and data networks are expected to be largely cognitive\nself-organizing networks (CSON). Such networks will have the essential property\nof cognitive self-organization, which can be achieved using machine learning\ntechniques (e.g., deep learning). Despite the potential of these techniques,\nthese techniques in their current form are vulnerable to adversarial attacks\nthat can cause cascaded damages with detrimental consequences for the whole\nnetwork. In this paper, we explore the effect of adversarial attacks on CSON.\nOur experiments highlight the level of threat that CSON have to deal with in\norder to meet the challenges of next-generation networks and point out\npromising directions for future work.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 10:25:17 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Usama", "Muhammad", ""], ["Qadir", "Junaid", ""], ["Al-Fuqaha", "Ala", ""]]}, {"id": "1810.07254", "submitter": "Amos Azaria", "authors": "Yitzhak Spielberg, Amos Azaria", "title": "The Concept of Criticality in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning methods carry a well known bias-variance trade-off in\nn-step algorithms for optimal control. Unfortunately, this has rarely been\naddressed in current research. This trade-off principle holds independent of\nthe choice of the algorithm, such as n-step SARSA, n-step Expected SARSA or\nn-step Tree backup. A small n results in a large bias, while a large n leads to\nlarge variance. The literature offers no straightforward recipe for the best\nchoice of this value. While currently all n-step algorithms use a fixed value\nof n over the state space we extend the framework of n-step updates by allowing\neach state to have its specific n.\n  We propose a solution to this problem within the context of human aided\nreinforcement learning. Our approach is based on the observation that a human\ncan learn more efficiently if she receives input regarding the criticality of a\ngiven state and thus the amount of attention she needs to invest into the\nlearning in that state. This observation is related to the idea that each state\nof the MDP has a certain measure of criticality which indicates how much the\nchoice of the action in that state influences the return. In our algorithm the\nRL agent utilizes the criticality measure, a function provided by a human\ntrainer, in order to locally choose the best stepnumber n for the update of the\nQ function.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 20:07:06 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Spielberg", "Yitzhak", ""], ["Azaria", "Amos", ""]]}, {"id": "1810.07286", "submitter": "Vlad Firoiu", "authors": "Vlad Firoiu, Tina Ju, Josh Tenenbaum", "title": "At Human Speed: Deep Reinforcement Learning with Action Delay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been a recent explosion in the capabilities of game-playing\nartificial intelligence. Many classes of tasks, from video games to motor\ncontrol to board games, are now solvable by fairly generic algorithms, based on\ndeep learning and reinforcement learning, that learn to play from experience\nwith minimal prior knowledge. However, these machines often do not win through\nintelligence alone -- they possess vastly superior speed and precision,\nallowing them to act in ways a human never could. To level the playing field,\nwe restrict the machine's reaction time to a human level, and find that\nstandard deep reinforcement learning methods quickly drop in performance. We\npropose a solution to the action delay problem inspired by human perception --\nto endow agents with a neural predictive model of the environment which\n\"undoes\" the delay inherent in their environment -- and demonstrate its\nefficacy against professional players in Super Smash Bros. Melee, a popular\nconsole fighting game.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 21:36:35 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Firoiu", "Vlad", ""], ["Ju", "Tina", ""], ["Tenenbaum", "Josh", ""]]}, {"id": "1810.07307", "submitter": "Rafik Hadfi", "authors": "Rafik Hadfi", "title": "Solving Tree Problems with Category Theory", "comments": "10 pages, 4 figures, International Conference on Artificial General\n  Intelligence (AGI) 2018", "journal-ref": "Hadfi R. (2018) Solving Tree Problems with Category Theory. In:\n  Ikl\\'e M., Franz A., Rzepka R., Goertzel B. (eds) Artificial General\n  Intelligence. AGI 2018. Lecture Notes in Computer Science, vol 10999.\n  Springer, Cham", "doi": "10.1007/978-3-319-97676-1_7", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) has long pursued models, theories, and\ntechniques to imbue machines with human-like general intelligence. Yet even the\ncurrently predominant data-driven approaches in AI seem to be lacking humans'\nunique ability to solve wide ranges of problems. This situation begs the\nquestion of the existence of principles that underlie general problem-solving\ncapabilities. We approach this question through the mathematical formulation of\nanalogies across different problems and solutions. We focus in particular on\nproblems that could be represented as tree-like structures. Most importantly,\nwe adopt a category-theoretic approach in formalising tree problems as\ncategories, and in proving the existence of equivalences across apparently\nunrelated problem domains. We prove the existence of a functor between the\ncategory of tree problems and the category of solutions. We also provide a\nweaker version of the functor by quantifying equivalences of problem categories\nusing a metric on tree problems.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 23:06:48 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Hadfi", "Rafik", ""]]}, {"id": "1810.07311", "submitter": "Yuu Jinnai", "authors": "Yuu Jinnai, David Abel, D Ellis Hershkowitz, Michael Littman, George\n  Konidaris", "title": "Finding Options that Minimize Planning Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize the problem of selecting the optimal set of options for planning\nas that of computing the smallest set of options so that planning converges in\nless than a given maximum of value-iteration passes. We first show that the\nproblem is NP-hard, even if the task is constrained to be deterministic---the\nfirst such complexity result for option discovery. We then present the first\npolynomial-time boundedly suboptimal approximation algorithm for this setting,\nand empirically evaluate it against both the optimal options and a\nrepresentative collection of heuristic approaches in simple grid-based domains\nincluding the classic four-rooms problem.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 23:24:18 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 19:04:14 GMT"}, {"version": "v3", "created": "Sat, 16 Mar 2019 20:08:18 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Jinnai", "Yuu", ""], ["Abel", "David", ""], ["Hershkowitz", "D Ellis", ""], ["Littman", "Michael", ""], ["Konidaris", "George", ""]]}, {"id": "1810.07460", "submitter": "Jan Romportl", "authors": "Eva Zackova and Jan Romportl", "title": "What might matter in autonomous cars adoption: first person versus third\n  person scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discussion between the automotive industry, governments, ethicists,\npolicy makers and general public about autonomous cars' moral agency is\nwidening, and therefore we see the need to bring more insight into what\nmeta-factors might actually influence the outcomes of such discussions, surveys\nand plebiscites. In our study, we focus on the psychological (personality\ntraits), practical (active driving experience), gender and rhetoric/framing\nfactors that might impact and even determine respondents' a priori preferences\nof autonomous cars' operation. We conducted an online survey (N=430) to collect\ndata that show that the third person scenario is less biased than the first\nperson scenario when presenting ethical dilemma related to autonomous cars.\nAccording to our analysis, gender bias should be explored in more extensive\nfuture studies as well. We recommend any participatory technology assessment\ndiscourse to use the third person scenario and to direct attention to the way\nany autonomous car related debate is introduced, especially in terms of\nlinguistic and communication aspects and gender.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 10:24:22 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Zackova", "Eva", ""], ["Romportl", "Jan", ""]]}, {"id": "1810.07528", "submitter": "David Gunning", "authors": "David Gunning", "title": "Machine Common Sense Concept Paper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarizes some of the technical background, research ideas, and\npossible development strategies for achieving machine common sense. Machine\ncommon sense has long been a critical-but-missing component of Artificial\nIntelligence (AI). Recent advances in machine learning have resulted in new AI\ncapabilities, but in all of these applications, machine reasoning is narrow and\nhighly specialized. Developers must carefully train or program systems for\nevery situation. General commonsense reasoning remains elusive. The absence of\ncommon sense prevents intelligent systems from understanding their world,\nbehaving reasonably in unforeseen situations, communicating naturally with\npeople, and learning from new experiences. Its absence is perhaps the most\nsignificant barrier between the narrowly focused AI applications we have today\nand the more general, human-like AI systems we would like to build in the\nfuture. Machine common sense remains a broad, potentially unbounded problem in\nAI. There are a wide range of strategies that could be employed to make\nprogress on this difficult challenge. This paper discusses two diverse\nstrategies for focusing development on two different machine commonsense\nservices: (1) a service that learns from experience, like a child, to construct\ncomputational models that mimic the core domains of child cognition for objects\n(intuitive physics), agents (intentional actors), and places (spatial\nnavigation); and (2) service that learns from reading the Web, like a research\nlibrarian, to construct a commonsense knowledge repository capable of answering\nnatural language and image-based questions about commonsense phenomena.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 13:31:41 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Gunning", "David", ""]]}, {"id": "1810.07632", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "Conceptual Collectives", "comments": "30 pages, 11 tables, 4 figures, technical report 1992", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notions of formal contexts and concept lattices, although introduced by\nWille only ten years ago, already have proven to be of great utility in various\napplications such as data analysis and knowledge representation. In this paper\nwe give arguments that Wille's original notion of formal context, although\nquite appealing in its simplicity, now should be replaced by a more semantic\nnotion. This new notion of formal context entails a modified approach to\nconcept construction. We base our arguments for these new versions of formal\ncontext and concept construction upon Wille's philosophical attitude with\nreference to the intensional aspect of concepts. We give a brief development of\nthe relational theory of formal contexts and concept construction,\ndemonstrating the equivalence of \"concept-lattice construction\" of Wille with\nthe well-known \"completion by cuts\" of MacNeille. Generalization and\nabstraction of these formal contexts offers a powerful approach to knowledge\nrepresentation.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 19:11:19 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1810.07778", "submitter": "Kunkun Pang", "authors": "Kunkun Pang, Mingzhi Dong, Yang Wu, Timothy M. Hospedales", "title": "Dynamic Ensemble Active Learning: A Non-Stationary Bandit with Expert\n  Advice", "comments": "This work has been accepted at ICPR2018 and won Piero Zamperoni Best\n  Student Paper Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning aims to reduce annotation cost by predicting which samples\nare useful for a human teacher to label. However it has become clear there is\nno best active learning algorithm. Inspired by various philosophies about what\nconstitutes a good criteria, different algorithms perform well on different\ndatasets. This has motivated research into ensembles of active learners that\nlearn what constitutes a good criteria in a given scenario, typically via\nmulti-armed bandit algorithms. Though algorithm ensembles can lead to better\nresults, they overlook the fact that not only does algorithm efficacy vary\nacross datasets, but also during a single active learning session. That is, the\nbest criteria is non-stationary. This breaks existing algorithms' guarantees\nand hampers their performance in practice. In this paper, we propose dynamic\nensemble active learning as a more general and promising research direction. We\ndevelop a dynamic ensemble active learner based on a non-stationary multi-armed\nbandit with expert advice algorithm. Our dynamic ensemble selects the right\ncriteria at each step of active learning. It has theoretical guarantees, and\nshows encouraging results on $13$ popular datasets.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 14:29:02 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Pang", "Kunkun", ""], ["Dong", "Mingzhi", ""], ["Wu", "Yang", ""], ["Hospedales", "Timothy M.", ""]]}, {"id": "1810.08040", "submitter": "Radom\\'ir Hala\\v{s}", "authors": "Radom\\'ir Hala\\v{s}, Radko Mesiar, Jozef P\\'ocs", "title": "Description of sup- and inf-preserving aggregation functions via\n  families of clusters in data tables", "comments": "24 pages", "journal-ref": null, "doi": "10.1016/j.ins.2017.02.060", "report-no": null, "categories": "cs.LO cs.AI math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connection between the theory of aggregation functions and formal concept\nanalysis is discussed and studied, thus filling a gap in the literature by\nbuilding a bridge between these two theories, one of them living in the world\nof data fusion, the second one in the area of data mining. We show how Galois\nconnections can be used to describe an important class of aggregation functions\npreserving suprema, and, by duality, to describe aggregation functions\npreserving infima. Our discovered method gives an elegant and complete\ndescription of these classes. Also possible applications of our results within\ncertain biclustering fuzzy FCA-based methods are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 07:51:48 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Hala\u0161", "Radom\u00edr", ""], ["Mesiar", "Radko", ""], ["P\u00f3cs", "Jozef", ""]]}, {"id": "1810.08059", "submitter": "Alok Chauhan", "authors": "Nikolas Klug, Alok Chauhan, Ramesh Ragala, V Vijayakumar", "title": "k-RNN: Extending NN-heuristics for the TSP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an extension of existing Nearest-Neighbor heuristics\nto an algorithm called k-Repetitive-Nearest-Neighbor. The idea is to start with\na tour of k nodes and then perform a Nearest-Neighbor search from there on.\nAfter doing this for all permutations of k nodes the result gets selected as\nthe shortest tour found. Experimental results show that for 2-RNN the solutions\nquality remains relatively stable between about 10% to 40% above the optimum.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 11:32:15 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Klug", "Nikolas", ""], ["Chauhan", "Alok", ""], ["Ragala", "Ramesh", ""], ["Vijayakumar", "V", ""]]}, {"id": "1810.08074", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "The Institutional Approach", "comments": "24 pages, 8 figures. The original publication is available at\n  https://link.springer.com/chapter/10.1007/978-90-481-8847-5_23", "journal-ref": "In: Poli R., Healy M., Kameas A. (eds.). Pages 533-563. Theory and\n  Applications of Ontology: Computer Applications. 12 August 2010. Springer,\n  Dordrecht", "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter discusses the institutional approach for organizing and\nmaintaining ontologies. The theory of institutions was named and initially\ndeveloped by Joseph Goguen and Rod Burstall. This theory, a metatheory based on\ncategory theory, regards ontologies as logical theories or local logics. The\ntheory of institutions uses the category-theoretic ideas of fibrations and\nindexed categories to develop logical theories. Institutions unite the lattice\napproach of Formal Concept Analysis of Ganter and Wille with the distributed\nlogic of Information Flow of Barwise and Seligman. The institutional approach\nincorporates locally the lattice of theories idea of Sowa from the theory of\nknowledge representation. The Information Flow Framework, which was initiated\nwithin the IEEE Standard Upper Ontology project, uses the institutional\napproach in its applied aspect for the comparison, semantic integration and\nmaintenance of ontologies. This chapter explains the central ideas of the\ninstitutional approach to ontologies in a careful and detailed manner.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 17:59:56 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1810.08124", "submitter": "Lina Al-Kanj Dr.", "authors": "Lina Al-Kanj, Juliana Nascimento and Warren B. Powell", "title": "Approximate Dynamic Programming for Planning a Ride-Sharing System using\n  Autonomous Fleets of Electric Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within a decade, almost every major auto company, along with fleet operators\nsuch as Uber, have announced plans to put autonomous vehicles on the road. At\nthe same time, electric vehicles are quickly emerging as a next-generation\ntechnology that is cost effective, in addition to offering the benefits of\nreducing the carbon footprint. The combination of a centrally managed fleet of\ndriverless vehicles, along with the operating characteristics of electric\nvehicles, is creating a transformative new technology that offers significant\ncost savings with high service levels. This problem involves a dispatch problem\nfor assigning riders to cars, a surge pricing problem for deciding on the price\nper trip and a planning problem for deciding on the fleet size. We use\napproximate dynamic programming to develop high-quality operational dispatch\nstrategies to determine which car is best for a particular trip, when a car\nshould be recharged, and when it should be re-positioned to a different zone\nwhich offers a higher density of trips. We prove that the value functions are\nmonotone in the battery and time dimensions and use hierarchical aggregation to\nget better estimates of the value functions with a small number of\nobservations. Then, surge pricing is discussed using an adaptive learning\napproach to decide on the price for each trip. Finally, we discuss the fleet\nsize problem which depends on the previous two problems.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 15:54:58 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 22:57:04 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Al-Kanj", "Lina", ""], ["Nascimento", "Juliana", ""], ["Powell", "Warren B.", ""]]}, {"id": "1810.08159", "submitter": "Sandhya Saisubramanian", "authors": "Sandhya Saisubramanian, Kyle Hollins Wray, Luis Pineda, Shlomo\n  Zilberstein", "title": "Planning in Stochastic Environments with Goal Uncertainty", "comments": "6 pages, IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS) 2019", "journal-ref": "2019 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS), Macau, China, 2019, pp. 1649-1654", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Goal Uncertain Stochastic Shortest Path (GUSSP) problem -- a\ngeneral framework to model path planning and decision making in stochastic\nenvironments with goal uncertainty. The framework extends the stochastic\nshortest path (SSP) model to dynamic environments in which it is impossible to\ndetermine the exact goal states ahead of plan execution. GUSSPs introduce\nflexibility in goal specification by allowing a belief over possible goal\nconfigurations. The unique observations at potential goals helps the agent\nidentify the true goal during plan execution. The partial observability is\nrestricted to goals, facilitating the reduction to an SSP with a modified state\nspace. We formally define a GUSSP and discuss its theoretical properties. We\nthen propose an admissible heuristic that reduces the planning time using\nFLARES -- a start-of-the-art probabilistic planner. We also propose a\ndeterminization approach for solving this class of problems. Finally, we\npresent empirical results on a search and rescue mobile robot and three other\nproblem domains in simulation.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 16:56:09 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 23:18:14 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Saisubramanian", "Sandhya", ""], ["Wray", "Kyle Hollins", ""], ["Pineda", "Luis", ""], ["Zilberstein", "Shlomo", ""]]}, {"id": "1810.08163", "submitter": "Steven Hansen", "authors": "Steven Hansen, Pablo Sprechmann, Alexander Pritzel, Andr\\'e Barreto,\n  Charles Blundell", "title": "Fast deep reinforcement learning using online adjustments from the past", "comments": "Accepted at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Ephemeral Value Adjusments (EVA): a means of allowing deep\nreinforcement learning agents to rapidly adapt to experience in their replay\nbuffer. EVA shifts the value predicted by a neural network with an estimate of\nthe value function found by planning over experience tuples from the replay\nbuffer near the current state. EVA combines a number of recent ideas around\ncombining episodic memory-like structures into reinforcement learning agents:\nslot-based storage, content-based retrieval, and memory-based planning. We show\nthat EVAis performant on a demonstration task and Atari games.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 17:00:20 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Hansen", "Steven", ""], ["Sprechmann", "Pablo", ""], ["Pritzel", "Alexander", ""], ["Barreto", "Andr\u00e9", ""], ["Blundell", "Charles", ""]]}, {"id": "1810.08170", "submitter": "Daniel Rodr\\'iguez-Chavarr\\'ia", "authors": "Daniel Rodr\\'iguez-Chavarr\\'ia, Miguel A. Guti\\'errez-Naranjo and\n  Joaqu\\'in Borrego-D\\'iaz", "title": "Logic Negation with Spiking Neural P Systems", "comments": "25 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the success of neural networks as reasoning systems is doubtless.\nNonetheless, one of the drawbacks of such reasoning systems is that they work\nas black-boxes and the acquired knowledge is not human readable. In this paper,\nwe present a new step in order to close the gap between connectionist and logic\nbased reasoning systems. We show that two of the most used inference rules for\nobtaining negative information in rule based reasoning systems, the so-called\nClosed World Assumption and Negation as Finite Failure can be characterized by\nmeans of spiking neural P systems, a formal model of the third generation of\nneural networks born in the framework of membrane computing.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 17:22:30 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 16:26:25 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Rodr\u00edguez-Chavarr\u00eda", "Daniel", ""], ["Guti\u00e9rrez-Naranjo", "Miguel A.", ""], ["Borrego-D\u00edaz", "Joaqu\u00edn", ""]]}, {"id": "1810.08178", "submitter": "Amir Erfan Eshratifar", "authors": "Amir Erfan Eshratifar, David Eigen, Massoud Pedram", "title": "Gradient Agreement as an Optimization Objective for Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel optimization method for maximizing generalization\nover tasks in meta-learning. The goal of meta-learning is to learn a model for\nan agent adapting rapidly when presented with previously unseen tasks. Tasks\nare sampled from a specific distribution which is assumed to be similar for\nboth seen and unseen tasks. We focus on a family of meta-learning methods\nlearning initial parameters of a base model which can be fine-tuned quickly on\na new task, by few gradient steps (MAML). Our approach is based on pushing the\nparameters of the model to a direction in which tasks have more agreement upon.\nIf the gradients of a task agree with the parameters update vector, then their\ninner product will be a large positive value. As a result, given a batch of\ntasks to be optimized for, we associate a positive (negative) weight to the\nloss function of a task, if the inner product between its gradients and the\naverage of the gradients of all tasks in the batch is a positive (negative)\nvalue. Therefore, the degree of the contribution of a task to the parameter\nupdates is controlled by introducing a set of weights on the loss function of\nthe tasks. Our method can be easily integrated with the current meta-learning\nalgorithms for neural networks. Our experiments demonstrate that it yields\nmodels with better generalization compared to MAML and Reptile.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 17:38:57 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Eshratifar", "Amir Erfan", ""], ["Eigen", "David", ""], ["Pedram", "Massoud", ""]]}, {"id": "1810.08189", "submitter": "Cheng Kang Hsieh", "authors": "Cheng-Kang Hsieh, Miguel Campo, Abhinav Taliyan, Matt Nickens,\n  Mitkumar Pandya, JJ Espinoza", "title": "Convolutional Collaborative Filter Network for Video Based\n  Recommendation Systems", "comments": "8 pages, 3 figures, 1 table include ablation study. arguments /\n  results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This analysis explores the temporal sequencing of objects in a movie trailer.\nTemporal sequencing of objects in a movie trailer (e.g., a long shot of an\nobject vs intermittent short shots) can convey information about the type of\nmovie, plot of the movie, role of the main characters, and the filmmakers\ncinematographic choices. When combined with historical customer data,\nsequencing analysis can be used to improve predictions of customer behavior.\nE.g., a customer buys tickets to a new movie and maybe the customer has seen\nmovies in the past that contained similar sequences. To explore object\nsequencing in movie trailers, we propose a video convolutional network to\ncapture actions and scenes that are predictive of customers' preferences. The\nmodel learns the specific nature of sequences for different types of objects\n(e.g., cars vs faces), and the role of sequences in predicting customer future\nbehavior. We show how such a temporal-aware model outperforms simple feature\npooling methods proposed in our previous works and, importantly, demonstrate\nthe additional model explain-ability allowed by such a model.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 17:57:58 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 20:43:16 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Hsieh", "Cheng-Kang", ""], ["Campo", "Miguel", ""], ["Taliyan", "Abhinav", ""], ["Nickens", "Matt", ""], ["Pandya", "Mitkumar", ""], ["Espinoza", "JJ", ""]]}, {"id": "1810.08236", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "Semantic Integration in the Information Flow Framework", "comments": "12 pages, 2 figures. Dagstuhl Seminar Proceedings 04391, Semantic\n  Interoperability and Integration, Schloss Dagstuhl, Leibniz-Zentrum fur\n  Informatik GmbH, 2005 Online at:\n  http://drops.dagstuhl.de/opus/portals/index.php?semnr=04391", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Information Flow Framework (IFF) is a descriptive category metatheory\ncurrently under development, which is being offered as the structural aspect of\nthe Standard Upper Ontology (SUO). The architecture of the IFF is composed of\nmetalevels, namespaces and meta-ontologies. The main application of the IFF is\ninstitutional: the notion of institutions and their morphisms are being\naxiomatized in the upper metalevels of the IFF, and the lower metalevel of the\nIFF has axiomatized various institutions in which semantic integration has a\nnatural expression as the colimit of theories.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 18:50:37 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1810.08272", "submitter": "Dzmitry Bahdanau", "authors": "Maxime Chevalier-Boisvert, Dzmitry Bahdanau, Salem Lahlou, Lucas\n  Willems, Chitwan Saharia, Thien Huu Nguyen, Yoshua Bengio", "title": "BabyAI: A Platform to Study the Sample Efficiency of Grounded Language\n  Learning", "comments": "Accepted at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Allowing humans to interactively train artificial agents to understand\nlanguage instructions is desirable for both practical and scientific reasons,\nbut given the poor data efficiency of the current learning methods, this goal\nmay require substantial research efforts. Here, we introduce the BabyAI\nresearch platform to support investigations towards including humans in the\nloop for grounded language learning. The BabyAI platform comprises an\nextensible suite of 19 levels of increasing difficulty. The levels gradually\nlead the agent towards acquiring a combinatorially rich synthetic language\nwhich is a proper subset of English. The platform also provides a heuristic\nexpert agent for the purpose of simulating a human teacher. We report baseline\nresults and estimate the amount of human involvement that would be required to\ntrain a neural network-based agent on some of the BabyAI levels. We put forward\nstrong evidence that current deep learning methods are not yet sufficiently\nsample efficient when it comes to learning a language with compositional\nproperties.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 20:48:08 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 20:53:11 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2019 18:12:35 GMT"}, {"version": "v4", "created": "Thu, 19 Dec 2019 15:44:33 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Chevalier-Boisvert", "Maxime", ""], ["Bahdanau", "Dzmitry", ""], ["Lahlou", "Salem", ""], ["Willems", "Lucas", ""], ["Saharia", "Chitwan", ""], ["Nguyen", "Thien Huu", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1810.08303", "submitter": "Corina P\\u{a}s\\u{a}reanu", "authors": "Corina S. Pasareanu, Divya Gopinath, Huafeng Yu", "title": "Compositional Verification for Autonomous Systems with Deep Learning\n  Components", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As autonomy becomes prevalent in many applications, ranging from\nrecommendation systems to fully autonomous vehicles, there is an increased need\nto provide safety guarantees for such systems. The problem is difficult, as\nthese are large, complex systems which operate in uncertain environments,\nrequiring data-driven machine-learning components. However, learning techniques\nsuch as Deep Neural Networks, widely used today, are inherently unpredictable\nand lack the theoretical foundations to provide strong assurance guarantees. We\npresent a compositional approach for the scalable, formal verification of\nautonomous systems that contain Deep Neural Network components. The approach\nuses assume-guarantee reasoning whereby {\\em contracts}, encoding the\ninput-output behavior of individual components, allow the designer to model and\nincorporate the behavior of the learning-enabled components working\nside-by-side with the other components. We illustrate the approach on an\nexample taken from the autonomous vehicles domain.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 23:16:23 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Pasareanu", "Corina S.", ""], ["Gopinath", "Divya", ""], ["Yu", "Huafeng", ""]]}, {"id": "1810.08431", "submitter": "Damien Pellier", "authors": "Damien Pellier and Humbert Fiorino", "title": "Assumption-Based Planning", "comments": null, "journal-ref": "Proceedings of the International Conference on Advances in\n  Intelligence Systems Theory and Applications (AISTA), 2004, November, pages\n  367-376, Luxembourg-Kirchberg, Luxembourg", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of the paper is to introduce a new approach of planning called\nAssumption-Based Planning. This approach is a very interesting way to devise a\nplanner based on a multi-agent system in which the production of a global\nshared plan is obtained by conjecture/refutation cycles. Contrary to classical\napproaches, our contribution relies on the agents reasoning that leads to the\nproduction of a plan from planning domains. To take into account complex\nenvironments and the partial agents knowledge, we propose to consider the\nplanning problem as a defeasible reasoning where the agents exchange proposals\nand counter-proposals and are able to reason about uncertainty. The\nargumentation dialogue between agents must not be viewed as a negotiation\nprocess but as an investigation process in order to build a plan. In this\npaper, we focus on the mechanisms that allow an agent to produce `reasonable'\nproposals according to its knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 10:26:27 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Pellier", "Damien", ""], ["Fiorino", "Humbert", ""]]}, {"id": "1810.08438", "submitter": "Damien Pellier", "authors": "Damien Pellier and Humbert Fiorino", "title": "Coordinated exploration for labyrinthine environments with application\n  to the Pursuit-Evasion problem", "comments": null, "journal-ref": "Workshop on Cooperative Robotics \\--- International Conference on\n  Intelligent Robots and Systems (IROS), 2002, 30 September - 04 October, pages\n  50-58, Lausanne, Switzerland", "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a multirobot cooperation approach to solve the \"pursuit\nevasion\" problem for mobile robots that have omnidirectional vision sensors.\nThe main characteristic of this approach is to implement a real cooperation\nbetween robots based on knowledge sharing and makes them work as a team. A\ncomplete algorithm for computing a motion strategy of robots is also presented.\nThis algorithm is based on searching critical points in the environment.\nFinally, the deliberation protocol which distributes the exploration task among\nthe team and takes the best possible outcome from the robots resources is\npresented.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 10:53:53 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Pellier", "Damien", ""], ["Fiorino", "Humbert", ""]]}, {"id": "1810.08460", "submitter": "Damien Pellier", "authors": "Damien Pellier and lias. Belaidi", "title": "Planification par fusions incr\\'ementales de graphes", "comments": "in French", "journal-ref": "Journ\\'ees Francophones de Planification, D\\'ecision,\n  Apprentissage pour la conduite de syst\\`emes (JFPDA). 2008, Metz, France", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a generic and fresh model for distributed\nplanning called \"Distributed Planning Through Graph Merging\" ({\\sf DPGM}). This\nmodel unifies the different steps of the distributed planning process into a\nsingle step. Our approach is based on a planning graph structure for the agent\nreasoning and a CSP mechanism for the individual plan extraction and the\ncoordination. We assume that no agent can reach the global goal alone.\nTherefore the agents must cooperate, {\\it i.e.,} take in into account potential\npositive interactions between their activities to reach their common shared\ngoal. The originality of our model consists in considering as soon as possible,\n{\\it i.e.,} in the individual planning process, the positive and the negative\ninteractions between agents activities in order to reduce the search cost of a\nglobal coordinated solution plan.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 12:21:47 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Pellier", "Damien", ""], ["Belaidi", "lias.", ""]]}, {"id": "1810.08492", "submitter": "Damien Pellier", "authors": "Ying Siu Liang and Damien Pellier and Humbert Fiorino and Sylvie Pesty", "title": "A Framework for Robot Programming in Cobotic Environments: First user\n  experiments", "comments": null, "journal-ref": "International Conference on Mechatronics and Robotics Engineering,\n  pages 30-35, 2017", "doi": null, "report-no": "ISBN: 978-1-4503-5280-2", "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing presence of robots in industries has not gone unnoticed. Large\nindustrial players have incorporated them into their production lines, but\nsmaller companies hesitate due to high initial costs and the lack of\nprogramming expertise. In this work we introduce a framework that combines two\ndisciplines, Programming by Demonstration and Automated Planning, to allow\nusers without any programming knowledge to program a robot. The user teaches\nthe robot atomic actions together with their semantic meaning and represents\nthem in terms of preconditions and effects. Using these atomic actions the\nrobot can generate action sequences autonomously to reach any goal given by the\nuser. We evaluated the usability of our framework in terms of user experiments\nwith a Baxter Research Robot and showed that it is well-adapted to users\nwithout any programming experience.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 13:29:36 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Liang", "Ying Siu", ""], ["Pellier", "Damien", ""], ["Fiorino", "Humbert", ""], ["Pesty", "Sylvie", ""]]}, {"id": "1810.08515", "submitter": "Mark Schutera", "authors": "Mark Schutera, Niklas Goby, Dirk Neumann, Markus Reischl", "title": "Transfer Learning versus Multi-agent Learning regarding Distributed\n  Decision-Making in Highway Traffic", "comments": "Proc. of the 10th International Workshop on Agents in Traffic and\n  Transportation (ATT 2018), co-located with ECAI/IJCAI, AAMAS and ICML 2018\n  conferences (FAIM 2018)", "journal-ref": "CEUR Workshop Proceedings 2018", "doi": null, "report-no": "CEUR-WS.org/Vol-2129", "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation and traffic are currently undergoing a rapid increase in terms\nof both scale and complexity. At the same time, an increasing share of traffic\nparticipants are being transformed into agents driven or supported by\nartificial intelligence resulting in mixed-intelligence traffic. This work\nexplores the implications of distributed decision-making in mixed-intelligence\ntraffic. The investigations are carried out on the basis of an online-simulated\nhighway scenario, namely the MIT \\emph{DeepTraffic} simulation. In the first\nstep traffic agents are trained by means of a deep reinforcement learning\napproach, being deployed inside an elitist evolutionary algorithm for\nhyperparameter search. The resulting architectures and training parameters are\nthen utilized in order to either train a single autonomous traffic agent and\ntransfer the learned weights onto a multi-agent scenario or else to conduct\nmulti-agent learning directly. Both learning strategies are evaluated on\ndifferent ratios of mixed-intelligence traffic. The strategies are assessed\naccording to the average speed of all agents driven by artificial intelligence.\nTraffic patterns that provoke a reduction in traffic flow are analyzed with\nrespect to the different strategies.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 14:16:25 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Schutera", "Mark", ""], ["Goby", "Niklas", ""], ["Neumann", "Dirk", ""], ["Reischl", "Markus", ""]]}, {"id": "1810.08540", "submitter": "Ansh Patel", "authors": "Ansh Patel", "title": "Fairness for Whom? Critically reframing fairness with Nash Welfare\n  Product", "comments": "Submitted to FAT* 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on disparate impact in machine learning applications have\nsparked a debate around the concept of fairness along with attempts to\nformalize its different criteria. Many of these approaches focus on reducing\nprediction errors while maximizing sole utility of the institution. This work\nseeks to reconceptualize and critically frame the existing discourse on\nfairness by underlining the implicit biases embedded in common understandings\nof fairness in the literature and how they contrast with its corresponding\neconomic and legal definitions. This paper expands the concept of utility and\nfairness by bringing in concepts from established literature in welfare\neconomics and game theory. We then translate these concepts for the algorithmic\nprediction domain by defining a formalization of Nash Welfare Product that\nseeks to expand utility by collapsing that of the institution using the\nprediction tool and the individual subject to the prediction into one function.\nWe then apply a modulating function that makes the fairness and welfare\ntrade-offs explicit based on designated policy goals and then apply it to a\ntemporal model to take into account the effects of decisions beyond the scope\nof one-shot predictions. We apply this on a binary classification problem and\npresent results of a multi-epoch simulation based on the UCI Adult Income\ndataset and a test case analysis of the ProPublica recidivism dataset that show\nthat expanding the concept of utility results in a fairer distribution\ncorrecting for the embedded biases in the dataset without sacrificing the\nclassifier accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 15:12:56 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Patel", "Ansh", ""]]}, {"id": "1810.08575", "submitter": "Paul Christiano", "authors": "Paul Christiano, Buck Shlegeris, Dario Amodei", "title": "Supervising strong learners by amplifying weak experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world learning tasks involve complex or hard-to-specify objectives,\nand using an easier-to-specify proxy can lead to poor performance or misaligned\nbehavior. One solution is to have humans provide a training signal by\ndemonstrating or judging performance, but this approach fails if the task is\ntoo complicated for a human to directly evaluate. We propose Iterated\nAmplification, an alternative training strategy which progressively builds up a\ntraining signal for difficult problems by combining solutions to easier\nsubproblems. Iterated Amplification is closely related to Expert Iteration\n(Anthony et al., 2017; Silver et al., 2017), except that it uses no external\nreward function. We present results in algorithmic environments, showing that\nIterated Amplification can efficiently learn complex behaviors.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 16:30:48 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Christiano", "Paul", ""], ["Shlegeris", "Buck", ""], ["Amodei", "Dario", ""]]}, {"id": "1810.08577", "submitter": "Adam Hornsby", "authors": "Adam N. Hornsby, Thomas Evans, Peter Riefer, Rosie Prior and Bradley\n  C. Love", "title": "Conceptual Organization is Revealed by Consumer Activity Patterns", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": "10.1007/s42113-019-00064-9", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meaning may arise from an element's role or interactions within a larger\nsystem. For example, hitting nails is more central to people's concept of a\nhammer than its particular material composition or other intrinsic features.\nLikewise, the importance of a web page may result from its links with other\npages rather than solely from its content. One example of meaning arising from\nextrinsic relationships are approaches that extract the meaning of word\nconcepts from co-occurrence patterns in large, text corpora. The success of\nthese methods suggest that human activity patterns may reveal conceptual\norganization. However, texts do not directly reflect human activity, but\ninstead serve a communicative function and are usually highly curated or edited\nto suit an audience. Here, we apply methods devised for text to a data source\nthat directly reflects thousands of individuals' activity patterns, namely\nsupermarket purchases. Using product co-occurrence data from nearly 1.3m\nshopping baskets, we trained a topic model to learn 25 high-level concepts (or\n\"topics\"). These topics were found to be comprehensible and coherent by both\nretail experts and consumers. Topics ranged from specific (e.g., ingredients\nfor a stir-fry) to general (e.g., cooking from scratch). Topics tended to be\ngoal-directed and situational, consistent with the notion that human conceptual\nknowledge is tailored to support action. Individual differences in the topics\nsampled predicted basic demographic characteristics. These results suggest that\nhuman activity patterns reveal conceptual organization and may give rise to it.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 16:41:27 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Hornsby", "Adam N.", ""], ["Evans", "Thomas", ""], ["Riefer", "Peter", ""], ["Prior", "Rosie", ""], ["Love", "Bradley C.", ""]]}, {"id": "1810.08647", "submitter": "Natasha Jaques", "authors": "Natasha Jaques, Angeliki Lazaridou, Edward Hughes, Caglar Gulcehre,\n  Pedro A. Ortega, DJ Strouse, Joel Z. Leibo, Nando de Freitas", "title": "Social Influence as Intrinsic Motivation for Multi-Agent Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unified mechanism for achieving coordination and communication\nin Multi-Agent Reinforcement Learning (MARL), through rewarding agents for\nhaving causal influence over other agents' actions. Causal influence is\nassessed using counterfactual reasoning. At each timestep, an agent simulates\nalternate actions that it could have taken, and computes their effect on the\nbehavior of other agents. Actions that lead to bigger changes in other agents'\nbehavior are considered influential and are rewarded. We show that this is\nequivalent to rewarding agents for having high mutual information between their\nactions. Empirical results demonstrate that influence leads to enhanced\ncoordination and communication in challenging social dilemma environments,\ndramatically increasing the learning curves of the deep RL agents, and leading\nto more meaningful learned communication protocols. The influence rewards for\nall agents can be computed in a decentralized way by enabling agents to learn a\nmodel of other agents using deep neural networks. In contrast, key previous\nworks on emergent communication in the MARL setting were unable to learn\ndiverse policies in a decentralized manner and had to resort to centralized\ntraining. Consequently, the influence reward opens up a window of new\nopportunities for research in this area.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 19:01:15 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 22:44:48 GMT"}, {"version": "v3", "created": "Fri, 8 Feb 2019 23:52:07 GMT"}, {"version": "v4", "created": "Tue, 18 Jun 2019 21:39:08 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Jaques", "Natasha", ""], ["Lazaridou", "Angeliki", ""], ["Hughes", "Edward", ""], ["Gulcehre", "Caglar", ""], ["Ortega", "Pedro A.", ""], ["Strouse", "DJ", ""], ["Leibo", "Joel Z.", ""], ["de Freitas", "Nando", ""]]}, {"id": "1810.08648", "submitter": "George Kyriakides", "authors": "George Kyriakides, Konstantinos Margaritis", "title": "Towards automated neural design: An open source, distributed neural\n  architecture research framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NORD (Neural Operations Research & Development) is an open source distributed\ndeep learning architectural research framework, based on PyTorch, MPI and\nHorovod. It aims to make research of deep architectures easier for experts of\ndifferent domains, in order to accelerate the process of finding better\narchitectures, as well as study the best architectures generated for different\ndatasets. Although currently under heavy development, the framework aims to\nallow the easy implementation of different design and optimization method\nfamilies (optimization algorithms, meta-heuristics, reinforcement learning\netc.) as well as the fair comparison between them. Furthermore, due to the\ncomputational resources required in order to optimize and evaluate network\narchitectures, it leverage the use of distributed computing, while aiming to\nminimize the researcher's overhead required to implement it. Moreover, it\nstrives to make the creation of architectures more intuitive, by implementing\nnetwork descriptors, allowing to separately define the architecture's nodes and\nconnections. In this paper, we present the framework's current state of\ndevelopment, while presenting its basic concepts, providing simple examples as\nwell as their experimental results.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 20:31:45 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Kyriakides", "George", ""], ["Margaritis", "Konstantinos", ""]]}, {"id": "1810.08669", "submitter": "Giovanni Iacca Dr.", "authors": "G. Iacca, F. Neri, E. Mininno, Y. S. Ong, M. H. Lim", "title": "Ockham's Razor in Memetic Computing: Three Stage Optimal Memetic\n  Exploration", "comments": null, "journal-ref": "Information Sciences, Volume 188, pp 17-43, 2012", "doi": "10.1016/j.ins.2011.11.025", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memetic Computing is a subject in computer science which considers complex\nstructures as the combination of simple agents, memes, whose evolutionary\ninteractions lead to intelligent structures capable of problem-solving. This\npaper focuses on Memetic Computing optimization algorithms and proposes a\ncounter-tendency approach for algorithmic design. Research in the field tends\nto go in the direction of improving existing algorithms by combining different\nmethods or through the formulation of more complicated structures. Contrary to\nthis trend, we instead focus on simplicity, proposing a structurally simple\nalgorithm with emphasis on processing only one solution at a time. The proposed\nalgorithm, namely Three Stage Optimal Memetic Exploration, is composed of three\nmemes; the first stochastic and with a long search radius, the second\nstochastic and with a moderate search radius and the third deterministic and\nwith a short search radius. The bottom-up combination of the three operators by\nmeans of a natural trial and error logic, generates a robust and efficient\noptimizer, capable of competing with modern complex and computationally\nexpensive algorithms. This is suggestive of the fact that complexity in\nalgorithmic structures can be unnecessary, if not detrimental, and that simple\nbottom-up approaches are likely to be competitive is here invoked as an\nextension to Memetic Computing basing on the philosophical concept of Ockham's\nRazor. An extensive experimental setup on various test problems and one digital\nsignal processing application is presented. Numerical results show that the\nproposed approach, despite its simplicity and low computational cost displays a\nvery good performance on several problems, and is competitive with\nsophisticated algorithms representing the-state-of-the-art in computational\nintelligence optimization.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 14:14:34 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Iacca", "G.", ""], ["Neri", "F.", ""], ["Mininno", "E.", ""], ["Ong", "Y. S.", ""], ["Lim", "M. H.", ""]]}, {"id": "1810.08676", "submitter": "Kommy Weldemariam Dr", "authors": "Skyler Speakman, Srihari Sridharan, Sekou Remy, Komminist Weldemariam,\n  Edward McFowland", "title": "Subset Scanning Over Neural Network Activations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work views neural networks as data generating systems and applies\nanomalous pattern detection techniques on that data in order to detect when a\nnetwork is processing an anomalous input. Detecting anomalies is a critical\ncomponent for multiple machine learning problems including detecting\nadversarial noise. More broadly, this work is a step towards giving neural\nnetworks the ability to recognize an out-of-distribution sample. This is the\nfirst work to introduce \"Subset Scanning\" methods from the anomalous pattern\ndetection domain to the task of detecting anomalous input of neural networks.\nSubset scanning treats the detection problem as a search for the most anomalous\nsubset of node activations (i.e., highest scoring subset according to\nnon-parametric scan statistics). Mathematical properties of these scoring\nfunctions allow the search to be completed in log-linear rather than\nexponential time while still guaranteeing the most anomalous subset of nodes in\nthe network is identified for a given input. Quantitative results for detecting\nand characterizing adversarial noise are provided for CIFAR-10 images on a\nsimple convolutional neural network. We observe an \"interference\" pattern where\nanomalous activations in shallow layers suppress the activation structure of\nthe original image in deeper layers.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 20:22:53 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Speakman", "Skyler", ""], ["Sridharan", "Srihari", ""], ["Remy", "Sekou", ""], ["Weldemariam", "Komminist", ""], ["McFowland", "Edward", ""]]}, {"id": "1810.08678", "submitter": "Zhenpeng Zhou", "authors": "Zhenpeng Zhou, Steven Kearnes, Li Li, Richard N. Zare, and Patrick\n  Riley", "title": "Optimization of Molecules via Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.1038/s41598-019-47148-x", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework, which we call Molecule Deep $Q$-Networks (MolDQN),\nfor molecule optimization by combining domain knowledge of chemistry and\nstate-of-the-art reinforcement learning techniques (double $Q$-learning and\nrandomized value functions). We directly define modifications on molecules,\nthereby ensuring 100\\% chemical validity. Further, we operate without\npre-training on any dataset to avoid possible bias from the choice of that set.\nInspired by problems faced during medicinal chemistry lead optimization, we\nextend our model with multi-objective reinforcement learning, which maximizes\ndrug-likeness while maintaining similarity to the original molecule. We further\nshow the path through chemical space to achieve optimization for a molecule to\nunderstand how the model works.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 20:23:44 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 05:28:46 GMT"}, {"version": "v3", "created": "Fri, 1 Mar 2019 01:46:11 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Zhou", "Zhenpeng", ""], ["Kearnes", "Steven", ""], ["Li", "Li", ""], ["Zare", "Richard N.", ""], ["Riley", "Patrick", ""]]}, {"id": "1810.08680", "submitter": "Benjamin Penchas", "authors": "Tobin Bell and Benjamin Penchas", "title": "Lightweight Convolutional Approaches to Reading Comprehension on SQuAD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art reading comprehension models rely heavily on\nrecurrent neural networks. We explored an entirely different approach to\nquestion answering: a convolutional model. By their nature, these convolutional\nmodels are fast to train and capture local dependencies well, though they can\nstruggle with longer-range dependencies and thus require augmentation to\nachieve comparable performance to RNN-based models. We conducted over two dozen\ncontrolled experiments with convolutional models and various\nkernel/attention/regularization schemes to determine the precise performance\ngains of each strategy, while maintaining a focus on speed. We ultimately\nensembled three models: crossconv (0.5398 dev F1), attnconv (0.5665), and\nmaybeconv (0.5285). The ensembled model was able to achieve a 0.6238 F1 score\nusing the official SQuAD evaluation script. Our individual convolutional model\ncrossconv was able to exceed the performance of the RNN-plus-attention baseline\nby 25% while training 6 times faster.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 20:32:36 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Bell", "Tobin", ""], ["Penchas", "Benjamin", ""]]}, {"id": "1810.08700", "submitter": "Bj\\\"orn L\\\"utjens", "authors": "Bj\\\"orn L\\\"utjens, Michael Everett, Jonathan P. How", "title": "Safe Reinforcement Learning with Model Uncertainty Estimates", "comments": "ICRA 2019; Presented at IROS 2018 Workshop on Machine Learning in\n  Robot Motion Planning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many current autonomous systems are being designed with a strong reliance on\nblack box predictions from deep neural networks (DNNs). However, DNNs tend to\nbe overconfident in predictions on unseen data and can give unpredictable\nresults for far-from-distribution test data. The importance of predictions that\nare robust to this distributional shift is evident for safety-critical\napplications, such as collision avoidance around pedestrians. Measures of model\nuncertainty can be used to identify unseen data, but the state-of-the-art\nextraction methods such as Bayesian neural networks are mostly intractable to\ncompute. This paper uses MC-Dropout and Bootstrapping to give computationally\ntractable and parallelizable uncertainty estimates. The methods are embedded in\na Safe Reinforcement Learning framework to form uncertainty-aware navigation\naround pedestrians. The result is a collision avoidance policy that knows what\nit does not know and cautiously avoids pedestrians that exhibit unseen\nbehavior. The policy is demonstrated in simulation to be more robust to novel\nobservations and take safer actions than an uncertainty-unaware baseline.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 22:04:59 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 05:03:11 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["L\u00fctjens", "Bj\u00f6rn", ""], ["Everett", "Michael", ""], ["How", "Jonathan P.", ""]]}, {"id": "1810.08707", "submitter": "Leonardo Fanzeres", "authors": "Leonardo A. Fanzeres (1), Adriana S. Vivacqua (1), Luiz W. P.\n  Biscainho (2) ((1) PPGI, DCC/IM, Universidade Federal do Rio de Janeiro, (2)\n  DEL/Poli & PEE/COPPE, Universidade Federal do Rio de Janeiro)", "title": "Mobile Sound Recognition for the Deaf and Hard of Hearing", "comments": "25 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human perception of surrounding events is strongly dependent on audio cues.\nThus, acoustic insulation can seriously impact situational awareness. We\npresent an exploratory study in the domain of assistive computing, eliciting\nrequirements and presenting solutions to problems found in the development of\nan environmental sound recognition system, which aims to assist deaf and hard\nof hearing people in the perception of sounds. To take advantage of smartphones\ncomputational ubiquity, we propose a system that executes all processing on the\ndevice itself, from audio features extraction to recognition and visual\npresentation of results. Our application also presents the confidence level of\nthe classification to the user. A test of the system conducted with deaf users\nprovided important and inspiring feedback from participants.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 22:47:52 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Fanzeres", "Leonardo A.", ""], ["Vivacqua", "Adriana S.", ""], ["Biscainho", "Luiz W. P.", ""]]}, {"id": "1810.08744", "submitter": "Mark Hamilton", "authors": "Mark Hamilton, Sudarshan Raghunathan, Ilya Matiach, Andrew\n  Schonhoffer, Anand Raman, Eli Barzilay, Karthik Rajendran, Dalitso Banda,\n  Casey Jisoo Hong, Manon Knoertzer, Ben Brodsky, Minsoo Thigpen, Janhavi\n  Suresh Mahajan, Courtney Cochrane, Abhiram Eswaran, Ari Green", "title": "MMLSpark: Unifying Machine Learning Ecosystems at Massive Scales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Microsoft Machine Learning for Apache Spark (MMLSpark), an\necosystem of enhancements that expand the Apache Spark distributed computing\nlibrary to tackle problems in Deep Learning, Micro-Service Orchestration,\nGradient Boosting, Model Interpretability, and other areas of modern\ncomputation. Furthermore, we present a novel system called Spark Serving that\nallows users to run any Apache Spark program as a distributed, sub-millisecond\nlatency web service backed by their existing Spark Cluster. All MMLSpark\ncontributions have the same API to enable simple composition across frameworks\nand usage across batch, streaming, and RESTful web serving scenarios on static,\nelastic, or serverless clusters. We showcase MMLSpark by creating a method for\ndeep object detection capable of learning without human labeled data and\ndemonstrate its effectiveness for Snow Leopard conservation.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 03:12:59 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 15:39:52 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Hamilton", "Mark", ""], ["Raghunathan", "Sudarshan", ""], ["Matiach", "Ilya", ""], ["Schonhoffer", "Andrew", ""], ["Raman", "Anand", ""], ["Barzilay", "Eli", ""], ["Rajendran", "Karthik", ""], ["Banda", "Dalitso", ""], ["Hong", "Casey Jisoo", ""], ["Knoertzer", "Manon", ""], ["Brodsky", "Ben", ""], ["Thigpen", "Minsoo", ""], ["Mahajan", "Janhavi Suresh", ""], ["Cochrane", "Courtney", ""], ["Eswaran", "Abhiram", ""], ["Green", "Ari", ""]]}, {"id": "1810.08759", "submitter": "Leila Rajabpour", "authors": "Leila Rajabpour, Mokhtar Shasadeghi and Alireza Barzegar", "title": "Design of robust H_inf fuzzy output feedback controller for affine\n  nonlinear systems:Fuzzy Lyapunov function approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new systematic approach based on nonquadratic\nLyapunov function and technique of introducing slack matrices, for a class of\naffine nonlinear systems with disturbance. To achieve the goal, first, the\naffine nonlinear system is represented via Takagi-Sugeno (T-S) fuzzy bilinear\nmodel. Subsequently, the robust H_inf controller is designed based on parallel\ndistributed compensation (PDC) scheme. Then, the stability conditions are\nderived in terms of linear matrix inequalities (LMIs) by utilizing Lyapunov\nfunction. Moreover, some slack matrices are proposed to reduce the\nconservativeness of the LMI stability conditions. Finally, for illustrating the\nmerits and verifying the effectiveness of the proposed approach, the\napplication of an isothermal continuous stirred tank reactor (CSTR) for Van de\nVusse reactor is discussed in details.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 06:33:30 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Rajabpour", "Leila", ""], ["Shasadeghi", "Mokhtar", ""], ["Barzegar", "Alireza", ""]]}, {"id": "1810.08782", "submitter": "Abhishek", "authors": "Abhishek Abhishek and Amar Prakash Azad and Balaji Ganesan and Ashish\n  Anand and Amit Awekar", "title": "Collective Learning From Diverse Datasets for Entity Typing in the Wild", "comments": "Accepted at EYRE'19 Workshop, CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity typing (ET) is the problem of assigning labels to given entity\nmentions in a sentence. Existing works for ET require knowledge about the\ndomain and target label set for a given test instance. ET in the absence of\nsuch knowledge is a novel problem that we address as ET in the wild. We\nhypothesize that the solution to this problem is to build supervised models\nthat generalize better on the ET task as a whole, rather than a specific\ndataset. In this direction, we propose a Collective Learning Framework (CLF),\nwhich enables learning from diverse datasets in a unified way. The CLF first\ncreates a unified hierarchical label set (UHLS) and a label mapping by\naggregating label information from all available datasets. Then it builds a\nsingle neural network classifier using UHLS, label mapping, and a partial loss\nfunction. The single classifier predicts the finest possible label across all\navailable domains even though these labels may not be present in any\ndomain-specific dataset. We also propose a set of evaluation schemes and\nmetrics to evaluate the performance of models in this novel problem. Extensive\nexperimentation on seven diverse real-world datasets demonstrates the efficacy\nof our CLF.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 09:59:31 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 08:20:25 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 15:59:10 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Abhishek", "Abhishek", ""], ["Azad", "Amar Prakash", ""], ["Ganesan", "Balaji", ""], ["Anand", "Ashish", ""], ["Awekar", "Amit", ""]]}, {"id": "1810.08811", "submitter": "Yosuke Fukuchi", "authors": "Yosuke Fukuchi, Masahiko Osawa, Hiroshi Yamakawa, Michita Imai", "title": "Autonomous Self-Explanation of Behavior for Interactive Reinforcement\n  Learning Agents", "comments": null, "journal-ref": "Proceedings of the 5th International Conference on Human Agent\n  Interaction Pages 97-101 2017", "doi": "10.1145/3125739.3125746", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cooperation, the workers must know how co-workers behave. However, an\nagent's policy, which is embedded in a statistical machine learning model, is\nhard to understand, and requires much time and knowledge to comprehend.\nTherefore, it is difficult for people to predict the behavior of machine\nlearning robots, which makes Human Robot Cooperation challenging. In this\npaper, we propose Instruction-based Behavior Explanation (IBE), a method to\nexplain an autonomous agent's future behavior. In IBE, an agent can\nautonomously acquire the expressions to explain its own behavior by reusing the\ninstructions given by a human expert to accelerate the learning of the agent's\npolicy. IBE also enables a developmental agent, whose policy may change during\nthe cooperation, to explain its own behavior with sufficient time granularity.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 14:25:53 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Fukuchi", "Yosuke", ""], ["Osawa", "Masahiko", ""], ["Yamakawa", "Hiroshi", ""], ["Imai", "Michita", ""]]}, {"id": "1810.08831", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "Enriched Interpretation", "comments": "10 pages, Conference Proceedings of the Third International Workshop\n  on Rough Sets and Soft Computing (RSSC'94), T.Y. Lin, editor, pages 116-123,\n  San Jose State University, San Jose, California, USA, November 1994", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory introduced, presented and developed in this paper, is concerned\nwith an enriched extension of the theory of Rough Sets pioneered by Zdzislaw\nPawlak. The enrichment discussed here is in the sense of valuated categories as\ndeveloped by F.W. Lawvere. This paper relates Rough Sets to an abstraction of\nthe theory of Fuzzy Sets pioneered by Lotfi Zadeh, and provides a natural\nfoundation for \"soft computation\". To paraphrase Lotfi Zadeh, the impetus for\nthe transition from a hard theory to a soft theory derives from the fact that\nboth the generality of a theory and its applicability to real-world problems\nare substantially enhanced by replacing various hard concepts with their soft\ncounterparts. Here we discuss the corresponding enriched notions for\nindiscernibility, subsets, upper/lower approximations, and rough sets.\nThroughout, we indicate linkages with the theory of Formal Concept Analysis\npioneered by Rudolf Wille. We pay particular attention to the all-important\nnotion of a \"linguistic variable\" - developing its enriched extension,\ncomparing it with the notion of conceptual scale from Formal Concept Analysis,\nand discussing the pragmatic issues of its creation and use in the\ninterpretation of data. These pragmatic issues are exemplified by the\ndiscovery, conceptual analysis, interpretation, and categorization of networked\ninformation resources in WAVE, the Web Analysis and Visualization Environment\ncurrently being developed for the management and interpretation of the universe\nof resource information distributed over the World-Wide Web.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 17:41:16 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1810.08914", "submitter": "Salvador Garc\\'ia", "authors": "Jos\\'e-Ram\\'on Cano and Juli\\'an Luengo and Salvador Garc\\'ia", "title": "Label Noise Filtering Techniques to Improve Monotonic Classification", "comments": "This paper is already accepted for publication in Neurocomputing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The monotonic ordinal classification has increased the interest of\nresearchers and practitioners within machine learning community in the last\nyears. In real applications, the problems with monotonicity constraints are\nvery frequent. To construct predictive monotone models from those problems,\nmany classifiers require as input a data set satisfying the monotonicity\nrelationships among all samples. Changing the class labels of the data set\n(relabelling) is useful for this. Relabelling is assumed to be an important\nbuilding block for the construction of monotone classifiers and it is proved\nthat it can improve the predictive performance.\n  In this paper, we will address the construction of monotone datasets\nconsidering as noise the cases that do not meet the monotonicity restrictions.\nFor the first time in the specialized literature, we propose the use of noise\nfiltering algorithms in a preprocessing stage with a double goal: to increase\nboth the monotonicity index of the models and the accuracy of the predictions\nfor different monotonic classifiers. The experiments are performed over 12\ndatasets coming from classification and regression problems and show that our\nscheme improves the prediction capabilities of the monotonic classifiers\ninstead of being applied to original and relabeled datasets. In addition, we\nhave included the analysis of noise filtering process in the particular case of\nwine quality classification to understand its effect in the predictive models\ngenerated.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 08:36:37 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Cano", "Jos\u00e9-Ram\u00f3n", ""], ["Luengo", "Juli\u00e1n", ""], ["Garc\u00eda", "Salvador", ""]]}, {"id": "1810.09026", "submitter": "Marc Lanctot", "authors": "Sriram Srinivasan, Marc Lanctot, Vinicius Zambaldi, Julien Perolat,\n  Karl Tuyls, Remi Munos, Michael Bowling", "title": "Actor-Critic Policy Optimization in Partially Observable Multiagent\n  Environments", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization of parameterized policies for reinforcement learning (RL) is an\nimportant and challenging problem in artificial intelligence. Among the most\ncommon approaches are algorithms based on gradient ascent of a score function\nrepresenting discounted return. In this paper, we examine the role of these\npolicy gradient and actor-critic algorithms in partially-observable multiagent\nenvironments. We show several candidate policy update rules and relate them to\na foundation of regret minimization and multiagent learning techniques for the\none-shot and tabular cases, leading to previously unknown convergence\nguarantees. We apply our method to model-free multiagent reinforcement learning\nin adversarial sequential decision problems (zero-sum imperfect information\ngames), using RL-style function approximation. We evaluate on commonly used\nbenchmark Poker domains, showing performance against fixed policies and\nempirical convergence to approximate Nash equilibria in self-play with rates\nsimilar to or better than a baseline model-free algorithm for zero sum games,\nwithout any domain-specific state space reductions.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 21:01:49 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 04:41:14 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 23:16:33 GMT"}, {"version": "v4", "created": "Sat, 19 Oct 2019 15:23:13 GMT"}, {"version": "v5", "created": "Fri, 12 Jun 2020 04:32:01 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Srinivasan", "Sriram", ""], ["Lanctot", "Marc", ""], ["Zambaldi", "Vinicius", ""], ["Perolat", "Julien", ""], ["Tuyls", "Karl", ""], ["Munos", "Remi", ""], ["Bowling", "Michael", ""]]}, {"id": "1810.09028", "submitter": "Michael Schaarschmidt", "authors": "Michael Schaarschmidt, Sven Mika, Kai Fricke, Eiko Yoneki", "title": "RLgraph: Modular Computation Graphs for Deep Reinforcement Learning", "comments": "SysML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) tasks are challenging to implement, execute and\ntest due to algorithmic instability, hyper-parameter sensitivity, and\nheterogeneous distributed communication patterns. We argue for the separation\nof logical component composition, backend graph definition, and distributed\nexecution. To this end, we introduce RLgraph, a library for designing and\nexecuting reinforcement learning tasks in both static graph and define-by-run\nparadigms. The resulting implementations are robust, incrementally testable,\nand yield high performance across different deep learning frameworks and\ndistributed backends.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 21:12:06 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 19:32:08 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Schaarschmidt", "Michael", ""], ["Mika", "Sven", ""], ["Fricke", "Kai", ""], ["Yoneki", "Eiko", ""]]}, {"id": "1810.09030", "submitter": "Siwei Fu", "authors": "Siwei Fu, Anbang Xu, Xiaotong Liu, Huimin Zhou, Rama Akkiraju", "title": "Challenge AI Mind: A Crowd System for Proactive AI Testing", "comments": "a 10-page full paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Intelligence (AI) has burrowed into our lives in various aspects;\nhowever, without appropriate testing, deployed AI systems are often being\ncriticized to fail in critical and embarrassing cases. Existing testing\napproaches mainly depend on fixed and pre-defined datasets, providing a limited\ntesting coverage. In this paper, we propose the concept of proactive testing to\ndynamically generate testing data and evaluate the performance of AI systems.\nWe further introduce Challenge.AI, a new crowd system that features the\nintegration of crowdsourcing and machine learning techniques in the process of\nerror generation, error validation, error categorization, and error analysis.\nWe present experiences and insights into a participatory design with AI\ndevelopers. The evaluation shows that the crowd workflow is more effective with\nthe help of machine learning techniques. AI developers found that our system\ncan help them discover unknown errors made by the AI models, and engage in the\nprocess of proactive testing.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 21:13:48 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Fu", "Siwei", ""], ["Xu", "Anbang", ""], ["Liu", "Xiaotong", ""], ["Zhou", "Huimin", ""], ["Akkiraju", "Rama", ""]]}, {"id": "1810.09036", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "Soft Concept Analysis", "comments": "16 pages, 5 figures, 6 tables", "journal-ref": "Rough-Fuzzy Hybridization: New Trend in Decision-Making, pages\n  215-232. Sankar K. Pal and Andrzej Skowron, editors, Springer-Verlag,\n  Singapore, June 1999", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter we discuss soft concept analysis, a study which identifies an\nenriched notion of \"conceptual scale\" as developed in formal concept analysis\nwith an enriched notion of \"linguistic variable\" as discussed in fuzzy logic.\nThe identification \"enriched conceptual scale\" = \"enriched linguistic variable\"\nwas made in a previous paper (Enriched interpretation, Robert E. Kent). In this\nchapter we offer further arguments for the importance of this identification by\ndiscussing the philosophy, spirit, and practical application of conceptual\nscaling to the discovery, conceptual analysis, interpretation, and\ncategorization of networked information resources. We argue that a linguistic\nvariable, which has been defined at just the right generalization of valuated\ncategories, provides a natural definition for the process of soft conceptual\nscaling. This enrichment using valuated categories models the relation of\nindiscernability, a notion of central importance in rough set theory. At a more\nfundamental level for soft concept analysis, it also models the derivation of\nformal concepts, a process of central importance in formal concept analysis.\nSoft concept analysis is synonymous with enriched concept analysis. From one\nviewpoint, the study of soft concept analysis that is initiated here extends\nformal concept analysis to soft computational structures. From another\nviewpoint, soft concept analysis provides a natural foundation for soft\ncomputation by unifying and explaining notions from soft computation in terms\nof suitably generalized notions from formal concept analysis, rough set theory\nand fuzzy set theory.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 22:30:17 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1810.09038", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Yoshua Bengio", "title": "Depth with Nonlinearity Creates No Bad Local Minima in ResNets", "comments": null, "journal-ref": "Neural Networks, volume 118, pages 167-174 (2019)", "doi": "10.1016/j.neunet.2019.06.009", "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove that depth with nonlinearity creates no bad local\nminima in a type of arbitrarily deep ResNets with arbitrary nonlinear\nactivation functions, in the sense that the values of all local minima are no\nworse than the global minimum value of corresponding classical machine-learning\nmodels, and are guaranteed to further improve via residual representations. As\na result, this paper provides an affirmative answer to an open question stated\nin a paper in the conference on Neural Information Processing Systems 2018.\nThis paper advances the optimization theory of deep learning only for ResNets\nand not for other network architectures.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 22:38:32 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 16:50:26 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 14:59:54 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1810.09084", "submitter": "Hin Wai Lui", "authors": "Hin Wai Lui", "title": "A general learning system based on neuron bursting and tonic firing", "comments": null, "journal-ref": "Medical Hypotheses, Volume 123, February 2019, Pages 35-46", "doi": "10.1016/j.mehy.2018.12.001", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a framework for the biological learning mechanism as a\ngeneral learning system. The proposal is as follows. The bursting and tonic\nmodes of firing patterns found in many neuron types in the brain correspond to\ntwo separate modes of information processing, with one mode resulting in\nawareness, and another mode being subliminal. In such a coding scheme, a neuron\nin bursting state codes for the highest level of perceptual abstraction\nrepresenting a pattern of sensory stimuli, or volitional abstraction\nrepresenting a pattern of muscle contraction sequences. Within the 50-250 ms\nminimum integration time of experience, the bursting neurons form synchrony\nensembles to allow for binding of related percepts. The degree which different\nbursting neurons can be merged into the same synchrony ensemble depends on the\nunderlying cortical connections that represent the degree of perceptual\nsimilarity. These synchrony ensembles compete for selective attention to remain\nactive. The dominant synchrony ensemble triggers episodic memory recall in the\nhippocampus, while forming new episodic memory with current sensory stimuli,\nresulting in a stream of thoughts. Neuromodulation modulates both top-down\nselection of synchrony ensembles, and memory formation. Episodic memory stored\nin the hippocampus is transferred to semantic and procedural memory in the\ncortex during rapid eye movement sleep, by updating cortical neuron synaptic\nweights with spike timing dependent plasticity. With the update of synaptic\nweights, new neurons become bursting while previous bursting neurons become\ntonic, allowing bursting neurons to move up to a higher level of perceptual\nabstraction. Finally, the proposed learning mechanism is compared with the\nback-propagation algorithm used in deep neural networks, and a proposal of how\nthe credit assignment problem can be addressed by the current proposal is\npresented.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 04:52:39 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Lui", "Hin Wai", ""]]}, {"id": "1810.09103", "submitter": "Sungsu Lim", "authors": "Sungsu Lim, Ajin Joseph, Lei Le, Yangchen Pan, Martha White", "title": "Actor-Expert: A Framework for using Q-learning in Continuous Action\n  Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Q-learning can be difficult to use in continuous action spaces, because an\noptimization has to be solved to find the maximal action for the action-values.\nA common strategy has been to restrict the functional form of the action-values\nto be concave in the actions, to simplify the optimization. Such restrictions,\nhowever, can prevent learning accurate action-values. In this work, we propose\na new policy search objective that facilitates using Q-learning and a framework\nto optimize this objective, called Actor-Expert. The Expert uses Q-learning to\nupdate the action-values towards optimal action-values. The Actor learns the\nmaximal actions over time for these changing action-values. We develop a Cross\nEntropy Method (CEM) for the Actor, where such a global optimization approach\nfacilitates use of generically parameterized action-values. This method - which\nwe call Conditional CEM - iteratively concentrates density around maximal\nactions, conditioned on state. We prove that this algorithm tracks the expected\nCEM update, over states with changing action-values. We demonstrate in a toy\nenvironment that previous methods that restrict the action-value\nparameterization fail whereas Actor-Expert with a more general action-value\nparameterization succeeds. Finally, we demonstrate that Actor-Expert performs\nas well as or better than competitors on four benchmark continuous-action\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 06:35:03 GMT"}, {"version": "v2", "created": "Sun, 28 Apr 2019 17:34:35 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Lim", "Sungsu", ""], ["Joseph", "Ajin", ""], ["Le", "Lei", ""], ["Pan", "Yangchen", ""], ["White", "Martha", ""]]}, {"id": "1810.09145", "submitter": "Damien Pellier", "authors": "Sandra Castellanos-Paez and Damien Pellier and Humbert Fiorino and\n  Sylvie Pesty", "title": "Mining useful Macro-actions in Planning", "comments": "International Conference on Artificial Intelligence and Pattern\n  Recognition, 2016", "journal-ref": "International Conference on Artificial Intelligence and Pattern\n  Recognition, 2016", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning has achieved significant progress in recent years. Among the various\napproaches to scale up plan synthesis, the use of macro-actions has been widely\nexplored. As a first stage towards the development of a solution to learn\non-line macro-actions, we propose an algorithm to identify useful macro-actions\nbased on data mining techniques. The integration in the planning search of\nthese learned macro-actions shows significant improvements over six classical\nplanning benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 09:05:57 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Castellanos-Paez", "Sandra", ""], ["Pellier", "Damien", ""], ["Fiorino", "Humbert", ""], ["Pesty", "Sylvie", ""]]}, {"id": "1810.09150", "submitter": "Damien Pellier", "authors": "Damien Pellier and Bruno Bouzy and Marc M\\'etivier", "title": "Mean-based Heuristic Search for Real-Time Planning", "comments": "Journ\\'ees Francophones de Planification, D\\'ecision, Apprentissage\n  pour la conduite de syst\\`emes, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new heuristic search algorithm based on mean\nvalues for real-time planning, called MHSP. It consists in associating the\nprinciples of UCT, a bandit-based algorithm which gave very good results in\ncomputer games, and especially in Computer Go, with heuristic search in order\nto obtain a real-time planner in the context of classical planning. MHSP is\nevaluated on different planning problems and compared to existing algorithms\nperforming on-line search and learning. Besides, our results highlight the\ncapacity of MHSP to return plans in a real-time manner which tend to an optimal\nplan over the time which is faster and of better quality compared to existing\nalgorithms in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 09:32:55 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Pellier", "Damien", ""], ["Bouzy", "Bruno", ""], ["M\u00e9tivier", "Marc", ""]]}, {"id": "1810.09171", "submitter": "Fabian Neuhaus", "authors": "Fabian Neuhaus", "title": "What is an Ontology?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the knowledge engineering community \"ontology\" is usually defined in the\ntradition of Gruber as an \"explicit specification of a conceptualization\".\nSeveral variations of this definition exist. In the paper we argue that (with\none notable exception) these definitions are of no explanatory value, because\nthey violate one of the basic rules for good definitions: The defining\nstatement (the definiens) should be clearer than the term that is defined (the\ndefiniendum). In the paper we propose a different definition of \"ontology\" and\ndiscuss how it helps to explain various phenomena: the ability of ontologies to\nchange, the role of the choice of vocabulary, the significance of annotations,\nthe possibility of collaborative ontology development, and the relationship\nbetween ontological conceptualism and ontological realism.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 10:47:03 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Neuhaus", "Fabian", ""]]}, {"id": "1810.09202", "submitter": "Zongqing Lu", "authors": "Jiechuan Jiang, Chen Dun, Tiejun Huang, and Zongqing Lu", "title": "Graph Convolutional Reinforcement Learning", "comments": "ICLR'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to cooperate is crucially important in multi-agent environments. The\nkey is to understand the mutual interplay between agents. However, multi-agent\nenvironments are highly dynamic, where agents keep moving and their neighbors\nchange quickly. This makes it hard to learn abstract representations of mutual\ninterplay between agents. To tackle these difficulties, we propose graph\nconvolutional reinforcement learning, where graph convolution adapts to the\ndynamics of the underlying graph of the multi-agent environment, and relation\nkernels capture the interplay between agents by their relation representations.\nLatent features produced by convolutional layers from gradually increased\nreceptive fields are exploited to learn cooperation, and cooperation is further\nimproved by temporal relation regularization for consistency. Empirically, we\nshow that our method substantially outperforms existing methods in a variety of\ncooperative scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 12:17:40 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 12:42:24 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 05:21:13 GMT"}, {"version": "v4", "created": "Tue, 4 Feb 2020 03:22:09 GMT"}, {"version": "v5", "created": "Tue, 11 Feb 2020 13:46:23 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Jiang", "Jiechuan", ""], ["Dun", "Chen", ""], ["Huang", "Tiejun", ""], ["Lu", "Zongqing", ""]]}, {"id": "1810.09206", "submitter": "Heechang Ryu", "authors": "Heechang Ryu, Hayong Shin, Jinkyoo Park", "title": "Multi-Agent Actor-Critic with Generative Cooperative Policy Network", "comments": "10 pages, total 9 figures including all sub-figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an efficient multi-agent reinforcement learning approach to derive\nequilibrium strategies for multi-agents who are participating in a Markov game.\nMainly, we are focused on obtaining decentralized policies for agents to\nmaximize the performance of a collaborative task by all the agents, which is\nsimilar to solving a decentralized Markov decision process. We propose to use\ntwo different policy networks: (1) decentralized greedy policy network used to\ngenerate greedy action during training and execution period and (2) generative\ncooperative policy network (GCPN) used to generate action samples to make other\nagents improve their objectives during training period. We show that the\nsamples generated by GCPN enable other agents to explore the policy space more\neffectively and favorably to reach a better policy in terms of achieving the\ncollaborative tasks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 12:24:11 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Ryu", "Heechang", ""], ["Shin", "Hayong", ""], ["Park", "Jinkyoo", ""]]}, {"id": "1810.09245", "submitter": "Damien Pellier", "authors": "Ankuj Arora and Humbert Fiorino and Damien Pellier and Sylvie Pesty", "title": "A Review on Learning Planning Action Models for Socio-Communicative HRI", "comments": "Workshop on Affect, Artifcial Compagnon and Interaction, 2016", "journal-ref": "Workshop on Affect, Artifcial Compagnon and Interaction, 2016", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For social robots to be brought more into widespread use in the fields of\ncompanionship, care taking and domestic help, they must be capable of\ndemonstrating social intelligence. In order to be acceptable, they must exhibit\nsocio-communicative skills. Classic approaches to program HRI from observed\nhuman-human interactions fails to capture the subtlety of multimodal\ninteractions as well as the key structural differences between robots and\nhumans. The former arises due to a difficulty in quantifying and coding\nmultimodal behaviours, while the latter due to a difference of the degrees of\nliberty between a robot and a human. However, the notion of reverse engineering\nfrom multimodal HRI traces to learn the underlying behavioral blueprint of the\nrobot given multimodal traces seems an option worth exploring. With this\nspirit, the entire HRI can be seen as a sequence of exchanges of speech acts\nbetween the robot and human, each act treated as an action, bearing in mind\nthat the entire sequence is goal-driven. Thus, this entire interaction can be\ntreated as a sequence of actions propelling the interaction from its initial to\ngoal state, also known as a plan in the domain of AI planning. In the same\ndomain, this action sequence that stems from plan execution can be represented\nas a trace. AI techniques, such as machine learning, can be used to learn\nbehavioral models (also known as symbolic action models in AI), intended to be\nreusable for AI planning, from the aforementioned multimodal traces. This\narticle reviews recent machine learning techniques for learning planning action\nmodels which can be applied to the field of HRI with the intent of rendering\nrobots as socio-communicative.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 13:17:28 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Arora", "Ankuj", ""], ["Fiorino", "Humbert", ""], ["Pellier", "Damien", ""], ["Pesty", "Sylvie", ""]]}, {"id": "1810.09302", "submitter": "Qingyu Chen", "authors": "Qingyu Chen, Yifan Peng, and Zhiyong Lu", "title": "BioSentVec: creating sentence embeddings for biomedical texts", "comments": "5 pages, 3 tables and 2 figures accepted by The Seventh IEEE\n  International Conference on Healthcare Informatics (ICHI 2019)", "journal-ref": null, "doi": "10.1109/ICHI.2019.8904728", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence embeddings have become an essential part of today's natural language\nprocessing (NLP) systems, especially together advanced deep learning methods.\nAlthough pre-trained sentence encoders are available in the general domain,\nnone exists for biomedical texts to date. In this work, we introduce\nBioSentVec: the first open set of sentence embeddings trained with over 30\nmillion documents from both scholarly articles in PubMed and clinical notes in\nthe MIMIC-III Clinical Database. We evaluate BioSentVec embeddings in two\nsentence pair similarity tasks in different text genres. Our benchmarking\nresults demonstrate that the BioSentVec embeddings can better capture sentence\nsemantics compared to the other competitive alternatives and achieve\nstate-of-the-art performance in both tasks. We expect BioSentVec to facilitate\nthe research and development in biomedical text mining and to complement the\nexisting resources in biomedical word embeddings. BioSentVec is publicly\navailable at https://github.com/ncbi-nlp/BioSentVec\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 14:10:01 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 15:04:19 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 04:41:06 GMT"}, {"version": "v4", "created": "Tue, 18 Jun 2019 13:46:32 GMT"}, {"version": "v5", "created": "Wed, 19 Jun 2019 00:33:32 GMT"}, {"version": "v6", "created": "Fri, 24 Jan 2020 21:48:13 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Chen", "Qingyu", ""], ["Peng", "Yifan", ""], ["Lu", "Zhiyong", ""]]}, {"id": "1810.09304", "submitter": "Marie-Laure Mugnier", "authors": "Stathis Delivorias, Michel Leclere, Marie-Laure Mugnier and Federico\n  Ulliana", "title": "On the k-Boundedness for Existential Rules", "comments": "20 pages, revised version of the paper published at RuleML+RR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The chase is a fundamental tool for existential rules. Several chase variants\nare known, which differ on how they handle redundancies possibly caused by the\nintroduction of nulls. Given a chase variant, the halting problem takes as\ninput a set of existential rules and asks if this set of rules ensures the\ntermination of the chase for any factbase. It is well-known that this problem\nis undecidable for all known chase variants. The related problem of boundedness\nasks if a given set of existential rules is bounded, i.e., whether there is a\npredefined upper bound on the number of (breadth-first) steps of the chase,\nindependently from any factbase. This problem is already undecidable in the\nspecific case of datalog rules. However, knowing that a set of rules is bounded\nfor some chase variant does not help much in practice if the bound is unknown.\nHence, in this paper, we investigate the decidability of the k-boundedness\nproblem, which asks whether a given set of rules is bounded by an integer k. We\nprove that k-boundedness is decidable for three chase variants, namely the\noblivious, semi-oblivious and restricted chase.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 14:12:03 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Delivorias", "Stathis", ""], ["Leclere", "Michel", ""], ["Mugnier", "Marie-Laure", ""], ["Ulliana", "Federico", ""]]}, {"id": "1810.09352", "submitter": "Riccardo Guidotti", "authors": "Riccardo Guidotti, Salvatore Ruggieri", "title": "On The Stability of Interpretable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable classification models are built with the purpose of providing a\ncomprehensible description of the decision logic to an external oversight\nagent. When considered in isolation, a decision tree, a set of classification\nrules, or a linear model, are widely recognized as human-interpretable.\nHowever, such models are generated as part of a larger analytical process. Bias\nin data collection and preparation, or in model's construction may severely\naffect the accountability of the design process. We conduct an experimental\nstudy of the stability of interpretable models with respect to feature\nselection, instance selection, and model selection. Our conclusions should\nraise awareness and attention of the scientific community on the need of a\nstability impact assessment of interpretable models.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 15:16:53 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 08:45:23 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Guidotti", "Riccardo", ""], ["Ruggieri", "Salvatore", ""]]}, {"id": "1810.09391", "submitter": "Constantine Dovrolis", "authors": "Constantine Dovrolis", "title": "A neuro-inspired architecture for unsupervised continual learning based\n  on online clustering and hierarchical predictive coding", "comments": "Under peer-review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose that the Continual Learning desiderata can be achieved through a\nneuro-inspired architecture, grounded on Mountcastle's cortical column\nhypothesis. The proposed architecture involves a single module, called\nSelf-Taught Associative Memory (STAM), which models the function of a cortical\ncolumn. STAMs are repeated in multi-level hierarchies involving feedforward,\nlateral and feedback connections. STAM networks learn in an unsupervised\nmanner, based on a combination of online clustering and hierarchical predictive\ncoding. This short paper only presents the architecture and its connections\nwith neuroscience. A mathematical formulation and experimental results will be\npresented in an extended version of this paper.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 16:27:21 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Dovrolis", "Constantine", ""]]}, {"id": "1810.09431", "submitter": "Christopher Shulby", "authors": "Christopher Dane Shulby, Leonardo Pombal, Vitor Jord\\~ao, Guilherme\n  Ziolle, Bruno Martho, Ant\\^onio Postal, Thiago Prochnow", "title": "Proactive Security: Embedded AI Solution for Violent and Abusive Speech\n  Recognition", "comments": "6 Pages, Bracis 2018 Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Violence is an epidemic in Brazil and a problem on the rise world-wide.\nMobile devices provide communication technologies which can be used to monitor\nand alert about violent situations. However, current solutions, like panic\nbuttons or safe words, might increase the loss of life in violent situations.\nWe propose an embedded artificial intelligence solution, using natural language\nand speech processing technology, to silently alert someone who can help in\nthis situation. The corpus used contains 400 positive phrases and 800 negative\nphrases, totaling 1,200 sentences which are classified using two well-known\nextraction methods for natural language processing tasks: bag-of-words and word\nembeddings and classified with a support vector machine. We describe the\nproof-of-concept product in development with promising results, indicating a\npath towards a commercial product. More importantly we show that model\nimprovements via word embeddings and data augmentation techniques provide an\nintrinsically robust model. The final embedded solution also has a small\nfootprint of less than 10 MB.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 17:56:08 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Shulby", "Christopher Dane", ""], ["Pombal", "Leonardo", ""], ["Jord\u00e3o", "Vitor", ""], ["Ziolle", "Guilherme", ""], ["Martho", "Bruno", ""], ["Postal", "Ant\u00f4nio", ""], ["Prochnow", "Thiago", ""]]}, {"id": "1810.09590", "submitter": "R.Stuart Geiger", "authors": "R. Stuart Geiger", "title": "The Lives of Bots", "comments": "Originally published in 2011", "journal-ref": "Book chapter in __Wikipedia: A Critical Point of View__ (Institute\n  of Network Cultures, Amsterdam), 2011", "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automated software agents --- or bots --- have long been an important part of\nhow Wikipedia's volunteer community of editors write, edit, update, monitor,\nand moderate content. In this paper, I discuss the complex social and technical\nenvironment in which Wikipedia's bots operate. This paper focuses on the\nestablishment and role of English Wikipedia's bot policies and the Bot\nApprovals Group, a volunteer committee that reviews applications for new bots\nand helps resolve conflicts between Wikipedians about automation. In\nparticular, I examine an early bot controversy over the first bot in Wikipedia\nto automatically enforce a social norm about how Wikipedian editors ought to\ninteract in discussion spaces. As I show, bots enforce many rules in Wikipedia,\nbut humans produce these bots and negotiate rules around their operation.\nBecause of the openness of Wikipedia's processes around automation, we can\nvividly observe the often-invisible human work involved in such algorithmic\nsystems --- in stark contrast to most other user-generated content platforms.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 23:04:05 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Geiger", "R. Stuart", ""]]}, {"id": "1810.09591", "submitter": "Malay Haldar", "authors": "Malay Haldar, Mustafa Abdool, Prashant Ramanathan, Tao Xu, Shulin\n  Yang, Huizhong Duan, Qing Zhang, Nick Barrow-Williams, Bradley C. Turnbull,\n  Brendan M. Collins and Thomas Legrand", "title": "Applying Deep Learning To Airbnb Search", "comments": "8 pages", "journal-ref": null, "doi": "10.1145/3292500.3330658", "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application to search ranking is one of the biggest machine learning\nsuccess stories at Airbnb. Much of the initial gains were driven by a gradient\nboosted decision tree model. The gains, however, plateaued over time. This\npaper discusses the work done in applying neural networks in an attempt to\nbreak out of that plateau. We present our perspective not with the intention of\npushing the frontier of new modeling techniques. Instead, ours is a story of\nthe elements we found useful in applying neural networks to a real life\nproduct. Deep learning was steep learning for us. To other teams embarking on\nsimilar journeys, we hope an account of our struggles and triumphs will provide\nsome useful pointers. Bon voyage!\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 23:11:01 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 18:28:03 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Haldar", "Malay", ""], ["Abdool", "Mustafa", ""], ["Ramanathan", "Prashant", ""], ["Xu", "Tao", ""], ["Yang", "Shulin", ""], ["Duan", "Huizhong", ""], ["Zhang", "Qing", ""], ["Barrow-Williams", "Nick", ""], ["Turnbull", "Bradley C.", ""], ["Collins", "Brendan M.", ""], ["Legrand", "Thomas", ""]]}, {"id": "1810.09597", "submitter": "Setu Shah", "authors": "Setu Shah and Xiao Luo", "title": "Biomedical Document Clustering and Visualization based on the Concepts\n  of Diseases", "comments": "KDD 2017's Data Driven Discovery Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document clustering is a text mining technique used to provide better\ndocument search and browsing in digital libraries or online corpora. A lot of\nresearch has been done on biomedical document clustering that is based on using\nexisting ontology. But, associations and co-occurrences of the medical concepts\nare not well represented by using ontology. In this research, a vector\nrepresentation of concepts of diseases and similarity measurement between\nconcepts are proposed. They identify the closest concepts of diseases in the\ncontext of a corpus. Each document is represented by using the vector space\nmodel. A weight scheme is proposed to consider both local content and\nassociations between concepts. A Self-Organizing Map is used as document\nclustering algorithm. The vector projection and visualization features of SOM\nenable visualization and analysis of the clusters distributions and\nrelationships on the two dimensional space. The experimental results show that\nthe proposed document clustering framework generates meaningful clusters and\nfacilitate visualization of the clusters based on the concepts of diseases.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 23:37:31 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Shah", "Setu", ""], ["Luo", "Xiao", ""]]}, {"id": "1810.09598", "submitter": "Tae Wan Kim", "authors": "Tae Wan Kim", "title": "Explainable artificial intelligence (XAI), the goodness criteria and the\n  grasp-ability test", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the \"grasp-ability test\" as a \"goodness\" criteria by\nwhich to compare which explanation is more or less meaningful than others for\nusers to understand the automated algorithmic data processing.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 23:40:20 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Kim", "Tae Wan", ""]]}, {"id": "1810.09620", "submitter": "Derek Doran", "authors": "Giuseppe Nebbione, Derek Doran, Srikanth Nadella, Brandon Minnery", "title": "Deep Neural Ranking for Crowdsourced Geopolitical Event Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many examples of 'wisdom of the crowd' effects in which the large\nnumber of participants imparts confidence in the collective judgment of the\ncrowd. But how do we form an aggregated judgment when the size of the crowd is\nlimited? Whose judgments do we include, and whose do we accord the most weight?\nThis paper considers this problem in the context of geopolitical event\nforecasting, where volunteer analysts are queried to give their expertise,\nconfidence, and predictions about the outcome of an event. We develop a\nforecast aggregation model that integrates topical information about a\nquestion, meta-data about a pair of forecasters, and their predictions in a\ndeep siamese neural network that decides which forecasters' predictions are\nmore likely to be close to the correct response. A ranking of the forecasters\nis induced from a tournament of pair-wise forecaster comparisons, with the\nranking used to create an aggregate forecast. Preliminary results find the\naggregate prediction of the best forecasters ranked by our deep siamese network\nmodel consistently beats typical aggregation techniques by Brier score.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 01:08:25 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Nebbione", "Giuseppe", ""], ["Doran", "Derek", ""], ["Nadella", "Srikanth", ""], ["Minnery", "Brandon", ""]]}, {"id": "1810.09648", "submitter": "Shi Feng", "authors": "Shi Feng, Jordan Boyd-Graber", "title": "What can AI do for me: Evaluating Machine Learning Interpretations in\n  Cooperative Play", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is an important tool for decision making, but its ethical\nand responsible application requires rigorous vetting of its interpretability\nand utility: an understudied problem, particularly for natural language\nprocessing models. We propose an evaluation of interpretation on a real task\nwith real human users, where the effectiveness of interpretation is measured by\nhow much it improves human performance. We design a grounded, realistic\nhuman-computer cooperative setting using a question answering task, Quizbowl.\nWe recruit both trivia experts and novices to play this game with computer as\ntheir teammate, who communicates its prediction via three different\ninterpretations. We also provide design guidance for natural language\nprocessing human-in-the-loop settings.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 03:59:22 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 14:34:06 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 02:39:28 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Feng", "Shi", ""], ["Boyd-Graber", "Jordan", ""]]}, {"id": "1810.09656", "submitter": "Ermo Wei", "authors": "Ermo Wei and Drew Wicke and Sean Luke", "title": "Hierarchical Approaches for Reinforcement Learning in Parameterized\n  Action Space", "comments": "Accepted in AAAI 18 Spring Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore Deep Reinforcement Learning in a parameterized action space.\nSpecifically, we investigate how to achieve sample-efficient end-to-end\ntraining in these tasks. We propose a new compact architecture for the tasks\nwhere the parameter policy is conditioned on the output of the discrete action\npolicy. We also propose two new methods based on the state-of-the-art\nalgorithms Trust Region Policy Optimization (TRPO) and Stochastic Value\nGradient (SVG) to train such an architecture. We demonstrate that these methods\noutperform the state of the art method, Parameterized Action DDPG, on test\ndomains.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 04:52:53 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Wei", "Ermo", ""], ["Wicke", "Drew", ""], ["Luke", "Sean", ""]]}, {"id": "1810.09712", "submitter": "Tomoharu Iwata", "authors": "Tomoharu Iwata, Takuma Otsuka, Hitoshi Shimizu, Hiroshi Sawada,\n  Futoshi Naya, Naonori Ueda", "title": "Finding Appropriate Traffic Regulations via Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Appropriate traffic regulations, e.g. planned road closure, are important in\ncongested events. Crowd simulators have been used to find appropriate\nregulations by simulating multiple scenarios with different regulations.\nHowever, this approach requires multiple simulation runs, which are\ntime-consuming. In this paper, we propose a method to learn a function that\noutputs regulation effects given the current traffic situation as inputs. If\nthe function is learned using the training data of many simulation runs in\nadvance, we can obtain an appropriate regulation efficiently by bypassing\nsimulations for the current situation. We use the graph convolutional networks\nfor modeling the function, which enable us to find regulations even for unseen\nareas. With the proposed method, we construct a graph for each area, where a\nnode represents a road, and an edge represents the road connection. By running\ncrowd simulations with various regulations on various areas, we generate\ntraffic situations and regulation effects. The graph convolutional networks are\ntrained to output the regulation effects given the graph with the traffic\nsituation information as inputs. With experiments using real-world road\nnetworks and a crowd simulator, we demonstrate that the proposed method can\nfind a road to close that reduces the average time needed to reach the\ndestination.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 08:19:33 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Iwata", "Tomoharu", ""], ["Otsuka", "Takuma", ""], ["Shimizu", "Hitoshi", ""], ["Sawada", "Hiroshi", ""], ["Naya", "Futoshi", ""], ["Ueda", "Naonori", ""]]}, {"id": "1810.09717", "submitter": "Jakub Bednarek", "authors": "Jakub Bednarek, Karol Piaskowski, Krzysztof Krawiec", "title": "Ain't Nobody Got Time For Coding: Structure-Aware Program Synthesis From\n  Natural Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program synthesis from natural language (NL) is practical for humans and,\nonce technically feasible, would significantly facilitate software development\nand revolutionize end-user programming. We present SAPS, an end-to-end neural\nnetwork capable of mapping relatively complex, multi-sentence NL specifications\nto snippets of executable code. The proposed architecture relies exclusively on\nneural components, and is trained on abstract syntax trees, combined with a\npretrained word embedding and a bi-directional multi-layer LSTM for processing\nof word sequences. The decoder features a doubly-recurrent LSTM, for which we\npropose novel signal propagation schemes and soft attention mechanism. When\napplied to a large dataset of problems proposed in a previous study, SAPS\nperforms on par with or better than the method proposed there, producing\ncorrect programs in over 92% of cases. In contrast to other methods, it does\nnot require post-processing of the resulting programs, and uses a\nfixed-dimensional latent representation as the only interface between the NL\nanalyzer and the source code generator.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 08:29:11 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 07:17:09 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Bednarek", "Jakub", ""], ["Piaskowski", "Karol", ""], ["Krawiec", "Krzysztof", ""]]}, {"id": "1810.09729", "submitter": "Mohammed Ali Al-Garadi Dr", "authors": "Reza Shakeri, Mohammed Ali Al-Garadi, Ahmed Badawy, Amr Mohamed, Tamer\n  Khattab, Abdulla Al-Ali, Khaled A. Harras, Mohsen Guizani", "title": "Design Challenges of Multi-UAV Systems in Cyber-Physical Applications: A\n  Comprehensive Survey, and Future Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned Aerial Vehicles (UAVs) have recently rapidly grown to facilitate a\nwide range of innovative applications that can fundamentally change the way\ncyber-physical systems (CPSs) are designed. CPSs are a modern generation of\nsystems with synergic cooperation between computational and physical potentials\nthat can interact with humans through several new mechanisms. The main\nadvantages of using UAVs in CPS application is their exceptional features,\nincluding their mobility, dynamism, effortless deployment, adaptive altitude,\nagility, adjustability, and effective appraisal of real-world functions anytime\nand anywhere. Furthermore, from the technology perspective, UAVs are predicted\nto be a vital element of the development of advanced CPSs. Therefore, in this\nsurvey, we aim to pinpoint the most fundamental and important design challenges\nof multi-UAV systems for CPS applications. We highlight key and versatile\naspects that span the coverage and tracking of targets and infrastructure\nobjects, energy-efficient navigation, and image analysis using machine learning\nfor fine-grained CPS applications. Key prototypes and testbeds are also\ninvestigated to show how these practical technologies can facilitate CPS\napplications. We present and propose state-of-the-art algorithms to address\ndesign challenges with both quantitative and qualitative methods and map these\nchallenges with important CPS applications to draw insightful conclusions on\nthe challenges of each application. Finally, we summarize potential new\ndirections and ideas that could shape future research in these areas.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 08:51:54 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Shakeri", "Reza", ""], ["Al-Garadi", "Mohammed Ali", ""], ["Badawy", "Ahmed", ""], ["Mohamed", "Amr", ""], ["Khattab", "Tamer", ""], ["Al-Ali", "Abdulla", ""], ["Harras", "Khaled A.", ""], ["Guizani", "Mohsen", ""]]}, {"id": "1810.09807", "submitter": "Hong Chen", "authors": "Hong Chen, Zhenhua Fan, Hao Lu, Alan L. Yuille and Shu Rong", "title": "PreCo: A Large-scale Dataset in Preschool Vocabulary for Coreference\n  Resolution", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce PreCo, a large-scale English dataset for coreference resolution.\nThe dataset is designed to embody the core challenges in coreference, such as\nentity representation, by alleviating the challenge of low overlap between\ntraining and test sets and enabling separated analysis of mention detection and\nmention clustering. To strengthen the training-test overlap, we collect a large\ncorpus of about 38K documents and 12.4M words which are mostly from the\nvocabulary of English-speaking preschoolers. Experiments show that with higher\ntraining-test overlap, error analysis on PreCo is more efficient than the one\non OntoNotes, a popular existing dataset. Furthermore, we annotate singleton\nmentions making it possible for the first time to quantify the influence that a\nmention detector makes on coreference resolution performance. The dataset is\nfreely available at https://preschool-lab.github.io/PreCo/.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 12:09:37 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Chen", "Hong", ""], ["Fan", "Zhenhua", ""], ["Lu", "Hao", ""], ["Yuille", "Alan L.", ""], ["Rong", "Shu", ""]]}, {"id": "1810.09832", "submitter": "Rediet Abebe", "authors": "Rediet Abebe, Kira Goldner", "title": "Mechanism Design for Social Good", "comments": "AI Matters, 2018", "journal-ref": null, "doi": "10.1145/3284751.328476", "report-no": null, "categories": "cs.GT cs.AI cs.CY cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Across various domains--such as health, education, and housing--improving\nsocietal welfare involves allocating resources, setting policies, targeting\ninterventions, and regulating activities. These solutions have an immense\nimpact on the day-to-day lives of individuals, whether in the form of access to\nquality healthcare, labor market outcomes, or how votes are accounted for in a\ndemocratic society. Problems that can have an out-sized impact on individuals\nwhose opportunities have historically been limited often pose conceptual and\ntechnical challenges, requiring insights from many disciplines. Conversely, the\nlack of interdisciplinary approach can leave these urgent needs unaddressed and\ncan even exacerbate underlying socioeconomic inequalities. To realize the\nopportunities in these domains, we need to correctly set objectives and reason\nabout human behavior and actions. Doing so requires a deep grounding in the\nfield of interest and collaboration with domain experts who understand the\nsocietal implications and feasibility of proposed solutions. These insights can\nplay an instrumental role in proposing algorithmically-informed policies.\n  In this article, we describe the Mechanism Design for Social Good (MD4SG)\nresearch agenda, which involves using insights from algorithms, optimization,\nand mechanism design to improve access to opportunity. The MD4SG research\ncommunity takes an interdisciplinary, multi-stakeholder approach to improve\nsocietal welfare. We discuss three exciting research avenues within MD4SG\nrelated to improving access to opportunity in the developing world, labor\nmarkets and discrimination, and housing. For each of these, we showcase ongoing\nwork, underline new directions, and discuss potential for implementing existing\nwork in practice.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 18:41:52 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Abebe", "Rediet", ""], ["Goldner", "Kira", ""]]}, {"id": "1810.09845", "submitter": "Bhairav Mehta", "authors": "Bhairav Mehta, Adithya Ramanathan", "title": "A Scalable, Flexible Augmentation of the Student Education Process", "comments": "Accepted to NIPS 2018 AI for Social Good Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel intelligent tutoring system which builds upon\nwell-established hypotheses in educational psychology and incorporates them\ninside of a scalable software architecture. Specifically, we build upon the\nknown benefits of knowledge vocalization, parallel learning, and immediate\nfeedback in the context of student learning. We show that open-source data\ncombined with state-of-the-art techniques in deep learning and natural language\nprocessing can apply the benefits of these three factors at scale, while still\noperating at the granularity of individual student needs and recommendations.\nAdditionally, we allow teachers to retain full control of the outputs of the\nalgorithms, and provide student statistics to help better guide classroom\ndiscussions towards topics that would benefit from more in-person review and\ncoverage. Our experiments and pilot programs show promising results, and cement\nour hypothesis that the system is flexible enough to serve a wide variety of\npurposes in both classroom and classroom-free settings.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 04:47:52 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 21:51:25 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Mehta", "Bhairav", ""], ["Ramanathan", "Adithya", ""]]}, {"id": "1810.09854", "submitter": "Lukas Mauch", "authors": "Lukas Mauch and Bin Yang", "title": "Deep Neural Network inference with reduced word length", "comments": "submitted to ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) are powerful models for many pattern recognition\ntasks, yet their high computational complexity and memory requirement limit\nthem to applications on high-performance computing platforms. In this paper, we\npropose a new method to evaluate DNNs trained with 32bit floating point\n(float32) accuracy using only low precision integer arithmetics in combination\nwith binary shift and clipping operations. Because hardware implementation of\nthese operations is much simpler than high precision floating point\ncalculation, our method can be used for an efficient DNN inference on dedicated\nhardware. In experiments on MNIST, we demonstrate that DNNs trained with\nfloat32 can be evaluated using a combination of 2bit integer arithmetics and a\nfew float32 calculations in each layer or only 3bit integer arithmetics in\ncombination with binary shift and clipping without significant performance\ndegradation.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 13:48:53 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Mauch", "Lukas", ""], ["Yang", "Bin", ""]]}, {"id": "1810.09879", "submitter": "Sebastian Kahl", "authors": "Sebastian Kahl, Stefan Kopp", "title": "A predictive processing model of perception and action for self-other\n  distinction", "comments": "Main text including supplementary materials. This manuscript ist\n  currently under review at Frontiers in Psychology Cognitive Science", "journal-ref": null, "doi": "10.3389/fpsyg.2018.02421", "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During interaction with others, we perceive and produce social actions in\nclose temporal distance or even simultaneously. It has been argued that the\nmotor system is involved in perception and action, playing a fundamental role\nin the handling of actions produced by oneself and by others. But how does it\ndistinguish in this processing between self and other, thus contributing to\nself-other distinction? In this paper we propose a hierarchical model of\nsensorimotor coordination based on principles of perception-action coupling and\npredictive processing in which self-other distinction arises during action and\nperception. For this we draw on mechanisms assumed for the integration of cues\nfor a sense of agency, i.e., the sense that an action is self-generated. We\nreport results from simulations of different scenarios, showing that the model\nis not only able to minimize free energy during perception and action, but also\nshowing that the model can correctly attribute sense of agency to own actions.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 14:27:30 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 11:44:00 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Kahl", "Sebastian", ""], ["Kopp", "Stefan", ""]]}, {"id": "1810.09923", "submitter": "Pawel Gomoluch", "authors": "Pawel Gomoluch, Dalal Alrajeh, Alessandra Russo", "title": "Learning Classical Planning Strategies with Policy Gradient", "comments": "Accepted for ICAPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common paradigm in classical planning is heuristic forward search. Forward\nsearch planners often rely on simple best-first search which remains fixed\nthroughout the search process. In this paper, we introduce a novel search\nframework capable of alternating between several forward search approaches\nwhile solving a particular planning problem. Selection of the approach is\nperformed using a trainable stochastic policy, mapping the state of the search\nto a probability distribution over the approaches. This enables using policy\ngradient to learn search strategies tailored to a specific distributions of\nplanning problems and a selected performance metric, e.g. the IPC score. We\ninstantiate the framework by constructing a policy space consisting of five\nsearch approaches and a two-dimensional representation of the planner's state.\nThen, we train the system on randomly generated problems from five IPC domains\nusing three different performance metrics. Our experimental results show that\nthe learner is able to discover domain-specific search strategies, improving\nthe planner's performance relative to the baselines of plain best-first search\nand a uniform policy.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 15:44:44 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 16:15:22 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Gomoluch", "Pawel", ""], ["Alrajeh", "Dalal", ""], ["Russo", "Alessandra", ""]]}, {"id": "1810.09949", "submitter": "Natsuki Oka", "authors": "Akane Matsushima, Ryosuke Kanajiri, Yusuke Hattori, Chie Fukada,\n  Natsuki Oka", "title": "Stepwise Acquisition of Dialogue Act Through Human-Robot Interaction", "comments": "Published as a conference paper at IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A dialogue act (DA) represents the meaning of an utterance at the\nillocutionary force level (Austin 1962) such as a question, a request, and a\ngreeting. Since DAs take charge of the most fundamental part of communication,\nwe believe that the elucidation of DA learning mechanism is important for\ncognitive science and artificial intelligence. The purpose of this study is to\nverify that scaffolding takes place when a human teaches a robot, and to let a\nrobot learn to estimate DAs and to make a response based on them step by step\nutilizing scaffolding provided by a human. To realize that, it is necessary for\nthe robot to detect changes in utterance and rewards given by the partner and\ncontinue learning accordingly. Experimental results demonstrated that\nparticipants who continued interaction for a sufficiently long time often gave\nscaffolding for the robot. Although the number of experiments is still\ninsufficient to obtain a definite conclusion, we observed that 1) the robot\nquickly learned to respond to DAs in most cases if the participants only spoke\nutterances that match the situation, 2) in the case of participants who builds\nscaffolding differently from what we assumed, learning did not proceed quickly,\nand 3) the robot could learn to estimate DAs almost exactly if the participants\nkept interaction for a sufficiently long time even if the scaffolding was\nunexpected.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 16:28:27 GMT"}, {"version": "v2", "created": "Sun, 28 Apr 2019 07:11:35 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Matsushima", "Akane", ""], ["Kanajiri", "Ryosuke", ""], ["Hattori", "Yusuke", ""], ["Fukada", "Chie", ""], ["Oka", "Natsuki", ""]]}, {"id": "1810.09993", "submitter": "Tomer Libal", "authors": "Tomer Libal and Matteo Pascucci", "title": "Automated Reasoning in Normative Detachment Structures with Ideal\n  Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems of deontic logic suffer either from being too expressive and\ntherefore hard to mechanize, or from being too simple to capture relevant\naspects of normative reasoning. In this article we look for a suitable way in\nbetween: the automation of a simple logic of normative ideality and\nsub-ideality that is not affected by many deontic paradoxes and that is\nexpressive enough to capture contrary-to-duty reason- ing. We show that this\nlogic is very useful to reason on normative scenarios from which one can\nextract a certain kind of argumentative structure, called a Normative\nDetachment Structure with Ideal Conditions. The theoretical analysis of the\nlogic is accompanied by examples of automated reasoning on a concrete legal\ntext.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 17:52:36 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Libal", "Tomer", ""], ["Pascucci", "Matteo", ""]]}, {"id": "1810.10031", "submitter": "Mohammad Hashemi", "authors": "Mohammad Hashemi, Greg Cusack, Eric Keller", "title": "Stochastic Substitute Training: A Gray-box Approach to Craft Adversarial\n  Examples Against Gradient Obfuscation Defenses", "comments": "Accepted by AISec '18: 11th ACM Workshop on Artificial Intelligence\n  and Security. Source code at https://github.com/S-Mohammad-Hashemi/SST", "journal-ref": null, "doi": "10.1145/3270101.3270111", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that adversaries can craft example inputs to neural\nnetworks which are similar to legitimate inputs but have been created to\npurposely cause the neural network to misclassify the input. These adversarial\nexamples are crafted, for example, by calculating gradients of a carefully\ndefined loss function with respect to the input. As a countermeasure, some\nresearchers have tried to design robust models by blocking or obfuscating\ngradients, even in white-box settings. Another line of research proposes\nintroducing a separate detector to attempt to detect adversarial examples. This\napproach also makes use of gradient obfuscation techniques, for example, to\nprevent the adversary from trying to fool the detector. In this paper, we\nintroduce stochastic substitute training, a gray-box approach that can craft\nadversarial examples for defenses which obfuscate gradients. For those defenses\nthat have tried to make models more robust, with our technique, an adversary\ncan craft adversarial examples with no knowledge of the defense. For defenses\nthat attempt to detect the adversarial examples, with our technique, an\nadversary only needs very limited information about the defense to craft\nadversarial examples. We demonstrate our technique by applying it against two\ndefenses which make models more robust and two defenses which detect\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 18:14:47 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Hashemi", "Mohammad", ""], ["Cusack", "Greg", ""], ["Keller", "Eric", ""]]}, {"id": "1810.10096", "submitter": "Jacob Rafati", "authors": "Jacob Rafati and David C. Noelle", "title": "Learning Representations in Model-Free Hierarchical Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common approaches to Reinforcement Learning (RL) are seriously challenged by\nlarge-scale applications involving huge state spaces and sparse delayed reward\nfeedback. Hierarchical Reinforcement Learning (HRL) methods attempt to address\nthis scalability issue by learning action selection policies at multiple levels\nof temporal abstraction. Abstraction can be had by identifying a relatively\nsmall set of states that are likely to be useful as subgoals, in concert with\nthe learning of corresponding skill policies to achieve those subgoals. Many\napproaches to subgoal discovery in HRL depend on the analysis of a model of the\nenvironment, but the need to learn such a model introduces its own problems of\nscale. Once subgoals are identified, skills may be learned through intrinsic\nmotivation, introducing an internal reward signal marking subgoal attainment.\nIn this paper, we present a novel model-free method for subgoal discovery using\nincremental unsupervised learning over a small memory of the most recent\nexperiences (trajectories) of the agent. When combined with an intrinsic\nmotivation learning mechanism, this method learns both subgoals and skills,\nbased on experiences in the environment. Thus, we offer an original approach to\nHRL that does not require the acquisition of a model of the environment,\nsuitable for large-scale applications. We demonstrate the efficiency of our\nmethod on two RL problems with sparse delayed feedback: a variant of the rooms\nenvironment and the first screen of the ATARI 2600 Montezuma's Revenge game.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 21:24:06 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 21:19:51 GMT"}, {"version": "v3", "created": "Fri, 12 Apr 2019 16:37:31 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Rafati", "Jacob", ""], ["Noelle", "David C.", ""]]}, {"id": "1810.10102", "submitter": "Saleh Mousa", "authors": "Saleh Mousa, Sherif Ishak", "title": "Comparative Evaluation of Tree-Based Ensemble Algorithms for Short-Term\n  Travel Time Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Disseminating accurate travel time information to road users helps achieve\ntraffic equilibrium and reduce traffic congestion. The deployment of Connected\nVehicles technology will provide unique opportunities for the implementation of\ntravel time prediction models. The aim of this study is twofold: (1) estimate\ntravel times in the freeway network at five-minute intervals using Basic Safety\nMessages (BSM); (2) develop an eXtreme Gradient Boosting (XGB) model for\nshort-term travel time prediction on freeways. The XGB tree-based ensemble\nprediction model is evaluated against common tree-based ensemble algorithms and\nthe evaluations are performed at five-minute intervals over a 30-minute\nhorizon. BSMs generated by the Safety Pilot Model Deployment conducted in Ann\nArbor, Michigan, were used. Nearly two billion messages were processed for\nproviding travel time estimates for the entire freeway network. A Combination\nof grid search and five-fold cross-validation techniques using the travel time\nestimates were used for developing the prediction models and tuning their\nparameters. About 9.6 km freeway stretch was used for evaluating the XGB\ntogether with the most common tree-based ensemble algorithms. The results show\nthat XGB is superior to all other algorithms, followed by the Gradient\nBoosting. XGB travel time predictions were accurate and consistent with\nvariations during peak periods, with mean absolute percentage error in\nprediction about 5.9% and 7.8% for 5-minute and 30-minute horizons,\nrespectively. Additionally, through applying the developed models to another\n4.7 km stretch along the eastbound segment of M-14, the XGB demonstrated its\nconsiderable advantages in travel time prediction during congested and\nuncongested conditions.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 21:41:41 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Mousa", "Saleh", ""], ["Ishak", "Sherif", ""]]}, {"id": "1810.10126", "submitter": "Yang Li", "authors": "Yang Li, Lukasz Kaiser, Samy Bengio, Si Si", "title": "Area Attention", "comments": "@InProceedings{pmlr-v97-li19e, title = {Area Attention}, author =\n  {Li, Yang and Kaiser, Lukasz and Bengio, Samy and Si, Si}, booktitle =\n  {Proceedings of the 36th International Conference on Machine Learning}, pages\n  = {3846--3855}, year = {2019}, volume = {97}, series = {Proceedings of\n  Machine Learning Research}, publisher = {PMLR} }", "journal-ref": "ICML 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing attention mechanisms are trained to attend to individual items in a\ncollection (the memory) with a predefined, fixed granularity, e.g., a word\ntoken or an image grid. We propose area attention: a way to attend to areas in\nthe memory, where each area contains a group of items that are structurally\nadjacent, e.g., spatially for a 2D memory such as images, or temporally for a\n1D memory such as natural language sentences. Importantly, the shape and the\nsize of an area are dynamically determined via learning, which enables a model\nto attend to information with varying granularity. Area attention can easily\nwork with existing model architectures such as multi-head attention for\nsimultaneously attending to multiple areas in the memory. We evaluate area\nattention on two tasks: neural machine translation (both character and\ntoken-level) and image captioning, and improve upon strong (state-of-the-art)\nbaselines in all the cases. These improvements are obtainable with a basic form\nof area attention that is parameter free.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 23:14:27 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 22:01:08 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 01:31:26 GMT"}, {"version": "v4", "created": "Tue, 5 Feb 2019 19:58:57 GMT"}, {"version": "v5", "created": "Thu, 23 May 2019 23:34:46 GMT"}, {"version": "v6", "created": "Wed, 5 Jun 2019 22:07:12 GMT"}, {"version": "v7", "created": "Thu, 7 May 2020 21:55:04 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Li", "Yang", ""], ["Kaiser", "Lukasz", ""], ["Bengio", "Samy", ""], ["Si", "Si", ""]]}, {"id": "1810.10147", "submitter": "Hao Zhu", "authors": "Xu Han, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao, Zhiyuan Liu,\n  Maosong Sun", "title": "FewRel: A Large-Scale Supervised Few-Shot Relation Classification\n  Dataset with State-of-the-Art Evaluation", "comments": "EMNLP 2018. The first four authors contribute equally. The order is\n  determined by dice rolling. Visit our website http://zhuhao.me/fewrel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a Few-Shot Relation Classification Dataset (FewRel), consisting of\n70, 000 sentences on 100 relations derived from Wikipedia and annotated by\ncrowdworkers. The relation of each sentence is first recognized by distant\nsupervision methods, and then filtered by crowdworkers. We adapt the most\nrecent state-of-the-art few-shot learning methods for relation classification\nand conduct a thorough evaluation of these methods. Empirical results show that\neven the most competitive few-shot learning models struggle on this task,\nespecially as compared with humans. We also show that a range of different\nreasoning skills are needed to solve our task. These results indicate that\nfew-shot relation classification remains an open problem and still requires\nfurther research. Our detailed analysis points multiple directions for future\nresearch. All details and resources about the dataset and baselines are\nreleased on http://zhuhao.me/fewrel.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 01:18:08 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 21:41:46 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Han", "Xu", ""], ["Zhu", "Hao", ""], ["Yu", "Pengfei", ""], ["Wang", "Ziyun", ""], ["Yao", "Yuan", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "1810.10156", "submitter": "Zi Long", "authors": "Shengping Zhou and Zi Long and Lianzhi Tan and Hao Guo", "title": "Automatic Identification of Indicators of Compromise using Neural-Based\n  Sequence Labelling", "comments": "accepted by PACLIC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indicators of Compromise (IOCs) are artifacts observed on a network or in an\noperating system that can be utilized to indicate a computer intrusion and\ndetect cyber-attacks in an early stage. Thus, they exert an important role in\nthe field of cybersecurity. However, state-of-the-art IOCs detection systems\nrely heavily on hand-crafted features with expert knowledge of cybersecurity,\nand require a large amount of supervised training corpora to train an IOC\nclassifier. In this paper, we propose using a neural-based sequence labelling\nmodel to identify IOCs automatically from reports on cybersecurity without\nexpert knowledge of cybersecurity. Our work is the first to apply an end-to-end\nsequence labelling to the task in IOCs identification. By using an attention\nmechanism and several token spelling features, we find that the proposed model\nis capable of identifying the low frequency IOCs from long sentences contained\nin cybersecurity reports. Experiments show that the proposed model outperforms\nother sequence labelling models, achieving over 88% average F1-score.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 02:40:14 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Zhou", "Shengping", ""], ["Long", "Zi", ""], ["Tan", "Lianzhi", ""], ["Guo", "Hao", ""]]}, {"id": "1810.10175", "submitter": "Ye Liu", "authors": "Ye Liu, Jiawei Zhang, Chenwei Zhang, Philip S. Yu", "title": "Data-driven Blockbuster Planning on Online Movie Knowledge Library", "comments": "IEEE BigData", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data, logistic planning can be made data-driven to take\nadvantage of accumulated knowledge in the past. While in the movie industry,\nmovie planning can also exploit the existing online movie knowledge library to\nachieve better results. However, it is ineffective to solely rely on\nconventional heuristics for movie planning, due to a large number of existing\nmovies and various real-world factors that contribute to the success of each\nmovie, such as the movie genre, available budget, production team (involving\nactor, actress, director, and writer), etc. In this paper, we study a\n\"Blockbuster Planning\" (BP) problem to learn from previous movies and plan for\nlow budget yet high return new movies in a totally data-driven fashion. After a\nthorough investigation of an online movie knowledge library, a novel movie\nplanning framework \"Blockbuster Planning with Maximized Movie Configuration\nAcquaintance\" (BigMovie) is introduced in this paper. From the investment\nperspective, BigMovie maximizes the estimated gross of the planned movies with\na given budget. It is able to accurately estimate the movie gross with a 0.26\nmean absolute percentage error (and 0.16 for budget). Meanwhile, from the\nproduction team's perspective, BigMovie is able to formulate an optimized team\nwith people/movie genres that team members are acquainted with. Historical\ncollaboration records are utilized to estimate acquaintance scores of movie\nconfiguration factors via an acquaintance tensor. We formulate the BP problem\nas a non-linear binary programming problem and prove its NP-hardness. To solve\nit in polynomial time, BigMovie relaxes the hard binary constraints and\naddresses the BP problem as a cubic programming problem. Extensive experiments\nconducted on IMDB movie database demonstrate the capability of BigMovie for an\neffective data-driven blockbuster planning.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 03:56:07 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Liu", "Ye", ""], ["Zhang", "Jiawei", ""], ["Zhang", "Chenwei", ""], ["Yu", "Philip S.", ""]]}, {"id": "1810.10181", "submitter": "Zhaopeng Tu", "authors": "Zi-Yi Dou, Zhaopeng Tu, Xing Wang, Shuming Shi, Tong Zhang", "title": "Exploiting Deep Representations for Neural Machine Translation", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced neural machine translation (NMT) models generally implement encoder\nand decoder as multiple layers, which allows systems to model complex functions\nand capture complicated linguistic structures. However, only the top layers of\nencoder and decoder are leveraged in the subsequent process, which misses the\nopportunity to exploit the useful information embedded in other layers. In this\nwork, we propose to simultaneously expose all of these signals with layer\naggregation and multi-layer attention mechanisms. In addition, we introduce an\nauxiliary regularization term to encourage different layers to capture diverse\ninformation. Experimental results on widely-used WMT14 English-German and WMT17\nChinese-English translation data demonstrate the effectiveness and universality\nof the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 04:08:22 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Dou", "Zi-Yi", ""], ["Tu", "Zhaopeng", ""], ["Wang", "Xing", ""], ["Shi", "Shuming", ""], ["Zhang", "Tong", ""]]}, {"id": "1810.10182", "submitter": "Zhaopeng Tu", "authors": "Baosong Yang, Zhaopeng Tu, Derek F. Wong, Fandong Meng, Lidia S. Chao,\n  Tong Zhang", "title": "Modeling Localness for Self-Attention Networks", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention networks have proven to be of profound value for its strength\nof capturing global dependencies. In this work, we propose to model localness\nfor self-attention networks, which enhances the ability of capturing useful\nlocal context. We cast localness modeling as a learnable Gaussian bias, which\nindicates the central and scope of the local region to be paid more attention.\nThe bias is then incorporated into the original attention distribution to form\na revised distribution. To maintain the strength of capturing long distance\ndependencies and enhance the ability of capturing short-range dependencies, we\nonly apply localness modeling to lower layers of self-attention networks.\nQuantitative and qualitative analyses on Chinese-English and English-German\ntranslation tasks demonstrate the effectiveness and universality of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 04:08:25 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Yang", "Baosong", ""], ["Tu", "Zhaopeng", ""], ["Wong", "Derek F.", ""], ["Meng", "Fandong", ""], ["Chao", "Lidia S.", ""], ["Zhang", "Tong", ""]]}, {"id": "1810.10183", "submitter": "Zhaopeng Tu", "authors": "Jian Li, Zhaopeng Tu, Baosong Yang, Michael R. Lyu, Tong Zhang", "title": "Multi-Head Attention with Disagreement Regularization", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-head attention is appealing for the ability to jointly attend to\ninformation from different representation subspaces at different positions. In\nthis work, we introduce a disagreement regularization to explicitly encourage\nthe diversity among multiple attention heads. Specifically, we propose three\ntypes of disagreement regularization, which respectively encourage the\nsubspace, the attended positions, and the output representation associated with\neach attention head to be different from other heads. Experimental results on\nwidely-used WMT14 English-German and WMT17 Chinese-English translation tasks\ndemonstrate the effectiveness and universality of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 04:08:27 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Li", "Jian", ""], ["Tu", "Zhaopeng", ""], ["Yang", "Baosong", ""], ["Lyu", "Michael R.", ""], ["Zhang", "Tong", ""]]}, {"id": "1810.10191", "submitter": "Michelle A. Lee", "authors": "Michelle A. Lee, Yuke Zhu, Krishnan Srinivasan, Parth Shah, Silvio\n  Savarese, Li Fei-Fei, Animesh Garg, Jeannette Bohg", "title": "Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal\n  Representations for Contact-Rich Tasks", "comments": "ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact-rich manipulation tasks in unstructured environments often require\nboth haptic and visual feedback. However, it is non-trivial to manually design\na robot controller that combines modalities with very different\ncharacteristics. While deep reinforcement learning has shown success in\nlearning control policies for high-dimensional inputs, these algorithms are\ngenerally intractable to deploy on real robots due to sample complexity. We use\nself-supervision to learn a compact and multimodal representation of our\nsensory inputs, which can then be used to improve the sample efficiency of our\npolicy learning. We evaluate our method on a peg insertion task, generalizing\nover different geometry, configurations, and clearances, while being robust to\nexternal perturbations. Results for simulated and real robot experiments are\npresented.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 05:21:22 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 03:52:36 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Lee", "Michelle A.", ""], ["Zhu", "Yuke", ""], ["Srinivasan", "Krishnan", ""], ["Shah", "Parth", ""], ["Savarese", "Silvio", ""], ["Fei-Fei", "Li", ""], ["Garg", "Animesh", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1810.10192", "submitter": "Zhongyang Zhang", "authors": "Zhongyang Zhang (1), Ling Zhang (1), Ze Sun (1), Nicholas Erickson\n  (1), Ryan From (2), Jun Fan (1) ((1) Missouri S&T EMC Laboratory, Rolla, MO,\n  USA (2) Boeing Company, St. Louis, MO, USA)", "title": "Solving Poisson's Equation using Deep Learning in Particle Simulation of\n  PN Junction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulating the dynamic characteristics of a PN junction at the microscopic\nlevel requires solving the Poisson's equation at every time step. Solving at\nevery time step is a necessary but time-consuming process when using the\ntraditional finite difference (FDM) approach. Deep learning is a powerful\ntechnique to fit complex functions. In this work, deep learning is utilized to\naccelerate solving Poisson's equation in a PN junction. The role of the\nboundary condition is emphasized in the loss function to ensure a better\nfitting. The resulting I-V curve for the PN junction, using the deep learning\nsolver presented in this work, shows a perfect match to the I-V curve obtained\nusing the finite difference method, with the advantage of being 10 times faster\nat every time step.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 05:25:18 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 01:19:21 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Zhang", "Zhongyang", ""], ["Zhang", "Ling", ""], ["Sun", "Ze", ""], ["Erickson", "Nicholas", ""], ["From", "Ryan", ""], ["Fan", "Jun", ""]]}, {"id": "1810.10237", "submitter": "Zhengchao Zhang", "authors": "Zhengchao Zhang, Meng Li, Xi Lin, Yinhai Wang, Fang He", "title": "Multistep Speed Prediction on Traffic Networks: A Graph Convolutional\n  Sequence-to-Sequence Learning Approach with Attention Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multistep traffic forecasting on road networks is a crucial task in\nsuccessful intelligent transportation system applications. To capture the\ncomplex non-stationary temporal dynamics and spatial dependency in multistep\ntraffic-condition prediction, we propose a novel deep learning framework named\nattention graph convolutional sequence-to-sequence model (AGC-Seq2Seq). In the\nproposed deep learning framework, spatial and temporal dependencies are modeled\nthrough the Seq2Seq model and graph convolution network separately, and the\nattention mechanism along with a newly designed training method based on the\nSeq2Seq architecture is proposed to overcome the difficulty in multistep\nprediction and further capture the temporal heterogeneity of traffic pattern.\nWe conduct numerical tests to compare AGC-Seq2Seq with other benchmark models\nusing a real-world dataset. The results indicate that our model yields the best\nprediction performance in terms of various prediction error measures.\nFurthermore, the variation of spatiotemporal correlation of traffic conditions\nunder different perdition steps and road segments is revealed through\nsensitivity analyses.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 08:22:01 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Zhang", "Zhengchao", ""], ["Li", "Meng", ""], ["Lin", "Xi", ""], ["Wang", "Yinhai", ""], ["He", "Fang", ""]]}, {"id": "1810.10274", "submitter": "Jordi Pons M.Sc.", "authors": "Jordi Pons, Joan Serr\\`a, Xavier Serra", "title": "Training neural audio classifiers with few data", "comments": "Code: https://github.com/jordipons/neural-classifiers-with-few-audio/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate supervised learning strategies that improve the training of\nneural network audio classifiers on small annotated collections. In particular,\nwe study whether (i) a naive regularization of the solution space, (ii)\nprototypical networks, (iii) transfer learning, or (iv) their combination, can\nfoster deep learning models to better leverage a small amount of training\nexamples. To this end, we evaluate (i-iv) for the tasks of acoustic event\nrecognition and acoustic scene classification, considering from 1 to 100\nlabeled examples per class. Results indicate that transfer learning is a\npowerful strategy in such scenarios, but prototypical networks show promising\nresults when one does not count with external or validation data.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 09:59:17 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 21:03:52 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 16:42:07 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Pons", "Jordi", ""], ["Serr\u00e0", "Joan", ""], ["Serra", "Xavier", ""]]}, {"id": "1810.10293", "submitter": "Matvey Ezhov", "authors": "Matvey Ezhov, Adel Zakirov, Maxim Gusarev", "title": "Coarse-to-fine volumetric segmentation of teeth in Cone-Beam CT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of localizing and segmenting individual teeth inside\n3D Cone-Beam Computed Tomography (CBCT) images. To handle large image sizes we\napproach this task with a coarse-to-fine framework, where the whole volume is\nfirst analyzed as a 33-class semantic segmentation (adults have up to 32 teeth)\nin coarse resolution, followed by binary semantic segmentation of the cropped\nregion of interest in original resolution. To improve the performance of the\nchallenging 33-class segmentation, we first train the Coarse step model on a\nlarge weakly labeled dataset, then fine-tune it on a smaller precisely labeled\ndataset. The Fine step model is trained with precise labels only. Experiments\nusing our in-house dataset show significant improvement for both\nweakly-supervised pretraining and for the addition of the Fine step.\nEmpirically, this framework yields precise teeth masks with low localization\nerrors sufficient for many real-world applications.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 11:07:44 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Ezhov", "Matvey", ""], ["Zakirov", "Adel", ""], ["Gusarev", "Maxim", ""]]}, {"id": "1810.10331", "submitter": "Song Li", "authors": "Song Li, Geoffrey Kwok Fai Tso", "title": "Bottleneck Supervised U-Net for Pixel-wise Liver and Tumor Segmentation", "comments": "21 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a bottleneck supervised (BS) U-Net model for liver\nand tumor segmentation. Our main contributions are: first, we propose a\nvariation of the original U-Net that incorporates dense modules, inception\nmodules and dilated convolution in the encoding path; second, we propose a\nbottleneck supervised (BS) U-Net that contains an encoding U-Net and a\nsegmentation U-Net. To train the BS U-Net, the encoding U-Net is first trained\nto get encodings of the label maps that contain the anatomical information\n(shape and location). Subsequently, this information is used to guide the\ntraining of the segmentation U-Net so as to reserve the anatomical features of\nthe target objects. More specifically, the loss function for segmentation U-Net\nis set to be the weighted average of the dice loss and the MSE loss between the\nencodings and the bottleneck feature vectors. The model is applied to a public\nliver and tumor CT scan dataset. Experimental results show that besides\nachieving excellent overall segmentation performance, BS U-Net also works great\nin controlling shape distortion, reducing false positive and false negative\ncases.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 13:02:57 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 01:38:44 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Li", "Song", ""], ["Tso", "Geoffrey Kwok Fai", ""]]}, {"id": "1810.10341", "submitter": "Fabio Cuzzolin", "authors": "Fabio Cuzzolin", "title": "Visions of a generalized probability theory", "comments": null, "journal-ref": "Lambert Academic Publishing, Sep 24 2014", "doi": null, "report-no": null, "categories": "cs.CV cs.AI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this Book we argue that the fruitful interaction of computer vision and\nbelief calculus is capable of stimulating significant advances in both fields.\nFrom a methodological point of view, novel theoretical results concerning the\ngeometric and algebraic properties of belief functions as mathematical objects\nare illustrated and discussed in Part II, with a focus on both a perspective\n'geometric approach' to uncertainty and an algebraic solution to the issue of\nconflicting evidence. In Part III we show how these theoretical developments\narise from important computer vision problems (such as articulated object\ntracking, data association and object pose estimation) to which, in turn, the\nevidential formalism is able to provide interesting new solutions. Finally,\nsome initial steps towards a generalization of the notion of total probability\nto belief functions are taken, in the perspective of endowing the theory of\nevidence with a complete battery of estimation and inference tools to the\nbenefit of all scientists and practitioners.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 14:00:48 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Cuzzolin", "Fabio", ""]]}, {"id": "1810.10343", "submitter": "Felipe Medeiros", "authors": "Felipe A. Medeiros, Alessandro A. Jammal, Atalie C. Thompson", "title": "From Machine to Machine: An OCT-trained Deep Learning Algorithm for\n  Objective Quantification of Glaucomatous Damage in Fundus Photographs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous approaches using deep learning algorithms to classify glaucomatous\ndamage on fundus photographs have been limited by the requirement for human\nlabeling of a reference training set. We propose a new approach using\nspectral-domain optical coherence tomography (SDOCT) data to train a deep\nlearning algorithm to quantify glaucomatous structural damage on optic disc\nphotographs. The dataset included 32,820 pairs of optic disc photos and SDOCT\nretinal nerve fiber layer (RNFL) scans from 2,312 eyes of 1,198 subjects. A\ndeep learning convolutional neural network was trained to assess optic disc\nphotographs and predict SDOCT average RNFL thickness. The performance of the\nalgorithm was evaluated in an independent test sample. The mean prediction of\naverage RNFL thickness from all 6,292 optic disc photos in the test set was\n83.3$\\pm$14.5 $\\mu$m, whereas the mean average RNFL thickness from all\ncorresponding SDOCT scans was 82.5$\\pm$16.8 $\\mu$m (P = 0.164). There was a\nvery strong correlation between predicted and observed RNFL thickness values (r\n= 0.832; P<0.001), with mean absolute error of the predictions of 7.39 $\\mu$m.\nThe areas under the receiver operating characteristic curves for discriminating\nglaucoma from healthy eyes with the deep learning predictions and actual SDOCT\nmeasurements were 0.944 (95$\\%$ CI: 0.912- 0.966) and 0.940 (95$\\%$ CI: 0.902 -\n0.966), respectively (P = 0.724). In conclusion, we introduced a novel deep\nlearning approach to assess optic disc photographs and provide quantitative\ninformation about the amount of neural damage. This approach could potentially\nbe used to diagnose and stage glaucomatous damage from optic disc photographs.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 05:03:42 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Medeiros", "Felipe A.", ""], ["Jammal", "Alessandro A.", ""], ["Thompson", "Atalie C.", ""]]}, {"id": "1810.10351", "submitter": "Hsin-Pai Cheng", "authors": "Hsin-Pai Cheng, Yuanjun Huang, Xuyang Guo, Yifei Huang, Feng Yan, Hai\n  Li, Yiran Chen", "title": "Differentiable Fine-grained Quantization for Deep Neural Network\n  Compression", "comments": "Hsin-Pai Cheng, Yuanjun Huang and Xuyang Guo contributed equally and\n  are co-first authors for this paper. This work has been accepted by NIPS 2018\n  Workshop on Compact Deep Neural Network Representation with Industrial\n  Applications, Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks have shown great performance in cognitive tasks. When\ndeploying network models on mobile devices with limited resources, weight\nquantization has been widely adopted. Binary quantization obtains the highest\ncompression but usually results in big accuracy drop. In practice, 8-bit or\n16-bit quantization is often used aiming at maintaining the same accuracy as\nthe original 32-bit precision. We observe different layers have different\naccuracy sensitivity of quantization. Thus judiciously selecting different\nprecision for different layers/structures can potentially produce more\nefficient models compared to traditional quantization methods by striking a\nbetter balance between accuracy and compression rate. In this work, we propose\na fine-grained quantization approach for deep neural network compression by\nrelaxing the search space of quantization bitwidth from discrete to a\ncontinuous domain. The proposed approach applies gradient descend based\noptimization to generate a mixed-precision quantization scheme that outperforms\nthe accuracy of traditional quantization methods under the same compression\nrate.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 21:48:03 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 08:42:06 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2018 04:10:24 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Cheng", "Hsin-Pai", ""], ["Huang", "Yuanjun", ""], ["Guo", "Xuyang", ""], ["Huang", "Yifei", ""], ["Yan", "Feng", ""], ["Li", "Hai", ""], ["Chen", "Yiran", ""]]}, {"id": "1810.10368", "submitter": "Vincent Fortuin", "authors": "Vincent Fortuin, Gideon Dresdner, Heiko Strathmann, Gunnar R\\\"atsch", "title": "Scalable Gaussian Processes on Discrete Domains", "comments": "Published at IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2021.3082761", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods on discrete domains have shown great promise for many\nchallenging data types, for instance, biological sequence data and molecular\nstructure data. Scalable kernel methods like Support Vector Machines may offer\ngood predictive performances but do not intrinsically provide uncertainty\nestimates. In contrast, probabilistic kernel methods like Gaussian Processes\noffer uncertainty estimates in addition to good predictive performance but fall\nshort in terms of scalability. While the scalability of Gaussian processes can\nbe improved using sparse inducing point approximations, the selection of these\ninducing points remains challenging. We explore different techniques for\nselecting inducing points on discrete domains, including greedy selection,\ndeterminantal point processes, and simulated annealing. We find that simulated\nannealing, which can select inducing points that are not in the training set,\ncan perform competitively with support vector machines and full Gaussian\nprocesses on synthetic data, as well as on challenging real-world DNA sequence\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 12:55:00 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 10:11:50 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 16:57:43 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Fortuin", "Vincent", ""], ["Dresdner", "Gideon", ""], ["Strathmann", "Heiko", ""], ["R\u00e4tsch", "Gunnar", ""]]}, {"id": "1810.10395", "submitter": "Gerasimos Spanakis", "authors": "Ajkel Mino, Gerasimos Spanakis", "title": "LoGAN: Generating Logos with a Generative Adversarial Neural Network\n  Conditioned on color", "comments": "6 page, ICMLA18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing a logo is a long, complicated, and expensive process for any\ndesigner. However, recent advancements in generative algorithms provide models\nthat could offer a possible solution. Logos are multi-modal, have very few\ncategorical properties, and do not have a continuous latent space. Yet,\nconditional generative adversarial networks can be used to generate logos that\ncould help designers in their creative process. We propose LoGAN: an improved\nauxiliary classifier Wasserstein generative adversarial neural network (with\ngradient penalty) that is able to generate logos conditioned on twelve\ndifferent colors. In 768 generated instances (12 classes and 64 logos per\nclass), when looking at the most prominent color, the conditional generation\npart of the model has an overall precision and recall of 0.8 and 0.7\nrespectively. LoGAN's results offer a first glance at how artificial\nintelligence can be used to assist designers in their creative process and open\npromising future directions, such as including more descriptive labels which\nwill provide a more exhaustive and easy-to-use system.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 10:22:17 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Mino", "Ajkel", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "1810.10419", "submitter": "Archit Sakhadeo", "authors": "Archit Sakhadeo and Nisheeth Srivastava", "title": "Effective extractive summarization using frequency-filtered entity\n  relationship graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word frequency-based methods for extractive summarization are easy to\nimplement and yield reasonable results across languages. However, they have\nsignificant limitations - they ignore the role of context, they offer uneven\ncoverage of topics in a document, and sometimes are disjointed and hard to\nread. We use a simple premise from linguistic typology - that English sentences\nare complete descriptors of potential interactions between entities, usually in\nthe order subject-verb-object - to address a subset of these difficulties. We\nhave developed a hybrid model of extractive summarization that combines\nword-frequency based keyword identification with information from automatically\ngenerated entity relationship graphs to select sentences for summaries.\nComparative evaluation with word-frequency and topic word-based methods shows\nthat the proposed method is competitive by conventional ROUGE standards, and\nyields moderately more informative summaries on average, as assessed by a large\npanel (N=94) of human raters.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 14:30:39 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Sakhadeo", "Archit", ""], ["Srivastava", "Nisheeth", ""]]}, {"id": "1810.10498", "submitter": "Elena Pastorelli", "authors": "Cristiano Capone and Elena Pastorelli and Bruno Golosio and Pier\n  Stanislao Paolucci", "title": "Sleep-like slow oscillations improve visual classification through\n  synaptic homeostasis and memory association in a thalamo-cortical model", "comments": "11 pages, 5 figures, v5 is the final version published on Scientific\n  Reports journal", "journal-ref": "Sci Rep 9, 8990 (2019)", "doi": "10.1038/s41598-019-45525-0", "report-no": null, "categories": "q-bio.NC cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The occurrence of sleep passed through the evolutionary sieve and is\nwidespread in animal species. Sleep is known to be beneficial to cognitive and\nmnemonic tasks, while chronic sleep deprivation is detrimental. Despite the\nimportance of the phenomenon, a complete understanding of its functions and\nunderlying mechanisms is still lacking. In this paper, we show interesting\neffects of deep-sleep-like slow oscillation activity on a simplified\nthalamo-cortical model which is trained to encode, retrieve and classify images\nof handwritten digits. During slow oscillations,\nspike-timing-dependent-plasticity (STDP) produces a differential homeostatic\nprocess. It is characterized by both a specific unsupervised enhancement of\nconnections among groups of neurons associated to instances of the same class\n(digit) and a simultaneous down-regulation of stronger synapses created by the\ntraining. This hierarchical organization of post-sleep internal representations\nfavours higher performances in retrieval and classification tasks. The\nmechanism is based on the interaction between top-down cortico-thalamic\npredictions and bottom-up thalamo-cortical projections during deep-sleep-like\nslow oscillations. Indeed, when learned patterns are replayed during sleep,\ncortico-thalamo-cortical connections favour the activation of other neurons\ncoding for similar thalamic inputs, promoting their association. Such mechanism\nhints at possible applications to artificial learning systems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 17:06:00 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 15:38:12 GMT"}, {"version": "v3", "created": "Mon, 3 Dec 2018 15:24:40 GMT"}, {"version": "v4", "created": "Mon, 21 Jan 2019 15:51:14 GMT"}, {"version": "v5", "created": "Mon, 18 Nov 2019 13:01:01 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Capone", "Cristiano", ""], ["Pastorelli", "Elena", ""], ["Golosio", "Bruno", ""], ["Paolucci", "Pier Stanislao", ""]]}, {"id": "1810.10499", "submitter": "Yadollah Yaghoobzadeh", "authors": "Yadollah Yaghoobzadeh and Hinrich Sch\\\"utze", "title": "Multi-Multi-View Learning: Multilingual and Multi-Representation Entity\n  Typing", "comments": "7 pages, Accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases (KBs) are paramount in NLP. We employ multiview learning for\nincreasing accuracy and coverage of entity type information in KBs. We rely on\ntwo metaviews: language and representation. For language, we consider\nhigh-resource and low-resource languages from Wikipedia. For representation, we\nconsider representations based on the context distribution of the entity (i.e.,\non its embedding), on the entity's name (i.e., on its surface form) and on its\ndescription in Wikipedia. The two metaviews language and representation can be\nfreely combined: each pair of language and representation (e.g., German\nembedding, English description, Spanish name) is a distinct view. Our\nexperiments on entity typing with fine-grained classes demonstrate the\neffectiveness of multiview learning. We release MVET, a large multiview - and,\nin particular, multilingual - entity typing dataset we created. Mono- and\nmultilingual fine-grained entity typing systems can be evaluated on this\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 17:08:36 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Yaghoobzadeh", "Yadollah", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1810.10531", "submitter": "Andrew Saxe", "authors": "Andrew M. Saxe, James L. McClelland, and Surya Ganguli", "title": "A mathematical theory of semantic development in deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An extensive body of empirical research has revealed remarkable regularities\nin the acquisition, organization, deployment, and neural representation of\nhuman semantic knowledge, thereby raising a fundamental conceptual question:\nwhat are the theoretical principles governing the ability of neural networks to\nacquire, organize, and deploy abstract knowledge by integrating across many\nindividual experiences? We address this question by mathematically analyzing\nthe nonlinear dynamics of learning in deep linear networks. We find exact\nsolutions to this learning dynamics that yield a conceptual explanation for the\nprevalence of many disparate phenomena in semantic cognition, including the\nhierarchical differentiation of concepts through rapid developmental\ntransitions, the ubiquity of semantic illusions between such transitions, the\nemergence of item typicality and category coherence as factors controlling the\nspeed of semantic processing, changing patterns of inductive projection over\ndevelopment, and the conservation of semantic similarity in neural\nrepresentations across species. Thus, surprisingly, our simple neural model\nqualitatively recapitulates many diverse regularities underlying semantic\ndevelopment, while providing analytic insight into how the statistical\nstructure of an environment can interact with nonlinear deep learning dynamics\nto give rise to these regularities.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 22:20:27 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Saxe", "Andrew M.", ""], ["McClelland", "James L.", ""], ["Ganguli", "Surya", ""]]}, {"id": "1810.10565", "submitter": "Yulun Du", "authors": "Yulun Du, Chirag Raman, Alan W Black, Louis-Philippe Morency, Maxine\n  Eskenazi", "title": "Multimodal Polynomial Fusion for Detecting Driver Distraction", "comments": "INTERSPEECH 2018", "journal-ref": null, "doi": "10.21437/Interspeech.2018-2011", "report-no": null, "categories": "cs.CV cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distracted driving is deadly, claiming 3,477 lives in the U.S. in 2015 alone.\nAlthough there has been a considerable amount of research on modeling the\ndistracted behavior of drivers under various conditions, accurate automatic\ndetection using multiple modalities and especially the contribution of using\nthe speech modality to improve accuracy has received little attention. This\npaper introduces a new multimodal dataset for distracted driving behavior and\ndiscusses automatic distraction detection using features from three modalities:\nfacial expression, speech and car signals. Detailed multimodal feature analysis\nshows that adding more modalities monotonically increases the predictive\naccuracy of the model. Finally, a simple and effective multimodal fusion\ntechnique using a polynomial fusion layer shows superior distraction detection\nresults compared to the baseline SVM and neural network models.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 18:16:42 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Du", "Yulun", ""], ["Raman", "Chirag", ""], ["Black", "Alan W", ""], ["Morency", "Louis-Philippe", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1810.10593", "submitter": "Adam Gleave", "authors": "Aaron Tucker and Adam Gleave and Stuart Russell", "title": "Inverse reinforcement learning for video games", "comments": "10 pages, 4 figures. Submitted to NIPS Deep RL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning achieves superhuman performance in a range of\nvideo game environments, but requires that a designer manually specify a reward\nfunction. It is often easier to provide demonstrations of a target behavior\nthan to design a reward function describing that behavior. Inverse\nreinforcement learning (IRL) algorithms can infer a reward from demonstrations\nin low-dimensional continuous control environments, but there has been little\nwork on applying IRL to high-dimensional video games. In our CNN-AIRL baseline,\nwe modify the state-of-the-art adversarial IRL (AIRL) algorithm to use CNNs for\nthe generator and discriminator. To stabilize training, we normalize the reward\nand increase the size of the discriminator training dataset. We additionally\nlearn a low-dimensional state representation using a novel autoencoder\narchitecture tuned for video game environments. This embedding is used as input\nto the reward network, improving the sample efficiency of expert\ndemonstrations. Our method achieves high-level performance on the simple\nCatcher video game, substantially outperforming the CNN-AIRL baseline. We also\nscore points on the Enduro Atari racing game, but do not match expert\nperformance, highlighting the need for further work.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 20:00:50 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Tucker", "Aaron", ""], ["Gleave", "Adam", ""], ["Russell", "Stuart", ""]]}, {"id": "1810.10654", "submitter": "Lerrel Pinto Mr", "authors": "Lerrel Pinto, Aditya Mandalika, Brian Hou, Siddhartha Srinivasa", "title": "Sample-Efficient Learning of Nonprehensile Manipulation Policies via\n  Physics-Based Informed State Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a sample-efficient yet simple approach to learning\nclosed-loop policies for nonprehensile manipulation. Although reinforcement\nlearning (RL) can learn closed-loop policies without requiring access to\nunderlying physics models, it suffers from poor sample complexity on\nchallenging tasks. To overcome this problem, we leverage rearrangement planning\nto provide an informative physics-based prior on the environment's optimal\nstate-visitation distribution. Specifically, we present a new technique,\nLearning with Planned Episodic Resets (LeaPER), that resets the environment's\nstate to one informed by the prior during the learning phase. We experimentally\nshow that LeaPER significantly outperforms traditional RL approaches by a\nfactor of up to 5X on simulated rearrangement. Further, we relax dynamics from\nquasi-static to welded contacts to illustrate that LeaPER is robust to the use\nof simpler physics models. Finally, LeaPER's closed-loop policies significantly\nimprove task success rates relative to both open-loop controls with a planned\npath or simple feedback controllers that track open-loop trajectories. We\ndemonstrate the performance and behavior of LeaPER on a physical 7-DOF\nmanipulator in https://youtu.be/feS-zFq6J1c.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 23:49:58 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Pinto", "Lerrel", ""], ["Mandalika", "Aditya", ""], ["Hou", "Brian", ""], ["Srinivasa", "Siddhartha", ""]]}, {"id": "1810.10659", "submitter": "Zhuwen Li", "authors": "Zhuwen Li, Qifeng Chen and Vladlen Koltun", "title": "Combinatorial Optimization with Graph Convolutional Networks and Guided\n  Tree Search", "comments": "To appear in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a learning-based approach to computing solutions for certain\nNP-hard problems. Our approach combines deep learning techniques with useful\nalgorithmic elements from classic heuristics. The central component is a graph\nconvolutional network that is trained to estimate the likelihood, for each\nvertex in a graph, of whether this vertex is part of the optimal solution. The\nnetwork is designed and trained to synthesize a diverse set of solutions, which\nenables rapid exploration of the solution space via tree search. The presented\napproach is evaluated on four canonical NP-hard problems and five datasets,\nwhich include benchmark satisfiability problems and real social network graphs\nwith up to a hundred thousand nodes. Experimental results demonstrate that the\npresented approach substantially outperforms recent deep learning work, and\nperforms on par with highly optimized state-of-the-art heuristic solvers for\nsome NP-hard problems. Experiments indicate that our approach generalizes\nacross datasets, and scales to graphs that are orders of magnitude larger than\nthose used during training.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 00:12:44 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Li", "Zhuwen", ""], ["Chen", "Qifeng", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1810.10665", "submitter": "Jason  Weston", "authors": "Kurt Shuster, Samuel Humeau, Hexiang Hu, Antoine Bordes, Jason Weston", "title": "Engaging Image Captioning Via Personality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard image captioning tasks such as COCO and Flickr30k are factual,\nneutral in tone and (to a human) state the obvious (e.g., \"a man playing a\nguitar\"). While such tasks are useful to verify that a machine understands the\ncontent of an image, they are not engaging to humans as captions. With this in\nmind we define a new task, Personality-Captions, where the goal is to be as\nengaging to humans as possible by incorporating controllable style and\npersonality traits. We collect and release a large dataset of 201,858 of such\ncaptions conditioned over 215 possible traits. We build models that combine\nexisting work from (i) sentence representations (Mazare et al., 2018) with\nTransformers trained on 1.7 billion dialogue examples; and (ii) image\nrepresentations (Mahajan et al., 2018) with ResNets trained on 3.5 billion\nsocial media images. We obtain state-of-the-art performance on Flickr30k and\nCOCO, and strong performance on our new task. Finally, online evaluations\nvalidate that our task and models are engaging to humans, with our best model\nclose to human performance.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 00:46:16 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 16:53:33 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Shuster", "Kurt", ""], ["Humeau", "Samuel", ""], ["Hu", "Hexiang", ""], ["Bordes", "Antoine", ""], ["Weston", "Jason", ""]]}, {"id": "1810.10802", "submitter": "Lei Yu", "authors": "Lei Yu", "title": "Tackling Sequence to Sequence Mapping Problems with Neural Networks", "comments": "PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Natural Language Processing (NLP), it is important to detect the\nrelationship between two sequences or to generate a sequence of tokens given\nanother observed sequence. We call the type of problems on modelling sequence\npairs as sequence to sequence (seq2seq) mapping problems. A lot of research has\nbeen devoted to finding ways of tackling these problems, with traditional\napproaches relying on a combination of hand-crafted features, alignment models,\nsegmentation heuristics, and external linguistic resources. Although great\nprogress has been made, these traditional approaches suffer from various\ndrawbacks, such as complicated pipeline, laborious feature engineering, and the\ndifficulty for domain adaptation. Recently, neural networks emerged as a\npromising solution to many problems in NLP, speech recognition, and computer\nvision. Neural models are powerful because they can be trained end to end,\ngeneralise well to unseen examples, and the same framework can be easily\nadapted to a new domain.\n  The aim of this thesis is to advance the state-of-the-art in seq2seq mapping\nproblems with neural networks. We explore solutions from three major aspects:\ninvestigating neural models for representing sequences, modelling interactions\nbetween sequences, and using unpaired data to boost the performance of neural\nmodels. For each aspect, we propose novel models and evaluate their efficacy on\nvarious tasks of seq2seq mapping.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 09:24:13 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Yu", "Lei", ""]]}, {"id": "1810.10862", "submitter": "David Manheim", "authors": "David Manheim", "title": "Multiparty Dynamics and Failure Modes for Machine Learning and\n  Artificial Intelligence", "comments": "12 Pages, This version re-submitted to Big Data and Cognitive\n  Computing, Special Issue \"Artificial Superintelligence: Coordination &\n  Strategy\"", "journal-ref": "Big Data Cogn. Comput. 2019, 3, 21", "doi": "10.3390/bdcc3020021", "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important challenge for safety in machine learning and artificial\nintelligence systems is a~set of related failures involving specification\ngaming, reward hacking, fragility to distributional shifts, and Goodhart's or\nCampbell's law. This paper presents additional failure modes for interactions\nwithin multi-agent systems that are closely related. These multi-agent failure\nmodes are more complex, more problematic, and less well understood than the\nsingle-agent case, and are also already occurring, largely unnoticed. After\nmotivating the discussion with examples from poker-playing artificial\nintelligence (AI), the paper explains why these failure modes are in some\nsenses unavoidable. Following this, the paper categorizes failure modes,\nprovides definitions, and cites examples for each of the modes: accidental\nsteering, coordination failures, adversarial misalignment, input spoofing and\nfiltering, and goal co-option or direct hacking. The paper then discusses how\nextant literature on multi-agent AI fails to address these failure modes, and\nidentifies work which may be useful for the mitigation of these failure modes.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 10:55:58 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 15:58:08 GMT"}, {"version": "v3", "created": "Thu, 28 Feb 2019 19:38:05 GMT"}, {"version": "v4", "created": "Sun, 14 Apr 2019 07:39:06 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Manheim", "David", ""]]}, {"id": "1810.10884", "submitter": "Jee-Weon Jung", "authors": "Jee-weon Jung, Hee-soo Heo, Hye-jin Shim, Ha-jin Yu", "title": "Short utterance compensation in speaker verification via cosine-based\n  teacher-student learning of speaker embeddings", "comments": "5 pages, 2 figures, submitted to Interspeech 2019 as a conference\n  paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The short duration of an input utterance is one of the most critical threats\nthat degrade the performance of speaker verification systems. This study aimed\nto develop an integrated text-independent speaker verification system that\ninputs utterances with short duration of 2 seconds or less. We propose an\napproach using a teacher-student learning framework for this goal, applied to\nshort utterance compensation for the first time in our knowledge. The core\nconcept of the proposed system is to conduct the compensation throughout the\nnetwork that extracts the speaker embedding, mainly in phonetic-level, rather\nthan compensating via a separate system after extracting the speaker embedding.\nIn the proposed architecture, phonetic-level features where each feature\nrepresents a segment of 130 ms are extracted using convolutional layers. A\nlayer of gated recurrent units extracts an utterance-level feature using\nphonetic-level features. The proposed approach also adopts a new objective\nfunction for teacher-student learning that considers both Kullback-Leibler\ndivergence of output layers and cosine distance of speaker embeddings layers.\nExperiments were conducted using deep neural networks that take raw waveforms\nas input, and output speaker embeddings on VoxCeleb1 dataset. The proposed\nmodel could compensate approximately 65 \\% of the performance degradation due\nto the shortened duration.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 14:03:01 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 04:52:08 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Jung", "Jee-weon", ""], ["Heo", "Hee-soo", ""], ["Shim", "Hye-jin", ""], ["Yu", "Ha-jin", ""]]}, {"id": "1810.10907", "submitter": "Damien Pellier", "authors": "Damien Pellier and Bruno Bouzy and Marc M\\'etivier", "title": "Planification en temps r\\'eel avec agenda de buts et sauts", "comments": "in French, Journ\\'ees Francophones de Planification, D\\'ecision,\n  Apprentissage pour la conduite de syst\\`emes, 2011", "journal-ref": "Journ\\'ees Francophones de Planification, D\\'ecision,\n  Apprentissage pour la conduite de syst\\`emes, 2011", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of real-time planning, this paper investigates the\ncontributions of two enhancements for selecting actions. First, the\nagenda-driven planning enhancement ranks relevant atomic goals and solves them\nincrementally in a best-first manner. Second, the committed jump enhancement\ncommits a sequence of actions to be executed at the following time steps. To\nassess these two enhancements, we developed a real-time planning algorithm in\nwhich action selection can be driven by a goal-agenda, and committed jumps can\nbe done. Experimental results, performed on classical planning problems, show\nthat agenda-planning and committed jumps are clear advantages in the real-time\ncontext. Used simultaneously, they enable the planner to be several orders of\nmagnitude faster and solution plans to be shorter.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 10:25:01 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Pellier", "Damien", ""], ["Bouzy", "Bruno", ""], ["M\u00e9tivier", "Marc", ""]]}, {"id": "1810.10908", "submitter": "Damien Pellier", "authors": "Damien Pellier and Micka\\\"el Vanneufville and Humbert Fiorino and Marc\n  M\\'etivier and Bruno Bouzy", "title": "MGP: Un algorithme de planification temps r\\'eel prenant en compte\n  l'\\'evolution dynamique du but", "comments": "in French", "journal-ref": "Journ\\'ees Francophones de Planification, D\\'ecision,\n  Apprentissage pour la conduite de Syst\\`emes, 2012", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Devising intelligent robots or agents that interact with humans is a major\nchallenge for artificial intelligence. In such contexts, agents must constantly\nadapt their decisions according to human activities and modify their goals. In\nthis paper, we tackle this problem by introducing a novel planning approach,\ncalled Moving Goal Planning (MGP), to adapt plans to goal evolutions. This\nplanning algorithm draws inspiration from Moving Target Search (MTS)\nalgorithms. In order to limit the number of search iterations and to improve\nits efficiency, MGP delays as much as possible triggering new searches when the\ngoal changes over time. To this purpose, MGP uses two strategies: Open Check\n(OC) that checks if the new goal is still in the current search tree and Plan\nFollow (PF) that estimates whether executing actions of the current plan brings\nMGP closer to the new goal. Moreover, MGP uses a parsimonious strategy to\nupdate incrementally the search tree at each new search that reduces the number\nof calls to the heuristic function and speeds up the search. Finally, we show\nevaluation results that demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 12:02:56 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Pellier", "Damien", ""], ["Vanneufville", "Micka\u00ebl", ""], ["Fiorino", "Humbert", ""], ["M\u00e9tivier", "Marc", ""], ["Bouzy", "Bruno", ""]]}, {"id": "1810.10909", "submitter": "Damien Pellier", "authors": "Damien Pellier and Carole Adam and Wafa Johal and Humbert Fiorino and\n  Sylvie Pesty", "title": "Une architecture cognitive et affective orient{\\'e}e interaction", "comments": "in French", "journal-ref": "Workshop on Affect, Artificial Compagnon and Interaction, 2016", "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present CAIO, a Cognitive and Affective\nInteraction-Oriented architecture for social human-robot interactions (HRI),\nallowing robots to reason on mental states (including emotions), and to act\nphysically, emotionally and verbally. We also present a short scenario and\nimplementation on a Nao robot.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 13:40:51 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Pellier", "Damien", ""], ["Adam", "Carole", ""], ["Johal", "Wafa", ""], ["Fiorino", "Humbert", ""], ["Pesty", "Sylvie", ""]]}, {"id": "1810.10910", "submitter": "Damien Pellier", "authors": "Abdeldjalil Ramoul and Damien Pellier and Humbert Fiorino and Sylvie\n  Pesty", "title": "Une approche totalement instanci\\'ee pour la planification HTN", "comments": "in French, Journ\\'ees Francophones de Planification de D\\'ecision et\n  d'Apprentissage, 2016", "journal-ref": "Journ\\'ees Francophones de Planification de D\\'ecision et\n  d'Apprentissage, 2016", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many planning techniques have been developed to allow autonomous systems to\nact and make decisions based on their perceptions of the environment. Among\nthese techniques, HTN ({\\it Hierarchical Task Network}) planning is one of the\nmost used in practice. Unlike classical approaches of planning. HTN operates by\ndecomposing task into sub-tasks until each of these sub-tasks can be achieved\nan action. This hierarchical representation provide a richer representation of\nplanning problems and allows to better guide the plan search and provides more\nknowledge to the underlying algorithms. In this paper, we propose a new\napproach of HTN planning in which, as in conventional planning, we instantiate\nall planning operators before starting the search process. This approach has\nproven its effectiveness in classical planning and is necessary for the\ndevelopment of effective heuristics and encoding planning problems in other\nformalism such as CSP or SAT. The instantiation is actually used by most modern\nplanners but has never been applied in an HTN based planning framework. We\npresent in this article a generic instantiation algorithm which implements many\nsimplification techniques to reduce the process complexity inspired from those\nused in classical planning. Finally we present some results obtained from an\nexperimentation on a range of problems used in the international planning\ncompetitions with a modified version of SHOP planner using fully instantiated\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 14:06:48 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Ramoul", "Abdeldjalil", ""], ["Pellier", "Damien", ""], ["Fiorino", "Humbert", ""], ["Pesty", "Sylvie", ""]]}, {"id": "1810.10952", "submitter": "Yuankai Wu", "authors": "Yuankai Wu, Huachun Tan, Bin Ran", "title": "Differential Variable Speed Limits Control for Freeway Recurrent\n  Bottlenecks via Deep Reinforcement learning", "comments": "24 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable speed limits (VSL) control is a flexible way to improve traffic\ncondition,increase safety and reduce emission. There is an emerging trend of\nusing reinforcement learning technique for VSL control and recent studies have\nshown promising results. Currently, deep learning is enabling reinforcement\nlearning to develope autonomous control agents for problems that were\npreviously intractable. In this paper, we propose a more effective deep\nreinforcement learning (DRL) model for differential variable speed limits\n(DVSL) control, in which the dynamic and different speed limits among lanes can\nbe imposed. The proposed DRL models use a novel actor-critic architecture which\ncan learn a large number of discrete speed limits in a continues action space.\nDifferent reward signals, e.g. total travel time, bottleneck speed, emergency\nbraking, and vehicular emission are used to train the DVSL controller, and\ncomparison between these reward signals are conducted. We test proposed DRL\nbaased DVSL controllers on a simulated freeway recurrent bottleneck. Results\nshow that the efficiency, safety and emissions can be improved by the proposed\nmethod. We also show some interesting findings through the visulization of the\ncontrol policies generated from DRL models.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 16:11:29 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Wu", "Yuankai", ""], ["Tan", "Huachun", ""], ["Ran", "Bin", ""]]}, {"id": "1810.11043", "submitter": "Tianhe Yu", "authors": "Tianhe Yu, Pieter Abbeel, Sergey Levine, Chelsea Finn", "title": "One-Shot Hierarchical Imitation Learning of Compound Visuomotor Tasks", "comments": "Video results available at https://sites.google.com/view/one-shot-hil", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning multi-stage vision-based tasks on a real\nrobot from a single video of a human performing the task, while leveraging\ndemonstration data of subtasks with other objects. This problem presents a\nnumber of major challenges. Video demonstrations without teleoperation are easy\nfor humans to provide, but do not provide any direct supervision. Learning\npolicies from raw pixels enables full generality but calls for large function\napproximators with many parameters to be learned. Finally, compound tasks can\nrequire impractical amounts of demonstration data, when treated as a monolithic\nskill. To address these challenges, we propose a method that learns both how to\nlearn primitive behaviors from video demonstrations and how to dynamically\ncompose these behaviors to perform multi-stage tasks by \"watching\" a human\ndemonstrator. Our results on a simulated Sawyer robot and real PR2 robot\nillustrate our method for learning a variety of order fulfillment and kitchen\nserving tasks with novel objects and raw pixel inputs.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 18:05:08 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Yu", "Tianhe", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1810.11078", "submitter": "Jaroslaw Jankowski", "authors": "Jaros{\\l}aw W\\k{a}tr\\'obski, Jaros{\\l}aw Jankowski, Pawe{\\l} Ziemba,\n  Artur Karczmarczyk, Magdalena Zio{\\l}o", "title": "Generalised framework for multi-criteria method selection", "comments": null, "journal-ref": "J.W\\k{a}tr\\'obski, J.Jankowski, P.Ziemba, A.Karczmarczyk and\n  M.Zio{\\l}o, Generalised framework for multi-criteria method selection, Omega\n  (2018), doi.org/10.1016/j.omega.2018.07.004", "doi": "10.1016/j.omega.2018.07.004", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Criteria Decision Analysis (MCDA) methods are widely used in various\nfields and disciplines. While most of the research has been focused on the\ndevelopment and improvement of new MCDA methods, relatively limited attention\nhas been paid to their appropriate selection for the given decision problem.\nTheir improper application decreases the quality of recommendations, as\ndifferent MCDA methods deliver inconsistent results. The current paper presents\na methodological and practical framework for selecting suitable MCDA methods\nfor a particular decision situation. A set of 56 available MCDA methods was\nanalyzed and, based on that, a hierarchical set of methods characteristics and\nthe rule base were obtained. This analysis, rules and modelling of the\nuncertainty in the decision problem description allowed to build a framework\nsupporting the selection of a MCDA method for a given decision-making\nsituation. The practical studies indicate consistency between the methods\nrecommended with the proposed approach and those used by the experts in\nreference cases. The results of the research also showed that the proposed\napproach can be used as a general framework for selecting an appropriate MCDA\nmethod for a given area of decision support, even in cases of data gaps in the\ndecision-making problem description. The proposed framework was implemented\nwithin a web platform available for public use at www.mcda.it.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 19:29:46 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["W\u0105tr\u00f3bski", "Jaros\u0142aw", ""], ["Jankowski", "Jaros\u0142aw", ""], ["Ziemba", "Pawe\u0142", ""], ["Karczmarczyk", "Artur", ""], ["Zio\u0142o", "Magdalena", ""]]}, {"id": "1810.11116", "submitter": "Tae Wan Kim", "authors": "Tae Wan Kim, Thomas Donaldson, and John Hooker", "title": "Mimetic vs Anchored Value Alignment in Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Value alignment\" (VA) is considered as one of the top priorities in AI\nresearch. Much of the existing research focuses on the \"A\" part and not the \"V\"\npart of \"value alignment.\" This paper corrects that neglect by emphasizing the\n\"value\" side of VA and analyzes VA from the vantage point of requirements in\nvalue theory, in particular, of avoiding the \"naturalistic fallacy\"--a major\nepistemic caveat. The paper begins by isolating two distinct forms of VA:\n\"mimetic\" and \"anchored.\" Then it discusses which VA approach better avoids the\nnaturalistic fallacy. The discussion reveals stumbling blocks for VA approaches\nthat neglect implications of the naturalistic fallacy. Such problems are more\nserious in mimetic VA since the mimetic process imitates human behavior that\nmay or may not rise to the level of correct ethical behavior. Anchored VA,\nincluding hybrid VA, in contrast, holds more promise for future VA since it\nanchors alignment by normative concepts of intrinsic value.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 21:34:21 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Kim", "Tae Wan", ""], ["Donaldson", "Thomas", ""], ["Hooker", "John", ""]]}, {"id": "1810.11177", "submitter": "Zi Wang", "authors": "Victoria Xia and Zi Wang and Leslie Pack Kaelbling", "title": "Learning sparse relational transition models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a representation for describing transition models in complex\nuncertain domains using relational rules. For any action, a rule selects a set\nof relevant objects and computes a distribution over properties of just those\nobjects in the resulting state given their properties in the previous state. An\niterative greedy algorithm is used to construct a set of deictic references\nthat determine which objects are relevant in any given state. Feed-forward\nneural networks are used to learn the transition distribution on the relevant\nobjects' properties. This strategy is demonstrated to be both more versatile\nand more sample efficient than learning a monolithic transition model in a\nsimulated domain in which a robot pushes stacks of objects on a cluttered\ntable.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 03:45:22 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Xia", "Victoria", ""], ["Wang", "Zi", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1810.11181", "submitter": "Abhishek Das", "authors": "Abhishek Das, Georgia Gkioxari, Stefan Lee, Devi Parikh, Dhruv Batra", "title": "Neural Modular Control for Embodied Question Answering", "comments": "10 pages, 3 figures, 2 tables. Published at CoRL 2018. Webpage:\n  https://embodiedqa.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a modular approach for learning policies for navigation over long\nplanning horizons from language input. Our hierarchical policy operates at\nmultiple timescales, where the higher-level master policy proposes subgoals to\nbe executed by specialized sub-policies. Our choice of subgoals is\ncompositional and semantic, i.e. they can be sequentially combined in arbitrary\norderings, and assume human-interpretable descriptions (e.g. 'exit room', 'find\nkitchen', 'find refrigerator', etc.).\n  We use imitation learning to warm-start policies at each level of the\nhierarchy, dramatically increasing sample efficiency, followed by reinforcement\nlearning. Independent reinforcement learning at each level of hierarchy enables\nsub-policies to adapt to consequences of their actions and recover from errors.\nSubsequent joint hierarchical training enables the master policy to adapt to\nthe sub-policies.\n  On the challenging EQA (Das et al., 2018) benchmark in House3D (Wu et al.,\n2018), requiring navigating diverse realistic indoor environments, our approach\noutperforms prior work by a significant margin, both in terms of navigation and\nquestion answering.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 03:58:26 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 23:41:47 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Das", "Abhishek", ""], ["Gkioxari", "Georgia", ""], ["Lee", "Stefan", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1810.11187", "submitter": "Abhishek Das", "authors": "Abhishek Das, Th\\'eophile Gervet, Joshua Romoff, Dhruv Batra, Devi\n  Parikh, Michael Rabbat, Joelle Pineau", "title": "TarMAC: Targeted Multi-Agent Communication", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a targeted communication architecture for multi-agent\nreinforcement learning, where agents learn both what messages to send and whom\nto address them to while performing cooperative tasks in partially-observable\nenvironments. This targeting behavior is learnt solely from downstream\ntask-specific reward without any communication supervision. We additionally\naugment this with a multi-round communication approach where agents coordinate\nvia multiple rounds of communication before taking actions in the environment.\nWe evaluate our approach on a diverse set of cooperative multi-agent tasks, of\nvarying difficulties, with varying number of agents, in a variety of\nenvironments ranging from 2D grid layouts of shapes and simulated traffic\njunctions to 3D indoor environments, and demonstrate the benefits of targeted\nand multi-round communication. Moreover, we show that the targeted\ncommunication strategies learned by agents are interpretable and intuitive.\nFinally, we show that our architecture can be easily extended to mixed and\ncompetitive environments, leading to improved performance and sample complexity\nover recent state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 04:22:58 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 04:37:13 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Das", "Abhishek", ""], ["Gervet", "Th\u00e9ophile", ""], ["Romoff", "Joshua", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Rabbat", "Michael", ""], ["Pineau", "Joelle", ""]]}, {"id": "1810.11190", "submitter": "Ajay Patel", "authors": "Ajay Patel, Alexander Sands, Chris Callison-Burch, and Marianna\n  Apidianaki", "title": "Magnitude: A Fast, Efficient Universal Vector Embedding Utility Package", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector space embedding models like word2vec, GloVe, fastText, and ELMo are\nextremely popular representations in natural language processing (NLP)\napplications. We present Magnitude, a fast, lightweight tool for utilizing and\nprocessing embeddings. Magnitude is an open source Python package with a\ncompact vector storage file format that allows for efficient manipulation of\nhuge numbers of embeddings. Magnitude performs common operations up to 60 to\n6,000 times faster than Gensim. Magnitude introduces several novel features for\nimproved robustness like out-of-vocabulary lookups.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 05:04:07 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Patel", "Ajay", ""], ["Sands", "Alexander", ""], ["Callison-Burch", "Chris", ""], ["Apidianaki", "Marianna", ""]]}, {"id": "1810.11193", "submitter": "Sanqiang Zhao", "authors": "Sanqiang Zhao, Rui Meng, Daqing He, Saptono Andi, Parmanto Bambang", "title": "Integrating Transformer and Paraphrase Rules for Sentence Simplification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence simplification aims to reduce the complexity of a sentence while\nretaining its original meaning. Current models for sentence simplification\nadopted ideas from ma- chine translation studies and implicitly learned\nsimplification mapping rules from normal- simple sentence pairs. In this paper,\nwe explore a novel model based on a multi-layer and multi-head attention\narchitecture and we pro- pose two innovative approaches to integrate the Simple\nPPDB (A Paraphrase Database for Simplification), an external paraphrase\nknowledge base for simplification that covers a wide range of real-world\nsimplification rules. The experiments show that the integration provides two\nmajor benefits: (1) the integrated model outperforms multiple state- of-the-art\nbaseline models for sentence simplification in the literature (2) through\nanalysis of the rule utilization, the model seeks to select more accurate\nsimplification rules. The code and models used in the paper are available at\nhttps://github.com/ Sanqiang/text_simplification.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 05:44:01 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Zhao", "Sanqiang", ""], ["Meng", "Rui", ""], ["He", "Daqing", ""], ["Andi", "Saptono", ""], ["Bambang", "Parmanto", ""]]}, {"id": "1810.11227", "submitter": "Chenguang Lu", "authors": "Chenguang Lu", "title": "From the EM Algorithm to the CM-EM Algorithm for Global Convergence of\n  Mixture Models", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Expectation-Maximization (EM) algorithm for mixture models often results\nin slow or invalid convergence. The popular convergence proof affirms that the\nlikelihood increases with Q; Q is increasing in the M -step and non-decreasing\nin the E-step. The author found that (1) Q may and should decrease in some\nE-steps; (2) The Shannon channel from the E-step is improper and hence the\nexpectation is improper. The author proposed the CM-EM algorithm (CM means\nChannel's Matching), which adds a step to optimize the mixture ratios for the\nproper Shannon channel and maximizes G, average log-normalized-likelihood, in\nthe M-step. Neal and Hinton's Maximization-Maximization (MM) algorithm use F\ninstead of Q to speed the convergence. Maximizing G is similar to maximizing F.\nThe new convergence proof is similar to Beal's proof with the variational\nmethod. It first proves that the minimum relative entropy equals the minimum\nR-G (R is mutual information), then uses variational and iterative methods that\nShannon et al. use for rate-distortion functions to prove the global\nconvergence. Some examples show that Q and F should and may decrease in some\nE-steps. For the same example, the EM, MM, and CM-EM algorithms need about 36,\n18, and 9 iterations respectively.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 08:44:50 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Lu", "Chenguang", ""]]}, {"id": "1810.11291", "submitter": "Spyros Angelopoulos", "authors": "Spyros Angelopoulos and Alejandro Lopez-Ortiz", "title": "Interruptible Algorithms for Multiproblem Solving", "comments": "Extended version of IJCAI 2009 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of designing an interruptible system in\na setting in which $n$ problem instances, all equally important, must be solved\nconcurrently. The system involves scheduling executions of contract algorithms\n(which offer a trade-off between allowable computation time and quality of the\nsolution) in m identical parallel processors. When an interruption occurs, the\nsystem must report a solution to each of the $n$ problem instances. The quality\nof this output is then compared to the best-possible algorithm that has\nforeknowledge of the interruption time and must, likewise, produce solutions to\nall $n$ problem instances. This extends the well-studied setting in which only\none problem instance is queried at interruption time.\n  In this work we first introduce new measures for evaluating the performance\nof interruptible systems in this setting. In particular, we propose the\ndeficiency of a schedule as a performance measure that meets the requirements\nof the problem at hand. We then present a schedule whose performance we prove\nthat is within a small factor from optimal in the general, multiprocessor\nsetting. We also show several lower bounds on the deficiency of schedules on a\nsingle processor. More precisely, we prove a general lower bound of (n+1)/n, an\nimproved lower bound for the two-problem setting (n=2), and a tight lower bound\nfor the class of round-robin schedules. Our techniques can also yield a\nsimpler, alternative proof of the main result of [Bernstein et al, IJCAI 2003]\nconcerning the performance of cyclic schedules in multiprocessor environments.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 12:35:58 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Angelopoulos", "Spyros", ""], ["Lopez-Ortiz", "Alejandro", ""]]}, {"id": "1810.11369", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "The Information Flow Foundation for Conceptual Knowledge Organization", "comments": "7 pages, 3 figures, 1 table", "journal-ref": "Dynamism and Stability in Knowledge Organization, volume 7 of\n  Advances in Knowledge Organization, pages 111-117. Ergon Verlag, 2000.\n  Proceedings of the Sixth International ISKO Conference", "doi": null, "report-no": null, "categories": "cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sharing of ontologies between diverse communities of discourse allows\nthem to compare their own information structures with that of other communities\nthat share a common terminology and semantics - ontology sharing facilitates\ninteroperability between online knowledge organizations. This paper\ndemonstrates how ontology sharing is formalizable within the conceptual\nknowledge model of Information Flow (IF). Information Flow indirectly\nrepresents sharing through a specifiable, ontology extension hierarchy\naugmented with synonymic type equivalencing - two ontologies share terminology\nand meaning through a common generic ontology that each extends. Using the\nparadigm of participant community ontologies formalized as IF logics, a common\nshared extensible ontology formalized as an IF theory, participant community\nspecification links from the common ontology to the participating community\nontology formalizable as IF theory interpretations, this paper argues that\nontology sharing is concentrated in a virtual ontology of community\nconnections, and demonstrates how this virtual ontology is computable as the\nfusion of the participant ontologies - the quotient of the sum of the\nparticipant ontologies modulo the ontological sharing structure.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 19:20:17 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1810.11370", "submitter": "Abigail Chown", "authors": "Abigail H. Chown, Christopher J. Cook, Nigel B. Wilding", "title": "A simulated annealing approach to the student-project allocation problem", "comments": "22 pages, 6 figures", "journal-ref": "American Journal of Physics, 2018, Volume 86, Issue 9, Page 701", "doi": "10.1119/1.5045331", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a solution to the student-project allocation problem using\nsimulated annealing. The problem involves assigning students to projects, where\neach student has ranked a fixed number of projects in order of preference. Each\nproject is offered by a specific supervisor (or supervisors), and the goal is\nto find an optimal matching of students to projects taking into account the\nstudents' preferences, the constraint that only one student can be assigned to\na given project, and the constraint that supervisors have a maximum workload.\nWe show that when applied to a real dataset from a university physics\ndepartment, simulated annealing allows the rapid determination of high quality\nsolutions to this allocation problem. The quality of the solution is quantified\nby a satisfaction metric derived from empirical student survey data. Our\napproach provides high quality allocations in a matter of minutes that are as\ngood as those found previously by the course organizer using a laborious\ntrial-and-error approach. We investigate how the quality of the allocation is\naffected by the ratio of the number of projects offered to the number of\nstudents and the number of projects ranked by each student. We briefly discuss\nhow our approach can be generalized to include other types of constraints and\ndiscuss its potential applicability to wider allocation problems.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 14:23:13 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Chown", "Abigail H.", ""], ["Cook", "Christopher J.", ""], ["Wilding", "Nigel B.", ""]]}, {"id": "1810.11388", "submitter": "Muhammad Burhan Hafez", "authors": "Muhammad Burhan Hafez, Cornelius Weber, Matthias Kerzel, Stefan\n  Wermter", "title": "Deep Intrinsically Motivated Continuous Actor-Critic for Efficient\n  Robotic Visuomotor Skill Learning", "comments": null, "journal-ref": "Paladyn, Journal of Behavioral Robotics, Volume 10, Issue 1, Pages\n  14-29, 2019", "doi": "10.1515/pjbr-2019-0005", "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new intrinsically motivated actor-critic\nalgorithm for learning continuous motor skills directly from raw visual input.\nOur neural architecture is composed of a critic and an actor network. Both\nnetworks receive the hidden representation of a deep convolutional autoencoder\nwhich is trained to reconstruct the visual input, while the centre-most hidden\nrepresentation is also optimized to estimate the state value. Separately, an\nensemble of predictive world models generates, based on its learning progress,\nan intrinsic reward signal which is combined with the extrinsic reward to guide\nthe exploration of the actor-critic learner. Our approach is more\ndata-efficient and inherently more stable than the existing actor-critic\nmethods for continuous control from pixel data. We evaluate our algorithm for\nthe task of learning robotic reaching and grasping skills on a realistic\nphysics simulator and on a humanoid robot. The results show that the control\npolicies learned with our approach can achieve better performance than the\ncompared state-of-the-art and baseline algorithms in both dense-reward and\nchallenging sparse-reward settings.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 15:32:32 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 10:54:46 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Hafez", "Muhammad Burhan", ""], ["Weber", "Cornelius", ""], ["Kerzel", "Matthias", ""], ["Wermter", "Stefan", ""]]}, {"id": "1810.11391", "submitter": "Johan Kwisthout", "authors": "Johan Kwisthout", "title": "Finding dissimilar explanations in Bayesian networks: Complexity results", "comments": "Presented at the Benelux AI Conference (BNAIC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the most probable explanation for observed variables in a Bayesian\nnetwork is a notoriously intractable problem, particularly if there are hidden\nvariables in the network. In this paper we examine the complexity of a related\nproblem, that is, the problem of finding a set of sufficiently dissimilar, yet\nall plausible, explanations. Applications of this problem are, e.g., in search\nquery results (you won't want 10 results that all link to the same website) or\nin decision support systems. We show that the problem of finding a 'good\nenough' explanation that differs in structure from the best explanation is at\nleast as hard as finding the best explanation itself.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 15:37:24 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 10:33:54 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Kwisthout", "Johan", ""]]}, {"id": "1810.11488", "submitter": "Sankalp Garg", "authors": "Aniket Bajpai, Sankalp Garg, Mausam", "title": "Transfer of Deep Reactive Policies for MDP Planning", "comments": "To appear at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain-independent probabilistic planners input an MDP description in a\nfactored representation language such as PPDDL or RDDL, and exploit the\nspecifics of the representation for faster planning. Traditional algorithms\noperate on each problem instance independently, and good methods for\ntransferring experience from policies of other instances of a domain to a new\ninstance do not exist. Recently, researchers have begun exploring the use of\ndeep reactive policies, trained via deep reinforcement learning (RL), for MDP\nplanning domains. One advantage of deep reactive policies is that they are more\namenable to transfer learning.\n  In this paper, we present the first domain-independent transfer algorithm for\nMDP planning domains expressed in an RDDL representation. Our architecture\nexploits the symbolic state configuration and transition function of the domain\n(available via RDDL) to learn a shared embedding space for states and\nstate-action pairs for all problem instances of a domain. We then learn an RL\nagent in the embedding space, making a near zero-shot transfer possible, i.e.,\nwithout much training on the new instance, and without using the domain\nsimulator at all. Experiments on three different benchmark domains underscore\nthe value of our transfer algorithm. Compared against planning from scratch,\nand a state-of-the-art RL transfer algorithm, our transfer solution has\nsignificantly superior learning curves.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 18:28:42 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Bajpai", "Aniket", ""], ["Garg", "Sankalp", ""], ["Mausam", "", ""]]}, {"id": "1810.11518", "submitter": "Yasin Musa Ayami", "authors": "Yasin Musa Ayami, Aboubayda Shabat", "title": "An Acceleration Scheme to The Local Directional Pattern", "comments": "5 pages, 3 figures, 3 tables, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study seeks to improve the running time of the Local Directional Pattern\n(LDP) during feature extraction using a newly proposed acceleration scheme to\nLDP. LDP is considered to be computationally expensive. To confirm this, the\nrunning time of the LDP to gray level co-occurrence matrix (GLCM) were it was\nestablished that the running time for LDP was two orders of magnitude higher\nthan that of the GLCM. In this study, the performance of the newly proposed\nacceleration scheme was evaluated against LDP and Local Binary patter (LBP)\nusing images from the publicly available extended Cohn-Kanade (CK+) dataset.\nBased on our findings, the proposed acceleration scheme significantly improves\nthe running time of the LDP by almost 3 times during feature extraction\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 20:12:20 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Ayami", "Yasin Musa", ""], ["Shabat", "Aboubayda", ""]]}, {"id": "1810.11544", "submitter": "Anton Osokin", "authors": "Kirill Struminsky, Simon Lacoste-Julien, Anton Osokin", "title": "Quantifying Learning Guarantees for Convex but Inconsistent Surrogates", "comments": "Appears in: Advances in Neural Information Processing Systems 31\n  (NeurIPS 2018). 18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study consistency properties of machine learning methods based on\nminimizing convex surrogates. We extend the recent framework of Osokin et al.\n(2017) for the quantitative analysis of consistency properties to the case of\ninconsistent surrogates. Our key technical contribution consists in a new lower\nbound on the calibration function for the quadratic surrogate, which is\nnon-trivial (not always zero) for inconsistent cases. The new bound allows to\nquantify the level of inconsistency of the setting and shows how learning with\ninconsistent surrogates can have guarantees on sample complexity and\noptimization difficulty. We apply our theory to two concrete cases: multi-class\nclassification with the tree-structured loss and ranking with the mean average\nprecision loss. The results show the approximation-computation trade-offs\ncaused by inconsistent surrogates and their potential benefits.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 22:10:48 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 08:47:58 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Struminsky", "Kirill", ""], ["Lacoste-Julien", "Simon", ""], ["Osokin", "Anton", ""]]}, {"id": "1810.11545", "submitter": "Nicholas Waytowich", "authors": "Vinicius G. Goecks, Gregory M. Gremillion, Vernon J. Lawhern, John\n  Valasek, Nicholas R. Waytowich", "title": "Efficiently Combining Human Demonstrations and Interventions for Safe\n  Training of Autonomous Systems in Real-Time", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates how to utilize different forms of human interaction\nto safely train autonomous systems in real-time by learning from both human\ndemonstrations and interventions. We implement two components of the\nCycle-of-Learning for Autonomous Systems, which is our framework for combining\nmultiple modalities of human interaction. The current effort employs human\ndemonstrations to teach a desired behavior via imitation learning, then\nleverages intervention data to correct for undesired behaviors produced by the\nimitation learner to teach novel tasks to an autonomous agent safely, after\nonly minutes of training. We demonstrate this method in an autonomous perching\ntask using a quadrotor with continuous roll, pitch, yaw, and throttle commands\nand imagery captured from a downward-facing camera in a high-fidelity simulated\nenvironment. Our method improves task completion performance for the same\namount of human interaction when compared to learning from demonstrations\nalone, while also requiring on average 32% less data to achieve that\nperformance. This provides evidence that combining multiple modes of human\ninteraction can increase both the training speed and overall performance of\npolicies for autonomous systems.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 22:23:27 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 21:31:07 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Goecks", "Vinicius G.", ""], ["Gremillion", "Gregory M.", ""], ["Lawhern", "Vernon J.", ""], ["Valasek", "John", ""], ["Waytowich", "Nicholas R.", ""]]}, {"id": "1810.11580", "submitter": "Guanhong Tao", "authors": "Guanhong Tao, Shiqing Ma, Yingqi Liu, Xiangyu Zhang", "title": "Attacks Meet Interpretability: Attribute-steered Detection of\n  Adversarial Samples", "comments": "Accepted to NIPS 2018 Spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial sample attacks perturb benign inputs to induce DNN misbehaviors.\nRecent research has demonstrated the widespread presence and the devastating\nconsequences of such attacks. Existing defense techniques either assume prior\nknowledge of specific attacks or may not work well on complex models due to\ntheir underlying assumptions. We argue that adversarial sample attacks are\ndeeply entangled with interpretability of DNN models: while classification\nresults on benign inputs can be reasoned based on the human perceptible\nfeatures/attributes, results on adversarial samples can hardly be explained.\nTherefore, we propose a novel adversarial sample detection technique for face\nrecognition models, based on interpretability. It features a novel\nbi-directional correspondence inference between attributes and internal neurons\nto identify neurons critical for individual attributes. The activation values\nof critical neurons are enhanced to amplify the reasoning part of the\ncomputation and the values of other neurons are weakened to suppress the\nuninterpretable part. The classification results after such transformation are\ncompared with those of the original model to detect adversaries. Results show\nthat our technique can achieve 94% detection accuracy for 7 different kinds of\nattacks with 9.91% false positives on benign inputs. In contrast, a\nstate-of-the-art feature squeezing technique can only achieve 55% accuracy with\n23.3% false positives.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 02:32:32 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Tao", "Guanhong", ""], ["Ma", "Shiqing", ""], ["Liu", "Yingqi", ""], ["Zhang", "Xiangyu", ""]]}, {"id": "1810.11583", "submitter": "Matthew Riemer", "authors": "Matthew Riemer, Miao Liu, Gerald Tesauro", "title": "Learning Abstract Options", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building systems that autonomously create temporal abstractions from data is\na key challenge in scaling learning and planning in reinforcement learning. One\npopular approach for addressing this challenge is the options framework (Sutton\net al., 1999). However, only recently in (Bacon et al., 2017) was a policy\ngradient theorem derived for online learning of general purpose options in an\nend to end fashion. In this work, we extend previous work on this topic that\nonly focuses on learning a two-level hierarchy including options and primitive\nactions to enable learning simultaneously at multiple resolutions in time. We\nachieve this by considering an arbitrarily deep hierarchy of options where high\nlevel temporally extended options are composed of lower level options with\nfiner resolutions in time. We extend results from (Bacon et al., 2017) and\nderive policy gradient theorems for a deep hierarchy of options. Our proposed\nhierarchical option-critic architecture is capable of learning internal\npolicies, termination conditions, and hierarchical compositions over options\nwithout the need for any intrinsic rewards or subgoals. Our empirical results\nin both discrete and continuous environments demonstrate the efficiency of our\nframework.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 02:54:59 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 17:43:42 GMT"}, {"version": "v3", "created": "Sat, 1 Dec 2018 23:36:25 GMT"}, {"version": "v4", "created": "Tue, 31 Dec 2019 17:25:40 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Riemer", "Matthew", ""], ["Liu", "Miao", ""], ["Tesauro", "Gerald", ""]]}, {"id": "1810.11603", "submitter": "Shou-Yu Chen", "authors": "Shou-Yu Chen, Guang-Sheng Chen and Wei-Peng Jing", "title": "A Miniaturized Semantic Segmentation Method for Remote Sensing Image", "comments": "5 pages, 3 figures, 3 tables, this paper is to be submitted to the\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to save the memory, we propose a miniaturization method for neural\nnetwork to reduce the parameter quantity existed in remote sensing (RS) image\nsemantic segmentation model. The compact convolution optimization method is\nfirst used for standard U-Net to reduce the weights quantity. With the purpose\nof decreasing model performance loss caused by miniaturization and based on the\ncharacteristics of remote sensing image, fewer down-samplings and improved\ncascade atrous convolution are then used to improve the performance of the\nminiaturized U-Net. Compared with U-Net, our proposed Micro-Net not only\nachieves 29.26 times model compression, but also basically maintains the\nperformance unchanged on the public dataset. We provide a Keras and Tensorflow\nhybrid programming implementation for our model:\nhttps://github.com/Isnot2bad/Micro-Net\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 05:58:36 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Chen", "Shou-Yu", ""], ["Chen", "Guang-Sheng", ""], ["Jing", "Wei-Peng", ""]]}, {"id": "1810.11649", "submitter": "Viraj Prabhu", "authors": "Utsav Garg, Viraj Prabhu, Deshraj Yadav, Ram Ramrakhya, Harsh Agrawal,\n  Dhruv Batra", "title": "Fabrik: An Online Collaborative Neural Network Editor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Fabrik, an online neural network editor that provides tools to\nvisualize, edit, and share neural networks from within a browser. Fabrik\nprovides a simple and intuitive GUI to import neural networks written in\npopular deep learning frameworks such as Caffe, Keras, and TensorFlow, and\nallows users to interact with, build, and edit models via simple drag and drop.\nFabrik is designed to be framework agnostic and support high interoperability,\nand can be used to export models back to any supported framework. Finally, it\nprovides powerful collaborative features to enable users to iterate over model\ndesign remotely and at scale.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 14:23:38 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Garg", "Utsav", ""], ["Prabhu", "Viraj", ""], ["Yadav", "Deshraj", ""], ["Ramrakhya", "Ram", ""], ["Agrawal", "Harsh", ""], ["Batra", "Dhruv", ""]]}, {"id": "1810.11702", "submitter": "Christian Schroeder de Witt", "authors": "Christian A. Schroeder de Witt, Jakob N. Foerster, Gregory Farquhar,\n  Philip H. S. Torr, Wendelin Boehmer, Shimon Whiteson", "title": "Multi-Agent Common Knowledge Reinforcement Learning", "comments": "Advances in Neural Information Processing Systems, 9924-9935", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative multi-agent reinforcement learning often requires decentralised\npolicies, which severely limit the agents' ability to coordinate their\nbehaviour. In this paper, we show that common knowledge between agents allows\nfor complex decentralised coordination. Common knowledge arises naturally in a\nlarge number of decentralised cooperative multi-agent tasks, for example, when\nagents can reconstruct parts of each others' observations. Since agents an\nindependently agree on their common knowledge, they can execute complex\ncoordinated policies that condition on this knowledge in a fully decentralised\nfashion. We propose multi-agent common knowledge reinforcement learning\n(MACKRL), a novel stochastic actor-critic algorithm that learns a hierarchical\npolicy tree. Higher levels in the hierarchy coordinate groups of agents by\nconditioning on their common knowledge, or delegate to lower levels with\nsmaller subgroups but potentially richer common knowledge. The entire policy\ntree can be executed in a fully decentralised fashion. As the lowest policy\ntree level consists of independent policies for each agent, MACKRL reduces to\nindependently learnt decentralised policies as a special case. We demonstrate\nthat our method can exploit common knowledge for superior performance on\ncomplex decentralised coordination tasks, including a stochastic matrix game\nand challenging problems in StarCraft II unit micromanagement.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 20:45:19 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 14:53:34 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 13:05:30 GMT"}, {"version": "v4", "created": "Sun, 23 Jun 2019 16:45:17 GMT"}, {"version": "v5", "created": "Tue, 1 Oct 2019 11:13:59 GMT"}, {"version": "v6", "created": "Sun, 10 Nov 2019 13:35:42 GMT"}, {"version": "v7", "created": "Tue, 3 Dec 2019 11:03:40 GMT"}, {"version": "v8", "created": "Sat, 11 Jan 2020 22:42:13 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["de Witt", "Christian A. Schroeder", ""], ["Foerster", "Jakob N.", ""], ["Farquhar", "Gregory", ""], ["Torr", "Philip H. S.", ""], ["Boehmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1810.11714", "submitter": "Andrew Hundt", "authors": "Andrew Hundt, Varun Jain, Chia-Hung Lin, Chris Paxton, Gregory D.\n  Hager", "title": "The CoSTAR Block Stacking Dataset: Learning with Workspace Constraints", "comments": "This is a major revision refocusing the topic towards the JHU CoSTAR\n  Block Stacking Dataset, workspace constraints, and a comparison of HyperTrees\n  with hand-designed algorithms. 12 pages, 10 figures, and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robot can now grasp an object more effectively than ever before, but once\nit has the object what happens next? We show that a mild relaxation of the task\nand workspace constraints implicit in existing object grasping datasets can\ncause neural network based grasping algorithms to fail on even a simple block\nstacking task when executed under more realistic circumstances.\n  To address this, we introduce the JHU CoSTAR Block Stacking Dataset (BSD),\nwhere a robot interacts with 5.1 cm colored blocks to complete an\norder-fulfillment style block stacking task. It contains dynamic scenes and\nreal time-series data in a less constrained environment than comparable\ndatasets. There are nearly 12,000 stacking attempts and over 2 million frames\nof real data. We discuss the ways in which this dataset provides a valuable\nresource for a broad range of other topics of investigation.\n  We find that hand-designed neural networks that work on prior datasets do not\ngeneralize to this task. Thus, to establish a baseline for this dataset, we\ndemonstrate an automated search of neural network based models using a novel\nmultiple-input HyperTree MetaModel, and find a final model which makes\nreasonable 3D pose predictions for grasping and stacking on our dataset.\n  The CoSTAR BSD, code, and instructions are available at\nhttps://sites.google.com/site/costardataset.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 21:26:42 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 23:17:17 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Hundt", "Andrew", ""], ["Jain", "Varun", ""], ["Lin", "Chia-Hung", ""], ["Paxton", "Chris", ""], ["Hager", "Gregory D.", ""]]}, {"id": "1810.11732", "submitter": "Labib Terrissa", "authors": "Safa Meraghni, Labib Sadek Terrissa, Soheyb Ayad, Noureddine Zerhouni,\n  Christophe Varnier", "title": "Post-prognostics decision in Cyber-Physical Systems", "comments": "6 pages, 4 figures, 2018 IEEE Ic_ASET", "journal-ref": null, "doi": "10.1109/ASET.2018.8379859", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prognostics and Health Management (PHM) offers several benefits for\npredictive maintenance. It predicts the future behavior of a system as well as\nits Remaining Useful Life (RUL). This RUL is used to planned the maintenance\noperation to avoid the failure, the stop time and optimize the cost of the\nmaintenance and failure. However, with the development of the industry the\nassets are nowadays distributed this is why the PHM needs to be developed using\nthe new IT. In our work we propose a PHM solution based on Cyber physical\nsystem where the physical side is connected to the analyze process of the PHM\nwhich are developed in the cloud to be shared and to benefit of the cloud\ncharacteristics\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 23:47:39 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Meraghni", "Safa", ""], ["Terrissa", "Labib Sadek", ""], ["Ayad", "Soheyb", ""], ["Zerhouni", "Noureddine", ""], ["Varnier", "Christophe", ""]]}, {"id": "1810.11783", "submitter": "Huan Zhang", "authors": "Huan Zhang, Pengchuan Zhang, Cho-Jui Hsieh", "title": "RecurJac: An Efficient Recursive Algorithm for Bounding Jacobian Matrix\n  of Neural Networks and Its Applications", "comments": "Work done during internship at Microsoft Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Jacobian matrix (or the gradient for single-output networks) is directly\nrelated to many important properties of neural networks, such as the function\nlandscape, stationary points, (local) Lipschitz constants and robustness to\nadversarial attacks. In this paper, we propose a recursive algorithm, RecurJac,\nto compute both upper and lower bounds for each element in the Jacobian matrix\nof a neural network with respect to network's input, and the network can\ncontain a wide range of activation functions. As a byproduct, we can\nefficiently obtain a (local) Lipschitz constant, which plays a crucial role in\nneural network robustness verification, as well as the training stability of\nGANs. Experiments show that (local) Lipschitz constants produced by our method\nis of better quality than previous approaches, thus providing better robustness\nverification results. Our algorithm has polynomial time complexity, and its\ncomputation time is reasonable even for relatively large networks.\nAdditionally, we use our bounds of Jacobian matrix to characterize the\nlandscape of the neural network, for example, to determine whether there exist\nstationary points in a local neighborhood. Source code available at\n\\url{http://github.com/huanzhang12/RecurJac-Jacobian-bounds}.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 09:25:08 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 07:01:58 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Zhang", "Huan", ""], ["Zhang", "Pengchuan", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1810.11787", "submitter": "Karanbir Chahal", "authors": "Karanbir Chahal, Manraj Singh Grover, Kuntal Dey", "title": "A Hitchhiker's Guide On Distributed Training of Deep Neural Networks", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has led to tremendous advancements in the field of Artificial\nIntelligence. One caveat however is the substantial amount of compute needed to\ntrain these deep learning models. Training a benchmark dataset like ImageNet on\na single machine with a modern GPU can take upto a week, distributing training\non multiple machines has been observed to drastically bring this time down.\nRecent work has brought down ImageNet training time to a time as low as 4\nminutes by using a cluster of 2048 GPUs. This paper surveys the various\nalgorithms and techniques used to distribute training and presents the current\nstate of the art for a modern distributed training framework. More\nspecifically, we explore the synchronous and asynchronous variants of\ndistributed Stochastic Gradient Descent, various All Reduce gradient\naggregation strategies and best practices for obtaining higher throughout and\nlower latency over a cluster such as mixed precision training, large batch\ntraining and gradient compression.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 09:37:47 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Chahal", "Karanbir", ""], ["Grover", "Manraj Singh", ""], ["Dey", "Kuntal", ""]]}, {"id": "1810.11804", "submitter": "Frank F\\\"orster", "authors": "Frank F\\\"orster, Joe Saunders, Hagen Lehmann, Chrystopher L. Nehaniv", "title": "Robots Learning to Say `No': Prohibition and Rejective Mechanisms in\n  Acquisition of Linguistic Negation", "comments": "Submitted journal article. 21 pages main paper plus 28 pages\n  supplementary information / appendix. 8 figures in main paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  `No' belongs to the first ten words used by children and embodies the first\nactive form of linguistic negation. Despite its early occurrence the details of\nits acquisition process remain largely unknown. The circumstance that `no'\ncannot be construed as a label for perceptible objects or events puts it\noutside of the scope of most modern accounts of language acquisition. Moreover,\nmost symbol grounding architectures will struggle to ground the word due to its\nnon-referential character. In an experimental study involving the child-like\nhumanoid robot iCub that was designed to illuminate the acquisition process of\nnegation words, the robot is deployed in several rounds of speech-wise\nunconstrained interaction with na\\\"ive participants acting as its language\nteachers. The results corroborate the hypothesis that affect or volition plays\na pivotal role in the socially distributed acquisition process. Negation words\nare prosodically salient within prohibitive utterances and negative intent\ninterpretations such that they can be easily isolated from the teacher's speech\nsignal. These words subsequently may be grounded in negative affective states.\nHowever, observations of the nature of prohibitive acts and the temporal\nrelationships between its linguistic and extra-linguistic components raise\nserious questions over the suitability of Hebbian-type algorithms for language\ngrounding.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 12:17:27 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["F\u00f6rster", "Frank", ""], ["Saunders", "Joe", ""], ["Lehmann", "Hagen", ""], ["Nehaniv", "Chrystopher L.", ""]]}, {"id": "1810.11861", "submitter": "Andrew Wilson", "authors": "William Herlands, Daniel B. Neill, Hannes Nickisch, Andrew Gordon\n  Wilson", "title": "Change Surfaces for Expressive Multidimensional Changepoints and\n  Counterfactual Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying changes in model parameters is fundamental in machine learning\nand statistics. However, standard changepoint models are limited in\nexpressiveness, often addressing unidimensional problems and assuming\ninstantaneous changes. We introduce change surfaces as a multidimensional and\nhighly expressive generalization of changepoints. We provide a model-agnostic\nformalization of change surfaces, illustrating how they can provide variable,\nheterogeneous, and non-monotonic rates of change across multiple dimensions.\nAdditionally, we show how change surfaces can be used for counterfactual\nprediction. As a concrete instantiation of the change surface framework, we\ndevelop Gaussian Process Change Surfaces (GPCS). We demonstrate counterfactual\nprediction with Bayesian posterior mean and credible sets, as well as massive\nscalability by introducing novel methods for additive non-separable kernels.\nUsing two large spatio-temporal datasets we employ GPCS to discover and\ncharacterize complex changes that can provide scientific and policy relevant\ninsights. Specifically, we analyze twentieth century measles incidence across\nthe United States and discover previously unknown heterogeneous changes after\nthe introduction of the measles vaccine. Additionally, we apply the model to\nrequests for lead testing kits in New York City, discovering distinct spatial\nand demographic patterns.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 19:08:18 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 11:56:42 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Herlands", "William", ""], ["Neill", "Daniel B.", ""], ["Nickisch", "Hannes", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1810.11878", "submitter": "Richard Yuanzhe Pang", "authors": "Richard Yuanzhe Pang, Kevin Gimpel", "title": "Unsupervised Evaluation Metrics and Learning Criteria for Non-Parallel\n  Textual Transfer", "comments": "EMNLP 2019 Workshop on Neural Generation and Translation (WNGT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of automatically generating textual paraphrases with\nmodified attributes or properties, focusing on the setting without parallel\ndata (Hu et al., 2017; Shen et al., 2017). This setting poses challenges for\nevaluation. We show that the metric of post-transfer classification accuracy is\ninsufficient on its own, and propose additional metrics based on semantic\npreservation and fluency as well as a way to combine them into a single overall\nscore. We contribute new loss functions and training strategies to address the\ndifferent metrics. Semantic preservation is addressed by adding a cyclic\nconsistency loss and a loss based on paraphrase pairs, while fluency is\nimproved by integrating losses based on style-specific language models. We\nexperiment with a Yelp sentiment dataset and a new literature dataset that we\npropose, using multiple models that extend prior work (Shen et al., 2017). We\ndemonstrate that our metrics correlate well with human judgments, at both the\nsentence-level and system-level. Automatic and manual evaluation also show\nlarge improvements over the baseline method of Shen et al. (2017). We hope that\nour proposed metrics can speed up system development for new textual transfer\ntasks while also encouraging the community to address our three complementary\naspects of transfer quality.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 20:40:16 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 16:03:11 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Pang", "Richard Yuanzhe", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1810.11910", "submitter": "Matthew Riemer", "authors": "Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish,\n  Yuhai Tu, Gerald Tesauro", "title": "Learning to Learn without Forgetting by Maximizing Transfer and\n  Minimizing Interference", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lack of performance when it comes to continual learning over non-stationary\ndistributions of data remains a major challenge in scaling neural network\nlearning to more human realistic settings. In this work we propose a new\nconceptualization of the continual learning problem in terms of a temporally\nsymmetric trade-off between transfer and interference that can be optimized by\nenforcing gradient alignment across examples. We then propose a new algorithm,\nMeta-Experience Replay (MER), that directly exploits this view by combining\nexperience replay with optimization based meta-learning. This method learns\nparameters that make interference based on future gradients less likely and\ntransfer based on future gradients more likely. We conduct experiments across\ncontinual lifelong supervised learning benchmarks and non-stationary\nreinforcement learning environments demonstrating that our approach\nconsistently outperforms recently proposed baselines for continual learning.\nOur experiments show that the gap between the performance of MER and baseline\nalgorithms grows both as the environment gets more non-stationary and as the\nfraction of the total experiences stored gets smaller.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 00:13:50 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 19:23:28 GMT"}, {"version": "v3", "created": "Fri, 3 May 2019 03:32:40 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Riemer", "Matthew", ""], ["Cases", "Ignacio", ""], ["Ajemian", "Robert", ""], ["Liu", "Miao", ""], ["Rish", "Irina", ""], ["Tu", "Yuhai", ""], ["Tesauro", "Gerald", ""]]}, {"id": "1810.11921", "submitter": "Weiping Song", "authors": "Weiping Song, Chence Shi, Zhiping Xiao, Zhijian Duan, Yewen Xu, Ming\n  Zhang, Jian Tang", "title": "AutoInt: Automatic Feature Interaction Learning via Self-Attentive\n  Neural Networks", "comments": "Accepted at CIKM2019", "journal-ref": null, "doi": "10.1145/3357384.3357925", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) prediction, which aims to predict the probability of\na user clicking on an ad or an item, is critical to many online applications\nsuch as online advertising and recommender systems. The problem is very\nchallenging since (1) the input features (e.g., the user id, user age, item id,\nitem category) are usually sparse and high-dimensional, and (2) an effective\nprediction relies on high-order combinatorial features (\\textit{a.k.a.} cross\nfeatures), which are very time-consuming to hand-craft by domain experts and\nare impossible to be enumerated. Therefore, there have been efforts in finding\nlow-dimensional representations of the sparse and high-dimensional raw features\nand their meaningful combinations. In this paper, we propose an effective and\nefficient method called the \\emph{AutoInt} to automatically learn the\nhigh-order feature interactions of input features. Our proposed algorithm is\nvery general, which can be applied to both numerical and categorical input\nfeatures. Specifically, we map both the numerical and categorical features into\nthe same low-dimensional space. Afterwards, a multi-head self-attentive neural\nnetwork with residual connections is proposed to explicitly model the feature\ninteractions in the low-dimensional space. With different layers of the\nmulti-head self-attentive neural networks, different orders of feature\ncombinations of input features can be modeled. The whole model can be\nefficiently fit on large-scale raw data in an end-to-end fashion. Experimental\nresults on four real-world datasets show that our proposed approach not only\noutperforms existing state-of-the-art approaches for prediction but also offers\ngood explainability. Code is available at:\n\\url{https://github.com/DeepGraphLearning/RecommenderSystems}.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 01:56:25 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 19:51:41 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Song", "Weiping", ""], ["Shi", "Chence", ""], ["Xiao", "Zhiping", ""], ["Duan", "Zhijian", ""], ["Xu", "Yewen", ""], ["Zhang", "Ming", ""], ["Tang", "Jian", ""]]}, {"id": "1810.11937", "submitter": "Satvik Jain", "authors": "Satvik Jain, Arun Balaji Buduru, Anshuman Chhabra", "title": "An approach to predictively securing critical cloud infrastructures\n  through probabilistic modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud infrastructures are being increasingly utilized in critical\ninfrastructures such as banking/finance, transportation and utility management.\nSophistication and resources used in recent security breaches including those\non critical infrastructures show that attackers are no longer limited by\nmonetary/computational constraints. In fact, they may be aided by entities with\nlarge financial and human resources. Hence there is urgent need to develop\npredictive approaches for cyber defense to strengthen cloud infrastructures\nspecifically utilized by critical infrastructures. Extensive research has been\ndone in the past on applying techniques such as Game Theory, Machine Learning\nand Bayesian Networks among others for the predictive defense of critical\ninfrastructures. However a major drawback of these approaches is that they do\nnot incorporate probabilistic human behavior which limits their predictive\nability. In this paper, a stochastic approach is proposed to predict less\nsecure states in critical cloud systems which might lead to potential security\nbreaches. These less-secure states are deemed as `risky' states in our\napproach. Markov Decision Process (MDP) is used to accurately incorporate user\nbehavior(s) as well as operational behavior of the cloud infrastructure through\na set of features. The developed reward/cost mechanism is then used to select\nappropriate `actions' to identify risky states at future time steps by learning\nan optimal policy. Experimental results show that the proposed framework\nperforms well in identifying future `risky' states. Through this work we\ndemonstrate the effectiveness of using probabilistic modeling (MDP) to\npredictively secure critical cloud infrastructures.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 03:34:56 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Jain", "Satvik", ""], ["Buduru", "Arun Balaji", ""], ["Chhabra", "Anshuman", ""]]}, {"id": "1810.11947", "submitter": "Bin Song", "authors": "Yue Zhang, Fang Tian, Bin Song, and Xiaojiang Du", "title": "Social Vehicle Swarms: A Novel Perspective on Social-aware Vehicular\n  Communication Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of vehicles is a promising area related to D2D communication and\ninternet of things. We present a novel perspective for vehicular\ncommunications, social vehicle swarms, to study and analyze socially aware\ninternet of vehicles with the assistance of an agent-based model intended to\nreveal hidden patterns behind superficial data. After discussing its\ncomponents, namely its agents, environments, and rules, we introduce supportive\ntechnology and methods, deep reinforcement learning, privacy preserving data\nmining and sub-cloud computing, in order to detect the most significant and\ninteresting information for each individual effectively, which is the key\ndesire. Finally, several relevant research topics and challenges are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 04:14:17 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Zhang", "Yue", ""], ["Tian", "Fang", ""], ["Song", "Bin", ""], ["Du", "Xiaojiang", ""]]}, {"id": "1810.11954", "submitter": "Shubham Agarwal", "authors": "Shubham Agarwal, Ondrej Dusek, Ioannis Konstas and Verena Rieser", "title": "A Knowledge-Grounded Multimodal Search-Based Conversational Agent", "comments": null, "journal-ref": "Proceedings of the 2018 EMNLP Workshop SCAI: The 2nd International\n  Workshop on Search-Oriented Conversational AI, pages 59-66, Brussels,\n  Belgium, October 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal search-based dialogue is a challenging new task: It extends\nvisually grounded question answering systems into multi-turn conversations with\naccess to an external database. We address this new challenge by learning a\nneural response generation system from the recently released Multimodal\nDialogue (MMD) dataset (Saha et al., 2017). We introduce a knowledge-grounded\nmultimodal conversational model where an encoded knowledge base (KB)\nrepresentation is appended to the decoder input. Our model substantially\noutperforms strong baselines in terms of text-based similarity measures (over 9\nBLEU points, 3 of which are solely due to the use of additional information\nfrom the KB.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 16:58:54 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Agarwal", "Shubham", ""], ["Dusek", "Ondrej", ""], ["Konstas", "Ioannis", ""], ["Rieser", "Verena", ""]]}, {"id": "1810.12034", "submitter": "Anders Arpteg", "authors": "Anders Arpteg, Bj\\\"orn Brinne, Luka Crnkovic-Friis, Jan Bosch", "title": "Software Engineering Challenges of Deep Learning", "comments": "44th Euromicro Conference on Software Engineering and Advanced\n  Applications, IEEE, 2018", "journal-ref": null, "doi": "10.1109/SEAA.2018.00018", "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surprisingly promising results have been achieved by deep learning (DL)\nsystems in recent years. Many of these achievements have been reached in\nacademic settings, or by large technology companies with highly skilled\nresearch groups and advanced supporting infrastructure. For companies without\nlarge research groups or advanced infrastructure, building high-quality\nproduction-ready systems with DL components has proven challenging. There is a\nclear lack of well-functioning tools and best practices for building DL\nsystems. It is the goal of this research to identify what the main challenges\nare, by applying an interpretive research approach in close collaboration with\ncompanies of varying size and type.\n  A set of seven projects have been selected to describe the potential with\nthis new technology and to identify associated main challenges. A set of 12\nmain challenges has been identified and categorized into the three areas of\ndevelopment, production, and organizational challenges. Furthermore, a mapping\nbetween the challenges and the projects is defined, together with selected\nmotivating descriptions of how and why the challenges apply to specific\nprojects.\n  Compared to other areas such as software engineering or database\ntechnologies, it is clear that DL is still rather immature and in need of\nfurther work to facilitate development of high-quality systems. The challenges\nidentified in this paper can be used to guide future research by the software\nengineering and DL communities. Together, we could enable a large number of\ncompanies to start taking advantage of the high potential of the DL technology.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 10:05:37 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Arpteg", "Anders", ""], ["Brinne", "Bj\u00f6rn", ""], ["Crnkovic-Friis", "Luka", ""], ["Bosch", "Jan", ""]]}, {"id": "1810.12069", "submitter": "Timoth\\'ee Lesort", "authors": "Timoth\\'ee Lesort, Alexander Gepperth, Andrei Stoian, David Filliat", "title": "Marginal Replay vs Conditional Replay for Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new replay-based method of continual classification learning\nthat we term \"conditional replay\" which generates samples and labels together\nby sampling from a distribution conditioned on the class. We compare\nconditional replay to another\n  replay-based continual learning paradigm (which we term \"marginal replay\")\nthat generates samples independently of their class and assigns labels in a\nseparate step.\n  The main improvement in conditional replay is that labels for generated\nsamples need not be inferred, which reduces the margin for error in complex\ncontinual classification learning tasks. We demonstrate the effectiveness of\nthis approach using novel and standard benchmarks constructed from MNIST and\nFashionMNIST data, and compare to the regularization-based \\textit{elastic\nweight consolidation} (EWC) method.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 12:17:48 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 13:23:15 GMT"}, {"version": "v3", "created": "Thu, 13 Dec 2018 20:22:15 GMT"}, {"version": "v4", "created": "Sat, 29 Dec 2018 10:35:42 GMT"}, {"version": "v5", "created": "Wed, 23 Jan 2019 14:49:00 GMT"}, {"version": "v6", "created": "Mon, 1 Jul 2019 14:12:50 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Lesort", "Timoth\u00e9e", ""], ["Gepperth", "Alexander", ""], ["Stoian", "Andrei", ""], ["Filliat", "David", ""]]}, {"id": "1810.12081", "submitter": "Lijun Wu", "authors": "Lijun Wu, Fei Tian, Yingce Xia, Yang Fan, Tao Qin, Jianhuang Lai,\n  Tie-Yan Liu", "title": "Learning to Teach with Dynamic Loss Functions", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teaching is critical to human society: it is with teaching that prospective\nstudents are educated and human civilization can be inherited and advanced. A\ngood teacher not only provides his/her students with qualified teaching\nmaterials (e.g., textbooks), but also sets up appropriate learning objectives\n(e.g., course projects and exams) considering different situations of a\nstudent. When it comes to artificial intelligence, treating machine learning\nmodels as students, the loss functions that are optimized act as perfect\ncounterparts of the learning objective set by the teacher. In this work, we\nexplore the possibility of imitating human teaching behaviors by dynamically\nand automatically outputting appropriate loss functions to train machine\nlearning models. Different from typical learning settings in which the loss\nfunction of a machine learning model is predefined and fixed, in our framework,\nthe loss function of a machine learning model (we call it student) is defined\nby another machine learning model (we call it teacher). The ultimate goal of\nteacher model is cultivating the student to have better performance measured on\ndevelopment dataset. Towards that end, similar to human teaching, the teacher,\na parametric model, dynamically outputs different loss functions that will be\nused and optimized by its student model at different training stages. We\ndevelop an efficient learning method for the teacher model that makes gradient\nbased optimization possible, exempt of the ineffective solutions such as policy\noptimization. We name our method as \"learning to teach with dynamic loss\nfunctions\" (L2T-DLF for short). Extensive experiments on real world tasks\nincluding image classification and neural machine translation demonstrate that\nour method significantly improves the quality of various student models.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 13:03:38 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Wu", "Lijun", ""], ["Tian", "Fei", ""], ["Xia", "Yingce", ""], ["Fan", "Yang", ""], ["Qin", "Tao", ""], ["Lai", "Jianhuang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1810.12114", "submitter": "Lester Beltran", "authors": "Lester Beltran and Suzette Geriente", "title": "Quantum Entanglement in Corpuses of Documents", "comments": "17 pages, no figures. arXiv admin note: text overlap with\n  arXiv:1802.02216 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that data collected from corpuses of documents violate the\nClauser-Horne-Shimony-Holt version of Bell's inequality (CHSH inequality) and\ntherefore indicate the presence of quantum entanglement in their structure. We\nobtain this result by considering two concepts and their combination and\ncoincidence operations consisting of searches of co-occurrences of exemplars of\nthese concepts in specific corpuses of documents. Measuring the frequencies of\nthese co-occurrences and calculating the relative frequencies as approximate\nprobabilities entering in the CHSH inequality, we obtain manifest violations of\nthe latter for all considered corpuses of documents. In comparing these\nviolations with those analogously obtained in an earlier work for the same\ncombined concepts in psychological coincidence experiments with human\nparticipants, also violating the CHSH inequality, we identify the entanglement\nas being carried by the meaning connection between the two considered concepts\nwithin the combination they form. We explain the stronger violation for the\ncorpuses of documents, as compared to the violation in the psychology\nexperiments, as being due to the superior meaning domain of the human mind and,\non the other side, to the latter reaching a broader domain of meaning and being\npossibly also actively influenced during the experimentation. We mention some\nof the issues to be analyzed in future work such as the violations of the CHSH\ninequality being larger than the `Cirel'son bound' for all of the considered\ncorpuses of documents.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 19:25:59 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Beltran", "Lester", ""], ["Geriente", "Suzette", ""]]}, {"id": "1810.12118", "submitter": "Jiamou Liu", "authors": "Helen Jiahe Zhao and Jiamou Liu", "title": "Finding Answers from the Word of God: Domain Adaptation for Neural\n  Networks in Biblical Question Answering", "comments": "The paper has been accepted at IJCNN 2018", "journal-ref": null, "doi": "10.1109/IJCNN.2018.8489756", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) has significantly benefitted from deep learning\ntechniques in recent years. However, domain-specific QA remains a challenge due\nto the significant amount of data required to train a neural network. This\npaper studies the answer sentence selection task in the Bible domain and answer\nquestions by selecting relevant verses from the Bible. For this purpose, we\ncreate a new dataset BibleQA based on bible trivia questions and propose three\nneural network models for our task. We pre-train our models on a large-scale QA\ndataset, SQuAD, and investigate the effect of transferring weights on model\naccuracy. Furthermore, we also measure the model accuracies with different\nanswer context lengths and different Bible translations. We affirm that\ntransfer learning has a noticeable improvement in the model accuracy. We\nachieve relatively good results with shorter context lengths, whereas longer\ncontext lengths decreased model accuracy. We also find that using a more modern\nBible translation in the dataset has a positive effect on the task.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 12:34:21 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Zhao", "Helen Jiahe", ""], ["Liu", "Jiamou", ""]]}, {"id": "1810.12125", "submitter": "Boyi Hou", "authors": "Boyi Hou, Qun Chen, Yanyan Wang, Youcef Nafa, Zhanhuai Li", "title": "Gradual Machine Learning for Entity Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usually considered as a classification problem, entity resolution (ER) can be\nvery challenging on real data due to the prevalence of dirty values. The\nstate-of-the-art solutions for ER were built on a variety of learning models\n(most notably deep neural networks), which require lots of accurately labeled\ntraining data. Unfortunately, high-quality labeled data usually require\nexpensive manual work, and are therefore not readily available in many real\nscenarios. In this paper, we propose a novel learning paradigm for ER, called\ngradual machine learning, which aims to enable effective machine labeling\nwithout the requirement for manual labeling effort. It begins with some easy\ninstances in a task, which can be automatically labeled by the machine with\nhigh accuracy, and then gradually labels more challenging instances by\niterative factor graph inference. In gradual machine learning, the hard\ninstances in a task are gradually labeled in small stages based on the\nestimated evidential certainty provided by the labeled easier instances. Our\nextensive experiments on real data have shown that the performance of the\nproposed approach is considerably better than its unsupervised alternatives,\nand highly competitive compared to the state-of-the-art supervised techniques.\nUsing ER as a test case, we demonstrate that gradual machine learning is a\npromising paradigm potentially applicable to other challenging classification\ntasks requiring extensive labeling effort.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 13:47:52 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 11:58:22 GMT"}, {"version": "v3", "created": "Wed, 24 Apr 2019 08:40:51 GMT"}, {"version": "v4", "created": "Fri, 14 Jun 2019 01:12:48 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Hou", "Boyi", ""], ["Chen", "Qun", ""], ["Wang", "Yanyan", ""], ["Nafa", "Youcef", ""], ["Li", "Zhanhuai", ""]]}, {"id": "1810.12162", "submitter": "Pranav Shyam", "authors": "Pranav Shyam, Wojciech Ja\\'skowski, Faustino Gomez", "title": "Model-Based Active Exploration", "comments": "ICML 2019. Code: https://github.com/nnaisense/max", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT cs.NE math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration is an unsolved problem in Reinforcement Learning which\nis usually addressed by reactively rewarding the agent for fortuitously\nencountering novel situations. This paper introduces an efficient active\nexploration algorithm, Model-Based Active eXploration (MAX), which uses an\nensemble of forward models to plan to observe novel events. This is carried out\nby optimizing agent behaviour with respect to a measure of novelty derived from\nthe Bayesian perspective of exploration, which is estimated using the\ndisagreement between the futures predicted by the ensemble members. We show\nempirically that in semi-random discrete environments where directed\nexploration is critical to make progress, MAX is at least an order of magnitude\nmore efficient than strong baselines. MAX scales to high-dimensional continuous\nenvironments where it builds task-agnostic models that can be used for any\ndownstream task.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 14:43:48 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 11:22:22 GMT"}, {"version": "v3", "created": "Thu, 7 Feb 2019 18:00:02 GMT"}, {"version": "v4", "created": "Mon, 13 May 2019 20:58:53 GMT"}, {"version": "v5", "created": "Thu, 13 Jun 2019 19:33:27 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Shyam", "Pranav", ""], ["Ja\u015bkowski", "Wojciech", ""], ["Gomez", "Faustino", ""]]}, {"id": "1810.12186", "submitter": "Nathanael Perraudin N. P.", "authors": "Nathana\\\"el Perraudin, Micha\\\"el Defferrard, Tomasz Kacprzak, Raphael\n  Sgier", "title": "DeepSphere: Efficient spherical Convolutional Neural Network with\n  HEALPix sampling for cosmological applications", "comments": "arXiv admin note: text overlap with arXiv:astro-ph/0409513 by other\n  authors", "journal-ref": null, "doi": "10.1016/j.ascom.2019.03.004", "report-no": null, "categories": "astro-ph.CO astro-ph.IM cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are a cornerstone of the Deep Learning\ntoolbox and have led to many breakthroughs in Artificial Intelligence. These\nnetworks have mostly been developed for regular Euclidean domains such as those\nsupporting images, audio, or video. Because of their success, CNN-based methods\nare becoming increasingly popular in Cosmology. Cosmological data often comes\nas spherical maps, which make the use of the traditional CNNs more complicated.\nThe commonly used pixelization scheme for spherical maps is the Hierarchical\nEqual Area isoLatitude Pixelisation (HEALPix). We present a spherical CNN for\nanalysis of full and partial HEALPix maps, which we call DeepSphere. The\nspherical CNN is constructed by representing the sphere as a graph. Graphs are\nversatile data structures that can act as a discrete representation of a\ncontinuous manifold. Using the graph-based representation, we define many of\nthe standard CNN operations, such as convolution and pooling. With filters\nrestricted to being radial, our convolutions are equivariant to rotation on the\nsphere, and DeepSphere can be made invariant or equivariant to rotation. This\nway, DeepSphere is a special case of a graph CNN, tailored to the HEALPix\nsampling of the sphere. This approach is computationally more efficient than\nusing spherical harmonics to perform convolutions. We demonstrate the method on\na classification problem of weak lensing mass maps from two cosmological models\nand compare the performance of the CNN with that of two baseline classifiers.\nThe results show that the performance of DeepSphere is always superior or equal\nto both of these baselines. For high noise levels and for data covering only a\nsmaller fraction of the sphere, DeepSphere achieves typically 10% better\nclassification accuracy than those baselines. Finally, we show how learned\nfilters can be visualized to introspect the neural network.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 15:23:18 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 17:11:17 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Perraudin", "Nathana\u00ebl", ""], ["Defferrard", "Micha\u00ebl", ""], ["Kacprzak", "Tomasz", ""], ["Sgier", "Raphael", ""]]}, {"id": "1810.12188", "submitter": "Kwang-Sung Jun", "authors": "Kwang-Sung Jun, Lihong Li, Yuzhe Ma, Xiaojin Zhu", "title": "Adversarial Attacks on Stochastic Bandits", "comments": "accepted to NIPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study adversarial attacks that manipulate the reward signals to control\nthe actions chosen by a stochastic multi-armed bandit algorithm. We propose the\nfirst attack against two popular bandit algorithms: $\\epsilon$-greedy and UCB,\n\\emph{without} knowledge of the mean rewards. The attacker is able to spend\nonly logarithmic effort, multiplied by a problem-specific parameter that\nbecomes smaller as the bandit problem gets easier to attack. The result means\nthe attacker can easily hijack the behavior of the bandit algorithm to promote\nor obstruct certain actions, say, a particular medical treatment. As bandits\nare seeing increasingly wide use in practice, our study exposes a significant\nsecurity threat.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 15:28:20 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Jun", "Kwang-Sung", ""], ["Li", "Lihong", ""], ["Ma", "Yuzhe", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "1810.12282", "submitter": "Katelyn Gao", "authors": "Charles Packer, Katelyn Gao, Jernej Kos, Philipp Kr\\\"ahenb\\\"uhl,\n  Vladlen Koltun, Dawn Song", "title": "Assessing Generalization in Deep Reinforcement Learning", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) has achieved breakthrough results on many\ntasks, but agents often fail to generalize beyond the environment they were\ntrained in. As a result, deep RL algorithms that promote generalization are\nreceiving increasing attention. However, works in this area use a wide variety\nof tasks and experimental setups for evaluation. The literature lacks a\ncontrolled assessment of the merits of different generalization schemes. Our\naim is to catalyze community-wide progress on generalization in deep RL. To\nthis end, we present a benchmark and experimental protocol, and conduct a\nsystematic empirical study. Our framework contains a diverse set of\nenvironments, our methodology covers both in-distribution and\nout-of-distribution generalization, and our evaluation includes deep RL\nalgorithms that specifically tackle generalization. Our key finding is that\n`vanilla' deep RL algorithms generalize better than specialized schemes that\nwere proposed specifically to tackle generalization.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:51:46 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 17:58:23 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Packer", "Charles", ""], ["Gao", "Katelyn", ""], ["Kos", "Jernej", ""], ["Kr\u00e4henb\u00fchl", "Philipp", ""], ["Koltun", "Vladlen", ""], ["Song", "Dawn", ""]]}, {"id": "1810.12283", "submitter": "David Eriksson", "authors": "David Eriksson, Kun Dong, Eric Hans Lee, David Bindel, Andrew Gordon\n  Wilson", "title": "Scaling Gaussian Process Regression with Derivatives", "comments": "Appears at Advances in Neural Information Processing Systems 32\n  (NIPS), 2018", "journal-ref": "Advances in Neural Information Processing Systems 32 (NIPS), 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) with derivatives are useful in many applications,\nincluding Bayesian optimization, implicit surface reconstruction, and terrain\nreconstruction. Fitting a GP to function values and derivatives at $n$ points\nin $d$ dimensions requires linear solves and log determinants with an ${n(d+1)\n\\times n(d+1)}$ positive definite matrix -- leading to prohibitive\n$\\mathcal{O}(n^3d^3)$ computations for standard direct methods. We propose\niterative solvers using fast $\\mathcal{O}(nd)$ matrix-vector multiplications\n(MVMs), together with pivoted Cholesky preconditioning that cuts the iterations\nto convergence by several orders of magnitude, allowing for fast kernel\nlearning and prediction. Our approaches, together with dimensionality\nreduction, enables Bayesian optimization with derivatives to scale to\nhigh-dimensional problems and large evaluation budgets.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:51:54 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Eriksson", "David", ""], ["Dong", "Kun", ""], ["Lee", "Eric Hans", ""], ["Bindel", "David", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1810.12366", "submitter": "Arjun Chandrasekaran", "authors": "Arjun Chandrasekaran, Viraj Prabhu, Deshraj Yadav, Prithvijit\n  Chattopadhyay, Devi Parikh", "title": "Do Explanations make VQA Models more Predictable to a Human?", "comments": "EMNLP 2018. 16 pages, 11 figures. Content overlaps with \"It Takes Two\n  to Tango: Towards Theory of AI's Mind\" (arXiv:1704.00717)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A rich line of research attempts to make deep neural networks more\ntransparent by generating human-interpretable 'explanations' of their decision\nprocess, especially for interactive tasks like Visual Question Answering (VQA).\nIn this work, we analyze if existing explanations indeed make a VQA model --\nits responses as well as failures -- more predictable to a human. Surprisingly,\nwe find that they do not. On the other hand, we find that human-in-the-loop\napproaches that treat the model as a black-box do.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 19:14:26 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Chandrasekaran", "Arjun", ""], ["Prabhu", "Viraj", ""], ["Yadav", "Deshraj", ""], ["Chattopadhyay", "Prithvijit", ""], ["Parikh", "Devi", ""]]}, {"id": "1810.12427", "submitter": "Julian Medina", "authors": "Julian Richard Medina, Jugal Kalita", "title": "Parallel Attention Mechanisms in Neural Machine Translation", "comments": "ICMLA 2018, 6 pages", "journal-ref": "17th IEEE International Conference on Machine Learning and\n  Applications 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent papers in neural machine translation have proposed the strict use of\nattention mechanisms over previous standards such as recurrent and\nconvolutional neural networks (RNNs and CNNs). We propose that by running\ntraditionally stacked encoding branches from encoder-decoder attention- focused\narchitectures in parallel, that even more sequential operations can be removed\nfrom the model and thereby decrease training time. In particular, we modify the\nrecently published attention-based architecture called Transformer by Google,\nby replacing sequential attention modules with parallel ones, reducing the\namount of training time and substantially improving BLEU scores at the same\ntime. Experiments over the English to German and English to French translation\ntasks show that our model establishes a new state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 21:58:13 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Medina", "Julian Richard", ""], ["Kalita", "Jugal", ""]]}, {"id": "1810.12429", "submitter": "Ziyang Tang", "authors": "Qiang Liu, Lihong Li, Ziyang Tang, Dengyong Zhou", "title": "Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation", "comments": "21 pages, 5 figures, NIPS 2018 (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the off-policy estimation problem of estimating the expected\nreward of a target policy using samples collected by a different behavior\npolicy. Importance sampling (IS) has been a key technique to derive (nearly)\nunbiased estimators, but is known to suffer from an excessively high variance\nin long-horizon problems. In the extreme case of in infinite-horizon problems,\nthe variance of an IS-based estimator may even be unbounded. In this paper, we\npropose a new off-policy estimation method that applies IS directly on the\nstationary state-visitation distributions to avoid the exploding variance issue\nfaced by existing estimators.Our key contribution is a novel approach to\nestimating the density ratio of two stationary distributions, with trajectories\nsampled from only the behavior distribution. We develop a mini-max loss\nfunction for the estimation problem, and derive a closed-form solution for the\ncase of RKHS. We support our method with both theoretical and empirical\nanalyses.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 22:03:58 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Liu", "Qiang", ""], ["Li", "Lihong", ""], ["Tang", "Ziyang", ""], ["Zhou", "Dengyong", ""]]}, {"id": "1810.12436", "submitter": "Wei Wang", "authors": "Shibo Zhou, Wei Wang", "title": "Object Detection based on LIDAR Temporal Pulses using Spiking Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks has been successfully used in the processing of Lidar data,\nespecially in the scenario of autonomous driving. However, existing methods\nheavily rely on pre-processing of the pulse signals derived from Lidar sensors\nand therefore result in high computational overhead and considerable latency.\nIn this paper, we proposed an approach utilizing Spiking Neural Network (SNN)\nto address the object recognition problem directly with raw temporal pulses. To\nhelp with the evaluation and benchmarking, a comprehensive temporal pulses\ndata-set was created to simulate Lidar reflection in different road scenarios.\nBeing tested with regard to recognition accuracy and time efficiency under\ndifferent noise conditions, our proposed method shows remarkable performance\nwith the inference accuracy up to 99.83% (with 10% noise) and the average\nrecognition delay as low as 265 ns. It highlights the potential of SNN in\nautonomous driving and some related applications. In particular, to our best\nknowledge, this is the first attempt to use SNN to directly perform object\nrecognition on raw Lidar temporal pulses.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 22:21:33 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Zhou", "Shibo", ""], ["Wang", "Wei", ""]]}, {"id": "1810.12488", "submitter": "Yen-Chang Hsu", "authors": "Yen-Chang Hsu, Yen-Cheng Liu, Anita Ramasamy, and Zsolt Kira", "title": "Re-evaluating Continual Learning Scenarios: A Categorization and Case\n  for Strong Baselines", "comments": "Continual Learning Workshop, 32nd Conference on Neural Information\n  Processing Systems (NIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning has received a great deal of attention recently with\nseveral approaches being proposed. However, evaluations involve a diverse set\nof scenarios making meaningful comparison difficult. This work provides a\nsystematic categorization of the scenarios and evaluates them within a\nconsistent framework including strong baselines and state-of-the-art methods.\nThe results provide an understanding of the relative difficulty of the\nscenarios and that simple baselines (Adagrad, L2 regularization, and naive\nrehearsal strategies) can surprisingly achieve similar performance to current\nmainstream methods. We conclude with several suggestions for creating harder\nevaluation scenarios and future research directions. The code is available at\nhttps://github.com/GT-RIPL/Continual-Learning-Benchmark\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 02:08:35 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 16:50:11 GMT"}, {"version": "v3", "created": "Mon, 10 Dec 2018 03:51:28 GMT"}, {"version": "v4", "created": "Wed, 23 Jan 2019 16:58:13 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Hsu", "Yen-Chang", ""], ["Liu", "Yen-Cheng", ""], ["Ramasamy", "Anita", ""], ["Kira", "Zsolt", ""]]}, {"id": "1810.12492", "submitter": "Mohammed Almukaynizi", "authors": "Mohammed Almukaynizi, Ericsson Marin, Eric Nunes, Paulo Shakarian,\n  Gerardo I. Simari, Dipsy Kapoor and Timothy Siedlecki", "title": "DARKMENTION: A Deployed System to Predict Enterprise-Targeted External\n  Cyberattacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent incidents of data breaches call for organizations to proactively\nidentify cyber attacks on their systems. Darkweb/Deepweb (D2web) forums and\nmarketplaces provide environments where hackers anonymously discuss existing\nvulnerabilities and commercialize malicious software to exploit those\nvulnerabilities. These platforms offer security practitioners a threat\nintelligence environment that allows to mine for patterns related to\norganization-targeted cyber attacks. In this paper, we describe a system\n(called DARKMENTION) that learns association rules correlating indicators of\nattacks from D2web to real-world cyber incidents. Using the learned rules,\nDARKMENTION generates and submits warnings to a Security Operations Center\n(SOC) prior to attacks. Our goal was to design a system that automatically\ngenerates enterprise-targeted warnings that are timely, actionable, accurate,\nand transparent. We show that DARKMENTION meets our goal. In particular, we\nshow that it outperforms baseline systems that attempt to generate warnings of\ncyber attacks related to two enterprises with an average increase in F1 score\nof about 45% and 57%. Additionally, DARKMENTION was deployed as part of a\nlarger system that is built under a contract with the IARPA Cyber-attack\nAutomated Unconventional Sensor Environment (CAUSE) program. It is actively\nproducing warnings that precede attacks by an average of 3 days.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 02:21:46 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Almukaynizi", "Mohammed", ""], ["Marin", "Ericsson", ""], ["Nunes", "Eric", ""], ["Shakarian", "Paulo", ""], ["Simari", "Gerardo I.", ""], ["Kapoor", "Dipsy", ""], ["Siedlecki", "Timothy", ""]]}, {"id": "1810.12521", "submitter": "Yi Zhu", "authors": "Yi Zhu and Jia Xue and Shawn Newsam", "title": "Gated Transfer Network for Transfer Learning", "comments": "Accepted at ACCV 2018. Camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have led to a series of breakthroughs in computer vision\ngiven sufficient annotated training datasets. For novel tasks with limited\nlabeled data, the prevalent approach is to transfer the knowledge learned in\nthe pre-trained models to the new tasks by fine-tuning. Classic model\nfine-tuning utilizes the fact that well trained neural networks appear to learn\ncross domain features. These features are treated equally during transfer\nlearning. In this paper, we explore the impact of feature selection in model\nfine-tuning by introducing a transfer module, which assigns weights to features\nextracted from pre-trained models. The proposed transfer module proves the\nimportance of feature selection for transferring models from source to target\ndomains. It is shown to significantly improve upon fine-tuning results with\nonly marginal extra computational cost. We also incorporate an auxiliary\nclassifier as an extra regularizer to avoid over-fitting. Finally, we build a\nGated Transfer Network (GTN) based on our transfer module and achieve\nstate-of-the-art results on six different tasks.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 04:31:48 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Zhu", "Yi", ""], ["Xue", "Jia", ""], ["Newsam", "Shawn", ""]]}, {"id": "1810.12522", "submitter": "Yi Zhu", "authors": "Yi Zhu and Shawn Newsam", "title": "Random Temporal Skipping for Multirate Video Analysis", "comments": "Accepted at ACCV 2018. Camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art approaches to video understanding adopt temporal\njittering to simulate analyzing the video at varying frame rates. However, this\ndoes not work well for multirate videos, in which actions or subactions occur\nat different speeds. The frame sampling rate should vary in accordance with the\ndifferent motion speeds. In this work, we propose a simple yet effective\nstrategy, termed random temporal skipping, to address this situation. This\nstrategy effectively handles multirate videos by randomizing the sampling rate\nduring training. It is an exhaustive approach, which can potentially cover all\nmotion speed variations. Furthermore, due to the large temporal skipping, our\nnetwork can see video clips that originally cover over 100 frames. Such a time\nrange is enough to analyze most actions/events. We also introduce an\nocclusion-aware optical flow learning method that generates improved motion\nmaps for human action recognition. Our framework is end-to-end trainable, runs\nin real-time, and achieves state-of-the-art performance on six widely adopted\nvideo benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 04:35:43 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Zhu", "Yi", ""], ["Newsam", "Shawn", ""]]}, {"id": "1810.12535", "submitter": "Qingzhong Wang", "authors": "Qingzhong Wang and Antoni B. Chan", "title": "Gated Hierarchical Attention for Image Captioning", "comments": "Accepted by ACCV", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention modules connecting encoder and decoders have been widely applied in\nthe field of object recognition, image captioning, visual question answering\nand neural machine translation, and significantly improves the performance. In\nthis paper, we propose a bottom-up gated hierarchical attention (GHA) mechanism\nfor image captioning. Our proposed model employs a CNN as the decoder which is\nable to learn different concepts at different layers, and apparently, different\nconcepts correspond to different areas of an image. Therefore, we develop the\nGHA in which low-level concepts are merged into high-level concepts and\nsimultaneously low-level attended features pass to the top to make predictions.\nOur GHA significantly improves the performance of the model that only applies\none level attention, for example, the CIDEr score increases from 0.923 to\n0.999, which is comparable to the state-of-the-art models that employ\nattributes boosting and reinforcement learning (RL). We also conduct extensive\nexperiments to analyze the CNN decoder and our proposed GHA, and we find that\ndeeper decoders cannot obtain better performance, and when the convolutional\ndecoder becomes deeper the model is likely to collapse during training.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 05:20:49 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 04:44:41 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Wang", "Qingzhong", ""], ["Chan", "Antoni B.", ""]]}, {"id": "1810.12558", "submitter": "Mahammad Humayoo", "authors": "Mahammad Humayoo and Xueqi Cheng", "title": "Relative Importance Sampling For Off-Policy Actor-Critic in Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy learning is more unstable compared to on-policy learning in\nreinforcement learning (RL). One reason for the instability of off-policy\nlearning is a discrepancy between the target ($\\pi$) and behavior (b) policy\ndistributions. The discrepancy between $\\pi$ and b distributions can be\nalleviated by employing a smooth variant of the importance sampling (IS), such\nas the relative importance sampling (RIS). RIS has parameter $\\beta\\in[0, 1]$\nwhich controls smoothness. To cope with instability, we present the first\nrelative importance sampling-off-policy actor-critic (RIS-Off-PAC) model-free\nalgorithms in RL. In our method, the network yields a target policy (the\nactor), a value function (the critic) assessing the current policy ($\\pi$)\nusing samples drawn from behavior policy. We use action value generated from\nthe behavior policy in reward function to train our algorithm rather than from\nthe target policy. We also use deep neural networks to train both actor and\ncritic. We evaluated our algorithm on a number of Open AI Gym benchmark\nproblems and demonstrate better or comparable performance to several\nstate-of-the-art RL baselines.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 07:41:08 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 07:13:50 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 00:27:31 GMT"}, {"version": "v4", "created": "Thu, 11 Jul 2019 02:42:41 GMT"}, {"version": "v5", "created": "Tue, 16 Jul 2019 01:35:44 GMT"}, {"version": "v6", "created": "Fri, 19 Jul 2019 03:08:45 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Humayoo", "Mahammad", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1810.12640", "submitter": "Lyes Khacef", "authors": "Lyes Khacef, Bernard Girau, Nicolas Rougier, Andres Upegui, Benoit\n  Miramond", "title": "Neuromorphic hardware as a self-organizing computing system", "comments": "Published in IEEE World Congress on Computational Intelligence\n  (WCCI), International Workshop: Neuromorphic Hardware in Practice and Use\n  (NHPU), Jul. 2018, Rio de Janeiro, Brazil", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the self-organized neuromorphic architecture named SOMA.\nThe objective is to study neural-based self-organization in computing systems\nand to prove the feasibility of a self-organizing hardware structure.\nConsidering that these properties emerge from large scale and fully connected\nneural maps, we will focus on the definition of a self-organizing hardware\narchitecture based on digital spiking neurons that offer hardware efficiency.\nFrom a biological point of view, this corresponds to a combination of the\nso-called synaptic and structural plasticities. We intend to define\ncomputational models able to simultaneously self-organize at both computation\nand communication levels, and we want these models to be hardware-compliant,\nfault tolerant and scalable by means of a neuro-cellular structure.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 10:35:07 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Khacef", "Lyes", ""], ["Girau", "Bernard", ""], ["Rougier", "Nicolas", ""], ["Upegui", "Andres", ""], ["Miramond", "Benoit", ""]]}, {"id": "1810.12644", "submitter": "Joachim Meyer", "authors": "Nir Douer and Joachim Meyer", "title": "The Responsibility Quantification (ResQu) Model of Human Interaction\n  with Automation", "comments": null, "journal-ref": "IEEE Transactions on Automation Science and Engineering, Vol. 17\n  (2), pp. 1044-1060, April 2020", "doi": "10.1109/TASE.2020.2965466", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent systems and advanced automation are involved in information\ncollection and evaluation, in decision-making and in the implementation of\nchosen actions. In such systems, human responsibility becomes equivocal.\nUnderstanding human casual responsibility is particularly important when\nintelligent autonomous systems can harm people, as with autonomous vehicles or,\nmost notably, with autonomous weapon systems (AWS). Using Information Theory,\nwe develop a responsibility quantification (ResQu) model of human involvement\nin intelligent automated systems and demonstrate its applications on decisions\nregarding AWS. The analysis reveals that human comparative responsibility to\noutcomes is often low, even when major functions are allocated to the human.\nThus, broadly stated policies of keeping humans in the loop and having\nmeaningful human control are misleading and cannot truly direct decisions on\nhow to involve humans in intelligent systems and advanced automation. The\ncurrent model is an initial step in the complex goal to create a comprehensive\nresponsibility model, that will enable quantification of human causal\nresponsibility. It assumes stationarity, full knowledge regarding the\ncharacteristic of the human and automation and ignores temporal aspects.\nDespite these limitations, it can aid in the analysis of systems designs\nalternatives and policy decisions regarding human responsibility in intelligent\nsystems and advanced automation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 10:45:57 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 08:11:48 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 07:18:40 GMT"}, {"version": "v4", "created": "Wed, 29 Apr 2020 15:19:14 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Douer", "Nir", ""], ["Meyer", "Joachim", ""]]}, {"id": "1810.12698", "submitter": "Vaidheeswaran Archana", "authors": "Muru Selvakumar, Suriyadeepan Ramamoorthy, Vaidheeswaran Archana,\n  Malaikannan Sankarasubbu", "title": "Compositional Attention Networks for Interpretability in Natural\n  Language Question Answering", "comments": "8 pages,10 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MAC Net is a compositional attention network designed for Visual Question\nAnswering. We propose a modified MAC net architecture for Natural Language\nQuestion Answering. Question Answering typically requires Language\nUnderstanding and multi-step Reasoning. MAC net's unique architecture - the\nseparation between memory and control, facilitates data-driven iterative\nreasoning. This makes it an ideal candidate for solving tasks that involve\nlogical reasoning. Our experiments with 20 bAbI tasks demonstrate the value of\nMAC net as a data-efficient and interpretable architecture for Natural Language\nQuestion Answering. The transparent nature of MAC net provides a highly\ngranular view of the reasoning steps taken by the network in answering a query.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 12:23:35 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Selvakumar", "Muru", ""], ["Ramamoorthy", "Suriyadeepan", ""], ["Archana", "Vaidheeswaran", ""], ["Sankarasubbu", "Malaikannan", ""]]}, {"id": "1810.12778", "submitter": "Dong Li", "authors": "Dong Li, Dongbin Zhao, Qichao Zhang, Yaran Chen", "title": "Reinforcement Learning and Deep Learning based Lateral Control for\n  Autonomous Driving", "comments": "14 pages, 12 figures, accepted to IEEE Computational Intelligence\n  Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the vision-based autonomous driving with deep\nlearning and reinforcement learning methods. Different from the end-to-end\nlearning method, our method breaks the vision-based lateral control system down\ninto a perception module and a control module. The perception module which is\nbased on a multi-task learning neural network first takes a driver-view image\nas its input and predicts the track features. The control module which is based\non reinforcement learning then makes a control decision based on these\nfeatures. In order to improve the data efficiency, we propose visual TORCS\n(VTORCS), a deep reinforcement learning environment which is based on the open\nracing car simulator (TORCS). By means of the provided functions, one can train\nan agent with the input of an image or various physical sensor measurement, or\nevaluate the perception algorithm on this simulator. The trained reinforcement\nlearning controller outperforms the linear quadratic regulator (LQR) controller\nand model predictive control (MPC) controller on different tracks. The\nexperiments demonstrate that the perception module shows promising performance\nand the controller is capable of controlling the vehicle drive well along the\ntrack center with visual input.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:43:36 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Li", "Dong", ""], ["Zhao", "Dongbin", ""], ["Zhang", "Qichao", ""], ["Chen", "Yaran", ""]]}, {"id": "1810.12780", "submitter": "Di Jin", "authors": "Di Jin, Peter Szolovits", "title": "Advancing PICO Element Detection in Biomedical Text via Deep Neural\n  Networks", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In evidence-based medicine (EBM), defining a clinical question in terms of\nthe specific patient problem aids the physicians to efficiently identify\nappropriate resources and search for the best available evidence for medical\ntreatment. In order to formulate a well-defined, focused clinical question, a\nframework called PICO is widely used, which identifies the sentences in a given\nmedical text that belong to the four components typically reported in clinical\ntrials: Participants/Problem (P), Intervention (I), Comparison (C) and Outcome\n(O). In this work, we propose a novel deep learning model for recognizing PICO\nelements in biomedical abstracts. Based on the previous state-of-the-art\nbidirectional long-short term memory (biLSTM) plus conditional random field\n(CRF) architecture, we add another layer of biLSTM upon the sentence\nrepresentation vectors so that the contextual information from surrounding\nsentences can be gathered to help infer the interpretation of the current one.\nIn addition, we propose two methods to further generalize and improve the\nmodel: adversarial training and unsupervised pre-training over large corpora.\nWe tested our proposed approach over two benchmark datasets. One is the\nPubMed-PICO dataset, where our best results outperform the previous best by\n5.5%, 7.9%, and 5.8% for P, I, and O elements in terms of F1 score,\nrespectively. And for the other dataset named NICTA-PIBOSO, the improvements\nfor P/I/O elements are 2.4%, 13.6%, and 1.0% in F1 score, respectively.\nOverall, our proposed deep learning model can obtain unprecedented PICO element\ndetection accuracy while avoiding the need for any manual feature selection.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:44:24 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 02:38:02 GMT"}, {"version": "v3", "created": "Sat, 5 Oct 2019 17:26:41 GMT"}, {"version": "v4", "created": "Sun, 10 Nov 2019 07:57:16 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Jin", "Di", ""], ["Szolovits", "Peter", ""]]}, {"id": "1810.12847", "submitter": "Bettina Berendt", "authors": "Bettina Berendt", "title": "AI for the Common Good?! Pitfalls, challenges, and Ethics Pen-Testing", "comments": "to appear in Paladyn. Journal of Behavioral Robotics; accepted on\n  27-10-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, many AI researchers and practitioners have embarked on research\nvisions that involve doing AI for \"Good\". This is part of a general drive\ntowards infusing AI research and practice with ethical thinking. One frequent\ntheme in current ethical guidelines is the requirement that AI be good for all,\nor: contribute to the Common Good. But what is the Common Good, and is it\nenough to want to be good? Via four lead questions, I will illustrate\nchallenges and pitfalls when determining, from an AI point of view, what the\nCommon Good is and how it can be enhanced by AI. The questions are: What is the\nproblem / What is a problem?, Who defines the problem?, What is the role of\nknowledge?, and What are important side effects and dynamics? The illustration\nwill use an example from the domain of \"AI for Social Good\", more specifically\n\"Data Science for Social Good\". Even if the importance of these questions may\nbe known at an abstract level, they do not get asked sufficiently in practice,\nas shown by an exploratory study of 99 contributions to recent conferences in\nthe field. Turning these challenges and pitfalls into a positive\nrecommendation, as a conclusion I will draw on another characteristic of\ncomputer-science thinking and practice to make these impediments visible and\nattenuate them: \"attacks\" as a method for improving design. This results in the\nproposal of ethics pen-testing as a method for helping AI designs to better\ncontribute to the Common Good.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 16:41:22 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 12:34:32 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Berendt", "Bettina", ""]]}, {"id": "1810.12850", "submitter": "Robson Bonidia", "authors": "Robson P. Bonidia, Luiz A. L. Rodrigues, Anderson P. Avila-Santos,\n  Danilo S. Sanches, and Jacques D. Brancher", "title": "Computational Intelligence in Sports: A Systematic Literature Review", "comments": null, "journal-ref": "Advances in Human-Computer Interaction\n  (https://www.hindawi.com/journals/ahci/2018/3426178/)", "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, data mining studies are being successfully conducted to estimate\nseveral parameters in a variety of domains. Data mining techniques have\nattracted the attention of the information industry and society as a whole, due\nto a large amount of data and the imminent need to turn it into useful\nknowledge. However, the effective use of data in some areas is still under\ndevelopment, as is the case in sports, which in recent years, has presented a\nslight growth; consequently, many sports organizations have begun to see that\nthere is a wealth of unexplored knowledge in the data extracted by them.\nTherefore, this article presents a systematic review of sports data mining.\nRegarding years 2010 to 2018, 31 types of research were found in this topic.\nBased on these studies, we present the current panorama, themes, the database\nused, proposals, algorithms, and research opportunities. Our findings provide a\nbetter understanding of the sports data mining potentials, besides motivating\nthe scientific community to explore this timely and interesting topic.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 16:46:08 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Bonidia", "Robson P.", ""], ["Rodrigues", "Luiz A. L.", ""], ["Avila-Santos", "Anderson P.", ""], ["Sanches", "Danilo S.", ""], ["Brancher", "Jacques D.", ""]]}, {"id": "1810.12894", "submitter": "Yuri Burda", "authors": "Yuri Burda, Harrison Edwards, Amos Storkey, Oleg Klimov", "title": "Exploration by Random Network Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an exploration bonus for deep reinforcement learning methods\nthat is easy to implement and adds minimal overhead to the computation\nperformed. The bonus is the error of a neural network predicting features of\nthe observations given by a fixed randomly initialized neural network. We also\nintroduce a method to flexibly combine intrinsic and extrinsic rewards. We find\nthat the random network distillation (RND) bonus combined with this increased\nflexibility enables significant progress on several hard exploration Atari\ngames. In particular we establish state of the art performance on Montezuma's\nRevenge, a game famously difficult for deep reinforcement learning methods. To\nthe best of our knowledge, this is the first method that achieves better than\naverage human performance on this game without using demonstrations or having\naccess to the underlying state of the game, and occasionally completes the\nfirst level.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 17:44:42 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Burda", "Yuri", ""], ["Edwards", "Harrison", ""], ["Storkey", "Amos", ""], ["Klimov", "Oleg", ""]]}, {"id": "1810.12936", "submitter": "Kai Hui", "authors": "Canjia Li, Yingfei Sun, Ben He, Le Wang, Kai Hui, Andrew Yates, Le\n  Sun, Jungang Xu", "title": "NPRF: A Neural Pseudo Relevance Feedback Framework for Ad-hoc\n  Information Retrieval", "comments": "Full paper in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pseudo-relevance feedback (PRF) is commonly used to boost the performance of\ntraditional information retrieval (IR) models by using top-ranked documents to\nidentify and weight new query terms, thereby reducing the effect of\nquery-document vocabulary mismatches. While neural retrieval models have\nrecently demonstrated strong results for ad-hoc retrieval, combining them with\nPRF is not straightforward due to incompatibilities between existing PRF\napproaches and neural architectures. To bridge this gap, we propose an\nend-to-end neural PRF framework that can be used with existing neural IR models\nby embedding different neural models as building blocks. Extensive experiments\non two standard test collections confirm the effectiveness of the proposed NPRF\nframework in improving the performance of two state-of-the-art neural IR\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 18:03:12 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Li", "Canjia", ""], ["Sun", "Yingfei", ""], ["He", "Ben", ""], ["Wang", "Le", ""], ["Hui", "Kai", ""], ["Yates", "Andrew", ""], ["Sun", "Le", ""], ["Xu", "Jungang", ""]]}, {"id": "1810.12997", "submitter": "Andreas B\\\"armann", "authors": "Andreas B\\\"armann and Alexander Martin and Sebastian Pokutta and Oskar\n  Schneider", "title": "An Online-Learning Approach to Inverse Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate how to learn the objective function of a\ndecision-maker while only observing the problem input data and the\ndecision-maker's corresponding decisions over multiple rounds. We present exact\nalgorithms for this online version of inverse optimization which converge at a\nrate of $ \\mathcal{O}(1/\\sqrt{T}) $ in the number of observations~$T$ and\ncompare their further properties. Especially, they all allow taking decisions\nwhich are essentially as good as those of the observed decision-maker already\nafter relatively few iterations, but are suited best for different settings\neach. Our approach is based on online learning and works for linear objectives\nover arbitrary feasible sets for which we have a linear optimization oracle. As\nsuch, it generalizes previous approaches based on KKT-system decomposition and\ndualization. We also introduce several generalizations, such as the approximate\nlearning of non-linear objective functions, dynamically changing as well as\nparameterized objectives and the case of suboptimal observed decisions. When\napplied to the stochastic offline case, our algorithms are able to give\nguarantees on the quality of the learned objectives in expectation. Finally, we\nshow the effectiveness and possible applications of our methods in indicative\ncomputational experiments.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 20:43:04 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 02:08:41 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["B\u00e4rmann", "Andreas", ""], ["Martin", "Alexander", ""], ["Pokutta", "Sebastian", ""], ["Schneider", "Oskar", ""]]}, {"id": "1810.13072", "submitter": "Xiaowu Sun", "authors": "Xiaowu Sun, Haitham Khedr, Yasser Shoukry", "title": "Formal Verification of Neural Network Controlled Autonomous Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of formally verifying the safety of an\nautonomous robot equipped with a Neural Network (NN) controller that processes\nLiDAR images to produce control actions. Given a workspace that is\ncharacterized by a set of polytopic obstacles, our objective is to compute the\nset of safe initial conditions such that a robot trajectory starting from these\ninitial conditions is guaranteed to avoid the obstacles. Our approach is to\nconstruct a finite state abstraction of the system and use standard\nreachability analysis over the finite state abstraction to compute the set of\nthe safe initial states. The first technical problem in computing the finite\nstate abstraction is to mathematically model the imaging function that maps the\nrobot position to the LiDAR image. To that end, we introduce the notion of\nimaging-adapted sets as partitions of the workspace in which the imaging\nfunction is guaranteed to be affine. We develop a polynomial-time algorithm to\npartition the workspace into imaging-adapted sets along with computing the\ncorresponding affine imaging functions. Given this workspace partitioning, a\ndiscrete-time linear dynamics of the robot, and a pre-trained NN controller\nwith Rectified Linear Unit (ReLU) nonlinearity, the second technical challenge\nis to analyze the behavior of the neural network. To that end, we utilize a\nSatisfiability Modulo Convex (SMC) encoding to enumerate all the possible\nsegments of different ReLUs. SMC solvers then use a Boolean satisfiability\nsolver and a convex programming solver and decompose the problem into smaller\nsubproblems. To accelerate this process, we develop a pre-processing algorithm\nthat could rapidly prune the space feasible ReLU segments. Finally, we\ndemonstrate the efficiency of the proposed algorithms using numerical\nsimulations with increasing complexity of the neural network controller.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 02:10:14 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Sun", "Xiaowu", ""], ["Khedr", "Haitham", ""], ["Shoukry", "Yasser", ""]]}, {"id": "1810.13075", "submitter": "Xiaowei Jia", "authors": "Xiaowei Jia, Jared Willard, Anuj Karpatne, Jordan Read, Jacob Zwart,\n  Michael Steinbach, Vipin Kumar", "title": "Physics Guided RNNs for Modeling Dynamical Systems: A Case Study in\n  Simulating Lake Temperature Profiles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a physics-guided recurrent neural network model (PGRNN)\nthat combines RNNs and physics-based models to leverage their complementary\nstrengths and improve the modeling of physical processes. Specifically, we show\nthat a PGRNN can improve prediction accuracy over that of physical models,\nwhile generating outputs consistent with physical laws, and achieving good\ngeneralizability. Standard RNNs, even when producing superior prediction\naccuracy, often produce physically inconsistent results and lack\ngeneralizability. We further enhance this approach by using a pre-training\nmethod that leverages the simulated data from a physics-based model to address\nthe scarcity of observed data. The PGRNN has the flexibility to incorporate\nadditional physical constraints and we incorporate a density-depth\nrelationship. Both enhancements further improve PGRNN performance. Although we\npresent and evaluate this methodology in the context of modeling the dynamics\nof temperature in lakes, it is applicable more widely to a range of scientific\nand engineering disciplines where mechanistic (also known as process-based)\nmodels are used, e.g., power engineering, climate science, materials science,\ncomputational chemistry, and biomedicine.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 02:21:19 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2019 00:11:32 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Jia", "Xiaowei", ""], ["Willard", "Jared", ""], ["Karpatne", "Anuj", ""], ["Read", "Jordan", ""], ["Zwart", "Jacob", ""], ["Steinbach", "Michael", ""], ["Kumar", "Vipin", ""]]}, {"id": "1810.13135", "submitter": "Naima Chouikhi", "authors": "Naima Chouikhi and Adel M. Alimi", "title": "Adaptive Extreme Learning Machine for Recurrent Beta-basis Function\n  Neural Network Training", "comments": "14 pages and 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beta Basis Function Neural Network (BBFNN) is a special kind of kernel basis\nneural networks. It is a feedforward network typified by the use of beta\nfunction as a hidden activation function. Beta is a flexible transfer function\nrepresenting richer forms than the common existing functions. As in every\nnetwork, the architecture setting as well as the learning method are two main\ngauntlets faced by BBFNN. In this paper, new architecture and training\nalgorithm are proposed for the BBFNN. An Extreme Learning Machine (ELM) is used\nas a training approach of BBFNN with the aim of quickening the training\nprocess. The peculiarity of ELM is permitting a certain decrement of the\ncomputing time and complexity regarding the already used BBFNN learning\nalgorithms such as backpropagation, OLS, etc. For the architectural design, a\nrecurrent structure is added to the common BBFNN architecture in order to make\nit more able to deal with complex, non linear and time varying problems.\nThroughout this paper, the conceived recurrent ELM-trained BBFNN is tested on a\nnumber of tasks related to time series prediction, classification and\nregression. Experimental results show noticeable achievements of the proposed\nnetwork compared to common feedforward and recurrent networks trained by ELM\nand using hyperbolic tangent as activation function. These achievements are in\nterms of accuracy and robustness against data breakdowns such as noise signals.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 07:31:08 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Chouikhi", "Naima", ""], ["Alimi", "Adel M.", ""]]}, {"id": "1810.13141", "submitter": "Sebastien Henry", "authors": "Thierno Diallo (Quartz), S\\'ebastien Henry (DISP), Yacine Ouzrout\n  (DISP)", "title": "Towards a more efficient use of process and product traceability data\n  for continuous improvement of industrial performances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays all industrial sectors are increasingly faced with the explosion in\nthe amount of data. Therefore, it raises the question of the efficient use of\nthis large amount of data. In this research work, we are concerned with process\nand product traceability data. In some sectors (e.g. pharmaceutical and\nagro-food), the collection and storage of these data are required. Beyond this\nconstraint (regulatory and / or contractual), we are interested in the use of\nthese data for continuous improvements of industrial performances. Two research\naxes were identified: product recall and responsiveness towards production\nhazards. For the first axis, a procedure for product recall exploiting\ntraceability data will be propose. The development of detection and prognosis\nfunctions combining process and product data is envisaged for the second axis.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 07:59:07 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Diallo", "Thierno", "", "Quartz"], ["Henry", "S\u00e9bastien", "", "DISP"], ["Ouzrout", "Yacine", "", "DISP"]]}, {"id": "1810.13166", "submitter": "Natalia D\\'iaz-Rodr\\'iguez", "authors": "Natalia D\\'iaz-Rodr\\'iguez and Vincenzo Lomonaco and David Filliat and\n  Davide Maltoni", "title": "Don't forget, there is more than forgetting: new metrics for Continual\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning consists of algorithms that learn from a stream of\ndata/tasks continuously and adaptively thought time, enabling the incremental\ndevelopment of ever more complex knowledge and skills. The lack of consensus in\nevaluating continual learning algorithms and the almost exclusive focus on\nforgetting motivate us to propose a more comprehensive set of implementation\nindependent metrics accounting for several factors we believe have practical\nimplications worth considering in the deployment of real AI systems that learn\ncontinually: accuracy or performance over time, backward and forward knowledge\ntransfer, memory overhead as well as computational efficiency. Drawing\ninspiration from the standard Multi-Attribute Value Theory (MAVT) we further\npropose to fuse these metrics into a single score for ranking purposes and we\nevaluate our proposal with five continual learning strategies on the iCIFAR-100\ncontinual learning benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 09:15:02 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["D\u00edaz-Rodr\u00edguez", "Natalia", ""], ["Lomonaco", "Vincenzo", ""], ["Filliat", "David", ""], ["Maltoni", "Davide", ""]]}, {"id": "1810.13191", "submitter": "Yacine Ouzrout", "authors": "Laurent Buzon (LIESP), Abdelaziz Bouras (LIESP), Yacine Ouzrout\n  (LIESP)", "title": "Infrastructure for the representation and electronic exchange of design\n  knowledge", "comments": null, "journal-ref": "IJEBM, 2003, 1 (1), pp.1-8", "doi": null, "report-no": "Lyon 2", "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops the concept of knowledge and its exchange using Semantic\nWeb technologies. It points out that knowledge is more than information because\nit embodies the meaning, that is to say semantic and context. These\ncharacteristics will influence our approach to represent and to treat the\nknowledge. In order to be adopted, the developed system needs to be simple and\nto use standards. The goal of the paper is to find standards to model knowledge\nand exchange it with an other person. Therefore, we propose to model knowledge\nusing UML models to show a graphical representation and to exchange it with XML\nto ensure the portability at low cost. We introduce the concept of ontology for\norganizing knowledge and for facilitating the knowledge exchange. Proposals\nhave been tested by implementing an application on the design knowledge of a\npen.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 10:07:47 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Buzon", "Laurent", "", "LIESP"], ["Bouras", "Abdelaziz", "", "LIESP"], ["Ouzrout", "Yacine", "", "LIESP"]]}, {"id": "1810.13192", "submitter": "Qiang Hu", "authors": "Qiang Hu and Hao Zhang", "title": "Nearly-tight bounds on linear regions of piecewise linear neural\n  networks", "comments": "Counting linear regions of neural networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The developments of deep neural networks (DNN) in recent years have ushered a\nbrand new era of artificial intelligence. DNNs are proved to be excellent in\nsolving very complex problems, e.g., visual recognition and text understanding,\nto the extent of competing with or even surpassing people. Despite inspiring\nand encouraging success of DNNs, thorough theoretical analyses still lack to\nunravel the mystery of their magics. The design of DNN structure is dominated\nby empirical results in terms of network depth, number of neurons and\nactivations. A few of remarkable works published recently in an attempt to\ninterpret DNNs have established the first glimpses of their internal\nmechanisms. Nevertheless, research on exploring how DNNs operate is still at\nthe initial stage with plenty of room for refinement. In this paper, we extend\nprecedent research on neural networks with piecewise linear activations (PLNN)\nconcerning linear regions bounds. We present (i) the exact maximal number of\nlinear regions for single layer PLNNs; (ii) a upper bound for multi-layer\nPLNNs; and (iii) a tighter upper bound for the maximal number of liner regions\non rectifier networks. The derived bounds also indirectly explain why deep\nmodels are more powerful than shallow counterparts, and how non-linearity of\nactivation functions impacts on expressiveness of networks.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 10:08:40 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 12:25:27 GMT"}, {"version": "v3", "created": "Wed, 12 Dec 2018 12:25:51 GMT"}, {"version": "v4", "created": "Wed, 26 Dec 2018 14:55:57 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Hu", "Qiang", ""], ["Zhang", "Hao", ""]]}, {"id": "1810.13197", "submitter": "Valentin Vielzeuf", "authors": "Valentin Vielzeuf, Corentin Kervadec, St\\'ephane Pateux, Fr\\'ed\\'eric\n  Jurie", "title": "The Many Moods of Emotion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to the facial expression generation\nproblem. Building upon the assumption of the psychological community that\nemotion is intrinsically continuous, we first design our own continuous emotion\nrepresentation with a 3-dimensional latent space issued from a neural network\ntrained on discrete emotion classification. The so-obtained representation can\nbe used to annotate large in the wild datasets and later used to trained a\nGenerative Adversarial Network. We first show that our model is able to map\nback to discrete emotion classes with a objectively and subjectively better\nquality of the images than usual discrete approaches. But also that we are able\nto pave the larger space of possible facial expressions, generating the many\nmoods of emotion. Moreover, two axis in this space may be found to generate\nsimilar expression changes as in traditional continuous representations such as\narousal-valence. Finally we show from visual interpretation, that the third\nremaining dimension is highly related to the well-known dominance dimension\nfrom psychology.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 10:24:08 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Vielzeuf", "Valentin", ""], ["Kervadec", "Corentin", ""], ["Pateux", "St\u00e9phane", ""], ["Jurie", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1810.13292", "submitter": "Duc Tam Nguyen", "authors": "Duc Tam Nguyen, Zhongyu Lou, Michael Klar, Thomas Brox", "title": "Anomaly Detection With Multiple-Hypotheses Predictions", "comments": "In proceedings of the 36th International Conference on Machine\n  Learning (ICML), Long Beach, California, PMLR 97, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In one-class-learning tasks, only the normal case (foreground) can be modeled\nwith data, whereas the variation of all possible anomalies is too erratic to be\ndescribed by samples. Thus, due to the lack of representative data, the\nwide-spread discriminative approaches cannot cover such learning tasks, and\nrather generative models, which attempt to learn the input density of the\nforeground, are used. However, generative models suffer from a large input\ndimensionality (as in images) and are typically inefficient learners. We\npropose to learn the data distribution of the foreground more efficiently with\na multi-hypotheses autoencoder. Moreover, the model is criticized by a\ndiscriminator, which prevents artificial data modes not supported by data, and\nenforces diversity across hypotheses. Our multiple-hypothesesbased anomaly\ndetection framework allows the reliable identification of out-of-distribution\nsamples. For anomaly detection on CIFAR-10, it yields up to 3.9% points\nimprovement over previously reported results. On a real anomaly detection task,\nthe approach reduces the error of the baseline models from 6.8% to 1.5%.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 14:05:44 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 12:36:22 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 06:13:45 GMT"}, {"version": "v4", "created": "Mon, 28 Jan 2019 15:05:09 GMT"}, {"version": "v5", "created": "Fri, 31 May 2019 12:25:42 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Nguyen", "Duc Tam", ""], ["Lou", "Zhongyu", ""], ["Klar", "Michael", ""], ["Brox", "Thomas", ""]]}, {"id": "1810.13306", "submitter": "Quanming Yao", "authors": "Quanming Yao, Mengshuo Wang, Yuqiang Chen, Wenyuan Dai, Yu-Feng Li,\n  Wei-Wei Tu, Qiang Yang, Yang Yu", "title": "Taking Human out of Learning Applications: A Survey on Automated Machine\n  Learning", "comments": "This is a preliminary and will be kept updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques have deeply rooted in our everyday life. However,\nsince it is knowledge- and labor-intensive to pursue good learning performance,\nhuman experts are heavily involved in every aspect of machine learning. In\norder to make machine learning techniques easier to apply and reduce the demand\nfor experienced human experts, automated machine learning (AutoML) has emerged\nas a hot topic with both industrial and academic interest. In this paper, we\nprovide an up to date survey on AutoML. First, we introduce and define the\nAutoML problem, with inspiration from both realms of automation and machine\nlearning. Then, we propose a general AutoML framework that not only covers most\nexisting approaches to date but also can guide the design for new methods.\nSubsequently, we categorize and review the existing works from two aspects,\ni.e., the problem setup and the employed techniques. Finally, we provide a\ndetailed analysis of AutoML approaches and explain the reasons underneath their\nsuccessful applications. We hope this survey can serve as not only an\ninsightful guideline for AutoML beginners but also an inspiration for future\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 14:35:38 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 11:29:43 GMT"}, {"version": "v3", "created": "Thu, 17 Jan 2019 10:47:18 GMT"}, {"version": "v4", "created": "Mon, 16 Dec 2019 05:36:13 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Yao", "Quanming", ""], ["Wang", "Mengshuo", ""], ["Chen", "Yuqiang", ""], ["Dai", "Wenyuan", ""], ["Li", "Yu-Feng", ""], ["Tu", "Wei-Wei", ""], ["Yang", "Qiang", ""], ["Yu", "Yang", ""]]}, {"id": "1810.13314", "submitter": "Naman Goel", "authors": "Naman Goel and Boi Faltings", "title": "Crowdsourcing with Fairness, Diversity and Budget Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that the labels collected from crowdworkers can be\ndiscriminatory with respect to sensitive attributes such as gender and race.\nThis raises questions about the suitability of using crowdsourced data for\nfurther use, such as for training machine learning algorithms. In this work, we\naddress the problem of fair and diverse data collection from a crowd under\nbudget constraints. We propose a novel algorithm which maximizes the expected\naccuracy of the collected data, while ensuring that the errors satisfy desired\nnotions of fairness. We provide guarantees on the performance of our algorithm\nand show that the algorithm performs well in practice through experiments on a\nreal dataset.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 14:46:17 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 13:29:53 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Goel", "Naman", ""], ["Faltings", "Boi", ""]]}, {"id": "1810.13329", "submitter": "Doyun Kim", "authors": "Doyun Kim, Han Young Yim, Sanghyuck Ha, Changgwun Lee, and Inyup Kang", "title": "Convolutional Neural Network Quantization using Generalized Gamma\n  Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As edge applications using convolutional neural networks (CNN) models grow,\nit is becoming necessary to introduce dedicated hardware accelerators in which\nnetwork parameters and feature-map data are represented with limited precision.\nIn this paper we propose a novel quantization algorithm for energy-efficient\ndeployment of the hardware accelerators. For weights and biases, the optimal\nbit length of the fractional part is determined so that the quantization error\nis minimized over their distribution. For feature-map data, meanwhile, their\nsample distribution is well approximated with the generalized gamma\ndistribution (GGD), and accordingly the optimal quantization step size can be\nobtained through the asymptotical closed form solution of GGD. The proposed\nquantization algorithm has a higher signal-to-quantization-noise ratio (SQNR)\nthan other quantization schemes previously proposed for CNNs, and even can be\nmore improved by tuning the quantization parameters, resulting in efficient\nimplementation of the hardware accelerators for CNNs in terms of power\nconsumption and memory bandwidth.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 15:17:05 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Kim", "Doyun", ""], ["Yim", "Han Young", ""], ["Ha", "Sanghyuck", ""], ["Lee", "Changgwun", ""], ["Kang", "Inyup", ""]]}, {"id": "1810.13338", "submitter": "Antoine Deleforge", "authors": "Helena Peic Tukuljac (EPFL), Antoine Deleforge (MULTISPEECH), R\\'emi\n  Gribonval (PANAMA)", "title": "MULAN: A Blind and Off-Grid Method for Multichannel Echo Retrieval", "comments": null, "journal-ref": "Thirty-second Conference on Neural Information Processing Systems\n  (NIPS 2018), Dec 2018, Montr{\\'e}al, Canada", "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the general problem of blind echo retrieval, i.e., given\nM sensors measuring in the discrete-time domain M mixtures of K delayed and\nattenuated copies of an unknown source signal, can the echo locations and\nweights be recovered? This problem has broad applications in fields such as\nsonars, seismol-ogy, ultrasounds or room acoustics. It belongs to the broader\nclass of blind channel identification problems, which have been intensively\nstudied in signal processing. Existing methods in the literature proceed in two\nsteps: (i) blind estimation of sparse discrete-time filters and (ii) echo\ninformation retrieval by peak-picking on filters. The precision of these\nmethods is fundamentally limited by the rate at which the signals are sampled:\nestimated echo locations are necessary on-grid, and since true locations never\nmatch the sampling grid, the weight estimation precision is impacted. This is\nthe so-called basis-mismatch problem in compressed sensing. We propose a\nradically different approach to the problem, building on the framework of\nfinite-rate-of-innovation sampling. The approach operates directly in the\nparameter-space of echo locations and weights, and enables near-exact blind and\noff-grid echo retrieval from discrete-time measurements. It is shown to\noutperform conventional methods by several orders of magnitude in precision.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 15:30:00 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Tukuljac", "Helena Peic", "", "EPFL"], ["Deleforge", "Antoine", "", "MULTISPEECH"], ["Gribonval", "R\u00e9mi", "", "PANAMA"]]}, {"id": "1810.13354", "submitter": "Ronen Brafman", "authors": "Amos Beimel and Ronen I. Brafman", "title": "Privacy Preserving Multi-Agent Planning with Provable Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In privacy-preserving multi-agent planning, a group of agents attempt to\ncooperatively solve a multi-agent planning problem while maintaining private\ntheir data and actions. Although much work was carried out in this area in past\nyears, its theoretical foundations have not been fully worked out.\nSpecifically, although algorithms with precise privacy guarantees exist, even\ntheir most efficient implementations are not fast enough on realistic\ninstances, whereas for practical algorithms no meaningful privacy guarantees\nexist. Secure-MAFS, a variant of the multi-agent forward search algorithm\n(MAFS) is the only practical algorithm to attempt to offer more precise\nguarantees, but only in very limited settings and with proof sketches only. In\nthis paper we formulate a precise notion of secure computation for search-based\nalgorithms and prove that Secure MAFS has this property in all domains.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 15:47:12 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 10:24:06 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Beimel", "Amos", ""], ["Brafman", "Ronen I.", ""]]}, {"id": "1810.13373", "submitter": "David Barrett", "authors": "David G.T. Barrett, Ari S. Morcos and Jakob H. Macke", "title": "Analyzing biological and artificial neural networks: challenges with\n  opportunities for synergy?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) transform stimuli across multiple processing\nstages to produce representations that can be used to solve complex tasks, such\nas object recognition in images. However, a full understanding of how they\nachieve this remains elusive. The complexity of biological neural networks\nsubstantially exceeds the complexity of DNNs, making it even more challenging\nto understand the representations that they learn. Thus, both machine learning\nand computational neuroscience are faced with a shared challenge: how can we\nanalyze their representations in order to understand how they solve complex\ntasks?\n  We review how data-analysis concepts and techniques developed by\ncomputational neuroscientists can be useful for analyzing representations in\nDNNs, and in turn, how recently developed techniques for analysis of DNNs can\nbe useful for understanding representations in biological neural networks. We\nexplore opportunities for synergy between the two fields, such as the use of\nDNNs as in-silico model systems for neuroscience, and how this synergy can lead\nto new hypotheses about the operating principles of biological neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 16:09:44 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Barrett", "David G. T.", ""], ["Morcos", "Ari S.", ""], ["Macke", "Jakob H.", ""]]}, {"id": "1810.13400", "submitter": "Brandon Amos", "authors": "Brandon Amos, Ivan Dario Jimenez Rodriguez, Jacob Sacks, Byron Boots,\n  J. Zico Kolter", "title": "Differentiable MPC for End-to-end Planning and Control", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present foundations for using Model Predictive Control (MPC) as a\ndifferentiable policy class for reinforcement learning in continuous state and\naction spaces. This provides one way of leveraging and combining the advantages\nof model-free and model-based approaches. Specifically, we differentiate\nthrough MPC by using the KKT conditions of the convex approximation at a fixed\npoint of the controller. Using this strategy, we are able to learn the cost and\ndynamics of a controller via end-to-end learning. Our experiments focus on\nimitation learning in the pendulum and cartpole domains, where we learn the\ncost and dynamics terms of an MPC policy class. We show that our MPC policies\nare significantly more data-efficient than a generic neural network and that\nour method is superior to traditional system identification in a setting where\nthe expert is unrealizable.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 16:46:38 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 18:58:30 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 17:49:37 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Amos", "Brandon", ""], ["Rodriguez", "Ivan Dario Jimenez", ""], ["Sacks", "Jacob", ""], ["Boots", "Byron", ""], ["Kolter", "J. Zico", ""]]}]