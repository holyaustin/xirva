[{"id": "1709.00023", "submitter": "Mo Yu", "authors": "Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei\n  Zhang, Shiyu Chang, Gerald Tesauro, Bowen Zhou, Jing Jiang", "title": "R$^3$: Reinforced Reader-Ranker for Open-Domain Question Answering", "comments": "8 pages, accepted by AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years researchers have achieved considerable success applying\nneural network methods to question answering (QA). These approaches have\nachieved state of the art results in simplified closed-domain settings such as\nthe SQuAD (Rajpurkar et al., 2016) dataset, which provides a pre-selected\npassage, from which the answer to a given question may be extracted. More\nrecently, researchers have begun to tackle open-domain QA, in which the model\nis given a question and access to a large corpus (e.g., wikipedia) instead of a\npre-selected passage (Chen et al., 2017a). This setting is more complex as it\nrequires large-scale search for relevant passages by an information retrieval\ncomponent, combined with a reading comprehension model that \"reads\" the\npassages to generate an answer to the question. Performance in this setting\nlags considerably behind closed-domain performance. In this paper, we present a\nnovel open-domain QA system called Reinforced Ranker-Reader $(R^3)$, based on\ntwo algorithmic innovations. First, we propose a new pipeline for open-domain\nQA with a Ranker component, which learns to rank retrieved passages in terms of\nlikelihood of generating the ground-truth answer to a given question. Second,\nwe propose a novel method that jointly trains the Ranker along with an\nanswer-generation Reader model, based on reinforcement learning. We report\nextensive experimental results showing that our method significantly improves\non the state of the art for multiple open-domain QA datasets.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 18:08:35 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 16:38:30 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Wang", "Shuohang", ""], ["Yu", "Mo", ""], ["Guo", "Xiaoxiao", ""], ["Wang", "Zhiguo", ""], ["Klinger", "Tim", ""], ["Zhang", "Wei", ""], ["Chang", "Shiyu", ""], ["Tesauro", "Gerald", ""], ["Zhou", "Bowen", ""], ["Jiang", "Jing", ""]]}, {"id": "1709.00084", "submitter": "Michele Colledanchise", "authors": "Michele Colledanchise and Petter \\\"Ogren", "title": "Behavior Trees in Robotics and AI: An Introduction", "comments": null, "journal-ref": "Chapman & Hall/CRC Artificial Intelligence and Robotics Series\n  2018", "doi": "10.1201/9780429489105", "report-no": "ISBN 9781138593732", "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Behavior Tree (BT) is a way to structure the switching between different\ntasks in an autonomous agent, such as a robot or a virtual entity in a computer\ngame. BTs are a very efficient way of creating complex systems that are both\nmodular and reactive. These properties are crucial in many applications, which\nhas led to the spread of BT from computer game programming to many branches of\nAI and Robotics. In this book, we will first give an introduction to BTs, then\nwe describe how BTs relate to, and in many cases generalize, earlier switching\nstructures. These ideas are then used as a foundation for a set of efficient\nand easy to use design principles. Properties such as safety, robustness, and\nefficiency are important for an autonomous system, and we describe a set of\ntools for formally analyzing these using a state space description of BTs. With\nthe new analysis tools, we can formalize the descriptions of how BTs generalize\nearlier approaches. We also show the use of BTs in automated planning and\nmachine learning. Finally, we describe an extended set of tools to capture the\nbehavior of Stochastic BTs, where the outcomes of actions are described by\nprobabilities. These tools enable the computation of both success probabilities\nand time to completion.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 21:05:18 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 07:33:32 GMT"}, {"version": "v3", "created": "Mon, 15 Jan 2018 17:41:24 GMT"}, {"version": "v4", "created": "Wed, 3 Jun 2020 16:25:31 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Colledanchise", "Michele", ""], ["\u00d6gren", "Petter", ""]]}, {"id": "1709.00103", "submitter": "Victor Zhong", "authors": "Victor Zhong, Caiming Xiong, and Richard Socher", "title": "Seq2SQL: Generating Structured Queries from Natural Language using\n  Reinforcement Learning", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant amount of the world's knowledge is stored in relational\ndatabases. However, the ability for users to retrieve facts from a database is\nlimited due to a lack of understanding of query languages such as SQL. We\npropose Seq2SQL, a deep neural network for translating natural language\nquestions to corresponding SQL queries. Our model leverages the structure of\nSQL queries to significantly reduce the output space of generated queries.\nMoreover, we use rewards from in-the-loop query execution over the database to\nlearn a policy to generate unordered parts of the query, which we show are less\nsuitable for optimization via cross entropy loss. In addition, we will publish\nWikiSQL, a dataset of 80654 hand-annotated examples of questions and SQL\nqueries distributed across 24241 tables from Wikipedia. This dataset is\nrequired to train our model and is an order of magnitude larger than comparable\ndatasets. By applying policy-based reinforcement learning with a query\nexecution environment to WikiSQL, our model Seq2SQL outperforms attentional\nsequence to sequence models, improving execution accuracy from 35.9% to 59.4%\nand logical form accuracy from 23.4% to 48.3%.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 23:12:15 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 19:14:04 GMT"}, {"version": "v3", "created": "Wed, 18 Oct 2017 01:34:46 GMT"}, {"version": "v4", "created": "Thu, 26 Oct 2017 21:13:56 GMT"}, {"version": "v5", "created": "Tue, 31 Oct 2017 20:49:31 GMT"}, {"version": "v6", "created": "Tue, 7 Nov 2017 16:53:10 GMT"}, {"version": "v7", "created": "Thu, 9 Nov 2017 23:06:14 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Zhong", "Victor", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1709.00149", "submitter": "Clayton Morrison", "authors": "Enrique Noriega-Atala, Marco A. Valenzuela-Escarcega, Clayton T.\n  Morrison, Mihai Surdeanu", "title": "Learning what to read: Focused machine reading", "comments": "6 pages, 1 figure, 1 algorithm, 2 tables, accepted to EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts in bioinformatics have achieved tremendous progress in the\nmachine reading of biomedical literature, and the assembly of the extracted\nbiochemical interactions into large-scale models such as protein signaling\npathways. However, batch machine reading of literature at today's scale (PubMed\nalone indexes over 1 million papers per year) is unfeasible due to both cost\nand processing overhead. In this work, we introduce a focused reading approach\nto guide the machine reading of biomedical literature towards what literature\nshould be read to answer a biomedical query as efficiently as possible. We\nintroduce a family of algorithms for focused reading, including an intuitive,\nstrong baseline, and a second approach which uses a reinforcement learning (RL)\nframework that learns when to explore (widen the search) or exploit (narrow\nit). We demonstrate that the RL approach is capable of answering more queries\nthan the baseline, while being more efficient, i.e., reading fewer documents.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 04:09:42 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Noriega-Atala", "Enrique", ""], ["Valenzuela-Escarcega", "Marco A.", ""], ["Morrison", "Clayton T.", ""], ["Surdeanu", "Mihai", ""]]}, {"id": "1709.00155", "submitter": "Lei Sha", "authors": "Lei Sha, Lili Mou, Tianyu Liu, Pascal Poupart, Sujian Li, Baobao\n  Chang, Zhifang Sui", "title": "Order-Planning Neural Text Generation From Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating texts from structured data (e.g., a table) is important for\nvarious natural language processing tasks such as question answering and dialog\nsystems. In recent studies, researchers use neural language models and\nencoder-decoder frameworks for table-to-text generation. However, these neural\nnetwork-based approaches do not model the order of contents during text\ngeneration. When a human writes a summary based on a given table, he or she\nwould probably consider the content order before wording. In a biography, for\nexample, the nationality of a person is typically mentioned before occupation\nin a biography. In this paper, we propose an order-planning text generation\nmodel to capture the relationship between different fields and use such\nrelationship to make the generated text more fluent and smooth. We conducted\nexperiments on the WikiBio dataset and achieve significantly higher performance\nthan previous methods in terms of BLEU, ROUGE, and NIST scores.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 04:46:10 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Sha", "Lei", ""], ["Mou", "Lili", ""], ["Liu", "Tianyu", ""], ["Poupart", "Pascal", ""], ["Li", "Sujian", ""], ["Chang", "Baobao", ""], ["Sui", "Zhifang", ""]]}, {"id": "1709.00322", "submitter": "Kenta Cho", "authors": "Kenta Cho and Bart Jacobs", "title": "Disintegration and Bayesian Inversion via String Diagrams", "comments": "Accepted for publication in Mathematical Structures in Computer\n  Science", "journal-ref": "Math. Struct. Comp. Sci. 29 (2019) 938-971", "doi": "10.1017/S0960129518000488", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notions of disintegration and Bayesian inversion are fundamental in\nconditional probability theory. They produce channels, as conditional\nprobabilities, from a joint state, or from an already given channel (in\nopposite direction). These notions exist in the literature, in concrete\nsituations, but are presented here in abstract graphical formulations. The\nresulting abstract descriptions are used for proving basic results in\nconditional probability theory. The existence of disintegration and Bayesian\ninversion is discussed for discrete probability, and also for measure-theoretic\nprobability --- via standard Borel spaces and via likelihoods. Finally, the\nusefulness of disintegration and Bayesian inversion is illustrated in several\nexamples.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 13:01:07 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 01:58:30 GMT"}, {"version": "v3", "created": "Fri, 8 Feb 2019 01:45:14 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Cho", "Kenta", ""], ["Jacobs", "Bart", ""]]}, {"id": "1709.00348", "submitter": "Kyumars Sheykh Esmaili", "authors": "Kyumars Sheykh Esmaili, Jaideep Chandrashekar, Pascal Le Guyadec", "title": "Inferring Networked Device Categories from Low-Level Activity Indicators", "comments": "14 pages, 9 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of inferring the type of a networked device in a home\nnetwork by leveraging low level traffic activity indicators seen at commodity\nhome gateways. We analyze a dataset of detailed device network activity\nobtained from 240 subscriber homes of a large European ISP and extract a number\nof traffic and spatial fingerprints for individual devices. We develop a two\nlevel taxonomy to describe devices onto which we map individual devices using a\nnumber of heuristics. We leverage the heuristically derived labels to train\nclassifiers that distinguish device classes based on the traffic and spatial\nfingerprints of a device. Our results show an accuracy level up to 91% for the\ncoarse level category and up to 84% for the fine grained category. By\nincorporating information from other sources (e.g., MAC OUI), we are able to\nfurther improve accuracy to above 97% and 92%, respectively. Finally, we also\nextract a set of simple and human-readable rules that concisely capture the\nbehaviour of these distinct device categories.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 14:47:23 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Esmaili", "Kyumars Sheykh", ""], ["Chandrashekar", "Jaideep", ""], ["Guyadec", "Pascal Le", ""]]}, {"id": "1709.00359", "submitter": "Rasmus Kr{\\ae}mmer Rendsvig", "authors": "Dominik Klein and Rasmus K. Rendsvig", "title": "Convergence, Continuity and Recurrence in Dynamic Epistemic Logic", "comments": "As appearing in \"Logic, Rationality, and Interaction (LORI 2017,\n  Sapporo, Japan)\", LNCS, Springer 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper analyzes dynamic epistemic logic from a topological perspective.\nThe main contribution consists of a framework in which dynamic epistemic logic\nsatisfies the requirements for being a topological dynamical system thus\ninterfacing discrete dynamic logics with continuous mappings of dynamical\nsystems. The setting is based on a notion of logical convergence,\ndemonstratively equivalent with convergence in Stone topology. Presented is a\nflexible, parametrized family of metrics inducing the latter, used as an\nanalytical aid. We show maps induced by action model transformations continuous\nwith respect to the Stone topology and present results on the recurrent\nbehavior of said maps.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 15:08:36 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Klein", "Dominik", ""], ["Rendsvig", "Rasmus K.", ""]]}, {"id": "1709.00410", "submitter": "Hendrik Richter", "authors": "Hendrik Richter", "title": "Visual art inspired by the collective feeding behavior of sand-bubbler\n  crabs", "comments": null, "journal-ref": "Computational Intelligence in Music, Sound, Art and Design,\n  EvoMUSART 2018, (Eds.: Liapis, A., Romero Cardalda, J.J., Ekart, A.),\n  Springer-Verlag, pp. 1-17, 2018", "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sand--bubblers are crabs of the genera Dotilla and Scopimera which are known\nto produce remarkable patterns and structures at tropical beaches. From these\npattern-making abilities, we may draw inspiration for digital visual art. A\nsimple mathematical model is proposed and an algorithm is designed that may\ncreate such sand-bubbler patterns artificially. In addition, design parameters\nto modify the patterns are identified and analyzed by computational aesthetic\nmeasures. Finally, an extension of the algorithm is discussed that may enable\ncontrolling and guiding generative evolution of the art-making process.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 09:01:39 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 11:57:56 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Richter", "Hendrik", ""]]}, {"id": "1709.00503", "submitter": "Cameron Allen", "authors": "Cameron Allen, Kavosh Asadi, Melrose Roderick, Abdel-rahman Mohamed,\n  George Konidaris, Michael Littman", "title": "Mean Actor Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm, Mean Actor-Critic (MAC), for discrete-action\ncontinuous-state reinforcement learning. MAC is a policy gradient algorithm\nthat uses the agent's explicit representation of all action values to estimate\nthe gradient of the policy, rather than using only the actions that were\nactually executed. We prove that this approach reduces variance in the policy\ngradient estimate relative to traditional actor-critic methods. We show\nempirical results on two control domains and on six Atari games, where MAC is\ncompetitive with state-of-the-art policy search algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 22:53:03 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 20:20:59 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Allen", "Cameron", ""], ["Asadi", "Kavosh", ""], ["Roderick", "Melrose", ""], ["Mohamed", "Abdel-rahman", ""], ["Konidaris", "George", ""], ["Littman", "Michael", ""]]}, {"id": "1709.00513", "submitter": "Zheng Xu", "authors": "Zheng Xu, Yen-Chang Hsu, Jiawei Huang", "title": "Training Shallow and Thin Networks for Acceleration via Knowledge\n  Distillation with Conditional Adversarial Networks", "comments": "Shorter version will appear at ICLR workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing interest on accelerating neural networks for real-time\napplications. We study the student-teacher strategy, in which a small and fast\nstudent network is trained with the auxiliary information learned from a large\nand accurate teacher network. We propose to use conditional adversarial\nnetworks to learn the loss function to transfer knowledge from teacher to\nstudent. The proposed method is particularly effective for relatively small\nstudent networks. Moreover, experimental results show the effect of network\nsize when the modern networks are used as student. We empirically study the\ntrade-off between inference time and classification accuracy, and provide\nsuggestions on choosing a proper student network.\n", "versions": [{"version": "v1", "created": "Sat, 2 Sep 2017 01:03:08 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 18:42:13 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Xu", "Zheng", ""], ["Hsu", "Yen-Chang", ""], ["Huang", "Jiawei", ""]]}, {"id": "1709.00539", "submitter": "Chandrasekaran Anirudh Bhardwaj", "authors": "Chandrasekaran Anirudh Bhardwaj, Megha Mishra and Sweetlin Hemalatha", "title": "An Automated Compatibility Prediction Engine using DISC Theory Based\n  Classification and Neural Networks", "comments": "Presented in 6th International Conference on Research Trends in\n  Engineering, Applied Science and Management (ICRTESM-2017).Published in\n  International Journal of Engineering, Technology, Science and Research", "journal-ref": "International Journal of Engineering, Technology, Science and\n  Research Volume 4 Issue 8 2017", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally psychometric tests were used for profiling incoming workers.\nThese methods use DISC profiling method to classify people into distinct\npersonality types, which are further used to predict if a person may be a\npossible fit to the organizational culture. This concept is taken further by\nintroducing a novel technique to predict if a particular pair of an incoming\nworker and the manager being assigned are compatible at a psychological scale.\nThis is done using multilayer perceptron neural network which can be adaptively\ntrained to showcase the true nature of the compatibility index. The proposed\nprototype model is used to quantify the relevant attributes, use them to train\nthe prediction engine, and to define the data pipeline required for it.\n", "versions": [{"version": "v1", "created": "Sat, 2 Sep 2017 06:38:12 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Bhardwaj", "Chandrasekaran Anirudh", ""], ["Mishra", "Megha", ""], ["Hemalatha", "Sweetlin", ""]]}, {"id": "1709.00572", "submitter": "C\\u{a}t\\u{a}lina Cangea", "authors": "C\\u{a}t\\u{a}lina Cangea, Petar Veli\\v{c}kovi\\'c, Pietro Li\\`o", "title": "XFlow: Cross-modal Deep Neural Networks for Audiovisual Classification", "comments": "Accepted at the IEEE ICDL-EPIROB 2017 Workshop on Computational\n  Models for Crossmodal Learning (CMCML), 4 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there have been numerous developments towards solving\nmultimodal tasks, aiming to learn a stronger representation than through a\nsingle modality. Certain aspects of the data can be particularly useful in this\ncase - for example, correlations in the space or time domain across modalities\n- but should be wisely exploited in order to benefit from their full predictive\npotential. We propose two deep learning architectures with multimodal\ncross-connections that allow for dataflow between several feature extractors\n(XFlow). Our models derive more interpretable features and achieve better\nperformances than models which do not exchange representations, usefully\nexploiting correlations between audio and visual data, which have a different\ndimensionality and are nontrivially exchangeable. Our work improves on existing\nmultimodal deep learning algorithms in two essential ways: (1) it presents a\nnovel method for performing cross-modality (before features are learned from\nindividual modalities) and (2) extends the previously proposed\ncross-connections which only transfer information between streams that process\ncompatible data. Illustrating some of the representations learned by the\nconnections, we analyse their contribution to the increase in discrimination\nability and reveal their compatibility with a lip-reading network intermediate\nrepresentation. We provide the research community with Digits, a new dataset\nconsisting of three data types extracted from videos of people saying the\ndigits 0-9. Results show that both cross-modal architectures outperform their\nbaselines (by up to 11.5%) when evaluated on the AVletters, CUAVE and Digits\ndatasets, achieving state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sat, 2 Sep 2017 12:43:59 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 21:43:42 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Cangea", "C\u0103t\u0103lina", ""], ["Veli\u010dkovi\u0107", "Petar", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "1709.00653", "submitter": "Viet Ha-Thuc", "authors": "Viet Ha-Thuc, Yan Yan, Xianren Wu, Vijay Dialani, Abhishek Gupta,\n  Shakti Sinha", "title": "From Query-By-Keyword to Query-By-Example: LinkedIn Talent Search\n  Approach", "comments": null, "journal-ref": null, "doi": "10.1145/3132847.3132869", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One key challenge in talent search is to translate complex criteria of a\nhiring position into a search query, while it is relatively easy for a searcher\nto list examples of suitable candidates for a given position. To improve search\nefficiency, we propose the next generation of talent search at LinkedIn, also\nreferred to as Search By Ideal Candidates. In this system, a searcher provides\none or several ideal candidates as the input to hire for a given position. The\nsystem then generates a query based on the ideal candidates and uses it to\nretrieve and rank results. Shifting from the traditional Query-By-Keyword to\nthis new Query-By-Example system poses a number of challenges: How to generate\na query that best describes the candidates? When moving to a completely\ndifferent paradigm, how does one leverage previous product logs to learn\nranking models and/or evaluate the new system with no existing usage logs?\nFinally, given the different nature between the two search paradigms, the\nranking features typically used for Query-By-Keyword systems might not be\noptimal for Query-By-Example. This paper describes our approach to solving\nthese challenges. We present experimental results confirming the effectiveness\nof the proposed solution, particularly on query building and search ranking\ntasks. As of writing this paper, the new system has been available to all\nLinkedIn members.\n", "versions": [{"version": "v1", "created": "Sun, 3 Sep 2017 02:02:08 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Ha-Thuc", "Viet", ""], ["Yan", "Yan", ""], ["Wu", "Xianren", ""], ["Dialani", "Vijay", ""], ["Gupta", "Abhishek", ""], ["Sinha", "Shakti", ""]]}, {"id": "1709.00661", "submitter": "Amita Misra", "authors": "Amita Misra and Marilyn Walker", "title": "Topic Independent Identification of Agreement and Disagreement in Social\n  Media Dialogue", "comments": "@inproceedings{Misra2013TopicII, title={Topic Independent\n  Identification of Agreement and Disagreement in Social Media Dialogue},\n  author={Amita Misra and Marilyn A. Walker}, booktitle={SIGDIAL Conference},\n  year={2013}}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on the structure of dialogue has been hampered for years because\nlarge dialogue corpora have not been available. This has impacted the dialogue\nresearch community's ability to develop better theories, as well as good off\nthe shelf tools for dialogue processing. Happily, an increasing amount of\ninformation and opinion exchange occur in natural dialogue in online forums,\nwhere people share their opinions about a vast range of topics. In particular\nwe are interested in rejection in dialogue, also called disagreement and\ndenial, where the size of available dialogue corpora, for the first time,\noffers an opportunity to empirically test theoretical accounts of the\nexpression and inference of rejection in dialogue. In this paper, we test\nwhether topic-independent features motivated by theoretical predictions can be\nused to recognize rejection in online forums in a topic independent way. Our\nresults show that our theoretically motivated features achieve 66% accuracy, an\nimprovement over a unigram baseline of an absolute 6%.\n", "versions": [{"version": "v1", "created": "Sun, 3 Sep 2017 04:16:15 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Misra", "Amita", ""], ["Walker", "Marilyn", ""]]}, {"id": "1709.00662", "submitter": "Amita Misra", "authors": "Amita Misra, Pranav Anand, Jean E Fox Tree and Marilyn Walker", "title": "Using Summarization to Discover Argument Facets in Online Ideological\n  Dialog", "comments": "@inproceedings{Misra2015UsingST,title={Using Summarization to\n  Discover Argument Facets in Online Idealogical Dialog},author={Amita Misra\n  and Pranav Anand and Jean E. Fox Tree and Marilyn A.\n  Walker},booktitle={HLT-NAACL},year={2015}}", "journal-ref": null, "doi": "10.3115/v1/n15-1046", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More and more of the information available on the web is dialogic, and a\nsignificant portion of it takes place in online forum conversations about\ncurrent social and political topics. We aim to develop tools to summarize what\nthese conversations are about. What are the CENTRAL PROPOSITIONS associated\nwith different stances on an issue, what are the abstract objects under\ndiscussion that are central to a speaker's argument? How can we recognize that\ntwo CENTRAL PROPOSITIONS realize the same FACET of the argument? We hypothesize\nthat the CENTRAL PROPOSITIONS are exactly those arguments that people find most\nsalient, and use human summarization as a probe for discovering them. We\ndescribe our corpus of human summaries of opinionated dialogs, then show how we\ncan identify similar repeated arguments, and group them into FACETS across many\ndiscussions of a topic. We define a new task, ARGUMENT FACET SIMILARITY (AFS),\nand show that we can predict AFS with a .54 correlation score, versus an ngram\nsystem baseline of .39 and a semantic textual similarity system baseline of\n.45.\n", "versions": [{"version": "v1", "created": "Sun, 3 Sep 2017 04:16:25 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Misra", "Amita", ""], ["Anand", "Pranav", ""], ["Tree", "Jean E Fox", ""], ["Walker", "Marilyn", ""]]}, {"id": "1709.00670", "submitter": "Vinu E V", "authors": "Vinu E.V, P Sreenivasa Kumar", "title": "Difficulty-level Modeling of Ontology-based Factual Questions", "comments": "This manuscript is currently under review in the Semantic Web Journal\n  (http://www.semantic-web-journal.net/system/files/swj1712.pdf)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantics based knowledge representations such as ontologies are found to be\nvery useful in automatically generating meaningful factual questions.\nDetermining the difficulty level of these system generated questions is helpful\nto effectively utilize them in various educational and professional\napplications. The existing approaches for finding the difficulty level of\nfactual questions are very simple and are limited to a few basic principles. We\npropose a new methodology for this problem by considering an educational theory\ncalled Item Response Theory (IRT). In the IRT, knowledge proficiency of end\nusers (learners) are considered for assigning difficulty levels, because of the\nassumptions that a given question is perceived differently by learners of\nvarious proficiencies. We have done a detailed study on the features (factors)\nof a question statement which could possibly determine its difficulty level for\nthree learner categories (experts, intermediates and beginners). We formulate\nontology based metrics for the same. We then train three logistic regression\nmodels to predict the difficulty level corresponding to the three learner\ncategories.\n", "versions": [{"version": "v1", "created": "Sun, 3 Sep 2017 06:27:45 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["E.", "Vinu", "V"], ["Kumar", "P Sreenivasa", ""]]}, {"id": "1709.00744", "submitter": "Jochen Burghardt", "authors": "Jochen Burghardt", "title": "An Improved Algorithm for E-Generalization", "comments": "37 pages; 19 figures; complete C source sode available via ancillary\n  files", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  E-generalization computes common generalizations of given ground terms w.r.t.\na given equational background theory E. In 2005 [arXiv:1403.8118], we had\npresented a computation approach based on standard regular tree grammar\nalgorithms, and a Prolog prototype implementation. In this report, we present\nalgorithmic improvements, prove them correct and complete, and give some\ndetails of an efficiency-oriented implementation in C that allows us to handle\nproblems larger by several orders of magnitude.\n", "versions": [{"version": "v1", "created": "Sun, 3 Sep 2017 16:55:54 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Burghardt", "Jochen", ""]]}, {"id": "1709.00893", "submitter": "Dehong Ma", "authors": "Dehong Ma, Sujian Li, Xiaodong Zhang, Houfeng Wang", "title": "Interactive Attention Networks for Aspect-Level Sentiment Classification", "comments": "Accepted by IJCAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-level sentiment classification aims at identifying the sentiment\npolarity of specific target in its context. Previous approaches have realized\nthe importance of targets in sentiment classification and developed various\nmethods with the goal of precisely modeling their contexts via generating\ntarget-specific representations. However, these studies always ignore the\nseparate modeling of targets. In this paper, we argue that both targets and\ncontexts deserve special treatment and need to be learned their own\nrepresentations via interactive learning. Then, we propose the interactive\nattention networks (IAN) to interactively learn attentions in the contexts and\ntargets, and generate the representations for targets and contexts separately.\nWith this design, the IAN model can well represent a target and its collocative\ncontext, which is helpful to sentiment classification. Experimental results on\nSemEval 2014 Datasets demonstrate the effectiveness of our model.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 10:34:34 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Ma", "Dehong", ""], ["Li", "Sujian", ""], ["Zhang", "Xiaodong", ""], ["Wang", "Houfeng", ""]]}, {"id": "1709.00928", "submitter": "Ariel Rosenfeld", "authors": "Ariel Rosenfeld, Odaya Kardashov and Orel Zang", "title": "Automation of Android Applications Testing Using Machine Learning\n  Activities Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile applications are being used every day by more than half of the world's\npopulation to perform a great variety of tasks. With the increasingly\nwidespread usage of these applications, the need arises for efficient\ntechniques to test them. Many frameworks allow automating the process of\napplication testing, however existing frameworks mainly rely on the application\ndeveloper for providing testing scripts for each developed application, thus\npreventing reuse of these tests for similar applications. In this paper, we\npresent a novel approach for the automation of testing Android applications by\nleveraging machine learning techniques and reusing popular test scenarios. We\ndiscuss and demonstrate the potential benefits of our approach in an empirical\nstudy where we show that our developed testing tool, based on the proposed\napproach, outperforms standard methods in realistic settings.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 12:52:36 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Rosenfeld", "Ariel", ""], ["Kardashov", "Odaya", ""], ["Zang", "Orel", ""]]}, {"id": "1709.00931", "submitter": "Azlan Iqbal", "authors": "Azlan Iqbal", "title": "A Computer Composes A Fabled Problem: Four Knights vs. Queen", "comments": "12 pages, 5 figures and 2 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explain how the prototype automatic chess problem composer, Chesthetica,\nsuccessfully composed a rare and interesting chess problem using the new\nDigital Synaptic Neural Substrate (DSNS) computational creativity approach.\nThis problem represents a greater challenge from a creative standpoint because\nthe checkmate is not always clear and the method of winning even less so.\nCreating a decisive chess problem of this type without the aid of an omniscient\n7-piece endgame tablebase (and one that also abides by several chess\ncomposition conventions) would therefore be a challenge for most human players\nand composers working on their own. The fact that a small computer with\nrelatively low processing power and memory was sufficient to compose such a\nproblem using the DSNS approach in just 10 days is therefore noteworthy. In\nthis report we document the event and result in some detail. It lends\nadditional credence to the DSNS as a viable new approach in the field of\ncomputational creativity. In particular, in areas where human-like creativity\nis required for targeted or specific problems with no clear path to the\nsolution.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 12:56:23 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Iqbal", "Azlan", ""]]}, {"id": "1709.01070", "submitter": "Pavel Surynek", "authors": "Marika Ivanov\\'a, Pavel Surynek, Diep Thi Ngoc Nguyen", "title": "Maintaining Ad-Hoc Communication Network in Area Protection Scenarios\n  with Adversarial Agents", "comments": "arXiv admin note: substantial text overlap with arXiv:1708.07285", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address a problem of area protection in graph-based scenarios with\nmultiple mobile agents where connectivity is maintained among agents to ensure\nthey can communicate. The problem consists of two adversarial teams of agents\nthat move in an undirected graph shared by both teams. Agents are placed in\nvertices of the graph; at most one agent can occupy a vertex; and they can move\ninto adjacent vertices in a conflict free way. Teams have asymmetric goals: the\naim of one team - attackers - is to invade into given area while the aim of the\nopponent team - defenders - is to protect the area from being entered by\nattackers by occupying selected vertices. The team of defenders need to\nmaintain connectivity of vertices occupied by its own agents in a visibility\ngraph. The visibility graph models possibility of communication between pairs\nof vertices.\n  We study strategies for allocating vertices to be occupied by the team of\ndefenders to block attacking agents where connectivity is maintained at the\nsame time. To do this we reserve a subset of defending agents that do not try\nto block the attackers but instead are placed to support connectivity of the\nteam. The performance of strategies is tested in multiple benchmarks. The\nsuccess of a strategy is heavily dependent on the type of the instance, and so\none of the contributions of this work is that we identify suitable strategies\nfor diverse instance types.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 07:38:17 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Ivanov\u00e1", "Marika", ""], ["Surynek", "Pavel", ""], ["Nguyen", "Diep Thi Ngoc", ""]]}, {"id": "1709.01122", "submitter": "Rodrigo de Salvo Braz", "authors": "Rodrigo de Salvo Braz and Ciaran O'Reilly", "title": "Exact Inference for Relational Graphical Models with Interpreted\n  Functions: Lifted Probabilistic Inference Modulo Theories", "comments": "Appeared in the Uncertainty in Artificial Intelligence Conference,\n  August 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Inference Modulo Theories (PIMT) is a recent framework that\nexpands exact inference on graphical models to use richer languages that\ninclude arithmetic, equalities, and inequalities on both integers and real\nnumbers. In this paper, we expand PIMT to a lifted version that also processes\nrandom functions and relations. This enhancement is achieved by adapting\nInversion, a method from Lifted First-Order Probabilistic Inference literature,\nto also be modulo theories. This results in the first algorithm for exact\nprobabilistic inference that efficiently and simultaneously exploits random\nrelations and functions, arithmetic, equalities and inequalities.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 19:08:37 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Braz", "Rodrigo de Salvo", ""], ["O'Reilly", "Ciaran", ""]]}, {"id": "1709.01215", "submitter": "Chunyuan Li", "authors": "Chunyuan Li, Hao Liu, Changyou Chen, Yunchen Pu, Liqun Chen, Ricardo\n  Henao, Lawrence Carin", "title": "ALICE: Towards Understanding Adversarial Learning for Joint Distribution\n  Matching", "comments": "NIPS 2017 (22 pages); short version (9 pages):\n  http://people.duke.edu/~cl319/doc/papers/nips_2017_alice.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the non-identifiability issues associated with bidirectional\nadversarial training for joint distribution matching. Within a framework of\nconditional entropy, we propose both adversarial and non-adversarial approaches\nto learn desirable matched joint distributions for unsupervised and supervised\ntasks. We unify a broad family of adversarial models as joint distribution\nmatching problems. Our approach stabilizes learning of unsupervised\nbidirectional adversarial learning methods. Further, we introduce an extension\nfor semi-supervised learning tasks. Theoretical results are validated in\nsynthetic data and real-world applications.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 02:18:06 GMT"}, {"version": "v2", "created": "Sun, 5 Nov 2017 03:58:52 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Li", "Chunyuan", ""], ["Liu", "Hao", ""], ["Chen", "Changyou", ""], ["Pu", "Yunchen", ""], ["Chen", "Liqun", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1709.01308", "submitter": "Simyung Chang", "authors": "Simyung Chang, YoungJoon Yoo, Jaeseok Choi, Nojun Kwak", "title": "BOOK: Storing Algorithm-Invariant Episodes for Deep Reinforcement\n  Learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel method to train agents of reinforcement learning (RL) by\nsharing knowledge in a way similar to the concept of using a book. The recorded\ninformation in the form of a book is the main means by which humans learn\nknowledge. Nevertheless, the conventional deep RL methods have mainly focused\neither on experiential learning where the agent learns through interactions\nwith the environment from the start or on imitation learning that tries to\nmimic the teacher. Contrary to these, our proposed book learning shares key\ninformation among different agents in a book-like manner by delving into the\nfollowing two characteristic features: (1) By defining the linguistic function,\ninput states can be clustered semantically into a relatively small number of\ncore clusters, which are forwarded to other RL agents in a prescribed manner.\n(2) By defining state priorities and the contents for recording, core\nexperiences can be selected and stored in a small container. We call this\ncontainer as `BOOK'. Our method learns hundreds to thousand times faster than\nthe conventional methods by learning only a handful of core cluster\ninformation, which shows that deep RL agents can effectively learn through the\nshared knowledge from other agents.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 09:47:41 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 16:57:18 GMT"}, {"version": "v3", "created": "Mon, 12 Feb 2018 08:44:59 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Chang", "Simyung", ""], ["Yoo", "YoungJoon", ""], ["Choi", "Jaeseok", ""], ["Kwak", "Nojun", ""]]}, {"id": "1709.01366", "submitter": "Theeraphot Sriarunothai", "authors": "Theeraphot Sriarunothai, Sabine W\\\"olk, Gouri Shankar Giri, Nicolai\n  Friis, Vedran Dunjko, Hans J. Briegel, Christof Wunderlich", "title": "Speeding-up the decision making of a learning agent using an ion trap\n  quantum processor", "comments": "21 pages, 7 figures, 2 tables. Author names now spelled correctly;\n  sections rearranged; changes in the wording of the manuscript", "journal-ref": "Quantum Sci. Technol. 4, 015014 (2019)", "doi": "10.1088/2058-9565/aaef5e", "report-no": null, "categories": "quant-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a proof-of-principle experimental demonstration of the quantum\nspeed-up for learning agents utilizing a small-scale quantum information\nprocessor based on radiofrequency-driven trapped ions. The decision-making\nprocess of a quantum learning agent within the projective simulation paradigm\nfor machine learning is implemented in a system of two qubits. The latter are\nrealized using hyperfine states of two frequency-addressed atomic ions exposed\nto a static magnetic field gradient. We show that the deliberation time of this\nquantum learning agent is quadratically improved with respect to comparable\nclassical learning agents. The performance of this quantum-enhanced learning\nagent highlights the potential of scalable quantum processors taking advantage\nof machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 13:09:05 GMT"}, {"version": "v2", "created": "Mon, 23 Oct 2017 14:12:05 GMT"}, {"version": "v3", "created": "Wed, 19 Dec 2018 15:39:58 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Sriarunothai", "Theeraphot", ""], ["W\u00f6lk", "Sabine", ""], ["Giri", "Gouri Shankar", ""], ["Friis", "Nicolai", ""], ["Dunjko", "Vedran", ""], ["Briegel", "Hans J.", ""], ["Wunderlich", "Christof", ""]]}, {"id": "1709.01434", "submitter": "Manzil Zaheer", "authors": "Sashank J Reddi, Manzil Zaheer, Suvrit Sra, Barnabas Poczos, Francis\n  Bach, Ruslan Salakhutdinov, Alexander J Smola", "title": "A Generic Approach for Escaping Saddle points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central challenge to using first-order methods for optimizing nonconvex\nproblems is the presence of saddle points. First-order methods often get stuck\nat saddle points, greatly deteriorating their performance. Typically, to escape\nfrom saddles one has to use second-order methods. However, most works on\nsecond-order methods rely extensively on expensive Hessian-based computations,\nmaking them impractical in large-scale settings. To tackle this challenge, we\nintroduce a generic framework that minimizes Hessian based computations while\nat the same time provably converging to second-order critical points. Our\nframework carefully alternates between a first-order and a second-order\nsubroutine, using the latter only close to saddle points, and yields\nconvergence results competitive to the state-of-the-art. Empirical results\nsuggest that our strategy also enjoys a good practical performance.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 14:58:15 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Reddi", "Sashank J", ""], ["Zaheer", "Manzil", ""], ["Sra", "Suvrit", ""], ["Poczos", "Barnabas", ""], ["Bach", "Francis", ""], ["Salakhutdinov", "Ruslan", ""], ["Smola", "Alexander J", ""]]}, {"id": "1709.01476", "submitter": "Jan Zacharias", "authors": "Daniel Sonntag, Michael Barz, Jan Zacharias, Sven Stauden, Vahid\n  Rahmani, \\'Aron F\\'othi, Andr\\'as L\\H{o}rincz", "title": "Fine-tuning deep CNN models on specific MS COCO categories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fine-tuning of a deep convolutional neural network (CNN) is often desired.\nThis paper provides an overview of our publicly available py-faster-rcnn-ft\nsoftware library that can be used to fine-tune the VGG_CNN_M_1024 model on\ncustom subsets of the Microsoft Common Objects in Context (MS COCO) dataset.\nFor example, we improved the procedure so that the user does not have to look\nfor suitable image files in the dataset by hand which can then be used in the\ndemo program. Our implementation randomly selects images that contain at least\none object of the categories on which the model is fine-tuned.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 16:22:28 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Sonntag", "Daniel", ""], ["Barz", "Michael", ""], ["Zacharias", "Jan", ""], ["Stauden", "Sven", ""], ["Rahmani", "Vahid", ""], ["F\u00f3thi", "\u00c1ron", ""], ["L\u0151rincz", "Andr\u00e1s", ""]]}, {"id": "1709.01490", "submitter": "Garrett Andersen", "authors": "Garrett Andersen, George Konidaris", "title": "Active Exploration for Learning Symbolic Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an online active exploration algorithm for data-efficiently\nlearning an abstract symbolic model of an environment. Our algorithm is divided\ninto two parts: the first part quickly generates an intermediate Bayesian\nsymbolic model from the data that the agent has collected so far, which the\nagent can then use along with the second part to guide its future exploration\ntowards regions of the state space that the model is uncertain about. We show\nthat our algorithm outperforms random and greedy exploration policies on two\ndifferent computer game domains. The first domain is an Asteroids-inspired game\nwith complex dynamics but basic logical structure. The second is the Treasure\nGame, with simpler dynamics but more complex logical structure.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 17:09:48 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 15:09:31 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Andersen", "Garrett", ""], ["Konidaris", "George", ""]]}, {"id": "1709.01509", "submitter": "Akshay Balsubramani", "authors": "Akshay Balsubramani", "title": "Linking Generative Adversarial Learning and Binary Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we point out a basic link between generative adversarial (GA)\ntraining and binary classification -- any powerful discriminator essentially\ncomputes an (f-)divergence between real and generated samples. The result,\nrepeatedly re-derived in decision theory, has implications for GA Networks\n(GANs), providing an alternative perspective on training f-GANs by designing\nthe discriminator loss function.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 17:55:59 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Balsubramani", "Akshay", ""]]}, {"id": "1709.01532", "submitter": "Wenjie Pei", "authors": "Wenjie Pei, Jie Yang, Zhu Sun, Jie Zhang, Alessandro Bozzon, David\n  M.J. Tax", "title": "Interacting Attention-gated Recurrent Networks for Recommendation", "comments": "Accepted by ACM International Conference on Information and Knowledge\n  Management (CIKM), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing the temporal dynamics of user preferences over items is important\nfor recommendation. Existing methods mainly assume that all time steps in\nuser-item interaction history are equally relevant to recommendation, which\nhowever does not apply in real-world scenarios where user-item interactions can\noften happen accidentally. More importantly, they learn user and item dynamics\nseparately, thus failing to capture their joint effects on user-item\ninteractions. To better model user and item dynamics, we present the\nInteracting Attention-gated Recurrent Network (IARN) which adopts the attention\nmodel to measure the relevance of each time step. In particular, we propose a\nnovel attention scheme to learn the attention scores of user and item history\nin an interacting way, thus to account for the dependencies between user and\nitem dynamics in shaping user-item interactions. By doing so, IARN can\nselectively memorize different time steps of a user's history when predicting\nher preferences over different items. Our model can therefore provide\nmeaningful interpretations for recommendation results, which could be further\nenhanced by auxiliary features. Extensive validation on real-world datasets\nshows that IARN consistently outperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 18:01:39 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 10:08:44 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Pei", "Wenjie", ""], ["Yang", "Jie", ""], ["Sun", "Zhu", ""], ["Zhang", "Jie", ""], ["Bozzon", "Alessandro", ""], ["Tax", "David M. J.", ""]]}, {"id": "1709.01547", "submitter": "Ivan Yu. Tyukin", "authors": "Ivan Y. Tyukin, Alexander N. Gorban, Konstantin Sofeikov, Ilya\n  Romanenko", "title": "Knowledge Transfer Between Artificial Intelligence Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the fundamental question: how a legacy \"student\" Artificial\nIntelligent (AI) system could learn from a legacy \"teacher\" AI system or a\nhuman expert without complete re-training and, most importantly, without\nrequiring significant computational resources. Here \"learning\" is understood as\nan ability of one system to mimic responses of the other and vice-versa. We\ncall such learning an Artificial Intelligence knowledge transfer. We show that\nif internal variables of the \"student\" Artificial Intelligent system have the\nstructure of an $n$-dimensional topological vector space and $n$ is\nsufficiently high then, with probability close to one, the required knowledge\ntransfer can be implemented by simple cascades of linear functionals. In\nparticular, for $n$ sufficiently large, with probability close to one, the\n\"student\" system can successfully and non-iteratively learn $k\\ll n$ new\nexamples from the \"teacher\" (or correct the same number of mistakes) at the\ncost of two additional inner products. The concept is illustrated with an\nexample of knowledge transfer from a pre-trained convolutional neural network\nto a simple linear classifier with HOG features.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 18:38:07 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 08:21:13 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Tyukin", "Ivan Y.", ""], ["Gorban", "Alexander N.", ""], ["Sofeikov", "Konstantin", ""], ["Romanenko", "Ilya", ""]]}, {"id": "1709.01574", "submitter": "Devinder Kumar", "authors": "Devinder Kumar, Graham W Taylor, Alexander Wong", "title": "Opening the Black Box of Financial AI with CLEAR-Trade: A CLass-Enhanced\n  Attentive Response Approach for Explaining and Visualizing Deep\n  Learning-Driven Stock Market Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been shown to outperform traditional machine learning\nalgorithms across a wide range of problem domains. However, current deep\nlearning algorithms have been criticized as uninterpretable \"black-boxes\" which\ncannot explain their decision making processes. This is a major shortcoming\nthat prevents the widespread application of deep learning to domains with\nregulatory processes such as finance. As such, industries such as finance have\nto rely on traditional models like decision trees that are much more\ninterpretable but less effective than deep learning for complex problems. In\nthis paper, we propose CLEAR-Trade, a novel financial AI visualization\nframework for deep learning-driven stock market prediction that mitigates the\ninterpretability issue of deep learning methods. In particular, CLEAR-Trade\nprovides a effective way to visualize and explain decisions made by deep stock\nmarket prediction models. We show the efficacy of CLEAR-Trade in enhancing the\ninterpretability of stock market prediction by conducting experiments based on\nS&P 500 stock index prediction. The results demonstrate that CLEAR-Trade can\nprovide significant insight into the decision-making process of deep\nlearning-driven financial models, particularly for regulatory processes, thus\nimproving their potential uptake in the financial industry.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 19:56:36 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Kumar", "Devinder", ""], ["Taylor", "Graham W", ""], ["Wong", "Alexander", ""]]}, {"id": "1709.01610", "submitter": "Mihailo Jovanovic", "authors": "Neil K. Dhingra, Sei Zhen Khong, and Mihailo R. Jovanovi\\'c", "title": "A second order primal-dual method for nonsmooth convex composite\n  optimization", "comments": "32 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.SY nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a second order primal-dual method for optimization problems in\nwhich the objective function is given by the sum of a strongly convex twice\ndifferentiable term and a possibly nondifferentiable convex regularizer. After\nintroducing an auxiliary variable, we utilize the proximal operator of the\nnonsmooth regularizer to transform the associated augmented Lagrangian into a\nfunction that is once, but not twice, continuously differentiable. The saddle\npoint of this function corresponds to the solution of the original optimization\nproblem. We employ a generalization of the Hessian to define second order\nupdates on this function and prove global exponential stability of the\ncorresponding differential inclusion. Furthermore, we develop a globally\nconvergent customized algorithm that utilizes the primal-dual augmented\nLagrangian as a merit function. We show that the search direction can be\ncomputed efficiently and prove quadratic/superlinear asymptotic convergence. We\nuse the $\\ell_1$-regularized model predictive control problem and the problem\nof designing a distributed controller for a spatially-invariant system to\ndemonstrate the merits and the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 22:08:41 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 19:24:18 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Dhingra", "Neil K.", ""], ["Khong", "Sei Zhen", ""], ["Jovanovi\u0107", "Mihailo R.", ""]]}, {"id": "1709.01613", "submitter": "Hedvig Kjellstr\\\"om", "authors": "Patrik Jonell, Joseph Mendelson, Thomas Storskog, Goran Hagman, Per\n  Ostberg, Iolanda Leite, Taras Kucherenko, Olga Mikheeva, Ulrika Akenine,\n  Vesna Jelic, Alina Solomon, Jonas Beskow, Joakim Gustafson, Miia Kivipelto,\n  Hedvig Kjellstrom", "title": "Machine Learning and Social Robotics for Detecting Early Signs of\n  Dementia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the EACare project, an ambitious multi-disciplinary\ncollaboration with the aim to develop an embodied system, capable of carrying\nout neuropsychological tests to detect early signs of dementia, e.g., due to\nAlzheimer's disease. The system will use methods from Machine Learning and\nSocial Robotics, and be trained with examples of recorded clinician-patient\ninteractions. The interaction will be developed using a participatory design\napproach. We describe the scope and method of the project, and report on a\nfirst Wizard of Oz prototype.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 22:27:27 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Jonell", "Patrik", ""], ["Mendelson", "Joseph", ""], ["Storskog", "Thomas", ""], ["Hagman", "Goran", ""], ["Ostberg", "Per", ""], ["Leite", "Iolanda", ""], ["Kucherenko", "Taras", ""], ["Mikheeva", "Olga", ""], ["Akenine", "Ulrika", ""], ["Jelic", "Vesna", ""], ["Solomon", "Alina", ""], ["Beskow", "Jonas", ""], ["Gustafson", "Joakim", ""], ["Kivipelto", "Miia", ""], ["Kjellstrom", "Hedvig", ""]]}, {"id": "1709.01887", "submitter": "Amita Misra", "authors": "Amita Misra, Brian Ecker, and Marilyn A. Walker", "title": "Measuring the Similarity of Sentential Arguments in Dialog", "comments": "Measuring the Similarity of Sentential Arguments in Dialog, by Misra,\n  Amita and Ecker, Brian and Walker, Marilyn A, 17th Annual Meeting of the\n  Special Interest Group on Discourse and Dialogue, pages={276}, year={2016}\n  The dataset is available at https://nlds.soe.ucsc.edu/node/44", "journal-ref": null, "doi": "10.18653/v1/w16-3636", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When people converse about social or political topics, similar arguments are\noften paraphrased by different speakers, across many different conversations.\nDebate websites produce curated summaries of arguments on such topics; these\nsummaries typically consist of lists of sentences that represent frequently\nparaphrased propositions, or labels capturing the essence of one particular\naspect of an argument, e.g. Morality or Second Amendment. We call these\nfrequently paraphrased propositions ARGUMENT FACETS. Like these curated sites,\nour goal is to induce and identify argument facets across multiple\nconversations, and produce summaries. However, we aim to do this automatically.\nWe frame the problem as consisting of two steps: we first extract sentences\nthat express an argument from raw social media dialogs, and then rank the\nextracted arguments in terms of their similarity to one another. Sets of\nsimilar arguments are used to represent argument facets. We show here that we\ncan predict ARGUMENT FACET SIMILARITY with a correlation averaging 0.63\ncompared to a human topline averaging 0.68 over three debate topics, easily\nbeating several reasonable baselines.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 17:15:49 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Misra", "Amita", ""], ["Ecker", "Brian", ""], ["Walker", "Marilyn A.", ""]]}, {"id": "1709.01915", "submitter": "James Bradbury", "authors": "James Bradbury, Richard Socher", "title": "Towards Neural Machine Translation with Latent Tree Attention", "comments": "Presented at SPNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building models that take advantage of the hierarchical structure of language\nwithout a priori annotation is a longstanding goal in natural language\nprocessing. We introduce such a model for the task of machine translation,\npairing a recurrent neural network grammar encoder with a novel attentional\nRNNG decoder and applying policy gradient reinforcement learning to induce\nunsupervised tree structures on both the source and target. When trained on\ncharacter-level datasets with no explicit segmentation or parse annotation, the\nmodel learns a plausible segmentation and shallow parse, obtaining performance\nclose to an attentional baseline.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 17:44:53 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Bradbury", "James", ""], ["Socher", "Richard", ""]]}, {"id": "1709.01989", "submitter": "Florian Neukart", "authors": "Martin Hofmann, Florian Neukart, Thomas B\\\"ack", "title": "Artificial Intelligence and Data Science in the Automotive Industry", "comments": "22 pages, 4 figures", "journal-ref": "https://data-science-blog.com/blog/2017/05/06/artificial-intelligence-and-data-science-in-the-automotive-industry/", "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data science and machine learning are the key technologies when it comes to\nthe processes and products with automatic learning and optimization to be used\nin the automotive industry of the future. This article defines the terms \"data\nscience\" (also referred to as \"data analytics\") and \"machine learning\" and how\nthey are related. In addition, it defines the term \"optimizing analytics\" and\nillustrates the role of automatic optimization as a key technology in\ncombination with data analytics. It also uses examples to explain the way that\nthese technologies are currently being used in the automotive industry on the\nbasis of the major subprocesses in the automotive value chain (development,\nprocurement; logistics, production, marketing, sales and after-sales, connected\ncustomer). Since the industry is just starting to explore the broad range of\npotential uses for these technologies, visionary application examples are used\nto illustrate the revolutionary possibilities that they offer. Finally, the\narticle demonstrates how these technologies can make the automotive industry\nmore efficient and enhance its customer focus throughout all its operations and\nactivities, extending from the product and its development process to the\ncustomers and their connection to the product.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 20:38:00 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Hofmann", "Martin", ""], ["Neukart", "Florian", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "1709.02023", "submitter": "Murat Kocaoglu", "authors": "Murat Kocaoglu, Christopher Snyder, Alexandros G. Dimakis, Sriram\n  Vishwanath", "title": "CausalGAN: Learning Causal Implicit Generative Models with Adversarial\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an adversarial training procedure for learning a causal implicit\ngenerative model for a given causal graph. We show that adversarial training\ncan be used to learn a generative model with true observational and\ninterventional distributions if the generator architecture is consistent with\nthe given causal graph. We consider the application of generating faces based\non given binary labels where the dependency structure between the labels is\npreserved with a causal graph. This problem can be seen as learning a causal\nimplicit generative model for the image and labels. We devise a two-stage\nprocedure for this problem. First we train a causal implicit generative model\nover binary labels using a neural network consistent with a causal graph as the\ngenerator. We empirically show that WassersteinGAN can be used to output\ndiscrete labels. Later, we propose two new conditional GAN architectures, which\nwe call CausalGAN and CausalBEGAN. We show that the optimal generator of the\nCausalGAN, given the labels, samples from the image distributions conditioned\non these labels. The conditional GAN combined with a trained causal implicit\ngenerative model for the labels is then a causal implicit generative model over\nthe labels and the generated image. We show that the proposed architectures can\nbe used to sample from observational and interventional image distributions,\neven for interventions which do not naturally occur in the dataset.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 22:53:12 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 22:52:47 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Kocaoglu", "Murat", ""], ["Snyder", "Christopher", ""], ["Dimakis", "Alexandros G.", ""], ["Vishwanath", "Sriram", ""]]}, {"id": "1709.02066", "submitter": "Pin Wang", "authors": "Pin Wang, Ching-Yao Chan", "title": "Formulation of Deep Reinforcement Learning Architecture Toward\n  Autonomous Driving for On-Ramp Merge", "comments": "IEEE International Conference on Intelligent Transportation Systems,\n  Yokohama, Japan, 2017", "journal-ref": null, "doi": "10.1109/ITSC.2017.8317735", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple automakers have in development or in production automated driving\nsystems (ADS) that offer freeway-pilot functions. This type of ADS is typically\nlimited to restricted-access freeways only, that is, the transition from manual\nto automated modes takes place only after the ramp merging process is completed\nmanually. One major challenge to extend the automation to ramp merging is that\nthe automated vehicle needs to incorporate and optimize long-term objectives\n(e.g. successful and smooth merge) when near-term actions must be safely\nexecuted. Moreover, the merging process involves interactions with other\nvehicles whose behaviors are sometimes hard to predict but may influence the\nmerging vehicle optimal actions. To tackle such a complicated control problem,\nwe propose to apply Deep Reinforcement Learning (DRL) techniques for finding an\noptimal driving policy by maximizing the long-term reward in an interactive\nenvironment. Specifically, we apply a Long Short-Term Memory (LSTM)\narchitecture to model the interactive environment, from which an internal state\ncontaining historical driving information is conveyed to a Deep Q-Network\n(DQN). The DQN is used to approximate the Q-function, which takes the internal\nstate as input and generates Q-values as output for action selection. With this\nDRL architecture, the historical impact of interactive environment on the\nlong-term reward can be captured and taken into account for deciding the\noptimal control policy. The proposed architecture has the potential to be\nextended and applied to other autonomous driving scenarios such as driving\nthrough a complex intersection or changing lanes under varying traffic flow\nconditions.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 04:50:29 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 21:20:06 GMT"}, {"version": "v3", "created": "Sat, 2 Feb 2019 02:04:20 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Wang", "Pin", ""], ["Chan", "Ching-Yao", ""]]}, {"id": "1709.02126", "submitter": "EPTCS", "authors": "Lukas Bulwahn (BMW Car IT GmbH), Maryam Kamali (University of\n  Liverpool), Sven Linker (University of Liverpool)", "title": "Proceedings First Workshop on Formal Verification of Autonomous Vehicles", "comments": null, "journal-ref": "EPTCS 257, 2017", "doi": "10.4204/EPTCS.257", "report-no": null, "categories": "cs.SY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These are the proceedings of the workshop on Formal Verification of\nAutonomous Vehicles, held on September 19th, 2017 in Turin, Italy, as an\naffiliated workshop of the International Conference on integrated Formal\nMethods (iFM 2017). The workshop aim is to bring together researchers from the\nformal verification community that are developing formal methods for autonomous\nvehicles as well as researchers working, e.g., in the area of control theory or\nrobotics, interested in applying verification techniques for designing and\ndeveloping of autonomous vehicles.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 08:02:08 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Bulwahn", "Lukas", "", "BMW Car IT GmbH"], ["Kamali", "Maryam", "", "University of\n  Liverpool"], ["Linker", "Sven", "", "University of Liverpool"]]}, {"id": "1709.02169", "submitter": "Rafael Dos Santos De Oliveira", "authors": "Rafael Oliveira, Lionel Ott, Vitor Guizilini and Fabio Ramos", "title": "Bayesian Optimisation for Safe Navigation under Localisation Uncertainty", "comments": "To appear in the proceedings of the 18th International Symposium on\n  Robotics Research (ISRR 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In outdoor environments, mobile robots are required to navigate through\nterrain with varying characteristics, some of which might significantly affect\nthe integrity of the platform. Ideally, the robot should be able to identify\nareas that are safe for navigation based on its own percepts about the\nenvironment while avoiding damage to itself. Bayesian optimisation (BO) has\nbeen successfully applied to the task of learning a model of terrain\ntraversability while guiding the robot through more traversable areas. An\nissue, however, is that localisation uncertainty can end up guiding the robot\nto unsafe areas and distort the model being learnt. In this paper, we address\nthis problem and present a novel method that allows BO to consider localisation\nuncertainty by applying a Gaussian process model for uncertain inputs as a\nprior. We evaluate the proposed method in simulation and in experiments with a\nreal robot navigating over rough terrain and compare it against standard BO\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 10:17:52 GMT"}, {"version": "v2", "created": "Sat, 17 Feb 2018 02:46:33 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Oliveira", "Rafael", ""], ["Ott", "Lionel", ""], ["Guizilini", "Vitor", ""], ["Ramos", "Fabio", ""]]}, {"id": "1709.02249", "submitter": "Sungjoon Choi", "authors": "Sungjoon Choi, Kyungjae Lee, Sungbin Lim, Songhwai Oh", "title": "Uncertainty-Aware Learning from Demonstration using Mixture Density\n  Networks with Sampling-Free Variance Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an uncertainty-aware learning from demonstration\nmethod by presenting a novel uncertainty estimation method utilizing a mixture\ndensity network appropriate for modeling complex and noisy human behaviors. The\nproposed uncertainty acquisition can be done with a single forward path without\nMonte Carlo sampling and is suitable for real-time robotics applications. The\nproperties of the proposed uncertainty measure are analyzed through three\ndifferent synthetic examples, absence of data, heavy measurement noise, and\ncomposition of functions scenarios. We show that each case can be distinguished\nusing the proposed uncertainty measure and presented an uncertainty-aware\nlearn- ing from demonstration method of an autonomous driving using this\nproperty. The proposed uncertainty-aware learning from demonstration method\noutperforms other compared methods in terms of safety using a complex\nreal-world driving dataset.\n", "versions": [{"version": "v1", "created": "Sun, 3 Sep 2017 18:57:54 GMT"}, {"version": "v2", "created": "Fri, 8 Sep 2017 06:11:36 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Choi", "Sungjoon", ""], ["Lee", "Kyungjae", ""], ["Lim", "Sungbin", ""], ["Oh", "Songhwai", ""]]}, {"id": "1709.02256", "submitter": "Michel de Lara", "authors": "Michel de Lara (CERMICS)", "title": "Rationally Biased Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans display a tendency to pay more attention to bad outcomes, often in a\ndisproportionate way relative to their statistical occurrence. They also\ndisplay euphorism, as well as a preference for the current state of affairs\n(status quo bias). Based on the analysis of optimal solutions of infinite\nhorizon stationary optimization problems under imperfect state observation, we\nshow that such human perception and decision biases can be grounded in a form\nof rationality. We also provide conditions (boundaries) for their possible\noccurence and an analysis of their robustness.Thus, biases can be the product\nof rational behavior.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 13:36:46 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 13:42:27 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["de Lara", "Michel", "", "CERMICS"]]}, {"id": "1709.02314", "submitter": "Daniel O\\~noro-Rubio", "authors": "Daniel O\\~noro-Rubio, Mathias Niepert, Alberto Garc\\'ia-Dur\\'an,\n  Roberto Gonz\\'alez and Roberto J. L\\'opez-Sastre", "title": "Answering Visual-Relational Queries in Web-Extracted Knowledge Graphs", "comments": null, "journal-ref": "AKBC2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A visual-relational knowledge graph (KG) is a multi-relational graph whose\nentities are associated with images. We explore novel machine learning\napproaches for answering visual-relational queries in web-extracted knowledge\ngraphs. To this end, we have created ImageGraph, a KG with 1,330 relation\ntypes, 14,870 entities, and 829,931 images crawled from the web. With\nvisual-relational KGs such as ImageGraph one can introduce novel probabilistic\nquery types in which images are treated as first-class citizens. Both the\nprediction of relations between unseen images as well as multi-relational image\nretrieval can be expressed with specific families of visual-relational queries.\nWe introduce novel combinations of convolutional networks and knowledge graph\nembedding methods to answer such queries. We also explore a zero-shot learning\nscenario where an image of an entirely new entity is linked with multiple\nrelations to entities of an existing KG. The resulting multi-relational\ngrounding of unseen entity images into a knowledge graph serves as a semantic\nentity representation. We conduct experiments to demonstrate that the proposed\nmethods can answer these visual-relational queries efficiently and accurately.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 15:31:54 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 16:41:07 GMT"}, {"version": "v3", "created": "Tue, 21 Nov 2017 10:38:13 GMT"}, {"version": "v4", "created": "Thu, 15 Mar 2018 09:44:51 GMT"}, {"version": "v5", "created": "Sat, 31 Mar 2018 08:37:45 GMT"}, {"version": "v6", "created": "Fri, 3 May 2019 10:09:09 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["O\u00f1oro-Rubio", "Daniel", ""], ["Niepert", "Mathias", ""], ["Garc\u00eda-Dur\u00e1n", "Alberto", ""], ["Gonz\u00e1lez", "Roberto", ""], ["L\u00f3pez-Sastre", "Roberto J.", ""]]}, {"id": "1709.02349", "submitter": "Iulian Vlad Serban", "authors": "Iulian V. Serban, Chinnadhurai Sankar, Mathieu Germain, Saizheng\n  Zhang, Zhouhan Lin, Sandeep Subramanian, Taesup Kim, Michael Pieper, Sarath\n  Chandar, Nan Rosemary Ke, Sai Rajeshwar, Alexandre de Brebisson, Jose M. R.\n  Sotelo, Dendi Suhubdy, Vincent Michalski, Alexandre Nguyen, Joelle Pineau,\n  Yoshua Bengio", "title": "A Deep Reinforcement Learning Chatbot", "comments": "40 pages, 9 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MILABOT: a deep reinforcement learning chatbot developed by the\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\ncompetition. MILABOT is capable of conversing with humans on popular small talk\ntopics through both speech and text. The system consists of an ensemble of\nnatural language generation and retrieval models, including template-based\nmodels, bag-of-words models, sequence-to-sequence neural network and latent\nvariable neural network models. By applying reinforcement learning to\ncrowdsourced data and real-world user interactions, the system has been trained\nto select an appropriate response from the models in its ensemble. The system\nhas been evaluated through A/B testing with real-world users, where it\nperformed significantly better than many competing systems. Due to its machine\nlearning architecture, the system is likely to improve with additional data.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 16:51:09 GMT"}, {"version": "v2", "created": "Sun, 5 Nov 2017 21:02:57 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Serban", "Iulian V.", ""], ["Sankar", "Chinnadhurai", ""], ["Germain", "Mathieu", ""], ["Zhang", "Saizheng", ""], ["Lin", "Zhouhan", ""], ["Subramanian", "Sandeep", ""], ["Kim", "Taesup", ""], ["Pieper", "Michael", ""], ["Chandar", "Sarath", ""], ["Ke", "Nan Rosemary", ""], ["Rajeshwar", "Sai", ""], ["de Brebisson", "Alexandre", ""], ["Sotelo", "Jose M. R.", ""], ["Suhubdy", "Dendi", ""], ["Michalski", "Vincent", ""], ["Nguyen", "Alexandre", ""], ["Pineau", "Joelle", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1709.02357", "submitter": "Adam Derek Cobb", "authors": "Adam D. Cobb, Andrew Markham, Stephen J. Roberts", "title": "Learning from lions: inferring the utility of agents from their\n  trajectories", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build a model using Gaussian processes to infer a spatio-temporal vector\nfield from observed agent trajectories. Significant landmarks or influence\npoints in agent surroundings are jointly derived through vector calculus\noperations that indicate presence of sources and sinks. We evaluate these\ninfluence points by using the Kullback-Leibler divergence between the posterior\nand prior Laplacian of the inferred spatio-temporal vector field. Through\nlocating significant features that influence trajectories, our model aims to\ngive greater insight into underlying causal utility functions that determine\nagent decision-making. A key feature of our model is that it infers a joint\nGaussian process over the observed trajectories, the time-varying vector field\nof utility and canonical vector calculus operators. We apply our model to both\nsynthetic data and lion GPS data collected at the Bubye Valley Conservancy in\nsouthern Zimbabwe.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 17:10:12 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Cobb", "Adam D.", ""], ["Markham", "Andrew", ""], ["Roberts", "Stephen J.", ""]]}, {"id": "1709.02435", "submitter": "Rick Salay", "authors": "Rick Salay, Rodrigo Queiroz, Krzysztof Czarnecki", "title": "An Analysis of ISO 26262: Using Machine Learning Safely in Automotive\n  Software", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) plays an ever-increasing role in advanced automotive\nfunctionality for driver assistance and autonomous operation; however, its\nadequacy from the perspective of safety certification remains controversial. In\nthis paper, we analyze the impacts that the use of ML as an implementation\napproach has on ISO 26262 safety lifecycle and ask what could be done to\naddress them. We then provide a set of recommendations on how to adapt the\nstandard to accommodate ML.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 20:10:56 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Salay", "Rick", ""], ["Queiroz", "Rodrigo", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "1709.02477", "submitter": "Bryan He", "authors": "Paroma Varma, Bryan He, Payal Bajaj, Imon Banerjee, Nishith Khandwala,\n  Daniel L. Rubin, Christopher R\\'e", "title": "Inferring Generative Model Structure with Static Analysis", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining enough labeled data to robustly train complex discriminative models\nis a major bottleneck in the machine learning pipeline. A popular solution is\ncombining multiple sources of weak supervision using generative models. The\nstructure of these models affects training label quality, but is difficult to\nlearn without any ground truth labels. We instead rely on these weak\nsupervision sources having some structure by virtue of being encoded\nprogrammatically. We present Coral, a paradigm that infers generative model\nstructure by statically analyzing the code for these heuristics, thus reducing\nthe data required to learn structure significantly. We prove that Coral's\nsample complexity scales quasilinearly with the number of heuristics and number\nof relations found, improving over the standard sample complexity, which is\nexponential in $n$ for identifying $n^{\\textrm{th}}$ degree relations.\nExperimentally, Coral matches or outperforms traditional structure learning\napproaches by up to 3.81 F1 points. Using Coral to model dependencies instead\nof assuming independence results in better performance than a fully supervised\nmodel by 3.07 accuracy points when heuristics are used to label radiology data\nwithout ground truth labels.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 22:33:37 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Varma", "Paroma", ""], ["He", "Bryan", ""], ["Bajaj", "Payal", ""], ["Banerjee", "Imon", ""], ["Khandwala", "Nishith", ""], ["Rubin", "Daniel L.", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1709.02513", "submitter": "Biswarup Bhattacharya", "authors": "Biswarup Bhattacharya and Abhishek Sinha", "title": "Intelligent Subset Selection of Power Generators for Economic Dispatch", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sustainable and economical generation of electrical power is an essential and\nmandatory component of infrastructure in today's world. Optimal generation\n(generator subset selection) of power requires a careful evaluation of various\nfactors like type of source, generation, transmission & storage capacities,\ncongestion among others which makes this a difficult task. We created a grid to\nsimulate various conditions including stimuli like generator supply, weather\nand load demand using Siemens PSS/E software and this data is trained using\ndeep learning methods and subsequently tested. The results are highly\nencouraging. As per our knowledge, this is the first paper to propose a working\nand scalable deep learning model for this problem.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 02:54:59 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Bhattacharya", "Biswarup", ""], ["Sinha", "Abhishek", ""]]}, {"id": "1709.02555", "submitter": "EPTCS", "authors": "Takumi Akazaki (1), Yoshihiro Kumazawa (1), Ichiro Hasuo (2) ((1)\n  University of Tokyo, (2) National Institute of Informatics)", "title": "Causality-Aided Falsification", "comments": "In Proceedings FVAV 2017, arXiv:1709.02126", "journal-ref": "EPTCS 257, 2017, pp. 3-18", "doi": "10.4204/EPTCS.257.2", "report-no": null, "categories": "cs.SY cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Falsification is drawing attention in quality assurance of heterogeneous\nsystems whose complexities are beyond most verification techniques'\nscalability. In this paper we introduce the idea of causality aid in\nfalsification: by providing a falsification solver -- that relies on stochastic\noptimization of a certain cost function -- with suitable causal information\nexpressed by a Bayesian network, search for a falsifying input value can be\nefficient. Our experiment results show the idea's viability.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 06:34:21 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Akazaki", "Takumi", ""], ["Kumazawa", "Yoshihiro", ""], ["Hasuo", "Ichiro", ""]]}, {"id": "1709.02618", "submitter": "Daniele Francesco Santamaria", "authors": "Claudia Cantale, Domenico Cantone, Manuela Lupica Rinato, Marianna\n  Nicolosi-Asmundo, and Daniele Francesco Santamaria", "title": "The Shape of a Benedictine Monastery: The SaintGall Ontology (Extended\n  Version)", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an OWL 2 ontology representing the Saint Gall plan, one of the\nmost ancient documents arrived intact to us, which describes the ideal model of\na Benedictine monastic complex that inspired the design of many European\nmonasteries.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 09:51:31 GMT"}, {"version": "v2", "created": "Wed, 13 Sep 2017 18:21:38 GMT"}, {"version": "v3", "created": "Fri, 15 Sep 2017 05:30:23 GMT"}, {"version": "v4", "created": "Mon, 18 Sep 2017 11:20:18 GMT"}, {"version": "v5", "created": "Fri, 29 Jun 2018 17:02:32 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Cantale", "Claudia", ""], ["Cantone", "Domenico", ""], ["Rinato", "Manuela Lupica", ""], ["Nicolosi-Asmundo", "Marianna", ""], ["Santamaria", "Daniele Francesco", ""]]}, {"id": "1709.02642", "submitter": "Dmytro Terletskyi", "authors": "Dmytro Terletskyi", "title": "Object-Oriented Knowledge Extraction using Universal Exploiters", "comments": null, "journal-ref": "Proceedings of the XIIth International Scientific and Technical\n  Conference Computer Science and Information Technologies, CSIT-2017, 5-8\n  September, 2017, Lviv, Ukraine, pp. 257-266", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contains analysis and extension of exploiters-based knowledge\nextraction methods, which allow generation of new knowledge, based on the basic\nones. The main achievement of the paper is useful features of some universal\nexploiters proof, which allow extending set of basic classes and set of basic\nrelations by finite set of new classes of objects and relations among them,\nwhich allow creating of complete lattice. Proposed approach gives an\nopportunity to compute quantity of new classes, which can be generated using\nit, and quantity of different types, which each of obtained classes describes;\nconstructing of defined hierarchy of classes with determined subsumption\nrelation; avoidance of some problems of inheritance and more efficient\nrestoring of basic knowledge within the database.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 10:55:15 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Terletskyi", "Dmytro", ""]]}, {"id": "1709.02759", "submitter": "Pedro Almagro-Blanco", "authors": "Pedro Almagro-Blanco, Fernando Sancho-Caparrini", "title": "Semantic Preserving Embeddings for Generalized Graphs", "comments": "Multi-lingual Paper. Main language: English. Additional Language:\n  Spanish. 15 Figures. English: 28 pages. Spanish: 32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new approach to the study of Generalized Graphs as semantic data structures\nusing machine learning techniques is presented. We show how vector\nrepresentations maintaining semantic characteristics of the original data can\nbe obtained from a given graph using neural encoding architectures and\nconsidering the topological properties of the graph. Semantic features of these\nnew representations are tested by using some machine learning tasks and new\ndirections on efficient link discovery, entitity retrieval and long distance\nquery methodologies on large relational datasets are investigated using real\ndatasets.\n  ----\n  En este trabajo se presenta un nuevo enfoque en el contexto del aprendizaje\nautom\\'atico multi-relacional para el estudio de Grafos Generalizados. Se\nmuestra c\\'omo se pueden obtener representaciones vectoriales que mantienen\ncaracter\\'isticas sem\\'anticas del grafo original utilizando codificadores\nneuronales y considerando las propiedades topol\\'ogicas del grafo. Adem\\'as, se\neval\\'uan las caracter\\'isticas sem\\'anticas capturadas por estas nuevas\nrepresentaciones y se investigan nuevas metodolog\\'ias eficientes relacionadas\ncon Link Discovery, Entity Retrieval y consultas a larga distancia en grandes\nconjuntos de datos relacionales haciendo uso de bases de datos reales.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 10:58:37 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Almagro-Blanco", "Pedro", ""], ["Sancho-Caparrini", "Fernando", ""]]}, {"id": "1709.02779", "submitter": "Vedran Dunjko", "authors": "Vedran Dunjko and Hans J. Briegel", "title": "Machine learning \\& artificial intelligence in the quantum domain", "comments": "Review paper. 106 pages. 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum information technologies, and intelligent learning systems, are both\nemergent technologies that will likely have a transforming impact on our\nsociety. The respective underlying fields of research -- quantum information\n(QI) versus machine learning (ML) and artificial intelligence (AI) -- have\ntheir own specific challenges, which have hitherto been investigated largely\nindependently. However, in a growing body of recent work, researchers have been\nprobing the question to what extent these fields can learn and benefit from\neach other. QML explores the interaction between quantum computing and ML,\ninvestigating how results and techniques from one field can be used to solve\nthe problems of the other. Recently, we have witnessed breakthroughs in both\ndirections of influence. For instance, quantum computing is finding a vital\napplication in providing speed-ups in ML, critical in our \"big data\" world.\nConversely, ML already permeates cutting-edge technologies, and may become\ninstrumental in advanced quantum technologies. Aside from quantum speed-up in\ndata analysis, or classical ML optimization used in quantum experiments,\nquantum enhancements have also been demonstrated for interactive learning,\nhighlighting the potential of quantum-enhanced learning agents. Finally, works\nexploring the use of AI for the very design of quantum experiments, and for\nperforming parts of genuine research autonomously, have reported their first\nsuccesses. Beyond the topics of mutual enhancement, researchers have also\nbroached the fundamental issue of quantum generalizations of ML/AI concepts.\nThis deals with questions of the very meaning of learning and intelligence in a\nworld that is described by quantum mechanics. In this review, we describe the\nmain ideas, recent developments, and progress in a broad spectrum of research\ninvestigating machine learning and artificial intelligence in the quantum\ndomain.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 16:53:24 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Dunjko", "Vedran", ""], ["Briegel", "Hans J.", ""]]}, {"id": "1709.02844", "submitter": "Wen Jiang", "authors": "Zhiming Huang, Lin Yang, Wen Jiang", "title": "Uncertainty measurement with belief entropy on interference effect in\n  Quantum-Like Bayesian Networks", "comments": "25 Pages, 7 figures, Revision Submitted to Applied Mathematics and\n  Computations", "journal-ref": null, "doi": "10.1016/j.amc.2018.11.036", "report-no": null, "categories": "cs.AI math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social dilemmas have been regarded as the essence of evolution game theory,\nin which the prisoner's dilemma game is the most famous metaphor for the\nproblem of cooperation. Recent findings revealed people's behavior violated the\nSure Thing Principle in such games. Classic probability methodologies have\ndifficulty explaining the underlying mechanisms of people's behavior. In this\npaper, a novel quantum-like Bayesian Network was proposed to accommodate the\nparadoxical phenomenon. The special network can take interference into\nconsideration, which is likely to be an efficient way to describe the\nunderlying mechanism. With the assistance of belief entropy, named as Deng\nentropy, the paper proposes Belief Distance to render the model practical.\nTested with empirical data, the proposed model is proved to be predictable and\neffective.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 19:53:42 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Huang", "Zhiming", ""], ["Yang", "Lin", ""], ["Jiang", "Wen", ""]]}, {"id": "1709.02865", "submitter": "Alexander Peysakhovich", "authors": "Alexander Peysakhovich and Adam Lerer", "title": "Prosocial learning agents solve generalized Stag Hunts better than\n  selfish ones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has become an important paradigm for constructing\nagents that can enter complex multi-agent situations and improve their policies\nthrough experience. One commonly used technique is reactive training - applying\nstandard RL methods while treating other agents as a part of the learner's\nenvironment. It is known that in general-sum games reactive training can lead\ngroups of agents to converge to inefficient outcomes. We focus on one such\nclass of environments: Stag Hunt games. Here agents either choose a risky\ncooperative policy (which leads to high payoffs if both choose it but low\npayoffs to an agent who attempts it alone) or a safe one (which leads to a safe\npayoff no matter what). We ask how we can change the learning rule of a single\nagent to improve its outcomes in Stag Hunts that include other reactive\nlearners. We extend existing work on reward-shaping in multi-agent\nreinforcement learning and show that that making a single agent prosocial, that\nis, making them care about the rewards of their partners can increase the\nprobability that groups converge to good outcomes. Thus, even if we control a\nsingle agent in a group making that agent prosocial can increase our agent's\nlong-run payoff. We show experimentally that this result carries over to a\nvariety of more complex environments with Stag Hunt-like dynamics including\nones where agents must learn from raw input pixels.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 21:52:58 GMT"}, {"version": "v2", "created": "Fri, 8 Dec 2017 17:55:10 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Peysakhovich", "Alexander", ""], ["Lerer", "Adam", ""]]}, {"id": "1709.02877", "submitter": "Vincent Cicirello", "authors": "Vincent A. Cicirello", "title": "Variable Annealing Length and Parallelism in Simulated Annealing", "comments": "Tenth International Symposium on Combinatorial Search, pages 2-10.\n  June 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose: (a) a restart schedule for an adaptive simulated\nannealer, and (b) parallel simulated annealing, with an adaptive and\nparameter-free annealing schedule. The foundation of our approach is the\nModified Lam annealing schedule, which adaptively controls the temperature\nparameter to track a theoretically ideal rate of acceptance of neighboring\nstates. A sequential implementation of Modified Lam simulated annealing is\nalmost parameter-free. However, it requires prior knowledge of the annealing\nlength. We eliminate this parameter using restarts, with an exponentially\nincreasing schedule of annealing lengths. We then extend this restart schedule\nto parallel implementation, executing several Modified Lam simulated annealers\nin parallel, with varying initial annealing lengths, and our proposed parallel\nannealing length schedule. To validate our approach, we conduct experiments on\nan NP-Hard scheduling problem with sequence-dependent setup constraints. We\ncompare our approach to fixed length restarts, both sequentially and in\nparallel. Our results show that our approach can achieve substantial\nperformance gains, throughout the course of the run, demonstrating our approach\nto be an effective anytime algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 23:05:55 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Cicirello", "Vincent A.", ""]]}, {"id": "1709.02878", "submitter": "Danijar Hafner", "authors": "Danijar Hafner, James Davidson, Vincent Vanhoucke", "title": "TensorFlow Agents: Efficient Batched Reinforcement Learning in\n  TensorFlow", "comments": "White paper, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce TensorFlow Agents, an efficient infrastructure paradigm for\nbuilding parallel reinforcement learning algorithms in TensorFlow. We simulate\nmultiple environments in parallel, and group them to perform the neural network\ncomputation on a batch rather than individual observations. This allows the\nTensorFlow execution engine to parallelize computation, without the need for\nmanual synchronization. Environments are stepped in separate Python processes\nto progress them in parallel without interference of the global interpreter\nlock. As part of this project, we introduce BatchPPO, an efficient\nimplementation of the proximal policy optimization algorithm. By open sourcing\nTensorFlow Agents, we hope to provide a flexible starting point for future\nprojects that accelerates future research in the field.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 23:13:01 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 20:11:05 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Hafner", "Danijar", ""], ["Davidson", "James", ""], ["Vanhoucke", "Vincent", ""]]}, {"id": "1709.03008", "submitter": "Patrick O. Glauner", "authors": "Patrick Glauner, Niklas Dahringer, Oleksandr Puhachov, Jorge Augusto\n  Meira, Petko Valtchev, Radu State, Diogo Duarte", "title": "Identifying Irregular Power Usage by Turning Predictions into\n  Holographic Spatial Visualizations", "comments": "Proceedings of the 17th IEEE International Conference on Data Mining\n  Workshops (ICDMW 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power grids are critical infrastructure assets that face non-technical losses\n(NTL) such as electricity theft or faulty meters. NTL may range up to 40% of\nthe total electricity distributed in emerging countries. Industrial NTL\ndetection systems are still largely based on expert knowledge when deciding\nwhether to carry out costly on-site inspections of customers. Electricity\nproviders are reluctant to move to large-scale deployments of automated systems\nthat learn NTL profiles from data due to the latter's propensity to suggest a\nlarge number of unnecessary inspections. In this paper, we propose a novel\nsystem that combines automated statistical decision making with expert\nknowledge. First, we propose a machine learning framework that classifies\ncustomers into NTL or non-NTL using a variety of features derived from the\ncustomers' consumption data. The methodology used is specifically tailored to\nthe level of noise in the data. Second, in order to allow human experts to feed\ntheir knowledge in the decision loop, we propose a method for visualizing\nprediction results at various granularity levels in a spatial hologram. Our\napproach allows domain experts to put the classification results into the\ncontext of the data and to incorporate their knowledge for making the final\ndecisions of which customers to inspect. This work has resulted in appreciable\nresults on a real-world data set of 3.6M customers. Our system is being\ndeployed in a commercial NTL detection software.\n", "versions": [{"version": "v1", "created": "Sat, 9 Sep 2017 21:27:06 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Glauner", "Patrick", ""], ["Dahringer", "Niklas", ""], ["Puhachov", "Oleksandr", ""], ["Meira", "Jorge Augusto", ""], ["Valtchev", "Petko", ""], ["State", "Radu", ""], ["Duarte", "Diogo", ""]]}, {"id": "1709.03114", "submitter": "Yu. I. Manin", "authors": "Dmitrii Yu. Manin, Yuri I. Manin", "title": "Cognitive networks: brains, internet, and civilizations", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short essay, we discuss some basic features of cognitive activity at\nseveral different space-time scales: from neural networks in the brain to\ncivilizations. One motivation for such comparative study is its heuristic\nvalue. Attempts to better understand the functioning of \"wetware\" involved in\ncognitive activities of central nervous system by comparing it with a computing\ndevice have a long tradition. We suggest that comparison with Internet might be\nmore adequate. We briefly touch upon such subjects as encoding, compression,\nand Saussurean trichotomy langue/langage/parole in various environments.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 15:26:34 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Manin", "Dmitrii Yu.", ""], ["Manin", "Yuri I.", ""]]}, {"id": "1709.03126", "submitter": "Bowen Cheng", "authors": "Bowen Cheng, Zhangyang Wang, Zhaobin Zhang, Zhu Li, Ding Liu, Jianchao\n  Yang, Shuai Huang, Thomas S. Huang", "title": "Robust Emotion Recognition from Low Quality and Low Bit Rate Video: A\n  Deep Learning Approach", "comments": "Accepted by the Seventh International Conference on Affective\n  Computing and Intelligent Interaction (ACII2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion recognition from facial expressions is tremendously useful,\nespecially when coupled with smart devices and wireless multimedia\napplications. However, the inadequate network bandwidth often limits the\nspatial resolution of the transmitted video, which will heavily degrade the\nrecognition reliability. We develop a novel framework to achieve robust emotion\nrecognition from low bit rate video. While video frames are downsampled at the\nencoder side, the decoder is embedded with a deep network model for joint\nsuper-resolution (SR) and recognition. Notably, we propose a novel max-mix\ntraining strategy, leading to a single \"One-for-All\" model that is remarkably\nrobust to a vast range of downsampling factors. That makes our framework well\nadapted for the varied bandwidths in real transmission scenarios, without\nhampering scalability or efficiency. The proposed framework is evaluated on the\nAVEC 2016 benchmark, and demonstrates significantly improved stand-alone\nrecognition performance, as well as rate-distortion (R-D) performance, than\neither directly recognizing from LR frames, or separating SR and recognition.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 16:31:56 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Cheng", "Bowen", ""], ["Wang", "Zhangyang", ""], ["Zhang", "Zhaobin", ""], ["Li", "Zhu", ""], ["Liu", "Ding", ""], ["Yang", "Jianchao", ""], ["Huang", "Shuai", ""], ["Huang", "Thomas S.", ""]]}, {"id": "1709.03136", "submitter": "Vahid Moosavi", "authors": "Vahid Moosavi", "title": "Computational Machines in a Coexistence with Concrete Universals and\n  Data Streams", "comments": null, "journal-ref": "Buhlmann, V., Hovestadt, L., & Moosavi, V. (Eds.). (2015). Coding\n  as Literacy: Metalithic IV (Vol 4). Birkhauser", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss that how the majority of traditional modeling approaches are\nfollowing the idealism point of view in scientific modeling, which follow the\nset theoretical notions of models based on abstract universals. We show that\nwhile successful in many classical modeling domains, there are fundamental\nlimits to the application of set theoretical models in dealing with complex\nsystems with many potential aspects or properties depending on the\nperspectives. As an alternative to abstract universals, we propose a conceptual\nmodeling framework based on concrete universals that can be interpreted as a\ncategory theoretical approach to modeling. We call this modeling framework\npre-specific modeling. We further, discuss how a certain group of mathematical\nand computational methods, along with ever-growing data streams are able to\noperationalize the concept of pre-specific modeling.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 16:57:14 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Moosavi", "Vahid", ""]]}, {"id": "1709.03153", "submitter": "Somil Bansal", "authors": "Somil Bansal, Roberto Calandra, Kurtland Chua, Sergey Levine, Claire\n  Tomlin", "title": "MBMF: Model-Based Priors for Model-Free Reinforcement Learning", "comments": "After we submitted the paper for consideration in CoRL 2017 we found\n  a paper published in the recent past with a similar method (see related work\n  for a discussion). Considering the similarities between the two papers, we\n  have decided to retract our paper from CoRL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning is divided in two main paradigms: model-free and\nmodel-based. Each of these two paradigms has strengths and limitations, and has\nbeen successfully applied to real world domains that are appropriate to its\ncorresponding strengths. In this paper, we present a new approach aimed at\nbridging the gap between these two paradigms. We aim to take the best of the\ntwo paradigms and combine them in an approach that is at the same time\ndata-efficient and cost-savvy. We do so by learning a probabilistic dynamics\nmodel and leveraging it as a prior for the intertwined model-free optimization.\nAs a result, our approach can exploit the generality and structure of the\ndynamics model, but is also capable of ignoring its inevitable inaccuracies, by\ndirectly incorporating the evidence provided by the direct observation of the\ncost. Preliminary results demonstrate that our approach outperforms purely\nmodel-based and model-free approaches, as well as the approach of simply\nswitching from a model-based to a model-free setting.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 18:46:09 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 18:23:24 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Bansal", "Somil", ""], ["Calandra", "Roberto", ""], ["Chua", "Kurtland", ""], ["Levine", "Sergey", ""], ["Tomlin", "Claire", ""]]}, {"id": "1709.03221", "submitter": "Yuriy Brun", "authors": "Sainyam Galhotra, Yuriy Brun, Alexandra Meliou", "title": "Fairness Testing: Testing Software for Discrimination", "comments": "Sainyam Galhotra, Yuriy Brun, and Alexandra Meliou. 2017. Fairness\n  Testing: Testing Software for Discrimination. In Proceedings of 2017 11th\n  Joint Meeting of the European Software Engineering Conference and the ACM\n  SIGSOFT Symposium on the Foundations of Software Engineering (ESEC/FSE),\n  Paderborn, Germany, September 4-8, 2017 (ESEC/FSE'17).\n  https://doi.org/10.1145/3106237.3106277, ESEC/FSE, 2017", "journal-ref": null, "doi": "10.1145/3106237.3106277", "report-no": null, "categories": "cs.SE cs.AI cs.CY cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines software fairness and discrimination and develops a\ntesting-based method for measuring if and how much software discriminates,\nfocusing on causality in discriminatory behavior. Evidence of software\ndiscrimination has been found in modern software systems that recommend\ncriminal sentences, grant access to financial products, and determine who is\nallowed to participate in promotions. Our approach, Themis, generates efficient\ntest suites to measure discrimination. Given a schema describing valid system\ninputs, Themis generates discrimination tests automatically and does not\nrequire an oracle. We evaluate Themis on 20 software systems, 12 of which come\nfrom prior work with explicit focus on avoiding discrimination. We find that\n(1) Themis is effective at discovering software discrimination, (2)\nstate-of-the-art techniques for removing discrimination from algorithms fail in\nmany situations, at times discriminating against as much as 98% of an input\nsubdomain, (3) Themis optimizations are effective at producing efficient test\nsuites for measuring discrimination, and (4) Themis is more efficient on\nsystems that exhibit more discrimination. We thus demonstrate that fairness\ntesting is a critical aspect of the software development cycle in domains with\npossible discrimination and provide initial tools for measuring software\ndiscrimination.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 02:45:22 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Galhotra", "Sainyam", ""], ["Brun", "Yuriy", ""], ["Meliou", "Alexandra", ""]]}, {"id": "1709.03239", "submitter": "Xuan Peng", "authors": "Xuan Peng, Xunzhang Gao, Xiang Li", "title": "On better training the infinite restricted Boltzmann machines", "comments": "Submitted to Machine Learning", "journal-ref": null, "doi": "10.1007/s10994-018-5696-2", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The infinite restricted Boltzmann machine (iRBM) is an extension of the\nclassic RBM. It enjoys a good property of automatically deciding the size of\nthe hidden layer according to specific training data. With sufficient training,\nthe iRBM can achieve a competitive performance with that of the classic RBM.\nHowever, the convergence of learning the iRBM is slow, due to the fact that the\niRBM is sensitive to the ordering of its hidden units, the learned filters\nchange slowly from the left-most hidden unit to right. To break this dependency\nbetween neighboring hidden units and speed up the convergence of training, a\nnovel training strategy is proposed. The key idea of the proposed training\nstrategy is randomly regrouping the hidden units before each gradient descent\nstep. Potentially, a mixing of infinite many iRBMs with different permutations\nof the hidden units can be achieved by this learning method, which has a\nsimilar effect of preventing the model from over-fitting as the dropout. The\noriginal iRBM is also modified to be capable of carrying out discriminative\ntraining. To evaluate the impact of our method on convergence speed of learning\nand the model's generalization ability, several experiments have been performed\non the binarized MNIST and CalTech101 Silhouettes datasets. Experimental\nresults indicate that the proposed training strategy can greatly accelerate\nlearning and enhance generalization ability of iRBMs.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 04:41:06 GMT"}, {"version": "v2", "created": "Sat, 14 Oct 2017 19:05:55 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Peng", "Xuan", ""], ["Gao", "Xunzhang", ""], ["Li", "Xiang", ""]]}, {"id": "1709.03267", "submitter": "Thomas Guyet", "authors": "Thomas Guyet (LACODAM), Ren\\'e Quiniou (LACODAM, Inria), V\\'eronique\n  Masson (UR1, LACODAM)", "title": "Mining relevant interval rules", "comments": "International Conference on Formal Concept Analysis, Jun 2017,\n  Rennes, France. Supplementary proceedings of International Conference on\n  Formal Concept Analysis (ICFCA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article extends the method of Garriga et al. for mining relevant rules\nto numerical attributes by extracting interval-based pattern rules. We propose\nan algorithm that extracts such rules from numerical datasets using the\ninterval-pattern approach from Kaytoue et al. This algorithm has been\nimplemented and evaluated on real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 07:18:58 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Guyet", "Thomas", "", "LACODAM"], ["Quiniou", "Ren\u00e9", "", "LACODAM, Inria"], ["Masson", "V\u00e9ronique", "", "UR1, LACODAM"]]}, {"id": "1709.03270", "submitter": "Thomas Guyet", "authors": "Ahmed Samet (UR1, LACODAM), Thomas Guyet (LACODAM), Benjamin\n  Negrevergne (LAMSADE), Tien-Tuan Dao, Tuan Nha Hoang, Marie-Christine Ho Ba\n  Tho", "title": "Expert Opinion Extraction from a Biomedical Database", "comments": null, "journal-ref": "Conference on Symbolic and Quantitative Approaches to Reasoning\n  with Uncertainty (ECSQARU), Jul 2017, Lugano, Switzerland. Springer, 31 (LNCS\n  10369), pp.1 - 12, 2017, Proceedings of 14th European Conference on Symbolic\n  and Quantitative Approaches to Reasoning with Uncertainty", "doi": "10.1016/S0888-613X(02)00066-X", "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle the problem of extracting frequent opinions from\nuncertain databases. We introduce the foundation of an opinion mining approach\nwith the definition of pattern and support measure. The support measure is\nderived from the commitment definition. A new algorithm called OpMiner that\nextracts the set of frequent opinions modelled as a mass functions is detailed.\nFinally, we apply our approach on a real-world biomedical database that stores\nopinions of experts to evaluate the reliability level of biomedical data.\nPerformance analysis showed a better quality patterns for our proposed model in\ncomparison with literature-based methods.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 07:23:00 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Samet", "Ahmed", "", "UR1, LACODAM"], ["Guyet", "Thomas", "", "LACODAM"], ["Negrevergne", "Benjamin", "", "LAMSADE"], ["Dao", "Tien-Tuan", ""], ["Hoang", "Tuan Nha", ""], ["Tho", "Marie-Christine Ho Ba", ""]]}, {"id": "1709.03297", "submitter": "Giuseppe Vizzari", "authors": "Luca Crociani, Gregor L\\\"ammel, H. Joon Park, Giuseppe Vizzari", "title": "Cellular Automaton Based Simulation of Large Pedestrian Facilities - A\n  Case Study on the Staten Island Ferry Terminals", "comments": "96th Transportation Research Board annual meeting, Washington,\n  January 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current metropolises largely depend on a functioning transport infrastructure\nand the increasing demand can only be satisfied by a well organized mass\ntransit. One example for a crucial mass transit system is New York City's\nStaten Island Ferry, connecting the two boroughs of Staten Island and Manhattan\nwith a regular passenger service. Today's demand already exceeds 2500\npassengers for a single cycle during peek hours, and future projections suggest\nthat it will further increase. One way to appraise how the system will cope\nwith future demand is by simulation. This contribution proposes an integrated\nsimulation approach to evaluate the system performance with respect to future\ndemand. The simulation relies on a multiscale modeling approach where the\nterminal buildings are simulated by a microscopic and quantitatively valid\ncellular automata (CA) and the journeys of the ferries themselves are modeled\nby a mesoscopic queue simulation approach. Based on the simulation results\nrecommendations with respect to the future demand are given.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 08:48:19 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Crociani", "Luca", ""], ["L\u00e4mmel", "Gregor", ""], ["Park", "H. Joon", ""], ["Vizzari", "Giuseppe", ""]]}, {"id": "1709.03309", "submitter": "Yann Dauxais", "authors": "Yann Dauxais (UR1, LACODAM), Thomas Guyet (LACODAM), David\n  Gross-Amblard (DRUID), Andr\\'e Happe", "title": "Discriminant chronicles mining: Application to care pathways analytics", "comments": "Artificial Intelligence in Medicine, Jun 2017, Vienna, Austria. 2017,\n  16th Conference on Artificial Intelligence in Medicine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pharmaco-epidemiology (PE) is the study of uses and effects of drugs in well\ndefined populations. As medico-administrative databases cover a large part of\nthe population, they have become very interesting to carry PE studies. Such\ndatabases provide longitudinal care pathways in real condition containing\ntimestamped care events, especially drug deliveries. Temporal pattern mining\nbecomes a strategic choice to gain valuable insights about drug uses. In this\npaper we propose DCM, a new discriminant temporal pattern mining algorithm. It\nextracts chronicle patterns that occur more in a studied population than in a\ncontrol population. We present results on the identification of possible\nassociations between hospitalizations for seizure and anti-epileptic drug\nswitches in care pathway of epileptic patients.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 09:37:07 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Dauxais", "Yann", "", "UR1, LACODAM"], ["Guyet", "Thomas", "", "LACODAM"], ["Gross-Amblard", "David", "", "DRUID"], ["Happe", "Andr\u00e9", ""]]}, {"id": "1709.03339", "submitter": "Riccardo Polvara", "authors": "Riccardo Polvara, Massimiliano Patacchiola, Sanjay Sharma, Jian Wan,\n  Andrew Manning, Robert Sutton, Angelo Cangelosi", "title": "Autonomous Quadrotor Landing using Deep Reinforcement Learning", "comments": "The actual copy of the manuscript is a revised version resubmitted to\n  IROS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Landing an unmanned aerial vehicle (UAV) on a ground marker is an open\nproblem despite the effort of the research community. Previous attempts mostly\nfocused on the analysis of hand-crafted geometric features and the use of\nexternal sensors in order to allow the vehicle to approach the land-pad. In\nthis article, we propose a method based on deep reinforcement learning that\nonly requires low-resolution images taken from a down-looking camera in order\nto identify the position of the marker and land the UAV on it. The proposed\napproach is based on a hierarchy of Deep Q-Networks (DQNs) used as high-level\ncontrol policy for the navigation toward the marker. We implemented different\ntechnical solutions, such as the combination of vanilla and double DQNs, and a\npartitioned buffer replay. Using domain randomization we trained the vehicle on\nuniform textures and we tested it on a large variety of simulated and\nreal-world environments. The overall performance is comparable with a\nstate-of-the-art algorithm and human pilots.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 11:39:47 GMT"}, {"version": "v2", "created": "Wed, 6 Dec 2017 11:00:21 GMT"}, {"version": "v3", "created": "Tue, 27 Feb 2018 10:14:24 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Polvara", "Riccardo", ""], ["Patacchiola", "Massimiliano", ""], ["Sharma", "Sanjay", ""], ["Wan", "Jian", ""], ["Manning", "Andrew", ""], ["Sutton", "Robert", ""], ["Cangelosi", "Angelo", ""]]}, {"id": "1709.03363", "submitter": "David Tolpin", "authors": "Alexandre Cukier, Ronen I. Brafman, Yotam Perkal, David Tolpin", "title": "A Planning Approach to Monitoring Behavior of Computer Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel approach to monitoring high level behaviors using\nconcepts from AI planning. Our goal is to understand what a program is doing\nbased on its system call trace. This ability is particularly important for\ndetecting malware. We approach this problem by building an abstract model of\nthe operating system using the STRIPS planning language, casting system calls\nas planning operators. Given a system call trace, we simulate the corresponding\noperators on our model and by observing the properties of the state reached, we\nlearn about the nature of the original program and its behavior. Thus, unlike\nmost statistical detection methods that focus on syntactic features, our\napproach is semantic in nature. Therefore, it is more robust against\nobfuscation techniques used by malware that change the outward appearance of\nthe trace but not its effect. We demonstrate the efficacy of our approach by\nevaluating it on actual system call traces.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 13:19:08 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Cukier", "Alexandre", ""], ["Brafman", "Ronen I.", ""], ["Perkal", "Yotam", ""], ["Tolpin", "David", ""]]}, {"id": "1709.03413", "submitter": "Eray Ozkural", "authors": "Eray \\\"Ozkural", "title": "Gigamachine: incremental machine learning on desktop computers", "comments": "This is the original submission for my AGI-2010 paper titled\n  Stochastic Grammar Based Incremental Machine Learning Using Scheme which may\n  be found on http://agi-conf.org/2010/wp-content/uploads/2009/06/paper_24.pdf\n  and presented a partial but general solution to the transfer learning problem\n  in AI. arXiv admin note: substantial text overlap with arXiv:1103.1003", "journal-ref": "Artificial General Intelligence 2010, p. 190", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a concrete design for Solomonoff's incremental machine learning\nsystem suitable for desktop computers. We use R5RS Scheme and its standard\nlibrary with a few omissions as the reference machine. We introduce a Levin\nSearch variant based on a stochastic Context Free Grammar together with new\nupdate algorithms that use the same grammar as a guiding probability\ndistribution for incremental machine learning. The updates include adjusting\nproduction probabilities, re-using previous solutions, learning programming\nidioms and discovery of frequent subprograms. The issues of extending the a\npriori probability distribution and bootstrapping are discussed. We have\nimplemented a good portion of the proposed algorithms. Experiments with toy\nproblems show that the update algorithms work as expected.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 17:39:26 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["\u00d6zkural", "Eray", ""]]}, {"id": "1709.03450", "submitter": "Mario Amrehn", "authors": "Mario Amrehn, Sven Gaube, Mathias Unberath, Frank Schebesch, Tim Horz,\n  Maddalena Strumia, Stefan Steidl, Markus Kowarschik, Andreas Maier", "title": "UI-Net: Interactive Artificial Neural Networks for Iterative Image\n  Segmentation Based on a User Model", "comments": "This work is submitted to the 2017 Eurographics Workshop on Visual\n  Computing for Biology and Medicine", "journal-ref": "Eurographics Workshop on Visual Computing for Biology and Medicine\n  (2017) 143-147", "doi": "10.2312/vcbm.20171248", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For complex segmentation tasks, fully automatic systems are inherently\nlimited in their achievable accuracy for extracting relevant objects.\nEspecially in cases where only few data sets need to be processed for a highly\naccurate result, semi-automatic segmentation techniques exhibit a clear benefit\nfor the user. One area of application is medical image processing during an\nintervention for a single patient. We propose a learning-based cooperative\nsegmentation approach which includes the computing entity as well as the user\ninto the task. Our system builds upon a state-of-the-art fully convolutional\nartificial neural network (FCN) as well as an active user model for training.\nDuring the segmentation process, a user of the trained system can iteratively\nadd additional hints in form of pictorial scribbles as seed points into the FCN\nsystem to achieve an interactive and precise segmentation result. The\nsegmentation quality of interactive FCNs is evaluated. Iterative FCN approaches\ncan yield superior results compared to networks without the user input channel\ncomponent, due to a consistent improvement in segmentation quality after each\ninteraction.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 15:50:24 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Amrehn", "Mario", ""], ["Gaube", "Sven", ""], ["Unberath", "Mathias", ""], ["Schebesch", "Frank", ""], ["Horz", "Tim", ""], ["Strumia", "Maddalena", ""], ["Steidl", "Stefan", ""], ["Kowarschik", "Markus", ""], ["Maier", "Andreas", ""]]}, {"id": "1709.03456", "submitter": "Jawad Tayyub", "authors": "Jawad Tayyub, Majd Hawasly, David C. Hogg and Anthony G. Cohn", "title": "CLAD: A Complex and Long Activities Dataset with Rich Crowdsourced\n  Annotations", "comments": null, "journal-ref": null, "doi": "10.5518/249", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel activity dataset which exhibits real-life and\ndiverse scenarios of complex, temporally-extended human activities and actions.\nThe dataset presents a set of videos of actors performing everyday activities\nin a natural and unscripted manner. The dataset was recorded using a static\nKinect 2 sensor which is commonly used on many robotic platforms. The dataset\ncomprises of RGB-D images, point cloud data, automatically generated skeleton\ntracks in addition to crowdsourced annotations. Furthermore, we also describe\nthe methodology used to acquire annotations through crowdsourcing. Finally some\nactivity recognition benchmarks are presented using current state-of-the-art\ntechniques. We believe that this dataset is particularly suitable as a testbed\nfor activity recognition research but it can also be applicable for other\ncommon tasks in robotics/computer vision research such as object detection and\nhuman skeleton tracking.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 16:01:17 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 16:52:04 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Tayyub", "Jawad", ""], ["Hawasly", "Majd", ""], ["Hogg", "David C.", ""], ["Cohn", "Anthony G.", ""]]}, {"id": "1709.03480", "submitter": "Nicolas A. Barriga", "authors": "Nicolas A. Barriga, Marius Stanescu and Michael Buro", "title": "Combining Strategic Learning and Tactical Search in Real-Time Strategy\n  Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A commonly used technique for managing AI complexity in real-time strategy\n(RTS) games is to use action and/or state abstractions. High-level abstractions\ncan often lead to good strategic decision making, but tactical decision quality\nmay suffer due to lost details. A competing method is to sample the search\nspace which often leads to good tactical performance in simple scenarios, but\npoor high-level planning.\n  We propose to use a deep convolutional neural network (CNN) to select among a\nlimited set of abstract action choices, and to utilize the remaining\ncomputation time for game tree search to improve low level tactics. The CNN is\ntrained by supervised learning on game states labelled by Puppet Search, a\nstrategic search algorithm that uses action abstractions. The network is then\nused to select a script --- an abstract action --- to produce low level actions\nfor all units. Subsequently, the game tree search algorithm improves the\ntactical actions of a subset of units using a limited view of the game state\nonly considering units close to opponent units.\n  Experiments in the microRTS game show that the combined algorithm results in\nhigher win-rates than either of its two independent components and other\nstate-of-the-art microRTS agents.\n  To the best of our knowledge, this is the first successful application of a\nconvolutional network to play a full RTS game on standard game maps, as\nprevious work has focused on sub-problems, such as combat, or on very small\nmaps.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 17:17:51 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Barriga", "Nicolas A.", ""], ["Stanescu", "Marius", ""], ["Buro", "Michael", ""]]}, {"id": "1709.03582", "submitter": "Valentin Khrulkov", "authors": "Valentin Khrulkov and Ivan Oseledets", "title": "Art of singular vectors and universal adversarial perturbations", "comments": "Submitted to CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vulnerability of Deep Neural Networks (DNNs) to adversarial attacks has been\nattracting a lot of attention in recent studies. It has been shown that for\nmany state of the art DNNs performing image classification there exist\nuniversal adversarial perturbations --- image-agnostic perturbations mere\naddition of which to natural images with high probability leads to their\nmisclassification. In this work we propose a new algorithm for constructing\nsuch universal perturbations. Our approach is based on computing the so-called\n$(p, q)$-singular vectors of the Jacobian matrices of hidden layers of a\nnetwork. Resulting perturbations present interesting visual patterns, and by\nusing only 64 images we were able to construct universal perturbations with\nmore than 60 \\% fooling rate on the dataset consisting of 50000 images. We also\ninvestigate a correlation between the maximal singular value of the Jacobian\nmatrix and the fooling rate of the corresponding singular vector, and show that\nthe constructed perturbations generalize across networks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 20:22:37 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 03:09:07 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Khrulkov", "Valentin", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1709.03625", "submitter": "AmirEmad Ghassami", "authors": "AmirEmad Ghassami, Saber Salehkaleybar, Negar Kiyavash, Elias\n  Bareinboim", "title": "Budgeted Experiment Design for Causal Structure Learning", "comments": null, "journal-ref": "35th International Conference on Machine Learning (ICML), PMLR\n  80:1719-1728, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of causal structure learning when the experimenter is\nlimited to perform at most $k$ non-adaptive experiments of size $1$. We\nformulate the problem of finding the best intervention target set as an\noptimization problem, which aims to maximize the average number of edges whose\ndirections are resolved. We prove that the corresponding objective function is\nsubmodular and a greedy algorithm suffices to achieve\n$(1-\\frac{1}{e})$-approximation of the optimal value. We further present an\naccelerated variant of the greedy algorithm, which can lead to orders of\nmagnitude performance speedup. We validate our proposed approach on synthetic\nand real graphs. The results show that compared to the purely observational\nsetting, our algorithm orients the majority of the edges through a considerably\nsmall number of interventions.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 23:43:30 GMT"}, {"version": "v2", "created": "Sun, 29 Jul 2018 21:56:06 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Ghassami", "AmirEmad", ""], ["Salehkaleybar", "Saber", ""], ["Kiyavash", "Negar", ""], ["Bareinboim", "Elias", ""]]}, {"id": "1709.03683", "submitter": "Yan Zhao", "authors": "Yan Zhao, Xiao Fang, David Simchi-Levi", "title": "A Practically Competitive and Provably Consistent Algorithm for Uplift\n  Modeling", "comments": "Accepted by 2017 IEEE International Conference on Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized experiments have been critical tools of decision making for\ndecades. However, subjects can show significant heterogeneity in response to\ntreatments in many important applications. Therefore it is not enough to simply\nknow which treatment is optimal for the entire population. What we need is a\nmodel that correctly customize treatment assignment base on subject\ncharacteristics. The problem of constructing such models from randomized\nexperiments data is known as Uplift Modeling in the literature. Many algorithms\nhave been proposed for uplift modeling and some have generated promising\nresults on various data sets. Yet little is known about the theoretical\nproperties of these algorithms. In this paper, we propose a new tree-based\nensemble algorithm for uplift modeling. Experiments show that our algorithm can\nachieve competitive results on both synthetic and industry-provided data. In\naddition, by properly tuning the \"node size\" parameter, our algorithm is proved\nto be consistent under mild regularity conditions. This is the first consistent\nalgorithm for uplift modeling that we are aware of.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 03:49:57 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Zhao", "Yan", ""], ["Fang", "Xiao", ""], ["Simchi-Levi", "David", ""]]}, {"id": "1709.03714", "submitter": "Cheng Wang", "authors": "Cheng Wang", "title": "RRA: Recurrent Residual Attention for Sequence Learning", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a recurrent neural network (RNN) with residual\nattention (RRA) to learn long-range dependencies from sequential data. We\npropose to add residual connections across timesteps to RNN, which explicitly\nenhances the interaction between current state and hidden states that are\nseveral timesteps apart. This also allows training errors to be directly\nback-propagated through residual connections and effectively alleviates\ngradient vanishing problem. We further reformulate an attention mechanism over\nresidual connections. An attention gate is defined to summarize the individual\ncontribution from multiple previous hidden states in computing the current\nstate. We evaluate RRA on three tasks: the adding problem, pixel-by-pixel MNIST\nclassification and sentiment analysis on the IMDB dataset. Our experiments\ndemonstrate that RRA yields better performance, faster convergence and more\nstable training compared to a standard LSTM network. Furthermore, RRA shows\nhighly competitive performance to the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 07:39:43 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Wang", "Cheng", ""]]}, {"id": "1709.03854", "submitter": "Ivan Olier", "authors": "Ivan Olier, Noureddin Sadawi, G. Richard Bickerton, Joaquin\n  Vanschoren, Crina Grosan, Larisa Soldatova and Ross D. King", "title": "Meta-QSAR: a large-scale application of meta-learning to drug design and\n  discovery", "comments": "33 pages and 15 figures. Manuscript accepted for publication in\n  Machine Learning Journal. This is the author's pre-print version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the learning of quantitative structure activity relationships\n(QSARs) as a case-study of meta-learning. This application area is of the\nhighest societal importance, as it is a key step in the development of new\nmedicines. The standard QSAR learning problem is: given a target (usually a\nprotein) and a set of chemical compounds (small molecules) with associated\nbioactivities (e.g. inhibition of the target), learn a predictive mapping from\nmolecular representation to activity. Although almost every type of machine\nlearning method has been applied to QSAR learning there is no agreed single\nbest way of learning QSARs, and therefore the problem area is well-suited to\nmeta-learning. We first carried out the most comprehensive ever comparison of\nmachine learning methods for QSAR learning: 18 regression methods, 6 molecular\nrepresentations, applied to more than 2,700 QSAR problems. (These results have\nbeen made publicly available on OpenML and represent a valuable resource for\ntesting novel meta-learning methods.) We then investigated the utility of\nalgorithm selection for QSAR problems. We found that this meta-learning\napproach outperformed the best individual QSAR learning method (random forests\nusing a molecular fingerprint representation) by up to 13%, on average. We\nconclude that meta-learning outperforms base-learning methods for QSAR\nlearning, and as this investigation is one of the most extensive ever\ncomparisons of base and meta-learning methods ever made, it provides evidence\nfor the general effectiveness of meta-learning over base-learning.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 14:07:13 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Olier", "Ivan", ""], ["Sadawi", "Noureddin", ""], ["Bickerton", "G. Richard", ""], ["Vanschoren", "Joaquin", ""], ["Grosan", "Crina", ""], ["Soldatova", "Larisa", ""], ["King", "Ross D.", ""]]}, {"id": "1709.03879", "submitter": "Eray Ozkural", "authors": "Eray \\\"Ozkural", "title": "Ultimate Intelligence Part III: Measures of Intelligence, Perception and\n  Intelligent Agents", "comments": "Third installation of the Ultimate Intelligence series. Submitted to\n  AGI-2017. arXiv admin note: text overlap with arXiv:1504.03303", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose that operator induction serves as an adequate model of perception.\nWe explain how to reduce universal agent models to operator induction. We\npropose a universal measure of operator induction fitness, and show how it can\nbe used in a reinforcement learning model and a homeostasis (self-preserving)\nagent based on the free energy principle. We show that the action of the\nhomeostasis agent can be explained by the operator induction model.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 17:45:30 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["\u00d6zkural", "Eray", ""]]}, {"id": "1709.03915", "submitter": "Wilhelmiina H\\\"am\\\"al\\\"ainen", "authors": "Wilhelmiina H\\\"am\\\"al\\\"ainen and Geoffrey I. Webb", "title": "Specious rules: an efficient and effective unifying method for removing\n  misleading and uninformative patterns in association rule mining", "comments": "Note: This is a corrected version of the paper published in SDM'17.\n  In the equation on page 4, the range of the sum has been corrected", "journal-ref": "Proceedings of SIAM International Conference on Data Mining, pp.\n  309-317, SIAM 2017", "doi": "10.1137/1.9781611974973.35", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present theoretical analysis and a suite of tests and procedures for\naddressing a broad class of redundant and misleading association rules we call\n\\emph{specious rules}. Specious dependencies, also known as \\emph{spurious},\n\\emph{apparent}, or \\emph{illusory associations}, refer to a well-known\nphenomenon where marginal dependencies are merely products of interactions with\nother variables and disappear when conditioned on those variables.\n  The most extreme example is Yule-Simpson's paradox where two variables\npresent positive dependence in the marginal contingency table but negative in\nall partial tables defined by different levels of a confounding factor. It is\naccepted wisdom that in data of any nontrivial dimensionality it is infeasible\nto control for all of the exponentially many possible confounds of this nature.\nIn this paper, we consider the problem of specious dependencies in the context\nof statistical association rule mining. We define specious rules and show they\noffer a unifying framework which covers many types of previously proposed\nredundant or misleading association rules. After theoretical analysis, we\nintroduce practical algorithms for detecting and pruning out specious\nassociation rules efficiently under many key goodness measures, including\nmutual information and exact hypergeometric probabilities. We demonstrate that\nthe procedure greatly reduces the number of associations discovered, providing\nan elegant and effective solution to the problem of association mining\ndiscovering large numbers of misleading and redundant rules.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 15:39:47 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["H\u00e4m\u00e4l\u00e4inen", "Wilhelmiina", ""], ["Webb", "Geoffrey I.", ""]]}, {"id": "1709.03919", "submitter": "Boyi Li", "authors": "Boyi Li and Xiulian Peng and Zhangyang Wang and Jizheng Xu and Dan\n  Feng", "title": "End-to-End United Video Dehazing and Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent development of CNN-based image dehazing has revealed the\neffectiveness of end-to-end modeling. However, extending the idea to end-to-end\nvideo dehazing has not been explored yet. In this paper, we propose an\nEnd-to-End Video Dehazing Network (EVD-Net), to exploit the temporal\nconsistency between consecutive video frames. A thorough study has been\nconducted over a number of structure options, to identify the best temporal\nfusion strategy. Furthermore, we build an End-to-End United Video Dehazing and\nDetection Network(EVDD-Net), which concatenates and jointly trains EVD-Net with\na video object detection model. The resulting augmented end-to-end pipeline has\ndemonstrated much more stable and accurate detection results in hazy video.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 15:43:28 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Li", "Boyi", ""], ["Peng", "Xiulian", ""], ["Wang", "Zhangyang", ""], ["Xu", "Jizheng", ""], ["Feng", "Dan", ""]]}, {"id": "1709.03946", "submitter": "Nikhita Vedula", "authors": "Nikhita Vedula, Wei Sun, Hyunhwan Lee, Harsh Gupta, Mitsunori Ogihara,\n  Joseph Johnson, Gang Ren, Srinivasan Parthasarathy", "title": "Multimodal Content Analysis for Effective Advertisements on YouTube", "comments": "11 pages, 5 figures, ICDM 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid advances in e-commerce and Web 2.0 technologies have greatly\nincreased the impact of commercial advertisements on the general public. As a\nkey enabling technology, a multitude of recommender systems exists which\nanalyzes user features and browsing patterns to recommend appealing\nadvertisements to users. In this work, we seek to study the characteristics or\nattributes that characterize an effective advertisement and recommend a useful\nset of features to aid the designing and production processes of commercial\nadvertisements. We analyze the temporal patterns from multimedia content of\nadvertisement videos including auditory, visual and textual components, and\nstudy their individual roles and synergies in the success of an advertisement.\nThe objective of this work is then to measure the effectiveness of an\nadvertisement, and to recommend a useful set of features to advertisement\ndesigners to make it more successful and approachable to users. Our proposed\nframework employs the signal processing technique of cross modality feature\nlearning where data streams from different components are employed to train\nseparate neural network models and are then fused together to learn a shared\nrepresentation. Subsequently, a neural network model trained on this joint\nfeature embedding representation is utilized as a classifier to predict\nadvertisement effectiveness. We validate our approach using subjective ratings\nfrom a dedicated user study, the sentiment strength of online viewer comments,\nand a viewer opinion metric of the ratio of the Likes and Views received by\neach advertisement from an online platform.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 16:47:21 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Vedula", "Nikhita", ""], ["Sun", "Wei", ""], ["Lee", "Hyunhwan", ""], ["Gupta", "Harsh", ""], ["Ogihara", "Mitsunori", ""], ["Johnson", "Joseph", ""], ["Ren", "Gang", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "1709.03968", "submitter": "Nabiha Asghar", "authors": "Nabiha Asghar, Pascal Poupart, Jesse Hoey, Xin Jiang, Lili Mou", "title": "Affective Neural Response Generation", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing neural conversational models process natural language primarily on a\nlexico-syntactic level, thereby ignoring one of the most crucial components of\nhuman-to-human dialogue: its affective content. We take a step in this\ndirection by proposing three novel ways to incorporate affective/emotional\naspects into long short term memory (LSTM) encoder-decoder neural conversation\nmodels: (1) affective word embeddings, which are cognitively engineered, (2)\naffect-based objective functions that augment the standard cross-entropy loss,\nand (3) affectively diverse beam search for decoding. Experiments show that\nthese techniques improve the open-domain conversational prowess of\nencoder-decoder networks by enabling them to produce emotionally rich responses\nthat are more interesting and natural.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 17:41:30 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Asghar", "Nabiha", ""], ["Poupart", "Pascal", ""], ["Hoey", "Jesse", ""], ["Jiang", "Xin", ""], ["Mou", "Lili", ""]]}, {"id": "1709.03969", "submitter": "Zhiyu Lin", "authors": "Zhiyu Lin, Brent Harrison, Aaron Keech, and Mark O. Riedl", "title": "Explore, Exploit or Listen: Combining Human Feedback and Policy Model to\n  Speed up Deep Reinforcement Learning in 3D Worlds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method to use discrete human feedback to enhance the\nperformance of deep learning agents in virtual three-dimensional environments\nby extending deep-reinforcement learning to model the confidence and\nconsistency of human feedback. This enables deep reinforcement learning\nalgorithms to determine the most appropriate time to listen to the human\nfeedback, exploit the current policy model, or explore the agent's environment.\nManaging the trade-off between these three strategies allows DRL agents to be\nrobust to inconsistent or intermittent human feedback. Through experimentation\nusing a synthetic oracle, we show that our technique improves the training\nspeed and overall performance of deep reinforcement learning in navigating\nthree-dimensional environments using Minecraft. We further show that our\ntechnique is robust to highly innacurate human feedback and can also operate\nwhen no human feedback is given.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 17:42:21 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 20:27:31 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Lin", "Zhiyu", ""], ["Harrison", "Brent", ""], ["Keech", "Aaron", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1709.03980", "submitter": "Wen Zhang", "authors": "Wen Zhang, Jiawei Hu, Yang Feng, Qun Liu", "title": "Refining Source Representations with Relation Networks for Neural\n  Machine Translation", "comments": "i am planned to improve my experiments and modified our paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural machine translation (NMT) with the encoder-decoder framework\nhas achieved great success in recent times, it still suffers from some\ndrawbacks: RNNs tend to forget old information which is often useful and the\nencoder only operates through words without considering word relationship. To\nsolve these problems, we introduce a relation networks (RN) into NMT to refine\nthe encoding representations of the source. In our method, the RN first\naugments the representation of each source word with its neighbors and reasons\nall the possible pairwise relations between them. Then the source\nrepresentations and all the relations are fed to the attention module and the\ndecoder together, keeping the main encoder-decoder architecture unchanged.\nExperiments on two Chinese-to-English data sets in different scales both show\nthat our method can outperform the competitive baselines significantly.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 13:38:11 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 08:20:13 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 13:36:08 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Zhang", "Wen", ""], ["Hu", "Jiawei", ""], ["Feng", "Yang", ""], ["Liu", "Qun", ""]]}, {"id": "1709.03981", "submitter": "Richard Pettigrew", "authors": "Richard Pettigrew", "title": "Aggregating incoherent agents who disagree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore how we should aggregate the degrees of belief of of\na group of agents to give a single coherent set of degrees of belief, when at\nleast some of those agents might be probabilistically incoherent. There are a\nnumber of way of aggregating degrees of belief, and there are a number of ways\nof fixing incoherent degrees of belief. When we have picked one of each, should\nwe aggregate first and then fix, or fix first and then aggregate? Or should we\ntry to do both at once? And when do these different procedures agree with one\nanother? In this paper, we focus particularly on the final question.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 17:38:42 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Pettigrew", "Richard", ""]]}, {"id": "1709.04029", "submitter": "Subhash Kak", "authors": "Subhash Kak", "title": "Probability Reversal and the Disjunction Effect in Reasoning Systems", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data based judgments go into artificial intelligence applications but they\nundergo paradoxical reversal when seemingly unnecessary additional data is\nprovided. Examples of this are Simpson's reversal and the disjunction effect\nwhere the beliefs about the data change once it is presented or aggregated\ndifferently. Sometimes the significance of the difference can be evaluated\nusing statistical tests such as Pearson's chi-squared or Fisher's exact test,\nbut this may not be helpful in threshold-based decision systems that operate\nwith incomplete information. To mitigate risks in the use of algorithms in\ndecision-making, we consider the question of modeling of beliefs. We argue that\nevidence supports that beliefs are not classical statistical variables and they\nshould, in the general case, be considered as superposition states of disjoint\nor polar outcomes. We analyze the disjunction effect from the perspective of\nthe belief as a quantum vector.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 19:18:22 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Kak", "Subhash", ""]]}, {"id": "1709.04049", "submitter": "Wen Shen", "authors": "Wen Shen, Jacob W. Crandall, Ke Yan, Cristina V. Lopes", "title": "Information Design in Crowdfunding under Thresholding Policies", "comments": "9 pages, 2 figures, In Proceedings of the 17th International\n  Conference on Autonomous Agents and Multiagent Systems (AAMAS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Crowdfunding has emerged as a prominent way for entrepreneurs to secure\nfunding without sophisticated intermediation. In crowdfunding, an entrepreneur\noften has to decide how to disclose the campaign status in order to collect as\nmany contributions as possible. Such decisions are difficult to make primarily\ndue to incomplete information. We propose information design as a tool to help\nthe entrepreneur to improve revenue by influencing backers' beliefs. We\nintroduce a heuristic algorithm to dynamically compute information-disclosure\npolicies for the entrepreneur, followed by an empirical evaluation to\ndemonstrate its competitiveness over the widely-adopted immediate-disclosure\npolicy. Our results demonstrate that the immediate-disclosure policy is not\noptimal when backers follow thresholding policies despite its ease of\nimplementation. With appropriate heuristics, an entrepreneur can benefit from\ndynamic information disclosure. Our work sheds light on information design in a\ndynamic setting where agents make decisions using thresholding policies.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 20:29:08 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 20:27:16 GMT"}, {"version": "v3", "created": "Tue, 21 Nov 2017 23:32:14 GMT"}, {"version": "v4", "created": "Sat, 17 Mar 2018 18:31:53 GMT"}, {"version": "v5", "created": "Wed, 28 Mar 2018 19:55:42 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Shen", "Wen", ""], ["Crandall", "Jacob W.", ""], ["Yan", "Ke", ""], ["Lopes", "Cristina V.", ""]]}, {"id": "1709.04057", "submitter": "Eric Martin", "authors": "Eric Martin, Chris Cundy", "title": "Parallelizing Linear Recurrent Neural Nets Over Sequence Length", "comments": "9 pages. Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are widely used to model sequential data but\ntheir non-linear dependencies between sequence elements prevent parallelizing\ntraining over sequence length. We show the training of RNNs with only linear\nsequential dependencies can be parallelized over the sequence length using the\nparallel scan algorithm, leading to rapid training on long sequences even with\nsmall minibatch size. We develop a parallel linear recurrence CUDA kernel and\nshow that it can be applied to immediately speed up training and inference of\nseveral state of the art RNN architectures by up to 9x. We abstract recent work\non linear RNNs into a new framework of linear surrogate RNNs and develop a\nlinear surrogate model for the long short-term memory unit, the GILR-LSTM, that\nutilizes parallel linear recurrence. We extend sequence learning to new\nextremely long sequence regimes that were previously out of reach by\nsuccessfully training a GILR-LSTM on a synthetic sequence classification task\nwith a one million timestep dependency.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 20:52:22 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 05:38:25 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Martin", "Eric", ""], ["Cundy", "Chris", ""]]}, {"id": "1709.04071", "submitter": "Yuyu Zhang", "authors": "Yuyu Zhang, Hanjun Dai, Zornitsa Kozareva, Alexander J. Smola, Le Song", "title": "Variational Reasoning for Question Answering with Knowledge Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph (KG) is known to be helpful for the task of question\nanswering (QA), since it provides well-structured relational information\nbetween entities, and allows one to further infer indirect facts. However, it\nis challenging to build QA systems which can learn to reason over knowledge\ngraphs based on question-answer pairs alone. First, when people ask questions,\ntheir expressions are noisy (for example, typos in texts, or variations in\npronunciations), which is non-trivial for the QA system to match those\nmentioned entities to the knowledge graph. Second, many questions require\nmulti-hop logic reasoning over the knowledge graph to retrieve the answers. To\naddress these challenges, we propose a novel and unified deep learning\narchitecture, and an end-to-end variational learning algorithm which can handle\nnoise in questions, and learn multi-hop reasoning simultaneously. Our method\nachieves state-of-the-art performance on a recent benchmark dataset in the\nliterature. We also derive a series of new benchmark datasets, including\nquestions for multi-hop reasoning, questions paraphrased by neural translation\nmodel, and questions in human voice. Our method yields very promising results\non all these challenging datasets.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 22:27:34 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 06:24:24 GMT"}, {"version": "v3", "created": "Thu, 12 Oct 2017 23:18:47 GMT"}, {"version": "v4", "created": "Tue, 21 Nov 2017 00:33:53 GMT"}, {"version": "v5", "created": "Mon, 27 Nov 2017 21:58:40 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Zhang", "Yuyu", ""], ["Dai", "Hanjun", ""], ["Kozareva", "Zornitsa", ""], ["Smola", "Alexander J.", ""], ["Song", "Le", ""]]}, {"id": "1709.04083", "submitter": "Yunshu Du", "authors": "Gabriel V. de la Cruz Jr, Yunshu Du and Matthew E. Taylor", "title": "Pre-training Neural Networks with Human Demonstrations for Deep\n  Reinforcement Learning", "comments": "ALA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (deep RL) has achieved superior performance in\ncomplex sequential tasks by using a deep neural network as its function\napproximator and by learning directly from raw images. A drawback of using raw\nimages is that deep RL must learn the state feature representation from the raw\nimages in addition to learning a policy. As a result, deep RL can require a\nprohibitively large amount of training time and data to reach reasonable\nperformance, making it difficult to use deep RL in real-world applications,\nespecially when data is expensive. In this work, we speed up training by\naddressing half of what deep RL is trying to solve --- learning features. Our\napproach is to learn some of the important features by pre-training deep RL\nnetwork's hidden layers via supervised learning using a small set of human\ndemonstrations. We empirically evaluate our approach using deep Q-network (DQN)\nand asynchronous advantage actor-critic (A3C) algorithms on the Atari 2600\ngames of Pong, Freeway, and Beamrider. Our results show that: 1) pre-training\nwith human demonstrations in a supervised learning manner is better at\ndiscovering features relative to pre-training naively in DQN, and 2)\ninitializing a deep RL network with a pre-trained model provides a significant\nimprovement in training time even when pre-training from a small number of\nhuman demonstrations.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 23:17:45 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 21:59:20 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Cruz", "Gabriel V. de la", "Jr"], ["Du", "Yunshu", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1709.04176", "submitter": "Marco Schaerf", "authors": "Francesco Lupia, Angelo Mendicelli, Andrea Ribichini, Francesco\n  Scarcello and Marco Schaerf", "title": "Computing the Shapley Value in Allocation Problems: Approximations and\n  Bounds, with an Application to the Italian VQR Research Assessment Program", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In allocation problems, a given set of goods are assigned to agents in such a\nway that the social welfare is maximised, that is, the largest possible global\nworth is achieved. When goods are indivisible, it is possible to use money\ncompensation to perform a fair allocation taking into account the actual\ncontribution of all agents to the social welfare. Coalitional games provide a\nformal mathematical framework to model such problems, in particular the Shapley\nvalue is a solution concept widely used for assigning worths to agents in a\nfair way. Unfortunately, computing this value is a $\\#{\\rm P}$-hard problem, so\nthat applying this good theoretical notion is often quite difficult in\nreal-world problems.\n  We describe useful properties that allow us to greatly simplify the instances\nof allocation problems, without affecting the Shapley value of any player.\nMoreover, we propose algorithms for computing lower bounds and upper bounds of\nthe Shapley value, which in some cases provide the exact result and that can be\ncombined with approximation algorithms.\n  The proposed techniques have been implemented and tested on a real-world\napplication of allocation problems, namely, the Italian research assessment\nprogram, known as VQR. For the large university considered in the experiments,\nthe problem involves thousands of agents and goods (here, researchers and their\nresearch products). The algorithms described in the paper are able to compute\nthe Shapley value for most of those agents, and to get a good approximation of\nthe Shapley value for all of them.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 08:11:29 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Lupia", "Francesco", ""], ["Mendicelli", "Angelo", ""], ["Ribichini", "Andrea", ""], ["Scarcello", "Francesco", ""], ["Schaerf", "Marco", ""]]}, {"id": "1709.04182", "submitter": "Arnaud Martin", "authors": "Arnaud Martin (DRUID)", "title": "Conflict management in information fusion with belief functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Information fusion, the conflict is an important concept. Indeed,\ncombining several imperfect experts or sources allows conflict. In the theory\nof belief functions, this notion has been discussed a lot. The mass appearing\non the empty set during the conjunctive combination rule is generally\nconsidered as conflict, but that is not really a conflict. Some measures of\nconflict have been proposed and some approaches have been proposed in order to\nmanage this conflict or to decide with conflicting mass functions. We recall in\nthis chapter some of them and we propose a discussion to consider the conflict\nin information fusion with the theory of belief functions.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 08:35:48 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Martin", "Arnaud", "", "DRUID"]]}, {"id": "1709.04186", "submitter": "Ignacio Martin", "authors": "Ignacio Mart\\'in, Jos\\'e Alberto Hern\\'andez, Sergio de los Santos", "title": "On labeling Android malware signatures using minhashing and further\n  classification with Structural Equation Models", "comments": "15 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-scanner Antivirus systems provide insightful information on the nature\nof a suspect application; however there is often a lack of consensus and\nconsistency between different Anti-Virus engines. In this article, we analyze\nmore than 250 thousand malware signatures generated by 61 different Anti-Virus\nengines after analyzing 82 thousand different Android malware applications. We\nidentify 41 different malware classes grouped into three major categories,\nnamely Adware, Harmful Threats and Unknown or Generic signatures. We further\ninvestigate the relationships between such 41 classes using community detection\nalgorithms from graph theory to identify similarities between them; and we\nfinally propose a Structure Equation Model to identify which Anti-Virus engines\nare more powerful at detecting each macro-category. As an application, we show\nhow such models can help in identifying whether Unknown malware applications\nare more likely to be of Harmful or Adware type.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 08:38:36 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Mart\u00edn", "Ignacio", ""], ["Hern\u00e1ndez", "Jos\u00e9 Alberto", ""], ["Santos", "Sergio de los", ""]]}, {"id": "1709.04219", "submitter": "Jeremy Barnes", "authors": "Jeremy Barnes, Roman Klinger and Sabine Schulte im Walde", "title": "Assessing State-of-the-Art Sentiment Models on State-of-the-Art\n  Sentiment Datasets", "comments": "Presented at WASSA 2017", "journal-ref": "In Proceedings of WASSA (2017). 2 - 12", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been a good amount of progress in sentiment analysis over the past\n10 years, including the proposal of new methods and the creation of benchmark\ndatasets. In some papers, however, there is a tendency to compare models only\non one or two datasets, either because of time restraints or because the model\nis tailored to a specific task. Accordingly, it is hard to understand how well\na certain model generalizes across different tasks and datasets. In this paper,\nwe contribute to this situation by comparing several models on six different\nbenchmarks, which belong to different domains and additionally have different\nlevels of granularity (binary, 3-class, 4-class and 5-class). We show that\nBi-LSTMs perform well across datasets and that both LSTMs and Bi-LSTMs are\nparticularly good at fine-grained sentiment tasks (i. e., with more than two\nclasses). Incorporating sentiment information into word embeddings during\ntraining gives good results for datasets that are lexically similar to the\ntraining data. With our experiments, we contribute to a better understanding of\nthe performance of different model architectures on different data sets.\nConsequently, we detect novel state-of-the-art results on the SenTube datasets.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 09:43:02 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Barnes", "Jeremy", ""], ["Klinger", "Roman", ""], ["Walde", "Sabine Schulte im", ""]]}, {"id": "1709.04240", "submitter": "Joseph Ramsey", "authors": "Joseph D. Ramsey and Bryan Andrews", "title": "A Comparison of Public Causal Search Packages on Linear, Gaussian Data\n  with No Latent Variables", "comments": "7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare Tetrad (Java) algorithms to the other public software packages BNT\n(Bayes Net Toolbox, Matlab), pcalg (R), bnlearn (R) on the \\vanilla\" task of\nrecovering DAG structure to the extent possible from data generated recursively\nfrom linear, Gaussian structure equation models (SEMs) with no latent\nvariables, for random graphs, with no additional knowledge of variable order or\nadjacency structure, and without additional specification of intervention\ninformation. Each one of the above packages offers at least one implementation\nsuitable to this purpose. We compare them on adjacency and orientation accuracy\nas well as time performance, for fixed datasets. We vary the number of\nvariables, the number of samples, and the density of graph, for a total of 27\ncombinations, averaging all statistics over 10 runs, for a total of 270\ndatasets. All runs are carried out on the same machine and on their native\nplatforms. An interactive visualization tool is provided for the reader who\nwishes to know more than can be documented explicitly in this report.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 10:41:19 GMT"}, {"version": "v2", "created": "Sat, 16 Sep 2017 16:09:06 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Ramsey", "Joseph D.", ""], ["Andrews", "Bryan", ""]]}, {"id": "1709.04271", "submitter": "Sam Toyer", "authors": "Sam Toyer, Felipe Trevizan, Sylvie Thi\\'ebaux, Lexing Xie", "title": "Action Schema Networks: Generalised Policies with Deep Learning", "comments": "Accepted to AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the Action Schema Network (ASNet): a neural\nnetwork architecture for learning generalised policies for probabilistic\nplanning problems. By mimicking the relational structure of planning problems,\nASNets are able to adopt a weight-sharing scheme which allows the network to be\napplied to any problem from a given planning domain. This allows the cost of\ntraining the network to be amortised over all problems in that domain. Further,\nwe propose a training method which balances exploration and supervised training\non small problems to produce a policy which remains robust when evaluated on\nlarger problems. In experiments, we show that ASNet's learning capability\nallows it to significantly outperform traditional non-learning planners in\nseveral challenging domains.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 12:15:52 GMT"}, {"version": "v2", "created": "Fri, 22 Dec 2017 07:59:26 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Toyer", "Sam", ""], ["Trevizan", "Felipe", ""], ["Thi\u00e9baux", "Sylvie", ""], ["Xie", "Lexing", ""]]}, {"id": "1709.04305", "submitter": "Tim Oates", "authors": "Zhiguang Wang, Chul Gwon, Tim Oates, Adam Iezzi", "title": "Automated Cloud Provisioning on AWS using Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the use of cloud computing continues to rise, controlling cost becomes\nincreasingly important. Yet there is evidence that 30\\% - 45\\% of cloud spend\nis wasted. Existing tools for cloud provisioning typically rely on highly\ntrained human experts to specify what to monitor, thresholds for triggering\naction, and actions. In this paper we explore the use of reinforcement learning\n(RL) to acquire policies to balance performance and spend, allowing humans to\nspecify what they want as opposed to how to do it, minimizing the need for\ncloud expertise. Empirical results with tabular, deep, and dueling double deep\nQ-learning with the CloudSim simulator show the utility of RL and the relative\nmerits of the approaches. We also demonstrate effective policy transfer\nlearning from an extremely simple simulator to CloudSim, with the next step\nbeing transfer from CloudSim to an Amazon Web Services physical environment.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 13:06:43 GMT"}, {"version": "v2", "created": "Tue, 19 Sep 2017 14:45:59 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Wang", "Zhiguang", ""], ["Gwon", "Chul", ""], ["Oates", "Tim", ""], ["Iezzi", "Adam", ""]]}, {"id": "1709.04318", "submitter": "Varun Ojha", "authors": "Varun Kumar Ojha, Serena Schiano, Chuan-Yu Wu, V\\'aclav Sn\\'a\\v{s}el,\n  Ajith Abraham", "title": "Predictive modeling of die filling of the pharmaceutical granules using\n  the flexible neural tree", "comments": null, "journal-ref": "Neural Computing and Application, 2016", "doi": "10.1007/s00521-016-2545-8", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a computational intelligence (CI) technique named flexible\nneural tree (FNT) was developed to predict die filling performance of\npharmaceutical granules and to identify significant die filling process\nvariables. FNT resembles feedforward neural network, which creates a tree-like\nstructure by using genetic programming. To improve accuracy, FNT parameters\nwere optimized by using differential evolution algorithm. The performance of\nthe FNT-based CI model was evaluated and compared with other CI techniques:\nmultilayer perceptron, Gaussian process regression, and reduced error pruning\ntree. The accuracy of the CI model was evaluated experimentally using die\nfilling as a case study. The die filling experiments were performed using a\nmodel shoe system and three different grades of microcrystalline cellulose\n(MCC) powders (MCC PH 101, MCC PH 102, and MCC DG). The feed powders were\nroll-compacted and milled into granules. The granules were then sieved into\nsamples of various size classes. The mass of granules deposited into the die at\ndifferent shoe speeds was measured. From these experiments, a dataset\nconsisting true density, mean diameter (d50), granule size, and shoe speed as\nthe inputs and the deposited mass as the output was generated. Cross-validation\n(CV) methods such as 10FCV and 5x2FCV were applied to develop and to validate\nthe predictive models. It was found that the FNT-based CI model (for both CV\nmethods) performed much better than other CI models. Additionally, it was\nobserved that process variables such as the granule size and the shoe speed had\na higher impact on the predictability than that of the powder property such as\nd50. Furthermore, validation of model prediction with experimental data showed\nthat the die filling behavior of coarse granules could be better predicted than\nthat of fine granules.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 08:50:24 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Ojha", "Varun Kumar", ""], ["Schiano", "Serena", ""], ["Wu", "Chuan-Yu", ""], ["Sn\u00e1\u0161el", "V\u00e1clav", ""], ["Abraham", "Ajith", ""]]}, {"id": "1709.04326", "submitter": "Jakob Foerster", "authors": "Jakob N. Foerster, Richard Y. Chen, Maruan Al-Shedivat, Shimon\n  Whiteson, Pieter Abbeel, Igor Mordatch", "title": "Learning with Opponent-Learning Awareness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent settings are quickly gathering importance in machine learning.\nThis includes a plethora of recent work on deep multi-agent reinforcement\nlearning, but also can be extended to hierarchical RL, generative adversarial\nnetworks and decentralised optimisation. In all these settings the presence of\nmultiple learning agents renders the training problem non-stationary and often\nleads to unstable training or undesired final results. We present Learning with\nOpponent-Learning Awareness (LOLA), a method in which each agent shapes the\nanticipated learning of the other agents in the environment. The LOLA learning\nrule includes a term that accounts for the impact of one agent's policy on the\nanticipated parameter update of the other agents. Results show that the\nencounter of two LOLA agents leads to the emergence of tit-for-tat and\ntherefore cooperation in the iterated prisoners' dilemma, while independent\nlearning does not. In this domain, LOLA also receives higher payouts compared\nto a naive learner, and is robust against exploitation by higher order\ngradient-based methods. Applied to repeated matching pennies, LOLA agents\nconverge to the Nash equilibrium. In a round robin tournament we show that LOLA\nagents successfully shape the learning of a range of multi-agent learning\nalgorithms from literature, resulting in the highest average returns on the\nIPD. We also show that the LOLA update rule can be efficiently calculated using\nan extension of the policy gradient estimator, making the method suitable for\nmodel-free RL. The method thus scales to large parameter and input spaces and\nnonlinear function approximators. We apply LOLA to a grid world task with an\nembedded social dilemma using recurrent policies and opponent modelling. By\nexplicitly considering the learning of the other agent, LOLA agents learn to\ncooperate out of self-interest. The code is at github.com/alshedivat/lola.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 13:42:15 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 23:24:07 GMT"}, {"version": "v3", "created": "Wed, 2 May 2018 06:42:30 GMT"}, {"version": "v4", "created": "Wed, 19 Sep 2018 19:22:48 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Foerster", "Jakob N.", ""], ["Chen", "Richard Y.", ""], ["Al-Shedivat", "Maruan", ""], ["Whiteson", "Shimon", ""], ["Abbeel", "Pieter", ""], ["Mordatch", "Igor", ""]]}, {"id": "1709.04328", "submitter": "Maxime Lenormand", "authors": "Maxime Lenormand", "title": "Generating OWA weights using truncated distributions", "comments": "7 pages, 7 figures", "journal-ref": "International Journal of Intelligent Systems 33, 791-801 (2018)", "doi": "10.1002/int.21963", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordered weighted averaging (OWA) operators have been widely used in decision\nmaking these past few years. An important issue facing the OWA operators' users\nis the determination of the OWA weights. This paper introduces an OWA\ndetermination method based on truncated distributions that enables intuitive\ngeneration of OWA weights according to a certain level of risk and trade-off.\nThese two dimensions are represented by the two first moments of the truncated\ndistribution. We illustrate our approach with the well-know normal distribution\nand the definition of a continuous parabolic decision-strategy space. We\nfinally study the impact of the number of criteria on the results.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 13:43:43 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 23:42:13 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Lenormand", "Maxime", ""]]}, {"id": "1709.04380", "submitter": "Tianyu Li", "authors": "Tianyu Li, Guillaume Rabusseau, Doina Precup", "title": "Neural Network Based Nonlinear Weighted Finite Automata", "comments": "AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Weighted finite automata (WFA) can expressively model functions defined over\nstrings but are inherently linear models. Given the recent successes of\nnonlinear models in machine learning, it is natural to wonder whether\nex-tending WFA to the nonlinear setting would be beneficial. In this paper, we\npropose a novel model of neural network based nonlinearWFA model (NL-WFA) along\nwith a learning algorithm. Our learning algorithm is inspired by the spectral\nlearning algorithm for WFAand relies on a nonlinear decomposition of the\nso-called Hankel matrix, by means of an auto-encoder network. The expressive\npower of NL-WFA and the proposed learning algorithm are assessed on both\nsynthetic and real-world data, showing that NL-WFA can lead to smaller model\nsizes and infer complex grammatical structures from data.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 15:26:50 GMT"}, {"version": "v2", "created": "Thu, 21 Dec 2017 13:42:43 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Li", "Tianyu", ""], ["Rabusseau", "Guillaume", ""], ["Precup", "Doina", ""]]}, {"id": "1709.04511", "submitter": "Yaodong Yang Mr.", "authors": "Yaodong Yang, Lantao Yu, Yiwei Bai, Jun Wang, Weinan Zhang, Ying Wen,\n  Yong Yu", "title": "A Study of AI Population Dynamics with Million-agent Reinforcement\n  Learning", "comments": "Full version of the paper presented at AAMAS 2018 (International\n  Conference on Autonomous Agents and Multiagent Systems)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct an empirical study on discovering the ordered collective dynamics\nobtained by a population of intelligence agents, driven by million-agent\nreinforcement learning. Our intention is to put intelligent agents into a\nsimulated natural context and verify if the principles developed in the real\nworld could also be used in understanding an artificially-created intelligent\npopulation. To achieve this, we simulate a large-scale predator-prey world,\nwhere the laws of the world are designed by only the findings or logical\nequivalence that have been discovered in nature. We endow the agents with the\nintelligence based on deep reinforcement learning (DRL). In order to scale the\npopulation size up to millions agents, a large-scale DRL training platform with\nredesigned experience buffer is proposed. Our results show that the population\ndynamics of AI agents, driven only by each agent's individual self-interest,\nreveals an ordered pattern that is similar to the Lotka-Volterra model studied\nin population biology. We further discover the emergent behaviors of collective\nadaptations in studying how the agents' grouping behaviors will change with the\nenvironmental resources. Both of the two findings could be explained by the\nself-organization theory in nature.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 19:21:57 GMT"}, {"version": "v2", "created": "Sun, 17 Sep 2017 23:06:31 GMT"}, {"version": "v3", "created": "Thu, 5 Oct 2017 13:25:18 GMT"}, {"version": "v4", "created": "Mon, 14 May 2018 13:30:45 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Yang", "Yaodong", ""], ["Yu", "Lantao", ""], ["Bai", "Yiwei", ""], ["Wang", "Jun", ""], ["Zhang", "Weinan", ""], ["Wen", "Ying", ""], ["Yu", "Yong", ""]]}, {"id": "1709.04517", "submitter": "Kartik Talamadupula", "authors": "Tathagata Chakraborti and Kshitij P. Fadnis and Kartik Talamadupula\n  and Mishal Dholakia and Biplav Srivastava and Jeffrey O. Kephart and Rachel\n  K. E. Bellamy", "title": "Visualizations for an Explainable Planning Agent", "comments": "PREVIOUSLY Mr. Jones -- Towards a Proactive Smart Room Orchestrator\n  (appeared in AAAI 2017 Fall Symposium on Human-Agent Groups)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we report on the visualization capabilities of an Explainable\nAI Planning (XAIP) agent that can support human in the loop decision making.\nImposing transparency and explainability requirements on such agents is\nespecially important in order to establish trust and common ground with the\nend-to-end automated planning system. Visualizing the agent's internal\ndecision-making processes is a crucial step towards achieving this. This may\ninclude externalizing the \"brain\" of the agent -- starting from its sensory\ninputs, to progressively higher order decisions made by it in order to drive\nits planning components. We also show how the planner can bootstrap on the\nlatest techniques in explainable planning to cast plan visualization as a plan\nexplanation problem, and thus provide concise model-based visualization of its\nplans. We demonstrate these functionalities in the context of the automated\nplanning components of a smart assistant in an instrumented meeting space.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 19:50:44 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 18:35:30 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Chakraborti", "Tathagata", ""], ["Fadnis", "Kshitij P.", ""], ["Talamadupula", "Kartik", ""], ["Dholakia", "Mishal", ""], ["Srivastava", "Biplav", ""], ["Kephart", "Jeffrey O.", ""], ["Bellamy", "Rachel K. E.", ""]]}, {"id": "1709.04524", "submitter": "Kartik Talamadupula", "authors": "Kartik Talamadupula and Biplav Srivastava and Jeffrey O. Kephart", "title": "Workflow Complexity for Collaborative Interactions: Where are the\n  Metrics? -- A Challenge", "comments": "4 pages, 1 figure, 1 table Appeared in the ICAPS 2017 UISP Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the problem of denoting and deriving the\ncomplexity of workflows (plans, schedules) in collaborative, planner-assisted\nsettings where humans and agents are trying to jointly solve a task. The\ninteractions -- and hence the workflows that connect the human and the agents\n-- may differ according to the domain and the kind of agents. We adapt insights\nfrom prior work in human-agent teaming and workflow analysis to suggest metrics\nfor workflow complexity. The main motivation behind this work is to highlight\nmetrics for human comprehensibility of plans and schedules. The planning\ncommunity has seen its fair share of work on the synthesis of plans that take\ndiversity into account -- what value do such plans hold if their generation is\nnot guided at least in part by metrics that reflect the ease of engaging with\nand using those plans?\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 20:06:43 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Talamadupula", "Kartik", ""], ["Srivastava", "Biplav", ""], ["Kephart", "Jeffrey O.", ""]]}, {"id": "1709.04555", "submitter": "Wengong Jin", "authors": "Wengong Jin, Connor W. Coley, Regina Barzilay, Tommi Jaakkola", "title": "Predicting Organic Reaction Outcomes with Weisfeiler-Lehman Network", "comments": "accepted by NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prediction of organic reaction outcomes is a fundamental problem in\ncomputational chemistry. Since a reaction may involve hundreds of atoms, fully\nexploring the space of possible transformations is intractable. The current\nsolution utilizes reaction templates to limit the space, but it suffers from\ncoverage and efficiency issues. In this paper, we propose a template-free\napproach to efficiently explore the space of product molecules by first\npinpointing the reaction center -- the set of nodes and edges where graph edits\noccur. Since only a small number of atoms contribute to reaction center, we can\ndirectly enumerate candidate products. The generated candidates are scored by a\nWeisfeiler-Lehman Difference Network that models high-order interactions\nbetween changes occurring at nodes across the molecule. Our framework\noutperforms the top-performing template-based approach with a 10\\% margin,\nwhile running orders of magnitude faster. Finally, we demonstrate that the\nmodel accuracy rivals the performance of domain experts.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 22:28:46 GMT"}, {"version": "v2", "created": "Mon, 4 Dec 2017 18:53:33 GMT"}, {"version": "v3", "created": "Fri, 29 Dec 2017 16:31:51 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Jin", "Wengong", ""], ["Coley", "Connor W.", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1709.04558", "submitter": "John Ball", "authors": "John S. Ball", "title": "Using NLU in Context for Question Answering: Improving on Facebook's\n  bAbI Tasks", "comments": "38 Pages, 10 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the next step in human to machine interaction, Artificial Intelligence\n(AI) should interact predominantly using natural language because, if it\nworked, it would be the fastest way to communicate. Facebook's toy tasks (bAbI)\nprovide a useful benchmark to compare implementations for conversational AI.\nWhile the published experiments so far have been based on exploiting the\ndistributional hypothesis with machine learning, our model exploits natural\nlanguage understanding (NLU) with the decomposition of language based on Role\nand Reference Grammar (RRG) and the brain-based Patom theory. Our combinatorial\nsystem for conversational AI based on linguistics has many advantages: passing\nbAbI task tests without parsing or statistics while increasing scalability. Our\nmodel validates both the training and test data to find 'garbage' input and\noutput (GIGO). It is not rules-based, nor does it use parts of speech, but\ninstead relies on meaning. While Deep Learning is difficult to debug and fix,\nevery step in our model can be understood and changed like any non-statistical\ncomputer program. Deep Learning's lack of explicable reasoning has raised\nopposition to AI, partly due to fear of the unknown. To support the goals of\nAI, we propose extended tasks to use human-level statements with tense, aspect\nand voice, and embedded clauses with junctures: and answers to be natural\nlanguage generation (NLG) instead of keywords. While machine learning permits\ninvalid training data to produce incorrect test responses, our system cannot\nbecause the context tracking would need to be intentionally broken. We believe\nno existing learning systems can currently solve these extended natural\nlanguage tests. There appears to be a knowledge gap between NLP researchers and\nlinguists, but ongoing competitive results such as these promise to narrow that\ngap.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 22:48:39 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 01:19:52 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Ball", "John S.", ""]]}, {"id": "1709.04571", "submitter": "Pierre-Luc Bacon", "authors": "Jean Harb, Pierre-Luc Bacon, Martin Klissarov, Doina Precup", "title": "When Waiting is not an Option : Learning Options with a Deliberation\n  Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that temporally extended actions (options) can be\nlearned fully end-to-end as opposed to being specified in advance. While the\nproblem of \"how\" to learn options is increasingly well understood, the question\nof \"what\" good options should be has remained elusive. We formulate our answer\nto what \"good\" options should be in the bounded rationality framework (Simon,\n1957) through the notion of deliberation cost. We then derive practical\ngradient-based learning algorithms to implement this objective. Our results in\nthe Arcade Learning Environment (ALE) show increased performance and\ninterpretability.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 00:18:44 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Harb", "Jean", ""], ["Bacon", "Pierre-Luc", ""], ["Klissarov", "Martin", ""], ["Precup", "Doina", ""]]}, {"id": "1709.04574", "submitter": "Victor Shih", "authors": "Victor Shih, David C Jangraw, Paul Sajda, Sameer Saproo", "title": "Towards personalized human AI interaction - adapting the behavior of AI\n  agents using neural signatures of subjective interest", "comments": "11 pages, 9 figures, 1 table, Submitted to IEEE Trans. on Neural\n  Networks and Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning AI commonly uses reward/penalty signals that are\nobjective and explicit in an environment -- e.g. game score, completion time,\netc. -- in order to learn the optimal strategy for task performance. However,\nHuman-AI interaction for such AI agents should include additional reinforcement\nthat is implicit and subjective -- e.g. human preferences for certain AI\nbehavior -- in order to adapt the AI behavior to idiosyncratic human\npreferences. Such adaptations would mirror naturally occurring processes that\nincrease trust and comfort during social interactions. Here, we show how a\nhybrid brain-computer-interface (hBCI), which detects an individual's level of\ninterest in objects/events in a virtual environment, can be used to adapt the\nbehavior of a Deep Reinforcement Learning AI agent that is controlling a\nvirtual autonomous vehicle. Specifically, we show that the AI learns a driving\nstrategy that maintains a safe distance from a lead vehicle, and most novelly,\npreferentially slows the vehicle when the human passengers of the vehicle\nencounter objects of interest. This adaptation affords an additional 20\\%\nviewing time for subjectively interesting objects. This is the first\ndemonstration of how an hBCI can be used to provide implicit reinforcement to\nan AI agent in a way that incorporates user preferences into the control\nsystem.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 01:27:44 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Shih", "Victor", ""], ["Jangraw", "David C", ""], ["Sajda", "Paul", ""], ["Saproo", "Sameer", ""]]}, {"id": "1709.04579", "submitter": "Behzad Ghazanfari", "authors": "Behzad Ghazanfari and Matthew E. Taylor", "title": "Autonomous Extracting a Hierarchical Structure of Tasks in Reinforcement\n  Learning and Multi-task Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL), while often powerful, can suffer from slow\nlearning speeds, particularly in high dimensional spaces. The autonomous\ndecomposition of tasks and use of hierarchical methods hold the potential to\nsignificantly speed up learning in such domains. This paper proposes a novel\npractical method that can autonomously decompose tasks, by leveraging\nassociation rule mining, which discovers hidden relationship among entities in\ndata mining. We introduce a novel method called ARM-HSTRL (Association Rule\nMining to extract Hierarchical Structure of Tasks in Reinforcement Learning).\nIt extracts temporal and structural relationships of sub-goals in RL, and\nmulti-task RL. In particular,it finds sub-goals and relationship among them. It\nis shown the significant efficiency and performance of the proposed method in\ntwo main topics of RL.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 01:43:13 GMT"}, {"version": "v2", "created": "Fri, 15 Sep 2017 16:21:03 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Ghazanfari", "Behzad", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1709.04596", "submitter": "Nesreen Ahmed", "authors": "Nesreen K. Ahmed, Ryan A. Rossi, Rong Zhou, John Boaz Lee, Xiangnan\n  Kong, Theodore L. Willke and Hoda Eldardiry", "title": "A Framework for Generalizing Graph-based Representation Learning Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random walks are at the heart of many existing deep learning algorithms for\ngraph data. However, such algorithms have many limitations that arise from the\nuse of random walks, e.g., the features resulting from these methods are unable\nto transfer to new nodes and graphs as they are tied to node identity. In this\nwork, we introduce the notion of attributed random walks which serves as a\nbasis for generalizing existing methods such as DeepWalk, node2vec, and many\nothers that leverage random walks. Our proposed framework enables these methods\nto be more widely applicable for both transductive and inductive learning as\nwell as for use on graphs with attributes (if available). This is achieved by\nlearning functions that generalize to new nodes and graphs. We show that our\nproposed framework is effective with an average AUC improvement of 16.1% while\nrequiring on average 853 times less space than existing methods on a variety of\ngraphs from several domains.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 02:37:52 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Ahmed", "Nesreen K.", ""], ["Rossi", "Ryan A.", ""], ["Zhou", "Rong", ""], ["Lee", "John Boaz", ""], ["Kong", "Xiangnan", ""], ["Willke", "Theodore L.", ""], ["Eldardiry", "Hoda", ""]]}, {"id": "1709.04636", "submitter": "Marius Lindauer", "authors": "Marius Lindauer and Frank Hutter", "title": "Warmstarting of Model-based Algorithm Configuration", "comments": "Preprint of AAAI'18 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of many hard combinatorial problem solvers depends strongly\non their parameter settings, and since manual parameter tuning is both tedious\nand suboptimal the AI community has recently developed several algorithm\nconfiguration (AC) methods to automatically address this problem. While all\nexisting AC methods start the configuration process of an algorithm A from\nscratch for each new type of benchmark instances, here we propose to exploit\ninformation about A's performance on previous benchmarks in order to warmstart\nits configuration on new types of benchmarks. We introduce two complementary\nways in which we can exploit this information to warmstart AC methods based on\na predictive model. Experiments for optimizing a very flexible modern SAT\nsolver on twelve different instance sets show that our methods often yield\nsubstantial speedups over existing AC methods (up to 165-fold) and can also\nfind substantially better configurations given the same compute budget.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 07:09:54 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 07:14:01 GMT"}, {"version": "v3", "created": "Tue, 28 Nov 2017 10:07:41 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Lindauer", "Marius", ""], ["Hutter", "Frank", ""]]}, {"id": "1709.04676", "submitter": "Alberto Garcia-Duran", "authors": "Alberto Garcia-Duran and Mathias Niepert", "title": "KBLRN : End-to-End Learning of Knowledge Base Representations with\n  Latent, Relational, and Numerical Features", "comments": "UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present KBLRN, a framework for end-to-end learning of knowledge base\nrepresentations from latent, relational, and numerical features. KBLRN\nintegrates feature types with a novel combination of neural representation\nlearning and probabilistic product of experts models. To the best of our\nknowledge, KBLRN is the first approach that learns representations of knowledge\nbases by integrating latent, relational, and numerical features. We show that\ninstances of KBLRN outperform existing methods on a range of knowledge base\ncompletion tasks. We contribute a novel data sets enriching commonly used\nknowledge base completion benchmarks with numerical features. The data sets are\navailable under a permissive BSD-3 license. We also investigate the impact\nnumerical features have on the KB completion performance of KBLRN.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 09:13:46 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 14:40:43 GMT"}, {"version": "v3", "created": "Mon, 11 Jun 2018 11:55:27 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Garcia-Duran", "Alberto", ""], ["Niepert", "Mathias", ""]]}, {"id": "1709.04695", "submitter": "Nikolay Jetchev", "authors": "Nikolay Jetchev, Urs Bergmann", "title": "The Conditional Analogy GAN: Swapping Fashion Articles on People Images", "comments": "To appear at the International Conference on Computer Vision, ICCV\n  2017, Workshop on Computer Vision for Fashion", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method to solve image analogy problems : it allows to\nlearn the relation between paired images present in training data, and then\ngeneralize and generate images that correspond to the relation, but were never\nseen in the training set. Therefore, we call the method Conditional Analogy\nGenerative Adversarial Network (CAGAN), as it is based on adversarial training\nand employs deep convolutional neural networks. An especially interesting\napplication of that technique is automatic swapping of clothing on fashion\nmodel photos. Our work has the following contributions. First, the definition\nof the end-to-end trainable CAGAN architecture, which implicitly learns\nsegmentation masks without expensive supervised labeling data. Second,\nexperimental results show plausible segmentation masks and often convincing\nswapped images, given the target article. Finally, we discuss the next steps\nfor that technique: neural network architecture improvements and more advanced\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 10:39:51 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Jetchev", "Nikolay", ""], ["Bergmann", "Urs", ""]]}, {"id": "1709.04696", "submitter": "Tao Shen", "authors": "Tao Shen, Tianyi Zhou, Guodong Long, Jing Jiang, Shirui Pan and\n  Chengqi Zhang", "title": "DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language\n  Understanding", "comments": "10 pages, 8 figures; Accepted in AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural nets (RNN) and convolutional neural nets (CNN) are widely\nused on NLP tasks to capture the long-term and local dependencies,\nrespectively. Attention mechanisms have recently attracted enormous interest\ndue to their highly parallelizable computation, significantly less training\ntime, and flexibility in modeling dependencies. We propose a novel attention\nmechanism in which the attention between elements from input sequence(s) is\ndirectional and multi-dimensional (i.e., feature-wise). A light-weight neural\nnet, \"Directional Self-Attention Network (DiSAN)\", is then proposed to learn\nsentence embedding, based solely on the proposed attention without any RNN/CNN\nstructure. DiSAN is only composed of a directional self-attention with temporal\norder encoded, followed by a multi-dimensional attention that compresses the\nsequence into a vector representation. Despite its simple form, DiSAN\noutperforms complicated RNN models on both prediction quality and time\nefficiency. It achieves the best test accuracy among all sentence encoding\nmethods and improves the most recent best result by 1.02% on the Stanford\nNatural Language Inference (SNLI) dataset, and shows state-of-the-art test\naccuracy on the Stanford Sentiment Treebank (SST), Multi-Genre natural language\ninference (MultiNLI), Sentences Involving Compositional Knowledge (SICK),\nCustomer Review, MPQA, TREC question-type classification and Subjectivity\n(SUBJ) datasets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 10:42:44 GMT"}, {"version": "v2", "created": "Sat, 16 Sep 2017 02:53:35 GMT"}, {"version": "v3", "created": "Mon, 20 Nov 2017 23:39:11 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Shen", "Tao", ""], ["Zhou", "Tianyi", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Pan", "Shirui", ""], ["Zhang", "Chengqi", ""]]}, {"id": "1709.04734", "submitter": "Neelanshi Varia", "authors": "Mahipal Jadeja and Neelanshi Varia", "title": "Perspectives for Evaluating Conversational AI", "comments": "SCAI'17 - Search-Oriented Conversational AI (@ICTIR'17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational AI systems are becoming famous in day to day lives. In this\npaper, we are trying to address the following key question: To identify whether\ndesign, as well as development efforts for search oriented conversational AI\nare successful or not.It is tricky to define 'success' in the case of\nconversational AI and equally tricky part is to use appropriate metrics for the\nevaluation of conversational AI. We propose four different perspectives namely\nuser experience, information retrieval, linguistic and artificial intelligence\nfor the evaluation of conversational AI systems. Additionally, background\ndetails of conversational AI systems are provided including desirable\ncharacteristics of personal assistants, differences between chatbot and an AI\nbased personal assistant. An importance of personalization and how it can be\nachieved is explained in detail. Current challenges in the development of an\nideal conversational AI (personal assistant) are also highlighted along with\nguidelines for achieving personalized experience for users.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 12:37:08 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Jadeja", "Mahipal", ""], ["Varia", "Neelanshi", ""]]}, {"id": "1709.04762", "submitter": "Giacomo Spigler", "authors": "Giacomo Spigler", "title": "Denoising Autoencoders for Overgeneralization in Neural Networks", "comments": "9 pages, 5 figures, submitted", "journal-ref": null, "doi": "10.1109/TPAMI.2019.2909876", "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent developments that allowed neural networks to achieve\nimpressive performance on a variety of applications, these models are\nintrinsically affected by the problem of overgeneralization, due to their\npartitioning of the full input space into the fixed set of target classes used\nduring training. Thus it is possible for novel inputs belonging to categories\nunknown during training or even completely unrecognizable to humans to fool the\nsystem into classifying them as one of the known classes, even with a high\ndegree of confidence. Solving this problem may help improve the security of\nsuch systems in critical applications, and may further lead to applications in\nthe context of open set recognition and 1-class recognition. This paper\npresents a novel way to compute a confidence score using denoising autoencoders\nand shows that such confidence score can correctly identify the regions of the\ninput space close to the training distribution by approximately identifying its\nlocal maxima.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 13:12:03 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 11:09:10 GMT"}, {"version": "v3", "created": "Mon, 14 Jan 2019 22:35:13 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Spigler", "Giacomo", ""]]}, {"id": "1709.04763", "submitter": "Yuanduo He", "authors": "Yuanduo He, Xu Chu, Juguang Peng, Jingyue Gao, Yasha Wang", "title": "Motif-based Rule Discovery for Predicting Real-valued Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series prediction is of great significance in many applications and has\nattracted extensive attention from the data mining community. Existing work\nsuggests that for many problems, the shape in the current time series may\ncorrelate an upcoming shape in the same or another series. Therefore, it is a\npromising strategy to associate two recurring patterns as a rule's antecedent\nand consequent: the occurrence of the antecedent can foretell the occurrence of\nthe consequent, and the learned shape of consequent will give accurate\npredictions. Earlier work employs symbolization methods, but the symbolized\nrepresentation maintains too little information of the original series to mine\nvalid rules. The state-of-the-art work, though directly manipulating the\nseries, fails to segment the series precisely for seeking\nantecedents/consequents, resulting in inaccurate rules in common scenarios. In\nthis paper, we propose a novel motif-based rule discovery method, which\nutilizes motif discovery to accurately extract frequently occurring consecutive\nsubsequences, i.e. motifs, as antecedents/consequents. It then investigates the\nunderlying relationships between motifs by matching motifs as rule candidates\nand ranking them based on the similarities. Experimental results on real open\ndatasets show that the proposed approach outperforms the baseline method by\n23.9%. Furthermore, it extends the applicability from single time series to\nmultiple ones.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 13:13:01 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 14:30:52 GMT"}, {"version": "v3", "created": "Sat, 18 Nov 2017 08:19:44 GMT"}, {"version": "v4", "created": "Sat, 2 Dec 2017 03:30:23 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["He", "Yuanduo", ""], ["Chu", "Xu", ""], ["Peng", "Juguang", ""], ["Gao", "Jingyue", ""], ["Wang", "Yasha", ""]]}, {"id": "1709.04794", "submitter": "Joris Tavernier", "authors": "Joris Tavernier, Jaak Simm, Karl Meerbergen, Joerg Kurt Wegner, Hugo\n  Ceulemans and Yves Moreau", "title": "Fast semi-supervised discriminant analysis for binary classification of\n  large data-sets", "comments": null, "journal-ref": null, "doi": "10.1016/j.patcog.2019.02.015", "report-no": null, "categories": "cs.AI cs.NA cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional data requires scalable algorithms. We propose and analyze\nthree scalable and related algorithms for semi-supervised discriminant analysis\n(SDA). These methods are based on Krylov subspace methods which exploit the\ndata sparsity and the shift-invariance of Krylov subspaces. In addition, the\nproblem definition was improved by adding centralization to the semi-supervised\nsetting. The proposed methods are evaluated on a industry-scale data set from a\npharmaceutical company to predict compound activity on target proteins. The\nresults show that SDA achieves good predictive performance and our methods only\nrequire a few seconds, significantly improving computation time on previous\nstate of the art.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 13:53:49 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 14:00:31 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Tavernier", "Joris", ""], ["Simm", "Jaak", ""], ["Meerbergen", "Karl", ""], ["Wegner", "Joerg Kurt", ""], ["Ceulemans", "Hugo", ""], ["Moreau", "Yves", ""]]}, {"id": "1709.04825", "submitter": "Francisco J. Arjonilla", "authors": "Francisco J. Arjonilla, Tetsuya Ogata", "title": "General problem solving with category theory", "comments": "Laboratory for Intelligent Dynamics and Representation. Waseda\n  University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a formal cognitive framework for problem solving based on\ncategory theory. We introduce cognitive categories, which are categories with\nexactly one morphism between any two objects. Objects in these categories are\ninterpreted as states and morphisms as transformations between states.\nMoreover, cognitive problems are reduced to the specification of two objects in\na cognitive category: an outset (i.e. the current state of the system) and a\ngoal (i.e. the desired state). Cognitive systems transform the target system by\nmeans of generators and evaluators. Generators realize cognitive operations\nover a system by grouping morphisms, whilst evaluators group objects as a way\nto generalize outsets and goals to partially defined states. Meta-cognition\nemerges when the whole cognitive system is self-referenced as sub-states in the\ncognitive category, whilst learning must always be considered as a\nmeta-cognitive process to maintain consistency. Several examples grounded in\nbasic AI methods are provided as well.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 14:56:49 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Arjonilla", "Francisco J.", ""], ["Ogata", "Tetsuya", ""]]}, {"id": "1709.04905", "submitter": "Chelsea Finn", "authors": "Chelsea Finn, Tianhe Yu, Tianhao Zhang, Pieter Abbeel, Sergey Levine", "title": "One-Shot Visual Imitation Learning via Meta-Learning", "comments": "Conference on Robot Learning, 2017 (to appear). First two authors\n  contributed equally. Video available at\n  https://sites.google.com/view/one-shot-imitation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order for a robot to be a generalist that can perform a wide range of\njobs, it must be able to acquire a wide variety of skills quickly and\nefficiently in complex unstructured environments. High-capacity models such as\ndeep neural networks can enable a robot to represent complex skills, but\nlearning each skill from scratch then becomes infeasible. In this work, we\npresent a meta-imitation learning method that enables a robot to learn how to\nlearn more efficiently, allowing it to acquire new skills from just a single\ndemonstration. Unlike prior methods for one-shot imitation, our method can\nscale to raw pixel inputs and requires data from significantly fewer prior\ntasks for effective learning of new skills. Our experiments on both simulated\nand real robot platforms demonstrate the ability to learn new tasks,\nend-to-end, from a single visual demonstration.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 17:50:18 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Finn", "Chelsea", ""], ["Yu", "Tianhe", ""], ["Zhang", "Tianhao", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1709.04909", "submitter": "Rakesh Radhakrishnan Menon", "authors": "Rakesh R Menon, Balaraman Ravindran", "title": "Shared Learning : Enhancing Reinforcement in $Q$-Ensembles", "comments": "Submitted to AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning has been able to achieve amazing successes in a\nvariety of domains from video games to continuous control by trying to maximize\nthe cumulative reward. However, most of these successes rely on algorithms that\nrequire a large amount of data to train in order to obtain results on par with\nhuman-level performance. This is not feasible if we are to deploy these systems\non real world tasks and hence there has been an increased thrust in exploring\ndata efficient algorithms. To this end, we propose the Shared Learning\nframework aimed at making $Q$-ensemble algorithms data-efficient. For achieving\nthis, we look into some principles of transfer learning which aim to study the\nbenefits of information exchange across tasks in reinforcement learning and\nadapt transfer to learning our value function estimates in a novel manner. In\nthis paper, we consider the special case of transfer between the value function\nestimates in the $Q$-ensemble architecture of BootstrappedDQN. We further\nempirically demonstrate how our proposed framework can help in speeding up the\nlearning process in $Q$-ensembles with minimum computational overhead on a\nsuite of Atari 2600 Games.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 17:54:05 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Menon", "Rakesh R", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1709.04991", "submitter": "Adrian Sampson", "authors": "Alex Renda, Harrison Goldstein, Sarah Bird, Chris Quirk and Adrian\n  Sampson", "title": "Abstractions for AI-Based User Interfaces and Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel user interfaces based on artificial intelligence, such as\nnatural-language agents, present new categories of engineering challenges.\nThese systems need to cope with uncertainty and ambiguity, interface with\nmachine learning algorithms, and compose information from multiple users to\nmake decisions. We propose to treat these challenges as language-design\nproblems. We describe three programming language abstractions for three core\nproblems in intelligent system design. First, hypothetical worlds support\nnondeterministic search over spaces of alternative actions. Second, a feature\ntype system abstracts the interaction between applications and learning\nalgorithms. Finally, constructs for collaborative execution extend hypothetical\nworlds across multiple machines while controlling access to private data. We\nenvision these features as first steps toward a complete language for\nimplementing AI-based interfaces and applications.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 21:53:01 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Renda", "Alex", ""], ["Goldstein", "Harrison", ""], ["Bird", "Sarah", ""], ["Quirk", "Chris", ""], ["Sampson", "Adrian", ""]]}, {"id": "1709.05014", "submitter": "Gonzalo Estr\\'an Buyo", "authors": "Gonzalo Estr\\'an Buyo", "title": "WOAH: Preliminaries to Zero-shot Ontology Learning for Conversational\n  Agents", "comments": "ICTIR' 17 Workshop on Search-Oriented Conversational AI (SCAI' 2017),\n  5 pages, LaTeX; typo corrected in the diagram", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper presents the Weighted Ontology Approximation Heuristic\n(WOAH), a novel zero-shot approach to ontology estimation for conversational\nagents development environments. This methodology extracts verbs and nouns\nseparately from data by distilling the dependencies obtained and applying\nsimilarity and sparsity metrics to generate an ontology estimation configurable\nin terms of the level of generalization.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 00:12:08 GMT"}, {"version": "v2", "created": "Tue, 19 Sep 2017 22:33:18 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Buyo", "Gonzalo Estr\u00e1n", ""]]}, {"id": "1709.05021", "submitter": "Ervin Teng", "authors": "Ervin Teng, Jo\\~ao Diogo Falc\\~ao, Bob Iannucci", "title": "ClickBAIT: Click-based Accelerated Incremental Training of Convolutional\n  Neural Networks", "comments": "11 pages, 14 figures. Datasets available at\n  http://clickbait.crossmobile.info", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's general-purpose deep convolutional neural networks (CNN) for image\nclassification and object detection are trained offline on large static\ndatasets. Some applications, however, will require training in real-time on\nlive video streams with a human-in-the-loop. We refer to this class of problem\nas Time-ordered Online Training (ToOT) - these problems will require a\nconsideration of not only the quantity of incoming training data, but the human\neffort required to tag and use it. In this paper, we define training benefit as\na metric to measure the effectiveness of a sequence in using each user\ninteraction. We demonstrate and evaluate a system tailored to performing ToOT\nin the field, capable of training an image classifier on a live video stream\nthrough minimal input from a human operator. We show that by exploiting the\ntime-ordered nature of the video stream through optical flow-based object\ntracking, we can increase the effectiveness of human actions by about 8 times.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 00:58:38 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Teng", "Ervin", ""], ["Falc\u00e3o", "Jo\u00e3o Diogo", ""], ["Iannucci", "Bob", ""]]}, {"id": "1709.05027", "submitter": "Wei Wen", "authors": "Wei Wen, Yuxiong He, Samyam Rajbhandari, Minjia Zhang, Wenhan Wang,\n  Fang Liu, Bin Hu, Yiran Chen, Hai Li", "title": "Learning Intrinsic Sparse Structures within Long Short-Term Memory", "comments": "Published in ICLR 2018 ( the Sixth International Conference on\n  Learning Representations)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression is significant for the wide adoption of Recurrent Neural\nNetworks (RNNs) in both user devices possessing limited resources and business\nclusters requiring quick responses to large-scale service requests. This work\naims to learn structurally-sparse Long Short-Term Memory (LSTM) by reducing the\nsizes of basic structures within LSTM units, including input updates, gates,\nhidden states, cell states and outputs. Independently reducing the sizes of\nbasic structures can result in inconsistent dimensions among them, and\nconsequently, end up with invalid LSTM units. To overcome the problem, we\npropose Intrinsic Sparse Structures (ISS) in LSTMs. Removing a component of ISS\nwill simultaneously decrease the sizes of all basic structures by one and\nthereby always maintain the dimension consistency. By learning ISS within LSTM\nunits, the obtained LSTMs remain regular while having much smaller basic\nstructures. Based on group Lasso regularization, our method achieves 10.59x\nspeedup without losing any perplexity of a language modeling of Penn TreeBank\ndataset. It is also successfully evaluated through a compact model with only\n2.69M weights for machine Question Answering of SQuAD dataset. Our approach is\nsuccessfully extended to non- LSTM RNNs, like Recurrent Highway Networks\n(RHNs). Our source code is publicly available at\nhttps://github.com/wenwei202/iss-rnns\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 01:10:23 GMT"}, {"version": "v2", "created": "Fri, 13 Oct 2017 17:23:05 GMT"}, {"version": "v3", "created": "Sat, 28 Oct 2017 15:49:22 GMT"}, {"version": "v4", "created": "Sun, 24 Dec 2017 19:24:23 GMT"}, {"version": "v5", "created": "Fri, 5 Jan 2018 16:23:10 GMT"}, {"version": "v6", "created": "Tue, 30 Jan 2018 04:42:43 GMT"}, {"version": "v7", "created": "Sun, 11 Feb 2018 16:36:32 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Wen", "Wei", ""], ["He", "Yuxiong", ""], ["Rajbhandari", "Samyam", ""], ["Zhang", "Minjia", ""], ["Wang", "Wenhan", ""], ["Liu", "Fang", ""], ["Hu", "Bin", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "1709.05036", "submitter": "Yu Hsueh Wu", "authors": "Tzu-Chien Liu, Yu-Hsueh Wu, Hung-Yi Lee", "title": "Query-based Attention CNN for Text Similarity Map", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Query-based Attention CNN(QACNN) for Text\nSimilarity Map, an end-to-end neural network for question answering. This\nnetwork is composed of compare mechanism, two-staged CNN architecture with\nattention mechanism, and a prediction layer. First, the compare mechanism\ncompares between the given passage, query, and multiple answer choices to build\nsimilarity maps. Then, the two-staged CNN architecture extracts features\nthrough word-level and sentence-level. At the same time, attention mechanism\nhelps CNN focus more on the important part of the passage based on the query\ninformation. Finally, the prediction layer find out the most possible answer\nchoice. We conduct this model on the MovieQA dataset using Plot Synopses only,\nand achieve 79.99% accuracy which is the state of the art on the dataset.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 02:25:57 GMT"}, {"version": "v2", "created": "Wed, 18 Oct 2017 14:01:20 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Liu", "Tzu-Chien", ""], ["Wu", "Yu-Hsueh", ""], ["Lee", "Hung-Yi", ""]]}, {"id": "1709.05047", "submitter": "Yang Li", "authors": "Yang Li, Quan Pan, Suhang Wang, Haiyun Peng, Tao Yang, Erik Cambria", "title": "Disentangled Variational Auto-Encoder for Semi-supervised Learning", "comments": "6 figures, 10 pages, Information Sciences 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning is attracting increasing attention due to the fact\nthat datasets of many domains lack enough labeled data. Variational\nAuto-Encoder (VAE), in particular, has demonstrated the benefits of\nsemi-supervised learning. The majority of existing semi-supervised VAEs utilize\na classifier to exploit label information, where the parameters of the\nclassifier are introduced to the VAE. Given the limited labeled data, learning\nthe parameters for the classifiers may not be an optimal solution for\nexploiting label information. Therefore, in this paper, we develop a novel\napproach for semi-supervised VAE without classifier. Specifically, we propose a\nnew model called Semi-supervised Disentangled VAE (SDVAE), which encodes the\ninput data into disentangled representation and non-interpretable\nrepresentation, then the category information is directly utilized to\nregularize the disentangled representation via the equality constraint. To\nfurther enhance the feature learning ability of the proposed VAE, we\nincorporate reinforcement learning to relieve the lack of data. The dynamic\nframework is capable of dealing with both image and text data with its\ncorresponding encoder and decoder networks. Extensive experiments on image and\ntext datasets demonstrate the effectiveness of the proposed framework.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 03:39:53 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 07:42:21 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Li", "Yang", ""], ["Pan", "Quan", ""], ["Wang", "Suhang", ""], ["Peng", "Haiyun", ""], ["Yang", "Tao", ""], ["Cambria", "Erik", ""]]}, {"id": "1709.05067", "submitter": "Neelanshi Varia", "authors": "Mahipal Jadeja, Neelanshi Varia and Agam Shah", "title": "Deep Reinforcement Learning for Conversational AI", "comments": "SCAI'17-Search-Oriented Conversational AI (@ICTIR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning is revolutionizing the artificial intelligence\nfield. Currently, it serves as a good starting point for constructing\nintelligent autonomous systems which offer a better knowledge of the visual\nworld. It is possible to scale deep reinforcement learning with the use of deep\nlearning and do amazing tasks such as use of pixels in playing video games. In\nthis paper, key concepts of deep reinforcement learning including reward\nfunction, differences between reinforcement learning and supervised learning\nand models for implementation of reinforcement are discussed. Key challenges\nrelated to the implementation of reinforcement learning in conversational AI\ndomain are identified as well as discussed in detail. Various conversational\nmodels which are based on deep reinforcement learning (as well as deep\nlearning) are also discussed. In summary, this paper discusses key aspects of\ndeep reinforcement learning which are crucial for designing an efficient\nconversational AI.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 06:18:33 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Jadeja", "Mahipal", ""], ["Varia", "Neelanshi", ""], ["Shah", "Agam", ""]]}, {"id": "1709.05077", "submitter": "Yuanlong Li", "authors": "Yuanlong Li, Yonggang Wen, Kyle Guan, Dacheng Tao", "title": "Transforming Cooling Optimization for Green Data Center via Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cooling system plays a critical role in a modern data center (DC). Developing\nan optimal control policy for DC cooling system is a challenging task. The\nprevailing approaches often rely on approximating system models that are built\nupon the knowledge of mechanical cooling, electrical and thermal management,\nwhich is difficult to design and may lead to sub-optimal or unstable\nperformances. In this paper, we propose utilizing the large amount of\nmonitoring data in DC to optimize the control policy. To do so, we cast the\ncooling control policy design into an energy cost minimization problem with\ntemperature constraints, and tap it into the emerging deep reinforcement\nlearning (DRL) framework. Specifically, we propose an end-to-end cooling\ncontrol algorithm (CCA) that is based on the actor-critic framework and an\noff-policy offline version of the deep deterministic policy gradient (DDPG)\nalgorithm. In the proposed CCA, an evaluation network is trained to predict an\nenergy cost counter penalized by the cooling status of the DC room, and a\npolicy network is trained to predict optimized control settings when gave the\ncurrent load and weather information. The proposed algorithm is evaluated on\nthe EnergyPlus simulation platform and on a real data trace collected from the\nNational Super Computing Centre (NSCC) of Singapore. Our results show that the\nproposed CCA can achieve about 11% cooling cost saving on the simulation\nplatform compared with a manually configured baseline control algorithm. In the\ntrace-based study, we propose a de-underestimation validation mechanism as we\ncannot directly test the algorithm on a real DC. Even though with DUE the\nresults are conservative, we can still achieve about 15% cooling energy saving\non the NSCC data trace if we set the inlet temperature threshold at 26.6 degree\nCelsius.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 07:14:35 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 03:13:28 GMT"}, {"version": "v3", "created": "Mon, 16 Jul 2018 14:32:02 GMT"}, {"version": "v4", "created": "Wed, 18 Jul 2018 13:42:59 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Li", "Yuanlong", ""], ["Wen", "Yonggang", ""], ["Guan", "Kyle", ""], ["Tao", "Dacheng", ""]]}, {"id": "1709.05107", "submitter": "Ke Chen", "authors": "Qian Wang and Ke Chen", "title": "Multi-Label Zero-Shot Human Action Recognition via Joint Latent Ranking\n  Embedding", "comments": "27 pages, 10 figures and 7 tables. Technical report submitted to a\n  journal. More experimental results/references were added and typos were\n  corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human action recognition refers to automatic recognizing human actions from a\nvideo clip. In reality, there often exist multiple human actions in a video\nstream. Such a video stream is often weakly-annotated with a set of relevant\nhuman action labels at a global level rather than assigning each label to a\nspecific video episode corresponding to a single action, which leads to a\nmulti-label learning problem. Furthermore, there are many meaningful human\nactions in reality but it would be extremely difficult to collect/annotate\nvideo clips regarding all of various human actions, which leads to a zero-shot\nlearning scenario. To the best of our knowledge, there is no work that has\naddressed all the above issues together in human action recognition. In this\npaper, we formulate a real-world human action recognition task as a multi-label\nzero-shot learning problem and propose a framework to tackle this problem in a\nholistic way. Our framework holistically tackles the issue of unknown temporal\nboundaries between different actions for multi-label learning and exploits the\nside information regarding the semantic relationship between different human\nactions for knowledge transfer. Consequently, our framework leads to a joint\nlatent ranking embedding for multi-label zero-shot human action recognition. A\nnovel neural architecture of two component models and an alternate learning\nalgorithm are proposed to carry out the joint latent ranking embedding\nlearning. Thus, multi-label zero-shot recognition is done by measuring\nrelatedness scores of action labels to a test video clip in the joint latent\nvisual and semantic embedding spaces. We evaluate our framework with different\nsettings, including a novel data split scheme designed especially for\nevaluating multi-label zero-shot learning, on two datasets: Breakfast and\nCharades. The experimental results demonstrate the effectiveness of our\nframework.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 08:44:02 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 08:51:15 GMT"}, {"version": "v3", "created": "Wed, 6 Feb 2019 12:42:58 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Wang", "Qian", ""], ["Chen", "Ke", ""]]}, {"id": "1709.05116", "submitter": "Yuan Du", "authors": "Yuan Du, Li Du, Yilei Li, Junjie Su, Mau-Chung Frank Chang", "title": "A Streaming Accelerator for Deep Convolutional Neural Networks with\n  Image and Feature Decomposition for Resource-limited System Applications", "comments": "5 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNN) are widely used in modern artificial\nintelligence (AI) and smart vision systems but also limited by computation\nlatency, throughput, and energy efficiency on a resource-limited scenario, such\nas mobile devices, internet of things (IoT), unmanned aerial vehicles (UAV),\nand so on. A hardware streaming architecture is proposed to accelerate\nconvolution and pooling computations for state-of-the-art deep CNNs. It is\noptimized for energy efficiency by maximizing local data reuse to reduce\noff-chip DRAM data access. In addition, image and feature decomposition\ntechniques are introduced to optimize memory access pattern for an arbitrary\nsize of image and number of features within limited on-chip SRAM capacity. A\nprototype accelerator was implemented in TSMC 65 nm CMOS technology with 2.3 mm\nx 0.8 mm core area, which achieves 144 GOPS peak throughput and 0.8 TOPS/W peak\nenergy efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 09:03:42 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Du", "Yuan", ""], ["Du", "Li", ""], ["Li", "Yilei", ""], ["Su", "Junjie", ""], ["Chang", "Mau-Chung Frank", ""]]}, {"id": "1709.05185", "submitter": "Timoth\\'ee Lesort", "authors": "Timoth\\'ee Lesort, Mathieu Seurin, Xinrui Li, Natalia\n  D\\'iaz-Rodr\\'iguez and David Filliat", "title": "Unsupervised state representation learning with robotic priors: a\n  robustness benchmark", "comments": "ICRA 2018 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our understanding of the world depends highly on our capacity to produce\nintuitive and simplified representations which can be easily used to solve\nproblems. We reproduce this simplification process using a neural network to\nbuild a low dimensional state representation of the world from images acquired\nby a robot. As in Jonschkowski et al. 2015, we learn in an unsupervised way\nusing prior knowledge about the world as loss functions called robotic priors\nand extend this approach to high dimension richer images to learn a 3D\nrepresentation of the hand position of a robot from RGB images. We propose a\nquantitative evaluation of the learned representation using nearest neighbors\nin the state space that allows to assess its quality and show both the\npotential and limitations of robotic priors in realistic environments. We\naugment image size, add distractors and domain randomization, all crucial\ncomponents to achieve transfer learning to real robots. Finally, we also\ncontribute a new prior to improve the robustness of the representation. The\napplications of such low dimensional state representation range from easing\nreinforcement learning (RL) and knowledge transfer across tasks, to\nfacilitating learning from raw data with more efficient and compact high level\nrepresentations. The results show that the robotic prior approach is able to\nextract high level representation as the 3D position of an arm and organize it\ninto a compact and coherent space of states in a challenging dataset.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 13:15:58 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Lesort", "Timoth\u00e9e", ""], ["Seurin", "Mathieu", ""], ["Li", "Xinrui", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""], ["Filliat", "David", ""]]}, {"id": "1709.05231", "submitter": "Argyris Kalogeratos", "authors": "Kevin Scaman, Argyris Kalogeratos, Luca Corinzia, Nicolas Vayatis", "title": "A Spectral Method for Activity Shaping in Continuous-Time Information\n  Cascades", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information Cascades Model captures dynamical properties of user activity in\na social network. In this work, we develop a novel framework for activity\nshaping under the Continuous-Time Information Cascades Model which allows the\nadministrator for local control actions by allocating targeted resources that\ncan alter the spread of the process. Our framework employs the optimization of\nthe spectral radius of the Hazard matrix, a quantity that has been shown to\ndrive the maximum influence in a network, while enjoying a simple convex\nrelaxation when used to minimize the influence of the cascade. In addition,\nuse-cases such as quarantine and node immunization are discussed to highlight\nthe generality of the proposed activity shaping framework. Finally, we present\nthe NetShape influence minimization method which is compared favorably to\nbaseline and state-of-the-art approaches through simulations on real social\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 14:32:36 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Scaman", "Kevin", ""], ["Kalogeratos", "Argyris", ""], ["Corinzia", "Luca", ""], ["Vayatis", "Nicolas", ""]]}, {"id": "1709.05246", "submitter": "Baojian Zhou", "authors": "Feng Chen, Baojian Zhou, Adil Alim, Liang Zhao", "title": "A Generic Framework for Interesting Subspace Cluster Detection in\n  Multi-attributed Networks", "comments": "18 pages, Accepted by IEEE International Conference on Data Mining\n  (ICDM), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of interesting (e.g., coherent or anomalous) clusters has been\nstudied extensively on plain or univariate networks, with various applications.\nRecently, algorithms have been extended to networks with multiple attributes\nfor each node in the real-world. In a multi-attributed network, often, a\ncluster of nodes is only interesting for a subset (subspace) of attributes, and\nthis type of clusters is called subspace clusters. However, in the current\nliterature, few methods are capable of detecting subspace clusters, which\ninvolves concurrent feature selection and network cluster detection. These\nrelevant methods are mostly heuristic-driven and customized for specific\napplication scenarios.\n  In this work, we present a generic and theoretical framework for detection of\ninteresting subspace clusters in large multi-attributed networks. Specifically,\nwe propose a subspace graph-structured matching pursuit algorithm, namely,\nSG-Pursuit, to address a broad class of such problems for different score\nfunctions (e.g., coherence or anomalous functions) and topology constraints\n(e.g., connected subgraphs and dense subgraphs). We prove that our algorithm 1)\nruns in nearly-linear time on the network size and the total number of\nattributes and 2) enjoys rigorous guarantees (geometrical convergence rate and\ntight error bound) analogous to those of the state-of-the-art algorithms for\nsparse feature selection problems and subgraph detection problems. As a case\nstudy, we specialize SG-Pursuit to optimize a number of well-known score\nfunctions for two typical tasks, including detection of coherent dense and\nanomalous connected subspace clusters in real-world networks. Empirical\nevidence demonstrates that our proposed generic algorithm SG-Pursuit performs\nsuperior over state-of-the-art methods that are designed specifically for these\ntwo tasks.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 14:58:49 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 15:09:11 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Chen", "Feng", ""], ["Zhou", "Baojian", ""], ["Alim", "Adil", ""], ["Zhao", "Liang", ""]]}, {"id": "1709.05262", "submitter": "Vikas Garg", "authors": "Vikas K. Garg, Adam Kalai", "title": "Supervising Unsupervised Learning", "comments": "11 two column pages. arXiv admin note: substantial text overlap with\n  arXiv:1612.09030", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework to leverage knowledge acquired from a repository of\n(heterogeneous) supervised datasets to new unsupervised datasets. Our\nperspective avoids the subjectivity inherent in unsupervised learning by\nreducing it to supervised learning, and provides a principled way to evaluate\nunsupervised algorithms. We demonstrate the versatility of our framework via\nsimple agnostic bounds on unsupervised problems. In the context of clustering,\nour approach helps choose the number of clusters and the clustering algorithm,\nremove the outliers, and provably circumvent the Kleinberg's impossibility\nresult. Experimental results across hundreds of problems demonstrate improved\nperformance on unsupervised data with simple algorithms, despite the fact that\nour problems come from heterogeneous domains. Additionally, our framework lets\nus leverage deep networks to learn common features from many such small\ndatasets, and perform zero shot learning.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 14:42:41 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 14:08:39 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Garg", "Vikas K.", ""], ["Kalai", "Adam", ""]]}, {"id": "1709.05278", "submitter": "Daoud Clarke", "authors": "Dion Bailey, Tom Pajak, Daoud Clarke, Carlos Rodriguez", "title": "Algorithms and Architecture for Real-time Recommendations at News UK", "comments": "Accepted for presentation at AI-2017 Thirty-seventh SGAI\n  International Conference on Artificial Intelligence. Cambridge, England 12-14\n  December 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems are recognised as being hugely important in industry,\nand the area is now well understood. At News UK, there is a requirement to be\nable to quickly generate recommendations for users on news items as they are\npublished. However, little has been published about systems that can generate\nrecommendations in response to changes in recommendable items and user\nbehaviour in a very short space of time. In this paper we describe a new\nalgorithm for updating collaborative filtering models incrementally, and\ndemonstrate its effectiveness on clickstream data from The Times. We also\ndescribe the architecture that allows recommendations to be generated on the\nfly, and how we have made each component scalable. The system is currently\nbeing used in production at News UK.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 15:47:23 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Bailey", "Dion", ""], ["Pajak", "Tom", ""], ["Clarke", "Daoud", ""], ["Rodriguez", "Carlos", ""]]}, {"id": "1709.05293", "submitter": "Mehul Bhatt", "authors": "Jakob Suchan and Mehul Bhatt", "title": "Commonsense Scene Semantics for Cognitive Robotics: Towards Grounding\n  Embodied Visuo-Locomotive Interactions", "comments": "to appear in: ICCV 2017 Workshop - Vision in Practice on Autonomous\n  Robots (ViPAR), International Conference on Computer Vision (ICCV), Venice,\n  Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a commonsense, qualitative model for the semantic grounding of\nembodied visuo-spatial and locomotive interactions. The key contribution is an\nintegrative methodology combining low-level visual processing with high-level,\nhuman-centred representations of space and motion rooted in artificial\nintelligence. We demonstrate practical applicability with examples involving\nobject interactions, and indoor movement.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 16:22:56 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Suchan", "Jakob", ""], ["Bhatt", "Mehul", ""]]}, {"id": "1709.05341", "submitter": "Stefano Germano", "authors": "Stefano Germano, Francesco Calimeri, Eliana Palermiti", "title": "LoIDE: a web-based IDE for Logic Programming - Preliminary Technical\n  Report", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic-based paradigms are nowadays widely used in many different fields, also\nthank to the availability of robust tools and systems that allow the\ndevelopment of real-world and industrial applications.\n  In this work we present LoIDE, an advanced and modular web-editor for\nlogic-based languages that also integrates with state-of-the-art solvers.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 18:15:36 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Germano", "Stefano", ""], ["Calimeri", "Francesco", ""], ["Palermiti", "Eliana", ""]]}, {"id": "1709.05360", "submitter": "Zhongang Qi", "authors": "Zhongang Qi, Saeed Khorram, Fuxin Li", "title": "Embedding Deep Networks into Visual Explanations", "comments": null, "journal-ref": "Artificial Intelligence (2020)", "doi": "10.1016/j.artint.2020.103435", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel Explanation Neural Network (XNN) to explain\nthe predictions made by a deep network. The XNN works by learning a nonlinear\nembedding of a high-dimensional activation vector of a deep network layer into\na low-dimensional explanation space while retaining faithfulness i.e., the\noriginal deep learning predictions can be constructed from the few concepts\nextracted by our explanation network. We then visualize such concepts for human\nto learn about the high-level concepts that the deep network is using to make\ndecisions. We propose an algorithm called Sparse Reconstruction Autoencoder\n(SRAE) for learning the embedding to the explanation space. SRAE aims to\nreconstruct part of the original feature space while retaining faithfulness. A\npull-away term is applied to SRAE to make the bases of the explanation space\nmore orthogonal to each other. A visualization system is then introduced for\nhuman understanding of the features in the explanation space. The proposed\nmethod is applied to explain CNN models in image classification tasks. We\nconducted a human study, which shows that the proposed approach outperforms\nsingle saliency map baselines, and improves human performance on a difficult\nclassification tasks. Also, several novel metrics are introduced to evaluate\nthe performance of explanations quantitatively without human involvement.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 18:16:34 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2018 01:13:52 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 09:26:19 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Qi", "Zhongang", ""], ["Khorram", "Saeed", ""], ["Li", "Fuxin", ""]]}, {"id": "1709.05380", "submitter": "Brendan O'Donoghue", "authors": "Brendan O'Donoghue, Ian Osband, Remi Munos, Volodymyr Mnih", "title": "The Uncertainty Bellman Equation and Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the exploration/exploitation problem in reinforcement learning.\nFor exploitation, it is well known that the Bellman equation connects the value\nat any time-step to the expected value at subsequent time-steps. In this paper\nwe consider a similar \\textit{uncertainty} Bellman equation (UBE), which\nconnects the uncertainty at any time-step to the expected uncertainties at\nsubsequent time-steps, thereby extending the potential exploratory benefit of a\npolicy beyond individual time-steps. We prove that the unique fixed point of\nthe UBE yields an upper bound on the variance of the posterior distribution of\nthe Q-values induced by any policy. This bound can be much tighter than\ntraditional count-based bonuses that compound standard deviation rather than\nvariance. Importantly, and unlike several existing approaches to optimism, this\nmethod scales naturally to large systems with complex generalization.\nSubstituting our UBE-exploration strategy for $\\epsilon$-greedy improves DQN\nperformance on 51 out of 57 games in the Atari suite.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 19:55:58 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 11:47:43 GMT"}, {"version": "v3", "created": "Tue, 19 Jun 2018 15:42:36 GMT"}, {"version": "v4", "created": "Mon, 22 Oct 2018 15:25:04 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["O'Donoghue", "Brendan", ""], ["Osband", "Ian", ""], ["Munos", "Remi", ""], ["Mnih", "Volodymyr", ""]]}, {"id": "1709.05436", "submitter": "Yuanlu Xu", "authors": "Hang Qi, Yuanlu Xu, Tao Yuan, Tianfu Wu, Song-Chun Zhu", "title": "Scene-centric Joint Parsing of Cross-view Videos", "comments": "Accepted by AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-view video understanding is an important yet under-explored area in\ncomputer vision. In this paper, we introduce a joint parsing framework that\nintegrates view-centric proposals into scene-centric parse graphs that\nrepresent a coherent scene-centric understanding of cross-view scenes. Our key\nobservations are that overlapping fields of views embed rich appearance and\ngeometry correlations and that knowledge fragments corresponding to individual\nvision tasks are governed by consistency constraints available in commonsense\nknowledge. The proposed joint parsing framework represents such correlations\nand constraints explicitly and generates semantic scene-centric parse graphs.\nQuantitative experiments show that scene-centric predictions in the parse graph\noutperform view-centric predictions.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 00:21:29 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 23:01:01 GMT"}, {"version": "v3", "created": "Mon, 5 Feb 2018 05:59:11 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Qi", "Hang", ""], ["Xu", "Yuanlu", ""], ["Yuan", "Tao", ""], ["Wu", "Tianfu", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1709.05437", "submitter": "Yuanlu Xu", "authors": "Yuanlu Xu, Lei Qin, Xiaobai Liu, Jianwen Xie, Song-Chun Zhu", "title": "A Causal And-Or Graph Model for Visibility Fluent Reasoning in Tracking\n  Interacting Objects", "comments": "accepted by CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracking humans that are interacting with the other subjects or environment\nremains unsolved in visual tracking, because the visibility of the human of\ninterests in videos is unknown and might vary over time. In particular, it is\nstill difficult for state-of-the-art human trackers to recover complete human\ntrajectories in crowded scenes with frequent human interactions. In this work,\nwe consider the visibility status of a subject as a fluent variable, whose\nchange is mostly attributed to the subject's interaction with the surrounding,\ne.g., crossing behind another object, entering a building, or getting into a\nvehicle, etc. We introduce a Causal And-Or Graph (C-AOG) to represent the\ncausal-effect relations between an object's visibility fluent and its\nactivities, and develop a probabilistic graph model to jointly reason the\nvisibility fluent change (e.g., from visible to invisible) and track humans in\nvideos. We formulate this joint task as an iterative search of a feasible\ncausal graph structure that enables fast search algorithm, e.g., dynamic\nprogramming method. We apply the proposed method on challenging video sequences\nto evaluate its capabilities of estimating visibility fluent changes of\nsubjects and tracking subjects of interests over time. Results with comparisons\ndemonstrate that our method outperforms the alternative trackers and can\nrecover complete trajectories of humans in complicated scenarios with frequent\nhuman interactions.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 00:21:44 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 02:05:45 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Xu", "Yuanlu", ""], ["Qin", "Lei", ""], ["Liu", "Xiaobai", ""], ["Xie", "Jianwen", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1709.05440", "submitter": "Shuhong Chen", "authors": "Shuhong Chen, Sen Yang, Moliang Zhou, Randall S. Burd, Ivan Marsic", "title": "Process-oriented Iterative Multiple Alignment for Medical Process Mining", "comments": "accepted at ICDMW 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adapted from biological sequence alignment, trace alignment is a process\nmining technique used to visualize and analyze workflow data. Any analysis done\nwith this method, however, is affected by the alignment quality. The best\nexisting trace alignment techniques use progressive guide-trees to\nheuristically approximate the optimal alignment in O(N2L2) time. These\nalgorithms are heavily dependent on the selected guide-tree metric, often\nreturn sum-of-pairs-score-reducing errors that interfere with interpretation,\nand are computationally intensive for large datasets. To alleviate these\nissues, we propose process-oriented iterative multiple alignment (PIMA), which\ncontains specialized optimizations to better handle workflow data. We\ndemonstrate that PIMA is a flexible framework capable of achieving better\nsum-of-pairs score than existing trace alignment algorithms in only O(NL2)\ntime. We applied PIMA to analyzing medical workflow data, showing how iterative\nalignment can better represent the data and facilitate the extraction of\ninsights from data visualization.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 00:51:39 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Chen", "Shuhong", ""], ["Yang", "Sen", ""], ["Zhou", "Moliang", ""], ["Burd", "Randall S.", ""], ["Marsic", "Ivan", ""]]}, {"id": "1709.05453", "submitter": "Tom Young", "authors": "Tom Young, Erik Cambria, Iti Chaturvedi, Minlie Huang, Hao Zhou,\n  Subham Biswas", "title": "Augmenting End-to-End Dialog Systems with Commonsense Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building dialog agents that can converse naturally with humans is a\nchallenging yet intriguing problem of artificial intelligence. In open-domain\nhuman-computer conversation, where the conversational agent is expected to\nrespond to human responses in an interesting and engaging way, commonsense\nknowledge has to be integrated into the model effectively. In this paper, we\ninvestigate the impact of providing commonsense knowledge about the concepts\ncovered in the dialog. Our model represents the first attempt to integrating a\nlarge commonsense knowledge base into end-to-end conversational models. In the\nretrieval-based scenario, we propose the Tri-LSTM model to jointly take into\naccount message and commonsense for selecting an appropriate response. Our\nexperiments suggest that the knowledge-augmented models are superior to their\nknowledge-free counterparts in automatic evaluation.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 04:14:53 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 05:52:45 GMT"}, {"version": "v3", "created": "Mon, 12 Feb 2018 14:13:21 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Young", "Tom", ""], ["Cambria", "Erik", ""], ["Chaturvedi", "Iti", ""], ["Huang", "Minlie", ""], ["Zhou", "Hao", ""], ["Biswas", "Subham", ""]]}, {"id": "1709.05576", "submitter": "Manolis Peponakis", "authors": "Anna Mastora, Manolis Peponakis, Sarantos Kapidakis", "title": "SKOS Concepts and Natural Language Concepts: an Analysis of Latent\n  Relationships in KOSs", "comments": "18 pages, 5 tables", "journal-ref": "Journal of Information Science, 43(4), 492-508 (2017)", "doi": "10.1177/0165551516648108", "report-no": null, "categories": "cs.DL cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The vehicle to represent Knowledge Organization Systems (KOSs) in the\nenvironment of the Semantic Web and linked data is the Simple Knowledge\nOrganization System (SKOS). SKOS provides a way to assign a URI to each\nconcept, and this URI functions as a surrogate for the concept. This fact makes\nof main concern the need to clarify the URIs' ontological meaning. The aim of\nthis study is to investigate the relation between the ontological substance of\nKOS concepts and concepts revealed through the grammatical and syntactic\nformalisms of natural language. For this purpose, we examined the dividableness\nof concepts in specific KOSs (i.e. a thesaurus, a subject headings system and a\nclassification scheme) by applying Natural Language Processing (NLP) techniques\n(i.e. morphosyntactic analysis) to the lexical representations (i.e. RDF\nliterals) of SKOS concepts. The results of the comparative analysis reveal\nthat, despite the use of multi-word units, thesauri tend to represent concepts\nin a way that can hardly be further divided conceptually, while Subject\nHeadings and Classification Schemes - to a certain extent - comprise terms that\ncan be decomposed into more conceptual constituents. Consequently, SKOS\nconcepts deriving from thesauri are more likely to represent atomic conceptual\nunits and thus be more appropriate tools for inference and reasoning. Since\nidentifiers represent the meaning of a concept, complex concepts are neither\nthe most appropriate nor the most efficient way of modelling a KOS for the\nSemantic Web.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 22:58:13 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Mastora", "Anna", ""], ["Peponakis", "Manolis", ""], ["Kapidakis", "Sarantos", ""]]}, {"id": "1709.05601", "submitter": "Arend Hintze", "authors": "Arend Hintze, Jeffrey A. Edlund, Randal S. Olson, David B. Knoester,\n  Jory Schossau, Larissa Albantakis, Ali Tehrani-Saleh, Peter Kvam, Leigh\n  Sheneman, Heather Goldsby, Clifford Bohm, Christoph Adami", "title": "Markov Brains: A Technical Introduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Brains are a class of evolvable artificial neural networks (ANN). They\ndiffer from conventional ANNs in many aspects, but the key difference is that\ninstead of a layered architecture, with each node performing the same function,\nMarkov Brains are networks built from individual computational components.\nThese computational components interact with each other, receive inputs from\nsensors, and control motor outputs. The function of the computational\ncomponents, their connections to each other, as well as connections to sensors\nand motors are all subject to evolutionary optimization. Here we describe in\ndetail how a Markov Brain works, what techniques can be used to study them, and\nhow they can be evolved.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 03:12:06 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Hintze", "Arend", ""], ["Edlund", "Jeffrey A.", ""], ["Olson", "Randal S.", ""], ["Knoester", "David B.", ""], ["Schossau", "Jory", ""], ["Albantakis", "Larissa", ""], ["Tehrani-Saleh", "Ali", ""], ["Kvam", "Peter", ""], ["Sheneman", "Leigh", ""], ["Goldsby", "Heather", ""], ["Bohm", "Clifford", ""], ["Adami", "Christoph", ""]]}, {"id": "1709.05638", "submitter": "Milan Aggarwal", "authors": "Milan Aggarwal, Aarushi Arora, Shagun Sodhani, Balaji Krishnamurthy", "title": "Improving Search through A3C Reinforcement Learning based Conversational\n  Agent", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a reinforcement learning based search assistant which can assist\nusers through a set of actions and sequence of interactions to enable them\nrealize their intent. Our approach caters to subjective search where the user\nis seeking digital assets such as images which is fundamentally different from\nthe tasks which have objective and limited search modalities. Labeled\nconversational data is generally not available in such search tasks and\ntraining the agent through human interactions can be time consuming. We propose\na stochastic virtual user which impersonates a real user and can be used to\nsample user behavior efficiently to train the agent which accelerates the\nbootstrapping of the agent. We develop A3C algorithm based context preserving\narchitecture which enables the agent to provide contextual assistance to the\nuser. We compare the A3C agent with Q-learning and evaluate its performance on\naverage rewards and state values it obtains with the virtual user in validation\nepisodes. Our experiments show that the agent learns to achieve higher rewards\nand better states.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 10:56:41 GMT"}, {"version": "v2", "created": "Sun, 19 Aug 2018 08:00:34 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Aggarwal", "Milan", ""], ["Arora", "Aarushi", ""], ["Sodhani", "Shagun", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "1709.05666", "submitter": "Th\\'eo Trouillon", "authors": "Th\\'eo Trouillon, \\'Eric Gaussier, Christopher R. Dance, Guillaume\n  Bouchard", "title": "On Inductive Abilities of Latent Factor Models for Relational Learning", "comments": "30+3 pages, submitted to the Journal of Artificial Intelligence\n  Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent factor models are increasingly popular for modeling multi-relational\nknowledge graphs. By their vectorial nature, it is not only hard to interpret\nwhy this class of models works so well, but also to understand where they fail\nand how they might be improved. We conduct an experimental survey of\nstate-of-the-art models, not towards a purely comparative end, but as a means\nto get insight about their inductive abilities. To assess the strengths and\nweaknesses of each model, we create simple tasks that exhibit first, atomic\nproperties of binary relations, and then, common inter-relational inference\nthrough synthetic genealogies. Based on these experimental results, we propose\nnew research directions to improve on existing models.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 14:20:05 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Trouillon", "Th\u00e9o", ""], ["Gaussier", "\u00c9ric", ""], ["Dance", "Christopher R.", ""], ["Bouchard", "Guillaume", ""]]}, {"id": "1709.05684", "submitter": "Ehsan Arbabi", "authors": "Mohsen Sahraei Ardakani and Ehsan Arbabi", "title": "A Categorical Approach for Recognizing Emotional Effects of Music", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, digital music libraries have been developed and can be plainly\naccessed. Latest research showed that current organization and retrieval of\nmusic tracks based on album information are inefficient. Moreover, they\ndemonstrated that people use emotion tags for music tracks in order to search\nand retrieve them. In this paper, we discuss separability of a set of emotional\nlabels, proposed in the categorical emotion expression, using Fisher's\nseparation theorem. We determine a set of adjectives to tag music parts: happy,\nsad, relaxing, exciting, epic and thriller. Temporal, frequency and energy\nfeatures have been extracted from the music parts. It could be seen that the\nmaximum separability within the extracted features occurs between relaxing and\nepic music parts. Finally, we have trained a classifier using Support Vector\nMachines to automatically recognize and generate emotional labels for a music\npart. Accuracy for recognizing each label has been calculated; where the\nresults show that epic music can be recognized more accurately (77.4%),\ncomparing to the other types of music.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 16:04:41 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Ardakani", "Mohsen Sahraei", ""], ["Arbabi", "Ehsan", ""]]}, {"id": "1709.05703", "submitter": "Justin Gottschlich", "authors": "Kory Becker and Justin Gottschlich", "title": "AI Programmer: Autonomously Creating Software Programs Using Genetic\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the first-of-its-kind machine learning (ML) system,\ncalled AI Programmer, that can automatically generate full software programs\nrequiring only minimal human guidance. At its core, AI Programmer uses genetic\nalgorithms (GA) coupled with a tightly constrained programming language that\nminimizes the overhead of its ML search space. Part of AI Programmer's novelty\nstems from (i) its unique system design, including an embedded, hand-crafted\ninterpreter for efficiency and security and (ii) its augmentation of GAs to\ninclude instruction-gene randomization bindings and programming\nlanguage-specific genome construction and elimination techniques. We provide a\ndetailed examination of AI Programmer's system design, several examples\ndetailing how the system works, and experimental data demonstrating its\nsoftware generation capabilities and performance using only mainstream CPUs.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 18:17:55 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Becker", "Kory", ""], ["Gottschlich", "Justin", ""]]}, {"id": "1709.05706", "submitter": "Arbaaz Khan", "authors": "Arbaaz Khan, Clark Zhang, Nikolay Atanasov, Konstantinos Karydis,\n  Vijay Kumar, Daniel D. Lee", "title": "Memory Augmented Control Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning problems in partially observable environments cannot be solved\ndirectly with convolutional networks and require some form of memory. But, even\nmemory networks with sophisticated addressing schemes are unable to learn\nintelligent reasoning satisfactorily due to the complexity of simultaneously\nlearning to access memory and plan. To mitigate these challenges we introduce\nthe Memory Augmented Control Network (MACN). The proposed network architecture\nconsists of three main parts. The first part uses convolutions to extract\nfeatures and the second part uses a neural network-based planning module to\npre-plan in the environment. The third part uses a network controller that\nlearns to store those specific instances of past information that are necessary\nfor planning. The performance of the network is evaluated in discrete grid\nworld environments for path planning in the presence of simple and complex\nobstacles. We show that our network learns to plan and can generalize to new\nenvironments.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 19:06:13 GMT"}, {"version": "v2", "created": "Wed, 27 Sep 2017 05:11:23 GMT"}, {"version": "v3", "created": "Fri, 3 Nov 2017 03:34:58 GMT"}, {"version": "v4", "created": "Wed, 27 Dec 2017 00:24:40 GMT"}, {"version": "v5", "created": "Mon, 12 Feb 2018 01:25:55 GMT"}, {"version": "v6", "created": "Wed, 14 Feb 2018 05:34:03 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Khan", "Arbaaz", ""], ["Zhang", "Clark", ""], ["Atanasov", "Nikolay", ""], ["Karydis", "Konstantinos", ""], ["Kumar", "Vijay", ""], ["Lee", "Daniel D.", ""]]}, {"id": "1709.05746", "submitter": "Fangyi Zhang", "authors": "Fangyi Zhang, J\\\"urgen Leitner, Zongyuan Ge, Michael Milford, Peter\n  Corke", "title": "Adversarial Discriminative Sim-to-real Transfer of Visuo-motor Policies", "comments": "Under review for the International Journal of Robotics Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various approaches have been proposed to learn visuo-motor policies for\nreal-world robotic applications. One solution is first learning in simulation\nthen transferring to the real world. In the transfer, most existing approaches\nneed real-world images with labels. However, the labelling process is often\nexpensive or even impractical in many robotic applications. In this paper, we\npropose an adversarial discriminative sim-to-real transfer approach to reduce\nthe cost of labelling real data. The effectiveness of the approach is\ndemonstrated with modular networks in a table-top object reaching task where a\n7 DoF arm is controlled in velocity mode to reach a blue cuboid in clutter\nthrough visual observations. The adversarial transfer approach reduced the\nlabelled real data requirement by 50%. Policies can be transferred to real\nenvironments with only 93 labelled and 186 unlabelled real images. The\ntransferred visuo-motor policies are robust to novel (not seen in training)\nobjects in clutter and even a moving target, achieving a 97.8% success rate and\n1.8 cm control accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 02:27:02 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 09:38:25 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Zhang", "Fangyi", ""], ["Leitner", "J\u00fcrgen", ""], ["Ge", "Zongyuan", ""], ["Milford", "Michael", ""], ["Corke", "Peter", ""]]}, {"id": "1709.05774", "submitter": "Julian Straub", "authors": "Julian Straub, Randi Cabezas, John Leonard, John W. Fisher III", "title": "Direction-Aware Semi-Dense SLAM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To aide simultaneous localization and mapping (SLAM), future perception\nsystems will incorporate forms of scene understanding. In a step towards fully\nintegrated probabilistic geometric scene understanding, localization and\nmapping we propose the first direction-aware semi-dense SLAM system. It jointly\ninfers the directional Stata Center World (SCW) segmentation and a surfel-based\nsemi-dense map while performing real-time camera tracking. The joint SCW map\nmodel connects a scene-wide Bayesian nonparametric Dirichlet Process\nvon-Mises-Fisher mixture model (DP-vMF) prior on surfel orientations with the\nlocal surfel locations via a conditional random field (CRF). Camera tracking\nleverages the SCW segmentation to improve efficiency via guided observation\nselection. Results demonstrate improved SLAM accuracy and tracking efficiency\nat state of the art performance.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 04:49:40 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Straub", "Julian", ""], ["Cabezas", "Randi", ""], ["Leonard", "John", ""], ["Fisher", "John W.", "III"]]}, {"id": "1709.05825", "submitter": "Ondrej Kuzelka", "authors": "Ondrej Kuzelka, Yuyi Wang, Jesse Davis, Steven Schockaert", "title": "Relational Marginal Problems: Theory and Estimation", "comments": "Long version of a paper that appeared in AAAI 2018; added a paragraph\n  to Related Work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the propositional setting, the marginal problem is to find a\n(maximum-entropy) distribution that has some given marginals. We study this\nproblem in a relational setting and make the following contributions. First, we\ncompare two different notions of relational marginals. Second, we show a\nduality between the resulting relational marginal problems and the maximum\nlikelihood estimation of the parameters of relational models, which generalizes\na well-known duality from the propositional setting. Third, by exploiting the\nrelational marginal formulation, we present a statistically sound method to\nlearn the parameters of relational models that will be applied in settings\nwhere the number of constants differs between the training and test data.\nFurthermore, based on a relational generalization of marginal polytopes, we\ncharacterize cases where the standard estimators based on feature's number of\ntrue groundings needs to be adjusted and we quantitatively characterize the\nconsequences of these adjustments. Fourth, we prove bounds on expected errors\nof the estimated parameters, which allows us to lower-bound, among other\nthings, the effective sample size of relational training data.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 09:10:27 GMT"}, {"version": "v2", "created": "Sun, 19 Nov 2017 12:46:20 GMT"}, {"version": "v3", "created": "Tue, 17 Apr 2018 13:25:40 GMT"}, {"version": "v4", "created": "Wed, 25 Apr 2018 09:57:42 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Kuzelka", "Ondrej", ""], ["Wang", "Yuyi", ""], ["Davis", "Jesse", ""], ["Schockaert", "Steven", ""]]}, {"id": "1709.05870", "submitter": "Jiaxin Shi", "authors": "Jiaxin Shi, Jianfei Chen, Jun Zhu, Shengyang Sun, Yucen Luo, Yihong\n  Gu, Yuhao Zhou", "title": "ZhuSuan: A Library for Bayesian Deep Learning", "comments": "The GitHub page is at https://github.com/thu-ml/zhusuan", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce ZhuSuan, a python probabilistic programming\nlibrary for Bayesian deep learning, which conjoins the complimentary advantages\nof Bayesian methods and deep learning. ZhuSuan is built upon Tensorflow. Unlike\nexisting deep learning libraries, which are mainly designed for deterministic\nneural networks and supervised tasks, ZhuSuan is featured for its deep root\ninto Bayesian inference, thus supporting various kinds of probabilistic models,\nincluding both the traditional hierarchical Bayesian models and recent deep\ngenerative models. We use running examples to illustrate the probabilistic\nprogramming on ZhuSuan, including Bayesian logistic regression, variational\nauto-encoders, deep sigmoid belief networks and Bayesian recurrent neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 11:30:08 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Shi", "Jiaxin", ""], ["Chen", "Jianfei", ""], ["Zhu", "Jun", ""], ["Sun", "Shengyang", ""], ["Luo", "Yucen", ""], ["Gu", "Yihong", ""], ["Zhou", "Yuhao", ""]]}, {"id": "1709.05915", "submitter": "Wenji Li", "authors": "Zhun Fan, Wenji Li, Xinye Cai, Hui Li, Caimin Wei, Qingfu Zhang,\n  Kalyanmoy Deb, and Erik D. Goodman", "title": "Push and Pull Search for Solving Constrained Multi-objective\n  Optimization Problems", "comments": "13 pages, 10 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a push and pull search (PPS) framework for solving\nconstrained multi-objective optimization problems (CMOPs). To be more specific,\nthe proposed PPS divides the search process into two different stages,\nincluding the push and pull search stages. In the push stage, a multi-objective\nevolutionary algorithm (MOEA) is adopted to explore the search space without\nconsidering any constraints, which can help to get across infeasible regions\nvery fast and approach the unconstrained Pareto front. Furthermore, the\nlandscape of CMOPs with constraints can be probed and estimated in the push\nstage, which can be utilized to conduct the parameters setting for\nconstraint-handling approaches applied in the pull stage. Then, a constrained\nmulti-objective evolutionary algorithm (CMOEA) equipped with an improved\nepsilon constraint-handling is applied to pull the infeasible individuals\nachieved in the push stage to the feasible and non-dominated regions. Compared\nwith other CMOEAs, the proposed PPS method can more efficiently get across\ninfeasible regions and converge to the feasible and non-dominated regions by\napplying push and pull search strategies at different stages. To evaluate the\nperformance regarding convergence and diversity, a set of benchmark CMOPs is\nused to test the proposed PPS and compare with other five CMOEAs, including\nMOEA/D-CDP, MOEA/D-SR, C-MOEA/D, MOEA/D-Epsilon and MOEA/D-IEpsilon. The\ncomprehensive experimental results demonstrate that the proposed PPS achieves\nsignificantly better or competitive performance than the other five CMOEAs on\nmost of the benchmark set.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 13:18:55 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Fan", "Zhun", ""], ["Li", "Wenji", ""], ["Cai", "Xinye", ""], ["Li", "Hui", ""], ["Wei", "Caimin", ""], ["Zhang", "Qingfu", ""], ["Deb", "Kalyanmoy", ""], ["Goodman", "Erik D.", ""]]}, {"id": "1709.05943", "submitter": "Alexander Wong", "authors": "Mohammad Javad Shafiee, Brendan Chywl, Francis Li, and Alexander Wong", "title": "Fast YOLO: A Fast You Only Look Once System for Real-time Embedded\n  Object Detection in Video", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection is considered one of the most challenging problems in this\nfield of computer vision, as it involves the combination of object\nclassification and object localization within a scene. Recently, deep neural\nnetworks (DNNs) have been demonstrated to achieve superior object detection\nperformance compared to other approaches, with YOLOv2 (an improved You Only\nLook Once model) being one of the state-of-the-art in DNN-based object\ndetection methods in terms of both speed and accuracy. Although YOLOv2 can\nachieve real-time performance on a powerful GPU, it still remains very\nchallenging for leveraging this approach for real-time object detection in\nvideo on embedded computing devices with limited computational power and\nlimited memory. In this paper, we propose a new framework called Fast YOLO, a\nfast You Only Look Once framework which accelerates YOLOv2 to be able to\nperform object detection in video on embedded devices in a real-time manner.\nFirst, we leverage the evolutionary deep intelligence framework to evolve the\nYOLOv2 network architecture and produce an optimized architecture (referred to\nas O-YOLOv2 here) that has 2.8X fewer parameters with just a ~2% IOU drop. To\nfurther reduce power consumption on embedded devices while maintaining\nperformance, a motion-adaptive inference method is introduced into the proposed\nFast YOLO framework to reduce the frequency of deep inference with O-YOLOv2\nbased on temporal motion characteristics. Experimental results show that the\nproposed Fast YOLO framework can reduce the number of deep inferences by an\naverage of 38.13%, and an average speedup of ~3.3X for objection detection in\nvideo compared to the original YOLOv2, leading Fast YOLO to run an average of\n~18FPS on a Nvidia Jetson TX1 embedded system.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 13:57:16 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Shafiee", "Mohammad Javad", ""], ["Chywl", "Brendan", ""], ["Li", "Francis", ""], ["Wong", "Alexander", ""]]}, {"id": "1709.05948", "submitter": "Florian Sikora", "authors": "Florian Sikora", "title": "The shortest way to visit all metro lines in a city", "comments": "Tokyo results added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What if $\\{$a tourist, a train addict, Dr. Sheldon Cooper, somebody who likes\nto waste time$\\}$ wants to visit all metro lines or carriages in a given\nnetwork in a minimum number of steps? We study this problem with an application\nto the metro network of Paris and Tokyo, proposing optimal solutions thanks to\nmathematical programming tools. Quite surprisingly, it appears that you can\nvisit all 16 Parisian metro lines in only 26 steps (we denote by a step the act\nof taking the metro from one station to an adjacent one). Perhaps even more\nsurprisingly, adding the 5 RER lines to these 16 lines does not increase the\nsize of the best solution. It is also possible to visit the 13 lines of (the\ndense network of) Tokyo with only 15 steps.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 13:41:59 GMT"}, {"version": "v2", "created": "Tue, 19 Sep 2017 15:08:16 GMT"}, {"version": "v3", "created": "Tue, 10 Apr 2018 12:56:36 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Sikora", "Florian", ""]]}, {"id": "1709.05958", "submitter": "Matthew Peveler", "authors": "Matthew Peveler, Naveen Sundar Govindarajulu, Selmer Bringsjord,\n  Biplav Srivastava, Kartik Talamadupula, Hui Su", "title": "Toward Cognitive and Immersive Systems: Experiments in a Cognitive\n  Microworld", "comments": "Submitted to Advances of Cognitive Systems 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As computational power has continued to increase, and sensors have become\nmore accurate, the corresponding advent of systems that are at once cognitive\nand immersive has arrived. These \\textit{cognitive and immersive systems}\n(CAISs) fall squarely into the intersection of AI with HCI/HRI: such systems\ninteract with and assist the human agents that enter them, in no small part\nbecause such systems are infused with AI able to understand and reason about\nthese humans and their knowledge, beliefs, goals, communications, plans, etc.\nWe herein explain our approach to engineering CAISs. We emphasize the capacity\nof a CAIS to develop and reason over a `theory of the mind' of its human\npartners. This capacity entails that the AI in question has a sophisticated\nmodel of the beliefs, knowledge, goals, desires, emotions, etc.\\ of these\nhumans. To accomplish this engineering, a formal framework of very high\nexpressivity is needed. In our case, this framework is a \\textit{cognitive\nevent calculus}, a particular kind of quantified multi-operator modal logic,\nand a matching high-expressivity automated reasoner and planner. To explain,\nadvance, and to a degree validate our approach, we show that a calculus of this\ntype satisfies a set of formal requirements, and can enable a CAIS to\nunderstand a psychologically tricky scenario couched in what we call the\n\\textit{cognitive polysolid framework} (CPF). We also formally show that a room\nthat satisfies these requirements can have a useful property we term\n\\emph{expectation of usefulness}. CPF, a sub-class of \\textit{cognitive\nmicroworlds}, includes machinery able to represent and plan over not merely\nblocks and actions (such as seen in the primitive `blocks worlds' of old), but\nalso over agents and their mental attitudes about both other agents and\ninanimate objects.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 21:52:54 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 17:26:47 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Peveler", "Matthew", ""], ["Govindarajulu", "Naveen Sundar", ""], ["Bringsjord", "Selmer", ""], ["Srivastava", "Biplav", ""], ["Talamadupula", "Kartik", ""], ["Su", "Hui", ""]]}, {"id": "1709.05976", "submitter": "Vivek Gupta", "authors": "Rahul Wadbude, Vivek Gupta, Piyush Rai, Nagarajan Natarajan, Harish\n  Karnick, Prateek Jain", "title": "Leveraging Distributional Semantics for Multi-Label Learning", "comments": "10 Pages, 0 Figures, Missing Result Joint Learning Included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel and scalable label embedding framework for large-scale\nmulti-label learning a.k.a ExMLDS (Extreme Multi-Label Learning using\nDistributional Semantics). Our approach draws inspiration from ideas rooted in\ndistributional semantics, specifically the Skip Gram Negative Sampling (SGNS)\napproach, widely used to learn word embeddings for natural language processing\ntasks. Learning such embeddings can be reduced to a certain matrix\nfactorization. Our approach is novel in that it highlights interesting\nconnections between label embedding methods used for multi-label learning and\nparagraph/document embedding methods commonly used for learning representations\nof text data. The framework can also be easily extended to incorporate\nauxiliary information such as label-label correlations; this is crucial\nespecially when there are a lot of missing labels in the training data. We\ndemonstrate the effectiveness of our approach through an extensive set of\nexperiments on a variety of benchmark datasets, and show that the proposed\nlearning methods perform favorably compared to several baselines and\nstate-of-the-art methods for large-scale multi-label learning. To facilitate\nend-to-end learning, we develop a joint learning algorithm that can learn the\nembeddings as well as a regression model that predicts these embeddings given\ninput features, via efficient gradient-based methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 14:34:16 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 10:48:18 GMT"}, {"version": "v3", "created": "Fri, 10 Nov 2017 08:04:21 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Wadbude", "Rahul", ""], ["Gupta", "Vivek", ""], ["Rai", "Piyush", ""], ["Natarajan", "Nagarajan", ""], ["Karnick", "Harish", ""], ["Jain", "Prateek", ""]]}, {"id": "1709.06011", "submitter": "Maximilian Huettenrauch", "authors": "Maximilian H\\\"uttenrauch and Adrian \\v{S}o\\v{s}i\\'c and Gerhard\n  Neumann", "title": "Guided Deep Reinforcement Learning for Swarm Systems", "comments": "15 pages, 8 figures, accepted at the AAMAS 2017 Autonomous Robots and\n  Multirobot Systems (ARMS) Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate how to learn to control a group of cooperative\nagents with limited sensing capabilities such as robot swarms. The agents have\nonly very basic sensor capabilities, yet in a group they can accomplish\nsophisticated tasks, such as distributed assembly or search and rescue tasks.\nLearning a policy for a group of agents is difficult due to distributed partial\nobservability of the state. Here, we follow a guided approach where a critic\nhas central access to the global state during learning, which simplifies the\npolicy evaluation problem from a reinforcement learning point of view. For\nexample, we can get the positions of all robots of the swarm using a camera\nimage of a scene. This camera image is only available to the critic and not to\nthe control policies of the robots. We follow an actor-critic approach, where\nthe actors base their decisions only on locally sensed information. In\ncontrast, the critic is learned based on the true global state. Our algorithm\nuses deep reinforcement learning to approximate both the Q-function and the\npolicy. The performance of the algorithm is evaluated on two tasks with simple\nsimulated 2D agents: 1) finding and maintaining a certain distance to each\nothers and 2) locating a target.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 15:37:45 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["H\u00fcttenrauch", "Maximilian", ""], ["\u0160o\u0161i\u0107", "Adrian", ""], ["Neumann", "Gerhard", ""]]}, {"id": "1709.06075", "submitter": "John Boaz Lee", "authors": "John Boaz Lee, Ryan Rossi, Xiangnan Kong", "title": "Deep Graph Attention Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph classification is a problem with practical applications in many\ndifferent domains. Most of the existing methods take the entire graph into\naccount when calculating graph features. In a graphlet-based approach, for\ninstance, the entire graph is processed to get the total count of different\ngraphlets or sub-graphs. In the real-world, however, graphs can be both large\nand noisy with discriminative patterns confined to certain regions in the graph\nonly. In this work, we study the problem of attentional processing for graph\nclassification. The use of attention allows us to focus on small but\ninformative parts of the graph, avoiding noise in the rest of the graph. We\npresent a novel RNN model, called the Graph Attention Model (GAM), that\nprocesses only a portion of the graph by adaptively selecting a sequence of\n\"interesting\" nodes. The model is equipped with an external memory component\nwhich allows it to integrate information gathered from different parts of the\ngraph. We demonstrate the effectiveness of the model through various\nexperiments.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 19:02:50 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Lee", "John Boaz", ""], ["Rossi", "Ryan", ""], ["Kong", "Xiangnan", ""]]}, {"id": "1709.06080", "submitter": "Maxim Naumov", "authors": "Maxim Naumov", "title": "Feedforward and Recurrent Neural Networks Backward Propagation and\n  Hessian in Matrix Form", "comments": "23 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on the linear algebra theory behind feedforward (FNN)\nand recurrent (RNN) neural networks. We review backward propagation, including\nbackward propagation through time (BPTT). Also, we obtain a new exact\nexpression for Hessian, which represents second order effects. We show that for\n$t$ time steps the weight gradient can be expressed as a rank-$t$ matrix, while\nthe weight Hessian is as a sum of $t^{2}$ Kronecker products of rank-$1$ and\n$W^{T}AW$ matrices, for some matrix $A$ and weight matrix $W$. Also, we show\nthat for a mini-batch of size $r$, the weight update can be expressed as a\nrank-$rt$ matrix. Finally, we briefly comment on the eigenvalues of the Hessian\nmatrix.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 18:59:17 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Naumov", "Maxim", ""]]}, {"id": "1709.06129", "submitter": "Simon Du", "authors": "Simon S. Du, Jason D. Lee, Yuandong Tian", "title": "When is a Convolutional Filter Easy To Learn?", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the convergence of (stochastic) gradient descent algorithm for\nlearning a convolutional filter with Rectified Linear Unit (ReLU) activation\nfunction. Our analysis does not rely on any specific form of the input\ndistribution and our proofs only use the definition of ReLU, in contrast with\nprevious works that are restricted to standard Gaussian input. We show that\n(stochastic) gradient descent with random initialization can learn the\nconvolutional filter in polynomial time and the convergence rate depends on the\nsmoothness of the input distribution and the closeness of patches. To the best\nof our knowledge, this is the first recovery guarantee of gradient-based\nalgorithms for convolutional filter on non-Gaussian input distributions. Our\ntheory also justifies the two-stage learning rate strategy in deep neural\nnetworks. While our focus is theoretical, we also present experiments that\nillustrate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 19:09:24 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 17:08:26 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Du", "Simon S.", ""], ["Lee", "Jason D.", ""], ["Tian", "Yuandong", ""]]}, {"id": "1709.06138", "submitter": "Rajat Sen", "authors": "Rajat Sen, Ananda Theertha Suresh, Karthikeyan Shanmugam, Alexandros\n  G. Dimakis and Sanjay Shakkottai", "title": "Model-Powered Conditional Independence Test", "comments": "19 Pages, 2 figures, Accepted for publication in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of non-parametric Conditional Independence testing\n(CI testing) for continuous random variables. Given i.i.d samples from the\njoint distribution $f(x,y,z)$ of continuous random vectors $X,Y$ and $Z,$ we\ndetermine whether $X \\perp Y | Z$. We approach this by converting the\nconditional independence test into a classification problem. This allows us to\nharness very powerful classifiers like gradient-boosted trees and deep neural\nnetworks. These models can handle complex probability distributions and allow\nus to perform significantly better compared to the prior state of the art, for\nhigh-dimensional CI testing. The main technical challenge in the classification\nproblem is the need for samples from the conditional product distribution\n$f^{CI}(x,y,z) = f(x|z)f(y|z)f(z)$ -- the joint distribution if and only if $X\n\\perp Y | Z.$ -- when given access only to i.i.d. samples from the true joint\ndistribution $f(x,y,z)$. To tackle this problem we propose a novel nearest\nneighbor bootstrap procedure and theoretically show that our generated samples\nare indeed close to $f^{CI}$ in terms of total variational distance. We then\ndevelop theoretical results regarding the generalization bounds for\nclassification for our problem, which translate into error bounds for CI\ntesting. We provide a novel analysis of Rademacher type classification bounds\nin the presence of non-i.i.d near-independent samples. We empirically validate\nthe performance of our algorithm on simulated and real datasets and show\nperformance gains over previous methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 19:56:07 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Sen", "Rajat", ""], ["Suresh", "Ananda Theertha", ""], ["Shanmugam", "Karthikeyan", ""], ["Dimakis", "Alexandros G.", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "1709.06166", "submitter": "Kunal Menda", "authors": "Kunal Menda, Katherine Driggs-Campbell, and Mykel J. Kochenderfer", "title": "DropoutDAgger: A Bayesian Approach to Safe Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While imitation learning is becoming common practice in robotics, this\napproach often suffers from data mismatch and compounding errors. DAgger is an\niterative algorithm that addresses these issues by continually aggregating\ntraining data from both the expert and novice policies, but does not consider\nthe impact of safety. We present a probabilistic extension to DAgger, which\nuses the distribution over actions provided by the novice policy, for a given\nobservation. Our method, which we call DropoutDAgger, uses dropout to train the\nnovice as a Bayesian neural network that provides insight to its confidence.\nUsing the distribution over the novice's actions, we estimate a probabilistic\nmeasure of safety with respect to the expert action, tuned to balance\nexploration and exploitation. The utility of this approach is evaluated on the\nMuJoCo HalfCheetah and in a simple driving experiment, demonstrating improved\nperformance and safety compared to other DAgger variants and classic imitation\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 20:51:53 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Menda", "Kunal", ""], ["Driggs-Campbell", "Katherine", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1709.06172", "submitter": "Mohamed Siala Dr", "authors": "Begum Genc, Mohamed Siala, Gilles Simonin, Barry O'Sullivan", "title": "On the Complexity of Robust Stable Marriage", "comments": "Accepted for publication in COCOA'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust Stable Marriage (RSM) is a variant of the classical Stable Marriage\nproblem, where the robustness of a given stable matching is measured by the\nnumber of modifications required for repairing it in case an unforeseen event\noccurs. We focus on the complexity of finding an (a,b)-supermatch. An\n(a,b)-supermatch is defined as a stable matching in which if any 'a'\n(non-fixed) men/women break up it is possible to find another stable matching\nby changing the partners of those 'a' men/women and also the partners of at\nmost 'b' other couples. In order to show deciding if there exists an\n(a,b)-supermatch is NP-Complete, we first introduce a SAT formulation that is\nNP-Complete by using Schaefer's Dichotomy Theorem. Then, we show the\nequivalence between the SAT formulation and finding a (1,1)-supermatch on a\nspecific family of instances.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 21:32:52 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 13:30:33 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Genc", "Begum", ""], ["Siala", "Mohamed", ""], ["Simonin", "Gilles", ""], ["O'Sullivan", "Barry", ""]]}, {"id": "1709.06196", "submitter": "Zachary Sunberg", "authors": "Zachary Sunberg and Mykel Kochenderfer", "title": "Online algorithms for POMDPs with continuous state, action, and\n  observation spaces", "comments": "Added Multilane section", "journal-ref": "Short version published in 2018 proceedings of the International\n  Conference on Automated Planning and Scheduling (ICAPS)", "doi": null, "report-no": null, "categories": "cs.AI cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online solvers for partially observable Markov decision processes have been\napplied to problems with large discrete state spaces, but continuous state,\naction, and observation spaces remain a challenge. This paper begins by\ninvestigating double progressive widening (DPW) as a solution to this\nchallenge. However, we prove that this modification alone is not sufficient\nbecause the belief representations in the search tree collapse to a single\nparticle causing the algorithm to converge to a policy that is suboptimal\nregardless of the computation time. This paper proposes and evaluates two new\nalgorithms, POMCPOW and PFT-DPW, that overcome this deficiency by using\nweighted particle filtering. Simulation results show that these modifications\nallow the algorithms to be successful where previous approaches fail.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 22:57:30 GMT"}, {"version": "v2", "created": "Fri, 10 Nov 2017 02:40:01 GMT"}, {"version": "v3", "created": "Wed, 27 Dec 2017 01:28:32 GMT"}, {"version": "v4", "created": "Sat, 17 Mar 2018 21:47:38 GMT"}, {"version": "v5", "created": "Thu, 12 Apr 2018 18:25:23 GMT"}, {"version": "v6", "created": "Thu, 6 Sep 2018 00:46:54 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Sunberg", "Zachary", ""], ["Kochenderfer", "Mykel", ""]]}, {"id": "1709.06201", "submitter": "Jaedeok Kim", "authors": "Jaedeok Kim, and Jingoo Seo", "title": "Human Understandable Explanation Extraction for Black-box Classification\n  Models Based on Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a number of artificial intelligent services have been\ndeveloped such as defect detection system or diagnosis system for customer\nservices. Unfortunately, the core in these services is a black-box in which\nhuman cannot understand the underlying decision making logic, even though the\ninspection of the logic is crucial before launching a commercial service. Our\ngoal in this paper is to propose an analytic method of a model explanation that\nis applicable to general classification models. To this end, we introduce the\nconcept of a contribution matrix and an explanation embedding in a constraint\nspace by using a matrix factorization. We extract a rule-like model explanation\nfrom the contribution matrix with the help of the nonnegative matrix\nfactorization. To validate our method, the experiment results provide with open\ndatasets as well as an industry dataset of a LTE network diagnosis and the\nresults show our method extracts reasonable explanations.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 23:44:45 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Kim", "Jaedeok", ""], ["Seo", "Jingoo", ""]]}, {"id": "1709.06202", "submitter": "Arslan Munir", "authors": "Avishek Bose, Arslan Munir, and Neda Shabani", "title": "A Comparative Quantitative Analysis of Contemporary Big Data Clustering\n  Algorithms for Market Segmentation in Hospitality Industry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hospitality industry is one of the data-rich industries that receives\nhuge Volumes of data streaming at high Velocity with considerably Variety,\nVeracity, and Variability. These properties make the data analysis in the\nhospitality industry a big data problem. Meeting the customers' expectations is\na key factor in the hospitality industry to grasp the customers' loyalty. To\nachieve this goal, marketing professionals in this industry actively look for\nways to utilize their data in the best possible manner and advance their data\nanalytic solutions, such as identifying a unique market segmentation clustering\nand developing a recommendation system. In this paper, we present a\ncomprehensive literature review of existing big data clustering algorithms and\ntheir advantages and disadvantages for various use cases. We implement the\nexisting big data clustering algorithms and provide a quantitative comparison\nof the performance of different clustering algorithms for different scenarios.\nWe also present our insights and recommendations regarding the suitability of\ndifferent big data clustering algorithms for different use cases. These\nrecommendations will be helpful for hoteliers in selecting the appropriate\nmarket segmentation clustering algorithm for different clustering datasets to\nimprove the customer experience and maximize the hotel revenue.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 23:47:44 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Bose", "Avishek", ""], ["Munir", "Arslan", ""], ["Shabani", "Neda", ""]]}, {"id": "1709.06275", "submitter": "Ryan Carey", "authors": "Ryan Carey", "title": "Incorrigibility in the CIRL Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A value learning system has incentives to follow shutdown instructions,\nassuming the shutdown instruction provides information (in the technical sense)\nabout which actions lead to valuable outcomes. However, this assumption is not\nrobust to model mis-specification (e.g., in the case of programmer errors). We\ndemonstrate this by presenting some Supervised POMDP scenarios in which errors\nin the parameterized reward function remove the incentive to follow shutdown\ncommands. These difficulties parallel those discussed by Soares et al. (2015)\nin their paper on corrigibility. We argue that it is important to consider\nsystems that follow shutdown commands under some weaker set of assumptions\n(e.g., that one small verified module is correctly implemented; as opposed to\nan entire prior probability distribution and/or parameterized reward function).\nWe discuss some difficulties with simple ways to attempt to attain these sorts\nof guarantees in a value learning framework.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 07:23:18 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 17:43:18 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Carey", "Ryan", ""]]}, {"id": "1709.06293", "submitter": "Kyungjae Lee", "authors": "Kyungjae Lee, Sungjoon Choi and Songhwai Oh", "title": "Sparse Markov Decision Processes with Causal Sparse Tsallis Entropy\n  Regularization for Reinforcement Learning", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a sparse Markov decision process (MDP) with novel causal\nsparse Tsallis entropy regularization is proposed.The proposed policy\nregularization induces a sparse and multi-modal optimal policy distribution of\na sparse MDP. The full mathematical analysis of the proposed sparse MDP is\nprovided.We first analyze the optimality condition of a sparse MDP. Then, we\npropose a sparse value iteration method which solves a sparse MDP and then\nprove the convergence and optimality of sparse value iteration using the Banach\nfixed point theorem. The proposed sparse MDP is compared to soft MDPs which\nutilize causal entropy regularization. We show that the performance error of a\nsparse MDP has a constant bound, while the error of a soft MDP increases\nlogarithmically with respect to the number of actions, where this performance\nerror is caused by the introduced regularization term. In experiments, we apply\nsparse MDPs to reinforcement learning problems. The proposed method outperforms\nexisting methods in terms of the convergence speed and performance.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 08:36:21 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 10:57:25 GMT"}, {"version": "v3", "created": "Fri, 13 Oct 2017 06:22:59 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Lee", "Kyungjae", ""], ["Choi", "Sungjoon", ""], ["Oh", "Songhwai", ""]]}, {"id": "1709.06298", "submitter": "Hao-Wen Dong", "authors": "Hao-Wen Dong, Wen-Yi Hsiao, Li-Chia Yang, Yi-Hsuan Yang", "title": "MuseGAN: Multi-track Sequential Generative Adversarial Networks for\n  Symbolic Music Generation and Accompaniment", "comments": "to appear at AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating music has a few notable differences from generating images and\nvideos. First, music is an art of time, necessitating a temporal model. Second,\nmusic is usually composed of multiple instruments/tracks with their own\ntemporal dynamics, but collectively they unfold over time interdependently.\nLastly, musical notes are often grouped into chords, arpeggios or melodies in\npolyphonic music, and thereby introducing a chronological ordering of notes is\nnot naturally suitable. In this paper, we propose three models for symbolic\nmulti-track music generation under the framework of generative adversarial\nnetworks (GANs). The three models, which differ in the underlying assumptions\nand accordingly the network architectures, are referred to as the jamming\nmodel, the composer model and the hybrid model. We trained the proposed models\non a dataset of over one hundred thousand bars of rock music and applied them\nto generate piano-rolls of five tracks: bass, drums, guitar, piano and strings.\nA few intra-track and inter-track objective metrics are also proposed to\nevaluate the generative results, in addition to a subjective user study. We\nshow that our models can generate coherent music of four bars right from\nscratch (i.e. without human inputs). We also extend our models to human-AI\ncooperative music generation: given a specific track composed by human, we can\ngenerate four additional tracks to accompany it. All code, the dataset and the\nrendered audio samples are available at https://salu133445.github.io/musegan/ .\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 08:49:40 GMT"}, {"version": "v2", "created": "Fri, 24 Nov 2017 05:11:39 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Dong", "Hao-Wen", ""], ["Hsiao", "Wen-Yi", ""], ["Yang", "Li-Chia", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "1709.06404", "submitter": "Ga\\\"etan Hadjeres", "authors": "Ga\\\"etan Hadjeres and Frank Nielsen", "title": "Interactive Music Generation with Positional Constraints using\n  Anticipation-RNNs", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNS) are now widely used on sequence generation\ntasks due to their ability to learn long-range dependencies and to generate\nsequences of arbitrary length. However, their left-to-right generation\nprocedure only allows a limited control from a potential user which makes them\nunsuitable for interactive and creative usages such as interactive music\ngeneration. This paper introduces a novel architecture called Anticipation-RNN\nwhich possesses the assets of the RNN-based generative models while allowing to\nenforce user-defined positional constraints. We demonstrate its efficiency on\nthe task of generating melodies satisfying positional constraints in the style\nof the soprano parts of the J.S. Bach chorale harmonizations. Sampling using\nthe Anticipation-RNN is of the same order of complexity than sampling from the\ntraditional RNN model. This fast and interactive generation of musical\nsequences opens ways to devise real-time systems that could be used for\ncreative purposes.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 13:29:53 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Hadjeres", "Ga\u00ebtan", ""], ["Nielsen", "Frank", ""]]}, {"id": "1709.06493", "submitter": "Wei Zhang", "authors": "Wei Zhang, Bowen Zhou", "title": "Learning to update Auto-associative Memory in Recurrent Neural Networks\n  for Improving Sequence Memorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to remember long sequences remains a challenging task for recurrent\nneural networks. Register memory and attention mechanisms were both proposed to\nresolve the issue with either high computational cost to retain memory\ndifferentiability, or by discounting the RNN representation learning towards\nencoding shorter local contexts than encouraging long sequence encoding.\nAssociative memory, which studies the compression of multiple patterns in a\nfixed size memory, were rarely considered in recent years. Although some recent\nwork tries to introduce associative memory in RNN and mimic the energy decay\nprocess in Hopfield nets, it inherits the shortcoming of rule-based memory\nupdates, and the memory capacity is limited. This paper proposes a method to\nlearn the memory update rule jointly with task objective to improve memory\ncapacity for remembering long sequences. Also, we propose an architecture that\nuses multiple such associative memory for more complex input encoding. We\nobserved some interesting facts when compared to other RNN architectures on\nsome well-studied sequence learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 15:55:16 GMT"}, {"version": "v2", "created": "Fri, 29 Sep 2017 20:52:46 GMT"}, {"version": "v3", "created": "Tue, 3 Oct 2017 14:31:03 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Zhang", "Wei", ""], ["Zhou", "Bowen", ""]]}, {"id": "1709.06533", "submitter": "Christopher Grimm", "authors": "Christopher Grimm, Yuhang Song and Michael L. Littman", "title": "Summable Reparameterizations of Wasserstein Critics in the\n  One-Dimensional Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are an exciting alternative to\nalgorithms for solving density estimation problems---using data to assess how\nlikely samples are to be drawn from the same distribution. Instead of\nexplicitly computing these probabilities, GANs learn a generator that can match\nthe given probabilistic source. This paper looks particularly at this matching\ncapability in the context of problems with one-dimensional outputs. We identify\na class of function decompositions with properties that make them well suited\nto the critic role in a leading approach to GANs known as Wasserstein GANs. We\nshow that Taylor and Fourier series decompositions belong to our class, provide\nexamples of these critics outperforming standard GAN approaches, and suggest\nhow they can be scaled to higher dimensional problems in the future.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 17:03:17 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Grimm", "Christopher", ""], ["Song", "Yuhang", ""], ["Littman", "Michael L.", ""]]}, {"id": "1709.06620", "submitter": "Qiyang Li", "authors": "Qiyang Li, Xintong Du, Yizhou Huang, Quinlan Sykora, and Angela P.\n  Schoellig", "title": "Learning of Coordination Policies for Robotic Swarms", "comments": "8 pages, 11 figures, submitted to 2018 IEEE International Conference\n  on Robotics and Automation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by biological swarms, robotic swarms are envisioned to solve\nreal-world problems that are difficult for individual agents. Biological swarms\ncan achieve collective intelligence based on local interactions and simple\nrules; however, designing effective distributed policies for large-scale\nrobotic swarms to achieve a global objective can be challenging. Although it is\noften possible to design an optimal centralized strategy for smaller numbers of\nagents, those methods can fail as the number of agents increases. Motivated by\nthe growing success of machine learning, we develop a deep learning approach\nthat learns distributed coordination policies from centralized policies. In\ncontrast to traditional distributed control approaches, which are usually based\non human-designed policies for relatively simple tasks, this learning-based\napproach can be adapted to more difficult tasks. We demonstrate the efficacy of\nour proposed approach on two different tasks, the well-known rendezvous problem\nand a more difficult particle assignment problem. For the latter, no known\ndistributed policy exists. From extensive simulations, it is shown that the\nperformance of the learned coordination policies is comparable to the\ncentralized policies, surpassing state-of-the-art distributed policies.\nThereby, our proposed approach provides a promising alternative for real-world\ncoordination problems that would be otherwise computationally expensive to\nsolve or intangible to explore.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 19:26:20 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Li", "Qiyang", ""], ["Du", "Xintong", ""], ["Huang", "Yizhou", ""], ["Sykora", "Quinlan", ""], ["Schoellig", "Angela P.", ""]]}, {"id": "1709.06656", "submitter": "Kunal Menda", "authors": "Kunal Menda, Yi-Chun Chen, Justin Grana, James W. Bono, Brendan D.\n  Tracey, Mykel J. Kochenderfer, and David Wolpert", "title": "Deep Reinforcement Learning for Event-Driven Multi-Agent Decision\n  Processes", "comments": "Published in IEEE Transactions on Intelligent Transportation Systems\n  (Volume: 20, Issue: 4, April 2019).\n  https://ieeexplore.ieee.org/document/8419722", "journal-ref": "IEEE Transactions on Intelligent Transportation Systems, vol. 20,\n  no. 4, pp. 1259-1268, April 2019", "doi": "10.1109/TITS.2018.2848264", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The incorporation of macro-actions (temporally extended actions) into\nmulti-agent decision problems has the potential to address the curse of\ndimensionality associated with such decision problems. Since macro-actions last\nfor stochastic durations, multiple agents executing decentralized policies in\ncooperative environments must act asynchronously. We present an algorithm that\nmodifies generalized advantage estimation for temporally extended actions,\nallowing a state-of-the-art policy optimization algorithm to optimize policies\nin Dec-POMDPs in which agents act asynchronously. We show that our algorithm is\ncapable of learning optimal policies in two cooperative domains, one involving\nreal-time bus holding control and one involving wildfire fighting with unmanned\naircraft. Our algorithm works by framing problems as \"event-driven decision\nprocesses,\" which are scenarios in which the sequence and timing of actions and\nevents are random and governed by an underlying stochastic process. In addition\nto optimizing policies with continuous state and action spaces, our algorithm\nalso facilitates the use of event-driven simulators, which do not require time\nto be discretized into time-steps. We demonstrate the benefit of using\nevent-driven simulation in the context of multiple agents taking asynchronous\nactions. We show that fixed time-step simulation risks obfuscating the sequence\nin which closely separated events occur, adversely affecting the policies\nlearned. In addition, we show that arbitrarily shrinking the time-step scales\npoorly with the number of agents.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 21:41:51 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 17:15:10 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Menda", "Kunal", ""], ["Chen", "Yi-Chun", ""], ["Grana", "Justin", ""], ["Bono", "James W.", ""], ["Tracey", "Brendan D.", ""], ["Kochenderfer", "Mykel J.", ""], ["Wolpert", "David", ""]]}, {"id": "1709.06662", "submitter": "Nina Narodytska", "authors": "Nina Narodytska, Shiva Prasad Kasiviswanathan, Leonid Ryzhyk, Mooly\n  Sagiv, Toby Walsh", "title": "Verifying Properties of Binarized Deep Neural Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding properties of deep neural networks is an important challenge in\ndeep learning. In this paper, we take a step in this direction by proposing a\nrigorous way of verifying properties of a popular class of neural networks,\nBinarized Neural Networks, using the well-developed means of Boolean\nsatisfiability. Our main contribution is a construction that creates a\nrepresentation of a binarized neural network as a Boolean formula. Our encoding\nis the first exact Boolean representation of a deep neural network. Using this\nencoding, we leverage the power of modern SAT solvers along with a proposed\ncounterexample-guided search procedure to verify various properties of these\nnetworks. A particular focus will be on the critical property of robustness to\nadversarial perturbations. For this property, our experimental results\ndemonstrate that our approach scales to medium-size deep neural networks used\nin image classification tasks. To the best of our knowledge, this is the first\nwork on verifying properties of deep neural networks using an exact Boolean\nencoding of the network.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 22:21:49 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 18:30:06 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Narodytska", "Nina", ""], ["Kasiviswanathan", "Shiva Prasad", ""], ["Ryzhyk", "Leonid", ""], ["Sagiv", "Mooly", ""], ["Walsh", "Toby", ""]]}, {"id": "1709.06673", "submitter": "Danushka Bollegala", "authors": "Huda Hakami and Danushka Bollegala and Hayashi Kohei", "title": "Why PairDiff works? -- A Mathematical Analysis of Bilinear Relational\n  Compositional Operators for Analogy Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing the semantic relations that exist between two given words (or\nentities) is an important first step in a wide-range of NLP applications such\nas analogical reasoning, knowledge base completion and relational information\nretrieval. A simple, yet surprisingly accurate method for representing a\nrelation between two words is to compute the vector offset (\\PairDiff) between\ntheir corresponding word embeddings. Despite the empirical success, it remains\nunclear as to whether \\PairDiff is the best operator for obtaining a relational\nrepresentation from word embeddings. We conduct a theoretical analysis of\ngeneralised bilinear operators that can be used to measure the $\\ell_{2}$\nrelational distance between two word-pairs. We show that, if the word\nembeddings are standardised and uncorrelated, such an operator will be\nindependent of bilinear terms, and can be simplified to a linear form, where\n\\PairDiff is a special case. For numerous word embedding types, we empirically\nverify the uncorrelation assumption, demonstrating the general applicability of\nour theoretical result. Moreover, we experimentally discover \\PairDiff from the\nbilinear relation composition operator on several benchmark analogy datasets.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 23:09:15 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 15:41:23 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Hakami", "Huda", ""], ["Bollegala", "Danushka", ""], ["Kohei", "Hayashi", ""]]}, {"id": "1709.06692", "submitter": "Ariel Procaccia", "authors": "Ritesh Noothigattu, Snehalkumar 'Neil' S. Gaikwad, Edmond Awad, Sohan\n  Dsouza, Iyad Rahwan, Pradeep Ravikumar, Ariel D. Procaccia", "title": "A Voting-Based System for Ethical Decision Making", "comments": "25 pages; paper has been reorganized, related work and discussion\n  sections have been expanded", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general approach to automating ethical decisions, drawing on\nmachine learning and computational social choice. In a nutshell, we propose to\nlearn a model of societal preferences, and, when faced with a specific ethical\ndilemma at runtime, efficiently aggregate those preferences to identify a\ndesirable choice. We provide a concrete algorithm that instantiates our\napproach; some of its crucial steps are informed by a new theory of\nswap-dominance efficient voting rules. Finally, we implement and evaluate a\nsystem for ethical decision making in the autonomous vehicle domain, using\npreference data collected from 1.3 million people through the Moral Machine\nwebsite.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 01:17:49 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 23:16:48 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Noothigattu", "Ritesh", ""], ["Gaikwad", "Snehalkumar 'Neil' S.", ""], ["Awad", "Edmond", ""], ["Dsouza", "Sohan", ""], ["Rahwan", "Iyad", ""], ["Ravikumar", "Pradeep", ""], ["Procaccia", "Ariel D.", ""]]}, {"id": "1709.06772", "submitter": "Angelo Impedovo", "authors": "Angelo Impedovo, Corrado Loglisci, Michelangelo Ceci", "title": "Temporal Pattern Mining from Evolving Networks", "comments": "4 pages, to be presented at the PhD forum of ECML-PKDD 2017 (The\n  European Conference on Machine Learning & Principles and Practice of\n  Knowledge Discovery in Databases) in Skopje, 22 September 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, evolving networks are becoming a suitable form to model many\nreal-world complex systems, due to their peculiarities to represent the systems\nand their constituting entities, the interactions between the entities and the\ntime-variability of their structure and properties. Designing computational\nmodels able to analyze evolving networks becomes relevant in many applications.\nThe goal of this research project is to evaluate the possible contribution of\ntemporal pattern mining techniques in the analysis of evolving networks. In\nparticular, we aim at exploiting available snapshots for the recognition of\nvaluable and potentially useful knowledge about the temporal dynamics exhibited\nby the network over the time, without making any prior assumption about the\nunderlying evolutionary schema. Pattern-based approaches of temporal pattern\nmining can be exploited to detect and characterize changes exhibited by a\nnetwork over the time, starting from observed snapshots.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 08:54:28 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Impedovo", "Angelo", ""], ["Loglisci", "Corrado", ""], ["Ceci", "Michelangelo", ""]]}, {"id": "1709.06871", "submitter": "Chris Bleakley", "authors": "Philip J. Corr, Guenole C. Silvestre and Chris J. Bleakley", "title": "Open Source Dataset and Deep Learning Models for Online Digit Gesture\n  Recognition on Touchscreens", "comments": "Irish Machine Vision and Image Processing Conference (IMVIP) 2017,\n  Maynooth, Ireland, 30 August-1 September 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an evaluation of deep neural networks for recognition of\ndigits entered by users on a smartphone touchscreen. A new large dataset of\nArabic numerals was collected for training and evaluation of the network. The\ndataset consists of spatial and temporal touch data recorded for 80 digits\nentered by 260 users. Two neural network models were investigated. The first\nmodel was a 2D convolutional neural (ConvNet) network applied to bitmaps of the\nglpyhs created by interpolation of the sensed screen touches and its topology\nis similar to that of previously published models for offline handwriting\nrecognition from scanned images. The second model used a 1D ConvNet\narchitecture but was applied to the sequence of polar vectors connecting the\ntouch points. The models were found to provide accuracies of 98.50% and 95.86%,\nrespectively. The second model was much simpler, providing a reduction in the\nnumber of parameters from 1,663,370 to 287,690. The dataset has been made\navailable to the community as an open source resource.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 14:02:55 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Corr", "Philip J.", ""], ["Silvestre", "Guenole C.", ""], ["Bleakley", "Chris J.", ""]]}, {"id": "1709.06907", "submitter": "Simon Razniewski", "authors": "Simon Razniewski, Vevake Balaraman, Werner Nutt", "title": "Doctoral Advisor or Medical Condition: Towards Entity-specific Rankings\n  of Knowledge Base Properties [Extended Version]", "comments": "Extended version of an ADMA 2017 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In knowledge bases such as Wikidata, it is possible to assert a large set of\nproperties for entities, ranging from generic ones such as name and place of\nbirth to highly profession-specific or background-specific ones such as\ndoctoral advisor or medical condition. Determining a preference or ranking in\nthis large set is a challenge in tasks such as prioritisation of edits or\nnatural-language generation. Most previous approaches to ranking knowledge base\nproperties are purely data-driven, that is, as we show, mistake frequency for\ninterestingness.\n  In this work, we have developed a human-annotated dataset of 350 preference\njudgments among pairs of knowledge base properties for fixed entities. From\nthis set, we isolate a subset of pairs for which humans show a high level of\nagreement (87.5% on average). We show, however, that baseline and\nstate-of-the-art techniques achieve only 61.3% precision in predicting human\npreferences for this subset.\n  We then analyze what contributes to one property being rated as more\nimportant than another one, and identify that at least three factors play a\nrole, namely (i) general frequency, (ii) applicability to similar entities and\n(iii) semantic similarity between property and entity. We experimentally\nanalyze the contribution of each factor and show that a combination of\ntechniques addressing all the three factors achieves 74% precision on the task.\n  The dataset is available at\nwww.kaggle.com/srazniewski/wikidatapropertyranking.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 14:43:08 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Razniewski", "Simon", ""], ["Balaraman", "Vevake", ""], ["Nutt", "Werner", ""]]}, {"id": "1709.06908", "submitter": "Chao Zhao", "authors": "Chao Zhao, Jingchi Jiang, Yi Guan", "title": "EMR-based medical knowledge representation and inference via Markov\n  random fields and distributed representation learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Electronic medical records (EMRs) contain an amount of medical\nknowledge which can be used for clinical decision support (CDS). Our objective\nis a general system that can extract and represent these knowledge contained in\nEMRs to support three CDS tasks: test recommendation, initial diagnosis, and\ntreatment plan recommendation, with the given condition of one patient.\nMethods: We extracted four kinds of medical entities from records and\nconstructed an EMR-based medical knowledge network (EMKN), in which nodes are\nentities and edges reflect their co-occurrence in a single record. Three\nbipartite subgraphs (bi-graphs) were extracted from the EMKN to support each\ntask. One part of the bi-graph was the given condition (e.g., symptoms), and\nthe other was the condition to be inferred (e.g., diseases). Each bi-graph was\nregarded as a Markov random field to support the inference. Three lazy energy\nfunctions and one parameter-based energy function were proposed, as well as two\nknowledge representation learning-based energy functions, which can provide a\ndistributed representation of medical entities. Three measures were utilized\nfor performance evaluation. Results: On the initial diagnosis task, 80.11% of\nthe test records identified at least one correct disease from top 10\ncandidates. Test and treatment recommendation results were 87.88% and 92.55%,\nrespectively. These results altogether indicate that the proposed system\noutperformed the baseline methods. The distributed representation of medical\nentities does reflect similarity relationships in regards to knowledge level.\nConclusion: Combining EMKN and MRF is an effective approach for general medical\nknowledge representation and inference. Different tasks, however, require\ndesigning their energy functions individually.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 14:45:21 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Zhao", "Chao", ""], ["Jiang", "Jingchi", ""], ["Guan", "Yi", ""]]}, {"id": "1709.06917", "submitter": "Konstantinos Chatzilygeroudis", "authors": "Konstantinos Chatzilygeroudis and Jean-Baptiste Mouret", "title": "Using Parameterized Black-Box Priors to Scale Up Model-Based Policy\n  Search for Robotics", "comments": "Accepted at ICRA 2018; 8 pages, 4 figures, 2 algorithms, 1 table;\n  Video at https://youtu.be/HFkZkhGGzTo ; Spotlight ICRA presentation at\n  https://youtu.be/_MZYDhfWeLc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most data-efficient algorithms for reinforcement learning in robotics are\nmodel-based policy search algorithms, which alternate between learning a\ndynamical model of the robot and optimizing a policy to maximize the expected\nreturn given the model and its uncertainties. Among the few proposed\napproaches, the recently introduced Black-DROPS algorithm exploits a black-box\noptimization algorithm to achieve both high data-efficiency and good\ncomputation times when several cores are used; nevertheless, like all\nmodel-based policy search approaches, Black-DROPS does not scale to high\ndimensional state/action spaces. In this paper, we introduce a new model\nlearning procedure in Black-DROPS that leverages parameterized black-box priors\nto (1) scale up to high-dimensional systems, and (2) be robust to large\ninaccuracies of the prior information. We demonstrate the effectiveness of our\napproach with the \"pendubot\" swing-up task in simulation and with a physical\nhexapod robot (48D state space, 18D action space) that has to walk forward as\nfast as possible. The results show that our new algorithm is more\ndata-efficient than previous model-based policy search algorithms (with and\nwithout priors) and that it can allow a physical 6-legged robot to learn new\ngaits in only 16 to 30 seconds of interaction time.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 15:03:47 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 16:39:40 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Chatzilygeroudis", "Konstantinos", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1709.06919", "submitter": "Konstantinos Chatzilygeroudis", "authors": "R\\'emi Pautrat, Konstantinos Chatzilygeroudis and Jean-Baptiste Mouret", "title": "Bayesian Optimization with Automatic Prior Selection for Data-Efficient\n  Direct Policy Search", "comments": "Accepted at ICRA 2018; 8 pages, 4 figures, 1 algorithm; Video at\n  https://youtu.be/xo8mUIZTvNE ; Spotlight ICRA presentation\n  https://youtu.be/iiVaV-U6Kqo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most interesting features of Bayesian optimization for direct\npolicy search is that it can leverage priors (e.g., from simulation or from\nprevious tasks) to accelerate learning on a robot. In this paper, we are\ninterested in situations for which several priors exist but we do not know in\nadvance which one fits best the current situation. We tackle this problem by\nintroducing a novel acquisition function, called Most Likely Expected\nImprovement (MLEI), that combines the likelihood of the priors and the expected\nimprovement. We evaluate this new acquisition function on a transfer learning\ntask for a 5-DOF planar arm and on a possibly damaged, 6-legged robot that has\nto learn to walk on flat ground and on stairs, with priors corresponding to\ndifferent stairs and different kinds of damages. Our results show that MLEI\neffectively identifies and exploits the priors, even when there is no obvious\nmatch between the current situations and the priors.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 15:04:50 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 16:45:49 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Pautrat", "R\u00e9mi", ""], ["Chatzilygeroudis", "Konstantinos", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1709.06977", "submitter": "Aditya Gudimella", "authors": "Aditya Gudimella, Ross Story, Matineh Shaker, Ruofan Kong, Matthew\n  Brown, Victor Shnayder, Marcos Campos", "title": "Deep Reinforcement Learning for Dexterous Manipulation with Concept\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning yields great results for a large array of\nproblems, but models are generally retrained anew for each new problem to be\nsolved. Prior learning and knowledge are difficult to incorporate when training\nnew models, requiring increasingly longer training as problems become more\ncomplex. This is especially problematic for problems with sparse rewards. We\nprovide a solution to these problems by introducing Concept Network\nReinforcement Learning (CNRL), a framework which allows us to decompose\nproblems using a multi-level hierarchy. Concepts in a concept network are\nreusable, and flexible enough to encapsulate feature extractors, skills, or\nother concept networks. With this hierarchical learning approach, deep\nreinforcement learning can be used to solve complex tasks in a modular way,\nthrough problem decomposition. We demonstrate the strength of CNRL by training\na model to grasp a rectangular prism and precisely stack it on top of a cube\nusing a gripper on a Kinova JACO arm, simulated in MuJoCo. Our experiments show\nthat our use of hierarchy results in a 45x reduction in environment\ninteractions compared to the state-of-the-art on this task.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 17:28:13 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Gudimella", "Aditya", ""], ["Story", "Ross", ""], ["Shaker", "Matineh", ""], ["Kong", "Ruofan", ""], ["Brown", "Matthew", ""], ["Shnayder", "Victor", ""], ["Campos", "Marcos", ""]]}, {"id": "1709.06990", "submitter": "Emmanuel Dufourq Mr", "authors": "Emmanuel Dufourq and Bruce A. Bassett", "title": "Text Compression for Sentiment Analysis via Evolutionary Algorithms", "comments": "8 pages, 2 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Can textual data be compressed intelligently without losing accuracy in\nevaluating sentiment? In this study, we propose a novel evolutionary\ncompression algorithm, PARSEC (PARts-of-Speech for sEntiment Compression),\nwhich makes use of Parts-of-Speech tags to compress text in a way that\nsacrifices minimal classification accuracy when used in conjunction with\nsentiment analysis algorithms. An analysis of PARSEC with eight commercial and\nnon-commercial sentiment analysis algorithms on twelve English sentiment data\nsets reveals that accurate compression is possible with (0%, 1.3%, 3.3%) loss\nin sentiment classification accuracy for (20%, 50%, 75%) data compression with\nPARSEC using LingPipe, the most accurate of the sentiment algorithms. Other\nsentiment analysis algorithms are more severely affected by compression. We\nconclude that significant compression of text data is possible for sentiment\nanalysis depending on the accuracy demands of the specific application and the\nspecific sentiment analysis algorithm used.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 17:57:16 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Dufourq", "Emmanuel", ""], ["Bassett", "Bruce A.", ""]]}, {"id": "1709.07080", "submitter": "Marta Arias", "authors": "Giorgio Stampa, Marta Arias, David Sanchez-Charles, Victor\n  Muntes-Mulero, Albert Cabellos", "title": "A Deep-Reinforcement Learning Approach for Software-Defined Networking\n  Routing Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we design and evaluate a Deep-Reinforcement Learning agent that\noptimizes routing. Our agent adapts automatically to current traffic conditions\nand proposes tailored configurations that attempt to minimize the network\ndelay. Experiments show very promising performance. Moreover, this approach\nprovides important operational advantages with respect to traditional\noptimization algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 21:01:59 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Stampa", "Giorgio", ""], ["Arias", "Marta", ""], ["Sanchez-Charles", "David", ""], ["Muntes-Mulero", "Victor", ""], ["Cabellos", "Albert", ""]]}, {"id": "1709.07092", "submitter": "Umut Oztok", "authors": "Umut Oztok and Adnan Darwiche", "title": "On Compiling DNNFs without Determinism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art knowledge compilers generate deterministic subsets of DNNF,\nwhich have been recently shown to be exponentially less succinct than DNNF. In\nthis paper, we propose a new method to compile DNNFs without enforcing\ndeterminism necessarily. Our approach is based on compiling deterministic DNNFs\nwith the addition of auxiliary variables to the input formula. These variables\nare then existentially quantified from the deterministic structure in linear\ntime, which would lead to a DNNF that is equivalent to the input formula and\nnot necessarily deterministic. On the theoretical side, we show that the new\nmethod could generate exponentially smaller DNNFs than deterministic ones, even\nby adding a single auxiliary variable. Further, we show that various existing\ntechniques that introduce auxiliary variables to the input formulas can be\nemployed in our framework. On the practical side, we empirically demonstrate\nthat our new method can significantly advance DNNF compilation on certain\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 21:45:29 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Oztok", "Umut", ""], ["Darwiche", "Adnan", ""]]}, {"id": "1709.07095", "submitter": "Ram Shankar Siva Kumar", "authors": "Ram Shankar Siva Kumar, Andrew Wicker, Matt Swann", "title": "Practical Machine Learning for Cloud Intrusion Detection: Challenges and\n  the Way Forward", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operationalizing machine learning based security detections is extremely\nchallenging, especially in a continuously evolving cloud environment.\nConventional anomaly detection does not produce satisfactory results for\nanalysts that are investigating security incidents in the cloud. Model\nevaluation alone presents its own set of problems due to a lack of benchmark\ndatasets. When deploying these detections, we must deal with model compliance,\nlocalization, and data silo issues, among many others. We pose the problem of\n\"attack disruption\" as a way forward in the security data science space. In\nthis paper, we describe the framework, challenges, and open questions\nsurrounding the successful operationalization of machine learning based\nsecurity detections in a cloud environment and provide some insights on how we\nhave addressed them.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 22:21:14 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Kumar", "Ram Shankar Siva", ""], ["Wicker", "Andrew", ""], ["Swann", "Matt", ""]]}, {"id": "1709.07114", "submitter": "Peter Henderson", "authors": "Peter Henderson, Matthew Vertescher, David Meger, Mark Coates", "title": "Cost Adaptation for Robust Decentralized Swarm Behaviour", "comments": "Accepted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized receding horizon control (D-RHC) provides a mechanism for\ncoordination in multi-agent settings without a centralized command center.\nHowever, combining a set of different goals, costs, and constraints to form an\nefficient optimization objective for D-RHC can be difficult. To allay this\nproblem, we use a meta-learning process -- cost adaptation -- which generates\nthe optimization objective for D-RHC to solve based on a set of human-generated\npriors (cost and constraint functions) and an auxiliary heuristic. We use this\nadaptive D-RHC method for control of mesh-networked swarm agents. This\nformulation allows a wide range of tasks to be encoded and can account for\nnetwork delays, heterogeneous capabilities, and increasingly large swarms\nthrough the adaptation mechanism. We leverage the Unity3D game engine to build\na simulator capable of introducing artificial networking failures and delays in\nthe swarm. Using the simulator we validate our method on an example coordinated\nexploration task. We demonstrate that cost adaptation allows for more efficient\nand safer task completion under varying environment conditions and increasingly\nlarge swarm sizes. We release our simulator and code to the community for\nfuture work.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 00:50:23 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 01:23:53 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Henderson", "Peter", ""], ["Vertescher", "Matthew", ""], ["Meger", "David", ""], ["Coates", "Mark", ""]]}, {"id": "1709.07150", "submitter": "Udayan Khurana", "authors": "Udayan Khurana and Horst Samulowitz and Deepak Turaga", "title": "Feature Engineering for Predictive Modeling using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature engineering is a crucial step in the process of predictive modeling.\nIt involves the transformation of given feature space, typically using\nmathematical functions, with the objective of reducing the modeling error for a\ngiven target. However, there is no well-defined basis for performing effective\nfeature engineering. It involves domain knowledge, intuition, and most of all,\na lengthy process of trial and error. The human attention involved in\noverseeing this process significantly influences the cost of model generation.\nWe present a new framework to automate feature engineering. It is based on\nperformance driven exploration of a transformation graph, which systematically\nand compactly enumerates the space of given options. A highly efficient\nexploration strategy is derived through reinforcement learning on past\nexamples.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 04:04:43 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Khurana", "Udayan", ""], ["Samulowitz", "Horst", ""], ["Turaga", "Deepak", ""]]}, {"id": "1709.07223", "submitter": "Roarke Horstmeyer", "authors": "Roarke Horstmeyer, Richard Y. Chen, Barbara Kappes and Benjamin\n  Judkewitz", "title": "Convolutional neural networks that teach microscopes how to image", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms offer a powerful means to automatically analyze the\ncontent of medical images. However, many biological samples of interest are\nprimarily transparent to visible light and contain features that are difficult\nto resolve with a standard optical microscope. Here, we use a convolutional\nneural network (CNN) not only to classify images, but also to optimize the\nphysical layout of the imaging device itself. We increase the classification\naccuracy of a microscope's recorded images by merging an optical model of image\nformation into the pipeline of a CNN. The resulting network simultaneously\ndetermines an ideal illumination arrangement to highlight important sample\nfeatures during image acquisition, along with a set of convolutional weights to\nclassify the detected images post-capture. We demonstrate our joint\noptimization technique with an experimental microscope configuration that\nautomatically identifies malaria-infected cells with 5-10% higher accuracy than\nstandard and alternative microscope lighting designs.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 09:17:47 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Horstmeyer", "Roarke", ""], ["Chen", "Richard Y.", ""], ["Kappes", "Barbara", ""], ["Judkewitz", "Benjamin", ""]]}, {"id": "1709.07224", "submitter": "Maximilian H\\\"uttenrauch", "authors": "Maximilian H\\\"uttenrauch and Adrian \\v{S}o\\v{s}i\\'c and Gerhard\n  Neumann", "title": "Local Communication Protocols for Learning Complex Swarm Behaviors with\n  Deep Reinforcement Learning", "comments": "13 pages, 4 figures, version 2, accepted at ANTS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Swarm systems constitute a challenging problem for reinforcement learning\n(RL) as the algorithm needs to learn decentralized control policies that can\ncope with limited local sensing and communication abilities of the agents.\nWhile it is often difficult to directly define the behavior of the agents,\nsimple communication protocols can be defined more easily using prior knowledge\nabout the given task. In this paper, we propose a number of simple\ncommunication protocols that can be exploited by deep reinforcement learning to\nfind decentralized control policies in a multi-robot swarm environment. The\nprotocols are based on histograms that encode the local neighborhood relations\nof the agents and can also transmit task-specific information, such as the\nshortest distance and direction to a desired target. In our framework, we use\nan adaptation of Trust Region Policy Optimization to learn complex\ncollaborative tasks, such as formation building and building a communication\nlink. We evaluate our findings in a simulated 2D-physics environment, and\ncompare the implications of different communication protocols.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 09:18:09 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 08:39:08 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["H\u00fcttenrauch", "Maximilian", ""], ["\u0160o\u0161i\u0107", "Adrian", ""], ["Neumann", "Gerhard", ""]]}, {"id": "1709.07255", "submitter": "Christian Stra{\\ss}er", "authors": "Jesse Heyninck and Christian Stra{\\ss}er and Pere Pardo", "title": "Assumption-Based Approaches to Reasoning with Priorities", "comments": "Forthcoming in the proceedings of AI^3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper maps out the relation between different approaches for handling\npreferences in argumentation with strict rules and defeasible assumptions by\noffering translations between them. The systems we compare are: non-prioritized\ndefeats i.e. attacks, preference-based defeats, and preference-based defeats\nextended with reverse defeat.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 10:46:00 GMT"}, {"version": "v2", "created": "Fri, 29 Sep 2017 15:49:26 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Heyninck", "Jesse", ""], ["Stra\u00dfer", "Christian", ""], ["Pardo", "Pere", ""]]}, {"id": "1709.07314", "submitter": "Ana Ozaki", "authors": "Boris Konev, Carsten Lutz, Ana Ozaki and Frank Wolter", "title": "Exact Learning of Lightweight Description Logic Ontologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning description logic (DL) ontologies in Angluin\net al.'s framework of exact learning via queries. We admit membership queries\n(\"is a given subsumption entailed by the target ontology?\") and equivalence\nqueries (\"is a given ontology equivalent to the target ontology?\"). We present\nthree main results: (1) ontologies formulated in (two relevant versions of) the\ndescription logic DL-Lite can be learned with polynomially many queries of\npolynomial size; (2) this is not the case for ontologies formulated in the\ndescription logic EL, even when only acyclic ontologies are admitted; and (3)\nontologies formulated in a fragment of EL related to the web ontology language\nOWL 2 RL can be learned in polynomial time. We also show that neither\nmembership nor equivalence queries alone are sufficient in cases (1) and (3).\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 10:25:25 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Konev", "Boris", ""], ["Lutz", "Carsten", ""], ["Ozaki", "Ana", ""], ["Wolter", "Frank", ""]]}, {"id": "1709.07358", "submitter": "Toshio Suzuki", "authors": "Toshio Suzuki", "title": "Non-Depth-First Search against Independent Distributions on an AND-OR\n  Tree", "comments": "12 pages, 1 figure", "journal-ref": "Inf. Process. Lett. 139, pp.13-17 (2018)", "doi": "10.1016/j.ipl.2018.06.013", "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suzuki and Niida (Ann. Pure. Appl. Logic, 2015) showed the following results\non independent distributions (IDs) on an AND-OR tree, where they took only\ndepth-first algorithms into consideration. (1) Among IDs such that probability\nof the root having value 0 is fixed as a given r such that 0 < r < 1, if d is a\nmaximizer of cost of the best algorithm then d is an independent and identical\ndistribution (IID). (2) Among all IDs, if d is a maximizer of cost of the best\nalgorithm then d is an IID. In the case where non-depth-first algorithms are\ntaken into consideration, the counter parts of (1) and (2) are left open in the\nabove work. Peng et al. (Inform. Process. Lett., 2017) extended (1) and (2) to\nmulti-branching trees, where in (2) they put an additional hypothesis on IDs\nthat probability of the root having value 0 is neither 0 nor 1. We give\npositive answers for the two questions of Suzuki-Niida. A key to the proof is\nthat if ID d achieves the equilibrium among IDs then we can chose an algorithm\nof the best cost against d from depth-first algorithms. In addition, we extend\nthe result of Peng et al. to the case where non-depth-first algorithms are\ntaken into consideration.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 14:54:52 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Suzuki", "Toshio", ""]]}, {"id": "1709.07401", "submitter": "Ashwin Bahulkar", "authors": "Ashwin Bahulkar, Boleslaw K. Szymanski, Nitesh Chawla, Omar Lizardo,\n  and Kevin Chan", "title": "Influence of Personal Preferences on Link Dynamics in Social Networks", "comments": "12 pages", "journal-ref": "Complexity Volume 2017 (2017),", "doi": "10.1155/2017/4543563", "report-no": "Article ID 4543563", "categories": "cs.SI cs.AI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a unique network dataset including periodic surveys and electronic\nlogs of dyadic contacts via smartphones. The participants were a sample of\nfreshmen entering university in the Fall 2011. Their opinions on a variety of\npolitical and social issues and lists of activities on campus were regularly\nrecorded at the beginning and end of each semester for the first three years of\nstudy. We identify a behavioral network defined by call and text data, and a\ncognitive network based on friendship nominations in ego-network surveys. Both\nnetworks are limited to study participants. Since a wide range of attributes on\neach node were collected in self-reports, we refer to these networks as\nattribute-rich networks. We study whether student preferences for certain\nattributes of friends can predict formation and dissolution of edges in both\nnetworks. We introduce a method for computing student preferences for different\nattributes which we use to predict link formation and dissolution. We then rank\nthese attributes according to their importance for making predictions. We find\nthat personal preferences, in particular political views, and preferences for\ncommon activities help predict link formation and dissolution in both the\nbehavioral and cognitive networks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 16:35:51 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Bahulkar", "Ashwin", ""], ["Szymanski", "Boleslaw K.", ""], ["Chawla", "Nitesh", ""], ["Lizardo", "Omar", ""], ["Chan", "Kevin", ""]]}, {"id": "1709.07417", "submitter": "Irwan Bello", "authors": "Irwan Bello, Barret Zoph, Vijay Vasudevan, Quoc V. Le", "title": "Neural Optimizer Search with Reinforcement Learning", "comments": "ICML 2017 Conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to automate the process of discovering optimization\nmethods, with a focus on deep learning architectures. We train a Recurrent\nNeural Network controller to generate a string in a domain specific language\nthat describes a mathematical update equation based on a list of primitive\nfunctions, such as the gradient, running average of the gradient, etc. The\ncontroller is trained with Reinforcement Learning to maximize the performance\nof a model after a few epochs. On CIFAR-10, our method discovers several update\nrules that are better than many commonly used optimizers, such as Adam,\nRMSProp, or SGD with and without Momentum on a ConvNet model. We introduce two\nnew optimizers, named PowerSign and AddSign, which we show transfer well and\nimprove training on a variety of different tasks and architectures, including\nImageNet classification and Google's neural machine translation system.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 17:01:47 GMT"}, {"version": "v2", "created": "Fri, 22 Sep 2017 15:27:27 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Bello", "Irwan", ""], ["Zoph", "Barret", ""], ["Vasudevan", "Vijay", ""], ["Le", "Quoc V.", ""]]}, {"id": "1709.07480", "submitter": "Michael Albert", "authors": "Mathijs de Weerdt, Michael Albert, Vincent Conitzer", "title": "Complexity of Scheduling Charging in the Smart Grid", "comments": null, "journal-ref": null, "doi": "10.24963/ijcai.2018/658", "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the smart grid, the intent is to use flexibility in demand, both to\nbalance demand and supply as well as to resolve potential congestion. A first\nprominent example of such flexible demand is the charging of electric vehicles,\nwhich do not necessarily need to be charged as soon as they are plugged in. The\nproblem of optimally scheduling the charging demand of electric vehicles within\nthe constraints of the electricity infrastructure is called the charge\nscheduling problem. The models of the charging speed, horizon, and charging\ndemand determine the computational complexity of the charge scheduling problem.\nFor about 20 variants, we show, using a dynamic programming approach, that the\nproblem is either in P or weakly NP-hard. We also show that about 10 variants\nof the problem are strongly NP-hard, presenting a potentially significant\nobstacle to their use in practical situations of scale.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 18:33:35 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["de Weerdt", "Mathijs", ""], ["Albert", "Michael", ""], ["Conitzer", "Vincent", ""]]}, {"id": "1709.07492", "submitter": "Fangchang Ma", "authors": "Fangchang Ma, Sertac Karaman", "title": "Sparse-to-Dense: Depth Prediction from Sparse Depth Samples and a Single\n  Image", "comments": "accepted to ICRA 2018. 8 pages, 8 figures, 3 tables. Video at\n  https://www.youtube.com/watch?v=vNIIT_M7x7Y. Code at\n  https://github.com/fangchangma/sparse-to-dense", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of dense depth prediction from a sparse set of depth\nmeasurements and a single RGB image. Since depth estimation from monocular\nimages alone is inherently ambiguous and unreliable, to attain a higher level\nof robustness and accuracy, we introduce additional sparse depth samples, which\nare either acquired with a low-resolution depth sensor or computed via visual\nSimultaneous Localization and Mapping (SLAM) algorithms. We propose the use of\na single deep regression network to learn directly from the RGB-D raw data, and\nexplore the impact of number of depth samples on prediction accuracy. Our\nexperiments show that, compared to using only RGB images, the addition of 100\nspatially random depth samples reduces the prediction root-mean-square error by\n50% on the NYU-Depth-v2 indoor dataset. It also boosts the percentage of\nreliable prediction from 59% to 92% on the KITTI dataset. We demonstrate two\napplications of the proposed algorithm: a plug-in module in SLAM to convert\nsparse maps to dense maps, and super-resolution for LiDARs. Software and video\ndemonstration are publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 18:50:04 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 04:16:14 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Ma", "Fangchang", ""], ["Karaman", "Sertac", ""]]}, {"id": "1709.07511", "submitter": "Mark Lewis", "authors": "Mark Lewis, Gary Kochenberger, John Metcalfe", "title": "Robust Optimization of Unconstrained Binary Quadratic Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on the unconstrained binary quadratic optimization\nmodel, maximize x^t Qx, x binary, and consider the problem of identifying\noptimal solutions that are robust with respect to perturbations in the Q\nmatrix.. We are motivated to find robust, or stable, solutions because of the\nuncertainty inherent in the big data origins of Q and limitations in computer\nnumerical precision, particularly in a new class of quantum annealing\ncomputers. Experimental design techniques are used to generate a diverse subset\nof possible scenarios, from which robust solutions are identified. An\nillustrative example with practical application to business decision making is\nexamined. The approach presented also generates a surface response equation\nwhich is used to estimate upper bounds in constant time for Q instantiations\nwithin the scenario extremes. In addition, a theoretical framework for the\nrobustness of individual x_i variables is considered by examining the range of\nQ values over which the x_i are predetermined.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 20:36:21 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Lewis", "Mark", ""], ["Kochenberger", "Gary", ""], ["Metcalfe", "John", ""]]}, {"id": "1709.07528", "submitter": "Kenneth Hess", "authors": "Kenneth L. Hess, Hugo D. Paz", "title": "Defining a Lingua Franca to Open the Black Box of a Na\\\"ive Bayes\n  Recommender", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many AI systems have a black box nature that makes it difficult to understand\nhow they make their recommendations. This can be unsettling, as the designer\ncannot be certain how the system will respond to novelty. To penetrate our\nNa\\\"ive Bayes recommender's black box, we first asked, what do we want to know\nfrom our system, and how can it be obtained? The answers led us to recursively\ndefine a common lexicon with the AI, a lingua franca, using the very items that\nthe system ranks to create meta-symbols recognized by the system, and enabling\nus to understand the system's knowledge in plain terms and at different levels\nof abstraction. As one bonus, using its existing knowledge, the lingua franca\ncan enable the system to extend recommendations to related, but entirely new\nareas, ameliorating the cold start problem. We also supplement the lingua\nfranca with techniques for visualizing the system's knowledge state, develop\nmetrics for evaluating the meaningfulness of terms in the lingua franca, and\ngeneralize the requirements for developing a similar lingua franca in other\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 22:06:26 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Hess", "Kenneth L.", ""], ["Paz", "Hugo D.", ""]]}, {"id": "1709.07534", "submitter": "Arijit Biswas", "authors": "Arijit Biswas, Mukul Bhutani and Subhajit Sanyal", "title": "MRNet-Product2Vec: A Multi-task Recurrent Neural Network for Product\n  Embeddings", "comments": "Published in ECML-PKDD 2017 (Applied Data Science Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-commerce websites such as Amazon, Alibaba, Flipkart, and Walmart sell\nbillions of products. Machine learning (ML) algorithms involving products are\noften used to improve the customer experience and increase revenue, e.g.,\nproduct similarity, recommendation, and price estimation. The products are\nrequired to be represented as features before training an ML algorithm. In this\npaper, we propose an approach called MRNet-Product2Vec for creating generic\nembeddings of products within an e-commerce ecosystem. We learn a dense and\nlow-dimensional embedding where a diverse set of signals related to a product\nare explicitly injected into its representation. We train a Discriminative\nMulti-task Bidirectional Recurrent Neural Network (RNN), where the input is a\nproduct title fed through a Bidirectional RNN and at the output, product labels\ncorresponding to fifteen different tasks are predicted. The task set includes\nseveral intrinsic characteristics about a product such as price, weight, size,\ncolor, popularity, and material. We evaluate the proposed embedding\nquantitatively and qualitatively. We demonstrate that they are almost as good\nas sparse and extremely high-dimensional TF-IDF representation in spite of\nhaving less than 3% of the TF-IDF dimension. We also use a multimodal\nautoencoder for comparing products from different language-regions and show\npreliminary yet promising qualitative results.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 22:38:51 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Biswas", "Arijit", ""], ["Bhutani", "Mukul", ""], ["Sanyal", "Subhajit", ""]]}, {"id": "1709.07576", "submitter": "Jialong Shi", "authors": "Jialong Shi, Qingfu Zhang, Edward Tsang", "title": "EB-GLS: An Improved Guided Local Search Based on the Big Valley\n  Structure", "comments": null, "journal-ref": "Memetic Computing, 2017: 1-18", "doi": "10.1007/s12293-017-0242-5", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local search is a basic building block in memetic algorithms. Guided Local\nSearch (GLS) can improve the efficiency of local search. By changing the guide\nfunction, GLS guides a local search to escape from locally optimal solutions\nand find better solutions. The key component of GLS is its penalizing mechanism\nwhich determines which feature is selected to penalize when the search is\ntrapped in a locally optimal solution. The original GLS penalizing mechanism\nonly makes use of the cost and the current penalty value of each feature. It is\nwell known that many combinatorial optimization problems have a big valley\nstructure, i.e., the better a solution is, the more the chance it is closer to\na globally optimal solution. This paper proposes to use big valley structure\nassumption to improve the GLS penalizing mechanism. An improved GLS algorithm\ncalled Elite Biased GLS (EB-GLS) is proposed. EB-GLS records and maintains an\nelite solution as an estimate of the globally optimal solutions, and reduces\nthe chance of penalizing the features in this solution. We have systematically\ntested the proposed algorithm on the symmetric traveling salesman problem.\nExperimental results show that EB-GLS is significantly better than GLS.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 02:43:25 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Shi", "Jialong", ""], ["Zhang", "Qingfu", ""], ["Tsang", "Edward", ""]]}, {"id": "1709.07581", "submitter": "Chiyu Jiang", "authors": "Chiyu \"Max\" Jiang, Philip Marcus", "title": "Hierarchical Detail Enhancing Mesh-Based Shape Generation with 3D\n  Generative Adversarial Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automatic mesh-based shape generation is of great interest across a wide\nrange of disciplines, from industrial design to gaming, computer graphics and\nvarious other forms of digital art. While most traditional methods focus on\nprimitive based model generation, advances in deep learning made it possible to\nlearn 3-dimensional geometric shape representations in an end-to-end manner.\nHowever, most current deep learning based frameworks focus on the\nrepresentation and generation of voxel and point-cloud based shapes, making it\nnot directly applicable to design and graphics communities. This study\naddresses the needs for automatic generation of mesh-based geometries, and\npropose a novel framework that utilizes signed distance function representation\nthat generates detail preserving three-dimensional surface mesh by a deep\nlearning based approach.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 03:17:34 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Jiang", "Chiyu \"Max\"", ""], ["Marcus", "Philip", ""]]}, {"id": "1709.07597", "submitter": "Mohit Sharma", "authors": "Mohit Sharma, Kris M. Kitani, and Joachim Groeger", "title": "Inverse Reinforcement Learning with Conditional Choice Probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make an important connection to existing results in econometrics to\ndescribe an alternative formulation of inverse reinforcement learning (IRL). In\nparticular, we describe an algorithm using Conditional Choice Probabilities\n(CCP), which are maximum likelihood estimates of the policy estimated from\nexpert demonstrations, to solve the IRL problem. Using the language of\nstructural econometrics, we re-frame the optimal decision problem and introduce\nan alternative representation of value functions due to (Hotz and Miller 1993).\nIn addition to presenting the theoretical connections that bridge the IRL\nliterature between Economics and Robotics, the use of CCPs also has the\npractical benefit of reducing the computational cost of solving the IRL\nproblem. Specifically, under the CCP representation, we show how one can avoid\nrepeated calls to the dynamic programming subroutine typically used in IRL. We\nshow via extensive experimentation on standard IRL benchmarks that CCP-IRL is\nable to outperform MaxEnt-IRL, with as much as a 5x speedup and without\ncompromising on the quality of the recovered reward function.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 05:12:04 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Sharma", "Mohit", ""], ["Kitani", "Kris M.", ""], ["Groeger", "Joachim", ""]]}, {"id": "1709.07604", "submitter": "Vincent Zheng", "authors": "Hongyun Cai, Vincent W. Zheng, Kevin Chen-Chuan Chang", "title": "A Comprehensive Survey of Graph Embedding: Problems, Techniques and\n  Applications", "comments": "A 20-page comprehensive survey of graph/network embedding for over\n  150+ papers till year 2018. It provides systematic categorization of\n  problems, techniques and applications. Accepted by IEEE Transactions on\n  Knowledge and Data Engineering (TKDE). Comments and suggestions are welcomed\n  for continuously improving this survey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph is an important data representation which appears in a wide diversity\nof real-world scenarios. Effective graph analytics provides users a deeper\nunderstanding of what is behind the data, and thus can benefit a lot of useful\napplications such as node classification, node recommendation, link prediction,\netc. However, most graph analytics methods suffer the high computation and\nspace cost. Graph embedding is an effective yet efficient way to solve the\ngraph analytics problem. It converts the graph data into a low dimensional\nspace in which the graph structural information and graph properties are\nmaximally preserved. In this survey, we conduct a comprehensive review of the\nliterature in graph embedding. We first introduce the formal definition of\ngraph embedding as well as the related concepts. After that, we propose two\ntaxonomies of graph embedding which correspond to what challenges exist in\ndifferent graph embedding problem settings and how the existing work address\nthese challenges in their solutions. Finally, we summarize the applications\nthat graph embedding enables and suggest four promising future research\ndirections in terms of computation efficiency, problem settings, techniques and\napplication scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 05:54:16 GMT"}, {"version": "v2", "created": "Wed, 3 Jan 2018 02:09:40 GMT"}, {"version": "v3", "created": "Fri, 2 Feb 2018 07:01:22 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Cai", "Hongyun", ""], ["Zheng", "Vincent W.", ""], ["Chang", "Kevin Chen-Chuan", ""]]}, {"id": "1709.07615", "submitter": "Katharina Eggensperger", "authors": "Katharina Eggensperger, Marius Lindauer and Frank Hutter", "title": "Neural Networks for Predicting Algorithm Runtime Distributions", "comments": null, "journal-ref": "International Joint Conference on Artificial Intelligence (2018),\n  1442--1448", "doi": "10.24963/ijcai.2018/200", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many state-of-the-art algorithms for solving hard combinatorial problems in\nartificial intelligence (AI) include elements of stochasticity that lead to\nhigh variations in runtime, even for a fixed problem instance. Knowledge about\nthe resulting runtime distributions (RTDs) of algorithms on given problem\ninstances can be exploited in various meta-algorithmic procedures, such as\nalgorithm selection, portfolios, and randomized restarts. Previous work has\nshown that machine learning can be used to individually predict mean, median\nand variance of RTDs. To establish a new state-of-the-art in predicting RTDs,\nwe demonstrate that the parameters of an RTD should be learned jointly and that\nneural networks can do this well by directly optimizing the likelihood of an\nRTD given runtime observations. In an empirical study involving five algorithms\nfor SAT solving and AI planning, we show that neural networks predict the true\nRTDs of unseen instances better than previous methods, and can even do so when\nonly few runtime observations are available per training instance.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 07:25:13 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 07:09:21 GMT"}, {"version": "v3", "created": "Wed, 9 May 2018 07:42:29 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Eggensperger", "Katharina", ""], ["Lindauer", "Marius", ""], ["Hutter", "Frank", ""]]}, {"id": "1709.07642", "submitter": "Wenhao Zheng", "authors": "Wenhao Zheng, Hong-Yu Zhou, Ming Li and Jianxin Wu", "title": "Code Attention: Translating Code to Comments by Exploiting Domain\n  Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Appropriate comments of code snippets provide insight for code functionality,\nwhich are helpful for program comprehension. However, due to the great cost of\nauthoring with the comments, many code projects do not contain adequate\ncomments. Automatic comment generation techniques have been proposed to\ngenerate comments from pieces of code in order to alleviate the human efforts\nin annotating the code. Most existing approaches attempt to exploit certain\ncorrelations (usually manually given) between code and generated comments,\nwhich could be easily violated if the coding patterns change and hence the\nperformance of comment generation declines. In this paper, we first build\nC2CGit, a large dataset from open projects in GitHub, which is more than\n20$\\times$ larger than existing datasets. Then we propose a new attention\nmodule called Code Attention to translate code to comments, which is able to\nutilize the domain features of code snippets, such as symbols and identifiers.\nWe make ablation studies to determine effects of different parts in Code\nAttention. Experimental results demonstrate that the proposed module has better\nperformance over existing approaches in both BLEU and METEOR.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 09:08:47 GMT"}, {"version": "v2", "created": "Mon, 27 Nov 2017 11:32:04 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Zheng", "Wenhao", ""], ["Zhou", "Hong-Yu", ""], ["Li", "Ming", ""], ["Wu", "Jianxin", ""]]}, {"id": "1709.07643", "submitter": "Tu-Hoa Pham", "authors": "Tu-Hoa Pham, Giovanni De Magistris, Ryuki Tachibana", "title": "OptLayer - Practical Constrained Optimization for Deep Reinforcement\n  Learning in the Real World", "comments": "To appear at ICRA 2018. Video:\n  https://www.youtube.com/watch?v=7liBbk3VjWQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep reinforcement learning techniques have recently produced\nconsiderable achievements on many decision-making problems, their use in\nrobotics has largely been limited to simulated worlds or restricted motions,\nsince unconstrained trial-and-error interactions in the real world can have\nundesirable consequences for the robot or its environment. To overcome such\nlimitations, we propose a novel reinforcement learning architecture, OptLayer,\nthat takes as inputs possibly unsafe actions predicted by a neural network and\noutputs the closest actions that satisfy chosen constraints. While learning\ncontrol policies often requires carefully crafted rewards and penalties while\nexploring the range of possible actions, OptLayer ensures that only safe\nactions are actually executed and unsafe predictions are penalized during\ntraining. We demonstrate the effectiveness of our approach on robot reaching\ntasks, both simulated and in the real world.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 09:10:10 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 08:39:26 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Pham", "Tu-Hoa", ""], ["De Magistris", "Giovanni", ""], ["Tachibana", "Ryuki", ""]]}, {"id": "1709.07791", "submitter": "Benjamin Goertzel", "authors": "Ben Goertzel, Julia Mossbridge, Eddie Monroe, David Hanson, Gino Yu", "title": "Humanoid Robots as Agents of Human Consciousness Expansion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"Loving AI\" project involves developing software enabling humanoid robots\nto interact with people in loving and compassionate ways, and to promote\npeople' self-understanding and self-transcendence. Currently the project\ncenters on the Hanson Robotics robot \"Sophia\" -- specifically, on supplying\nSophia with personality content and cognitive, linguistic, perceptual and\nbehavioral content aimed at enabling loving interactions supportive of human\nself-transcendence. In September 2017 a small pilot study was conducted,\ninvolving the Sophia robot leading human subjects through dialogues and\nexercises focused on meditation, visualization and relaxation. The pilot was an\napparent success, qualitatively demonstrating the viability of the approach and\nthe ability of appropriate human-robot interaction to increase human well-being\nand advance human consciousness.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 14:52:23 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Goertzel", "Ben", ""], ["Mossbridge", "Julia", ""], ["Monroe", "Eddie", ""], ["Hanson", "David", ""], ["Yu", "Gino", ""]]}, {"id": "1709.07796", "submitter": "Vincent Francois-Lavet", "authors": "Vincent Francois-Lavet, Guillaume Rabusseau, Joelle Pineau, Damien\n  Ernst, Raphael Fonteneau", "title": "On overfitting and asymptotic bias in batch reinforcement learning with\n  partial observability", "comments": "Accepted at the Journal of Artificial Intelligence Research (JAIR) -\n  31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an analysis of the tradeoff between asymptotic bias\n(suboptimality with unlimited data) and overfitting (additional suboptimality\ndue to limited data) in the context of reinforcement learning with partial\nobservability. Our theoretical analysis formally characterizes that while\npotentially increasing the asymptotic bias, a smaller state representation\ndecreases the risk of overfitting. This analysis relies on expressing the\nquality of a state representation by bounding L1 error terms of the associated\nbelief states. Theoretical results are empirically illustrated when the state\nrepresentation is a truncated history of observations, both on synthetic POMDPs\nand on a large-scale POMDP in the context of smartgrids, with real-world data.\nFinally, similarly to known results in the fully observable setting, we also\nbriefly discuss and empirically illustrate how using function approximators and\nadapting the discount factor may enhance the tradeoff between asymptotic bias\nand overfitting in the partially observable context.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 14:56:35 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 18:30:04 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Francois-Lavet", "Vincent", ""], ["Rabusseau", "Guillaume", ""], ["Pineau", "Joelle", ""], ["Ernst", "Damien", ""], ["Fonteneau", "Raphael", ""]]}, {"id": "1709.07808", "submitter": "Mikel Sanz", "authors": "M. Sanz, L. Lamata, E. Solano", "title": "Quantum Memristors in Quantum Photonics", "comments": null, "journal-ref": "APL Photonics 3, 080801 (2018)", "doi": "10.1063/1.5036596", "report-no": null, "categories": "quant-ph cond-mat.mes-hall cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to build quantum memristors in quantum photonic\nplatforms. We firstly design an effective beam splitter, which is tunable in\nreal-time, by means of a Mach-Zehnder-type array with two equal 50:50 beam\nsplitters and a tunable retarder, which allows us to control its reflectivity.\nThen, we show that this tunable beam splitter, when equipped with weak\nmeasurements and classical feedback, behaves as a quantum memristor. Indeed, in\norder to prove its quantumness, we show how to codify quantum information in\nthe coherent beams. Moreover, we estimate the memory capability of the quantum\nmemristor. Finally, we show the feasibility of the proposed setup in integrated\nquantum photonics.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 15:24:31 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 15:35:33 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Sanz", "M.", ""], ["Lamata", "L.", ""], ["Solano", "E.", ""]]}, {"id": "1709.07842", "submitter": "Lawrence Stewart", "authors": "Lawrence Stewart, Mark Stalzer", "title": "Bayesian Optimization for Parameter Tuning of the XOR Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When applying Machine Learning techniques to problems, one must select model\nparameters to ensure that the system converges but also does not become stuck\nat the objective function's local minimum. Tuning these parameters becomes a\nnon-trivial task for large models and it is not always apparent if the user has\nfound the optimal parameters. We aim to automate the process of tuning a Neural\nNetwork, (where only a limited number of parameter search attempts are\navailable) by implementing Bayesian Optimization. In particular, by assigning\nGaussian Process Priors to the parameter space, we utilize Bayesian\nOptimization to tune an Artificial Neural Network used to learn the XOR\nfunction, with the result of achieving higher prediction accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 16:52:02 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 19:31:41 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Stewart", "Lawrence", ""], ["Stalzer", "Mark", ""]]}, {"id": "1709.07848", "submitter": "Lucas Lamata", "authors": "F. A. C\\'ardenas-L\\'opez, L. Lamata, J. C. Retamal, E. Solano", "title": "Multiqubit and multilevel quantum reinforcement learning with quantum\n  technologies", "comments": null, "journal-ref": "PLoS ONE 13(7):e0200455 (2018)", "doi": "10.1371/journal.pone.0200455", "report-no": null, "categories": "quant-ph cond-mat.mes-hall cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a protocol to perform quantum reinforcement learning with quantum\ntechnologies. At variance with recent results on quantum reinforcement learning\nwith superconducting circuits, in our current protocol coherent feedback during\nthe learning process is not required, enabling its implementation in a wide\nvariety of quantum systems. We consider diverse possible scenarios for an\nagent, an environment, and a register that connects them, involving multiqubit\nand multilevel systems, as well as open-system dynamics. We finally propose\npossible implementations of this protocol in trapped ions and superconducting\ncircuits. The field of quantum reinforcement learning with quantum technologies\nwill enable enhanced quantum control, as well as more efficient machine\nlearning calculations.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 17:04:44 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2018 18:04:34 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["C\u00e1rdenas-L\u00f3pez", "F. A.", ""], ["Lamata", "L.", ""], ["Retamal", "J. C.", ""], ["Solano", "E.", ""]]}, {"id": "1709.07857", "submitter": "Alexander Irpan", "authors": "Konstantinos Bousmalis, Alex Irpan, Paul Wohlhart, Yunfei Bai, Matthew\n  Kelcey, Mrinal Kalakrishnan, Laura Downs, Julian Ibarz, Peter Pastor, Kurt\n  Konolige, Sergey Levine, Vincent Vanhoucke", "title": "Using Simulation and Domain Adaptation to Improve Efficiency of Deep\n  Robotic Grasping", "comments": "9 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instrumenting and collecting annotated visual grasping datasets to train\nmodern machine learning algorithms can be extremely time-consuming and\nexpensive. An appealing alternative is to use off-the-shelf simulators to\nrender synthetic data for which ground-truth annotations are generated\nautomatically. Unfortunately, models trained purely on simulated data often\nfail to generalize to the real world. We study how randomized simulated\nenvironments and domain adaptation methods can be extended to train a grasping\nsystem to grasp novel objects from raw monocular RGB images. We extensively\nevaluate our approaches with a total of more than 25,000 physical test grasps,\nstudying a range of simulation conditions and domain adaptation methods,\nincluding a novel extension of pixel-level domain adaptation that we term the\nGraspGAN. We show that, by using synthetic data and domain adaptation, we are\nable to reduce the number of real-world samples needed to achieve a given level\nof performance by up to 50 times, using only randomly generated simulated\nobjects. We also show that by using only unlabeled real-world data and our\nGraspGAN methodology, we obtain real-world grasping performance without any\nreal-world labels that is similar to that achieved with 939,777 labeled\nreal-world samples.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 17:23:12 GMT"}, {"version": "v2", "created": "Mon, 25 Sep 2017 21:35:45 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Bousmalis", "Konstantinos", ""], ["Irpan", "Alex", ""], ["Wohlhart", "Paul", ""], ["Bai", "Yunfei", ""], ["Kelcey", "Matthew", ""], ["Kalakrishnan", "Mrinal", ""], ["Downs", "Laura", ""], ["Ibarz", "Julian", ""], ["Pastor", "Peter", ""], ["Konolige", "Kurt", ""], ["Levine", "Sergey", ""], ["Vanhoucke", "Vincent", ""]]}, {"id": "1709.07871", "submitter": "Ethan Perez", "authors": "Ethan Perez, Florian Strub, Harm de Vries, Vincent Dumoulin, Aaron\n  Courville", "title": "FiLM: Visual Reasoning with a General Conditioning Layer", "comments": "AAAI 2018. Code available at http://github.com/ethanjperez/film .\n  Extends arXiv:1707.03017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general-purpose conditioning method for neural networks called\nFiLM: Feature-wise Linear Modulation. FiLM layers influence neural network\ncomputation via a simple, feature-wise affine transformation based on\nconditioning information. We show that FiLM layers are highly effective for\nvisual reasoning - answering image-related questions which require a\nmulti-step, high-level process - a task which has proven difficult for standard\ndeep learning methods that do not explicitly model reasoning. Specifically, we\nshow on visual reasoning tasks that FiLM layers 1) halve state-of-the-art error\nfor the CLEVR benchmark, 2) modulate features in a coherent manner, 3) are\nrobust to ablations and architectural modifications, and 4) generalize well to\nchallenging, new data from few examples or even zero-shot.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 17:54:12 GMT"}, {"version": "v2", "created": "Mon, 18 Dec 2017 21:25:53 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Perez", "Ethan", ""], ["Strub", "Florian", ""], ["de Vries", "Harm", ""], ["Dumoulin", "Vincent", ""], ["Courville", "Aaron", ""]]}, {"id": "1709.07876", "submitter": "Juan Rojas", "authors": "Shuangqi Luo, Hongmin Wu, Hongbin Lin, Shuangda Duan, Yisheng Guan,\n  and Juan Rojas", "title": "Fast, Robust, and Versatile Event Detection through HMM Belief State\n  Gradient Measures", "comments": "8 pages, 7 figures, double col, ieee conference format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event detection is a critical feature in data-driven systems as it assists\nwith the identification of nominal and anomalous behavior. Event detection is\nincreasingly relevant in robotics as robots operate with greater autonomy in\nincreasingly unstructured environments. In this work, we present an accurate,\nrobust, fast, and versatile measure for skill and anomaly identification. A\ntheoretical proof establishes the link between the derivative of the\nlog-likelihood of the HMM filtered belief state and the latest emission\nprobabilities. The key insight is the inverse relationship in which gradient\nanalysis is used for skill and anomaly identification. Our measure showed\nbetter performance across all metrics than related state-of-the art works. The\nresult is broadly applicable to domains that use HMMs for event detection.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 15:27:36 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 06:20:42 GMT"}, {"version": "v3", "created": "Wed, 20 Jun 2018 03:01:08 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Luo", "Shuangqi", ""], ["Wu", "Hongmin", ""], ["Lin", "Hongbin", ""], ["Duan", "Shuangda", ""], ["Guan", "Yisheng", ""], ["Rojas", "Juan", ""]]}, {"id": "1709.07941", "submitter": "Janis Kalofolias", "authors": "Janis Kalofolias, Mario Boley and Jilles Vreeken", "title": "Efficiently Discovering Locally Exceptional yet Globally Representative\n  Subgroups", "comments": "10 pages, To appear in ICDM17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subgroup discovery is a local pattern mining technique to find interpretable\ndescriptions of sub-populations that stand out on a given target variable. That\nis, these sub-populations are exceptional with regard to the global\ndistribution. In this paper we argue that in many applications, such as\nscientific discovery, subgroups are only useful if they are additionally\nrepresentative of the global distribution with regard to a control variable.\nThat is, when the distribution of this control variable is the same, or almost\nthe same, as over the whole data.\n  We formalise this objective function and give an efficient algorithm to\ncompute its tight optimistic estimator for the case of a numeric target and a\nbinary control variable. This enables us to use the branch-and-bound framework\nto efficiently discover the top-$k$ subgroups that are both exceptional as well\nas representative. Experimental evaluation on a wide range of datasets shows\nthat with this algorithm we discover meaningful representative patterns and are\nup to orders of magnitude faster in terms of node evaluations as well as time.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 20:49:41 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Kalofolias", "Janis", ""], ["Boley", "Mario", ""], ["Vreeken", "Jilles", ""]]}, {"id": "1709.07979", "submitter": "Wenhao Yu", "authors": "Wenhao Yu, C. Karen Liu, Greg Turk", "title": "Multi-task Learning with Gradient Guided Policy Specialization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for efficient learning of control policies for multiple\nrelated robotic motor skills. Our approach consists of two stages, joint\ntraining and specialization training. During the joint training stage, a neural\nnetwork policy is trained with minimal information to disambiguate the motor\nskills. This forces the policy to learn a common representation of the\ndifferent tasks. Then, during the specialization training stage we selectively\nsplit the weights of the policy based on a per-weight metric that measures the\ndisagreement among the multiple tasks. By splitting part of the control policy,\nit can be further trained to specialize to each task. To update the control\npolicy during learning, we use Trust Region Policy Optimization with\nGeneralized Advantage Function (TRPOGAE). We propose a modification to the\ngradient update stage of TRPO to better accommodate multi-task learning\nscenarios. We evaluate our approach on three continuous motor skill learning\nproblems in simulation: 1) a locomotion task where three single legged robots\nwith considerable difference in shape and size are trained to hop forward, 2) a\nmanipulation task where three robot manipulators with different sizes and joint\ntypes are trained to reach different locations in 3D space, and 3) locomotion\nof a two-legged robot, whose range of motion of one leg is constrained in\ndifferent ways. We compare our training method to three baselines. The first\nbaseline uses only joint training for the policy, the second trains independent\npolicies for each task, and the last randomly selects weights to split. We show\nthat our approach learns more efficiently than each of the baseline methods.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 00:54:18 GMT"}, {"version": "v2", "created": "Wed, 11 Oct 2017 15:28:57 GMT"}, {"version": "v3", "created": "Fri, 2 Mar 2018 22:23:00 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Yu", "Wenhao", ""], ["Liu", "C. Karen", ""], ["Turk", "Greg", ""]]}, {"id": "1709.08019", "submitter": "Jalal Mirakhorli", "authors": "Jalal Mirakhorli, Hamidreza Amindavar", "title": "Semi-Supervised Hierarchical Semantic Object Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models based on Convolutional Neural Networks (CNNs) have been proven very\nsuccessful for semantic segmentation and object parsing that yield hierarchies\nof features. Our key insight is to build convolutional networks that take input\nof arbitrary size and produce object parsing output with efficient inference\nand learning. In this work, we focus on the task of instance segmentation and\nparsing which recognizes and localizes objects down to a pixel level base on\ndeep CNN. Therefore, unlike some related work, a pixel cannot belong to\nmultiple instances and parsing. Our model is based on a deep neural network\ntrained for object masking that supervised with input image and follow\nincorporates a Conditional Random Field (CRF) with end-to-end trainable\npiecewise order potentials based on object parsing outputs. In each CRF unit we\ndesigned terms to capture the short range and long range dependencies from\nvarious neighbors. The accurate instance-level segmentation that our network\nproduce is reflected by the considerable improvements obtained over previous\nwork at high APr thresholds. We demonstrate the effectiveness of our model with\nextensive experiments on challenging dataset subset of PASCAL VOC2012.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 08:01:44 GMT"}, {"version": "v2", "created": "Tue, 3 Oct 2017 13:54:11 GMT"}, {"version": "v3", "created": "Sun, 29 Oct 2017 16:24:53 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Mirakhorli", "Jalal", ""], ["Amindavar", "Hamidreza", ""]]}, {"id": "1709.08024", "submitter": "Yuanfang Chen", "authors": "Yuanfang Chen, Mohsen Guizani, Yan Zhang, Lei Wang, Noel Crespi, Gyu\n  Myoung Lee", "title": "When Traffic Flow Prediction Meets Wireless Big Data Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic flow prediction is an important research issue for solving the\ntraffic congestion problem in an Intelligent Transportation System (ITS).\nTraffic congestion is one of the most serious problems in a city, which can be\npredicted in advance by analyzing traffic flow patterns. Such prediction is\npossible by analyzing the real-time transportation data from correlative roads\nand vehicles. This article first gives a brief introduction to the\ntransportation data, and surveys the state-of-the-art prediction methods. Then,\nwe verify whether or not the prediction performance is able to be improved by\nfitting actual data to optimize the parameters of the prediction model which is\nused to predict the traffic flow. Such verification is conducted by comparing\nthe optimized time series prediction model with the normal time series\nprediction model. This means that in the era of big data, accurate use of the\ndata becomes the focus of studying the traffic flow prediction to solve the\ncongestion problem. Finally, experimental results of a case study are provided\nto verify the existence of such performance improvement, while the research\nchallenges of this data-analytics-based prediction are presented and discussed.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 08:54:25 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Chen", "Yuanfang", ""], ["Guizani", "Mohsen", ""], ["Zhang", "Yan", ""], ["Wang", "Lei", ""], ["Crespi", "Noel", ""], ["Lee", "Gyu Myoung", ""]]}, {"id": "1709.08027", "submitter": "Dmytro Terletskyi", "authors": "Dmytro Terletskyi", "title": "Object-Oriented Knowledge Representation and Data Storage Using\n  Inhomogeneous Classes", "comments": "2 figures", "journal-ref": "Information and Software Technologies, Volume 756 of the series\n  Communications in Computer and Information Science, 2017, pp. 48-61", "doi": "10.1007/978-3-319-67642-5_5", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contains analysis of concept of a class within different\nobject-oriented knowledge representation models. The main attention is paid to\nstructure of the class and its efficiency in the context of data storage, using\nobject-relational mapping. The main achievement of the paper is extension of\nconcept of homogeneous class of objects by introducing concepts of single-core\nand multi-core inhomogeneous classes of objects, which allow simultaneous\ndefining of a few different types within one class of objects, avoiding\nduplication of properties and methods in representation of types, decreasing\nsizes of program codes and providing more efficient information storage in the\ndatabases. In addition, the paper contains results of experiment, which show\nthat data storage in relational database, using proposed extensions of the\nclass, in some cases is more efficient in contrast to usage of homogeneous\nclasses of objects.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 09:09:04 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Terletskyi", "Dmytro", ""]]}, {"id": "1709.08028", "submitter": "Noreddine Gherabi", "authors": "Noreddine Gherabi, Redouane Nejjahi, and Abderrahim Marzouk", "title": "Towards Classification of Web ontologies using the Horizontal and\n  Vertical Segmentation", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-64719-7", "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new era of the Web is known as the semantic Web or the Web of data. The\nsemantic Web depends on ontologies that are seen as one of its pillars. The\nbigger these ontologies, the greater their exploitation. However, when these\nontologies become too big other problems may appear, such as the complexity to\ncharge big files in memory, the time it needs to download such files and\nespecially the time it needs to make reasoning on them. We discuss in this\npaper approaches for segmenting such big Web ontologies as well as its\nusefulness. The segmentation method extracts from an existing ontology a\nsegment that represents a layer or a generation in the existing ontology; i.e.\na horizontally extraction. The extracted segment should be itself an ontology.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 09:20:34 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Gherabi", "Noreddine", ""], ["Nejjahi", "Redouane", ""], ["Marzouk", "Abderrahim", ""]]}, {"id": "1709.08034", "submitter": "Beishui Liao", "authors": "Beishui Liao, Nir Oren, Leendert van der Torre and Serena Villata", "title": "Prioritized Norms in Formal Argumentation", "comments": "Accepted by the Journal of Logic and Computation on November 2nd,\n  2017", "journal-ref": null, "doi": "10.1093/logcom/exy009", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To resolve conflicts among norms, various nonmonotonic formalisms can be used\nto perform prioritized normative reasoning. Meanwhile, formal argumentation\nprovides a way to represent nonmonotonic logics. In this paper, we propose a\nrepresentation of prioritized normative reasoning by argumentation. Using\nhierarchical abstract normative systems, we define three kinds of prioritized\nnormative reasoning approaches, called Greedy, Reduction, and Optimization.\nThen, after formulating an argumentation theory for a hierarchical abstract\nnormative system, we show that for a totally ordered hierarchical abstract\nnormative system, Greedy and Reduction can be represented in argumentation by\napplying the weakest link and the last link principles respectively, and\nOptimization can be represented by introducing additional defeats capturing the\nidea that for each argument that contains a norm not belonging to the maximal\nobeyable set then this argument should be rejected.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 10:21:56 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 11:44:26 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Liao", "Beishui", ""], ["Oren", "Nir", ""], ["van der Torre", "Leendert", ""], ["Villata", "Serena", ""]]}, {"id": "1709.08071", "submitter": "Stefano Albrecht", "authors": "Stefano V. Albrecht, Peter Stone", "title": "Autonomous Agents Modelling Other Agents: A Comprehensive Survey and\n  Open Problems", "comments": "Final manuscript (46 pages), published in Artificial Intelligence\n  Journal. The arXiv version also contains a table of contents after the\n  abstract, but is otherwise identical to the AIJ version. Keywords: autonomous\n  agents, multiagent systems, modelling other agents, opponent modelling", "journal-ref": null, "doi": "10.1016/j.artint.2018.01.002", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much research in artificial intelligence is concerned with the development of\nautonomous agents that can interact effectively with other agents. An important\naspect of such agents is the ability to reason about the behaviours of other\nagents, by constructing models which make predictions about various properties\nof interest (such as actions, goals, beliefs) of the modelled agents. A variety\nof modelling approaches now exist which vary widely in their methodology and\nunderlying assumptions, catering to the needs of the different sub-communities\nwithin which they were developed and reflecting the different practical uses\nfor which they are intended. The purpose of the present article is to provide a\ncomprehensive survey of the salient modelling methods which can be found in the\nliterature. The article concludes with a discussion of open problems which may\nform the basis for fruitful future research.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 16:10:52 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 15:54:18 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Albrecht", "Stefano V.", ""], ["Stone", "Peter", ""]]}, {"id": "1709.08073", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "Petar Veli\\v{c}kovi\\'c, Laurynas Karazija, Nicholas D. Lane, Sourav\n  Bhattacharya, Edgar Liberis, Pietro Li\\`o, Angela Chieh, Otmane Bellahsen,\n  Matthieu Vegreville", "title": "Cross-modal Recurrent Models for Weight Objective Prediction from\n  Multimodal Time-series Data", "comments": "To appear in NIPS ML4H 2017 and NIPS TSW 2017", "journal-ref": null, "doi": "10.1145/3240925.3240937", "report-no": null, "categories": "stat.ML cs.AI cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse multimodal time-series data corresponding to weight, sleep and\nsteps measurements. We focus on predicting whether a user will successfully\nachieve his/her weight objective. For this, we design several deep long\nshort-term memory (LSTM) architectures, including a novel cross-modal LSTM\n(X-LSTM), and demonstrate their superiority over baseline approaches. The\nX-LSTM improves parameter efficiency by processing each modality separately and\nallowing for information flow between them by way of recurrent\ncross-connections. We present a general hyperparameter optimisation technique\nfor X-LSTMs, which allows us to significantly improve on the LSTM and a prior\nstate-of-the-art cross-modal approach, using a comparable number of parameters.\nFinally, we visualise the model's predictions, revealing implications about\nlatent variables in this task.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 16:42:34 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 07:45:28 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Veli\u010dkovi\u0107", "Petar", ""], ["Karazija", "Laurynas", ""], ["Lane", "Nicholas D.", ""], ["Bhattacharya", "Sourav", ""], ["Liberis", "Edgar", ""], ["Li\u00f2", "Pietro", ""], ["Chieh", "Angela", ""], ["Bellahsen", "Otmane", ""], ["Vegreville", "Matthieu", ""]]}, {"id": "1709.08126", "submitter": "Guido de Croon", "authors": "G.C.H.E. de Croon", "title": "Self-supervised learning: When is fusion of the primary and secondary\n  sensor cue useful?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning (SSL) is a reliable learning mechanism in which a\nrobot enhances its perceptual capabilities. Typically, in SSL a trusted,\nprimary sensor cue provides supervised training data to a secondary sensor cue.\nIn this article, a theoretical analysis is performed on the fusion of the\nprimary and secondary cue in a minimal model of SSL. A proof is provided that\ndetermines the specific conditions under which it is favorable to perform\nfusion. In short, it is favorable when (i) the prior on the target value is\nstrong or (ii) the secondary cue is sufficiently accurate. The theoretical\nfindings are validated with computational experiments. Subsequently, a\nreal-world case study is performed to investigate if fusion in SSL is also\nbeneficial when assumptions of the minimal model are not met. In particular, a\nflying robot learns to map pressure measurements to sonar height measurements\nand then fuses the two, resulting in better height estimation. Fusion is also\nbeneficial in the opposite case, when pressure is the primary cue. The analysis\nand results are encouraging to study SSL fusion also for other robots and\nsensors.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 23:21:26 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["de Croon", "G. C. H. E.", ""]]}, {"id": "1709.08163", "submitter": "David Tolpin", "authors": "David Tolpin", "title": "A Renewal Model of Intrusion", "comments": "12 pages including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic model of an intrusion in a renewal process. Given\na process and a sequence of events, an intrusion is a subsequence of events\nthat is not produced by the process. Applications of the model are, for\nexample, online payment fraud with the fraudster taking over a user's account\nand performing payments on the user's behalf, or unexpected equipment failures\ndue to unintended use.\n  We adopt Bayesian approach to infer the probability of an intrusion in a\nsequence of events, a MAP subsequence of events constituting the intrusion, and\nthe marginal probability of each event in a sequence to belong to the\nintrusion. We evaluate the model for intrusion detection on synthetic data and\non anonymized data from an online payment system.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 08:46:05 GMT"}, {"version": "v2", "created": "Mon, 23 Oct 2017 16:49:51 GMT"}, {"version": "v3", "created": "Fri, 13 Apr 2018 12:13:17 GMT"}, {"version": "v4", "created": "Tue, 17 Apr 2018 20:33:51 GMT"}, {"version": "v5", "created": "Mon, 28 May 2018 08:22:21 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Tolpin", "David", ""]]}, {"id": "1709.08201", "submitter": "Siyuan Li", "authors": "Siyuan Li and Chongjie Zhang", "title": "An Optimal Online Method of Selecting Source Policies for Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning significantly accelerates the reinforcement learning\nprocess by exploiting relevant knowledge from previous experiences. The problem\nof optimally selecting source policies during the learning process is of great\nimportance yet challenging. There has been little theoretical analysis of this\nproblem. In this paper, we develop an optimal online method to select source\npolicies for reinforcement learning. This method formulates online source\npolicy selection as a multi-armed bandit problem and augments Q-learning with\npolicy reuse. We provide theoretical guarantees of the optimal selection\nprocess and convergence to the optimal policy. In addition, we conduct\nexperiments on a grid-based robot navigation domain to demonstrate its\nefficiency and robustness by comparing to the state-of-the-art transfer\nlearning method.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 14:17:14 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Li", "Siyuan", ""], ["Zhang", "Chongjie", ""]]}, {"id": "1709.08233", "submitter": "Siyi Li", "authors": "Siyi Li, Tianbo Liu, Chi Zhang, Dit-Yan Yeung, Shaojie Shen", "title": "Learning Unmanned Aerial Vehicle Control for Autonomous Target Following", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep reinforcement learning (RL) methods have achieved unprecedented\nsuccesses in a range of challenging problems, their applicability has been\nmainly limited to simulation or game domains due to the high sample complexity\nof the trial-and-error learning process. However, real-world robotic\napplications often need a data-efficient learning process with safety-critical\nconstraints. In this paper, we consider the challenging problem of learning\nunmanned aerial vehicle (UAV) control for tracking a moving target. To acquire\na strategy that combines perception and control, we represent the policy by a\nconvolutional neural network. We develop a hierarchical approach that combines\na model-free policy gradient method with a conventional feedback\nproportional-integral-derivative (PID) controller to enable stable learning\nwithout catastrophic failure. The neural network is trained by a combination of\nsupervised learning from raw images and reinforcement learning from games of\nself-play. We show that the proposed approach can learn a target following\npolicy in a simulator efficiently and the learned behavior can be successfully\ntransferred to the DJI quadrotor platform for real-world UAV control.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 18:28:47 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Li", "Siyi", ""], ["Liu", "Tianbo", ""], ["Zhang", "Chi", ""], ["Yeung", "Dit-Yan", ""], ["Shen", "Shaojie", ""]]}, {"id": "1709.08267", "submitter": "Kamran Kowsari", "authors": "Kamran Kowsari, Donald E. Brown, Mojtaba Heidarysafa, Kiana Jafari\n  Meimandi, Matthew S. Gerber, Laura E. Barnes", "title": "HDLTex: Hierarchical Deep Learning for Text Classification", "comments": "ICMLA 2017", "journal-ref": null, "doi": "10.1109/ICMLA.2017.0-134", "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continually increasing number of documents produced each year\nnecessitates ever improving information processing methods for searching,\nretrieving, and organizing text. Central to these information processing\nmethods is document classification, which has become an important application\nfor supervised learning. Recently the performance of these traditional\nclassifiers has degraded as the number of documents has increased. This is\nbecause along with this growth in the number of documents has come an increase\nin the number of categories. This paper approaches this problem differently\nfrom current document classification methods that view the problem as\nmulti-class classification. Instead we perform hierarchical classification\nusing an approach we call Hierarchical Deep Learning for Text classification\n(HDLTex). HDLTex employs stacks of deep learning architectures to provide\nspecialized understanding at each level of the document hierarchy.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 21:58:12 GMT"}, {"version": "v2", "created": "Fri, 6 Oct 2017 18:16:31 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Kowsari", "Kamran", ""], ["Brown", "Donald E.", ""], ["Heidarysafa", "Mojtaba", ""], ["Meimandi", "Kiana Jafari", ""], ["Gerber", "Matthew S.", ""], ["Barnes", "Laura E.", ""]]}, {"id": "1709.08292", "submitter": "Peter Henderson", "authors": "Florian Shkurti, Wei-Di Chang, Peter Henderson, Md Jahidul Islam, Juan\n  Camilo Gamboa Higuera, Jimmy Li, Travis Manderson, Anqi Xu, Gregory Dudek,\n  Junaed Sattar", "title": "Underwater Multi-Robot Convoying using Visual Tracking by Detection", "comments": "Accepted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a robust multi-robot convoying approach that relies on visual\ndetection of the leading agent, thus enabling target following in unstructured\n3-D environments. Our method is based on the idea of tracking-by-detection,\nwhich interleaves efficient model-based object detection with temporal\nfiltering of image-based bounding box estimation. This approach has the\nimportant advantage of mitigating tracking drift (i.e. drifting away from the\ntarget object), which is a common symptom of model-free trackers and is\ndetrimental to sustained convoying in practice. To illustrate our solution, we\ncollected extensive footage of an underwater robot in ocean settings, and\nhand-annotated its location in each frame. Based on this dataset, we present an\nempirical comparison of multiple tracker variants, including the use of several\nconvolutional neural networks, both with and without recurrent connections, as\nwell as frequency-based model-free trackers. We also demonstrate the\npracticality of this tracking-by-detection strategy in real-world scenarios by\nsuccessfully controlling a legged underwater robot in five degrees of freedom\nto follow another robot's independent motion.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 01:55:00 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Shkurti", "Florian", ""], ["Chang", "Wei-Di", ""], ["Henderson", "Peter", ""], ["Islam", "Md Jahidul", ""], ["Higuera", "Juan Camilo Gamboa", ""], ["Li", "Jimmy", ""], ["Manderson", "Travis", ""], ["Xu", "Anqi", ""], ["Dudek", "Gregory", ""], ["Sattar", "Junaed", ""]]}, {"id": "1709.08366", "submitter": "Anush Sankaran", "authors": "Vitobha Munigala, Srikanth Tamilselvam, Anush Sankaran", "title": "\"Let me convince you to buy my product ... \": A Case Study of an\n  Automated Persuasive System for Fashion Products", "comments": "ML4Creativity workshop at SIGKDD 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persuasivenes is a creative art aimed at making people believe in certain set\nof beliefs. Many a times, such creativity is about adapting richness of one\ndomain into another to strike a chord with the target audience. In this\nresearch, we present PersuAIDE! - A persuasive system based on linguistic\ncreativity to transform given sentence to generate various forms of persuading\nsentences. These various forms cover multiple focus of persuasion such as\nmemorability and sentiment. For a given simple product line, the algorithm is\ncomposed of several steps including: (i) select an appropriate well-known\nexpression for the target domain to add memorability, (ii) identify keywords\nand entities in the given sentence and expression and transform it to produce\ncreative persuading sentence, and (iii) adding positive or negative sentiment\nfor further persuasion. The persuasive conversion were manually verified using\nqualitative results and the effectiveness of the proposed approach is\nempirically discussed.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 08:28:23 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Munigala", "Vitobha", ""], ["Tamilselvam", "Srikanth", ""], ["Sankaran", "Anush", ""]]}, {"id": "1709.08385", "submitter": "Xavier Bellekens", "authors": "Gregory D. Hill and Xavier J. A. Bellekens", "title": "Deep Learning Based Cryptographic Primitive Classification", "comments": "9 Pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cryptovirological augmentations present an immediate, incomparable threat.\nOver the last decade, the substantial proliferation of crypto-ransomware has\nhad widespread consequences for consumers and organisations alike. Established\npreventive measures perform well, however, the problem has not ceased. Reverse\nengineering potentially malicious software is a cumbersome task due to platform\neccentricities and obfuscated transmutation mechanisms, hence requiring\nsmarter, more efficient detection strategies. The following manuscript presents\na novel approach for the classification of cryptographic primitives in compiled\nbinary executables using deep learning. The model blueprint, a DCNN, is\nfittingly configured to learn from variable-length control flow diagnostics\noutput from a dynamic trace. To rival the size and variability of contemporary\ndata compendiums, hence feeding the model cognition, a methodology for the\nprocedural generation of synthetic cryptographic binaries is defined, utilising\ncore primitives from OpenSSL with multivariate obfuscation, to draw a vastly\nscalable distribution. The library, CryptoKnight, rendered an algorithmic pool\nof AES, RC4, Blowfish, MD5 and RSA to synthesis combinable variants which are\nautomatically fed in its core model. Converging at 91% accuracy, CryptoKnight\nis successfully able to classify the sample algorithms with minimal loss.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 09:07:30 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Hill", "Gregory D.", ""], ["Bellekens", "Xavier J. A.", ""]]}, {"id": "1709.08426", "submitter": "Ji Xu", "authors": "Ji Xu and Guoyin Wang", "title": "Non-iterative Label Propagation in Optimal Leading Forest", "comments": "Claim the itelligence property by first uploading it to the preprint\n  platform. After carefullu revision of this initial draft, we would like to\n  submit it to a conference or journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph based semi-supervised learning (GSSL) has intuitive representation and\ncan be improved by exploiting the matrix calculation. However, it has to\nperform iterative optimization to achieve a preset objective, which usually\nleads to low efficiency. Another inconvenience lying in GSSL is that when new\ndata come, the graph construction and the optimization have to be conducted all\nover again. We propose a sound assumption, arguing that: the neighboring data\npoints are not in peer-to-peer relation, but in a partial-ordered relation\ninduced by the local density and distance between the data; and the label of a\ncenter can be regarded as the contribution of its followers. Starting from the\nassumption, we develop a highly efficient non-iterative label propagation\nalgorithm based on a novel data structure named as optimal leading forest\n(LaPOLeaF). The major weaknesses of the traditional GSSL are addressed by this\nstudy. We further scale LaPOLeaF to accommodate big data by utilizing block\ndistance matrix technique, parallel computing, and Locality-Sensitive Hashing\n(LSH). Experiments on large datasets have shown the promising results of the\nproposed methods.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 11:25:36 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 09:50:32 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Xu", "Ji", ""], ["Wang", "Guoyin", ""]]}, {"id": "1709.08430", "submitter": "Giuseppe Paolo Mr", "authors": "Giuseppe Paolo, Lei Tai and Ming Liu", "title": "Towards continuous control of flippers for a multi-terrain robot using\n  deep reinforcement learning", "comments": "12 pages, single column, submitted to International Journal of\n  Robotics and Automation (IJRA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on developing a control algorithm for multi-terrain\ntracked robots with flippers using a reinforcement learning (RL) approach. The\nwork is based on the deep deterministic policy gradient (DDPG) algorithm,\nproven to be very successful in simple simulation environments. The algorithm\nworks in an end-to-end fashion in order to control the continuous position of\nthe flippers. This end-to-end approach makes it easy to apply the controller to\na wide array of circumstances, but the huge flexibility comes to the cost of an\nincreased difficulty of solution. The complexity of the task is enlarged even\nmore by the fact that real multi-terrain robots move in partially observable\nenvironments. Notwithstanding these complications, being able to smoothly\ncontrol a multi-terrain robot can produce huge benefits in impaired people\ndaily lives or in search and rescue situations.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 11:29:34 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Paolo", "Giuseppe", ""], ["Tai", "Lei", ""], ["Liu", "Ming", ""]]}, {"id": "1709.08448", "submitter": "Kevin Alex Mathews", "authors": "Kevin Alex Mathews, P Sreenivasa Kumar", "title": "Extracting Ontological Knowledge from Textual Descriptions", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authoring of OWL-DL ontologies is intellectually challenging and to make this\nprocess simpler, many systems accept natural language text as input. A\ntext-based ontology authoring approach can be successful only when it is\ncombined with an effective method for extracting ontological axioms from text.\nExtracting axioms from unrestricted English input is a substantially\nchallenging task due to the richness of the language. Controlled natural\nlanguages (CNLs) have been proposed in this context and these tend to be highly\nrestrictive. In this paper, we propose a new CNL called TEDEI (TExtual\nDEscription Identifier) whose grammar is inspired by the different ways OWL-DL\nconstructs are expressed in English. We built a system that transforms TEDEI\nsentences into corresponding OWL-DL axioms. Now, ambiguity due to different\npossible lexicalizations of sentences and semantic ambiguity present in\nsentences are challenges in this context. We find that the best way to handle\nthese challenges is to construct axioms corresponding to alternative\nformalizations of the sentence so that the end-user can make an appropriate\nchoice. The output is compared against human-authored axioms and in substantial\nnumber of cases, human-authored axiom is indeed one of the alternatives given\nby the system. The proposed system substantially enhances the types of sentence\nstructures that can be used for ontology authoring.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 12:22:51 GMT"}, {"version": "v2", "created": "Tue, 26 Sep 2017 08:41:06 GMT"}, {"version": "v3", "created": "Thu, 28 Sep 2017 19:37:02 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Mathews", "Kevin Alex", ""], ["Kumar", "P Sreenivasa", ""]]}, {"id": "1709.08461", "submitter": "Vincent Branders", "authors": "Vincent Branders, Pierre Schaus and Pierre Dupont", "title": "Mining a Sub-Matrix of Maximal Sum", "comments": "12 pages, 1 figure, Presented at NFMCP 2017, The 6th International\n  Workshop on New Frontiers in Mining Complex Patterns, Skopje, Macedonia, Sep\n  22, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biclustering techniques have been widely used to identify homogeneous\nsubgroups within large data matrices, such as subsets of genes similarly\nexpressed across subsets of patients. Mining a max-sum sub-matrix is a related\nbut distinct problem for which one looks for a (non-necessarily contiguous)\nrectangular sub-matrix with a maximal sum of its entries. Le Van et al. (Ranked\nTiling, 2014) already illustrated its applicability to gene expression analysis\nand addressed it with a constraint programming (CP) approach combined with\nlarge neighborhood search (CP-LNS). In this work, we exhibit some key\nproperties of this NP-hard problem and define a bounding function such that\nlarger problems can be solved in reasonable time. Two different algorithms are\nproposed in order to exploit the highlighted characteristics of the problem: a\nCP approach with a global constraint (CPGC) and mixed integer linear\nprogramming (MILP). Practical experiments conducted both on synthetic and real\ngene expression data exhibit the characteristics of these approaches and their\nrelative benefits over the original CP-LNS method. Overall, the CPGC approach\ntends to be the fastest to produce a good solution. Yet, the MILP formulation\nis arguably the easiest to formulate and can also be competitive.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 12:54:17 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Branders", "Vincent", ""], ["Schaus", "Pierre", ""], ["Dupont", "Pierre", ""]]}, {"id": "1709.08471", "submitter": "Hans Kersting", "authors": "Emilia Magnani, Hans Kersting, Michael Schober, Philipp Hennig", "title": "Bayesian Filtering for ODEs with Bounded Derivatives", "comments": "14 pages, 9 figrues", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been increasing interest in probabilistic solvers for\nordinary differential equations (ODEs) that return full probability measures,\ninstead of point estimates, over the solution and can incorporate uncertainty\nover the ODE at hand, e.g. if the vector field or the initial value is only\napproximately known or evaluable. The ODE filter proposed in recent work models\nthe solution of the ODE by a Gauss-Markov process which serves as a prior in\nthe sense of Bayesian statistics. While previous work employed a Wiener process\nprior on the (possibly multiple times) differentiated solution of the ODE and\nestablished equivalence of the corresponding solver with classical numerical\nmethods, this paper raises the question whether other priors also yield\npractically useful solvers. To this end, we discuss a range of possible priors\nwhich enable fast filtering and propose a new prior--the Integrated Ornstein\nUhlenbeck Process (IOUP)--that complements the existing Integrated Wiener\nprocess (IWP) filter by encoding the property that a derivative in time of the\nsolution is bounded in the sense that it tends to drift back to zero. We\nprovide experiments comparing IWP and IOUP filters which support the belief\nthat IWP approximates better divergent ODE's solutions whereas IOUP is a better\nprior for trajectories with bounded derivatives.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 13:11:31 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Magnani", "Emilia", ""], ["Kersting", "Hans", ""], ["Schober", "Michael", ""], ["Hennig", "Philipp", ""]]}, {"id": "1709.08519", "submitter": "Mikel Sanz", "authors": "F. A. C\\'ardenas-L\\'opez, M. Sanz, J. C. Retamal, E. Solano", "title": "Enhanced Quantum Synchronization via Quantum Machine Learning", "comments": null, "journal-ref": "Adv. Quantum Technol. 1800076 (2019)", "doi": "10.1002/qute.201800076", "report-no": null, "categories": "quant-ph cond-mat.mes-hall cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the quantum synchronization between a pair of two-level systems\ninside two coupled cavities. By using a digital-analog decomposition of the\nmaster equation that rules the system dynamics, we show that this approach\nleads to quantum synchronization between both two-level systems. Moreover, we\ncan identify in this digital-analog block decomposition the fundamental\nelements of a quantum machine learning protocol, in which the agent and the\nenvironment (learning units) interact through a mediating system, namely, the\nregister. If we can additionally equip this algorithm with a classical feedback\nmechanism, which consists of projective measurements in the register,\nreinitialization of the register state and local conditional operations on the\nagent and environment subspace, a powerful and flexible quantum machine\nlearning protocol emerges. Indeed, numerical simulations show that this\nprotocol enhances the synchronization process, even when every subsystem\nexperience different loss/decoherence mechanisms, and give us the flexibility\nto choose the synchronization state. Finally, we propose an implementation\nbased on current technologies in superconducting circuits.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 14:40:11 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 11:21:39 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["C\u00e1rdenas-L\u00f3pez", "F. A.", ""], ["Sanz", "M.", ""], ["Retamal", "J. C.", ""], ["Solano", "E.", ""]]}, {"id": "1709.08568", "submitter": "Yoshua Bengio", "authors": "Yoshua Bengio", "title": "The Consciousness Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new prior is proposed for learning representations of high-level concepts\nof the kind we manipulate with language. This prior can be combined with other\npriors in order to help disentangling abstract factors from each other. It is\ninspired by cognitive neuroscience theories of consciousness, seen as a\nbottleneck through which just a few elements, after having been selected by\nattention from a broader pool, are then broadcast and condition further\nprocessing, both in perception and decision-making. The set of recently\nselected elements one becomes aware of is seen as forming a low-dimensional\nconscious state. This conscious state is combining the few concepts\nconstituting a conscious thought, i.e., what one is immediately conscious of at\na particular moment. We claim that this architectural and\ninformation-processing constraint corresponds to assumptions about the joint\ndistribution between high-level concepts. To the extent that these assumptions\nare generally true (and the form of natural language seems consistent with\nthem), they can form a useful prior for representation learning. A\nlow-dimensional thought or conscious state is analogous to a sentence: it\ninvolves only a few variables and yet can make a statement with very high\nprobability of being true. This is consistent with a joint distribution (over\nhigh-level concepts) which has the form of a sparse factor graph, i.e., where\nthe dependencies captured by each factor of the factor graph involve only very\nfew variables while creating a strong dip in the overall energy function. The\nconsciousness prior also makes it natural to map conscious states to natural\nlanguage utterances or to express classical AI knowledge in a form similar to\nfacts and rules, albeit capturing uncertainty as well as efficient search\nmechanisms implemented by attention mechanisms.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 15:59:11 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 22:53:39 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Bengio", "Yoshua", ""]]}, {"id": "1709.08590", "submitter": "Ali Al-Taei", "authors": "Ali Al-Taei", "title": "Ensemble Classifier for Eye State Classification using EEG Signals", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing importance and utilization of measuring brain waves (e.g. EEG\nsignals of eye state) in brain-computer interface (BCI) applications\nhighlighted the need for suitable classification methods. In this paper, a\ncomparison between three of well-known classification methods (i.e. support\nvector machine (SVM), hidden Markov map (HMM), and radial basis function (RBF))\nfor EEG based eye state classification was achieved. Furthermore, a suggested\nmethod that is based on ensemble model was tested. The suggested (ensemble\nsystem) method based on a voting algorithm with two kernels: random forest (RF)\nand Kstar classification methods. The performance was tested using three\nmeasurement parameters: accuracy, mean absolute error (MAE), and confusion\nmatrix. Results showed that the proposed method outperforms the other tested\nmethods. For instance, the suggested method's performance was 97.27% accuracy\nand 0.13 MAE.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 16:44:39 GMT"}, {"version": "v2", "created": "Tue, 26 Sep 2017 03:19:37 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Al-Taei", "Ali", ""]]}, {"id": "1709.08607", "submitter": "Maxim Borisyak", "authors": "Maxim Borisyak, Fedor Ratnikov, Denis Derkach and Andrey Ustyuzhanin", "title": "Towards automation of data quality system for CERN CMS experiment", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/898/9/092041", "report-no": null, "categories": "physics.data-an cs.AI cs.LG hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Daily operation of a large-scale experiment is a challenging task,\nparticularly from perspectives of routine monitoring of quality for data being\ntaken. We describe an approach that uses Machine Learning for the automated\nsystem to monitor data quality, which is based on partial use of data qualified\nmanually by detector experts. The system automatically classifies marginal\ncases: both of good an bad data, and use human expert decision to classify\nremaining \"grey area\" cases.\n  This study uses collision data collected by the CMS experiment at LHC in\n2010. We demonstrate that proposed workflow is able to automatically process at\nleast 20\\% of samples without noticeable degradation of the result.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 17:24:15 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Borisyak", "Maxim", ""], ["Ratnikov", "Fedor", ""], ["Derkach", "Denis", ""], ["Ustyuzhanin", "Andrey", ""]]}, {"id": "1709.08624", "submitter": "Weinan Zhang", "authors": "Jiaxian Guo, Sidi Lu, Han Cai, Weinan Zhang, Yong Yu, Jun Wang", "title": "Long Text Generation via Adversarial Training with Leaked Information", "comments": "14 pages, AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatically generating coherent and semantically meaningful text has many\napplications in machine translation, dialogue systems, image captioning, etc.\nRecently, by combining with policy gradient, Generative Adversarial Nets (GAN)\nthat use a discriminative model to guide the training of the generative model\nas a reinforcement learning policy has shown promising results in text\ngeneration. However, the scalar guiding signal is only available after the\nentire text has been generated and lacks intermediate information about text\nstructure during the generative process. As such, it limits its success when\nthe length of the generated text samples is long (more than 20 words). In this\npaper, we propose a new framework, called LeakGAN, to address the problem for\nlong text generation. We allow the discriminative net to leak its own\nhigh-level extracted features to the generative net to further help the\nguidance. The generator incorporates such informative signals into all\ngeneration steps through an additional Manager module, which takes the\nextracted features of current generated words and outputs a latent vector to\nguide the Worker module for next-word generation. Our extensive experiments on\nsynthetic data and various real-world tasks with Turing test demonstrate that\nLeakGAN is highly effective in long text generation and also improves the\nperformance in short text generation scenarios. More importantly, without any\nsupervision, LeakGAN would be able to implicitly learn sentence structures only\nthrough the interaction between Manager and Worker.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 13:35:08 GMT"}, {"version": "v2", "created": "Fri, 8 Dec 2017 18:53:52 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Guo", "Jiaxian", ""], ["Lu", "Sidi", ""], ["Cai", "Han", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""], ["Wang", "Jun", ""]]}, {"id": "1709.08669", "submitter": "Konstantina Christakopoulou", "authors": "Konstantina Christakopoulou, Adam Tauman Kalai", "title": "Glass-Box Program Synthesis: A Machine Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently proposed models which learn to write computer programs from data use\neither input/output examples or rich execution traces. Instead, we argue that a\nnovel alternative is to use a glass-box loss function, given as a program\nitself that can be directly inspected. Glass-box optimization covers a wide\nrange of problems, from computing the greatest common divisor of two integers,\nto learning-to-learn problems.\n  In this paper, we present an intelligent search system which learns, given\nthe partial program and the glass-box problem, the probabilities over the space\nof programs. We empirically demonstrate that our informed search procedure\nleads to significant improvements compared to brute-force program search, both\nin terms of accuracy and time. For our experiments we use rich context free\ngrammars inspired by number theory, text processing, and algebra. Our results\nshow that (i) performing 4 rounds of our framework typically solves about 70%\nof the target problems, (ii) our framework can improve itself even in domain\nagnostic scenarios, and (iii) it can solve problems that would be otherwise too\nslow to solve with brute-force search.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 18:43:56 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Christakopoulou", "Konstantina", ""], ["Kalai", "Adam Tauman", ""]]}, {"id": "1709.08693", "submitter": "Xiaojun Xu", "authors": "Xiaojun Xu, Xinyun Chen, Chang Liu, Anna Rohrbach, Trevor Darrell and\n  Dawn Song", "title": "Fooling Vision and Language Models Despite Localization and Attention\n  Mechanism", "comments": "CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks are known to succeed on classifiers, but it has been an\nopen question whether more complex vision systems are vulnerable. In this\npaper, we study adversarial examples for vision and language models, which\nincorporate natural language understanding and complex structures such as\nattention, localization, and modular architectures. In particular, we\ninvestigate attacks on a dense captioning model and on two visual question\nanswering (VQA) models. Our evaluation shows that we can generate adversarial\nexamples with a high success rate (i.e., > 90%) for these models. Our work\nsheds new light on understanding adversarial attacks on vision systems which\nhave a language component and shows that attention, bounding box localization,\nand compositional internal structures are vulnerable to adversarial attacks.\nThese observations will inform future work towards building effective defenses.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 19:32:49 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 01:56:16 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Xu", "Xiaojun", ""], ["Chen", "Xinyun", ""], ["Liu", "Chang", ""], ["Rohrbach", "Anna", ""], ["Darrell", "Trevor", ""], ["Song", "Dawn", ""]]}, {"id": "1709.08850", "submitter": "Emmanouil Antonios Platanios", "authors": "Emmanouil Antonios Platanios and Ashish Kapoor and Eric Horvitz", "title": "Active Learning amidst Logical Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured prediction is ubiquitous in applications of machine learning such\nas knowledge extraction and natural language processing. Structure often can be\nformulated in terms of logical constraints. We consider the question of how to\nperform efficient active learning in the presence of logical constraints among\nvariables inferred by different classifiers. We propose several methods and\nprovide theoretical results that demonstrate the inappropriateness of employing\nuncertainty guided sampling, a commonly used active learning method.\nFurthermore, experiments on ten different datasets demonstrate that the methods\nsignificantly outperform alternatives in practice. The results are of practical\nsignificance in situations where labeled data is scarce.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 06:13:49 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Platanios", "Emmanouil Antonios", ""], ["Kapoor", "Ashish", ""], ["Horvitz", "Eric", ""]]}, {"id": "1709.08853", "submitter": "Xianggen Liu", "authors": "Zhengdong Lu and Xianggen Liu and Haotian Cui and Yukun Yan and Daqi\n  Zheng", "title": "Object-oriented Neural Programming (OONP) for Document Understanding", "comments": "accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Object-oriented Neural Programming (OONP), a framework for\nsemantically parsing documents in specific domains. Basically, OONP reads a\ndocument and parses it into a predesigned object-oriented data structure\n(referred to as ontology in this paper) that reflects the domain-specific\nsemantics of the document. An OONP parser models semantic parsing as a decision\nprocess: a neural net-based Reader sequentially goes through the document, and\nduring the process it builds and updates an intermediate ontology to summarize\nits partial understanding of the text it covers. OONP supports a rich family of\noperations (both symbolic and differentiable) for composing the ontology, and a\nbig variety of forms (both symbolic and differentiable) for representing the\nstate and the document. An OONP parser can be trained with supervision of\ndifferent forms and strength, including supervised learning (SL) ,\nreinforcement learning (RL) and hybrid of the two. Our experiments on both\nsynthetic and real-world document parsing tasks have shown that OONP can learn\nto handle fairly complicated ontology with training data of modest sizes.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 06:17:35 GMT"}, {"version": "v2", "created": "Thu, 28 Sep 2017 06:56:18 GMT"}, {"version": "v3", "created": "Tue, 3 Oct 2017 15:07:54 GMT"}, {"version": "v4", "created": "Sun, 8 Oct 2017 07:36:03 GMT"}, {"version": "v5", "created": "Thu, 19 Jul 2018 11:21:07 GMT"}, {"version": "v6", "created": "Wed, 25 Jul 2018 08:56:09 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Lu", "Zhengdong", ""], ["Liu", "Xianggen", ""], ["Cui", "Haotian", ""], ["Yan", "Yukun", ""], ["Zheng", "Daqi", ""]]}, {"id": "1709.08878", "submitter": "Kelvin Guu", "authors": "Kelvin Guu, Tatsunori B. Hashimoto, Yonatan Oren, Percy Liang", "title": "Generating Sentences by Editing Prototypes", "comments": "14 pages, Transactions of the Association for Computational\n  Linguistics (TACL), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new generative model of sentences that first samples a prototype\nsentence from the training corpus and then edits it into a new sentence.\nCompared to traditional models that generate from scratch either left-to-right\nor by first sampling a latent sentence vector, our prototype-then-edit model\nimproves perplexity on language modeling and generates higher quality outputs\naccording to human evaluation. Furthermore, the model gives rise to a latent\nedit vector that captures interpretable semantics such as sentence similarity\nand sentence-level analogies.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 08:11:33 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 04:57:15 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Guu", "Kelvin", ""], ["Hashimoto", "Tatsunori B.", ""], ["Oren", "Yonatan", ""], ["Liang", "Percy", ""]]}, {"id": "1709.08880", "submitter": "Noreddine Gherabi", "authors": "Noreddine Gherabi, Abdelhadi Daoui, and Abderrahim Marzouk", "title": "An enhanced method to compute the similarity between concepts of\n  ontology", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-64719-7", "report-no": null, "categories": "cs.DB cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the use of ontologies in several domains such as semantic web,\ninformation retrieval, artificial intelligence, the concept of similarity\nmeasuring has become a very important domain of research. Therefore, in the\ncurrent paper, we propose our method of similarity measuring which uses the\nDijkstra algorithm to define and compute the shortest path. Then, we use this\none to compute the semantic distance between two concepts defined in the same\nhierarchy of ontology. Afterward, we base on this result to compute the\nsemantic similarity. Finally, we present an experimental comparison between our\nmethod and other methods of similarity measuring.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 08:18:15 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Gherabi", "Noreddine", ""], ["Daoui", "Abdelhadi", ""], ["Marzouk", "Abderrahim", ""]]}, {"id": "1709.08982", "submitter": "Aisha Blfgeh", "authors": "Aisha Blfgeh and Phillip Lord", "title": "User and Developer Interaction with Editable and Readable Ontologies", "comments": "5 pages, 5 figures, accepted at ICBO 2017, License updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The process of building ontologies is a difficult task that involves\ncollaboration between ontology developers and domain experts and requires an\nongoing interaction between them. This collaboration is made more difficult,\nbecause they tend to use different tool sets, which can hamper this\ninteraction. In this paper, we propose to decrease this distance between domain\nexperts and ontology developers by creating more readable forms of ontologies,\nand further to enable editing in normal office environments. Building on a\nprogrammatic ontology development environment, such as Tawny-OWL, we are now\nable to generate these readable/editable from the raw ontological source and\nits embedded comments. We have this translation to HTML for reading; this\nenvironment provides rich hyperlinking as well as active features such as\nhiding the source code in favour of comments. We are now working on translation\nto a Word document that also enables editing. Taken together this should\nprovide a significant new route for collaboration between the ontologist and\ndomain specialist.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 12:48:33 GMT"}, {"version": "v2", "created": "Thu, 28 Sep 2017 14:13:47 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Blfgeh", "Aisha", ""], ["Lord", "Phillip", ""]]}, {"id": "1709.08992", "submitter": "Nicolas Bredeche", "authors": "Nicolas Bredeche, Evert Haasdijk, Abraham Prieto", "title": "Embodied Evolution in Collective Robotics: A Review", "comments": "23 pages, 1 figure, 1 table", "journal-ref": "(2018) Embodied Evolution in Collective Robotics: A Review. Front.\n  Robot. AI 5:12", "doi": "10.3389/frobt.2018.00012", "report-no": null, "categories": "cs.NE cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an overview of evolutionary robotics techniques applied\nto on-line distributed evolution for robot collectives -- namely, embodied\nevolution. It provides a definition of embodied evolution as well as a thorough\ndescription of the underlying concepts and mechanisms. The paper also presents\na comprehensive summary of research published in the field since its inception\n(1999-2017), providing various perspectives to identify the major trends. In\nparticular, we identify a shift from considering embodied evolution as a\nparallel search method within small robot collectives (fewer than 10 robots) to\nembodied evolution as an on-line distributed learning method for designing\ncollective behaviours in swarm-like collectives. The paper concludes with a\ndiscussion of applications and open questions, providing a milestone for past\nand an inspiration for future research.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 13:08:27 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 14:56:37 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Bredeche", "Nicolas", ""], ["Haasdijk", "Evert", ""], ["Prieto", "Abraham", ""]]}, {"id": "1709.09051", "submitter": "Ikhlef Bechar", "authors": "Ikhlef Bechar", "title": "Exact MAP inference in general higher-order graphical models using\n  linear programming", "comments": "50 pages, detailed proofs, self-contained paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the problem of exact MAP inference in general\nhigher-order graphical models by means of a traditional linear programming\nrelaxation approach. In fact, the proof that we have developed in this paper is\na rather simple algebraic proof being made straightforward, above all, by the\nintroduction of two novel algebraic tools. Indeed, on the one hand, we\nintroduce the notion of delta-distribution which merely stands for the\ndifference of two arbitrary probability distributions, and which mainly serves\nto alleviate the sign constraint inherent to a traditional probability\ndistribution. On the other hand, we develop an approximation framework of\ngeneral discrete functions by means of an orthogonal projection expressing in\nterms of linear combinations of function margins with respect to a given\ncollection of point subsets, though, we rather exploit the latter approach for\nthe purpose of modeling locally consistent sets of discrete functions from a\nglobal perspective. After that, as a first step, we develop from scratch the\nexpectation optimization framework which is nothing else than a reformulation,\non stochastic grounds, of the convex-hull approach, as a second step, we\ndevelop the traditional LP relaxation of such an expectation optimization\napproach, and we show that it enables to solve the MAP inference problem in\ngraphical models under rather general assumptions. Last but not least, we\ndescribe an algorithm which allows to compute an exact MAP solution from a\nperhaps fractional optimal (probability) solution of the proposed LP\nrelaxation.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 15:13:38 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Bechar", "Ikhlef", ""]]}, {"id": "1709.09093", "submitter": "R.Stuart Geiger", "authors": "R. Stuart Geiger", "title": "Beyond opening up the black box: Investigating the role of algorithmic\n  systems in Wikipedian organizational culture", "comments": "14 pages, typo fixed in v2", "journal-ref": "Big Data & Society 4(2). 2017", "doi": "10.1177/2053951717730735", "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scholars and practitioners across domains are increasingly concerned with\nalgorithmic transparency and opacity, interrogating the values and assumptions\nembedded in automated, black-boxed systems, particularly in user-generated\ncontent platforms. I report from an ethnography of infrastructure in Wikipedia\nto discuss an often understudied aspect of this topic: the local, contextual,\nlearned expertise involved in participating in a highly automated\nsocial-technical environment. Today, the organizational culture of Wikipedia is\ndeeply intertwined with various data-driven algorithmic systems, which\nWikipedians rely on to help manage and govern the \"anyone can edit\"\nencyclopedia at a massive scale. These bots, scripts, tools, plugins, and\ndashboards make Wikipedia more efficient for those who know how to work with\nthem, but like all organizational culture, newcomers must learn them if they\nwant to fully participate. I illustrate how cultural and organizational\nexpertise is enacted around algorithmic agents by discussing two\nautoethnographic vignettes, which relate my personal experience as a veteran in\nWikipedia. I present thick descriptions of how governance and gatekeeping\npractices are articulated through and in alignment with these automated\ninfrastructures. Over the past 15 years, Wikipedian veterans and administrators\nhave made specific decisions to support administrative and editorial workflows\nwith automation in particular ways and not others. I use these cases of\nWikipedia's bot-supported bureaucracy to discuss several issues in the fields\nof critical algorithms studies, critical data studies, and fairness,\naccountability, and transparency in machine learning -- most principally\narguing that scholarship and practice must go beyond trying to \"open up the\nblack box\" of such systems and also examine sociocultural processes like\nnewcomer socialization.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 15:38:26 GMT"}, {"version": "v2", "created": "Sun, 1 Oct 2017 15:24:56 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Geiger", "R. Stuart", ""]]}, {"id": "1709.09108", "submitter": "Lenore Mullin", "authors": "John L. Gustafson and Lenore M. Mullin", "title": "Tensors Come of Age: Why the AI Revolution will help HPC", "comments": "To be published in this years 30th anniversary edition of HPCwire", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article discusses how the automation of tensor algorithms, based on A\nMathematics of Arrays and Psi Calculus, and a new way to represent numbers,\nUnum Arithmetic, enables mechanically provable, scalable, portable, and more\nnumerically accurate software.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 16:11:43 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Gustafson", "John L.", ""], ["Mullin", "Lenore M.", ""]]}, {"id": "1709.09131", "submitter": "Felix H\\\"ulsmann", "authors": "Felix H\\\"ulsmann, Stefan Kopp, Mario Botsch", "title": "Automatic Error Analysis of Human Motor Performance for Interactive\n  Coaching in Virtual Reality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of fitness coaching or for rehabilitation purposes, the motor\nactions of a human participant must be observed and analyzed for errors in\norder to provide effective feedback. This task is normally carried out by human\ncoaches, and it needs to be solved automatically in technical applications that\nare to provide automatic coaching (e.g. training environments in VR). However,\nmost coaching systems only provide coarse information on movement quality, such\nas a scalar value per body part that describes the overall deviation from the\ncorrect movement. Further, they are often limited to static body postures or\nrather simple movements of single body parts. While there are many approaches\nto distinguish between different types of movements (e.g., between walking and\njumping), the detection of more subtle errors in a motor performance is less\ninvestigated. We propose a novel approach to classify errors in sports or\nrehabilitation exercises such that feedback can be delivered in a rapid and\ndetailed manner: Homogeneous sub-sequences of exercises are first temporally\naligned via Dynamic Time Warping. Next, we extract a feature vector from the\naligned sequences, which serves as a basis for feature selection using Random\nForests. The selected features are used as input for Support Vector Machines,\nwhich finally classify the movement errors. We compare our algorithm to a well\nestablished state-of-the-art approach in time series classification, 1-Nearest\nNeighbor combined with Dynamic Time Warping, and show our algorithm's\nsuperiority regarding classification quality as well as computational cost.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 17:01:32 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["H\u00fclsmann", "Felix", ""], ["Kopp", "Stefan", ""], ["Botsch", "Mario", ""]]}, {"id": "1709.09233", "submitter": "Dan Nguyen", "authors": "Dan Nguyen, Troy Long, Xun Jia, Weiguo Lu, Xuejun Gu, Zohaib Iqbal,\n  Steve Jiang", "title": "A feasibility study for predicting optimal radiation therapy dose\n  distributions of prostate cancer patients from patient anatomy using deep\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement of treatment modalities in radiation therapy for cancer\npatients, outcomes have improved, but at the cost of increased treatment plan\ncomplexity and planning time. The accurate prediction of dose distributions\nwould alleviate this issue by guiding clinical plan optimization to save time\nand maintain high quality plans. We have modified a convolutional deep network\nmodel, U-net (originally designed for segmentation purposes), for predicting\ndose from patient image contours of the planning target volume (PTV) and organs\nat risk (OAR). We show that, as an example, we are able to accurately predict\nthe dose of intensity-modulated radiation therapy (IMRT) for prostate cancer\npatients, where the average Dice similarity coefficient is 0.91 when comparing\nthe predicted vs. true isodose volumes between 0% and 100% of the prescription\ndose. The average value of the absolute differences in [max, mean] dose is\nfound to be under 5% of the prescription dose, specifically for each structure\nis [1.80%, 1.03%](PTV), [1.94%, 4.22%](Bladder), [1.80%, 0.48%](Body), [3.87%,\n1.79%](L Femoral Head), [5.07%, 2.55%](R Femoral Head), and [1.26%,\n1.62%](Rectum) of the prescription dose. We thus managed to map a desired\nradiation dose distribution from a patient's PTV and OAR contours. As an\nadditional advantage, relatively little data was used in the techniques and\nmodels described in this paper.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 19:43:29 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2018 06:26:06 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 23:45:25 GMT"}, {"version": "v4", "created": "Thu, 29 Nov 2018 21:34:27 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Nguyen", "Dan", ""], ["Long", "Troy", ""], ["Jia", "Xun", ""], ["Lu", "Weiguo", ""], ["Gu", "Xuejun", ""], ["Iqbal", "Zohaib", ""], ["Jiang", "Steve", ""]]}, {"id": "1709.09250", "submitter": "Omar Al-Harbi Mohammad", "authors": "Omar Al-Harbi, Shaidah Jusoh, Norita Md Norwawi", "title": "Lexical Disambiguation in Natural Language Questions (NLQs)", "comments": "8 pages, 4 figures", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 8,\n  Issue 4, No 2, July 2011 (143-150)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question processing is a fundamental step in a question answering (QA)\napplication, and its quality impacts the performance of QA application. The\nmajor challenging issue in processing question is how to extract semantic of\nnatural language questions (NLQs). A human language is ambiguous. Ambiguity may\noccur at two levels; lexical and syntactic. In this paper, we propose a new\napproach for resolving lexical ambiguity problem by integrating context\nknowledge and concepts knowledge of a domain, into shallow natural language\nprocessing (SNLP) techniques. Concepts knowledge is modeled using ontology,\nwhile context knowledge is obtained from WordNet, and it is determined based on\nneighborhood words in a question. The approach will be applied to a university\nQA system.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 20:24:10 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Al-Harbi", "Omar", ""], ["Jusoh", "Shaidah", ""], ["Norwawi", "Norita Md", ""]]}, {"id": "1709.09268", "submitter": "Kamran Kowsari", "authors": "Kamran Kowsari, Nima Bari, Roman Vichr, Farhad A. Goodarzi", "title": "FSL-BM: Fuzzy Supervised Learning with Binary Meta-Feature for\n  Classification", "comments": "FICC2018", "journal-ref": null, "doi": "10.1007/978-3-030-03405-4_46", "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel real-time Fuzzy Supervised Learning with Binary\nMeta-Feature (FSL-BM) for big data classification task. The study of real-time\nalgorithms addresses several major concerns, which are namely: accuracy, memory\nconsumption, and ability to stretch assumptions and time complexity. Attaining\na fast computational model providing fuzzy logic and supervised learning is one\nof the main challenges in the machine learning. In this research paper, we\npresent FSL-BM algorithm as an efficient solution of supervised learning with\nfuzzy logic processing using binary meta-feature representation using Hamming\nDistance and Hash function to relax assumptions. While many studies focused on\nreducing time complexity and increasing accuracy during the last decade, the\nnovel contribution of this proposed solution comes through integration of\nHamming Distance, Hash function, binary meta-features, binary classification to\nprovide real time supervised method. Hash Tables (HT) component gives a fast\naccess to existing indices; and therefore, the generation of new indices in a\nconstant time complexity, which supersedes existing fuzzy supervised algorithms\nwith better or comparable results. To summarize, the main contribution of this\ntechnique for real-time Fuzzy Supervised Learning is to represent hypothesis\nthrough binary input as meta-feature space and creating the Fuzzy Supervised\nHash table to train and validate model.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 21:52:41 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 23:34:10 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Kowsari", "Kamran", ""], ["Bari", "Nima", ""], ["Vichr", "Roman", ""], ["Goodarzi", "Farhad A.", ""]]}, {"id": "1709.09312", "submitter": "Einar Cesar Santos", "authors": "Einar Cesar Santos", "title": "A Simple Reinforcement Learning Mechanism for Resource Allocation in\n  LTE-A Networks with Markov Decision Process and Q-Learning", "comments": "6 pages, 11 figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource allocation is still a difficult issue to deal with in wireless\nnetworks. The unstable channel condition and traffic demand for Quality of\nService (QoS) raise some barriers that interfere with the process. It is\nsignificant that an optimal policy takes into account some resources available\nto each traffic class while considering the spectral efficiency and other\nrelated channel issues. Reinforcement learning is a dynamic and effective\nmethod to support the accomplishment of resource allocation properly\nmaintaining QoS levels for applications. The technique can track the system\nstate as feedback to enhance the performance of a given task. Herein, it is\nproposed a simple reinforcement learning mechanism introduced in LTE-A networks\nand aimed to choose and limit the number of resources allocated for each\ntraffic class, regarding the QoS Class Identifier (QCI), at each Transmission\nTime Interval (TTI) along the scheduling procedure. The proposed mechanism\nimplements a Markov Decision Process (MDP) solved by the Q-Learning algorithm\nto find an optimal action-state decision policy. The results obtained from\nsimulation exhibit good performance, especially for the real-time Video\napplication.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 02:42:29 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Santos", "Einar Cesar", ""]]}, {"id": "1709.09364", "submitter": "Chengwei Huang", "authors": "Chengwei Huang", "title": "Research on several key technologies in practical speech emotion\n  recognition", "comments": "in Chinese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this dissertation the practical speech emotion recognition technology is\nstudied, including several cognitive related emotion types, namely fidgetiness,\nconfidence and tiredness. The high quality of naturalistic emotional speech\ndata is the basis of this research. The following techniques are used for\ninducing practical emotional speech: cognitive task, computer game, noise\nstimulation, sleep deprivation and movie clips.\n  A practical speech emotion recognition system is studied based on Gaussian\nmixture model. A two-class classifier set is adopted for performance\nimprovement under the small sample case. Considering the context information in\ncontinuous emotional speech, a Gaussian mixture model embedded with Markov\nnetworks is proposed.\n  A further study is carried out for system robustness analysis. First, noise\nreduction algorithm based on auditory masking properties is fist introduced to\nthe practical speech emotion recognition. Second, to deal with the complicated\nunknown emotion types under real situation, an emotion recognition method with\nrejection ability is proposed, which enhanced the system compatibility against\nunknown emotion samples. Third, coping with the difficulties brought by a large\nnumber of unknown speakers, an emotional feature normalization method based on\nspeaker-sensitive feature clustering is proposed. Fourth, by adding the\nelectrocardiogram channel, a bi-modal emotion recognition system based on\nspeech signals and electrocardiogram signals is first introduced.\n  The speech emotion recognition methods studied in this dissertation may be\nextended into the cross-language speech emotion recognition and the whispered\nspeech emotion recognition.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 07:21:26 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Huang", "Chengwei", ""]]}, {"id": "1709.09433", "submitter": "Fulvio Mastrogiovanni", "authors": "Luca Buoncompagni, Fulvio Mastrogiovanni, Alessandro Saffiotti", "title": "Scene learning, recognition and similarity detection in a fuzzy ontology\n  via human examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a Fuzzy Logic framework for scene learning, recognition\nand similarity detection, where scenes are taught via human examples. The\nframework allows a robot to: (i) deal with the intrinsic vagueness associated\nwith determining spatial relations among objects; (ii) infer similarities and\ndissimilarities in a set of scenes, and represent them in a hierarchical\nstructure represented in a Fuzzy ontology. In this paper, we briefly formalize\nour approach and we provide a few use cases by way of illustration.\nNevertheless, we discuss how the framework can be used in real-world scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 10:19:38 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Buoncompagni", "Luca", ""], ["Mastrogiovanni", "Fulvio", ""], ["Saffiotti", "Alessandro", ""]]}, {"id": "1709.09450", "submitter": "Mohammad Halawani", "authors": "Mohammad K. Halawani, Rob Forsyth and Phillip Lord", "title": "A Literature Based Approach to Define the Scope of Biomedical\n  Ontologies: A Case Study on a Rehabilitation Therapy Ontology", "comments": "Accepted at the International Conference for Biomedical Ontologies\n  2017(ICBO 2017), 4 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article, we investigate our early attempts at building an ontology\ndescribing rehabilitation therapies following brain injury. These therapies are\nwide-ranging, involving interventions of many different kinds. As a result,\nthese therapies are hard to describe. As well as restricting actual practice,\nthis is also a major impediment to evidence-based medicine as it is hard to\nmeaningfully compare two treatment plans.\n  Ontology development requires significant effort from both ontologists and\ndomain experts. Knowledge elicited from domain experts forms the scope of the\nontology. The process of knowledge elicitation is expensive, consumes experts'\ntime and might have biases depending on the selection of the experts. Various\nmethodologies and techniques exist for enabling this knowledge elicitation,\nincluding community groups and open development practices. A related problem is\nthat of defining scope. By defining the scope, we can decide whether a concept\n(i.e. term) should be represented in the ontology. This is the opposite of\nknowledge elicitation, in the sense that it defines what should not be in the\nontology. This can be addressed by pre-defining a set of competency questions.\n  These approaches are, however, expensive and time-consuming. Here, we\ndescribe our work toward an alternative approach, bootstrapping the ontology\nfrom an initially small corpus of literature that will define the scope of the\nontology, expanding this to a set covering the domain, then using information\nextraction to define an initial terminology to provide the basis and the\ncompetencies for the ontology. Here, we discuss four approaches to building a\nsuitable corpus that is both sufficiently covering and precise.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 11:11:54 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Halawani", "Mohammad K.", ""], ["Forsyth", "Rob", ""], ["Lord", "Phillip", ""]]}, {"id": "1709.09480", "submitter": "Daniel Hein", "authors": "Daniel Hein, Stefan Depeweg, Michel Tokic, Steffen Udluft, Alexander\n  Hentschel, Thomas A. Runkler, Volkmar Sterzing", "title": "A Benchmark Environment Motivated by Industrial Control Problems", "comments": null, "journal-ref": "2017 IEEE Symposium Series on Computational Intelligence (SSCI)", "doi": "10.1109/SSCI.2017.8280935", "report-no": null, "categories": "cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the research area of reinforcement learning (RL), frequently novel and\npromising methods are developed and introduced to the RL community. However,\nalthough many researchers are keen to apply their methods on real-world\nproblems, implementing such methods in real industry environments often is a\nfrustrating and tedious process. Generally, academic research groups have only\nlimited access to real industrial data and applications. For this reason, new\nmethods are usually developed, evaluated and compared by using artificial\nsoftware benchmarks. On one hand, these benchmarks are designed to provide\ninterpretable RL training scenarios and detailed insight into the learning\nprocess of the method on hand. On the other hand, they usually do not share\nmuch similarity with industrial real-world applications. For this reason we\nused our industry experience to design a benchmark which bridges the gap\nbetween freely available, documented, and motivated artificial benchmarks and\nproperties of real industrial problems. The resulting industrial benchmark (IB)\nhas been made publicly available to the RL community by publishing its Java and\nPython code, including an OpenAI Gym wrapper, on Github. In this paper we\nmotivate and describe in detail the IB's dynamics and identify prototypic\nexperimental settings that capture common situations in real-world industry\ncontrol problems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 13:03:52 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 10:59:19 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Hein", "Daniel", ""], ["Depeweg", "Stefan", ""], ["Tokic", "Michel", ""], ["Udluft", "Steffen", ""], ["Hentschel", "Alexander", ""], ["Runkler", "Thomas A.", ""], ["Sterzing", "Volkmar", ""]]}, {"id": "1709.09527", "submitter": "Benjamin Donnot", "authors": "Benjamin Donnot (TAU, LRI), Isabelle Guyon (LRI, TAU), Marc Schoenauer\n  (TAU, LRI), Patrick Panciatici, Antoine Marot", "title": "Introducing machine learning for power system operation support", "comments": "IREP Symposium, Aug 2017, Espinho, Portugal. 2017,\n  \\&\\#x3008;http://irep2017.inesctec.pt/\\&\\#x3009", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of assisting human dispatchers in operating power\ngrids in today's changing context using machine learning, with theaim of\nincreasing security and reducing costs. Power networks are highly regulated\nsystems, which at all times must meet varying demands of electricity with a\ncomplex production system, including conventional power plants, less\npredictable renewable energies (such as wind or solar power), and the\npossibility of buying/selling electricity on the international market with more\nand more actors involved at a Europeanscale. This problem is becoming ever more\nchallenging in an aging network infrastructure. One of the primary goals of\ndispatchers is to protect equipment (e.g. avoid that transmission lines\noverheat) with few degrees of freedom: we are considering in this paper solely\nmodifications in network topology, i.e. re-configuring the way in which lines,\ntransformers, productions and loads are connected in sub-stations. Using years\nof historical data collected by the French Transmission Service Operator (TSO)\n\"R\\'eseau de Transport d'Electricit\\'e\" (RTE), we develop novel machine\nlearning techniques (drawing on \"deep learning\") to mimic human decisions to\ndevise \"remedial actions\" to prevent any line to violate power flow limits\n(so-called \"thermal limits\"). The proposed technique is hybrid. It does not\nrely purely on machine learning: every action will be tested with actual\nsimulators before being proposed to the dispatchers or implemented on the grid.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 13:59:35 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Donnot", "Benjamin", "", "TAU, LRI"], ["Guyon", "Isabelle", "", "LRI, TAU"], ["Schoenauer", "Marc", "", "TAU, LRI"], ["Panciatici", "Patrick", ""], ["Marot", "Antoine", ""]]}, {"id": "1709.09534", "submitter": "Lydia Manikonda", "authors": "Lydia Manikonda, Subbarao Kambhampati", "title": "Tweeting AI: Perceptions of Lay vs Expert Twitterati", "comments": "arXiv admin note: substantial text overlap with arXiv:1704.08389", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent advancements in Artificial Intelligence (AI), various\norganizations and individuals are debating about the progress of AI as a\nblessing or a curse for the future of the society. This paper conducts an\ninvestigation on how the public perceives the progress of AI by utilizing the\ndata shared on Twitter. Specifically, this paper performs a comparative\nanalysis on the understanding of users belonging to two categories -- general\nAI-Tweeters (AIT) and expert AI-Tweeters (EAIT) who share posts about AI on\nTwitter. Our analysis revealed that users from both the categories express\ndistinct emotions and interests towards AI. Users from both the categories\nregard AI as positive and are optimistic about the progress of AI but the\nexperts are more negative than the general AI-Tweeters. Expert AI-Tweeters\nshare relatively large percentage of tweets about their personal news compared\nto technical aspects of AI. However, the effects of automation on the future\nare of primary concern to AIT than to EAIT. When the expert category is\nsub-categorized, the emotion analysis revealed that students and industry\nprofessionals have more insights in their tweets about AI than academicians.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 19:14:21 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Manikonda", "Lydia", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1709.09569", "submitter": "Michael Albert", "authors": "Guni Sharon, Michael Albert, Tarun Rambha, Stephen Boyles, and Peter\n  Stone", "title": "Traffic Optimization For a Mixture of Self-interested and Compliant\n  Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on two commonly used path assignment policies for agents\ntraversing a congested network: self-interested routing, and system-optimum\nrouting. In the self-interested routing policy each agent selects a path that\noptimizes its own utility, while the system-optimum routing agents are assigned\npaths with the goal of maximizing system performance. This paper considers a\nscenario where a centralized network manager wishes to optimize utilities over\nall agents, i.e., implement a system-optimum routing policy. In many real-life\nscenarios, however, the system manager is unable to influence the route\nassignment of all agents due to limited influence on route choice decisions.\nMotivated by such scenarios, a computationally tractable method is presented\nthat computes the minimal amount of agents that the system manager needs to\ninfluence (compliant agents) in order to achieve system optimal performance.\nMoreover, this methodology can also determine whether a given set of compliant\nagents is sufficient to achieve system optimum and compute the optimal route\nassignment for the compliant agents to do so. Experimental results are\npresented showing that in several large-scale, realistic traffic networks\noptimal flow can be achieved with as low as 13% of the agent being compliant\nand up to 54%.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 15:03:48 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Sharon", "Guni", ""], ["Albert", "Michael", ""], ["Rambha", "Tarun", ""], ["Boyles", "Stephen", ""], ["Stone", "Peter", ""]]}, {"id": "1709.09585", "submitter": "Xingyi Cheng", "authors": "Xingyi Cheng, Ruiqing Zhang, Jie Zhou, Wei Xu", "title": "DeepTransport: Learning Spatial-Temporal Dependency for Traffic\n  Condition Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting traffic conditions has been recently explored as a way to relieve\ntraffic congestion. Several pioneering approaches have been proposed based on\ntraffic observations of the target location as well as its adjacent regions,\nbut they obtain somewhat limited accuracy due to lack of mining road topology.\nTo address the effect attenuation problem, we propose to take account of the\ntraffic of surrounding locations(wider than adjacent range). We propose an\nend-to-end framework called DeepTransport, in which Convolutional Neural\nNetworks (CNN) and Recurrent Neural Networks (RNN) are utilized to obtain\nspatial-temporal traffic information within a transport network topology. In\naddition, attention mechanism is introduced to align spatial and temporal\ninformation. Moreover, we constructed and released a real-world large traffic\ncondition dataset with 5-minute resolution. Our experiments on this dataset\ndemonstrate our method captures the complex relationship in temporal and\nspatial domain. It significantly outperforms traditional statistical methods\nand a state-of-the-art deep learning method.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 15:39:49 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 02:49:09 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Cheng", "Xingyi", ""], ["Zhang", "Ruiqing", ""], ["Zhou", "Jie", ""], ["Xu", "Wei", ""]]}, {"id": "1709.09586", "submitter": "Linyi Li", "authors": "Linyi Li, Matt Fredrikson, Shayak Sen, Anupam Datta", "title": "Case Study: Explaining Diabetic Retinopathy Detection Deep CNNs via\n  Integrated Gradients", "comments": "This report has been withdrawn as it needs co-authors' permission and\n  further verification of conclusions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we applied integrated gradients to explaining a neural\nnetwork for diabetic retinopathy detection. The integrated gradient is an\nattribution method which measures the contributions of input to the quantity of\ninterest. We explored some new ways for applying this method such as explaining\nintermediate layers, filtering out unimportant units by their attribution value\nand generating contrary samples. Moreover, the visualization results extend the\nuse of diabetic retinopathy detection model from merely predicting to assisting\nfinding potential lesions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 15:43:10 GMT"}, {"version": "v2", "created": "Wed, 11 Oct 2017 13:11:42 GMT"}, {"version": "v3", "created": "Wed, 18 Oct 2017 13:18:04 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Li", "Linyi", ""], ["Fredrikson", "Matt", ""], ["Sen", "Shayak", ""], ["Datta", "Anupam", ""]]}, {"id": "1709.09587", "submitter": "Tal Baumel", "authors": "Tal Baumel, Jumana Nassour-Kassis, Raphael Cohen, Michael Elhadad and\n  No`emie Elhadad", "title": "Multi-Label Classification of Patient Notes a Case Study on ICD Code\n  Assignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of the Electronic Health Record, automated diagnosis coding of\npatient notes is a useful task, but a challenging one due to the large number\nof codes and the length of patient notes. We investigate four models for\nassigning multiple ICD codes to discharge summaries taken from both MIMIC II\nand III. We present Hierarchical Attention-GRU (HA-GRU), a hierarchical\napproach to tag a document by identifying the sentences relevant for each\nlabel. HA-GRU achieves state-of-the art results. Furthermore, the learned\nsentence-level attention layer highlights the model decision process, allows\neasier error analysis, and suggests future directions for improvement.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 15:46:07 GMT"}, {"version": "v2", "created": "Fri, 29 Sep 2017 12:04:57 GMT"}, {"version": "v3", "created": "Mon, 20 Nov 2017 20:32:26 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Baumel", "Tal", ""], ["Nassour-Kassis", "Jumana", ""], ["Cohen", "Raphael", ""], ["Elhadad", "Michael", ""], ["Elhadad", "No`emie", ""]]}, {"id": "1709.09611", "submitter": "Xiao Li", "authors": "Xiao Li, Yao Ma and Calin Belta", "title": "A Policy Search Method For Temporal Logic Specified Reinforcement\n  Learning Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reward engineering is an important aspect of reinforcement learning. Whether\nor not the user's intentions can be correctly encapsulated in the reward\nfunction can significantly impact the learning outcome. Current methods rely on\nmanually crafted reward functions that often require parameter tuning to obtain\nthe desired behavior. This operation can be expensive when exploration requires\nsystems to interact with the physical world. In this paper, we explore the use\nof temporal logic (TL) to specify tasks in reinforcement learning. TL formula\ncan be translated to a real-valued function that measures its level of\nsatisfaction against a trajectory. We take advantage of this function and\npropose temporal logic policy search (TLPS), a model-free learning technique\nthat finds a policy that satisfies the TL specification. A set of simulated\nexperiments are conducted to evaluate the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 16:37:51 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Li", "Xiao", ""], ["Ma", "Yao", ""], ["Belta", "Calin", ""]]}, {"id": "1709.09735", "submitter": "Zackory Erickson", "authors": "Zackory Erickson, Henry M. Clever, Greg Turk, C. Karen Liu, and\n  Charles C. Kemp", "title": "Deep Haptic Model Predictive Control for Robot-Assisted Dressing", "comments": "8 pages, 12 figures, 1 table, 2018 IEEE International Conference on\n  Robotics and Automation (ICRA)", "journal-ref": null, "doi": "10.1109/ICRA.2018.8460656", "report-no": null, "categories": "cs.RO cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot-assisted dressing offers an opportunity to benefit the lives of many\npeople with disabilities, such as some older adults. However, robots currently\nlack common sense about the physical implications of their actions on people.\nThe physical implications of dressing are complicated by non-rigid garments,\nwhich can result in a robot indirectly applying high forces to a person's body.\nWe present a deep recurrent model that, when given a proposed action by the\nrobot, predicts the forces a garment will apply to a person's body. We also\nshow that a robot can provide better dressing assistance by using this model\nwith model predictive control. The predictions made by our model only use\nhaptic and kinematic observations from the robot's end effector, which are\nreadily attainable. Collecting training data from real world physical\nhuman-robot interaction can be time consuming, costly, and put people at risk.\nInstead, we train our predictive model using data collected in an entirely\nself-supervised fashion from a physics-based simulation. We evaluated our\napproach with a PR2 robot that attempted to pull a hospital gown onto the arms\nof 10 human participants. With a 0.2s prediction horizon, our controller\nsucceeded at high rates and lowered applied force while navigating the garment\naround a persons fist and elbow without getting caught. Shorter prediction\nhorizons resulted in significantly reduced performance with the sleeve catching\non the participants' fists and elbows, demonstrating the value of our model's\npredictions. These behaviors of mitigating catches emerged from our deep\npredictive model and the controller objective function, which primarily\npenalizes high forces.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 21:10:26 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 14:43:31 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 21:30:47 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Erickson", "Zackory", ""], ["Clever", "Henry M.", ""], ["Turk", "Greg", ""], ["Liu", "C. Karen", ""], ["Kemp", "Charles C.", ""]]}, {"id": "1709.09741", "submitter": "Raj Korpan", "authors": "Raj Korpan, Susan L. Epstein, Anoop Aroor, Gil Dekel", "title": "WHY: Natural Explanations from a Robot Navigator", "comments": "Accepted at AAAI 2017 Fall Symposium on Natural Communication for\n  Human-Robot Collaboration", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective collaboration between a robot and a person requires natural\ncommunication. When a robot travels with a human companion, the robot should be\nable to explain its navigation behavior in natural language. This paper\nexplains how a cognitively-based, autonomous robot navigation system produces\ninformative, intuitive explanations for its decisions. Language generation here\nis based upon the robot's commonsense, its qualitative reasoning, and its\nlearned spatial model. This approach produces natural explanations in real time\nfor a robot as it navigates in a large, complex indoor environment.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 21:30:53 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Korpan", "Raj", ""], ["Epstein", "Susan L.", ""], ["Aroor", "Anoop", ""], ["Dekel", "Gil", ""]]}, {"id": "1709.09816", "submitter": "Federico Fancellu", "authors": "Ben Krause, Marco Damonte, Mihai Dobre, Daniel Duma, Joachim Fainberg,\n  Federico Fancellu, Emmanuel Kahembwe, Jianpeng Cheng, Bonnie Webber", "title": "Edina: Building an Open Domain Socialbot with Self-dialogues", "comments": "10 pages; submitted to the 1st Proceedings of the Alexa Prize", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Edina, the University of Edinburgh's social bot for the Amazon\nAlexa Prize competition. Edina is a conversational agent whose responses\nutilize data harvested from Amazon Mechanical Turk (AMT) through an innovative\nnew technique we call self-dialogues. These are conversations in which a single\nAMT Worker plays both participants in a dialogue. Such dialogues are\nsurprisingly natural, efficient to collect and reflective of relevant and/or\ntrending topics. These self-dialogues provide training data for a generative\nneural network as well as a basis for soft rules used by a matching score\ncomponent. Each match of a soft rule against a user utterance is associated\nwith a confidence score which we show is strongly indicative of reply quality,\nallowing this component to self-censor and be effectively integrated with other\ncomponents. Edina's full architecture features a rule-based system backing off\nto a matching score, backing off to a generative neural network. Our hybrid\ndata-driven methodology thus addresses both coverage limitations of a strictly\nrule-based approach and the lack of guarantees of a strictly machine-learning\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 06:13:33 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Krause", "Ben", ""], ["Damonte", "Marco", ""], ["Dobre", "Mihai", ""], ["Duma", "Daniel", ""], ["Fainberg", "Joachim", ""], ["Fancellu", "Federico", ""], ["Kahembwe", "Emmanuel", ""], ["Cheng", "Jianpeng", ""], ["Webber", "Bonnie", ""]]}, {"id": "1709.09839", "submitter": "Mor Vered", "authors": "Mor Vered and Gal A. Kaminka", "title": "Heuristic Online Goal Recognition in Continuous Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal recognition is the problem of inferring the goal of an agent, based on\nits observed actions. An inspiring approach - plan recognition by planning\n(PRP) - uses off-the-shelf planners to dynamically generate plans for given\ngoals, eliminating the need for the traditional plan library. However, existing\nPRP formulation is inherently inefficient in online recognition, and cannot be\nused with motion planners for continuous spaces. In this paper, we utilize a\ndifferent PRP formulation which allows for online goal recognition, and for\napplication in continuous spaces. We present an online recognition algorithm,\nwhere two heuristic decision points may be used to improve run-time\nsignificantly over existing work. We specify heuristics for continuous domains,\nprove guarantees on their use, and empirically evaluate the algorithm over\nhundreds of experiments in both a 3D navigational environment and a cooperative\nrobotic team task.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 07:58:59 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Vered", "Mor", ""], ["Kaminka", "Gal A.", ""]]}, {"id": "1709.09844", "submitter": "Amit Mandelbaum", "authors": "Amit Mandelbaum and Daphna Weinshall", "title": "Distance-based Confidence Score for Neural Network Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reliable measurement of confidence in classifiers' predictions is very\nimportant for many applications and is, therefore, an important part of\nclassifier design. Yet, although deep learning has received tremendous\nattention in recent years, not much progress has been made in quantifying the\nprediction confidence of neural network classifiers. Bayesian models offer a\nmathematically grounded framework to reason about model uncertainty, but\nusually come with prohibitive computational costs. In this paper we propose a\nsimple, scalable method to achieve a reliable confidence score, based on the\ndata embedding derived from the penultimate layer of the network. We\ninvestigate two ways to achieve desirable embeddings, by using either a\ndistance-based loss or Adversarial Training. We then test the benefits of our\nmethod when used for classification error prediction, weighting an ensemble of\nclassifiers, and novelty detection. In all tasks we show significant\nimprovement over traditional, commonly used confidence scores.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 08:09:47 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Mandelbaum", "Amit", ""], ["Weinshall", "Daphna", ""]]}, {"id": "1709.09882", "submitter": "Giulia Pasquale", "authors": "Giulia Pasquale, Carlo Ciliberto, Francesca Odone, Lorenzo Rosasco and\n  Lorenzo Natale", "title": "Are we done with object recognition? The iCub robot's perspective", "comments": "21 pages + supplementary material", "journal-ref": "Robotics and Autonomous Systems, Volume 112, February 2019, Pages\n  260-281", "doi": "10.1016/j.robot.2018.11.001", "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on an extensive study of the benefits and limitations of current\ndeep learning approaches to object recognition in robot vision scenarios,\nintroducing a novel dataset used for our investigation. To avoid the biases in\ncurrently available datasets, we consider a natural human-robot interaction\nsetting to design a data-acquisition protocol for visual object recognition on\nthe iCub humanoid robot. Analyzing the performance of off-the-shelf models\ntrained off-line on large-scale image retrieval datasets, we show the necessity\nfor knowledge transfer. We evaluate different ways in which this last step can\nbe done, and identify the major bottlenecks affecting robotic scenarios. By\nstudying both object categorization and identification problems, we highlight\nkey differences between object recognition in robotics applications and in\nimage retrieval tasks, for which the considered deep learning approaches have\nbeen originally designed. In a nutshell, our results confirm the remarkable\nimprovements yield by deep learning in this setting, while pointing to specific\nopen challenges that need be addressed for seamless deployment in robotics.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 10:16:52 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 14:16:09 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Pasquale", "Giulia", ""], ["Ciliberto", "Carlo", ""], ["Odone", "Francesca", ""], ["Rosasco", "Lorenzo", ""], ["Natale", "Lorenzo", ""]]}, {"id": "1709.09902", "submitter": "Dat Thanh Tran", "authors": "Dat Thanh Tran, Alexandros Iosifidis, Moncef Gabbouj", "title": "Improving Efficiency in Convolutional Neural Network with Multilinear\n  Filters", "comments": "10 pages, 3 figures", "journal-ref": "Neural Networks vol. 105, pp. 328-339, 2018", "doi": "10.1016/j.neunet.2018.05.017", "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The excellent performance of deep neural networks has enabled us to solve\nseveral automatization problems, opening an era of autonomous devices. However,\ncurrent deep net architectures are heavy with millions of parameters and\nrequire billions of floating point operations. Several works have been\ndeveloped to compress a pre-trained deep network to reduce memory footprint\nand, possibly, computation. Instead of compressing a pre-trained network, in\nthis work, we propose a generic neural network layer structure employing\nmultilinear projection as the primary feature extractor. The proposed\narchitecture requires several times less memory as compared to the traditional\nConvolutional Neural Networks (CNN), while inherits the similar design\nprinciples of a CNN. In addition, the proposed architecture is equipped with\ntwo computation schemes that enable computation reduction or scalability.\nExperimental results show the effectiveness of our compact projection that\noutperforms traditional CNN, while requiring far fewer parameters.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 11:55:13 GMT"}, {"version": "v2", "created": "Mon, 9 Oct 2017 12:45:30 GMT"}, {"version": "v3", "created": "Mon, 23 Oct 2017 15:42:11 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Tran", "Dat Thanh", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1709.09972", "submitter": "Andr\\'e Hottung", "authors": "Andr\\'e Hottung, Shunji Tanaka, Kevin Tierney", "title": "Deep Learning Assisted Heuristic Tree Search for the Container\n  Pre-marshalling Problem", "comments": null, "journal-ref": "Computers & Operations Research 113 (2020) 104781", "doi": "10.1016/j.cor.2019.104781", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The container pre-marshalling problem (CPMP) is concerned with the\nre-ordering of containers in container terminals during off-peak times so that\ncontainers can be quickly retrieved when the port is busy. The problem has\nreceived significant attention in the literature and is addressed by a large\nnumber of exact and heuristic methods. Existing methods for the CPMP heavily\nrely on problem-specific components (e.g., proven lower bounds) that need to be\ndeveloped by domain experts with knowledge of optimization techniques and a\ndeep understanding of the problem at hand. With the goal to automate the costly\nand time-intensive design of heuristics for the CPMP, we propose a new method\ncalled Deep Learning Heuristic Tree Search (DLTS). It uses deep neural networks\nto learn solution strategies and lower bounds customized to the CPMP solely\nthrough analyzing existing (near-) optimal solutions to CPMP instances. The\nnetworks are then integrated into a tree search procedure to decide which\nbranch to choose next and to prune the search tree. DLTS produces the highest\nquality heuristic solutions to the CPMP to date with gaps to optimality below\n2% on real-world sized instances.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 14:06:28 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 15:16:38 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Hottung", "Andr\u00e9", ""], ["Tanaka", "Shunji", ""], ["Tierney", "Kevin", ""]]}, {"id": "1709.09994", "submitter": "Mingzhe Wang", "authors": "Mingzhe Wang, Yihe Tang, Jian Wang, Jia Deng", "title": "Premise Selection for Theorem Proving by Deep Graph Embedding", "comments": "Mingzhe Wang and Yihe Tang contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep learning-based approach to the problem of premise\nselection: selecting mathematical statements relevant for proving a given\nconjecture. We represent a higher-order logic formula as a graph that is\ninvariant to variable renaming but still fully preserves syntactic and semantic\ninformation. We then embed the graph into a vector via a novel embedding method\nthat preserves the information of edge ordering. Our approach achieves\nstate-of-the-art results on the HolStep dataset, improving the classification\naccuracy from 83% to 90.3%.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 14:44:40 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Wang", "Mingzhe", ""], ["Tang", "Yihe", ""], ["Wang", "Jian", ""], ["Deng", "Jia", ""]]}, {"id": "1709.10082", "submitter": "Jia Pan", "authors": "Pinxin Long, Tingxiang Fan, Xinyi Liao, Wenxi Liu, Hao Zhang and Jia\n  Pan", "title": "Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing a safe and efficient collision avoidance policy for multiple\nrobots is challenging in the decentralized scenarios where each robot generate\nits paths without observing other robots' states and intents. While other\ndistributed multi-robot collision avoidance systems exist, they often require\nextracting agent-level features to plan a local collision-free action, which\ncan be computationally prohibitive and not robust. More importantly, in\npractice the performance of these methods are much lower than their centralized\ncounterparts.\n  We present a decentralized sensor-level collision avoidance policy for\nmulti-robot systems, which directly maps raw sensor measurements to an agent's\nsteering commands in terms of movement velocity. As a first step toward\nreducing the performance gap between decentralized and centralized methods, we\npresent a multi-scenario multi-stage training framework to find an optimal\npolicy which is trained over a large number of robots on rich, complex\nenvironments simultaneously using a policy gradient based reinforcement\nlearning algorithm. We validate the learned sensor-level collision avoidance\npolicy in a variety of simulated scenarios with thorough performance\nevaluations and show that the final learned policy is able to find time\nefficient, collision-free paths for a large-scale robot system. We also\ndemonstrate that the learned policy can be well generalized to new scenarios\nthat do not appear in the entire training period, including navigating a\nheterogeneous group of robots and a large-scale scenario with 100 robots.\nVideos are available at https://sites.google.com/view/drlmaca\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 17:44:09 GMT"}, {"version": "v2", "created": "Fri, 29 Sep 2017 02:20:12 GMT"}, {"version": "v3", "created": "Sun, 20 May 2018 08:36:24 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Long", "Pinxin", ""], ["Fan", "Tingxiang", ""], ["Liao", "Xinyi", ""], ["Liu", "Wenxi", ""], ["Zhang", "Hao", ""], ["Pan", "Jia", ""]]}, {"id": "1709.10087", "submitter": "Aravind Rajeswaran", "authors": "Aravind Rajeswaran, Vikash Kumar, Abhishek Gupta, Giulia Vezzani, John\n  Schulman, Emanuel Todorov, Sergey Levine", "title": "Learning Complex Dexterous Manipulation with Deep Reinforcement Learning\n  and Demonstrations", "comments": "Accepted for presentation at Robotics: Science and Systems (RSS)\n  2018. Project page:\n  https://sites.google.com/view/deeprl-dexterous-manipulation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dexterous multi-fingered hands are extremely versatile and provide a generic\nway to perform a multitude of tasks in human-centric environments. However,\neffectively controlling them remains challenging due to their high\ndimensionality and large number of potential contacts. Deep reinforcement\nlearning (DRL) provides a model-agnostic approach to control complex dynamical\nsystems, but has not been shown to scale to high-dimensional dexterous\nmanipulation. Furthermore, deployment of DRL on physical systems remains\nchallenging due to sample inefficiency. Consequently, the success of DRL in\nrobotics has thus far been limited to simpler manipulators and tasks. In this\nwork, we show that model-free DRL can effectively scale up to complex\nmanipulation tasks with a high-dimensional 24-DoF hand, and solve them from\nscratch in simulated experiments. Furthermore, with the use of a small number\nof human demonstrations, the sample complexity can be significantly reduced,\nwhich enables learning with sample sizes equivalent to a few hours of robot\nexperience. The use of demonstrations result in policies that exhibit very\nnatural movements and, surprisingly, are also substantially more robust.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 17:51:13 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 13:31:37 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Rajeswaran", "Aravind", ""], ["Kumar", "Vikash", ""], ["Gupta", "Abhishek", ""], ["Vezzani", "Giulia", ""], ["Schulman", "John", ""], ["Todorov", "Emanuel", ""], ["Levine", "Sergey", ""]]}, {"id": "1709.10089", "submitter": "Ashvin Nair", "authors": "Ashvin Nair, Bob McGrew, Marcin Andrychowicz, Wojciech Zaremba, Pieter\n  Abbeel", "title": "Overcoming Exploration in Reinforcement Learning with Demonstrations", "comments": "8 pages, ICRA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration in environments with sparse rewards has been a persistent problem\nin reinforcement learning (RL). Many tasks are natural to specify with a sparse\nreward, and manually shaping a reward function can result in suboptimal\nperformance. However, finding a non-zero reward is exponentially more difficult\nwith increasing task horizon or action dimensionality. This puts many\nreal-world tasks out of practical reach of RL methods. In this work, we use\ndemonstrations to overcome the exploration problem and successfully learn to\nperform long-horizon, multi-step robotics tasks with continuous control such as\nstacking blocks with a robot arm. Our method, which builds on top of Deep\nDeterministic Policy Gradients and Hindsight Experience Replay, provides an\norder of magnitude of speedup over RL on simulated robotics tasks. It is simple\nto implement and makes only the additional assumption that we can collect a\nsmall set of demonstrations. Furthermore, our method is able to solve tasks not\nsolvable by either RL or behavior cloning alone, and often ends up\noutperforming the demonstrator policy.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 17:51:48 GMT"}, {"version": "v2", "created": "Sun, 25 Feb 2018 07:48:19 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Nair", "Ashvin", ""], ["McGrew", "Bob", ""], ["Andrychowicz", "Marcin", ""], ["Zaremba", "Wojciech", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1709.10163", "submitter": "Nicholas Waytowich", "authors": "Garrett Warnell, Nicholas Waytowich, Vernon Lawhern, Peter Stone", "title": "Deep TAMER: Interactive Agent Shaping in High-Dimensional State Spaces", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent advances in deep reinforcement learning have allowed autonomous\nlearning agents to succeed at a variety of complex tasks, existing algorithms\ngenerally require a lot of training data. One way to increase the speed at\nwhich agents are able to learn to perform tasks is by leveraging the input of\nhuman trainers. Although such input can take many forms, real-time,\nscalar-valued feedback is especially useful in situations where it proves\ndifficult or impossible for humans to provide expert demonstrations. Previous\napproaches have shown the usefulness of human input provided in this fashion\n(e.g., the TAMER framework), but they have thus far not considered\nhigh-dimensional state spaces or employed the use of deep learning. In this\npaper, we do both: we propose Deep TAMER, an extension of the TAMER framework\nthat leverages the representational power of deep neural networks in order to\nlearn complex tasks in just a short amount of time with a human trainer. We\ndemonstrate Deep TAMER's success by using it and just 15 minutes of\nhuman-provided feedback to train an agent that performs better than humans on\nthe Atari game of Bowling - a task that has proven difficult for even\nstate-of-the-art reinforcement learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 20:43:40 GMT"}, {"version": "v2", "created": "Fri, 19 Jan 2018 20:36:13 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Warnell", "Garrett", ""], ["Waytowich", "Nicholas", ""], ["Lawhern", "Vernon", ""], ["Stone", "Peter", ""]]}, {"id": "1709.10204", "submitter": "Bin Bi", "authors": "Bin Bi and Hao Ma", "title": "A Neural Comprehensive Ranker (NCR) for Open-Domain Question Answering", "comments": "A paper with a similar method has been published earlier at\n  arXiv:1706.04815 The authors believe there is no need for a separate\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel neural machine reading model for open-domain\nquestion answering at scale. Existing machine comprehension models typically\nassume that a short piece of relevant text containing answers is already\nidentified and given to the models, from which the models are designed to\nextract answers. This assumption, however, is not realistic for building a\nlarge-scale open-domain question answering system which requires both deep text\nunderstanding and identifying relevant text from corpus simultaneously.\n  In this paper, we introduce Neural Comprehensive Ranker (NCR) that integrates\nboth passage ranking and answer extraction in one single framework. A Q&A\nsystem based on this framework allows users to issue an open-domain question\nwithout needing to provide a piece of text that must contain the answer.\nExperiments show that the unified NCR model is able to outperform the\nstates-of-the-art in both retrieval of relevant text and answer extraction.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 00:27:48 GMT"}, {"version": "v2", "created": "Thu, 5 Oct 2017 17:56:02 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Bi", "Bin", ""], ["Ma", "Hao", ""]]}, {"id": "1709.10205", "submitter": "Georgios Detorakis", "authors": "Georgios Detorakis, Sadique Sheik, Charles Augustine, Somnath Paul,\n  Bruno U. Pedroni, Nikil Dutt, Jeffrey Krichmar, Gert Cauwenberghs, Emre\n  Neftci", "title": "Neural and Synaptic Array Transceiver: A Brain-Inspired Computing\n  Framework for Embedded Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded, continual learning for autonomous and adaptive behavior is a key\napplication of neuromorphic hardware. However, neuromorphic implementations of\nembedded learning at large scales that are both flexible and efficient have\nbeen hindered by a lack of a suitable algorithmic framework. As a result, the\nmost neuromorphic hardware is trained off-line on large clusters of dedicated\nprocessors or GPUs and transferred post hoc to the device. We address this by\nintroducing the neural and synaptic array transceiver (NSAT), a neuromorphic\ncomputational framework facilitating flexible and efficient embedded learning\nby matching algorithmic requirements and neural and synaptic dynamics. NSAT\nsupports event-driven supervised, unsupervised and reinforcement learning\nalgorithms including deep learning. We demonstrate the NSAT in a wide range of\ntasks, including the simulation of Mihalas-Niebur neuron, dynamic neural\nfields, event-driven random back-propagation for event-based deep learning,\nevent-based contrastive divergence for unsupervised learning, and voltage-based\nlearning rules for sequence learning. We anticipate that this contribution will\nestablish the foundation for a new generation of devices enabling adaptive\nmobile systems, wearable devices, and robots with data-driven autonomy.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 00:30:32 GMT"}, {"version": "v2", "created": "Fri, 6 Oct 2017 22:51:48 GMT"}, {"version": "v3", "created": "Wed, 8 Aug 2018 18:30:13 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Detorakis", "Georgios", ""], ["Sheik", "Sadique", ""], ["Augustine", "Charles", ""], ["Paul", "Somnath", ""], ["Pedroni", "Bruno U.", ""], ["Dutt", "Nikil", ""], ["Krichmar", "Jeffrey", ""], ["Cauwenberghs", "Gert", ""], ["Neftci", "Emre", ""]]}, {"id": "1709.10207", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini, Guy Katz, Clark Barrett, David L. Dill", "title": "Provably Minimally-Distorted Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to deploy neural networks in real-world, safety-critical systems\nis severely limited by the presence of adversarial examples: slightly perturbed\ninputs that are misclassified by the network. In recent years, several\ntechniques have been proposed for increasing robustness to adversarial examples\n--- and yet most of these have been quickly shown to be vulnerable to future\nattacks. For example, over half of the defenses proposed by papers accepted at\nICLR 2018 have already been broken. We propose to address this difficulty\nthrough formal verification techniques. We show how to construct provably\nminimally distorted adversarial examples: given an arbitrary neural network and\ninput sample, we can construct adversarial examples which we prove are of\nminimal distortion. Using this approach, we demonstrate that one of the recent\nICLR defense proposals, adversarial retraining, provably succeeds at increasing\nthe distortion required to construct adversarial examples by a factor of 4.2.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 00:57:12 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 05:35:36 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Carlini", "Nicholas", ""], ["Katz", "Guy", ""], ["Barrett", "Clark", ""], ["Dill", "David L.", ""]]}, {"id": "1709.10242", "submitter": "Liu Feng", "authors": "Feng Liu, Yong Shi, Ying Liu", "title": "Intelligence Quotient and Intelligence Grade of Artificial Intelligence", "comments": null, "journal-ref": "Annals of Data Science, June 2017, Volume 4, Issue 2, pp 179-191", "doi": "10.1007/s40745-017-0109-0", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although artificial intelligence is currently one of the most interesting\nareas in scientific research, the potential threats posed by emerging AI\nsystems remain a source of persistent controversy. To address the issue of AI\nthreat, this study proposes a standard intelligence model that unifies AI and\nhuman characteristics in terms of four aspects of knowledge, i.e., input,\noutput, mastery, and creation. Using this model, we observe three challenges,\nnamely, expanding of the von Neumann architecture; testing and ranking the\nintelligence quotient of naturally and artificially intelligent systems,\nincluding humans, Google, Bing, Baidu, and Siri; and finally, the dividing of\nartificially intelligent systems into seven grades from robots to Google Brain.\nBased on this, we conclude that AlphaGo belongs to the third grade.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 05:43:39 GMT"}, {"version": "v2", "created": "Wed, 4 Oct 2017 16:33:07 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Liu", "Feng", ""], ["Shi", "Yong", ""], ["Liu", "Ying", ""]]}, {"id": "1709.10256", "submitter": "Daniele Magazzeni", "authors": "Maria Fox, Derek Long, Daniele Magazzeni", "title": "Explainable Planning", "comments": "Presented at the IJCAI-17 workshop on Explainable AI\n  (http://home.earthlink.net/~dwaha/research/meetings/ijcai17-xai/). Melbourne,\n  August 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As AI is increasingly being adopted into application solutions, the challenge\nof supporting interaction with humans is becoming more apparent. Partly this is\nto support integrated working styles, in which humans and intelligent systems\ncooperate in problem-solving, but also it is a necessary step in the process of\nbuilding trust as humans migrate greater responsibility to such systems. The\nchallenge is to find effective ways to communicate the foundations of AI-driven\nbehaviour, when the algorithms that drive it are far from transparent to\nhumans. In this paper we consider the opportunities that arise in AI planning,\nexploiting the model-based representations that form a familiar and common\nbasis for communication with users, while acknowledging the gap between\nplanning algorithms and human problem-solving.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 07:05:38 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Fox", "Maria", ""], ["Long", "Derek", ""], ["Magazzeni", "Daniele", ""]]}, {"id": "1709.10423", "submitter": "Yanchao Yu", "authors": "Yanchao Yu, Arash Eshghi, Oliver Lemon", "title": "Learning how to learn: an adaptive dialogue agent for incrementally\n  learning visually grounded word meanings", "comments": "10 pages, RoboNLP Workshop from ACL Conference", "journal-ref": null, "doi": "10.18653/v1/W17-2802", "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an optimised multi-modal dialogue agent for interactive learning\nof visually grounded word meanings from a human tutor, trained on real\nhuman-human tutoring data. Within a life-long interactive learning period, the\nagent, trained using Reinforcement Learning (RL), must be able to handle\nnatural conversations with human users and achieve good learning performance\n(accuracy) while minimising human effort in the learning process. We train and\nevaluate this system in interaction with a simulated human tutor, which is\nbuilt on the BURCHAK corpus -- a Human-Human Dialogue dataset for the visual\nlearning task. The results show that: 1) The learned policy can coherently\ninteract with the simulated user to achieve the goal of the task (i.e. learning\nvisual attributes of objects, e.g. colour and shape); and 2) it finds a better\ntrade-off between classifier accuracy and tutoring costs than hand-crafted\nrule-based policies, including ones with dynamic policies.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 14:21:31 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Yu", "Yanchao", ""], ["Eshghi", "Arash", ""], ["Lemon", "Oliver", ""]]}, {"id": "1709.10426", "submitter": "Yanchao Yu", "authors": "Yanchao Yu, Arash Eshghi, Oliver Lemon", "title": "Training an adaptive dialogue policy for interactive learning of\n  visually grounded word meanings", "comments": "11 pages, SIGDIAL 2016 Conference", "journal-ref": null, "doi": "10.18653/v1/W16-3643", "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multi-modal dialogue system for interactive learning of\nperceptually grounded word meanings from a human tutor. The system integrates\nan incremental, semantic parsing/generation framework - Dynamic Syntax and Type\nTheory with Records (DS-TTR) - with a set of visual classifiers that are\nlearned throughout the interaction and which ground the meaning representations\nthat it produces. We use this system in interaction with a simulated human\ntutor to study the effects of different dialogue policies and capabilities on\nthe accuracy of learned meanings, learning rates, and efforts/costs to the\ntutor. We show that the overall performance of the learning agent is affected\nby (1) who takes initiative in the dialogues; (2) the ability to express/use\ntheir confidence level about visual attributes; and (3) the ability to process\nelliptical and incrementally constructed dialogue turns. Ultimately, we train\nan adaptive dialogue policy which optimises the trade-off between classifier\naccuracy and tutoring costs.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 14:28:31 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Yu", "Yanchao", ""], ["Eshghi", "Arash", ""], ["Lemon", "Oliver", ""]]}, {"id": "1709.10431", "submitter": "Yanchao Yu", "authors": "Yanchao Yu, Arash Eshghi, Gregory Mills, Oliver Joseph Lemon", "title": "The BURCHAK corpus: a Challenge Data Set for Interactive Learning of\n  Visually Grounded Word Meanings", "comments": "10 pages, THE 6TH WORKSHOP ON VISION AND LANGUAGE (VL'17)", "journal-ref": null, "doi": "10.18653/v1/W17-2001", "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We motivate and describe a new freely available human-human dialogue dataset\nfor interactive learning of visually grounded word meanings through ostensive\ndefinition by a tutor to a learner. The data has been collected using a novel,\ncharacter-by-character variant of the DiET chat tool (Healey et al., 2003;\nMills and Healey, submitted) with a novel task, where a Learner needs to learn\ninvented visual attribute words (such as \" burchak \" for square) from a tutor.\nAs such, the text-based interactions closely resemble face-to-face conversation\nand thus contain many of the linguistic phenomena encountered in natural,\nspontaneous dialogue. These include self-and other-correction, mid-sentence\ncontinuations, interruptions, overlaps, fillers, and hedges. We also present a\ngeneric n-gram framework for building user (i.e. tutor) simulations from this\ntype of incremental data, which is freely available to researchers. We show\nthat the simulations produce outputs that are similar to the original data\n(e.g. 78% turn match similarity). Finally, we train and evaluate a\nReinforcement Learning dialogue control agent for learning visually grounded\nword meanings, trained from the BURCHAK corpus. The learned policy shows\ncomparable performance to a rule-based system built previously.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 14:43:06 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Yu", "Yanchao", ""], ["Eshghi", "Arash", ""], ["Mills", "Gregory", ""], ["Lemon", "Oliver Joseph", ""]]}, {"id": "1709.10445", "submitter": "Seunghyun Yoon", "authors": "Seunghyun Yoon, Pablo Estrada, Kyomin Jung", "title": "Synonym Discovery with Etymology-based Word Embeddings", "comments": "6 pages, IEEE Symposium Series on Computational Intelligence (IEEE\n  SSCI 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to learn word embeddings based on an extended\nversion of the distributional hypothesis. Our model derives word embedding\nvectors using the etymological composition of words, rather than the context in\nwhich they appear. It has the strength of not requiring a large text corpus,\nbut instead it requires reliable access to etymological roots of words, making\nit specially fit for languages with logographic writing systems. The model\nconsists on three steps: (1) building an etymological graph, which is a\nbipartite network of words and etymological roots, (2) obtaining the\nbiadjacency matrix of the etymological graph and reducing its dimensionality,\n(3) using columns/rows of the resulting matrices as embedding vectors. We test\nour model in the Chinese and Sino-Korean vocabularies. Our graphs are formed by\na set of 117,000 Chinese words, and a set of 135,000 Sino-Korean words. In both\ncases we show that our model performs well in the task of synonym discovery.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 15:10:20 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 12:57:59 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Yoon", "Seunghyun", ""], ["Estrada", "Pablo", ""], ["Jung", "Kyomin", ""]]}, {"id": "1709.10482", "submitter": "Andrea Marrella", "authors": "Andrea Marrella", "title": "What Automated Planning can do for Business Process Management", "comments": "Preprint of a paper to be published in BPAI 2017, Workshop on BP\n  Innovation with Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Business Process Management (BPM) is a central element of today\norganizations. Despite over the years its main focus has been the support of\nprocesses in highly controlled domains, nowadays many domains of interest to\nthe BPM community are characterized by ever-changing requirements,\nunpredictable environments and increasing amounts of data that influence the\nexecution of process instances. Under such dynamic conditions, BPM systems must\nincrease their level of automation to provide the reactivity and flexibility\nnecessary for process management. On the other hand, the Artificial\nIntelligence (AI) community has concentrated its efforts on investigating\ndynamic domains that involve active control of computational entities and\nphysical devices (e.g., robots, software agents, etc.). In this context,\nAutomated Planning, which is one of the oldest areas in AI, is conceived as a\nmodel-based approach to synthesize autonomous behaviours in automated way from\na model. In this paper, we discuss how automated planning techniques can be\nleveraged to enable new levels of automation and support for business\nprocessing, and we show some concrete examples of their successful application\nto the different stages of the BPM life cycle.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 16:18:18 GMT"}, {"version": "v2", "created": "Fri, 20 Oct 2017 15:19:29 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Marrella", "Andrea", ""]]}, {"id": "1709.10489", "submitter": "Gregory Kahn", "authors": "Gregory Kahn, Adam Villaflor, Bosen Ding, Pieter Abbeel, Sergey Levine", "title": "Self-supervised Deep Reinforcement Learning with Generalized Computation\n  Graphs for Robot Navigation", "comments": "ICRA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enabling robots to autonomously navigate complex environments is essential\nfor real-world deployment. Prior methods approach this problem by having the\nrobot maintain an internal map of the world, and then use a localization and\nplanning method to navigate through the internal map. However, these approaches\noften include a variety of assumptions, are computationally intensive, and do\nnot learn from failures. In contrast, learning-based methods improve as the\nrobot acts in the environment, but are difficult to deploy in the real-world\ndue to their high sample complexity. To address the need to learn complex\npolicies with few samples, we propose a generalized computation graph that\nsubsumes value-based model-free methods and model-based methods, with specific\ninstantiations interpolating between model-free and model-based. We then\ninstantiate this graph to form a navigation model that learns from raw images\nand is sample efficient. Our simulated car experiments explore the design\ndecisions of our navigation model, and show our approach outperforms\nsingle-step and $N$-step double Q-learning. We also evaluate our approach on a\nreal-world RC car and show it can learn to navigate through a complex indoor\nenvironment with a few hours of fully autonomous, self-supervised training.\nVideos of the experiments and code can be found at github.com/gkahn13/gcg\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 16:47:14 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 23:55:32 GMT"}, {"version": "v3", "created": "Thu, 17 May 2018 22:32:25 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Kahn", "Gregory", ""], ["Villaflor", "Adam", ""], ["Ding", "Bosen", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1709.10494", "submitter": "Valsamis Ntouskos", "authors": "Marta Sanzari, Valsamis Ntouskos, Fiora Pirri", "title": "Discovery and recognition of motion primitives in human activities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework for the automatic discovery and recognition of\nmotion primitives in videos of human activities. Given the 3D pose of a human\nin a video, human motion primitives are discovered by optimizing the `motion\nflux', a quantity which captures the motion variation of a group of skeletal\njoints. A normalization of the primitives is proposed in order to make them\ninvariant with respect to a subject anatomical variations and data sampling\nrate. The discovered primitives are unknown and unlabeled and are\nunsupervisedly collected into classes via a hierarchical non-parametric Bayes\nmixture model. Once classes are determined and labeled they are further\nanalyzed for establishing models for recognizing discovered primitives. Each\nprimitive model is defined by a set of learned parameters.\n  Given new video data and given the estimated pose of the subject appearing on\nthe video, the motion is segmented into primitives, which are recognized with a\nprobability given according to the parameters of the learned models.\n  Using our framework we build a publicly available dataset of human motion\nprimitives, using sequences taken from well-known motion capture datasets. We\nexpect that our framework, by providing an objective way for discovering and\ncategorizing human motion, will be a useful tool in numerous research fields\nincluding video analysis, human inspired motion generation, learning by\ndemonstration, intuitive human-robot interaction, and human behavior analysis.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 16:59:06 GMT"}, {"version": "v2", "created": "Mon, 23 Oct 2017 12:29:13 GMT"}, {"version": "v3", "created": "Tue, 13 Feb 2018 14:02:03 GMT"}, {"version": "v4", "created": "Tue, 15 May 2018 10:24:48 GMT"}, {"version": "v5", "created": "Tue, 12 Jun 2018 12:32:24 GMT"}, {"version": "v6", "created": "Thu, 3 Jan 2019 20:18:03 GMT"}, {"version": "v7", "created": "Mon, 4 Feb 2019 13:17:58 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Sanzari", "Marta", ""], ["Ntouskos", "Valsamis", ""], ["Pirri", "Fiora", ""]]}, {"id": "1709.10507", "submitter": "Francesco Puja", "authors": "Francesco Puja, Simone Grazioso, Antonio Tammaro, Valsmis Ntouskos,\n  Marta Sanzari, Fiora Pirri", "title": "Vision-based deep execution monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Execution monitor of high-level robot actions can be effectively improved by\nvisual monitoring the state of the world in terms of preconditions and\npostconditions that hold before and after the execution of an action.\nFurthermore a policy for searching where to look at, either for verifying the\nrelations that specify the pre and postconditions or to refocus in case of a\nfailure, can tremendously improve the robot execution in an uncharted\nenvironment. It is now possible to strongly rely on visual perception in order\nto make the assumption that the environment is observable, by the amazing\nresults of deep learning. In this work we present visual execution monitoring\nfor a robot executing tasks in an uncharted Lab environment. The execution\nmonitor interacts with the environment via a visual stream that uses two DCNN\nfor recognizing the objects the robot has to deal with and manipulate, and a\nnon-parametric Bayes estimation to discover the relations out of the DCNN\nfeatures. To recover from lack of focus and failures due to missed objects we\nresort to visual search policies via deep reinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 17:33:39 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Puja", "Francesco", ""], ["Grazioso", "Simone", ""], ["Tammaro", "Antonio", ""], ["Ntouskos", "Valsmis", ""], ["Sanzari", "Marta", ""], ["Pirri", "Fiora", ""]]}]