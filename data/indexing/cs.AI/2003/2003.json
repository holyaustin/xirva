[{"id": "2003.00030", "submitter": "Romina Abachi", "authors": "Romina Abachi, Mohammad Ghavamzadeh, Amir-massoud Farahmand", "title": "Policy-Aware Model Learning for Policy Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of learning a model in model-based\nreinforcement learning (MBRL). We examine how the planning module of an MBRL\nalgorithm uses the model, and propose that the model learning module should\nincorporate the way the planner is going to use the model. This is in contrast\nto conventional model learning approaches, such as those based on maximum\nlikelihood estimate, that learn a predictive model of the environment without\nexplicitly considering the interaction of the model and the planner. We focus\non policy gradient type of planning algorithms and derive new loss functions\nfor model learning that incorporate how the planner uses the model. We call\nthis approach Policy-Aware Model Learning (PAML). We theoretically analyze a\ngeneric model-based policy gradient algorithm and provide a convergence\nguarantee for the optimized policy. We also empirically evaluate PAML on some\nbenchmark problems, showing promising results.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 19:18:18 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 03:20:54 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Abachi", "Romina", ""], ["Ghavamzadeh", "Mohammad", ""], ["Farahmand", "Amir-massoud", ""]]}, {"id": "2003.00126", "submitter": "Zhe Zeng Miss", "authors": "Zhe Zeng, Paolo Morettin, Fanqi Yan, Antonio Vergari, Guy Van den\n  Broeck", "title": "Scaling up Hybrid Probabilistic Inference with Logical and Arithmetic\n  Constraints via Message Passing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted model integration (WMI) is a very appealing framework for\nprobabilistic inference: it allows to express the complex dependencies of\nreal-world problems where variables are both continuous and discrete, via the\nlanguage of Satisfiability Modulo Theories (SMT), as well as to compute\nprobabilistic queries with complex logical and arithmetic constraints. Yet,\nexisting WMI solvers are not ready to scale to these problems. They either\nignore the intrinsic dependency structure of the problem at all, or they are\nlimited to too restrictive structures. To narrow this gap, we derive a\nfactorized formalism of WMI enabling us to devise a scalable WMI solver based\non message passing, MP-WMI. Namely, MP-WMI is the first WMI solver which allows\nto: 1) perform exact inference on the full class of tree-structured WMI\nproblems; 2) compute all marginal densities in linear time; 3) amortize\ninference inter query. Experimental results show that our solver dramatically\noutperforms the existing WMI solvers on a large set of benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 23:51:45 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 22:41:13 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Zeng", "Zhe", ""], ["Morettin", "Paolo", ""], ["Yan", "Fanqi", ""], ["Vergari", "Antonio", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "2003.00138", "submitter": "Luting Yang", "authors": "Luting Yang, Bingqian Lu and Shaolei Ren", "title": "A Note on Latency Variability of Deep Neural Networks for Mobile\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Running deep neural network (DNN) inference on mobile devices, i.e., mobile\ninference, has become a growing trend, making inference less dependent on\nnetwork connections and keeping private data locally. The prior studies on\noptimizing DNNs for mobile inference typically focus on the metric of average\ninference latency, thus implicitly assuming that mobile inference exhibits\nlittle latency variability. In this note, we conduct a preliminary measurement\nstudy on the latency variability of DNNs for mobile inference. We show that the\ninference latency variability can become quite significant in the presence of\nCPU resource contention. More interestingly, unlike the common belief that the\nrelative performance superiority of DNNs on one device can carry over to\nanother device and/or another level of resource contention, we highlight that a\nDNN model with a better latency performance than another model can become\noutperformed by the other model when resource contention be more severe or\nrunning on another device. Thus, when optimizing DNN models for mobile\ninference, only measuring the average latency may not be adequate; instead,\nlatency variability under various conditions should be accounted for, including\nbut not limited to different devices and different levels of CPU resource\ncontention considered in this note.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 00:30:52 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Yang", "Luting", ""], ["Lu", "Bingqian", ""], ["Ren", "Shaolei", ""]]}, {"id": "2003.00152", "submitter": "Jonathan Frankle", "authors": "Jonathan Frankle, David J. Schwab, and Ari S. Morcos", "title": "Training BatchNorm and Only BatchNorm: On the Expressive Power of Random\n  Features in CNNs", "comments": "Published in ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide variety of deep learning techniques from style transfer to multitask\nlearning rely on training affine transformations of features. Most prominent\namong these is the popular feature normalization technique BatchNorm, which\nnormalizes activations and then subsequently applies a learned affine\ntransform. In this paper, we aim to understand the role and expressive power of\naffine parameters used to transform features in this way. To isolate the\ncontribution of these parameters from that of the learned features they\ntransform, we investigate the performance achieved when training only these\nparameters in BatchNorm and freezing all weights at their random\ninitializations. Doing so leads to surprisingly high performance considering\nthe significant limitations that this style of training imposes. For example,\nsufficiently deep ResNets reach 82% (CIFAR-10) and 32% (ImageNet, top-5)\naccuracy in this configuration, far higher than when training an equivalent\nnumber of randomly chosen parameters elsewhere in the network. BatchNorm\nachieves this performance in part by naturally learning to disable around a\nthird of the random features. Not only do these results highlight the\nexpressive power of affine parameters in deep learning, but - in a broader\nsense - they characterize the expressive power of neural networks constructed\nsimply by shifting and rescaling random features.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 01:57:37 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 14:52:52 GMT"}, {"version": "v3", "created": "Sun, 21 Mar 2021 21:48:35 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Frankle", "Jonathan", ""], ["Schwab", "David J.", ""], ["Morcos", "Ari S.", ""]]}, {"id": "2003.00153", "submitter": "Andrea Zanette", "authors": "Andrea Zanette, Alessandro Lazaric, Mykel Kochenderfer, Emma Brunskill", "title": "Learning Near Optimal Policies with Low Inherent Bellman Error", "comments": "Bug fixes in appendix; appears in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the exploration problem with approximate linear action-value\nfunctions in episodic reinforcement learning under the notion of low inherent\nBellman error, a condition normally employed to show convergence of approximate\nvalue iteration. First we relate this condition to other common frameworks and\nshow that it is strictly more general than the low rank (or linear) MDP\nassumption of prior work. Second we provide an algorithm with a high\nprobability regret bound $\\widetilde O(\\sum_{t=1}^H d_t \\sqrt{K} + \\sum_{t=1}^H\n\\sqrt{d_t} \\IBE K)$ where $H$ is the horizon, $K$ is the number of episodes,\n$\\IBE$ is the value if the inherent Bellman error and $d_t$ is the feature\ndimension at timestep $t$. In addition, we show that the result is unimprovable\nbeyond constants and logs by showing a matching lower bound. This has two\nimportant consequences: 1) it shows that exploration is possible using only\n\\emph{batch assumptions} with an algorithm that achieves the optimal\nstatistical rate for the setting we consider, which is more general than prior\nwork on low-rank MDPs 2) the lack of closedness (measured by the inherent\nBellman error) is only amplified by $\\sqrt{d_t}$ despite working in the online\nsetting. Finally, the algorithm reduces to the celebrated \\textsc{LinUCB} when\n$H=1$ but with a different choice of the exploration parameter that allows\nhandling misspecified contextual linear bandits. While computational\ntractability questions remain open for the MDP setting, this enriches the class\nof MDPs with a linear representation for the action-value function where\nstatistically efficient reinforcement learning is possible.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 02:02:40 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 02:06:43 GMT"}, {"version": "v3", "created": "Sun, 28 Jun 2020 23:46:53 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Zanette", "Andrea", ""], ["Lazaric", "Alessandro", ""], ["Kochenderfer", "Mykel", ""], ["Brunskill", "Emma", ""]]}, {"id": "2003.00164", "submitter": "Yinjie Lei", "authors": "Yinjie Lei, Yan Liu, Pingping Zhang, Lingqiao Liu", "title": "Towards Using Count-level Weak Supervision for Crowd Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing crowd counting methods require object location-level\nannotation, i.e., placing a dot at the center of an object. While being simpler\nthan the bounding-box or pixel-level annotation, obtaining this annotation is\nstill labor-intensive and time-consuming especially for images with highly\ncrowded scenes. On the other hand, weaker annotations that only know the total\ncount of objects can be almost effortless in many practical scenarios. Thus, it\nis desirable to develop a learning method that can effectively train models\nfrom count-level annotations. To this end, this paper studies the problem of\nweakly-supervised crowd counting which learns a model from only a small amount\nof location-level annotations (fully-supervised) but a large amount of\ncount-level annotations (weakly-supervised). To perform effective training in\nthis scenario, we observe that the direct solution of regressing the integral\nof density map to the object count is not sufficient and it is beneficial to\nintroduce stronger regularizations on the predicted density map of\nweakly-annotated images. We devise a simple-yet-effective training strategy,\nnamely Multiple Auxiliary Tasks Training (MATT), to construct regularizes for\nrestricting the freedom of the generated density maps. Through extensive\nexperiments on existing datasets and a newly proposed dataset, we validate the\neffectiveness of the proposed weakly-supervised method and demonstrate its\nsuperior performance over existing solutions.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 02:58:36 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Lei", "Yinjie", ""], ["Liu", "Yan", ""], ["Zhang", "Pingping", ""], ["Liu", "Lingqiao", ""]]}, {"id": "2003.00168", "submitter": "Hardik Uppal", "authors": "Hardik Uppal, Alireza Sepas-Moghaddam, Michael Greenspan and Ali\n  Etemad", "title": "Two-Level Attention-based Fusion Learning for RGB-D Face Recognition", "comments": "8 Pages, 4 figure, Accepted to International Conference on Pattern\n  Recognition (ICPR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With recent advances in RGB-D sensing technologies as well as improvements in\nmachine learning and fusion techniques, RGB-D facial recognition has become an\nactive area of research. A novel attention aware method is proposed to fuse two\nimage modalities, RGB and depth, for enhanced RGB-D facial recognition. The\nproposed method first extracts features from both modalities using a\nconvolutional feature extractor. These features are then fused using a\ntwo-layer attention mechanism. The first layer focuses on the fused feature\nmaps generated by the feature extractor, exploiting the relationship between\nfeature maps using LSTM recurrent learning. The second layer focuses on the\nspatial features of those maps using convolution. The training database is\npreprocessed and augmented through a set of geometric transformations, and the\nlearning process is further aided using transfer learning from a pure 2D RGB\nimage training process. Comparative evaluations demonstrate that the proposed\nmethod outperforms other state-of-the-art approaches, including both\ntraditional and deep neural network-based methods, on the challenging\nCurtinFaces and IIIT-D RGB-D benchmark databases, achieving classification\naccuracies over 98.2% and 99.3% respectively. The proposed attention mechanism\nis also compared with other attention mechanisms, demonstrating more accurate\nresults.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 03:18:52 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 20:30:47 GMT"}, {"version": "v3", "created": "Sun, 18 Oct 2020 10:20:01 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Uppal", "Hardik", ""], ["Sepas-Moghaddam", "Alireza", ""], ["Greenspan", "Michael", ""], ["Etemad", "Ali", ""]]}, {"id": "2003.00172", "submitter": "Ziyue Wang", "authors": "Xiang Zhang, Qingqing Yang, Jinru Ding and Ziyue Wang", "title": "Entity Profiling in Knowledge Graphs", "comments": "10 pages, 5 figures", "journal-ref": "in IEEE Access, vol. 8, pp. 27257-27266, 2020", "doi": "10.1109/ACCESS.2020.2971567", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graphs (KGs) are graph-structured knowledge bases storing factual\ninformation about real-world entities. Understanding the uniqueness of each\nentity is crucial to the analyzing, sharing, and reusing of KGs. Traditional\nprofiling technologies encompass a vast array of methods to find distinctive\nfeatures in various applications, which can help to differentiate entities in\nthe process of human understanding of KGs. In this work, we present a novel\nprofiling approach to identify distinctive entity features. The distinctiveness\nof features is carefully measured by a HAS model, which is a scalable\nrepresentation learning model to produce a multi-pattern entity embedding. We\nfully evaluate the quality of entity profiles generated from real KGs. The\nresults show that our approach facilitates human understanding of entities in\nKGs.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 03:44:24 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Zhang", "Xiang", ""], ["Yang", "Qingqing", ""], ["Ding", "Jinru", ""], ["Wang", "Ziyue", ""]]}, {"id": "2003.00186", "submitter": "Shuangjie Xu", "authors": "Maosheng Ye, Shuangjie Xu and Tongyi Cao", "title": "HVNet: Hybrid Voxel Network for LiDAR Based 3D Object Detection", "comments": "accepted to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Hybrid Voxel Network (HVNet), a novel one-stage unified network\nfor point cloud based 3D object detection for autonomous driving. Recent\nstudies show that 2D voxelization with per voxel PointNet style feature\nextractor leads to accurate and efficient detector for large 3D scenes. Since\nthe size of the feature map determines the computation and memory cost, the\nsize of the voxel becomes a parameter that is hard to balance. A smaller voxel\nsize gives a better performance, especially for small objects, but a longer\ninference time. A larger voxel can cover the same area with a smaller feature\nmap, but fails to capture intricate features and accurate location for smaller\nobjects. We present a Hybrid Voxel network that solves this problem by fusing\nvoxel feature encoder (VFE) of different scales at point-wise level and project\ninto multiple pseudo-image feature maps. We further propose an attentive voxel\nfeature encoding that outperforms plain VFE and a feature fusion pyramid\nnetwork to aggregate multi-scale information at feature map level. Experiments\non the KITTI benchmark show that a single HVNet achieves the best mAP among all\nexisting methods with a real time inference speed of 31Hz.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 05:46:19 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 15:51:05 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Ye", "Maosheng", ""], ["Xu", "Shuangjie", ""], ["Cao", "Tongyi", ""]]}, {"id": "2003.00196", "submitter": "Aliaksandr Siarohin", "authors": "Aliaksandr Siarohin, St\\'ephane Lathuili\\`ere, Sergey Tulyakov, Elisa\n  Ricci and Nicu Sebe", "title": "First Order Motion Model for Image Animation", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Image animation consists of generating a video sequence so that an object in\na source image is animated according to the motion of a driving video. Our\nframework addresses this problem without using any annotation or prior\ninformation about the specific object to animate. Once trained on a set of\nvideos depicting objects of the same category (e.g. faces, human bodies), our\nmethod can be applied to any object of this class. To achieve this, we decouple\nappearance and motion information using a self-supervised formulation. To\nsupport complex motions, we use a representation consisting of a set of learned\nkeypoints along with their local affine transformations. A generator network\nmodels occlusions arising during target motions and combines the appearance\nextracted from the source image and the motion derived from the driving video.\nOur framework scores best on diverse benchmarks and on a variety of object\ncategories. Our source code is publicly available.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 07:08:56 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 08:38:53 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 15:26:15 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Siarohin", "Aliaksandr", ""], ["Lathuili\u00e8re", "St\u00e9phane", ""], ["Tulyakov", "Sergey", ""], ["Ricci", "Elisa", ""], ["Sebe", "Nicu", ""]]}, {"id": "2003.00201", "submitter": "Chaehan So", "authors": "Chaehan So", "title": "What Emotions Make One or Five Stars? Understanding Ratings of Online\n  Product Reviews by Sentiment Analysis and XAI", "comments": "To be published in: Lecture Notes in Artificial Intelligence, 1st\n  International Conference on Artificial Intelligence in HCI, AI-HCI, Held as\n  Part of HCI International 2020, Kopenhagen, Denmark, July 19-24, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When people buy products online, they primarily base their decisions on the\nrecommendations of others given in online reviews. The current work analyzed\nthese online reviews by sentiment analysis and used the extracted sentiments as\nfeatures to predict the product ratings by several machine learning algorithms.\nThese predictions were disentangled by various meth-ods of explainable AI (XAI)\nto understand whether the model showed any bias during prediction. Study 1\nbenchmarked these algorithms (knn, support vector machines, random forests,\ngradient boosting machines, XGBoost) and identified random forests and XGBoost\nas best algorithms for predicting the product ratings. In Study 2, the analysis\nof global feature importance identified the sentiment joy and the emotional\nvalence negative as most predictive features. Two XAI visualization methods,\nlocal feature attributions and partial dependency plots, revealed several\nincorrect prediction mechanisms on the instance-level. Performing the\nbenchmarking as classification, Study 3 identified a high no-information rate\nof 64.4% that indicated high class imbalance as underlying reason for the\nidentified problems. In conclusion, good performance by machine learning\nalgorithms must be taken with caution because the dataset, as encountered in\nthis work, could be biased towards certain predictions. This work demonstrates\nhow XAI methods reveal such prediction bias.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 07:39:35 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["So", "Chaehan", ""]]}, {"id": "2003.00229", "submitter": "Kang Wei", "authors": "Kang Wei, Jun Li, Ming Ding, Chuan Ma, Hang Su, Bo Zhang and H.\n  Vincent Poor", "title": "User-Level Privacy-Preserving Federated Learning: Analysis and\n  Performance Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL), as a type of collaborative machine learning\nframework, is capable of preserving private data from mobile terminals (MTs)\nwhile training the data into useful models. Nevertheless, from a viewpoint of\ninformation theory, it is still possible for a curious server to infer private\ninformation from the shared models uploaded by MTs. To address this problem, we\nfirst make use of the concept of local differential privacy (LDP), and propose\na user-level differential privacy (UDP) algorithm by adding artificial noise to\nthe shared models before uploading them to servers. According to our analysis,\nthe UDP framework can realize $(\\epsilon_{i}, \\delta_{i})$-LDP for the $i$-th\nMT with adjustable privacy protection levels by varying the variances of the\nartificial noise processes. We then derive a theoretical convergence\nupper-bound for the UDP algorithm. It reveals that there exists an optimal\nnumber of communication rounds to achieve the best learning performance. More\nimportantly, we propose a communication rounds discounting (CRD) method.\nCompared with the heuristic search method, the proposed CRD method can achieve\na much better trade-off between the computational complexity of searching and\nthe convergence performance. Extensive experiments indicate that our UDP\nalgorithm using the proposed CRD method can effectively improve both the\ntraining efficiency and model quality for the given privacy protection levels.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 10:13:39 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 01:39:03 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Wei", "Kang", ""], ["Li", "Jun", ""], ["Ding", "Ming", ""], ["Ma", "Chuan", ""], ["Su", "Hang", ""], ["Zhang", "Bo", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2003.00234", "submitter": "Sumant Pushp", "authors": "Raza Rahi, Sumant Pushp, Arif Khan, Smriti Kumar Sinha", "title": "A Finite State Transducer Based Morphological Analyzer of Maithili\n  Language", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Morphological analyzers are the essential milestones for many linguistic\napplications like; machine translation, word sense disambiguation, spells\ncheckers, and search engines etc. Therefore, development of an effective\nmorphological analyzer has a greater impact on the computational recognition of\na language. In this paper, we present a finite state transducer based\ninflectional morphological analyzer for a resource poor language of India,\nknown as Maithili. Maithili is an eastern Indo-Aryan language spoken in the\neastern and northern regions of Bihar in India and the southeastern plains,\nknown as tarai of Nepal. This work can be recognized as the first work towards\nthe computational development of Maithili which may attract researchers around\nthe country to up-rise the language to establish in computational world.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 11:00:15 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Rahi", "Raza", ""], ["Pushp", "Sumant", ""], ["Khan", "Arif", ""], ["Sinha", "Smriti Kumar", ""]]}, {"id": "2003.00260", "submitter": "Jens Braband", "authors": "Jens Braband and Hendrik Sch\\\"abe", "title": "On Safety Assessment of Artificial Intelligence", "comments": "16 pages, 7 figures", "journal-ref": "Dependability, vol. 20 no. 4, 2020", "doi": "10.21683/1729-2646-2020-20-4-25-34", "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we discuss how systems with Artificial Intelligence (AI) can\nundergo safety assessment. This is relevant, if AI is used in safety related\napplications. Taking a deeper look into AI models, we show, that many models of\nartificial intelligence, in particular machine learning, are statistical\nmodels. Safety assessment would then have t o concentrate on the model that is\nused in AI, besides the normal assessment procedure. Part of the budget of\ndangerous random failures for the relevant safety integrity level needs to be\nused for the probabilistic faulty behavior of the AI system. We demonstrate our\nthoughts with a simple example and propose a research challenge that may be\ndecisive for the use of AI in safety related systems.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 14:05:28 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Braband", "Jens", ""], ["Sch\u00e4be", "Hendrik", ""]]}, {"id": "2003.00274", "submitter": "Ajaz Bhat", "authors": "Ajaz A. Bhat and Vishwanathan Mohan", "title": "Causal Learning by a Robot with Semantic-Episodic Memory in an Aesop's\n  Fable Experiment", "comments": "To appear in ICLR 2020 4 pages For associated videos, see\n  https://www.youtube.com/playlist?list=PLIfoHEM1gr24EniCzBuUxZ2tqNpQA8QQm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Corvids, apes, and children solve The Crow and The Pitcher task (from Aesop's\nFables) indicating a causal understanding of the task. By cumulatively\ninteracting with different objects, how can cognitive agents abstract the\nunderlying cause-effect relations to predict affordances of novel objects? We\naddress this question by re-enacting the Aesop's Fable task on a robot and\npresent a) a brain-guided neural model of semantic-episodic memory; with b)\nfour task-agnostic learning rules that compare expectations from recalled past\nepisodes with the current scenario to progressively extract the hidden causal\nrelations. The ensuing robot behaviours illustrate causal learning; and\npredictions for novel objects converge to Archimedes' principle, independent of\nboth the objects explored during learning and the order of their cumulative\nexploration.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 15:02:16 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Bhat", "Ajaz A.", ""], ["Mohan", "Vishwanathan", ""]]}, {"id": "2003.00317", "submitter": "Abhinav K. Jha", "authors": "Ziping Liu, Joyce C. Mhlanga, Richard Laforest, Paul-Robert\n  Derenoncourt, Barry A. Siegel, Abhinav K. Jha", "title": "An estimation-based approach to tumor segmentation in oncological PET", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tumor segmentation in oncological PET is challenging, a major reason being\nthe partial-volume effects due to the low system resolution and finite voxel\nsize. The latter results in tissue-fraction effects, i.e. voxels contain a\nmixture of tissue classes. Most conventional methods perform segmentation by\nexclusively assigning each voxel in the image as belonging to either the tumor\nor normal tissue classes. Thus, these methods are inherently limited in\nmodeling the tissue-fraction effects. To address this inherent limitation, we\npropose an estimation-based approach to segmentation. Specifically, we develop\na Bayesian method that estimates the posterior mean of fractional volume that\nthe tumor occupies within each image voxel. The proposed method, implemented\nusing an encoder-decoder network, was first evaluated using clinically\nrealistic 2-D simulation studies with known ground truth, in the context of\nsegmenting the primary tumor in PET images of patients with lung cancer. The\nevaluation studies demonstrated that the method accurately estimated the\ntumor-fraction areas and significantly outperformed widely used conventional\nmethods, including a U-net-based method, on the task of segmenting the tumor.\nIn addition, the proposed method was relatively insensitive to partial-volume\neffects and yielded reliable tumor segmentation for different clinical-scanner\nconfigurations. The method was then evaluated using clinical images of patients\nwith stage II and III non-small cell lung cancer from ACRIN 6668/RTOG 0235\nmulti-center clinical trial. Here, the results showed that the proposed method\nsignificantly outperformed all other considered methods and yielded accurate\ntumor segmentation on patient images with dice similarity coefficient of 0.82\n(95% CI: 0.78, 0.86). Overall, this study demonstrates the efficacy of the\nproposed method to accurately segment tumors in PET images.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 17:40:04 GMT"}, {"version": "v2", "created": "Sun, 3 Jan 2021 21:56:21 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Liu", "Ziping", ""], ["Mhlanga", "Joyce C.", ""], ["Laforest", "Richard", ""], ["Derenoncourt", "Paul-Robert", ""], ["Siegel", "Barry A.", ""], ["Jha", "Abhinav K.", ""]]}, {"id": "2003.00330", "submitter": "Luis Lamb", "authors": "Luis C. Lamb, Artur Garcez, Marco Gori, Marcelo Prates, Pedro Avelar,\n  Moshe Vardi", "title": "Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and\n  Perspective", "comments": "Updated version, draft of accepted IJCAI2020 Survey Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural-symbolic computing has now become the subject of interest of both\nacademic and industry research laboratories. Graph Neural Networks (GNN) have\nbeen widely used in relational and symbolic domains, with widespread\napplication of GNNs in combinatorial optimization, constraint satisfaction,\nrelational reasoning and other scientific domains. The need for improved\nexplainability, interpretability and trust of AI systems in general demands\nprincipled methodologies, as suggested by neural-symbolic computing. In this\npaper, we review the state-of-the-art on the use of GNNs as a model of\nneural-symbolic computing. This includes the application of GNNs in several\ndomains as well as its relationship to current developments in neural-symbolic\ncomputing.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 18:55:13 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 20:00:26 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 12:14:42 GMT"}, {"version": "v4", "created": "Wed, 11 Mar 2020 20:33:01 GMT"}, {"version": "v5", "created": "Sat, 16 May 2020 20:44:26 GMT"}, {"version": "v6", "created": "Thu, 21 May 2020 17:11:36 GMT"}, {"version": "v7", "created": "Sat, 12 Jun 2021 23:05:33 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lamb", "Luis C.", ""], ["Garcez", "Artur", ""], ["Gori", "Marco", ""], ["Prates", "Marcelo", ""], ["Avelar", "Pedro", ""], ["Vardi", "Moshe", ""]]}, {"id": "2003.00342", "submitter": "Hongzhuo Liang", "authors": "Hongzhuo Liang and Chuangchuang Zhou and Shuang Li and Xiaojian Ma and\n  Norman Hendrich and Timo Gerkmann and Fuchun Sun and Marcus Stoffel and\n  Jianwei Zhang", "title": "Robust Robotic Pouring using Audition and Haptics", "comments": "accepted by IROS2020", "journal-ref": "2020 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS)", "doi": "10.1109/IROS45743.2020.9340859", "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust and accurate estimation of liquid height lies as an essential part of\npouring tasks for service robots. However, vision-based methods often fail in\noccluded conditions while audio-based methods cannot work well in a noisy\nenvironment. We instead propose a multimodal pouring network (MP-Net) that is\nable to robustly predict liquid height by conditioning on both audition and\nhaptics input. MP-Net is trained on a self-collected multimodal pouring\ndataset. This dataset contains 300 robot pouring recordings with audio and\nforce/torque measurements for three types of target containers. We also augment\nthe audio data by inserting robot noise. We evaluated MP-Net on our collected\ndataset and a wide variety of robot experiments. Both network training results\nand robot experiments demonstrate that MP-Net is robust against noise and\nchanges to the task and environment. Moreover, we further combine the predicted\nheight and force data to estimate the shape of the target container.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 20:24:11 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 15:35:11 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Liang", "Hongzhuo", ""], ["Zhou", "Chuangchuang", ""], ["Li", "Shuang", ""], ["Ma", "Xiaojian", ""], ["Hendrich", "Norman", ""], ["Gerkmann", "Timo", ""], ["Sun", "Fuchun", ""], ["Stoffel", "Marcus", ""], ["Zhang", "Jianwei", ""]]}, {"id": "2003.00344", "submitter": "Ruwan Wickramarachchi", "authors": "Ruwan Wickramarachchi, Cory Henson, Amit Sheth", "title": "An Evaluation of Knowledge Graph Embeddings for Autonomous Driving Data:\n  Experience and Practice", "comments": "11 pages, To appear in AAAI 2020 Spring Symposium on Combining\n  Machine Learning and Knowledge Engineering in Practice (AAAI-MAKE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The autonomous driving (AD) industry is exploring the use of knowledge graphs\n(KGs) to manage the vast amount of heterogeneous data generated from vehicular\nsensors. The various types of equipped sensors include video, LIDAR and RADAR.\nScene understanding is an important topic in AD which requires consideration of\nvarious aspects of a scene, such as detected objects, events, time and\nlocation. Recent work on knowledge graph embeddings (KGEs) - an approach that\nfacilitates neuro-symbolic fusion - has shown to improve the predictive\nperformance of machine learning models. With the expectation that\nneuro-symbolic fusion through KGEs will improve scene understanding, this\nresearch explores the generation and evaluation of KGEs for autonomous driving\ndata. We also present an investigation of the relationship between the level of\ninformational detail in a KG and the quality of its derivative embeddings. By\nsystematically evaluating KGEs along four dimensions -- i.e. quality metrics,\nKG informational detail, algorithms, and datasets -- we show that (1) higher\nlevels of informational detail in KGs lead to higher quality embeddings, (2)\ntype and relation semantics are better captured by the semantic transitional\ndistance-based TransE algorithm, and (3) some metrics, such as coherence\nmeasure, may not be suitable for intrinsically evaluating KGEs in this domain.\nAdditionally, we also present an (early) investigation of the usefulness of\nKGEs for two use-cases in the AD domain.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 20:33:48 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Wickramarachchi", "Ruwan", ""], ["Henson", "Cory", ""], ["Sheth", "Amit", ""]]}, {"id": "2003.00359", "submitter": "Xiao Xu", "authors": "Xiao Xu, Fang Dong, Yanghua Li, Shaojian He, Xin Li", "title": "Contextual-Bandit Based Personalized Recommendation with Time-Varying\n  User Interests", "comments": "Accepted by AAAI 20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A contextual bandit problem is studied in a highly non-stationary\nenvironment, which is ubiquitous in various recommender systems due to the\ntime-varying interests of users. Two models with disjoint and hybrid payoffs\nare considered to characterize the phenomenon that users' preferences towards\ndifferent items vary differently over time. In the disjoint payoff model, the\nreward of playing an arm is determined by an arm-specific preference vector,\nwhich is piecewise-stationary with asynchronous and distinct changes across\ndifferent arms. An efficient learning algorithm that is adaptive to abrupt\nreward changes is proposed and theoretical regret analysis is provided to show\nthat a sublinear scaling of regret in the time length $T$ is achieved. The\nalgorithm is further extended to a more general setting with hybrid payoffs\nwhere the reward of playing an arm is determined by both an arm-specific\npreference vector and a joint coefficient vector shared by all arms. Empirical\nexperiments are conducted on real-world datasets to verify the advantages of\nthe proposed learning algorithms against baseline ones in both settings.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 22:59:15 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Xu", "Xiao", ""], ["Dong", "Fang", ""], ["Li", "Yanghua", ""], ["He", "Shaojian", ""], ["Li", "Xin", ""]]}, {"id": "2003.00387", "submitter": "Shizhe Chen", "authors": "Shizhe Chen, Qin Jin, Peng Wang, Qi Wu", "title": "Say As You Wish: Fine-grained Control of Image Caption Generation with\n  Abstract Scene Graphs", "comments": "To be appeared in CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are able to describe image contents with coarse to fine details as\nthey wish. However, most image captioning models are intention-agnostic which\ncan not generate diverse descriptions according to different user intentions\ninitiatively. In this work, we propose the Abstract Scene Graph (ASG) structure\nto represent user intention in fine-grained level and control what and how\ndetailed the generated description should be. The ASG is a directed graph\nconsisting of three types of \\textbf{abstract nodes} (object, attribute,\nrelationship) grounded in the image without any concrete semantic labels. Thus\nit is easy to obtain either manually or automatically. From the ASG, we propose\na novel ASG2Caption model, which is able to recognise user intentions and\nsemantics in the graph, and therefore generate desired captions according to\nthe graph structure. Our model achieves better controllability conditioning on\nASGs than carefully designed baselines on both VisualGenome and MSCOCO\ndatasets. It also significantly improves the caption diversity via\nautomatically sampling diverse ASGs as control signals.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 03:34:07 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Shizhe", ""], ["Jin", "Qin", ""], ["Wang", "Peng", ""], ["Wu", "Qi", ""]]}, {"id": "2003.00392", "submitter": "Shizhe Chen", "authors": "Shizhe Chen, Yida Zhao, Qin Jin, Qi Wu", "title": "Fine-grained Video-Text Retrieval with Hierarchical Graph Reasoning", "comments": "To be appeared in CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-modal retrieval between videos and texts has attracted growing\nattentions due to the rapid emergence of videos on the web. The current\ndominant approach for this problem is to learn a joint embedding space to\nmeasure cross-modal similarities. However, simple joint embeddings are\ninsufficient to represent complicated visual and textual details, such as\nscenes, objects, actions and their compositions. To improve fine-grained\nvideo-text retrieval, we propose a Hierarchical Graph Reasoning (HGR) model,\nwhich decomposes video-text matching into global-to-local levels. To be\nspecific, the model disentangles texts into hierarchical semantic graph\nincluding three levels of events, actions, entities and relationships across\nlevels. Attention-based graph reasoning is utilized to generate hierarchical\ntextual embeddings, which can guide the learning of diverse and hierarchical\nvideo representations. The HGR model aggregates matchings from different\nvideo-text levels to capture both global and local details. Experimental\nresults on three video-text datasets demonstrate the advantages of our model.\nSuch hierarchical decomposition also enables better generalization across\ndatasets and improves the ability to distinguish fine-grained semantic\ndifferences.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 03:44:19 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Shizhe", ""], ["Zhao", "Yida", ""], ["Jin", "Qin", ""], ["Wu", "Qi", ""]]}, {"id": "2003.00393", "submitter": "Denis Gudovskiy", "authors": "Denis Gudovskiy, Alec Hodgkinson, Takuya Yamaguchi, Sotaro Tsukizawa", "title": "Deep Active Learning for Biased Datasets via Fisher Kernel\n  Self-Supervision", "comments": "Accepted to CVPR 2020. Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning (AL) aims to minimize labeling efforts for data-demanding\ndeep neural networks (DNNs) by selecting the most representative data points\nfor annotation. However, currently used methods are ill-equipped to deal with\nbiased data. The main motivation of this paper is to consider a realistic\nsetting for pool-based semi-supervised AL, where the unlabeled collection of\ntrain data is biased. We theoretically derive an optimal acquisition function\nfor AL in this setting. It can be formulated as distribution shift minimization\nbetween unlabeled train data and weakly-labeled validation dataset. To\nimplement such acquisition function, we propose a low-complexity method for\nfeature density matching using self-supervised Fisher kernel (FK) as well as\nseveral novel pseudo-label estimators. Our FK-based method outperforms\nstate-of-the-art methods on MNIST, SVHN, and ImageNet classification while\nrequiring only 1/10th of processing. The conducted experiments show at least\n40% drop in labeling efforts for the biased class-imbalanced data compared to\nexisting methods.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 03:56:32 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Gudovskiy", "Denis", ""], ["Hodgkinson", "Alec", ""], ["Yamaguchi", "Takuya", ""], ["Tsukizawa", "Sotaro", ""]]}, {"id": "2003.00400", "submitter": "Lingfeng Tao", "authors": "Lingfeng Tao, Michael Bowman, Jiucai Zhang, Xiaoli Zhang", "title": "Learn Task First or Learn Human Partner First: A Hierarchical Task\n  Decomposition Method for Human-Robot Cooperation", "comments": "Submitted to SMC2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying Deep Reinforcement Learning (DRL) to Human-Robot Cooperation (HRC)\nin dynamic control problems is promising yet challenging as the robot needs to\nlearn the dynamics of the controlled system and dynamics of the human partner.\nIn existing research, the robot powered by DRL adopts coupled observation of\nthe environment and the human partner to learn both dynamics simultaneously.\nHowever, such a learning strategy is limited in terms of learning efficiency\nand team performance. This work proposes a novel task decomposition method with\na hierarchical reward mechanism that enables the robot to learn the\nhierarchical dynamic control task separately from learning the human partner's\nbehavior. The method is validated with a hierarchical control task in a\nsimulated environment with human subject experiments. Our method also provides\ninsight into the design of the learning strategy for HRC. The results show that\nthe robot should learn the task first to achieve higher team performance and\nlearn the human first to achieve higher learning efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 04:41:49 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 15:37:54 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Tao", "Lingfeng", ""], ["Bowman", "Michael", ""], ["Zhang", "Jiucai", ""], ["Zhang", "Xiaoli", ""]]}, {"id": "2003.00409", "submitter": "Haokun Li", "authors": "Haokun Li and Bican Xia", "title": "Solving Satisfiability of Polynomial Formulas By Sample-Cell Projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new algorithm for deciding the satisfiability of polynomial formulas over\nthe reals is proposed. The key point of the algorithm is a new projection\noperator, called sample-cell projection operator, custom-made for\nConflict-Driven Clause Learning (CDCL)-style search. Although the new operator\nis also a CAD (Cylindrical Algebraic Decomposition)-like projection operator\nwhich computes the cell (not necessarily cylindrical) containing a given sample\nsuch that each polynomial from the problem is sign-invariant on the cell, it is\nof singly exponential time complexity. The sample-cell projection operator can\nefficiently guide CDCL-style search away from conflicting states. Experiments\nshow the effectiveness of the new algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 05:36:09 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 03:01:35 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Li", "Haokun", ""], ["Xia", "Bican", ""]]}, {"id": "2003.00411", "submitter": "Md Zahidul Islam PhD", "authors": "Mahmood A. Khan, Md Zahidul Islam, Mohsin Hafeez", "title": "Data Pre-Processing and Evaluating the Performance of Several Data\n  Mining Methods for Predicting Irrigation Water Requirement", "comments": "This 13-page paper is a slightly modified version of our original\n  conference paper published in the 10th Australasian Data Mining Conference\n  2012. We then submitted the paper to the Journal of Research and Practice in\n  IT (JRPIT) as an invited paper. However, despite the acceptance for\n  publication the paper was never published by JRPIT since the journal\n  discontinued after it had accepted our paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent drought and population growth are planting unprecedented demand for\nthe use of available limited water resources. Irrigated agriculture is one of\nthe major consumers of freshwater. A large amount of water in irrigated\nagriculture is wasted due to poor water management practices. To improve water\nmanagement in irrigated areas, models for estimation of future water\nrequirements are needed. Developing a model for forecasting irrigation water\ndemand can improve water management practices and maximise water productivity.\nData mining can be used effectively to build such models.\n  In this study, we prepare a dataset containing information on suitable\nattributes for forecasting irrigation water demand. The data is obtained from\nthree different sources namely meteorological data, remote sensing images and\nwater delivery statements. In order to make the prepared dataset useful for\ndemand forecasting and pattern extraction, we pre-process the dataset using a\nnovel approach based on a combination of irrigation and data mining knowledge.\nWe then apply and compare the effectiveness of different data mining methods\nnamely decision tree (DT), artificial neural networks (ANNs), systematically\ndeveloped forest (SysFor) for multiple trees, support vector machine (SVM),\nlogistic regression, and the traditional Evapotranspiration (ETc) methods and\nevaluate the performance of these models to predict irrigation water demand.\nOur experimental results indicate the usefulness of data pre-processing and the\neffectiveness of different classifiers. Among the six methods we used, SysFor\nproduces the best prediction with 97.5% accuracy followed by a decision tree\nwith 96% and ANN with 95% respectively by closely matching the predictions with\nactual water usage. Therefore, we recommend using SysFor and DT models for\nirrigation water demand forecasting.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 05:42:04 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Khan", "Mahmood A.", ""], ["Islam", "Md Zahidul", ""], ["Hafeez", "Mohsin", ""]]}, {"id": "2003.00418", "submitter": "Rudrabha Mukhopadhyay", "authors": "Prajwal K R, Rudrabha Mukhopadhyay, Jerin Philip, Abhishek Jha, Vinay\n  Namboodiri, C.V. Jawahar", "title": "Towards Automatic Face-to-Face Translation", "comments": "9 pages (including references), 5 figures, Published in ACM\n  Multimedia, 2019", "journal-ref": "MM '19: Proceedings of the 27th ACM International Conference on\n  Multimedia; October 2019; Pages 1428-1436", "doi": "10.1145/3343031.3351066", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM cs.SD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In light of the recent breakthroughs in automatic machine translation\nsystems, we propose a novel approach that we term as \"Face-to-Face\nTranslation\". As today's digital communication becomes increasingly visual, we\nargue that there is a need for systems that can automatically translate a video\nof a person speaking in language A into a target language B with realistic lip\nsynchronization. In this work, we create an automatic pipeline for this problem\nand demonstrate its impact on multiple real-world applications. First, we build\na working speech-to-speech translation system by bringing together multiple\nexisting modules from speech and language. We then move towards \"Face-to-Face\nTranslation\" by incorporating a novel visual module, LipGAN for generating\nrealistic talking faces from the translated audio. Quantitative evaluation of\nLipGAN on the standard LRW test set shows that it significantly outperforms\nexisting approaches across all standard metrics. We also subject our\nFace-to-Face Translation pipeline, to multiple human evaluations and show that\nit can significantly improve the overall user experience for consuming and\ninteracting with multimodal content across languages. Code, models and demo\nvideo are made publicly available.\n  Demo video: https://www.youtube.com/watch?v=aHG6Oei8jF0\n  Code and models: https://github.com/Rudrabha/LipGAN\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 06:42:43 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["R", "Prajwal K", ""], ["Mukhopadhyay", "Rudrabha", ""], ["Philip", "Jerin", ""], ["Jha", "Abhishek", ""], ["Namboodiri", "Vinay", ""], ["Jawahar", "C. V.", ""]]}, {"id": "2003.00431", "submitter": "Kamran Alipour", "authors": "Kamran Alipour, Jurgen P. Schulze, Yi Yao, Avi Ziskind, Giedrius\n  Burachas", "title": "A Study on Multimodal and Interactive Explanations for Visual Question\n  Answering", "comments": "http://ceur-ws.org/Vol-2560/paper44.pdf", "journal-ref": "Proceedings of the Workshop on Artificial Intelligence Safety\n  (SafeAI 2020) co-located with 34th AAAI Conference on Artificial Intelligence\n  (AAAI 2020), New York, USA, Feb 7, 2020", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability and interpretability of AI models is an essential factor\naffecting the safety of AI. While various explainable AI (XAI) approaches aim\nat mitigating the lack of transparency in deep networks, the evidence of the\neffectiveness of these approaches in improving usability, trust, and\nunderstanding of AI systems are still missing. We evaluate multimodal\nexplanations in the setting of a Visual Question Answering (VQA) task, by\nasking users to predict the response accuracy of a VQA agent with and without\nexplanations. We use between-subjects and within-subjects experiments to probe\nexplanation effectiveness in terms of improving user prediction accuracy,\nconfidence, and reliance, among other factors. The results indicate that the\nexplanations help improve human prediction accuracy, especially in trials when\nthe VQA system's answer is inaccurate. Furthermore, we introduce active\nattention, a novel method for evaluating causal attentional effects through\nintervention by editing attention maps. User explanation ratings are strongly\ncorrelated with human prediction accuracy and suggest the efficacy of these\nexplanations in human-machine AI collaboration tasks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 07:54:01 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Alipour", "Kamran", ""], ["Schulze", "Jurgen P.", ""], ["Yao", "Yi", ""], ["Ziskind", "Avi", ""], ["Burachas", "Giedrius", ""]]}, {"id": "2003.00439", "submitter": "Yang Li", "authors": "Chengjun Li and Yang Li", "title": "Differential Evolution with Individuals Redistribution for Real\n  Parameter Single Objective Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential Evolution (DE) is quite powerful for real parameter single\nobjective optimization. However, the ability of extending or changing search\narea when falling into a local optimum is still required to be developed in DE\nfor accommodating extremely complicated fitness landscapes with a huge number\nof local optima. We propose a new flow of DE, termed DE with individuals\nredistribution, in which a process of individuals redistribution will be called\nwhen progress on fitness is low for generations. In such a process, mutation\nand crossover are standardized, while trial vectors are all kept in selection.\nOnce diversity exceeds a predetermined threshold, our opposition replacement is\nexecuted, then algorithm behavior returns to original mode. In our experiments\nbased on two benchmark test suites, we apply individuals redistribution in ten\nDE algorithms. Versions of the ten DE algorithms based on individuals\nredistribution are compared with not only original version but also version\nbased on complete restart, where individuals redistribution and complete\nrestart are based on the same entry criterion. Experimental results indicate\nthat, for most of the DE algorithms, version based on individuals\nredistribution performs better than both original version and version based on\ncomplete restart.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 08:40:52 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Li", "Chengjun", ""], ["Li", "Yang", ""]]}, {"id": "2003.00443", "submitter": "Xin Eric Wang", "authors": "Xin Eric Wang, Vihan Jain, Eugene Ie, William Yang Wang, Zornitsa\n  Kozareva, Sujith Ravi", "title": "Environment-agnostic Multitask Learning for Natural Language Grounded\n  Navigation", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent research efforts enable study for natural language grounded navigation\nin photo-realistic environments, e.g., following natural language instructions\nor dialog. However, existing methods tend to overfit training data in seen\nenvironments and fail to generalize well in previously unseen environments. To\nclose the gap between seen and unseen environments, we aim at learning a\ngeneralized navigation model from two novel perspectives: (1) we introduce a\nmultitask navigation model that can be seamlessly trained on both\nVision-Language Navigation (VLN) and Navigation from Dialog History (NDH)\ntasks, which benefits from richer natural language guidance and effectively\ntransfers knowledge across tasks; (2) we propose to learn environment-agnostic\nrepresentations for the navigation policy that are invariant among the\nenvironments seen during training, thus generalizing better on unseen\nenvironments. Extensive experiments show that environment-agnostic multitask\nlearning significantly reduces the performance gap between seen and unseen\nenvironments, and the navigation agent trained so outperforms baselines on\nunseen environments by 16% (relative measure on success rate) on VLN and 120%\n(goal progress) on NDH. Our submission to the CVDN leaderboard establishes a\nnew state-of-the-art for the NDH task on the holdout test set. Code is\navailable at https://github.com/google-research/valan.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 09:06:31 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 22:06:54 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 18:20:39 GMT"}, {"version": "v4", "created": "Fri, 17 Jul 2020 23:54:02 GMT"}, {"version": "v5", "created": "Tue, 21 Jul 2020 02:54:38 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Wang", "Xin Eric", ""], ["Jain", "Vihan", ""], ["Ie", "Eugene", ""], ["Wang", "William Yang", ""], ["Kozareva", "Zornitsa", ""], ["Ravi", "Sujith", ""]]}, {"id": "2003.00475", "submitter": "Jing Li", "authors": "Jing Li, Suiyi Ling, Junle Wang, Zhi Li, Patrick Le Callet", "title": "GPM: A Generic Probabilistic Model to Recover Annotator's Behavior and\n  Ground Truth Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the big data era, data labeling can be obtained through crowdsourcing.\nNevertheless, the obtained labels are generally noisy, unreliable or even\nadversarial. In this paper, we propose a probabilistic graphical annotation\nmodel to infer the underlying ground truth and annotator's behavior. To\naccommodate both discrete and continuous application scenarios (e.g.,\nclassifying scenes vs. rating videos on a Likert scale), the underlying ground\ntruth is considered following a distribution rather than a single value. In\nthis way, the reliable but potentially divergent opinions from \"good\"\nannotators can be recovered. The proposed model is able to identify whether an\nannotator has worked diligently towards the task during the labeling procedure,\nwhich could be used for further selection of qualified annotators. Our model\nhas been tested on both simulated data and real-world data, where it always\nshows superior performance than the other state-of-the-art models in terms of\naccuracy and robustness.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 12:14:52 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Li", "Jing", ""], ["Ling", "Suiyi", ""], ["Wang", "Junle", ""], ["Li", "Zhi", ""], ["Callet", "Patrick Le", ""]]}, {"id": "2003.00476", "submitter": "Jumabek Alikhanov", "authors": "Azizjon Meliboev, Jumabek Alikhanov, Wooseong Kim", "title": "1D CNN Based Network Intrusion Detection with Normalization on\n  Imbalanced Data", "comments": "Need more polishing", "journal-ref": "IEEE ICAIIC 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion detection system (IDS) plays an essential role in computer networks\nprotecting computing resources and data from outside attacks. Recent IDS faces\nchallenges improving flexibility and efficiency of the IDS for unexpected and\nunpredictable attacks. Deep neural network (DNN) is considered popularly for\ncomplex systems to abstract features and learn as a machine learning technique.\nIn this paper, we propose a deep learning approach for developing the efficient\nand flexible IDS using one-dimensional Convolutional Neural Network (1D-CNN).\nTwo-dimensional CNN methods have shown remarkable performance in detecting\nobjects of images in computer vision area. Meanwhile, the 1D-CNN can be used\nfor supervised learning on time-series data. We establish a machine learning\nmodel based on the 1D-CNN by serializing Transmission Control Protocol/Internet\nProtocol (TCP/IP) packets in a predetermined time range as an invasion Internet\ntraffic model for the IDS, where normal and abnormal network traffics are\ncategorized and labeled for supervised learning in the 1D-CNN. We evaluated our\nmodel on UNSW\\_NB15 IDS dataset to show the effectiveness of our method. For\ncomparison study in performance, machine learning-based Random Forest (RF) and\nSupport Vector Machine (SVM) models in addition to the 1D-CNN with various\nnetwork parameters and architecture are exploited. In each experiment, the\nmodels are run up to 200 epochs with a learning rate in 0.0001 on imbalanced\nand balanced data. 1D-CNN and its variant architectures have outperformed\ncompared to the classical machine learning classifiers. This is mainly due to\nthe reason that CNN has the capability to extract high-level feature\nrepresentations that represent the abstract form of low-level feature sets of\nnetwork traffic connections.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 12:23:46 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 09:44:56 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Meliboev", "Azizjon", ""], ["Alikhanov", "Jumabek", ""], ["Kim", "Wooseong", ""]]}, {"id": "2003.00504", "submitter": "Lei Tai", "authors": "Yongjian Chen and Lei Tai and Kai Sun and Mingyang Li", "title": "MonoPair: Monocular 3D Object Detection Using Pairwise Spatial\n  Relationships", "comments": "CVPR 2020 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monocular 3D object detection is an essential component in autonomous driving\nwhile challenging to solve, especially for those occluded samples which are\nonly partially visible. Most detectors consider each 3D object as an\nindependent training target, inevitably resulting in a lack of useful\ninformation for occluded samples. To this end, we propose a novel method to\nimprove the monocular 3D object detection by considering the relationship of\npaired samples. This allows us to encode spatial constraints for\npartially-occluded objects from their adjacent neighbors. Specifically, the\nproposed detector computes uncertainty-aware predictions for object locations\nand 3D distances for the adjacent object pairs, which are subsequently jointly\noptimized by nonlinear least squares. Finally, the one-stage uncertainty-aware\nprediction structure and the post-optimization module are dedicatedly\nintegrated for ensuring the run-time efficiency. Experiments demonstrate that\nour method yields the best performance on KITTI 3D detection benchmark, by\noutperforming state-of-the-art competitors by wide margins, especially for the\nhard samples.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 15:37:48 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Yongjian", ""], ["Tai", "Lei", ""], ["Sun", "Kai", ""], ["Li", "Mingyang", ""]]}, {"id": "2003.00505", "submitter": "Lichao Sun", "authors": "Lichao Sun, Yingbo Zhou, Philip S. Yu, Caiming Xiong", "title": "Differentially Private Deep Learning with Smooth Sensitivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring the privacy of sensitive data used to train modern machine learning\nmodels is of paramount importance in many areas of practice. One approach to\nstudy these concerns is through the lens of differential privacy. In this\nframework, privacy guarantees are generally obtained by perturbing models in\nsuch a way that specifics of data used to train the model are made ambiguous. A\nparticular instance of this approach is through a \"teacher-student\" framework,\nwherein the teacher, who owns the sensitive data, provides the student with\nuseful, but noisy, information, hopefully allowing the student model to perform\nwell on a given task without access to particular features of the sensitive\ndata. Because stronger privacy guarantees generally involve more significant\nperturbation on the part of the teacher, deploying existing frameworks\nfundamentally involves a trade-off between student's performance and privacy\nguarantee. One of the most important techniques used in previous works involves\nan ensemble of teacher models, which return information to a student based on a\nnoisy voting procedure. In this work, we propose a novel voting mechanism with\nsmooth sensitivity, which we call Immutable Noisy ArgMax, that, under certain\nconditions, can bear very large random noising from the teacher without\naffecting the useful information transferred to the student.\n  Compared with previous work, our approach improves over the state-of-the-art\nmethods on all measures, and scale to larger tasks with both better performance\nand stronger privacy ($\\epsilon \\approx 0$). This new proposed framework can be\napplied with any machine learning models, and provides an appealing solution\nfor tasks that requires training on a large amount of data.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 15:38:00 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Sun", "Lichao", ""], ["Zhou", "Yingbo", ""], ["Yu", "Philip S.", ""], ["Xiong", "Caiming", ""]]}, {"id": "2003.00605", "submitter": "Jun Han Mr", "authors": "Jun Han, Fan Ding, Xianglong Liu, Lorenzo Torresani, Jian Peng, Qiang\n  Liu", "title": "Stein Variational Inference for Discrete Distributions", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based approximate inference methods, such as Stein variational\ngradient descent (SVGD), provide simple and general-purpose inference engines\nfor differentiable continuous distributions. However, existing forms of SVGD\ncannot be directly applied to discrete distributions. In this work, we fill\nthis gap by proposing a simple yet general framework that transforms discrete\ndistributions to equivalent piecewise continuous distributions, on which the\ngradient-free SVGD is applied to perform efficient approximate inference. The\nempirical results show that our method outperforms traditional algorithms such\nas Gibbs sampling and discontinuous Hamiltonian Monte Carlo on various\nchallenging benchmarks of discrete graphical models. We demonstrate that our\nmethod provides a promising tool for learning ensembles of binarized neural\nnetwork (BNN), outperforming other widely used ensemble methods on learning\nbinarized AlexNet on CIFAR-10 dataset. In addition, such transform can be\nstraightforwardly employed in gradient-free kernelized Stein discrepancy to\nperform goodness-of-fit (GOF) test on discrete distributions. Our proposed\nmethod outperforms existing GOF test methods for intractable discrete\ndistributions.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 22:45:41 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Han", "Jun", ""], ["Ding", "Fan", ""], ["Liu", "Xianglong", ""], ["Torresani", "Lorenzo", ""], ["Peng", "Jian", ""], ["Liu", "Qiang", ""]]}, {"id": "2003.00613", "submitter": "Hua Wei", "authors": "Hua Wei, Dongkuan Xu, Junjie Liang, Zhenhui Li", "title": "How Do We Move: Modeling Human Movement with System Dynamics", "comments": "Accepted by AAAI 2021, Appendices included. 12 pages, 8 figures. in\n  Proceedings of the Thirty-Fifth AAAI Conference on Artificial Intelligence\n  (AAAI'21), Feb 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling how human moves in the space is useful for policy-making in\ntransportation, public safety, and public health. Human movements can be viewed\nas a dynamic process that human transits between states (\\eg, locations) over\ntime. In the human world where intelligent agents like humans or vehicles with\nhuman drivers play an important role, the states of agents mostly describe\nhuman activities, and the state transition is influenced by both the human\ndecisions and physical constraints from the real-world system (\\eg, agents need\nto spend time to move over a certain distance). Therefore, the modeling of\nstate transition should include the modeling of the agent's decision process\nand the physical system dynamics. In this paper, we propose \\ours to model\nstate transition in human movement from a novel perspective, by learning the\ndecision model and integrating the system dynamics. \\ours learns the human\nmovement with Generative Adversarial Imitation Learning and integrates the\nstochastic constraints from system dynamics in the learning process. To the\nbest of our knowledge, we are the first to learn to model the state transition\nof moving agents with system dynamics. In extensive experiments on real-world\ndatasets, we demonstrate that the proposed method can generate trajectories\nsimilar to real-world ones, and outperform the state-of-the-art methods in\npredicting the next location and generating long-term future trajectories.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 23:43:22 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 13:28:03 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 13:24:48 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Wei", "Hua", ""], ["Xu", "Dongkuan", ""], ["Liang", "Junjie", ""], ["Li", "Zhenhui", ""]]}, {"id": "2003.00631", "submitter": "Bao Wang", "authors": "Thu Dinh, Bao Wang, Andrea L. Bertozzi, and Stanley J. Osher", "title": "Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism\n  Principled Robust Deep Neural Nets", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural nets (DNNs) compression is crucial for adaptation to mobile\ndevices. Though many successful algorithms exist to compress naturally trained\nDNNs, developing efficient and stable compression algorithms for robustly\ntrained DNNs remains widely open. In this paper, we focus on a co-design of\nefficient DNN compression algorithms and sparse neural architectures for robust\nand accurate deep learning. Such a co-design enables us to advance the goal of\naccommodating both sparsity and robustness. With this objective in mind, we\nleverage the relaxed augmented Lagrangian based algorithms to prune the weights\nof adversarially trained DNNs, at both structured and unstructured levels.\nUsing a Feynman-Kac formalism principled robust and sparse DNNs, we can at\nleast double the channel sparsity of the adversarially trained ResNet20 for\nCIFAR10 classification, meanwhile, improve the natural accuracy by $8.69$\\% and\nthe robust accuracy under the benchmark $20$ iterations of IFGSM attack by\n$5.42$\\%. The code is available at\n\\url{https://github.com/BaoWangMath/rvsm-rgsm-admm}.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 02:18:43 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Dinh", "Thu", ""], ["Wang", "Bao", ""], ["Bertozzi", "Andrea L.", ""], ["Osher", "Stanley J.", ""]]}, {"id": "2003.00635", "submitter": "Hesham Mostafa", "authors": "Hesham Mostafa, Marcel Nassar", "title": "Permutohedral-GCN: Graph Convolutional Networks with Global Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) update a node's feature vector by\naggregating features from its neighbors in the graph. This ignores potentially\nuseful contributions from distant nodes. Identifying such useful distant\ncontributions is challenging due to scalability issues (too many nodes can\npotentially contribute) and oversmoothing (aggregating features from too many\nnodes risks swamping out relevant information and may result in nodes having\ndifferent labels but indistinguishable features). We introduce a global\nattention mechanism where a node can selectively attend to, and aggregate\nfeatures from, any other node in the graph. The attention coefficients depend\non the Euclidean distance between learnable node embeddings, and we show that\nthe resulting attention-based global aggregation scheme is analogous to\nhigh-dimensional Gaussian filtering. This makes it possible to use efficient\napproximate Gaussian filtering techniques to implement our attention-based\nglobal aggregation scheme. By employing an approximate filtering method based\non the permutohedral lattice, the time complexity of our proposed global\naggregation scheme only grows linearly with the number of nodes. The resulting\nGCNs, which we term permutohedral-GCNs, are differentiable and trained\nend-to-end, and they achieve state of the art performance on several node\nclassification benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 02:44:52 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Mostafa", "Hesham", ""], ["Nassar", "Marcel", ""]]}, {"id": "2003.00683", "submitter": "Rupam Acharyya", "authors": "Rupam Acharyya, Shouman Das, Ankani Chattoraj, Oishani Sengupta, Md\n  Iftekar Tanveer", "title": "Detection and Mitigation of Bias in Ted Talk Ratings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unbiased data collection is essential to guaranteeing fairness in artificial\nintelligence models. Implicit bias, a form of behavioral conditioning that\nleads us to attribute predetermined characteristics to members of certain\ngroups and informs the data collection process. This paper quantifies implicit\nbias in viewer ratings of TEDTalks, a diverse social platform assessing social\nand professional performance, in order to present the correlations of different\nkinds of bias across sensitive attributes. Although the viewer ratings of these\nvideos should purely reflect the speaker's competence and skill, our analysis\nof the ratings demonstrates the presence of overwhelming and predominant\nimplicit bias with respect to race and gender. In our paper, we present\nstrategies to detect and mitigate bias that are critical to removing unfairness\nin AI.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 06:13:24 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Acharyya", "Rupam", ""], ["Das", "Shouman", ""], ["Chattoraj", "Ankani", ""], ["Sengupta", "Oishani", ""], ["Tanveer", "Md Iftekar", ""]]}, {"id": "2003.00688", "submitter": "David Krueger", "authors": "David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang,\n  Jonathan Binas, Dinghuai Zhang, Remi Le Priol, Aaron Courville", "title": "Out-of-Distribution Generalization via Risk Extrapolation (REx)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional shift is one of the major obstacles when transferring machine\nlearning prediction systems from the lab to the real world. To tackle this\nproblem, we assume that variation across training domains is representative of\nthe variation we might encounter at test time, but also that shifts at test\ntime may be more extreme in magnitude. In particular, we show that reducing\ndifferences in risk across training domains can reduce a model's sensitivity to\na wide range of extreme distributional shifts, including the challenging\nsetting where the input contains both causal and anti-causal elements. We\nmotivate this approach, Risk Extrapolation (REx), as a form of robust\noptimization over a perturbation set of extrapolated domains (MM-REx), and\npropose a penalty on the variance of training risks (V-REx) as a simpler\nvariant. We prove that variants of REx can recover the causal mechanisms of the\ntargets, while also providing some robustness to changes in the input\ndistribution (\"covariate shift\"). By appropriately trading-off robustness to\ncausally induced distributional shifts and covariate shift, REx is able to\noutperform alternative methods such as Invariant Risk Minimization in\nsituations where these types of shift co-occur.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 06:29:50 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 04:15:23 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2020 22:57:37 GMT"}, {"version": "v4", "created": "Thu, 10 Dec 2020 21:46:28 GMT"}, {"version": "v5", "created": "Thu, 25 Feb 2021 17:53:07 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Krueger", "David", ""], ["Caballero", "Ethan", ""], ["Jacobsen", "Joern-Henrik", ""], ["Zhang", "Amy", ""], ["Binas", "Jonathan", ""], ["Zhang", "Dinghuai", ""], ["Priol", "Remi Le", ""], ["Courville", "Aaron", ""]]}, {"id": "2003.00696", "submitter": "Yurui Ren", "authors": "Yurui Ren, Xiaoming Yu, Junming Chen, Thomas H. Li, Ge Li", "title": "Deep Image Spatial Transformation for Person Image Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pose-guided person image generation is to transform a source person image to\na target pose. This task requires spatial manipulations of source data.\nHowever, Convolutional Neural Networks are limited by the lack of ability to\nspatially transform the inputs. In this paper, we propose a differentiable\nglobal-flow local-attention framework to reassemble the inputs at the feature\nlevel. Specifically, our model first calculates the global correlations between\nsources and targets to predict flow fields. Then, the flowed local patch pairs\nare extracted from the feature maps to calculate the local attention\ncoefficients. Finally, we warp the source features using a content-aware\nsampling method with the obtained local attention coefficients. The results of\nboth subjective and objective experiments demonstrate the superiority of our\nmodel. Besides, additional results in video animation and view synthesis show\nthat our model is applicable to other tasks requiring spatial transformation.\nOur source code is available at\nhttps://github.com/RenYurui/Global-Flow-Local-Attention.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 07:31:00 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 09:42:02 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Ren", "Yurui", ""], ["Yu", "Xiaoming", ""], ["Chen", "Junming", ""], ["Li", "Thomas H.", ""], ["Li", "Ge", ""]]}, {"id": "2003.00703", "submitter": "Jianglei Han", "authors": "Jianglei Han, Jing Li, Aixin Sun", "title": "UFTR: A Unified Framework for Ticket Routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Corporations today face increasing demands for the timely and effective\ndelivery of customer service. This creates the need for a robust and accurate\nautomated solution to what is formally known as the ticket routing problem.\nThis task is to match each unresolved service incident, or \"ticket\", to the\nright group of service experts. Existing studies divide the task into two\nindependent subproblems - initial group assignment and inter-group transfer.\nHowever, our study addresses both subproblems jointly using an end-to-end\nmodeling approach. We first performed a preliminary analysis of half a million\narchived tickets to uncover relevant features. Then, we devised the UFTR, a\nUnified Framework for Ticket Routing using four types of features (derived from\ntickets, groups, and their interactions). In our experiments, we implemented\ntwo ranking models with the UFTR. Our models outperform baselines on three\nrouting metrics. Furthermore, a post-hoc analysis reveals that this superior\nperformance can largely be attributed to the features that capture the\nassociations between ticket assignment and group assignment. In short, our\nresults demonstrate that the UFTR is a superior solution to the ticket routing\nproblem because it takes into account previously unexploited interrelationships\nbetween the group assignment and group transfer problems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 08:01:14 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Han", "Jianglei", ""], ["Li", "Jing", ""], ["Sun", "Aixin", ""]]}, {"id": "2003.00708", "submitter": "Gaurav Verma", "authors": "Gaurav Verma, Vishwa Vinay, Sahil Bansal, Shashank Oberoi, Makkunda\n  Sharma, Prakhar Gupta", "title": "Using Image Captions and Multitask Learning for Recommending Query\n  Reformulations", "comments": "Accepted as a full paper at ECIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive search sessions often contain multiple queries, where the user\nsubmits a reformulated version of the previous query in response to the\noriginal results. We aim to enhance the query recommendation experience for a\ncommercial image search engine. Our proposed methodology incorporates current\nstate-of-the-art practices from relevant literature -- the use of\ngeneration-based sequence-to-sequence models that capture session context, and\na multitask architecture that simultaneously optimizes the ranking of results.\nWe extend this setup by driving the learning of such a model with captions of\nclicked images as the target, instead of using the subsequent query within the\nsession. Since these captions tend to be linguistically richer, the\nreformulation mechanism can be seen as assistance to construct more descriptive\nqueries. In addition, via the use of a pairwise loss for the secondary ranking\ntask, we show that the generated reformulations are more diverse.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 08:22:46 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Verma", "Gaurav", ""], ["Vinay", "Vishwa", ""], ["Bansal", "Sahil", ""], ["Oberoi", "Shashank", ""], ["Sharma", "Makkunda", ""], ["Gupta", "Prakhar", ""]]}, {"id": "2003.00719", "submitter": "Nicolas Heist", "authors": "Nicolas Heist, Sven Hertling, Daniel Ringler and Heiko Paulheim", "title": "Knowledge Graphs on the Web -- an Overview", "comments": "Nicolas Heist, Sven Hertling, Daniel Ringler, Heiko Paulheim:\n  Knowledge Graphs on the Web -- an Overview. In: Ilaria Tiddi, Freddy Lecue,\n  Pascal Hitzler (eds.), Knowledge Graphs for eXplainable AI -- Foundations,\n  Applications and Challenges. Studies on the Semantic Web, IOS Press,\n  Amsterdam, 2020, to appear. [extended version]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graphs are an emerging form of knowledge representation. While\nGoogle coined the term Knowledge Graph first and promoted it as a means to\nimprove their search results, they are used in many applications today. In a\nknowledge graph, entities in the real world and/or a business domain (e.g.,\npeople, places, or events) are represented as nodes, which are connected by\nedges representing the relations between those entities. While companies such\nas Google, Microsoft, and Facebook have their own, non-public knowledge graphs,\nthere is also a larger body of publicly available knowledge graphs, such as\nDBpedia or Wikidata. In this chapter, we provide an overview and comparison of\nthose publicly available knowledge graphs, and give insights into their\ncontents, size, coverage, and overlap.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 08:58:21 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 07:36:55 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 10:31:25 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Heist", "Nicolas", ""], ["Hertling", "Sven", ""], ["Ringler", "Daniel", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2003.00722", "submitter": "Junfeng Wen", "authors": "Junfeng Wen, Bo Dai, Lihong Li, Dale Schuurmans", "title": "Batch Stationary Distribution Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of approximating the stationary distribution of an\nergodic Markov chain given a set of sampled transitions. Classical\nsimulation-based approaches assume access to the underlying process so that\ntrajectories of sufficient length can be gathered to approximate stationary\nsampling. Instead, we consider an alternative setting where a fixed set of\ntransitions has been collected beforehand, by a separate, possibly unknown\nprocedure. The goal is still to estimate properties of the stationary\ndistribution, but without additional access to the underlying system. We\npropose a consistent estimator that is based on recovering a correction ratio\nfunction over the given data. In particular, we develop a variational power\nmethod (VPM) that provides provably consistent estimates under general\nconditions. In addition to unifying a number of existing approaches from\ndifferent subfields, we also find that VPM yields significantly better\nestimates across a range of problems, including queueing, stochastic\ndifferential equations, post-processing MCMC, and off-policy evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 09:10:01 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Wen", "Junfeng", ""], ["Dai", "Bo", ""], ["Li", "Lihong", ""], ["Schuurmans", "Dale", ""]]}, {"id": "2003.00744", "submitter": "Dat Quoc Nguyen", "authors": "Dat Quoc Nguyen and Anh Tuan Nguyen", "title": "PhoBERT: Pre-trained language models for Vietnamese", "comments": "EMNLP 2020 (Findings)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PhoBERT with two versions, PhoBERT-base and PhoBERT-large, the\nfirst public large-scale monolingual language models pre-trained for\nVietnamese. Experimental results show that PhoBERT consistently outperforms the\nrecent best pre-trained multilingual model XLM-R (Conneau et al., 2020) and\nimproves the state-of-the-art in multiple Vietnamese-specific NLP tasks\nincluding Part-of-speech tagging, Dependency parsing, Named-entity recognition\nand Natural language inference. We release PhoBERT to facilitate future\nresearch and downstream applications for Vietnamese NLP. Our PhoBERT models are\navailable at https://github.com/VinAIResearch/PhoBERT\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 10:21:17 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 17:36:29 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 09:53:19 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Nguyen", "Dat Quoc", ""], ["Nguyen", "Anh Tuan", ""]]}, {"id": "2003.00749", "submitter": "David Tuckey", "authors": "David Tuckey, Alessandra Russo, Krysia Broda", "title": "A general framework for scientifically inspired explanations in AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability in AI is gaining attention in the computer science community\nin response to the increasing success of deep learning and the important need\nof justifying how such systems make predictions in life-critical applications.\nThe focus of explainability in AI has predominantly been on trying to gain\ninsights into how machine learning systems function by exploring relationships\nbetween input data and predicted outcomes or by extracting simpler\ninterpretable models. Through literature surveys of philosophy and social\nscience, authors have highlighted the sharp difference between these generated\nexplanations and human-made explanations and claimed that current explanations\nin AI do not take into account the complexity of human interaction to allow for\neffective information passing to not-expert users. In this paper we instantiate\nthe concept of structure of scientific explanation as the theoretical\nunderpinning for a general framework in which explanations for AI systems can\nbe implemented. This framework aims to provide the tools to build a\n\"mental-model\" of any AI system so that the interaction with the user can\nprovide information on demand and be closer to the nature of human-made\nexplanations. We illustrate how we can utilize this framework through two very\ndifferent examples: an artificial neural network and a Prolog solver and we\nprovide a possible implementation for both examples.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 10:32:21 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Tuckey", "David", ""], ["Russo", "Alessandra", ""], ["Broda", "Krysia", ""]]}, {"id": "2003.00752", "submitter": "Antonio Loquercio", "authors": "Antonio Loquercio, Alexey Dosovitskiy, and Davide Scaramuzza", "title": "Learning Depth With Very Sparse Supervision", "comments": "Accepted for Publication at the IEEE Robotics and Automation Letters\n  (RA-L) 2020, and International Conference on Intelligent Robots and Systems\n  (IROS) 2020", "journal-ref": "IEEE Robotics and Automation Letters (RA-L) 2020", "doi": "10.1109/LRA.2020.3009067", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the astonishing capabilities of natural intelligent agents and\ninspired by theories from psychology, this paper explores the idea that\nperception gets coupled to 3D properties of the world via interaction with the\nenvironment. Existing works for depth estimation require either massive amounts\nof annotated training data or some form of hard-coded geometrical constraint.\nThis paper explores a new approach to learning depth perception requiring\nneither of those. Specifically, we train a specialized global-local network\narchitecture with what would be available to a robot interacting with the\nenvironment: from extremely sparse depth measurements down to even a single\npixel per image. From a pair of consecutive images, our proposed network\noutputs a latent representation of the observer's motion between the images and\na dense depth map. Experiments on several datasets show that, when ground truth\nis available even for just one of the image pixels, the proposed network can\nlearn monocular dense depth estimation up to 22.5% more accurately than\nstate-of-the-art approaches. We believe that this work, despite its scientific\ninterest, lays the foundations to learn depth from extremely sparse\nsupervision, which can be valuable to all robotic systems acting under severe\nbandwidth or sensing constraints.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 10:44:13 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 10:01:55 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Loquercio", "Antonio", ""], ["Dosovitskiy", "Alexey", ""], ["Scaramuzza", "Davide", ""]]}, {"id": "2003.00767", "submitter": "Ringo Baumann", "authors": "Ringo Baumann", "title": "On the Existence of Characterization Logics and Fundamental Properties\n  of Argumentation Semantics", "comments": "Treatise", "journal-ref": "https://nbn-resolving.org/urn:nbn:de:bsz:15-qucosa2-365957 2019", "doi": "10.13140/RG.2.2.21831.24483", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the large variety of existing logical formalisms it is of utmost\nimportance to select the most adequate one for a specific purpose, e.g. for\nrepresenting the knowledge relevant for a particular application or for using\nthe formalism as a modeling tool for problem solving. Awareness of the nature\nof a logical formalism, in other words, of its fundamental intrinsic\nproperties, is indispensable and provides the basis of an informed choice. In\nthis treatise we consider the existence characterization logics as well as\nproperties like existence and uniqueness, expressibility, replaceability and\nverifiability in the realm of abstract argumentation\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 11:18:30 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Baumann", "Ringo", ""]]}, {"id": "2003.00806", "submitter": "Jalal Etesami", "authors": "Jalal Etesami and Philipp Geiger", "title": "Causal Transfer for Imitation Learning and Decision Making under\n  Sensor-shift", "comments": "It appears in AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from demonstrations (LfD) is an efficient paradigm to train AI\nagents. But major issues arise when there are differences between (a) the\ndemonstrator's own sensory input, (b) our sensors that observe the demonstrator\nand (c) the sensory input of the agent we train. In this paper, we propose a\ncausal model-based framework for transfer learning under such \"sensor-shifts\",\nfor two common LfD tasks: (1) inferring the effect of the demonstrator's\nactions and (2) imitation learning. First we rigorously analyze, on the\npopulation-level, to what extent the relevant underlying mechanisms (the action\neffects and the demonstrator policy) can be identified and transferred from the\navailable observations together with prior knowledge of sensor characteristics.\nAnd we device an algorithm to infer these mechanisms. Then we introduce several\nproxy methods which are easier to calculate, estimate from finite data and\ninterpret than the exact solutions, alongside theoretical bounds on their\ncloseness to the exact ones. We validate our two main methods on simulated and\nsemi-real world data.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 12:37:23 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Etesami", "Jalal", ""], ["Geiger", "Philipp", ""]]}, {"id": "2003.00813", "submitter": "Bingquan Zhu", "authors": "Bingquan Zhu, Hao Fang, Yanan Sui, Luming Li", "title": "Deepfakes for Medical Video De-Identification: Privacy Protection and\n  Diagnostic Information Preservation", "comments": "Accepted for publication at the AAAI/ACM Conference on Artificial\n  Intelligence, Ethics, and Society (AIES) 2020", "journal-ref": null, "doi": "10.1145/3375627.3375849", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data sharing for medical research has been difficult as open-sourcing\nclinical data may violate patient privacy. Traditional methods for face\nde-identification wipe out facial information entirely, making it impossible to\nanalyze facial behavior. Recent advancements on whole-body keypoints detection\nalso rely on facial input to estimate body keypoints. Both facial and body\nkeypoints are critical in some medical diagnoses, and keypoints invariability\nafter de-identification is of great importance. Here, we propose a solution\nusing deepfake technology, the face swapping technique. While this swapping\nmethod has been criticized for invading privacy and portraiture right, it could\nconversely protect privacy in medical video: patients' faces could be swapped\nto a proper target face and become unrecognizable. However, it remained an open\nquestion that to what extent the swapping de-identification method could affect\nthe automatic detection of body keypoints. In this study, we apply deepfake\ntechnology to Parkinson's disease examination videos to de-identify subjects,\nand quantitatively show that: face-swapping as a de-identification approach is\nreliable, and it keeps the keypoints almost invariant, significantly better\nthan traditional methods. This study proposes a pipeline for video\nde-identification and keypoint preservation, clearing up some ethical\nrestrictions for medical data sharing. This work could make open-source high\nquality medical video datasets more feasible and promote future medical\nresearch that benefits our society.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 22:36:48 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Zhu", "Bingquan", ""], ["Fang", "Hao", ""], ["Sui", "Yanan", ""], ["Li", "Luming", ""]]}, {"id": "2003.00814", "submitter": "Bin Guo", "authors": "Hao Wang, Bin Guo, Wei Wu, Zhiwen Yu", "title": "Towards information-rich, logical text generation with\n  knowledge-enhanced neural models", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text generation system has made massive promising progress contributed by\ndeep learning techniques and has been widely applied in our life. However,\nexisting end-to-end neural models suffer from the problem of tending to\ngenerate uninformative and generic text because they cannot ground input\ncontext with background knowledge. In order to solve this problem, many\nresearchers begin to consider combining external knowledge in text generation\nsystems, namely knowledge-enhanced text generation. The challenges of knowledge\nenhanced text generation including how to select the appropriate knowledge from\nlarge-scale knowledge bases, how to read and understand extracted knowledge,\nand how to integrate knowledge into generation process. This survey gives a\ncomprehensive review of knowledge-enhanced text generation systems, summarizes\nresearch progress to solving these challenges and proposes some open issues and\nresearch directions.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 12:41:02 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Wang", "Hao", ""], ["Guo", "Bin", ""], ["Wu", "Wei", ""], ["Yu", "Zhiwen", ""]]}, {"id": "2003.00819", "submitter": "Zhengyang Zhou", "authors": "Zhengyang Zhou, Yang Wang, Xike Xie, Lianliang Chen, Hengchang Liu", "title": "RiskOracle: A Minute-level Citywide Traffic Accident Forecasting\n  Framework", "comments": "8 pages, 4 figures. Conference paper accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time traffic accident forecasting is increasingly important for public\nsafety and urban management (e.g., real-time safe route planning and emergency\nresponse deployment). Previous works on accident forecasting are often\nperformed on hour levels, utilizing existed neural networks with static\nregion-wise correlations taken into account. However, it is still challenging\nwhen the granularity of forecasting step improves as the highly dynamic nature\nof road network and inherent rareness of accident records in one training\nsample, which leads to biased results and zero-inflated issue. In this work, we\npropose a novel framework RiskOracle, to improve the prediction granularity to\nminute levels. Specifically, we first transform the zero-risk values in labels\nto fit the training network. Then, we propose the Differential Time-varying\nGraph neural network (DTGN) to capture the immediate changes of traffic status\nand dynamic inter-subregion correlations. Furthermore, we adopt multi-task and\nregion selection schemes to highlight citywide most-likely accident subregions,\nbridging the gap between biased risk values and sporadic accident distribution.\nExtensive experiments on two real-world datasets demonstrate the effectiveness\nand scalability of our RiskOracle framework.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 07:18:46 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Zhou", "Zhengyang", ""], ["Wang", "Yang", ""], ["Xie", "Xike", ""], ["Chen", "Lianliang", ""], ["Liu", "Hengchang", ""]]}, {"id": "2003.00824", "submitter": "Gengchen Mai", "authors": "Gengchen Mai, Krzysztof Janowicz, Bo Yan, Rui Zhu, Ling Cai, Ni Lao", "title": "Multi-Scale Representation Learning for Spatial Feature Distributions\n  using Grid Cells", "comments": "15 pages; Accepted to ICLR 2020 as a spotlight paper", "journal-ref": "ICLR 2020, Apr. 26 - 30, 2020, Addis Ababa, ETHIOPIA", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised text encoding models have recently fueled substantial progress\nin NLP. The key idea is to use neural networks to convert words in texts to\nvector space representations based on word positions in a sentence and their\ncontexts, which are suitable for end-to-end training of downstream tasks. We\nsee a strikingly similar situation in spatial analysis, which focuses on\nincorporating both absolute positions and spatial contexts of geographic\nobjects such as POIs into models. A general-purpose representation model for\nspace is valuable for a multitude of tasks. However, no such general model\nexists to date beyond simply applying discretization or feed-forward nets to\ncoordinates, and little effort has been put into jointly modeling distributions\nwith vastly different characteristics, which commonly emerges from GIS data.\nMeanwhile, Nobel Prize-winning Neuroscience research shows that grid cells in\nmammals provide a multi-scale periodic representation that functions as a\nmetric for location encoding and is critical for recognizing places and for\npath-integration. Therefore, we propose a representation learning model called\nSpace2Vec to encode the absolute positions and spatial relationships of places.\nWe conduct experiments on two real-world geographic data for two different\ntasks: 1) predicting types of POIs given their positions and context, 2) image\nclassification leveraging their geo-locations. Results show that because of its\nmulti-scale representations, Space2Vec outperforms well-established ML\napproaches such as RBF kernels, multi-layer feed-forward nets, and tile\nembedding approaches for location modeling and image classification tasks.\nDetailed analysis shows that all baselines can at most well handle distribution\nat one scale but show poor performances in other scales. In contrast,\nSpace2Vec's multi-scale representation can handle distributions at different\nscales.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 04:22:18 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Mai", "Gengchen", ""], ["Janowicz", "Krzysztof", ""], ["Yan", "Bo", ""], ["Zhu", "Rui", ""], ["Cai", "Ling", ""], ["Lao", "Ni", ""]]}, {"id": "2003.00827", "submitter": "Laleh Seyyed-Kalantari", "authors": "Laleh Seyyed-Kalantari, Guanxiong Liu, Matthew McDermott, Irene Y.\n  Chen, Marzyeh Ghassemi", "title": "CheXclusion: Fairness gaps in deep chest X-ray classifiers", "comments": "Paper is accepted in Pacific Symposium on Biocomputing 2021\n  (PSB2021). Code can be found at, https://github.com/LalehSeyyed/CheXclusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems have received much attention recently for their\nability to achieve expert-level performance on clinical tasks, particularly in\nmedical imaging. Here, we examine the extent to which state-of-the-art deep\nlearning classifiers trained to yield diagnostic labels from X-ray images are\nbiased with respect to protected attributes. We train convolution neural\nnetworks to predict 14 diagnostic labels in 3 prominent public chest X-ray\ndatasets: MIMIC-CXR, Chest-Xray8, CheXpert, as well as a multi-site aggregation\nof all those datasets. We evaluate the TPR disparity -- the difference in true\npositive rates (TPR) -- among different protected attributes such as patient\nsex, age, race, and insurance type as a proxy for socioeconomic status. We\ndemonstrate that TPR disparities exist in the state-of-the-art classifiers in\nall datasets, for all clinical tasks, and all subgroups. A multi-source dataset\ncorresponds to the smallest disparities, suggesting one way to reduce bias. We\nfind that TPR disparities are not significantly correlated with a subgroup's\nproportional disease burden. As clinical models move from papers to products,\nwe encourage clinical decision makers to carefully audit for algorithmic\ndisparities prior to deployment. Our code can be found at,\nhttps://github.com/LalehSeyyed/CheXclusion\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 22:08:12 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 03:26:20 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Seyyed-Kalantari", "Laleh", ""], ["Liu", "Guanxiong", ""], ["McDermott", "Matthew", ""], ["Chen", "Irene Y.", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "2003.00842", "submitter": "Changmin Wu", "authors": "Changmin Wu, Giannis Nikolentzos, Michalis Vazirgiannis", "title": "EvoNet: A Neural Network for Predicting the Evolution of Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks for structured data like graphs have been studied extensively\nin recent years. To date, the bulk of research activity has focused mainly on\nstatic graphs. However, most real-world networks are dynamic since their\ntopology tends to change over time. Predicting the evolution of dynamic graphs\nis a task of high significance in the area of graph mining. Despite its\npractical importance, the task has not been explored in depth so far, mainly\ndue to its challenging nature. In this paper, we propose a model that predicts\nthe evolution of dynamic graphs. Specifically, we use a graph neural network\nalong with a recurrent architecture to capture the temporal evolution patterns\nof dynamic graphs. Then, we employ a generative model which predicts the\ntopology of the graph at the next time step and constructs a graph instance\nthat corresponds to that topology. We evaluate the proposed model on several\nartificial datasets following common network evolving dynamics, as well as on\nreal-world datasets. Results demonstrate the effectiveness of the proposed\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 12:59:05 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Wu", "Changmin", ""], ["Nikolentzos", "Giannis", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "2003.00863", "submitter": "Haotian Zhang", "authors": "Haotian Zhang, Jianyong Sun and Zongben Xu", "title": "Adaptive Structural Hyper-Parameter Configuration by Q-Learning", "comments": null, "journal-ref": "2020 IEEE Congress on Evolutionary Computation (CEC)", "doi": "10.1109/CEC48606.2020.9185665", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tuning hyper-parameters for evolutionary algorithms is an important issue in\ncomputational intelligence. Performance of an evolutionary algorithm depends\nnot only on its operation strategy design, but also on its hyper-parameters.\nHyper-parameters can be categorized in two dimensions as structural/numerical\nand time-invariant/time-variant. Particularly, structural hyper-parameters in\nexisting studies are usually tuned in advance for time-invariant parameters, or\nwith hand-crafted scheduling for time-invariant parameters. In this paper, we\nmake the first attempt to model the tuning of structural hyper-parameters as a\nreinforcement learning problem, and present to tune the structural\nhyper-parameter which controls computational resource allocation in the CEC\n2018 winner algorithm by Q-learning. Experimental results show favorably\nagainst the winner algorithm on the CEC 2018 test functions.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 13:10:13 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Zhang", "Haotian", ""], ["Sun", "Jianyong", ""], ["Xu", "Zongben", ""]]}, {"id": "2003.00920", "submitter": "Vivien Cabannes", "authors": "Vivien Cabannes, Alessandro Rudi, Francis Bach", "title": "Structured Prediction with Partial Labelling through the Infimum Loss", "comments": "8 pages for main paper, 27 with main paper, 13 figures, 3 tables", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, PMLR 119:1230-1239, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotating datasets is one of the main costs in nowadays supervised learning.\nThe goal of weak supervision is to enable models to learn using only forms of\nlabelling which are cheaper to collect, as partial labelling. This is a type of\nincomplete annotation where, for each datapoint, supervision is cast as a set\nof labels containing the real one. The problem of supervised learning with\npartial labelling has been studied for specific instances such as\nclassification, multi-label, ranking or segmentation, but a general framework\nis still missing. This paper provides a unified framework based on structured\nprediction and on the concept of infimum loss to deal with partial labelling\nover a wide family of learning problems and loss functions. The framework leads\nnaturally to explicit algorithms that can be easily implemented and for which\nproved statistical consistency and learning rates. Experiments confirm the\nsuperiority of the proposed approach over commonly used baselines.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 13:59:41 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 14:34:17 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Cabannes", "Vivien", ""], ["Rudi", "Alessandro", ""], ["Bach", "Francis", ""]]}, {"id": "2003.00925", "submitter": "Andreas Fischbach", "authors": "Andreas Fischbach, Jan Strohschein, Andreas Bunte, J\\\"org Stork, Heide\n  Faeskorn-Woyke, Natalia Moriz, Thomas Bartz-Beielstein", "title": "CAAI -- A Cognitive Architecture to Introduce Artificial Intelligence in\n  Cyber-Physical Production Systems", "comments": null, "journal-ref": null, "doi": "10.1007/s00170-020-06094-z", "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces CAAI, a novel cognitive architecture for artificial\nintelligence in cyber-physical production systems. The goal of the architecture\nis to reduce the implementation effort for the usage of artificial intelligence\nalgorithms. The core of the CAAI is a cognitive module that processes\ndeclarative goals of the user, selects suitable models and algorithms, and\ncreates a configuration for the execution of a processing pipeline on a big\ndata platform. Constant observation and evaluation against performance criteria\nassess the performance of pipelines for many and varying use cases. Based on\nthese evaluations, the pipelines are automatically adapted if necessary. The\nmodular design with well-defined interfaces enables the reusability and\nextensibility of pipeline components. A big data platform implements this\nmodular design supported by technologies such as Docker, Kubernetes, and Kafka\nfor virtualization and orchestration of the individual components and their\ncommunication. The implementation of the architecture is evaluated using a\nreal-world use case.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 16:27:07 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Fischbach", "Andreas", ""], ["Strohschein", "Jan", ""], ["Bunte", "Andreas", ""], ["Stork", "J\u00f6rg", ""], ["Faeskorn-Woyke", "Heide", ""], ["Moriz", "Natalia", ""], ["Bartz-Beielstein", "Thomas", ""]]}, {"id": "2003.00935", "submitter": "C. Maria Keet", "authors": "George Rautenbach and C. Maria Keet", "title": "Toward equipping Artificial Moral Agents with multiple ethical theories", "comments": "technical report; 33 pages, 11 figures, 2 tables, 4 code listings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Moral Agents (AMA's) is a field in computer science with the\npurpose of creating autonomous machines that can make moral decisions akin to\nhow humans do. Researchers have proposed theoretical means of creating such\nmachines, while philosophers have made arguments as to how these machines ought\nto behave, or whether they should even exist. Of the currently theorised AMA's,\nall research and design has been done with either none or at most one specified\nnormative ethical theory as basis. This is problematic because it narrows down\nthe AMA's functional ability and versatility which in turn causes moral\noutcomes that a limited number of people agree with (thereby undermining an\nAMA's ability to be moral in a human sense). As solution we design a\nthree-layer model for general normative ethical theories that can be used to\nserialise the ethical views of people and businesses for an AMA to use during\nreasoning. Four specific ethical norms (Kantianism, divine command theory,\nutilitarianism, and egoism) were modelled and evaluated as proof of concept for\nnormative modelling. Furthermore, all models were serialised to XML/XSD as\nproof of support for computerisation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 14:33:22 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Rautenbach", "George", ""], ["Keet", "C. Maria", ""]]}, {"id": "2003.00986", "submitter": "Sarod Yatawatta", "authors": "Sarod Yatawatta", "title": "Stochastic Calibration of Radio Interferometers", "comments": "MNRAS Accepted 2020 March 2. Received 2020 March 2 ; in original form\n  2020 January 27", "journal-ref": null, "doi": "10.1093/mnras/staa648", "report-no": null, "categories": "astro-ph.IM cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With ever increasing data rates produced by modern radio telescopes like\nLOFAR and future telescopes like the SKA, many data processing steps are\noverwhelmed by the amount of data that needs to be handled using limited\ncompute resources. Calibration is one such operation that dominates the overall\ndata processing computational cost, nonetheless, it is an essential operation\nto reach many science goals. Calibration algorithms do exist that scale well\nwith the number of stations of an array and the number of directions being\ncalibrated. However, the remaining bottleneck is the raw data volume, which\nscales with the number of baselines, and which is proportional to the square of\nthe number of stations. We propose a 'stochastic' calibration strategy where we\nonly read in a mini-batch of data for obtaining calibration solutions, as\nopposed to reading the full batch of data being calibrated. Nonetheless, we\nobtain solutions that are valid for the full batch of data. Normally, data need\nto be averaged before calibration is performed to accommodate the data in\nsize-limited compute memory. Stochastic calibration overcomes the need for data\naveraging before any calibration can be performed, and offers many advantages\nincluding: enabling the mitigation of faint radio frequency interference;\nbetter removal of strong celestial sources from the data; and better detection\nand spatial localization of fast radio transients.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 16:04:38 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 10:42:20 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Yatawatta", "Sarod", ""]]}, {"id": "2003.00997", "submitter": "Aleksei Triastcyn", "authors": "Aleksei Triastcyn, Boi Faltings", "title": "Generating Higher-Fidelity Synthetic Datasets with Privacy Guarantees", "comments": "7 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of enhancing user privacy in common machine\nlearning development tasks, such as data annotation and inspection, by\nsubstituting the real data with samples form a generative adversarial network.\nWe propose employing Bayesian differential privacy as the means to achieve a\nrigorous theoretical guarantee while providing a better privacy-utility\ntrade-off. We demonstrate experimentally that our approach produces\nhigher-fidelity samples, compared to prior work, allowing to (1) detect more\nsubtle data errors and biases, and (2) reduce the need for real data labelling\nby achieving high accuracy when training directly on artificial samples.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 16:23:41 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Triastcyn", "Aleksei", ""], ["Faltings", "Boi", ""]]}, {"id": "2003.01006", "submitter": "Jennifer D'Souza", "authors": "Jennifer D'Souza, Anett Hoppe, Arthur Brack, Mohamad Yaser Jaradeh,\n  S\\\"oren Auer, Ralph Ewerth", "title": "The STEM-ECR Dataset: Grounding Scientific Entity References in STEM\n  Scholarly Content to Authoritative Encyclopedic and Lexicographic Sources", "comments": "Published in LREC 2020. Publication URL\n  https://www.aclweb.org/anthology/2020.lrec-1.268/; Dataset DOI\n  https://doi.org/10.25835/0017546", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the STEM (Science, Technology, Engineering, and Medicine)\nDataset for Scientific Entity Extraction, Classification, and Resolution,\nversion 1.0 (STEM-ECR v1.0). The STEM-ECR v1.0 dataset has been developed to\nprovide a benchmark for the evaluation of scientific entity extraction,\nclassification, and resolution tasks in a domain-independent fashion. It\ncomprises abstracts in 10 STEM disciplines that were found to be the most\nprolific ones on a major publishing platform. We describe the creation of such\na multidisciplinary corpus and highlight the obtained findings in terms of the\nfollowing features: 1) a generic conceptual formalism for scientific entities\nin a multidisciplinary scientific context; 2) the feasibility of the\ndomain-independent human annotation of scientific entities under such a generic\nformalism; 3) a performance benchmark obtainable for automatic extraction of\nmultidisciplinary scientific entities using BERT-based neural models; 4) a\ndelineated 3-step entity resolution procedure for human annotation of the\nscientific entities via encyclopedic entity linking and lexicographic word\nsense disambiguation; and 5) human evaluations of Babelfy returned encyclopedic\nlinks and lexicographic senses for our entities. Our findings cumulatively\nindicate that human annotation and automatic learning of multidisciplinary\nscientific concepts as well as their semantic disambiguation in a wide-ranging\nsetting as STEM is reasonable.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 16:35:17 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 11:38:40 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 08:58:48 GMT"}, {"version": "v4", "created": "Tue, 28 Jul 2020 09:45:52 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["D'Souza", "Jennifer", ""], ["Hoppe", "Anett", ""], ["Brack", "Arthur", ""], ["Jaradeh", "Mohamad Yaser", ""], ["Auer", "S\u00f6ren", ""], ["Ewerth", "Ralph", ""]]}, {"id": "2003.01008", "submitter": "Eden Abadi Ea", "authors": "Eden Abadi, Ronen I. Brafman", "title": "Learning and Solving Regular Decision Processes", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Regular Decision Processes (RDPs) are a recently introduced model that\nextends MDPs with non-Markovian dynamics and rewards. The non-Markovian\nbehavior is restricted to depend on regular properties of the history. These\ncan be specified using regular expressions or formulas in linear dynamic logic\nover finite traces. Fully specified RDPs can be solved by compiling them into\nan appropriate MDP. Learning RDPs from data is a challenging problem that has\nyet to be addressed, on which we focus in this paper. Our approach rests on a\nnew representation for RDPs using Mealy Machines that emit a distribution and\nan expected reward for each state-action pair. Building on this representation,\nwe combine automata learning techniques with history clustering to learn such a\nMealy machine and solve it by adapting MCTS to it. We empirically evaluate this\napproach, demonstrating its feasibility.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 16:36:16 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Abadi", "Eden", ""], ["Brafman", "Ronen I.", ""]]}, {"id": "2003.01025", "submitter": "Haoran Su", "authors": "Haoran Su, Kejian Shi, Joseph. Y.J. Chow, Li Jin", "title": "Dynamic Queue-Jump Lane for Emergency Vehicles under Partially Connected\n  Settings: A Multi-Agent Deep Reinforcement Learning Approach", "comments": "42 pages, 13 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emergency vehicle (EMV) service is a key function of cities and is\nexceedingly challenging due to urban traffic congestion. The main reason behind\nEMV service delay is the lack of communication and cooperation between vehicles\nblocking EMVs. In this paper, we study the improvement of EMV service under V2X\nconnectivity. We consider the establishment of dynamic queue jump lanes (DQJLs)\nbased on real-time coordination of connected vehicles in the presence of\nnon-connected human-driven vehicles. We develop a novel Markov decision process\nformulation for the DQJL coordination strategies, which explicitly accounts for\nthe uncertainty of drivers' yielding pattern to approaching EMVs. Based on\npairs of neural networks representing actors and critics for agent vehicles, we\ndevelop a multi-agent actor-critic deep reinforcement learning algorithm that\nhandles a varying number of vehicles and a random proportion of connected\nvehicles in the traffic. Approaching the optimal coordination strategies via\nindirect and direct reinforcement learning, we present two schemata to address\nmulti-agent reinforcement learning on this connected vehicle application. Both\napproaches are validated, on a micro-simulation testbed SUMO, to establish a\nDQJL fast and safely. Validation results reveal that, with DQJL coordination\nstrategies, it saves up to 30% time for EMVs to pass a link-level intelligent\nurban roadway than the baseline scenario.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 16:59:21 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 00:59:18 GMT"}, {"version": "v3", "created": "Fri, 15 Jan 2021 23:42:18 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Su", "Haoran", ""], ["Shi", "Kejian", ""], ["Chow", "Joseph. Y. J.", ""], ["Jin", "Li", ""]]}, {"id": "2003.01060", "submitter": "Nan Yang", "authors": "Nan Yang and Lukas von Stumberg and Rui Wang and Daniel Cremers", "title": "D3VO: Deep Depth, Deep Pose and Deep Uncertainty for Monocular Visual\n  Odometry", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose D3VO as a novel framework for monocular visual odometry that\nexploits deep networks on three levels -- deep depth, pose and uncertainty\nestimation. We first propose a novel self-supervised monocular depth estimation\nnetwork trained on stereo videos without any external supervision. In\nparticular, it aligns the training image pairs into similar lighting condition\nwith predictive brightness transformation parameters. Besides, we model the\nphotometric uncertainties of pixels on the input images, which improves the\ndepth estimation accuracy and provides a learned weighting function for the\nphotometric residuals in direct (feature-less) visual odometry. Evaluation\nresults show that the proposed network outperforms state-of-the-art\nself-supervised depth estimation networks. D3VO tightly incorporates the\npredicted depth, pose and uncertainty into a direct visual odometry method to\nboost both the front-end tracking as well as the back-end non-linear\noptimization. We evaluate D3VO in terms of monocular visual odometry on both\nthe KITTI odometry benchmark and the EuRoC MAV dataset.The results show that\nD3VO outperforms state-of-the-art traditional monocular VO methods by a large\nmargin. It also achieves comparable results to state-of-the-art stereo/LiDAR\nodometry on KITTI and to the state-of-the-art visual-inertial odometry on EuRoC\nMAV, while using only a single camera.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 17:47:13 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 21:08:41 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Yang", "Nan", ""], ["von Stumberg", "Lukas", ""], ["Wang", "Rui", ""], ["Cremers", "Daniel", ""]]}, {"id": "2003.01062", "submitter": "Aniket Bera", "authors": "Venkatraman Narayanan, Bala Murali Manoghar, Vishnu Sashank Dorbala,\n  Dinesh Manocha, Aniket Bera", "title": "ProxEmo: Gait-based Emotion Learning and Multi-view Proxemic Fusion for\n  Socially-Aware Robot Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ProxEmo, a novel end-to-end emotion prediction algorithm for\nsocially aware robot navigation among pedestrians. Our approach predicts the\nperceived emotions of a pedestrian from walking gaits, which is then used for\nemotion-guided navigation taking into account social and proxemic constraints.\nTo classify emotions, we propose a multi-view skeleton graph convolution-based\nmodel that works on a commodity camera mounted onto a moving robot. Our emotion\nrecognition is integrated into a mapless navigation scheme and makes no\nassumptions about the environment of pedestrian motion. It achieves a mean\naverage emotion prediction precision of 82.47% on the Emotion-Gait benchmark\ndataset. We outperform current state-of-art algorithms for emotion recognition\nfrom 3D gaits. We highlight its benefits in terms of navigation in indoor\nscenes using a Clearpath Jackal robot.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 17:47:49 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 15:38:09 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Narayanan", "Venkatraman", ""], ["Manoghar", "Bala Murali", ""], ["Dorbala", "Vishnu Sashank", ""], ["Manocha", "Dinesh", ""], ["Bera", "Aniket", ""]]}, {"id": "2003.01156", "submitter": "Ali Shafti", "authors": "Ali Shafti, Jonas Tjomsland, William Dudley and A. Aldo Faisal", "title": "Real-World Human-Robot Collaborative Reinforcement Learning", "comments": "6 pages - accepted at IROS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The intuitive collaboration of humans and intelligent robots (embodied AI) in\nthe real-world is an essential objective for many desirable applications of\nrobotics. Whilst there is much research regarding explicit communication, we\nfocus on how humans and robots interact implicitly, on motor adaptation level.\nWe present a real-world setup of a human-robot collaborative maze game,\ndesigned to be non-trivial and only solvable through collaboration, by limiting\nthe actions to rotations of two orthogonal axes, and assigning each axes to one\nplayer. This results in neither the human nor the agent being able to solve the\ngame on their own. We use deep reinforcement learning for the control of the\nrobotic agent, and achieve results within 30 minutes of real-world play,\nwithout any type of pre-training. We then use this setup to perform systematic\nexperiments on human/agent behaviour and adaptation when co-learning a policy\nfor the collaborative game. We present results on how co-policy learning occurs\nover time between the human and the robotic agent resulting in each\nparticipant's agent serving as a representation of how they would play the\ngame. This allows us to relate a person's success when playing with different\nagents than their own, by comparing the policy of the agent with that of their\nown agent.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 19:34:07 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 19:10:10 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Shafti", "Ali", ""], ["Tjomsland", "Jonas", ""], ["Dudley", "William", ""], ["Faisal", "A. Aldo", ""]]}, {"id": "2003.01200", "submitter": "Nader Tavaf", "authors": "Amirsina Torfi, Rouzbeh A. Shirvani, Yaser Keneshloo, Nader Tavaf,\n  Edward A. Fox", "title": "Natural Language Processing Advancements By Deep Learning: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural Language Processing (NLP) helps empower intelligent machines by\nenhancing a better understanding of the human language for linguistic-based\nhuman-computer communication. Recent developments in computational power and\nthe advent of large amounts of linguistic data have heightened the need and\ndemand for automating semantic analysis using data-driven approaches. The\nutilization of data-driven strategies is pervasive now due to the significant\nimprovements demonstrated through the usage of deep learning methods in areas\nsuch as Computer Vision, Automatic Speech Recognition, and in particular, NLP.\nThis survey categorizes and addresses the different aspects and applications of\nNLP that have benefited from deep learning. It covers core NLP tasks and\napplications and describes how deep learning methods and models advance these\nareas. We further analyze and compare different approaches and state-of-the-art\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 21:32:05 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 19:15:30 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 16:58:54 GMT"}, {"version": "v4", "created": "Sat, 27 Feb 2021 14:02:09 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Torfi", "Amirsina", ""], ["Shirvani", "Rouzbeh A.", ""], ["Keneshloo", "Yaser", ""], ["Tavaf", "Nader", ""], ["Fox", "Edward A.", ""]]}, {"id": "2003.01207", "submitter": "Michael Wybrow", "authors": "Ann E. Nicholson, Kevin B. Korb, Erik P. Nyberg, Michael Wybrow,\n  Ingrid Zukerman, Steven Mascaro, Shreshth Thakur, Abraham Oshni Alvandi, Jeff\n  Riley, Ross Pearson, Shane Morris, Matthieu Herrmann, A.K.M. Azad, Fergus\n  Bolger, Ulrike Hahn, and David Lagnado", "title": "BARD: A structured technique for group elicitation of Bayesian networks\n  to support analytic reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many complex, real-world situations, problem solving and decision making\nrequire effective reasoning about causation and uncertainty. However, human\nreasoning in these cases is prone to confusion and error. Bayesian networks\n(BNs) are an artificial intelligence technology that models uncertain\nsituations, supporting probabilistic and causal reasoning and decision making.\nHowever, to date, BN methodologies and software require significant upfront\ntraining, do not provide much guidance on the model building process, and do\nnot support collaboratively building BNs. BARD (Bayesian ARgumentation via\nDelphi) is both a methodology and an expert system that utilises (1) BNs as the\nunderlying structured representations for better argument analysis, (2) a\nmulti-user web-based software platform and Delphi-style social processes to\nassist with collaboration, and (3) short, high-quality e-courses on demand, a\nhighly structured process to guide BN construction, and a variety of helpful\ntools to assist in building and reasoning with BNs, including an automated\nexplanation tool to assist effective report writing. The result is an\nend-to-end online platform, with associated online training, for groups without\nprior BN expertise to understand and analyse a problem, build a model of its\nunderlying probabilistic causal structure, validate and reason with the causal\nmodel, and use it to produce a written analytic report. Initial experimental\nresults demonstrate that BARD aids in problem solving, reasoning and\ncollaboration.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 21:55:35 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Nicholson", "Ann E.", ""], ["Korb", "Kevin B.", ""], ["Nyberg", "Erik P.", ""], ["Wybrow", "Michael", ""], ["Zukerman", "Ingrid", ""], ["Mascaro", "Steven", ""], ["Thakur", "Shreshth", ""], ["Alvandi", "Abraham Oshni", ""], ["Riley", "Jeff", ""], ["Pearson", "Ross", ""], ["Morris", "Shane", ""], ["Herrmann", "Matthieu", ""], ["Azad", "A. K. M.", ""], ["Bolger", "Fergus", ""], ["Hahn", "Ulrike", ""], ["Lagnado", "David", ""]]}, {"id": "2003.01226", "submitter": "Xiaodong Yang", "authors": "Xiaodong Yang, Hoang-Dung Tran, Weiming Xiang, Taylor Johnson", "title": "Reachability Analysis for Feed-Forward Neural Networks using Face\n  Lattices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been widely applied as an effective approach to\nhandle complex and practical problems. However, one of the most fundamental\nopen problems is the lack of formal methods to analyze the safety of their\nbehaviors. To address this challenge, we propose a parallelizable technique to\ncompute exact reachable sets of a neural network to an input set. Our method\ncurrently focuses on feed-forward neural networks with ReLU activation\nfunctions. One of the primary challenges for polytope-based approaches is\nidentifying the intersection between intermediate polytopes and hyperplanes\nfrom neurons. In this regard, we present a new approach to construct the\npolytopes with the face lattice, a complete combinatorial structure. The\ncorrectness and performance of our methodology are evaluated by verifying the\nsafety of ACAS Xu networks and other benchmarks. Compared to state-of-the-art\nmethods such as Reluplex, Marabou, and NNV, our approach exhibits a\nsignificantly higher efficiency. Additionally, our approach is capable of\nconstructing the complete input set given an output set, so that any input that\nleads to safety violation can be tracked.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 22:23:57 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Yang", "Xiaodong", ""], ["Tran", "Hoang-Dung", ""], ["Xiang", "Weiming", ""], ["Johnson", "Taylor", ""]]}, {"id": "2003.01238", "submitter": "Andr\\'es P\\'aez", "authors": "Andr\\'es P\\'aez", "title": "Robot Mindreading and the Problem of Trust", "comments": "2020 Convention of the Society for the Study of Artificial\n  Intelligence and Simulation of Behavior", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper raises three questions regarding the attribution of beliefs,\ndesires, and intentions to robots. The first one is whether humans in fact\nengage in robot mindreading. If they do, this raises a second question: does\nrobot mindreading foster trust towards robots? Both of these questions are\nempirical, and I show that the available evidence is insufficient to answer\nthem. Now, if we assume that the answer to both questions is affirmative, a\nthird and more important question arises: should developers and engineers\npromote robot mindreading in view of their stated goal of enhancing\ntransparency? My worry here is that by attempting to make robots more\nmind-readable, they are abandoning the project of understanding automatic\ndecision processes. Features that enhance mind-readability are prone to make\nthe factors that determine automatic decisions even more opaque than they\nalready are. And current strategies to eliminate opacity do not enhance\nmind-readability. The last part of the paper discusses different ways to\nanalyze this apparent trade-off and suggests that a possible solution must\nadopt tolerable degrees of opacity that depend on pragmatic factors connected\nto the level of trust required for the intended uses of the robot.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 22:55:42 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["P\u00e1ez", "Andr\u00e9s", ""]]}, {"id": "2003.01274", "submitter": "Devi Parikh", "authors": "Devi Parikh", "title": "Predicting A Creator's Preferences In, and From, Interactive Generative\n  Art", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a lay user creates an art piece using an interactive generative art tool,\nwhat, if anything, do the choices they make tell us about them and their\npreferences? These preferences could be in the specific generative art form\n(e.g., color palettes, density of the piece, thickness or curvatures of any\nlines in the piece); predicting them could lead to a smarter interactive tool.\nOr they could be preferences in other walks of life (e.g., music, fashion,\nfood, interior design, paintings) or attributes of the person (e.g.,\npersonality type, gender, artistic inclinations); predicting them could lead to\nimproved personalized recommendations for products or experiences.\n  To study this research question, we collect preferences from 311 subjects,\nboth in a specific generative art form and in other walks of life. We analyze\nthe preferences and train machine learning models to predict a subset of\npreferences from the remaining. We find that preferences in the generative art\nform we studied cannot predict preferences in other walks of life better than\nchance (and vice versa). However, preferences within the generative art form\nare reliably predictive of each other.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 01:05:45 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Parikh", "Devi", ""]]}, {"id": "2003.01303", "submitter": "Lu Wen", "authors": "Lu Wen, Jingliang Duan, Shengbo Eben Li, Shaobing Xu, Huei Peng", "title": "Safe Reinforcement Learning for Autonomous Vehicles through Parallel\n  Constrained Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is attracting increasing interests in autonomous\ndriving due to its potential to solve complex classification and control\nproblems. However, existing RL algorithms are rarely applied to real vehicles\nfor two predominant problems: behaviours are unexplainable, and they cannot\nguarantee safety under new scenarios. This paper presents a safe RL algorithm,\ncalled Parallel Constrained Policy Optimization (PCPO), for two autonomous\ndriving tasks. PCPO extends today's common actor-critic architecture to a\nthree-component learning framework, in which three neural networks are used to\napproximate the policy function, value function and a newly added risk\nfunction, respectively. Meanwhile, a trust region constraint is added to allow\nlarge update steps without breaking the monotonic improvement condition. To\nensure the feasibility of safety constrained problems, synchronized parallel\nlearners are employed to explore different state spaces, which accelerates\nlearning and policy-update. The simulations of two scenarios for autonomous\nvehicles confirm we can ensure safety while achieving fast learning.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 02:53:30 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Wen", "Lu", ""], ["Duan", "Jingliang", ""], ["Li", "Shengbo Eben", ""], ["Xu", "Shaobing", ""], ["Peng", "Huei", ""]]}, {"id": "2003.01304", "submitter": "Aditeya Pandey", "authors": "Aditeya Pandey, Yixuan Zhang, John A. Guerra-Gomez, Andrea G. Parker,\n  Michelle A. Borkin", "title": "Digital Collaborator: Augmenting Task Abstraction in Visualization\n  Design with Artificial Intelligence", "comments": "This paper has been accepted at CHI 2020 workshop - Workshop on\n  Artificial Intelligence for HCI: A Modern Approach", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the task abstraction phase of the visualization design process, including\nin \"design studies\", a practitioner maps the observed domain goals to\ngeneralizable abstract tasks using visualization theory in order to better\nunderstand and address the users needs. We argue that this manual task\nabstraction process is prone to errors due to designer biases and a lack of\ndomain background and knowledge. Under these circumstances, a collaborator can\nhelp validate and provide sanity checks to visualization practitioners during\nthis important task abstraction stage. However, having a human collaborator is\nnot always feasible and may be subject to the same biases and pitfalls. In this\npaper, we first describe the challenges associated with task abstraction. We\nthen propose a conceptual Digital Collaborator: an artificial intelligence\nsystem that aims to help visualization practitioners by augmenting their\nability to validate and reason about the output of task abstraction. We also\ndiscuss several practical design challenges of designing and implementing such\nsystems\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 02:53:34 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Pandey", "Aditeya", ""], ["Zhang", "Yixuan", ""], ["Guerra-Gomez", "John A.", ""], ["Parker", "Andrea G.", ""], ["Borkin", "Michelle A.", ""]]}, {"id": "2003.01318", "submitter": "Jessica Van Brummelen", "authors": "Jessica Van Brummelen, Kevin Weng, Phoebe Lin, Catherine Yeo", "title": "Convo: What does conversational programming need? An exploration of\n  machine learning interface design", "comments": "9 pages, 7 figures, submitted to VL/HCC 2020, for associated user\n  study video: https://youtu.be/TC5P3OO5exo", "journal-ref": null, "doi": "10.1109/VL/HCC50065.2020.9127277", "report-no": null, "categories": "cs.HC cs.AI cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vast improvements in natural language understanding and speech recognition\nhave paved the way for conversational interaction with computers. While\nconversational agents have often been used for short goal-oriented dialog, we\nknow little about agents for developing computer programs. To explore the\nutility of natural language for programming, we conducted a study ($n$=45)\ncomparing different input methods to a conversational programming system we\ndeveloped. Participants completed novice and advanced tasks using voice-based,\ntext-based, and voice-or-text-based systems. We found that users appreciated\naspects of each system (e.g., voice-input efficiency, text-input precision) and\nthat novice users were more optimistic about programming using voice-input than\nadvanced users. Our results show that future conversational programming tools\nshould be tailored to users' programming experience and allow users to choose\ntheir preferred input mode. To reduce cognitive load, future interfaces can\nincorporate visualizations and possess custom natural language understanding\nand speech recognition models for programming.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 03:39:37 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Van Brummelen", "Jessica", ""], ["Weng", "Kevin", ""], ["Lin", "Phoebe", ""], ["Yeo", "Catherine", ""]]}, {"id": "2003.01338", "submitter": "Guang Liu", "authors": "Jingyuan Yang, Guang Liu, Yuzhao Mao, Zhiwei Zhao, Weiguo Gao, Xuan\n  Li, Haiqin Yang, Jianping Shen", "title": "Hierarchical Context Enhanced Multi-Domain Dialogue System for\n  Multi-domain Task Completion", "comments": "Presented at DSTC workshop, AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task 1 of the DSTC8-track1 challenge aims to develop an end-to-end\nmulti-domain dialogue system to accomplish complex users' goals under tourist\ninformation desk settings. This paper describes our submitted solution,\nHierarchical Context Enhanced Dialogue System (HCEDS), for this task. The main\nmotivation of our system is to comprehensively explore the potential of\nhierarchical context for sufficiently understanding complex dialogues. More\nspecifically, we apply BERT to capture token-level information and employ the\nattention mechanism to capture sentence-level information. The results listed\nin the leaderboard show that our system achieves first place in automatic\nevaluation and the second place in human evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 05:10:13 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Yang", "Jingyuan", ""], ["Liu", "Guang", ""], ["Mao", "Yuzhao", ""], ["Zhao", "Zhiwei", ""], ["Gao", "Weiguo", ""], ["Li", "Xuan", ""], ["Yang", "Haiqin", ""], ["Shen", "Jianping", ""]]}, {"id": "2003.01373", "submitter": "Haozhe Wang", "authors": "Haozhe Wang, Jiale Zhou, Xuming He", "title": "Learning Context-aware Task Reasoning for Efficient Meta-reinforcement\n  Learning", "comments": "accepted to AAMAS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent success of deep network-based Reinforcement Learning (RL), it\nremains elusive to achieve human-level efficiency in learning novel tasks.\nWhile previous efforts attempt to address this challenge using meta-learning\nstrategies, they typically suffer from sampling inefficiency with on-policy RL\nalgorithms or meta-overfitting with off-policy learning. In this work, we\npropose a novel meta-RL strategy to address those limitations. In particular,\nwe decompose the meta-RL problem into three sub-tasks, task-exploration,\ntask-inference and task-fulfillment, instantiated with two deep network agents\nand a task encoder. During meta-training, our method learns a task-conditioned\nactor network for task-fulfillment, an explorer network with a self-supervised\nreward shaping that encourages task-informative experiences in\ntask-exploration, and a context-aware graph-based task encoder for task\ninference. We validate our approach with extensive experiments on several\npublic benchmarks and the results show that our algorithm effectively performs\nexploration for task inference, improves sample efficiency during both training\nand testing, and mitigates the meta-overfitting problem.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 07:38:53 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Wang", "Haozhe", ""], ["Zhou", "Jiale", ""], ["He", "Xuming", ""]]}, {"id": "2003.01384", "submitter": "William Agnew", "authors": "William Agnew and Pedro Domingos", "title": "Relevance-Guided Modeling of Object Dynamics for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current deep reinforcement learning (RL) approaches incorporate minimal prior\nknowledge about the environment, limiting computational and sample efficiency.\n\\textit{Objects} provide a succinct and causal description of the world, and\nmany recent works have proposed unsupervised object representation learning\nusing priors and losses over static object properties like visual consistency.\nHowever, object dynamics and interactions are also critical cues for\nobjectness. In this paper we propose a framework for reasoning about object\ndynamics and behavior to rapidly determine minimal and task-specific object\nrepresentations. To demonstrate the need to reason over object behavior and\ndynamics, we introduce a suite of RGBD MuJoCo object collection and avoidance\ntasks that, while intuitive and visually simple, confound state-of-the-art\nunsupervised object representation learning algorithms. We also highlight the\npotential of this framework on several Atari games, using our object\nrepresentation and standard RL and planning algorithms to learn dramatically\nfaster than existing deep RL algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 08:18:49 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 05:55:55 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 19:38:32 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Agnew", "William", ""], ["Domingos", "Pedro", ""]]}, {"id": "2003.01431", "submitter": "Jacques Kaiser", "authors": "Jacques Kaiser, Michael Hoff, Andreas Konle, J. Camilo Vasquez Tieck,\n  David Kappel, Daniel Reichard, Anand Subramoney, Robert Legenstein, Arne\n  Roennau, Wolfgang Maass, Rudiger Dillmann", "title": "Embodied Synaptic Plasticity with Online Reinforcement learning", "comments": "18 pages, 5 figures, published in frontiers in neurorobotics", "journal-ref": "Frontiers in neurorobotics, volume 13, p81, 2019", "doi": "10.3389/fnbot.2019.00081", "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The endeavor to understand the brain involves multiple collaborating research\nfields. Classically, synaptic plasticity rules derived by theoretical\nneuroscientists are evaluated in isolation on pattern classification tasks.\nThis contrasts with the biological brain which purpose is to control a body in\nclosed-loop. This paper contributes to bringing the fields of computational\nneuroscience and robotics closer together by integrating open-source software\ncomponents from these two fields. The resulting framework allows to evaluate\nthe validity of biologically-plausibe plasticity models in closed-loop robotics\nenvironments. We demonstrate this framework to evaluate Synaptic Plasticity\nwith Online REinforcement learning (SPORE), a reward-learning rule based on\nsynaptic sampling, on two visuomotor tasks: reaching and lane following. We\nshow that SPORE is capable of learning to perform policies within the course of\nsimulated hours for both tasks. Provisional parameter explorations indicate\nthat the learning rate and the temperature driving the stochastic processes\nthat govern synaptic learning dynamics need to be regulated for performance\nimprovements to be retained. We conclude by discussing the recent deep\nreinforcement learning techniques which would be beneficial to increase the\nfunctionality of SPORE on visuomotor tasks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 10:29:02 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Kaiser", "Jacques", ""], ["Hoff", "Michael", ""], ["Konle", "Andreas", ""], ["Tieck", "J. Camilo Vasquez", ""], ["Kappel", "David", ""], ["Reichard", "Daniel", ""], ["Subramoney", "Anand", ""], ["Legenstein", "Robert", ""], ["Roennau", "Arne", ""], ["Maass", "Wolfgang", ""], ["Dillmann", "Rudiger", ""]]}, {"id": "2003.01525", "submitter": "Juliana Ferreira J", "authors": "Juliana Jansen Ferreira and Mateus de Souza Monteiro", "title": "Evidence-based explanation to promote fairness in AI systems", "comments": "Fair & Responsible AI Workshop @ CHI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As Artificial Intelligence (AI) technology gets more intertwined with every\nsystem, people are using AI to make decisions on their everyday activities. In\nsimple contexts, such as Netflix recommendations, or in more complex context\nlike in judicial scenarios, AI is part of people's decisions. People make\ndecisions and usually, they need to explain their decision to others or in some\nmatter. It is particularly critical in contexts where human expertise is\ncentral to decision-making. In order to explain their decisions with AI\nsupport, people need to understand how AI is part of that decision. When\nconsidering the aspect of fairness, the role that AI has on a decision-making\nprocess becomes even more sensitive since it affects the fairness and the\nresponsibility of those people making the ultimate decision. We have been\nexploring an evidence-based explanation design approach to 'tell the story of a\ndecision'. In this position paper, we discuss our approach for AI systems using\nfairness sensitive cases in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 14:22:11 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Ferreira", "Juliana Jansen", ""], ["Monteiro", "Mateus de Souza", ""]]}, {"id": "2003.01593", "submitter": "Benjamin Finley", "authors": "Abhishek Kumar, Benjamin Finley, Tristan Braud, Sasu Tarkoma, Pan Hui", "title": "Marketplace for AI Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence shows promise for solving many practical societal\nproblems in areas such as healthcare and transportation. However, the current\nmechanisms for AI model diffusion such as Github code repositories, academic\nproject webpages, and commercial AI marketplaces have some limitations; for\nexample, a lack of monetization methods, model traceability, and model\nauditabilty. In this work, we sketch guidelines for a new AI diffusion method\nbased on a decentralized online marketplace. We consider the technical,\neconomic, and regulatory aspects of such a marketplace including a discussion\nof solutions for problems in these areas. Finally, we include a comparative\nanalysis of several current AI marketplaces that are already available or in\ndevelopment. We find that most of these marketplaces are centralized commercial\nmarketplaces with relatively few models.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 15:27:30 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Kumar", "Abhishek", ""], ["Finley", "Benjamin", ""], ["Braud", "Tristan", ""], ["Tarkoma", "Sasu", ""], ["Hui", "Pan", ""]]}, {"id": "2003.01668", "submitter": "Daniel Kang", "authors": "Daniel Kang, Deepti Raghavan, Peter Bailis, Matei Zaharia", "title": "Model Assertions for Monitoring and Improving ML Models", "comments": null, "journal-ref": "MLSys 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ML models are increasingly deployed in settings with real world interactions\nsuch as vehicles, but unfortunately, these models can fail in systematic ways.\nTo prevent errors, ML engineering teams monitor and continuously improve these\nmodels. We propose a new abstraction, model assertions, that adapts the\nclassical use of program assertions as a way to monitor and improve ML models.\nModel assertions are arbitrary functions over a model's input and output that\nindicate when errors may be occurring, e.g., a function that triggers if an\nobject rapidly changes its class in a video. We propose methods of using model\nassertions at all stages of ML system deployment, including runtime monitoring,\nvalidating labels, and continuously improving ML models. For runtime\nmonitoring, we show that model assertions can find high confidence errors,\nwhere a model returns the wrong output with high confidence, which\nuncertainty-based monitoring techniques would not detect. For training, we\npropose two methods of using model assertions. First, we propose a bandit-based\nactive learning algorithm that can sample from data flagged by assertions and\nshow that it can reduce labeling costs by up to 40% over traditional\nuncertainty-based methods. Second, we propose an API for generating\n\"consistency assertions\" (e.g., the class change example) and weak labels for\ninputs where the consistency assertions fail, and show that these weak labels\ncan improve relative model quality by up to 46%. We evaluate model assertions\non four real-world tasks with video, LIDAR, and ECG data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 17:49:49 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 17:48:56 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 23:30:56 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Kang", "Daniel", ""], ["Raghavan", "Deepti", ""], ["Bailis", "Peter", ""], ["Zaharia", "Matei", ""]]}, {"id": "2003.01670", "submitter": "Pedro Casas Dr.", "authors": "Andrea Morichetta, Pedro Casas, Marco Mellia", "title": "EXPLAIN-IT: Towards Explainable AI for Unsupervised Network Traffic\n  Analysis", "comments": null, "journal-ref": "3rd ACM CoNEXT Workshop on Big DAta, Machine Learning and\n  Artificial Intelligence for Data Communication Networks (Big-DAMA 2019)", "doi": "10.1145/3359992.3366639", "report-no": null, "categories": "cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of unsupervised learning approaches, and in particular of\nclustering techniques, represents a powerful exploration means for the analysis\nof network measurements. Discovering underlying data characteristics, grouping\nsimilar measurements together, and identifying eventual patterns of interest\nare some of the applications which can be tackled through clustering. Being\nunsupervised, clustering does not always provide precise and clear insight into\nthe produced output, especially when the input data structure and distribution\nare complex and difficult to grasp. In this paper we introduce EXPLAIN-IT, a\nmethodology which deals with unlabeled data, creates meaningful clusters, and\nsuggests an explanation to the clustering results for the end-user. EXPLAIN-IT\nrelies on a novel explainable Artificial Intelligence (AI) approach, which\nallows to understand the reasons leading to a particular decision of a\nsupervised learning-based model, additionally extending its application to the\nunsupervised learning domain. We apply EXPLAIN-IT to the problem of YouTube\nvideo quality classification under encrypted traffic scenarios, showing\npromising results.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 17:54:41 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Morichetta", "Andrea", ""], ["Casas", "Pedro", ""], ["Mellia", "Marco", ""]]}, {"id": "2003.01709", "submitter": "Donald J. Hejna Iii", "authors": "Donald J. Hejna III, Pieter Abbeel, Lerrel Pinto", "title": "Hierarchically Decoupled Imitation for Morphological Transfer", "comments": "International Conference on Machine Learning (ICML) 2020 camera ready\n  submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning long-range behaviors on complex high-dimensional agents is a\nfundamental problem in robot learning. For such tasks, we argue that\ntransferring learned information from a morphologically simpler agent can\nmassively improve the sample efficiency of a more complex one. To this end, we\npropose a hierarchical decoupling of policies into two parts: an independently\nlearned low-level policy and a transferable high-level policy. To remedy poor\ntransfer performance due to mismatch in morphologies, we contribute two key\nideas. First, we show that incentivizing a complex agent's low-level to imitate\na simpler agent's low-level significantly improves zero-shot high-level\ntransfer. Second, we show that KL-regularized training of the high level\nstabilizes learning and prevents mode-collapse. Finally, on a suite of publicly\nreleased navigation and manipulation environments, we demonstrate the\napplicability of hierarchical transfer on long-range tasks across morphologies.\nOur code and videos can be found at\nhttps://sites.google.com/berkeley.edu/morphology-transfer.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 18:56:49 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 07:26:59 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Hejna", "Donald J.", "III"], ["Abbeel", "Pieter", ""], ["Pinto", "Lerrel", ""]]}, {"id": "2003.01820", "submitter": "Thomas Spooner", "authors": "Thomas Spooner, Rahul Savani", "title": "Robust Market Making via Adversarial Reinforcement Learning", "comments": "7 pages, 3 figures; IJCAI-PRICAI '20 Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that adversarial reinforcement learning (ARL) can be used to produce\nmarket marking agents that are robust to adversarial and adaptively-chosen\nmarket conditions. To apply ARL, we turn the well-studied single-agent model of\nAvellaneda and Stoikov [2008] into a discrete-time zero-sum game between a\nmarket maker and adversary. The adversary acts as a proxy for other market\nparticipants that would like to profit at the market maker's expense. We\nempirically compare two conventional single-agent RL agents with ARL, and show\nthat our ARL approach leads to: 1) the emergence of risk-averse behaviour\nwithout constraints or domain-specific penalties; 2) significant improvements\nin performance across a set of standard metrics, evaluated with or without an\nadversary in the test environment, and; 3) improved robustness to model\nuncertainty. We empirically demonstrate that our ARL method consistently\nconverges, and we prove for several special cases that the profiles that we\nconverge to correspond to Nash equilibria in a simplified single-stage game.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 22:40:57 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 15:15:09 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Spooner", "Thomas", ""], ["Savani", "Rahul", ""]]}, {"id": "2003.01825", "submitter": "C\\'edric Colas", "authors": "C\\'edric Colas, Joost Huizinga, Vashisht Madhavan, Jeff Clune", "title": "Scaling MAP-Elites to Deep Neuroevolution", "comments": "Accepted to GECCO 2020", "journal-ref": null, "doi": "10.1145/3377930.3390217", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality-Diversity (QD) algorithms, and MAP-Elites (ME) in particular, have\nproven very useful for a broad range of applications including enabling real\nrobots to recover quickly from joint damage, solving strongly deceptive maze\ntasks or evolving robot morphologies to discover new gaits. However, present\nimplementations of MAP-Elites and other QD algorithms seem to be limited to\nlow-dimensional controllers with far fewer parameters than modern deep neural\nnetwork models. In this paper, we propose to leverage the efficiency of\nEvolution Strategies (ES) to scale MAP-Elites to high-dimensional controllers\nparameterized by large neural networks. We design and evaluate a new hybrid\nalgorithm called MAP-Elites with Evolution Strategies (ME-ES) for post-damage\nrecovery in a difficult high-dimensional control task where traditional ME\nfails. Additionally, we show that ME-ES performs efficient exploration, on par\nwith state-of-the-art exploration algorithms in high-dimensional control tasks\nwith strongly deceptive rewards.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 23:02:37 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 08:53:53 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 15:59:15 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Colas", "C\u00e9dric", ""], ["Huizinga", "Joost", ""], ["Madhavan", "Vashisht", ""], ["Clune", "Jeff", ""]]}, {"id": "2003.01848", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Jeffrey Chen, Ruslan Salakhutdinov, Louis-Philippe\n  Morency, Satwik Kottur", "title": "On Emergent Communication in Competitive Multi-Agent Teams", "comments": "AAMAS 2020, code:\n  https://github.com/pliang279/Competitive-Emergent-Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent works have found the emergence of grounded compositional\nlanguage in the communication protocols developed by mostly cooperative\nmulti-agent systems when learned end-to-end to maximize performance on a\ndownstream task. However, human populations learn to solve complex tasks\ninvolving communicative behaviors not only in fully cooperative settings but\nalso in scenarios where competition acts as an additional external pressure for\nimprovement. In this work, we investigate whether competition for performance\nfrom an external, similar agent team could act as a social influence that\nencourages multi-agent populations to develop better communication protocols\nfor improved performance, compositionality, and convergence speed. We start\nfrom Task & Talk, a previously proposed referential game between two\ncooperative agents as our testbed and extend it into Task, Talk & Compete, a\ngame involving two competitive teams each consisting of two aforementioned\ncooperative agents. Using this new setting, we provide an empirical study\ndemonstrating the impact of competitive influence on multi-agent teams. Our\nresults show that an external competitive influence leads to improved accuracy\nand generalization, as well as faster emergence of communicative languages that\nare more informative and compositional.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 01:14:27 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 04:15:59 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Liang", "Paul Pu", ""], ["Chen", "Jeffrey", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""], ["Kottur", "Satwik", ""]]}, {"id": "2003.01886", "submitter": "Dhanoop Karunakaran", "authors": "Dhanoop Karunakaran, Stewart Worrall, Eduardo Nebot", "title": "Efficient statistical validation with edge cases to evaluate Highly\n  Automated Vehicles", "comments": "8 pages and submitted to IEEE ITSC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widescale deployment of Autonomous Vehicles (AV) seems to be imminent\ndespite many safety challenges that are yet to be resolved. It is well known\nthat there are no universally agreed Verification and Validation (VV)\nmethodologies to guarantee absolute safety, which is crucial for the acceptance\nof this technology. Existing standards focus on deterministic processes where\nthe validation requires only a set of test cases that cover the requirements.\nModern autonomous vehicles will undoubtedly include machine learning and\nprobabilistic techniques that require a much more comprehensive testing regime\ndue to the non-deterministic nature of the operating design domain. A rigourous\nstatistical validation process is an essential component required to address\nthis challenge. Most research in this area focuses on evaluating system\nperformance in large scale real-world data gathering exercises (number of miles\ntravelled), or randomised test scenarios in simulation.\n  This paper presents a new approach to compute the statistical characteristics\nof a system's behaviour by biasing automatically generated test cases towards\nthe worst case scenarios, identifying potential unsafe edge cases.We use\nreinforcement learning (RL) to learn the behaviours of simulated actors that\ncause unsafe behaviour measured by the well established RSS safety metric. We\ndemonstrate that by using the method we can more efficiently validate a system\nusing a smaller number of test cases by focusing the simulation towards the\nworst case scenario, generating edge cases that correspond to unsafe\nsituations.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 04:35:22 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Karunakaran", "Dhanoop", ""], ["Worrall", "Stewart", ""], ["Nebot", "Eduardo", ""]]}, {"id": "2003.01899", "submitter": "Phebe Vayanos", "authors": "Phebe Vayanos, Duncan McElfresh, Yingxiao Ye, John Dickerson, Eric\n  Rice", "title": "Active Preference Elicitation via Adjustable Robust Optimization", "comments": "88 pages, 13 figures, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem faced by a recommender system which seeks to offer a\nuser with unknown preferences an item. Before making a recommendation, the\nsystem has the opportunity to elicit the user's preferences by making queries.\nEach query corresponds to a pairwise comparison between items. We take the\npoint of view of either a risk averse or regret averse recommender system which\nonly possess set-based information on the user utility function. We\ninvestigate: a) an offline elicitation setting, where all queries are made at\nonce, and b) an online elicitation setting, where queries are selected\nsequentially over time. We propose exact robust optimization formulations of\nthese problems which integrate the elicitation and recommendation phases and\nstudy the complexity of these problems. For the offline case, where the problem\ntakes the form of a two-stage robust optimization problem with\ndecision-dependent information discovery, we provide an enumeration-based\nalgorithm and also an equivalent reformulation in the form of a mixed-binary\nlinear program which we solve via column-and-constraint generation. For the\nonline setting, where the problem takes the form of a multi-stage robust\noptimization problem with decision-dependent information discovery, we propose\na conservative solution approach. We evaluate the performance of our methods on\nboth synthetic data and real data from the Homeless Management Information\nSystem. We simulate elicitation of the preferences of policy-makers in terms of\ncharacteristics of housing allocation policies to better match individuals\nexperiencing homelessness to scarce housing resources. Our framework is shown\nto outperform the state-of-the-art techniques from the literature.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 05:24:08 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Vayanos", "Phebe", ""], ["McElfresh", "Duncan", ""], ["Ye", "Yingxiao", ""], ["Dickerson", "John", ""], ["Rice", "Eric", ""]]}, {"id": "2003.02054", "submitter": "Alaa Daoud", "authors": "Alaa Daoud", "title": "Semantic Web Environments for Multi-Agent Systems: Enabling agents to\n  use Web of Things via semantic web", "comments": "Internship report submitted for the degree of master in computer\n  science <<Cyber-Physical-Social Systems (CPS2)>> - Universit\\'e Jean Monnet -\n  Saint \\'Etienne - August 2018", "journal-ref": null, "doi": "10.13140/RG.2.2.32666.39362", "report-no": "CPS2-2018", "categories": "cs.SE cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Web is ubiquitous, increasingly populated with interconnected data,\nservices, people, and objects. Semantic web technologies (SWT) promote\nuniformity of data formats, as well as modularization and reuse of\nspecifications (e.g., ontologies), by allowing them to include and refer to\ninformation provided by other ontologies. In such a context, multi-agent system\n(MAS) technologies are the right abstraction for developing decentralized and\nopen Web applications in which agents discover, reason and act on Web resources\nand cooperate with each other and with people. The aim of the project is to\npropose an approach to transform \"Agent and artifact (A&A) meta-model\" into a\nWeb-readable format with ontologies in line with semantic web formats and to\nreuse already existing ontologies in order to provide uniform access for agents\nto things.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 11:18:29 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Daoud", "Alaa", ""]]}, {"id": "2003.02093", "submitter": "Xiao Ma", "authors": "Xiao Ma, Taylor W. Brown", "title": "AI-Mediated Exchange Theory", "comments": "For workshop \"Human-Centered Approaches to Fair and Responsible AI\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Artificial Intelligence (AI) plays an ever-expanding role in\nsociotechnical systems, it is important to articulate the relationships between\nhumans and AI. However, the scholarly communities studying human-AI\nrelationships -- including but not limited to social computing, machine\nlearning, science and technology studies, and other social sciences -- are\ndivided by the perspectives that define them. These perspectives vary both by\ntheir focus on humans or AI, and in the micro/macro lenses through which they\napproach subjects. These differences inhibit the integration of findings, and\nthus impede science and interdisciplinarity. In this position paper, we propose\nthe development of a framework AI-Mediated Exchange Theory (AI-MET) to bridge\nthese divides. As an extension to Social Exchange Theory (SET) in the social\nsciences, AI-MET views AI as influencing human-to-human relationships via a\ntaxonomy of mediation mechanisms. We list initial ideas of these mechanisms,\nand show how AI-MET can be used to help human-AI research communities speak to\none another.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 14:18:18 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Ma", "Xiao", ""], ["Brown", "Taylor W.", ""]]}, {"id": "2003.02097", "submitter": "Yara Rizk", "authors": "Yara Rizk, Vatche Isahagian, Merve Unuvar, Yasaman Khazaeni", "title": "A Snooze-less User-Aware Notification System for Proactive\n  Conversational Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquity of smart phones and electronic devices has placed a wealth of\ninformation at the fingertips of consumers as well as creators of digital\ncontent. This has led to millions of notifications being issued each second\nfrom alerts about posted YouTube videos to tweets, emails and personal\nmessages. Adding work related notifications and we can see how quickly the\nnumber of notifications increases. Not only does this cause reduced\nproductivity and concentration but has also been shown to cause alert fatigue.\nThis condition makes users desensitized to notifications, causing them to\nignore or miss important alerts. Depending on what domain users work in, the\ncost of missing a notification can vary from a mere inconvenience to life and\ndeath. Therefore, in this work, we propose an alert and notification framework\nthat intelligently issues, suppresses and aggregates notifications, based on\nevent severity, user preferences, or schedules, to minimize the need for users\nto ignore, or snooze their notifications and potentially forget about\naddressing important ones. Our framework can be deployed as a backend service,\nbut is better suited to be integrated into proactive conversational agents, a\nfield receiving a lot of attention with the digital transformation era, email\nservices, news services and others. However, the main challenge lies in\ndeveloping the right machine learning algorithms that can learn models from a\nwide set of users while customizing these models to individual users'\npreferences.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 14:31:21 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Rizk", "Yara", ""], ["Isahagian", "Vatche", ""], ["Unuvar", "Merve", ""], ["Khazaeni", "Yasaman", ""]]}, {"id": "2003.02232", "submitter": "Ankit Shah", "authors": "Ankit Shah, Samir Wadhwania, Julie Shah", "title": "Interactive Robot Training for Non-Markov Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Defining sound and complete specifications for robots using formal languages\nis challenging, while learning formal specifications directly from\ndemonstrations can lead to over-constrained task policies. In this paper, we\npropose a Bayesian interactive robot training framework that allows the robot\nto learn from both demonstrations provided by a teacher, and that teacher's\nassessments of the robot's task executions. We also present an active learning\napproach -- inspired by uncertainty sampling -- to identify the task execution\nwith the most uncertain degree of acceptability. Through a simulated\nexperiment, we demonstrate that our active learning approach identifies a\nteacher's intended task specification with an equivalent or greater similarity\nwhen compared to an approach that learns purely from demonstrations. Finally,\nwe demonstrate the efficacy of our approach in a real-world setting through a\nuser-study based on teaching a robot to set a dinner table.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 18:19:05 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 17:03:57 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Shah", "Ankit", ""], ["Wadhwania", "Samir", ""], ["Shah", "Julie", ""]]}, {"id": "2003.02320", "submitter": "Aidan Hogan", "authors": "Aidan Hogan, Eva Blomqvist, Michael Cochez, Claudia d'Amato, Gerard de\n  Melo, Claudio Gutierrez, Jos\\'e Emilio Labra Gayo, Sabrina Kirrane, Sebastian\n  Neumaier, Axel Polleres, Roberto Navigli, Axel-Cyrille Ngonga Ngomo, Sabbir\n  M. Rashid, Anisa Rula, Lukas Schmelzeisen, Juan Sequeda, Steffen Staab,\n  Antoine Zimmermann", "title": "Knowledge Graphs", "comments": "Revision from v4: Correcting minor typos and errata involving\n  entailment discussion (former/latter), figure for query rewriting (swap\n  city/venue for location), add more brittle nodes in connectivity; etc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide a comprehensive introduction to knowledge graphs,\nwhich have recently garnered significant attention from both industry and\nacademia in scenarios that require exploiting diverse, dynamic, large-scale\ncollections of data. After some opening remarks, we motivate and contrast\nvarious graph-based data models and query languages that are used for knowledge\ngraphs. We discuss the roles of schema, identity, and context in knowledge\ngraphs. We explain how knowledge can be represented and extracted using a\ncombination of deductive and inductive techniques. We summarise methods for the\ncreation, enrichment, quality assessment, refinement, and publication of\nknowledge graphs. We provide an overview of prominent open knowledge graphs and\nenterprise knowledge graphs, their applications, and how they use the\naforementioned techniques. We conclude with high-level future research\ndirections for knowledge graphs.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 20:20:32 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 19:39:38 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 00:07:00 GMT"}, {"version": "v4", "created": "Fri, 11 Dec 2020 16:16:28 GMT"}, {"version": "v5", "created": "Sun, 24 Jan 2021 02:06:48 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Hogan", "Aidan", ""], ["Blomqvist", "Eva", ""], ["Cochez", "Michael", ""], ["d'Amato", "Claudia", ""], ["de Melo", "Gerard", ""], ["Gutierrez", "Claudio", ""], ["Gayo", "Jos\u00e9 Emilio Labra", ""], ["Kirrane", "Sabrina", ""], ["Neumaier", "Sebastian", ""], ["Polleres", "Axel", ""], ["Navigli", "Roberto", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""], ["Rashid", "Sabbir M.", ""], ["Rula", "Anisa", ""], ["Schmelzeisen", "Lukas", ""], ["Sequeda", "Juan", ""], ["Staab", "Steffen", ""], ["Zimmermann", "Antoine", ""]]}, {"id": "2003.02372", "submitter": "Jieliang Luo", "authors": "Jieliang Luo and Hui Li", "title": "Dynamic Experience Replay", "comments": "10 pages, 5 figures, presented at 2019 Conference on Robot Learning\n  (CoRL)", "journal-ref": "PMLR 100:1191-1200, 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel technique called Dynamic Experience Replay (DER) that\nallows Reinforcement Learning (RL) algorithms to use experience replay samples\nnot only from human demonstrations but also successful transitions generated by\nRL agents during training and therefore improve training efficiency. It can be\ncombined with an arbitrary off-policy RL algorithm, such as DDPG or DQN, and\ntheir distributed versions. We build upon Ape-X DDPG and demonstrate our\napproach on robotic tight-fitting joint assembly tasks, based on force/torque\nand Cartesian pose observations. In particular, we run experiments on two\ndifferent tasks: peg-in-hole and lap-joint. In each case, we compare different\nreplay buffer structures and how DER affects them. Our ablation studies show\nthat Dynamic Experience Replay is a crucial ingredient that either largely\nshortens the training time in these challenging environments or solves the\ntasks that the vanilla Ape-X DDPG cannot solve. We also show that our policies\nlearned purely in simulation can be deployed successfully on the real robot.\nThe video presenting our experiments is available at\nhttps://sites.google.com/site/dynamicexperiencereplay\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 23:46:45 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Luo", "Jieliang", ""], ["Li", "Hui", ""]]}, {"id": "2003.02428", "submitter": "Steffen Holter", "authors": "Oscar Gomez, Steffen Holter, Jun Yuan, Enrico Bertini", "title": "ViCE: Visual Counterfactual Explanations for Machine Learning Models", "comments": "4 pages, 2 figures, ACM IUI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continued improvements in the predictive accuracy of machine learning\nmodels have allowed for their widespread practical application. Yet, many\ndecisions made with seemingly accurate models still require verification by\ndomain experts. In addition, end-users of a model also want to understand the\nreasons behind specific decisions. Thus, the need for interpretability is\nincreasingly paramount. In this paper we present an interactive visual\nanalytics tool, ViCE, that generates counterfactual explanations to\ncontextualize and evaluate model decisions. Each sample is assessed to identify\nthe minimal set of changes needed to flip the model's output. These\nexplanations aim to provide end-users with personalized actionable insights\nwith which to understand, and possibly contest or improve, automated decisions.\nThe results are effectively displayed in a visual interface where\ncounterfactual explanations are highlighted and interactive methods are\nprovided for users to explore the data and model. The functionality of the tool\nis demonstrated by its application to a home equity line of credit dataset.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 04:43:02 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Gomez", "Oscar", ""], ["Holter", "Steffen", ""], ["Yuan", "Jun", ""], ["Bertini", "Enrico", ""]]}, {"id": "2003.02599", "submitter": "Evangelia Kyrimi", "authors": "Evangelia Kyrimi, Somayyeh Mossadegh, Nigel Tai, William Marsh", "title": "An Incremental Explanation of Inference in Hybrid Bayesian Networks for\n  Increasing Model Trustworthiness and Supporting Clinical Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Various AI models are increasingly being considered as part of clinical\ndecision-support tools. However, the trustworthiness of such models is rarely\nconsidered. Clinicians are more likely to use a model if they can understand\nand trust its predictions. Key to this is if its underlying reasoning can be\nexplained. A Bayesian network (BN) model has the advantage that it is not a\nblack-box and its reasoning can be explained. In this paper, we propose an\nincremental explanation of inference that can be applied to hybrid BNs, i.e.\nthose that contain both discrete and continuous nodes. The key questions that\nwe answer are: (1) which important evidence supports or contradicts the\nprediction, and (2) through which intermediate variables does the information\nflow. The explanation is illustrated using a real clinical case study. A small\nevaluation study is also conducted.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 13:22:23 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 10:33:23 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Kyrimi", "Evangelia", ""], ["Mossadegh", "Somayyeh", ""], ["Tai", "Nigel", ""], ["Marsh", "William", ""]]}, {"id": "2003.02622", "submitter": "Toby Jia-Jun Li", "authors": "Toby Jia-Jun Li, Jingya Chen, Tom M. Mitchell, Brad A. Myers", "title": "Towards Effective Human-AI Collaboration in GUI-Based Interactive Task\n  Learning Agents", "comments": null, "journal-ref": "CHI 2020 Workshop on Artificial Intelligence for HCI: A Modern\n  Approach (AI4HCI)", "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that a key challenge in enabling usable and useful interactive task\nlearning for intelligent agents is to facilitate effective Human-AI\ncollaboration. We reflect on our past 5 years of efforts on designing,\ndeveloping and studying the SUGILITE system, discuss the issues on\nincorporating recent advances in AI with HCI principles in mixed-initiative\ninteractions and multi-modal interactions, and summarize the lessons we\nlearned. Lastly, we identify several challenges and opportunities, and describe\nour ongoing work\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 14:12:19 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Li", "Toby Jia-Jun", ""], ["Chen", "Jingya", ""], ["Mitchell", "Tom M.", ""], ["Myers", "Brad A.", ""]]}, {"id": "2003.02655", "submitter": "Tamir Blum", "authors": "Tamir Blum and Kazuya Yoshida", "title": "PPMC RL Training Algorithm: Rough Terrain Intelligent Robots through\n  Reinforcement Learning", "comments": "6 pages, 7 figures, 4 wheeled rover in a rough environment resembling\n  lunar surface", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots can now learn how to make decisions and control themselves,\ngeneralizing learned behaviors to unseen scenarios. In particular, AI powered\nrobots show promise in rough environments like the lunar surface, due to the\nenvironmental uncertainties. We address this critical generalization aspect for\nrobot locomotion in rough terrain through a training algorithm we have created\ncalled the Path Planning and Motion Control (PPMC) Training Algorithm. This\nalgorithm is coupled with any generic reinforcement learning algorithm to teach\nrobots how to respond to user commands and to travel to designated locations on\na single neural network. In this paper, we show that the algorithm works\nindependent of the robot structure, demonstrating that it works on a wheeled\nrover in addition the past results on a quadruped walking robot. Further, we\ntake several big steps towards real world practicality by introducing a rough\nhighly uneven terrain. Critically, we show through experiments that the robot\nlearns to generalize to new rough terrain maps, retaining a 100% success rate.\nTo the best of our knowledge, this is the first paper to introduce a generic\ntraining algorithm teaching generalized PPMC in rough environments to any\nrobot, with just the use of reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 10:14:52 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 08:26:45 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Blum", "Tamir", ""], ["Yoshida", "Kazuya", ""]]}, {"id": "2003.02756", "submitter": "Tianyu Liu", "authors": "Tianyu Liu, Xin Zheng, Baobao Chang and Zhifang Sui", "title": "HypoNLI: Exploring the Artificial Patterns of Hypothesis-only Bias in\n  Natural Language Inference", "comments": "LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent studies have shown that for models trained on datasets for\nnatural language inference (NLI), it is possible to make correct predictions by\nmerely looking at the hypothesis while completely ignoring the premise. In this\nwork, we manage to derive adversarial examples in terms of the hypothesis-only\nbias and explore eligible ways to mitigate such bias. Specifically, we extract\nvarious phrases from the hypotheses (artificial patterns) in the training sets,\nand show that they have been strong indicators to the specific labels. We then\nfigure out `hard' and `easy' instances from the original test sets whose labels\nare opposite to or consistent with those indications. We also set up baselines\nincluding both pretrained models (BERT, RoBERTa, XLNet) and competitive\nnon-pretrained models (InferSent, DAM, ESIM). Apart from the benchmark and\nbaselines, we also investigate two debiasing approaches which exploit the\nartificial pattern modeling to mitigate such hypothesis-only bias:\ndown-sampling and adversarial training. We believe those methods can be treated\nas competitive baselines in NLI debiasing tasks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 16:46:35 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 02:47:53 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Liu", "Tianyu", ""], ["Zheng", "Xin", ""], ["Chang", "Baobao", ""], ["Sui", "Zhifang", ""]]}, {"id": "2003.02763", "submitter": "Daniel Ish", "authors": "Daniel Ish, Andrew Lohn, Christian Curriden", "title": "A Quantitative History of A.I. Research in the United States and China", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recent interest in the status and consequences of competition\nbetween the U.S. and China in A.I. research, we analyze 60 years of abstract\ndata scraped from Scopus to explore and quantify trends in publications on A.I.\ntopics from institutions affiliated with each country. We find the total volume\nof publications produced in both countries grows with a remarkable regularity\nover tens of years. While China initially experienced faster growth in\npublication volume than the U.S., growth slowed in China when it reached parity\nwith the U.S. and the growth rates of both countries are now similar. We also\nsee both countries undergo a seismic shift in topic choice around 1990, and\nconnect this to an explosion of interest in neural network methods. Finally, we\nsee evidence that between 2000 and 2010, China's topic choice tended to lag\nthat of the U.S. but that in recent decades the topic portfolios have come into\ncloser alignment.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 16:55:31 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 14:35:39 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Ish", "Daniel", ""], ["Lohn", "Andrew", ""], ["Curriden", "Christian", ""]]}, {"id": "2003.02774", "submitter": "Francesco Palmieri A. N.", "authors": "Francesco A. N. Palmieri and Krishna R. Pattipati and Giovanni\n  Fioretti and Giovanni Di Gennaro and Amedeo Buonanno", "title": "Path Planning Using Probability Tensor Flows", "comments": "Submitted for journal publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probability models have been proposed in the literature to account for\n\"intelligent\" behavior in many contexts. In this paper, probability propagation\nis applied to model agent's motion in potentially complex scenarios that\ninclude goals and obstacles. The backward flow provides precious background\ninformation to the agent's behavior, viz., inferences coming from the future\ndetermine the agent's actions. Probability tensors are layered in time in both\ndirections in a manner similar to convolutional neural networks. The discussion\nis carried out with reference to a set of simulated grids where, despite the\napparent task complexity, a solution, if feasible, is always found. The\noriginal model proposed by Attias has been extended to include non-absorbing\nobstacles, multiple goals and multiple agents. The emerging behaviors are very\nrealistic and demonstrate great potentials of the application of this framework\nto real environments.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 17:14:52 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Palmieri", "Francesco A. N.", ""], ["Pattipati", "Krishna R.", ""], ["Fioretti", "Giovanni", ""], ["Di Gennaro", "Giovanni", ""], ["Buonanno", "Amedeo", ""]]}, {"id": "2003.02913", "submitter": "Yimeng Lu", "authors": "Yimeng Lu and Maryam Kamgarpour", "title": "Safe Mission Planning under Dynamical Uncertainties", "comments": "This paper appears in ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers safe robot mission planning in uncertain dynamical\nenvironments. This problem arises in applications such as surveillance,\nemergency rescue, and autonomous driving. It is a challenging problem due to\nmodeling and integrating dynamical uncertainties into a safe planning\nframework, and finding a solution in a computationally tractable way. In this\nwork, we first develop a probabilistic model for dynamical uncertainties. Then,\nwe provide a framework to generate a path that maximizes safety for complex\nmissions by incorporating the uncertainty model. We also devise a Monte Carlo\nmethod to obtain a safe path efficiently. Finally, we evaluate the performance\nof our approach and compare it to potential alternatives in several case\nstudies.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 20:45:42 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Lu", "Yimeng", ""], ["Kamgarpour", "Maryam", ""]]}, {"id": "2003.02979", "submitter": "Hengyuan Hu", "authors": "Hengyuan Hu, Adam Lerer, Alex Peysakhovich, Jakob Foerster", "title": "\"Other-Play\" for Zero-Shot Coordination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of zero-shot coordination - constructing AI agents\nthat can coordinate with novel partners they have not seen before (e.g.\nhumans). Standard Multi-Agent Reinforcement Learning (MARL) methods typically\nfocus on the self-play (SP) setting where agents construct strategies by\nplaying the game with themselves repeatedly. Unfortunately, applying SP naively\nto the zero-shot coordination problem can produce agents that establish highly\nspecialized conventions that do not carry over to novel partners they have not\nbeen trained with. We introduce a novel learning algorithm called other-play\n(OP), that enhances self-play by looking for more robust strategies, exploiting\nthe presence of known symmetries in the underlying problem. We characterize OP\ntheoretically as well as experimentally. We study the cooperative card game\nHanabi and show that OP agents achieve higher scores when paired with\nindependently trained agents. In preliminary results we also show that our OP\nagents obtains higher average scores when paired with human players, compared\nto state-of-the-art SP agents.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 00:39:37 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 17:58:40 GMT"}, {"version": "v3", "created": "Wed, 12 May 2021 05:22:20 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Hu", "Hengyuan", ""], ["Lerer", "Adam", ""], ["Peysakhovich", "Alex", ""], ["Foerster", "Jakob", ""]]}, {"id": "2003.02986", "submitter": "Xiao Ma", "authors": "Xiao Ma, Ariel Liu", "title": "Challenges in Supporting Exploratory Search through Voice Assistants", "comments": "For workshop \"Mapping Grand Challenges for the Conversational User\n  Interface Community\", CHI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice assistants have been successfully adopted for simple, routine tasks,\nsuch as asking for the weather or setting an alarm. However, as people get more\nfamiliar with voice assistants, they may increase their expectations for more\ncomplex tasks, such as exploratory search-- e.g., \"What should I do when I\nvisit Paris with kids? Oh, and ideally not too expensive.\" Compared to simple\nsearch tasks such as \"How tall is the Eiffel Tower?\", which can be answered\nwith a single-shot answer, the response to exploratory search is more nuanced,\nespecially through voice-based assistants. In this paper, we outline four\nchallenges in designing voice assistants that can better support exploratory\nsearch: addressing situationally induced impairments; working with mixed-modal\ninteractions; designing for diverse populations; and meeting users'\nexpectations and gaining their trust. Addressing these challenges is important\nfor developing more \"intelligent\" voice-based personal assistants.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 01:10:39 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Ma", "Xiao", ""], ["Liu", "Ariel", ""]]}, {"id": "2003.03069", "submitter": "Sattaya Singkul", "authors": "Sattaya Singkul, Borirat Khampingyot, Nattasit Maharattamalai, Supawat\n  Taerungruang and Tawunrat Chalothorn", "title": "Parsing Thai Social Data: A New Challenge for Thai NLP", "comments": "7 Pages, 8 figures, to be published in The 14th International Joint\n  Symposium on Artificial Intelligence and Natural Language Processing\n  (iSAI-NLP 2019)", "journal-ref": null, "doi": "10.1109/iSAI-NLP48611.2019.9045639", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Dependency parsing (DP) is a task that analyzes text for syntactic structure\nand relationship between words. DP is widely used to improve natural language\nprocessing (NLP) applications in many languages such as English. Previous works\non DP are generally applicable to formally written languages. However, they do\nnot apply to informal languages such as the ones used in social networks.\nTherefore, DP has to be researched and explored with such social network data.\nIn this paper, we explore and identify a DP model that is suitable for Thai\nsocial network data. After that, we will identify the appropriate linguistic\nunit as an input. The result showed that, the transition based model called,\nimprove Elkared dependency parser outperform the others at UAS of 81.42%.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 08:18:13 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Singkul", "Sattaya", ""], ["Khampingyot", "Borirat", ""], ["Maharattamalai", "Nattasit", ""], ["Taerungruang", "Supawat", ""], ["Chalothorn", "Tawunrat", ""]]}, {"id": "2003.03133", "submitter": "Kshitij Tiwari", "authors": "Kshitij Tiwari, Ville Kyrki, Allen Cheung, Naohide Yamamoto", "title": "DeFINE: Delayed Feedback based Immersive Navigation Environment for\n  Studying Goal-Directed Human Navigation", "comments": "43 pages, 10 figures, 5 tables, Submitted to Behavioral Research\n  Methods", "journal-ref": "Behav Res (2021)", "doi": "10.3758/s13428-021-01586-6", "report-no": null, "categories": "cs.HC cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the advent of consumer-grade products for presenting an immersive\nvirtual environment (VE), there is a growing interest in utilizing VEs for\ntesting human navigation behavior. However, preparing a VE still requires a\nhigh level of technical expertise in computer graphics and virtual reality,\nposing a significant hurdle to embracing the emerging technology. To address\nthis issue, this paper presents Delayed Feedback based Immersive Navigation\nEnvironment (DeFINE), a framework that allows for easy creation and\nadministration of navigation tasks within customizable VEs via intuitive\ngraphical user interfaces and simple settings files. Importantly, DeFINE has a\nbuilt-in capability to provide performance feedback to participants during an\nexperiment, a feature that is critically missing in other similar frameworks.\nTo show the usability of DeFINE from both experimentalists' and participants'\nperspectives, a demonstration was made in which participants navigated to a\nhidden goal location with feedback that differentially weighted speed and\naccuracy of their responses. In addition, the participants evaluated DeFINE in\nterms of its ease of use, required workload, and proneness to induce\ncybersickness. The demonstration exemplified typical experimental manipulations\nDeFINE accommodates and what types of data it can collect for characterizing\nparticipants' task performance. With its out-of-the-box functionality and\npotential customizability due to open-source licensing, DeFINE makes VEs more\naccessible to many researchers.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 11:00:12 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 09:03:41 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Tiwari", "Kshitij", ""], ["Kyrki", "Ville", ""], ["Cheung", "Allen", ""], ["Yamamoto", "Naohide", ""]]}, {"id": "2003.03136", "submitter": "Oriol Ramos Terrades", "authors": "B. Gautam and O. Ramos Terrades and J. M. Pujades and M. Valls", "title": "Knowledge graph based methods for record linkage", "comments": "the paper is under consideration at Pattern Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Nowadays, it is common in Historical Demography the use of individual-level\ndata as a consequence of a predominant life-course approach for the\nunderstanding of the demographic behaviour, family transition, mobility, etc.\nRecord linkage advance is key in these disciplines since it allows to increase\nthe volume and the data complexity to be analyzed. However, current methods are\nconstrained to link data coming from the same kind of sources. Knowledge graph\nare flexible semantic representations, which allow to encode data variability\nand semantic relations in a structured manner.\n  In this paper we propose the knowledge graph use to tackle record linkage\ntask. The proposed method, named {\\bf WERL}, takes advantage of the main\nknowledge graph properties and learns embedding vectors to encode census\ninformation. These embeddings are properly weighted to maximize the record\nlinkage performance. We have evaluated this method on benchmark data sets and\nwe have compared it to related methods with stimulating and satisfactory\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 11:09:44 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Gautam", "B.", ""], ["Terrades", "O. Ramos", ""], ["Pujades", "J. M.", ""], ["Valls", "M.", ""]]}, {"id": "2003.03168", "submitter": "Patrick Hart C", "authors": "Patrick Hart, Leonard Rychly, Alois Knol", "title": "Lane-Merging Using Policy-based Reinforcement Learning and\n  Post-Optimization", "comments": null, "journal-ref": null, "doi": "10.1109/ITSC.2019.8917002", "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many current behavior generation methods struggle to handle real-world\ntraffic situations as they do not scale well with complexity. However,\nbehaviors can be learned off-line using data-driven approaches. Especially,\nreinforcement learning is promising as it implicitly learns how to behave\nutilizing collected experiences. In this work, we combine policy-based\nreinforcement learning with local optimization to foster and synthesize the\nbest of the two methodologies. The policy-based reinforcement learning\nalgorithm provides an initial solution and guiding reference for the\npost-optimization. Therefore, the optimizer only has to compute a single\nhomotopy class, e.g.\\ drive behind or in front of the other vehicle. By storing\nthe state-history during reinforcement learning, it can be used for constraint\nchecking and the optimizer can account for interactions. The post-optimization\nadditionally acts as a safety-layer and the novel method, thus, can be applied\nin safety-critical applications. We evaluate the proposed method using\nlane-change scenarios with a varying number of vehicles.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 12:57:25 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Hart", "Patrick", ""], ["Rychly", "Leonard", ""], ["Knol", "Alois", ""]]}, {"id": "2003.03181", "submitter": "Constantine Goulimis", "authors": "Constantine Goulimis, Gast\\'on Simone", "title": "Can ML predict the solution value for a difficult combinatorial problem?", "comments": "The work will be presented in the PMO104 workshop (2 & 3 April 2020)\n  organised by the German Operations Research Society in Bad Honnef", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We look at whether machine learning can predict the final objective function\nvalue of a difficult combinatorial optimisation problem from the input. Our\ncontext is the pattern reduction problem, one industrially important but\ndifficult aspect of the cutting stock problem. Machine learning appears to have\nhigher prediction accuracy than a na\\\"ive model, reducing mean absolute\npercentage error (MAPE) from 12.0% to 8.7%.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 13:20:42 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Goulimis", "Constantine", ""], ["Simone", "Gast\u00f3n", ""]]}, {"id": "2003.03220", "submitter": "Ozan \\c{C}atal", "authors": "Ozan \\c{C}atal, Samuel Wauthier, Tim Verbelen, Cedric De Boom, Bart\n  Dhoedt", "title": "Deep Active Inference for Autonomous Robot Navigation", "comments": "workshop paper at BAICS at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Active inference is a theory that underpins the way biological agent's\nperceive and act in the real world. At its core, active inference is based on\nthe principle that the brain is an approximate Bayesian inference engine,\nbuilding an internal generative model to drive agents towards minimal surprise.\nAlthough this theory has shown interesting results with grounding in cognitive\nneuroscience, its application remains limited to simulations with small,\npredefined sensor and state spaces.\n  In this paper, we leverage recent advances in deep learning to build more\ncomplex generative models that can work without a predefined states space.\nState representations are learned end-to-end from real-world, high-dimensional\nsensory data such as camera frames. We also show that these generative models\ncan be used to engage in active inference. To the best of our knowledge this is\nthe first application of deep active inference for a real-world robot\nnavigation task.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 14:01:01 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["\u00c7atal", "Ozan", ""], ["Wauthier", "Samuel", ""], ["Verbelen", "Tim", ""], ["De Boom", "Cedric", ""], ["Dhoedt", "Bart", ""]]}, {"id": "2003.03239", "submitter": "Mutian He", "authors": "Mutian He, Yangqiu Song, Kun Xu, Dong Yu", "title": "On the Role of Conceptualization in Commonsense Knowledge Graph\n  Construction", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Commonsense knowledge graphs (CKGs) like Atomic and ASER are substantially\ndifferent from conventional KGs as they consist of much larger number of nodes\nformed by loosely-structured text, which, though, enables them to handle highly\ndiverse queries in natural language related to commonsense, leads to unique\nchallenges for automatic KG construction methods. Besides identifying relations\nabsent from the KG between nodes, such methods are also expected to explore\nabsent nodes represented by text, in which different real-world things, or\nentities, may appear. To deal with the innumerable entities involved with\ncommonsense in the real world, we introduce to CKG construction methods\nconceptualization, i.e., to view entities mentioned in text as instances of\nspecific concepts or vice versa. We build synthetic triples by\nconceptualization, and further formulate the task as triple classification,\nhandled by a discriminatory model with knowledge transferred from pretrained\nlanguage models and fine-tuned by negative sampling. Experiments demonstrate\nthat our methods can effectively identify plausible triples and expand the KG\nby triples of both new nodes and edges of high diversity and novelty.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 14:35:20 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 17:31:10 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["He", "Mutian", ""], ["Song", "Yangqiu", ""], ["Xu", "Kun", ""], ["Yu", "Dong", ""]]}, {"id": "2003.03268", "submitter": "Alberto Alvarez", "authors": "Alberto Alvarez and Jose Font", "title": "Learning the Designer's Preferences to Drive Evolution", "comments": "16 pages, Accepted and to appear in proceedings of the 23rd European\n  Conference on the Applications of Evolutionary and bio-inspired Computation,\n  EvoApplications 2020", "journal-ref": null, "doi": "10.1007/978-3-030-43722-0_28", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the Designer Preference Model, a data-driven solution\nthat pursues to learn from user generated data in a Quality-Diversity\nMixed-Initiative Co-Creativity (QD MI-CC) tool, with the aims of modelling the\nuser's design style to better assess the tool's procedurally generated content\nwith respect to that user's preferences. Through this approach, we aim for\nincreasing the user's agency over the generated content in a way that neither\nstalls the user-tool reciprocal stimuli loop nor fatigues the user with\nperiodical suggestion handpicking. We describe the details of this novel\nsolution, as well as its implementation in the MI-CC tool the Evolutionary\nDungeon Designer. We present and discuss our findings out of the initial tests\ncarried out, spotting the open challenges for this combined line of research\nthat integrates MI-CC with Procedural Content Generation through Machine\nLearning.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 15:10:09 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Alvarez", "Alberto", ""], ["Font", "Jose", ""]]}, {"id": "2003.03350", "submitter": "Kyrylo Malakhov", "authors": "Oleksandr Palagin, Vitalii Velychko, Kyrylo Malakhov and Oleksandr\n  Shchurov", "title": "Distributional semantic modeling: a revised technique to train term/word\n  vector space models applying the ontology-related approach", "comments": "In English, 9 pages, 2 figures. Not published yet. Prepared for\n  special issue (UkrPROG 2020 conference) of the scientific journal \"Problems\n  in programming\" (Founder: National Academy of Sciences of Ukraine, Institute\n  of Software Systems of NAS Ukraine)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a new technique for the distributional semantic modeling with a\nneural network-based approach to learn distributed term representations (or\nterm embeddings) - term vector space models as a result, inspired by the recent\nontology-related approach (using different types of contextual knowledge such\nas syntactic knowledge, terminological knowledge, semantic knowledge, etc.) to\nthe identification of terms (term extraction) and relations between them\n(relation extraction) called semantic pre-processing technology - SPT. Our\nmethod relies on automatic term extraction from the natural language texts and\nsubsequent formation of the problem-oriented or application-oriented (also\ndeeply annotated) text corpora where the fundamental entity is the term\n(includes non-compositional and compositional terms). This gives us an\nopportunity to changeover from distributed word representations (or word\nembeddings) to distributed term representations (or term embeddings). This\ntransition will allow to generate more accurate semantic maps of different\nsubject domains (also, of relations between input terms - it is useful to\nexplore clusters and oppositions, or to test your hypotheses about them). The\nsemantic map can be represented as a graph using Vec2graph - a Python library\nfor visualizing word embeddings (term embeddings in our case) as dynamic and\ninteractive graphs. The Vec2graph library coupled with term embeddings will not\nonly improve accuracy in solving standard NLP tasks, but also update the\nconventional concept of automated ontology development. The main practical\nresult of our work is the development kit (set of toolkits represented as web\nservice APIs and web application), which provides all necessary routines for\nthe basic linguistic pre-processing and the semantic pre-processing of the\nnatural language texts in Ukrainian for future training of term vector space\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 18:27:39 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Palagin", "Oleksandr", ""], ["Velychko", "Vitalii", ""], ["Malakhov", "Kyrylo", ""], ["Shchurov", "Oleksandr", ""]]}, {"id": "2003.03377", "submitter": "Alberto Alvarez", "authors": "Alberto Alvarez, Steve Dahlskog, Jose Font and Julian Togelius", "title": "Interactive Constrained MAP-Elites: Analysis and Evaluation of the\n  Expressiveness of the Feature Dimensions", "comments": "10 pages, 7 figures, Accepted by IEEE Transactions on Games for\n  publication. arXiv admin note: substantial text overlap with arXiv:1906.05175", "journal-ref": "IEEE Transactions on Games, pp. 1-10, 2020", "doi": "10.1109/TG.2020.3046133", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Interactive Constrained MAP-Elites, a quality-diversity\nsolution for game content generation, implemented as a new feature of the\nEvolutionary Dungeon Designer: a mixed-initiative co-creativity tool for\ndesigning dungeons. The feature uses the MAP-Elites algorithm, an illumination\nalgorithm that segregates the population among several cells depending on their\nscores with respect to different behavioral dimensions. Users can flexibly and\ndynamically alternate between these dimensions anytime, thus guiding the\nevolutionary process in an intuitive way, and then incorporate suggestions\nproduced by the algorithm in their room designs. At the same time, any\nmodifications performed by the human user will feed back into MAP-Elites,\nclosing a circular workflow of constant mutual inspiration. This paper presents\nthe algorithm followed by an in-depth analysis of its behaviour, with the aims\nof evaluating the expressive range of all possible dimension combinations in\nseveral scenarios, as well as discussing their influence in the fitness\nlandscape and in the overall performance of the mixed-initiative procedural\ncontent generation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 15:03:21 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 10:43:34 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Alvarez", "Alberto", ""], ["Dahlskog", "Steve", ""], ["Font", "Jose", ""], ["Togelius", "Julian", ""]]}, {"id": "2003.03410", "submitter": "Jakub Kowalski", "authors": "Jakub Kowalski, Marek Szyku{\\l}a", "title": "Experimental Studies in General Game Playing: An Experience Report", "comments": null, "journal-ref": "The AAAI 2020 Workshop on Reproducible AI - RAI2020", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe nearly fifteen years of General Game Playing experimental\nresearch history in the context of reproducibility and fairness of comparisons\nbetween various GGP agents and systems designed to play games described by\ndifferent formalisms. We think our survey may provide an interesting\nperspective of how chaotic methods were allowed when nothing better was\npossible. Finally, from our experience-based view, we would like to propose a\nfew recommendations of how such specific heterogeneous branch of research\nshould be handled appropriately in the future. The goal of this note is to\npoint out common difficulties and problems in the experimental research in the\narea. We hope that our recommendations will help in avoiding them in future\nworks and allow more fair and reproducible comparisons.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 19:53:28 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Kowalski", "Jakub", ""], ["Szyku\u0142a", "Marek", ""]]}, {"id": "2003.03433", "submitter": "Hangyu Mao", "authors": "Hangyu Mao, Zhibo Gong, and Zhen Xiao", "title": "Reward Design in Cooperative Multi-agent Reinforcement Learning for\n  Packet Routing", "comments": "cover https://openreview.net/forum?id=r15kjpHa-", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cooperative multi-agent reinforcement learning (MARL), how to design a\nsuitable reward signal to accelerate learning and stabilize convergence is a\ncritical problem. The global reward signal assigns the same global reward to\nall agents without distinguishing their contributions, while the local reward\nsignal provides different local rewards to each agent based solely on\nindividual behavior. Both of the two reward assignment approaches have some\nshortcomings: the former might encourage lazy agents, while the latter might\nproduce selfish agents.\n  In this paper, we study reward design problem in cooperative MARL based on\npacket routing environments. Firstly, we show that the above two reward signals\nare prone to produce suboptimal policies. Then, inspired by some observations\nand considerations, we design some mixed reward signals, which are\noff-the-shelf to learn better policies. Finally, we turn the mixed reward\nsignals into the adaptive counterparts, which achieve best results in our\nexperiments. Other reward signals are also discussed in this paper. As reward\ndesign is a very fundamental problem in RL and especially in MARL, we hope that\nMARL researchers can rethink the rewards used in their systems.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 02:27:46 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Mao", "Hangyu", ""], ["Gong", "Zhibo", ""], ["Xiao", "Zhen", ""]]}, {"id": "2003.03446", "submitter": "Pratyay Banerjee", "authors": "Chitta Baral, Pratyay Banerjee, Kuntal Kumar Pal, Arindam Mitra", "title": "Natural Language QA Approaches using Reasoning with External Knowledge", "comments": "6 pages, 3 figures, Work in Progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) in natural language (NL) has been an important aspect\nof AI from its early days. Winograd's ``councilmen'' example in his 1972 paper\nand McCarthy's Mr. Hug example of 1976 highlights the role of external\nknowledge in NL understanding. While Machine Learning has been the go-to\napproach in NL processing as well as NL question answering (NLQA) for the last\n30 years, recently there has been an increasingly emphasized thread on NLQA\nwhere external knowledge plays an important role. The challenges inspired by\nWinograd's councilmen example, and recent developments such as the Rebooting AI\nbook, various NLQA datasets, research on knowledge acquisition in the NLQA\ncontext, and their use in various NLQA models have brought the issue of NLQA\nusing ``reasoning'' with external knowledge to the forefront. In this paper, we\npresent a survey of the recent work on them. We believe our survey will help\nestablish a bridge between multiple fields of AI, especially between (a) the\ntraditional fields of knowledge representation and reasoning and (b) the field\nof NL understanding and NLQA.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 21:28:44 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Baral", "Chitta", ""], ["Banerjee", "Pratyay", ""], ["Pal", "Kuntal Kumar", ""], ["Mitra", "Arindam", ""]]}, {"id": "2003.03456", "submitter": "P Sharoff", "authors": "P Sharoff, Nishant A. Mehta, Ravi Ganti", "title": "A Farewell to Arms: Sequential Reward Maximization on a Budget with a\n  Giving Up Option", "comments": "16 pages, AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a sequential decision-making problem where an agent can take one\naction at a time and each action has a stochastic temporal extent, i.e., a new\naction cannot be taken until the previous one is finished. Upon completion, the\nchosen action yields a stochastic reward. The agent seeks to maximize its\ncumulative reward over a finite time budget, with the option of \"giving up\" on\na current action -- hence forfeiting any reward -- in order to choose another\naction. We cast this problem as a variant of the stochastic multi-armed bandits\nproblem with stochastic consumption of resource. For this problem, we first\nestablish that the optimal arm is the one that maximizes the ratio of the\nexpected reward of the arm to the expected waiting time before the agent sees\nthe reward due to pulling that arm. Using a novel upper confidence bound on\nthis ratio, we then introduce an upper confidence based-algorithm, WAIT-UCB,\nfor which we establish logarithmic, problem-dependent regret bound which has an\nimproved dependence on problem parameters compared to previous works.\nSimulations on various problem configurations comparing WAIT-UCB against the\nstate-of-the-art algorithms are also presented.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 22:16:20 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Sharoff", "P", ""], ["Mehta", "Nishant A.", ""], ["Ganti", "Ravi", ""]]}, {"id": "2003.03480", "submitter": "Huimin Zhang", "authors": "Huimin Zhang, Yafei Wang, Junjia Liu, Chengwei Li, Taiyuan Ma,\n  Chengliang Yin", "title": "A Multi-Modal States based Vehicle Descriptor and Dilated Convolutional\n  Social Pooling for Vehicle Trajectory Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precise trajectory prediction of surrounding vehicles is critical for\ndecision-making of autonomous vehicles and learning-based approaches are well\nrecognized for the robustness. However, state-of-the-art learning-based methods\nignore 1) the feasibility of the vehicle's multi-modal state information for\nprediction and 2) the mutual exclusive relationship between the global traffic\nscene receptive fields and the local position resolution when modeling\nvehicles' interactions, which may influence prediction accuracy. Therefore, we\npropose a vehicle-descriptor based LSTM model with the dilated convolutional\nsocial pooling (VD+DCS-LSTM) to cope with the above issues. First, each\nvehicle's multi-modal state information is employed as our model's input and a\nnew vehicle descriptor encoded by stacked sparse auto-encoders is proposed to\nreflect the deep interactive relationships between various states, achieving\nthe optimal feature extraction and effective use of multi-modal inputs.\nSecondly, the LSTM encoder is used to encode the historical sequences composed\nof the vehicle descriptor and a novel dilated convolutional social pooling is\nproposed to improve modeling vehicles' spatial interactions. Thirdly, the LSTM\ndecoder is used to predict the probability distribution of future trajectories\nbased on maneuvers. The validity of the overall model was verified over the\nNGSIM US-101 and I-80 datasets and our method outperforms the latest benchmark.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 01:23:20 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Zhang", "Huimin", ""], ["Wang", "Yafei", ""], ["Liu", "Junjia", ""], ["Li", "Chengwei", ""], ["Ma", "Taiyuan", ""], ["Yin", "Chengliang", ""]]}, {"id": "2003.03516", "submitter": "Lingfeng Tao", "authors": "Lingfeng Tao, Michael Bowman, Xu Zhou, Jiucai Zhang, Xiaoli Zhang", "title": "Learn and Transfer Knowledge of Preferred Assistance Strategies in\n  Semi-autonomous Telemanipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enabling robots to provide effective assistance yet still accommodating the\noperator's commands for telemanipulation of an object is very challenging\nbecause robot's assistive action is not always intuitive for human operators\nand human behaviors and preferences are sometimes ambiguous for the robot to\ninterpret. Although various assistance approaches are being developed to\nimprove the control quality from different optimization perspectives, the\nproblem still remains in determining the appropriate approach that satisfies\nthe fine motion constraints for the telemanipulation task and preference of the\noperator. To address these problems, we developed a novel preference-aware\nassistance knowledge learning approach. An assistance preference model learns\nwhat assistance is preferred by a human, and a stagewise model updating method\nensures the learning stability while dealing with the ambiguity of human\npreference data. Such a preference-aware assistance knowledge enables a\nteleoperated robot hand to provide more active yet preferred assistance toward\nmanipulation success. We also developed knowledge transfer methods to transfer\nthe preference knowledge across different robot hand structures to avoid\nextensive robot-specific training. Experiments to telemanipulate a 3-finger\nhand and 2-finger hand, respectively, to use, move, and hand over a cup have\nbeen conducted. Results demonstrated that the methods enabled the robots to\neffectively learn the preference knowledge and allowed knowledge transfer\nbetween robots with less training effort.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 04:49:57 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2020 20:21:40 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Tao", "Lingfeng", ""], ["Bowman", "Michael", ""], ["Zhou", "Xu", ""], ["Zhang", "Jiucai", ""], ["Zhang", "Xiaoli", ""]]}, {"id": "2003.03541", "submitter": "Devansh Saxena", "authors": "Devansh Saxena, Karla Badillo-Urquiola, Pamela J. Wisniewski, and\n  Shion Guha", "title": "A Human-Centered Review of the Algorithms used within the U.S. Child\n  Welfare System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The U.S. Child Welfare System (CWS) is charged with improving outcomes for\nfoster youth; yet, they are overburdened and underfunded. To overcome this\nlimitation, several states have turned towards algorithmic decision-making\nsystems to reduce costs and determine better processes for improving CWS\noutcomes. Using a human-centered algorithmic design approach, we synthesize 50\npeer-reviewed publications on computational systems used in CWS to assess how\nthey were being developed, common characteristics of predictors used, as well\nas the target outcomes. We found that most of the literature has focused on\nrisk assessment models but does not consider theoretical approaches (e.g.,\nchild-foster parent matching) nor the perspectives of caseworkers (e.g., case\nnotes). Therefore, future algorithms should strive to be context-aware and\ntheoretically robust by incorporating salient factors identified by past\nresearch. We provide the HCI community with research avenues for developing\nhuman-centered algorithms that redirect attention towards more equitable\noutcomes for CWS.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 09:16:12 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Saxena", "Devansh", ""], ["Badillo-Urquiola", "Karla", ""], ["Wisniewski", "Pamela J.", ""], ["Guha", "Shion", ""]]}, {"id": "2003.03543", "submitter": "Eric Heiden", "authors": "Eric Heiden, Luigi Palmieri, Kai O. Arras, Gaurav S. Sukhatme, Sven\n  Koenig", "title": "Experimental Comparison of Global Motion Planning Algorithms for Wheeled\n  Mobile Robots", "comments": "Extended version of manuscript under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning smooth and energy-efficient motions for wheeled mobile robots is a\ncentral task for applications ranging from autonomous driving to service and\nintralogistic robotics. Over the past decades, a wide variety of motion\nplanners, steer functions and path-improvement techniques have been proposed\nfor such non-holonomic systems. With the objective of comparing this large\nassortment of state-of-the-art motion-planning techniques, we introduce a novel\nopen-source motion-planning benchmark for wheeled mobile robots, whose\nscenarios resemble real-world applications (such as navigating warehouses,\nmoving in cluttered cities or parking), and propose metrics for planning\nefficiency and path quality. Our benchmark is easy to use and extend, and thus\nallows practitioners and researchers to evaluate new motion-planning\nalgorithms, scenarios and metrics easily. We use our benchmark to highlight the\nstrengths and weaknesses of several common state-of-the-art motion planners and\nprovide recommendations on when they should be used.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 09:45:49 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Heiden", "Eric", ""], ["Palmieri", "Luigi", ""], ["Arras", "Kai O.", ""], ["Sukhatme", "Gaurav S.", ""], ["Koenig", "Sven", ""]]}, {"id": "2003.03546", "submitter": "Victor Gallego", "authors": "David Rios Insua, Roi Naveiro, Victor Gallego, Jason Poulos", "title": "Adversarial Machine Learning: Perspectives from Adversarial Risk\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial Machine Learning (AML) is emerging as a major field aimed at the\nprotection of automated ML systems against security threats. The majority of\nwork in this area has built upon a game-theoretic framework by modelling a\nconflict between an attacker and a defender. After reviewing game-theoretic\napproaches to AML, we discuss the benefits that a Bayesian Adversarial Risk\nAnalysis perspective brings when defending ML based systems. A research agenda\nis included.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 10:30:43 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Insua", "David Rios", ""], ["Naveiro", "Roi", ""], ["Gallego", "Victor", ""], ["Poulos", "Jason", ""]]}, {"id": "2003.03623", "submitter": "Swati Padhee", "authors": "Amit Sheth, Swati Padhee, Amelie Gyrard", "title": "Knowledge Graphs and Knowledge Networks: The Story in Brief", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graphs (KGs) represent real-world noisy raw information in a\nstructured form, capturing relationships between entities. However, for dynamic\nreal-world applications such as social networks, recommender systems,\ncomputational biology, relational knowledge representation has emerged as a\nchallenging research problem where there is a need to represent the changing\nnodes, attributes, and edges over time. The evolution of search engine\nresponses to user queries in the last few years is partly because of the role\nof KGs such as Google KG. KGs are significantly contributing to various AI\napplications from link prediction, entity relations prediction, node\nclassification to recommendation and question answering systems. This article\nis an attempt to summarize the journey of KG for AI.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 18:09:18 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Sheth", "Amit", ""], ["Padhee", "Swati", ""], ["Gyrard", "Amelie", ""]]}, {"id": "2003.03645", "submitter": "Nabiha Asghar", "authors": "Nabiha Asghar, Ivan Kobyzev, Jesse Hoey, Pascal Poupart, and Muhammad\n  Bilal Sheikh", "title": "Generating Emotionally Aligned Responses in Dialogues using Affect\n  Control Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art neural dialogue systems excel at syntactic and semantic\nmodelling of language, but often have a hard time establishing emotional\nalignment with the human interactant during a conversation. In this work, we\nbring Affect Control Theory (ACT), a socio-mathematical model of emotions for\nhuman-human interactions, to the neural dialogue generation setting. ACT makes\npredictions about how humans respond to emotional stimuli in social situations.\nDue to this property, ACT and its derivative probabilistic models have been\nsuccessfully deployed in several applications of Human-Computer Interaction,\nincluding empathetic tutoring systems, assistive healthcare devices and\ntwo-person social dilemma games. We investigate how ACT can be used to develop\naffect-aware neural conversational agents, which produce emotionally aligned\nresponses to prompts and take into consideration the affective identities of\nthe interactants.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 19:31:08 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 06:46:25 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Asghar", "Nabiha", ""], ["Kobyzev", "Ivan", ""], ["Hoey", "Jesse", ""], ["Poupart", "Pascal", ""], ["Sheikh", "Muhammad Bilal", ""]]}, {"id": "2003.03676", "submitter": "Seyed Jalaleddin Mousavirad", "authors": "Shahryar Rahnamayan and Seyed Jalaleddin Mousavirad", "title": "Towards Solving Large-scale Expensive Optimization Problems Efficiently\n  Using Coordinate Descent Algorithm", "comments": "Accepted in IEEE International Conference On Systems, Man, and\n  Cybernetics, 2020, Toronto, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems are categorized as large-scale problems, and\nmetaheuristic algorithms as an alternative method to solve large-scale problem;\nthey need the evaluation of many candidate solutions to tackle them prior to\ntheir convergence, which is not affordable for practical applications since the\nmost of them are computationally expensive. In other words, these problems are\nnot only large-scale but also computationally expensive, that makes them very\ndifficult to solve. There is no efficient surrogate model to support\nlarge-scale expensive global optimization (LSEGO) problems. As a result, the\nalgorithms should address LSEGO problems using a limited computational budget\nto be applicable in real-world applications. Coordinate Descent (CD) algorithm\nis an optimization strategy based on the decomposition of a n-dimensional\nproblem into n one-dimensional problem. To the best our knowledge, there is no\nsignificant study to assess benchmark functions with various dimensions and\nlandscape properties to investigate CD algorithm. In this paper, we propose a\nmodified Coordinate Descent algorithm (MCD) to tackle LSEGO problems with a\nlimited computational budget. Our proposed algorithm benefits from two leading\nsteps, namely, finding the region of interest and then shrinkage of the search\nspace by folding it into the half with exponential speed. One of the main\nadvantages of the proposed algorithm is being free of any control parameters,\nwhich makes it far from the intricacies of the tuning process. The proposed\nalgorithm is compared with cooperative co-evolution with delta grouping on 20\nbenchmark functions with dimension 1000. Also, we conducted some experiments on\nCEC-2017, D=10, 30, 50, and 100, to investigate the behavior of MCD algorithm\nin lower dimensions. The results show that MCD is beneficial not only in\nlarge-scale problems, but also in low-scale optimization problems.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 22:48:38 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 12:49:34 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 11:52:50 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Rahnamayan", "Shahryar", ""], ["Mousavirad", "Seyed Jalaleddin", ""]]}, {"id": "2003.03779", "submitter": "Melvin Laux", "authors": "Melvin Laux, Oleg Arenz, Jan Peters, Joni Pajarinen", "title": "Deep Adversarial Reinforcement Learning for Object Disentangling", "comments": "7 pages, IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning in combination with improved training techniques and high\ncomputational power has led to recent advances in the field of reinforcement\nlearning (RL) and to successful robotic RL applications such as in-hand\nmanipulation. However, most robotic RL relies on a well known initial state\ndistribution. In real-world tasks, this information is however often not\navailable. For example, when disentangling waste objects the actual position of\nthe robot w.r.t.\\ the objects may not match the positions the RL policy was\ntrained for. To solve this problem, we present a novel adversarial\nreinforcement learning (ARL) framework. The ARL framework utilizes an\nadversary, which is trained to steer the original agent, the protagonist, to\nchallenging states. We train the protagonist and the adversary jointly to allow\nthem to adapt to the changing policy of their opponent. We show that our method\ncan generalize from training to test scenarios by training an end-to-end system\nfor robot control to solve a challenging object disentangling task. Experiments\nwith a KUKA LBR+ 7-DOF robot arm show that our approach outperforms the\nbaseline method in disentangling when starting from different initial states\nthan provided during training.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 13:20:39 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 14:30:17 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Laux", "Melvin", ""], ["Arenz", "Oleg", ""], ["Peters", "Jan", ""], ["Pajarinen", "Joni", ""]]}, {"id": "2003.03785", "submitter": "Zhangsheng Lai", "authors": "Zhangsheng Lai, Aik Beng Ng, Liang Ze Wong, Simon See, and Shaowei Lin", "title": "Dependently Typed Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning over knowledge graphs is traditionally built upon a hierarchy of\nlanguages in the Semantic Web Stack. Starting from the Resource Description\nFramework (RDF) for knowledge graphs, more advanced constructs have been\nintroduced through various syntax extensions to add reasoning capabilities to\nknowledge graphs. In this paper, we show how standardized semantic web\ntechnologies (RDF and its query language SPARQL) can be reproduced in a unified\nmanner with dependent type theory. In addition to providing the basic\nfunctionalities of knowledge graphs, dependent types add expressiveness in\nencoding both entities and queries, explainability in answers to queries\nthrough witnesses, and compositionality and automation in the construction of\nwitnesses. Using the Coq proof assistant, we demonstrate how to build and query\ndependently typed knowledge graphs as a proof of concept for future works in\nthis direction.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 14:04:23 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Lai", "Zhangsheng", ""], ["Ng", "Aik Beng", ""], ["Wong", "Liang Ze", ""], ["See", "Simon", ""], ["Lin", "Shaowei", ""]]}, {"id": "2003.03875", "submitter": "Xianpei Han", "authors": "Xianpei Han, Zhichun Wang, Jiangtao Zhang, Qinghua Wen, Wenqi Li,\n  Buzhou Tang, Qi Wang, Zhifan Feng, Yang Zhang, Yajuan Lu, Haitao Wang,\n  Wenliang Chen, Hao Shao, Yubo Chen, Kang Liu, Jun Zhao, Taifeng Wang, Kezun\n  Zhang, Meng Wang, Yinlin Jiang, Guilin Qi, Lei Zou, Sen Hu, Minhao Zhang,\n  Yinnian Lin", "title": "Overview of the CCKS 2019 Knowledge Graph Evaluation Track: Entity,\n  Relation, Event and QA", "comments": "21 pages, in Chinese, 9 figures and 17 tables, CCKS 2019 held an\n  evaluation track about knowledge graph with 6 tasks and attracted more than\n  1,600 teams", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph models world knowledge as concepts, entities, and the\nrelationships between them, which has been widely used in many real-world\ntasks. CCKS 2019 held an evaluation track with 6 tasks and attracted more than\n1,600 teams. In this paper, we give an overview of the knowledge graph\nevaluation tract at CCKS 2019. By reviewing the task definition, successful\nmethods, useful resources, good strategies and research challenges associated\nwith each task in CCKS 2019, this paper can provide a helpful reference for\ndeveloping knowledge graph applications and conducting future knowledge graph\nresearches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 00:32:13 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Han", "Xianpei", ""], ["Wang", "Zhichun", ""], ["Zhang", "Jiangtao", ""], ["Wen", "Qinghua", ""], ["Li", "Wenqi", ""], ["Tang", "Buzhou", ""], ["Wang", "Qi", ""], ["Feng", "Zhifan", ""], ["Zhang", "Yang", ""], ["Lu", "Yajuan", ""], ["Wang", "Haitao", ""], ["Chen", "Wenliang", ""], ["Shao", "Hao", ""], ["Chen", "Yubo", ""], ["Liu", "Kang", ""], ["Zhao", "Jun", ""], ["Wang", "Taifeng", ""], ["Zhang", "Kezun", ""], ["Wang", "Meng", ""], ["Jiang", "Yinlin", ""], ["Qi", "Guilin", ""], ["Zou", "Lei", ""], ["Hu", "Sen", ""], ["Zhang", "Minhao", ""], ["Lin", "Yinnian", ""]]}, {"id": "2003.03917", "submitter": "Ala Shaabana", "authors": "Yuma Rao, Jacob Steeves, Ala Shaabana, Daniel Attevelt, Matthew\n  McAteer", "title": "BitTensor: A Peer-to-Peer Intelligence Market", "comments": "The network described in this project is live, source code available\n  on: https://github.com/opentensor/bittensor", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  As with other commodities, markets could help us efficiently produce machine\nintelligence. We propose a market where intelligence is priced by other\nintelligence systems peer-to-peer across the internet. Peers rank each other by\ntraining neural networks which learn the value of their neighbors. Scores\naccumulate on a digital ledger where high ranking peers are monetarily rewarded\nwith additional weight in the network. However, this form of peer-ranking is\nnot resistant to collusion, which could disrupt the accuracy of the mechanism.\nThe solution is a connectivity-based regularization which exponentially rewards\ntrusted peers, making the system resistant to collusion of up to 50 percent of\nthe network weight. The result is a collectively run intelligence market which\ncontinual produces newly trained models and pays contributors who create\ninformation theoretic value.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 04:04:18 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 20:36:51 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Rao", "Yuma", ""], ["Steeves", "Jacob", ""], ["Shaabana", "Ala", ""], ["Attevelt", "Daniel", ""], ["McAteer", "Matthew", ""]]}, {"id": "2003.03924", "submitter": "Tengyang Xie", "authors": "Tengyang Xie, Nan Jiang", "title": "Q* Approximation Schemes for Batch Reinforcement Learning: A Theoretical\n  Comparison", "comments": "Published in UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove performance guarantees of two algorithms for approximating $Q^\\star$\nin batch reinforcement learning. Compared to classical iterative methods such\nas Fitted Q-Iteration---whose performance loss incurs quadratic dependence on\nhorizon---these methods estimate (some forms of) the Bellman error and enjoy\nlinear-in-horizon error propagation, a property established for the first time\nfor algorithms that rely solely on batch data and output stationary policies.\nOne of the algorithms uses a novel and explicit importance-weighting correction\nto overcome the infamous \"double sampling\" difficulty in Bellman error\nestimation, and does not use any squared losses. Our analyses reveal its\ndistinct characteristics and potential advantages compared to classical\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 05:12:39 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 03:32:46 GMT"}, {"version": "v3", "created": "Thu, 9 Apr 2020 21:37:37 GMT"}, {"version": "v4", "created": "Mon, 24 Aug 2020 04:09:22 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Xie", "Tengyang", ""], ["Jiang", "Nan", ""]]}, {"id": "2003.03932", "submitter": "Sunandita Patra", "authors": "Sunandita Patra, James Mason, Amit Kumar, Malik Ghallab, Paolo\n  Traverso, Dana Nau", "title": "Integrating Acting, Planning and Learning in Hierarchical Operational\n  Models", "comments": "Accepted in ICAPS 2020 (30th International Conference on Automated\n  Planning and Scheduling)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new planning and learning algorithms for RAE, the Refinement\nActing Engine. RAE uses hierarchical operational models to perform tasks in\ndynamically changing environments. Our planning procedure, UPOM, does a\nUCT-like search in the space of operational models in order to find a\nnear-optimal method to use for the task and context at hand. Our learning\nstrategies acquire, from online acting experiences and/or simulated planning\nresults, a mapping from decision contexts to method instances as well as a\nheuristic function to guide UPOM. Our experimental results show that UPOM and\nour learning strategies significantly improve RAE's performance in four test\ndomains using two different metrics: efficiency and success ratio.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 06:05:25 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Patra", "Sunandita", ""], ["Mason", "James", ""], ["Kumar", "Amit", ""], ["Ghallab", "Malik", ""], ["Traverso", "Paolo", ""], ["Nau", "Dana", ""]]}, {"id": "2003.04080", "submitter": "Pedro Casas Dr.", "authors": "Pedro Casas", "title": "Two Decades of AI4NETS-AI/ML for Data Networks: Challenges & Research\n  Directions", "comments": null, "journal-ref": "5th IEEE/IFIP International Workshop on Analytics for Network and\n  Service Management (AnNet 2020)", "doi": null, "report-no": null, "categories": "cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of Artificial Intelligence (AI) -- and of Machine Learning\n(ML) as an approach to AI, has dramatically increased in the last few years,\ndue to its outstanding performance in various domains, notably in image, audio,\nand natural language processing. In these domains, AI success-stories are\nboosting the applied field. When it comes to AI/ML for data communication\nNetworks (AI4NETS), and despite the many attempts to turn networks into\nlearning agents, the successful application of AI/ML in networking is limited.\nThere is a strong resistance against AI/ML-based solutions, and a striking gap\nbetween the extensive academic research and the actual deployments of such\nAI/ML-based systems in operational environments. The truth is, there are still\nmany unsolved complex challenges associated to the analysis of networking data\nthrough AI/ML, which hinders its acceptability and adoption in the practice. In\nthis positioning paper I elaborate on the most important show-stoppers in\nAI4NETS, and present a research agenda to tackle some of these challenges,\nenabling a natural adoption of AI/ML for networking. In particular, I focus the\nfuture research in AI4NETS around three major pillars: (i) to make AI/ML\nimmediately applicable in networking problems through the concepts of effective\nlearning, turning it into a useful and reliable way to deal with complex\ndata-driven networking problems; (ii) to boost the adoption of AI/ML at the\nlarge scale by learning from the Internet-paradigm itself, conceiving novel\ndistributed and hierarchical learning approaches mimicking the distributed\ntopological principles and operation of the Internet itself; and (iii) to\nexploit the softwarization and distribution of networks to conceive\nAI/ML-defined Networks (AIDN), relying on the distributed generation and\nre-usage of knowledge through novel Knowledge Delivery Networks (KDNs).\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 00:36:17 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Casas", "Pedro", ""]]}, {"id": "2003.04081", "submitter": "Zlatan Ajanovic", "authors": "Kailin Tong, Zlatan Ajanovic and Georg Stettinger", "title": "Overview of Tools Supporting Planning for Automated Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning is an essential topic in the realm of automated driving. Besides\nplanning algorithms that are widely covered in the literature, planning\nrequires different software tools for its development, validation, and\nexecution. This paper presents a survey of such tools including map\nrepresentations, communication, traffic rules, open-source planning stacks and\nmiddleware, simulation, and visualization tools as well as benchmarks. We start\nby defining the planning task and different supporting tools. Next, we provide\na comprehensive review of state-of-the-art developments and analysis of\nrelations among them. Finally, we discuss the current gaps and suggest future\nresearch directions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 12:38:12 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Tong", "Kailin", ""], ["Ajanovic", "Zlatan", ""], ["Stettinger", "Georg", ""]]}, {"id": "2003.04176", "submitter": "Philipp Wanko", "authors": "Pedro Cabalar and Jorge Fandinno and Torsten Schaub and Philipp Wanko", "title": "A Uniform Treatment of Aggregates and Constraints in Hybrid ASP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing hybrid ASP solving in a generic way is difficult since one\nneeds to abstract from specific theories. Inspired by lazy SMT solving, this is\nusually addressed by treating theory atoms as opaque. Unlike this, we propose a\nslightly more transparent approach that includes an abstract notion of a term.\nRather than imposing a syntax on terms, we keep them abstract by stipulating\nonly some basic properties. With this, we further develop a semantic framework\nfor hybrid ASP solving and provide aggregate functions for theory variables\nthat adhere to different semantic principles, show that they generalize\nexisting aggregate semantics in ASP and how we can rely on off-the-shelf hybrid\nsolvers for implementation.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 14:36:11 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 12:42:54 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Cabalar", "Pedro", ""], ["Fandinno", "Jorge", ""], ["Schaub", "Torsten", ""], ["Wanko", "Philipp", ""]]}, {"id": "2003.04195", "submitter": "Piji Li", "authors": "Piji Li", "title": "An Empirical Investigation of Pre-Trained Transformer Language Models\n  for Open-Domain Dialogue Generation", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an empirical investigation of pre-trained Transformer-based\nauto-regressive language models for the task of open-domain dialogue\ngeneration. Training paradigm of pre-training and fine-tuning is employed to\nconduct the parameter learning. Corpora of News and Wikipedia in Chinese and\nEnglish are collected for the pre-training stage respectively. Dialogue context\nand response are concatenated into a single sequence utilized as the input of\nthe models during the fine-tuning stage. A weighted joint prediction paradigm\nfor both context and response is designed to evaluate the performance of models\nwith or without the loss term for context prediction. Various of decoding\nstrategies such as greedy search, beam search, top-k sampling, etc. are\nemployed to conduct the response text generation. Extensive experiments are\nconducted on the typical single-turn and multi-turn dialogue corpora such as\nWeibo, Douban, Reddit, DailyDialog, and Persona-Chat. Detailed numbers of\nautomatic evaluation metrics on relevance and diversity of the generated\nresults for the languages models as well as the baseline approaches are\nreported.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 15:20:21 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Li", "Piji", ""]]}, {"id": "2003.04203", "submitter": "Neda Navidi", "authors": "Neda Navidi", "title": "Human AI interaction loop training: New approach for interactive\n  reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) in various decision-making tasks of machine\nlearning provides effective results with an agent learning from a stand-alone\nreward function. However, it presents unique challenges with large amounts of\nenvironment states and action spaces, as well as in the determination of\nrewards. This complexity, coming from high dimensionality and continuousness of\nthe environments considered herein, calls for a large number of learning trials\nto learn about the environment through Reinforcement Learning. Imitation\nLearning (IL) offers a promising solution for those challenges using a teacher.\nIn IL, the learning process can take advantage of human-sourced assistance\nand/or control over the agent and environment. A human teacher and an agent\nlearner are considered in this study. The teacher takes part in the agent\ntraining towards dealing with the environment, tackling a specific objective,\nand achieving a predefined goal. Within that paradigm, however, existing IL\napproaches have the drawback of expecting extensive demonstration information\nin long-horizon problems. This paper proposes a novel approach combining IL\nwith different types of RL methods, namely state action reward state action\n(SARSA) and asynchronous advantage actor-critic (A3C) agents, to overcome the\nproblems of both stand-alone systems. It is addressed how to effectively\nleverage the teacher feedback, be it direct binary or indirect detailed for the\nagent learner to learn sequential decision-making policies. The results of this\nstudy on various OpenAI Gym environments show that this algorithmic method can\nbe incorporated with different combinations, significantly decreases both human\nendeavor and tedious exploration process.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 15:27:48 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Navidi", "Neda", ""]]}, {"id": "2003.04218", "submitter": "Christopher Hahn", "authors": "Christopher Hahn, Frederik Schmitt, Jens U. Kreber, Markus N. Rabe,\n  Bernd Finkbeiner", "title": "Teaching Temporal Logics to Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two fundamental questions in neuro-symbolic computing: can deep\nlearning tackle challenging problems in logics end-to-end, and can neural\nnetworks learn the semantics of logics. In this work we focus on linear-time\ntemporal logic (LTL), as it is widely used in verification. We train a\nTransformer on the problem to directly predict a solution, i.e. a trace, to a\ngiven LTL formula. The training data is generated with classical solvers,\nwhich, however, only provide one of many possible solutions to each formula. We\ndemonstrate that it is sufficient to train on those particular solutions to\nformulas, and that Transformers can predict solutions even to formulas from\nbenchmarks from the literature on which the classical solver timed out.\nTransformers also generalize to the semantics of the logics: while they often\ndeviate from the solutions found by the classical solvers, they still predict\ncorrect solutions to most formulas.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 14:46:49 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 20:02:34 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 12:41:20 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Hahn", "Christopher", ""], ["Schmitt", "Frederik", ""], ["Kreber", "Jens U.", ""], ["Rabe", "Markus N.", ""], ["Finkbeiner", "Bernd", ""]]}, {"id": "2003.04225", "submitter": "Roberto Sebastiani", "authors": "Roberto Sebastiani", "title": "Are You Satisfied by This Partial Assignment?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many procedures for SAT and SAT-related problems -- in particular for those\nrequiring the complete enumeration of satisfying truth assignments -- rely\ntheir efficiency on the detection of partial assignments satisfying an input\nformula. In this paper we analyze the notion of partial-assignment\nsatisfiability -- in particular when dealing with non-CNF and\nexistentially-quantified formulas -- raising a flag about the ambiguities and\nsubtleties of this concept, and investigating their practical consequences.\nThis may drive the development of more effective assignment-enumeration\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 17:21:06 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Sebastiani", "Roberto", ""]]}, {"id": "2003.04227", "submitter": "Daniel Abolafia", "authors": "Daniel A. Abolafia, Rishabh Singh, Manzil Zaheer, Charles Sutton", "title": "Towards Modular Algorithm Induction", "comments": "10 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a modular neural network architecture Main that learns algorithms\ngiven a set of input-output examples. Main consists of a neural controller that\ninteracts with a variable-length input tape and learns to compose modules\ntogether with their corresponding argument choices. Unlike previous approaches,\nMain uses a general domain-agnostic mechanism for selection of modules and\ntheir arguments. It uses a general input tape layout together with a parallel\nhistory tape to indicate most recently used locations. Finally, it uses a\nmemoryless controller with a length-invariant self-attention based input tape\nencoding to allow for random access to tape locations. The Main architecture is\ntrained end-to-end using reinforcement learning from a set of input-output\nexamples. We evaluate Main on five algorithmic tasks and show that it can learn\npolicies that generalizes perfectly to inputs of much longer lengths than the\nones used for training.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 22:05:56 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Abolafia", "Daniel A.", ""], ["Singh", "Rishabh", ""], ["Zaheer", "Manzil", ""], ["Sutton", "Charles", ""]]}, {"id": "2003.04310", "submitter": "Filip Tolovski", "authors": "Filip Tolovski", "title": "Advancing Renewable Electricity Consumption With Reinforcement Learning", "comments": "To be presented at the Workshop on Tackling Climate Change with\n  Machine Learning at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the share of renewable energy sources in the present electric energy mix\nrises, their intermittence proves to be the biggest challenge to carbon free\nelectricity generation. To address this challenge, we propose an electricity\npricing agent, which sends price signals to the customers and contributes to\nshifting the customer demand to periods of high renewable energy generation. We\npropose an implementation of a pricing agent with a reinforcement learning\napproach where the environment is represented by the customers, the electricity\ngeneration utilities and the weather conditions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 20:57:58 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Tolovski", "Filip", ""]]}, {"id": "2003.04360", "submitter": "Pushpender Singh", "authors": "Vaishali Ingale, Pushpender Singh", "title": "GenNet : Reading Comprehension with Multiple Choice Questions using\n  Generation and Selection model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiple-choice machine reading comprehension is difficult task as its\nrequired machines to select the correct option from a set of candidate or\npossible options using the given passage and question.Reading Comprehension\nwith Multiple Choice Questions task,required a human (or machine) to read a\ngiven passage, question pair and select the best one option from n given\noptions. There are two different ways to select the correct answer from the\ngiven passage. Either by selecting the best match answer to by eliminating the\nworst match answer. Here we proposed GenNet model, a neural network-based\nmodel. In this model first we will generate the answer of the question from the\npassage and then will matched the generated answer with given answer, the best\nmatched option will be our answer. For answer generation we used S-net (Tan et\nal., 2017) model trained on SQuAD and to evaluate our model we used Large-scale\nRACE (ReAding Comprehension Dataset From Examinations) (Lai et al.,2017).\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 20:35:36 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 06:49:32 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Ingale", "Vaishali", ""], ["Singh", "Pushpender", ""]]}, {"id": "2003.04369", "submitter": "Kumar Sankar Ray", "authors": "Kumar Sankar Ray, Sandip Paul, Diganta Saha", "title": "Belief Base Revision for Further Improvement of Unified Answer Set\n  Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A belief base revision is developed. The belief base is represented using\nUnified Answer Set Programs which is capable of representing imprecise and\nuncertain information and perform nonomonotonic reasoning with them. The base\nrevision operator is developed using Removed Set Revision strategy. The\noperator is characterized with respect to the postulates for base revisions\noperator satisfies.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 08:31:01 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 11:05:36 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Ray", "Kumar Sankar", ""], ["Paul", "Sandip", ""], ["Saha", "Diganta", ""]]}, {"id": "2003.04371", "submitter": "Songyang Han", "authors": "Songyang Han, Fei Miao", "title": "Behavior Planning For Connected Autonomous Vehicles Using Feedback Deep\n  Reinforcement Learning", "comments": "conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of communication technologies, connected autonomous\nvehicles (CAVs) can share information with each other. We propose a novel\nbehavior planning method for CAVs to decide actions such as whether to change\nlane or keep lane based on the observation and shared information from\nneighbors, and to make sure that there exist corresponding control maneuvers\nsuch as acceleration and steering angle to guarantee the safety of each\nindividual autonomous vehicle. We formulate this problem as a hybrid partially\nobservable Markov decision process (HPOMDP) to consider objectives such as\nimproving traffic flow efficiency and driving comfort and safety requirements.\nThe discrete state transition is determined by the proposed feedback deep\nQ-learning algorithm using the feedback action from an underlying controller\nbased on control barrier functions. The feedback deep Q-learning algorithm we\ndesign aims to solve the critical challenge of reinforcement learning (RL) in a\nphysical system: guaranteeing the safety of the system while the RL is\nexploring the action space to increase the reward. We prove that our method\nrenders a forward invariant safe set for the continuous state physical dynamic\nmodel of the system while the RL agent is learning. In experiments, our\nbehavior planning method can increase traffic flow and driving comfort compared\nwith the intelligent driving model (IDM). We also validate that our method\nmaintains safety during the learning process.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 19:15:30 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 13:01:05 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Han", "Songyang", ""], ["Miao", "Fei", ""]]}, {"id": "2003.04404", "submitter": "Ruochen Yin", "authors": "Ruochen Yin, Biao Yu, Huapeng Wu, Yutao Song, Runxin Niu", "title": "FusionLane: Multi-Sensor Fusion for Lane Marking Semantic Segmentation\n  Using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a crucial step to achieve effective semantic segmentation of lane\nmarking during the construction of the lane level high-precision map. In recent\nyears, many image semantic segmentation methods have been proposed. These\nmethods mainly focus on the image from camera, due to the limitation of the\nsensor itself, the accurate three-dimensional spatial position of the lane\nmarking cannot be obtained, so the demand for the lane level high-precision map\nconstruction cannot be met. This paper proposes a lane marking semantic\nsegmentation method based on LIDAR and camera fusion deep neural network.\nDifferent from other methods, in order to obtain accurate position information\nof the segmentation results, the semantic segmentation object of this paper is\na bird's eye view converted from a LIDAR points cloud instead of an image\ncaptured by a camera. This method first uses the deeplabv3+ [\\ref{ref:1}]\nnetwork to segment the image captured by the camera, and the segmentation\nresult is merged with the point clouds collected by the LIDAR as the input of\nthe proposed network. In this neural network, we also add a long short-term\nmemory (LSTM) structure to assist the network for semantic segmentation of lane\nmarkings by using the the time series information. The experiments on more than\n14,000 image datasets which we have manually labeled and expanded have shown\nthe proposed method has better performance on the semantic segmentation of the\npoints cloud bird's eye view. Therefore, the automation of high-precision map\nconstruction can be significantly improved. Our code is available at\nhttps://github.com/rolandying/FusionLane.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 20:33:30 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Yin", "Ruochen", ""], ["Yu", "Biao", ""], ["Wu", "Huapeng", ""], ["Song", "Yutao", ""], ["Niu", "Runxin", ""]]}, {"id": "2003.04411", "submitter": "Wim Martens", "authors": "Diego Figueira and Adwait Godbole and S. Krishna and Wim Martens and\n  Matthias Niewerth and Tina Trautner", "title": "Containment of Simple Regular Path Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing containment of queries is a fundamental reasoning task in knowledge\nrepresentation. We study here the containment problem for Conjunctive Regular\nPath Queries (CRPQs), a navigational query language extensively used in\nontology and graph database querying. While it is known that containment of\nCRPQs is expspace-complete in general, we focus here on severely restricted\nfragments, which are known to be highly relevant in practice according to\nseveral recent studies. We obtain a detailed overview of the complexity of the\ncontainment problem, depending on the features used in the regular expressions\nof the queries, with completeness results for np, pitwo, pspace or expspace.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 21:05:29 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Figueira", "Diego", ""], ["Godbole", "Adwait", ""], ["Krishna", "S.", ""], ["Martens", "Wim", ""], ["Niewerth", "Matthias", ""], ["Trautner", "Tina", ""]]}, {"id": "2003.04427", "submitter": "Yan Zhang", "authors": "Yan Zhang and Michael M. Zavlanos", "title": "Transfer Reinforcement Learning under Unobserved Contextual Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a transfer reinforcement learning problem where the\nstate transitions and rewards are affected by the environmental context.\nSpecifically, we consider a demonstrator agent that has access to a\ncontext-aware policy and can generate transition and reward data based on that\npolicy. These data constitute the experience of the demonstrator. Then, the\ngoal is to transfer this experience, excluding the underlying contextual\ninformation, to a learner agent that does not have access to the environmental\ncontext, so that they can learn a control policy using fewer samples. It is\nwell known that, disregarding the causal effect of the contextual information,\ncan introduce bias in the transition and reward models estimated by the\nlearner, resulting in a learned suboptimal policy. To address this challenge,\nin this paper, we develop a method to obtain causal bounds on the transition\nand reward functions using the demonstrator's data, which we then use to obtain\ncausal bounds on the value functions. Using these value function bounds, we\npropose new Q learning and UCB-Q learning algorithms that converge to the true\nvalue function without bias. We provide numerical experiments for robot motion\nplanning problems that validate the proposed value function bounds and\ndemonstrate that the proposed algorithms can effectively make use of the data\nfrom the demonstrator to accelerate the learning process of the learner.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 22:00:04 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Zhang", "Yan", ""], ["Zavlanos", "Michael M.", ""]]}, {"id": "2003.04445", "submitter": "Michael Painter", "authors": "Michael Painter, Bruno Lacerda and Nick Hawes", "title": "Convex Hull Monte-Carlo Tree Search", "comments": "Camera-ready version of paper accepted to ICAPS 2020, along with\n  relevant appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates Monte-Carlo planning for agents in stochastic\nenvironments, with multiple objectives. We propose the Convex Hull Monte-Carlo\nTree-Search (CHMCTS) framework, which builds upon Trial Based Heuristic Tree\nSearch and Convex Hull Value Iteration (CHVI), as a solution to multi-objective\nplanning in large environments. Moreover, we consider how to pose the problem\nof approximating multiobjective planning solutions as a contextual multi-armed\nbandits problem, giving a principled motivation for how to select actions from\nthe view of contextual regret. This leads us to the use of Contextual Zooming\nfor action selection, yielding Zooming CHMCTS. We evaluate our algorithm using\nthe Generalised Deep Sea Treasure environment, demonstrating that Zooming\nCHMCTS can achieve a sublinear contextual regret and scales better than CHVI on\na given computational budget.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 22:52:59 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 11:01:03 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Painter", "Michael", ""], ["Lacerda", "Bruno", ""], ["Hawes", "Nick", ""]]}, {"id": "2003.04474", "submitter": "Nishad Gothoskar", "authors": "Nishad Gothoskar, Miguel L\\'azaro-Gredilla, Abhishek Agarwal, Yasemin\n  Bekiroglu, Dileep George", "title": "Learning a generative model for robot control using visual feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel formulation for incorporating visual feedback in\ncontrolling robots. We define a generative model from actions to image\nobservations of features on the end-effector. Inference in the model allows us\nto infer the robot state corresponding to target locations of the features.\nThis, in turn, guides motion of the robot and allows for matching the target\nlocations of the features in significantly fewer steps than state-of-the-art\nvisual servoing methods. The training procedure for our model enables effective\nlearning of the kinematics, feature structure, and camera parameters,\nsimultaneously. This can be done with no prior information about the robot,\nstructure, and cameras that observe it. Learning is done sample-efficiently and\nshows strong generalization to test data. Since our formulation is modular, we\ncan modify components of our setup, like cameras and objects, and relearn them\nquickly online. Our method can handle noise in the observed state and noise in\nthe controllers that we interact with. We demonstrate the effectiveness of our\nmethod by executing grasping and tight-fit insertions on robots with inaccurate\ncontrollers.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 00:34:01 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Gothoskar", "Nishad", ""], ["L\u00e1zaro-Gredilla", "Miguel", ""], ["Agarwal", "Abhishek", ""], ["Bekiroglu", "Yasemin", ""], ["George", "Dileep", ""]]}, {"id": "2003.04475", "submitter": "Remi Tachet Des Combes", "authors": "Remi Tachet, Han Zhao, Yu-Xiang Wang and Geoff Gordon", "title": "Domain Adaptation with Conditional Distribution Matching and Generalized\n  Label Shift", "comments": "Appeared in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial learning has demonstrated good performance in the unsupervised\ndomain adaptation setting, by learning domain-invariant representations.\nHowever, recent work has shown limitations of this approach when label\ndistributions differ between the source and target domains. In this paper, we\npropose a new assumption, generalized label shift ($GLS$), to improve\nrobustness against mismatched label distributions. $GLS$ states that,\nconditioned on the label, there exists a representation of the input that is\ninvariant between the source and target domains. Under $GLS$, we provide\ntheoretical guarantees on the transfer performance of any classifier. We also\ndevise necessary and sufficient conditions for $GLS$ to hold, by using an\nestimation of the relative class weights between domains and an appropriate\nreweighting of samples. Our weight estimation method could be straightforwardly\nand generically applied in existing domain adaptation (DA) algorithms that\nlearn domain-invariant representations, with small computational overhead. In\nparticular, we modify three DA algorithms, JAN, DANN and CDAN, and evaluate\ntheir performance on standard and artificial DA tasks. Our algorithms\noutperform the base versions, with vast improvements for large label\ndistribution mismatches. Our code is available at https://tinyurl.com/y585xt6j.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 00:35:23 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 04:01:17 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 21:59:58 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Tachet", "Remi", ""], ["Zhao", "Han", ""], ["Wang", "Yu-Xiang", ""], ["Gordon", "Geoff", ""]]}, {"id": "2003.04492", "submitter": "Hanchao Yu", "authors": "Hanchao Yu, Shanhui Sun, Haichao Yu, Xiao Chen, Honghui Shi, Thomas\n  Huang, Terrence Chen", "title": "FOAL: Fast Online Adaptive Learning for Cardiac Motion Estimation", "comments": "Accepted by CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion estimation of cardiac MRI videos is crucial for the evaluation of\nhuman heart anatomy and function. Recent researches show promising results with\ndeep learning-based methods. In clinical deployment, however, they suffer\ndramatic performance drops due to mismatched distributions between training and\ntesting datasets, commonly encountered in the clinical environment. On the\nother hand, it is arguably impossible to collect all representative datasets\nand to train a universal tracker before deployment. In this context, we\nproposed a novel fast online adaptive learning (FOAL) framework: an online\ngradient descent based optimizer that is optimized by a meta-learner. The\nmeta-learner enables the online optimizer to perform a fast and robust\nadaptation. We evaluated our method through extensive experiments on two public\nclinical datasets. The results showed the superior performance of FOAL in\naccuracy compared to the offline-trained tracking method. On average, the FOAL\ntook only $0.4$ second per video for online optimization.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 01:51:27 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 18:02:53 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Yu", "Hanchao", ""], ["Sun", "Shanhui", ""], ["Yu", "Haichao", ""], ["Chen", "Xiao", ""], ["Shi", "Honghui", ""], ["Huang", "Thomas", ""], ["Chen", "Terrence", ""]]}, {"id": "2003.04493", "submitter": "Qinqing Zheng", "authors": "Qinqing Zheng, Jinshuo Dong, Qi Long, Weijie J. Su", "title": "Sharp Composition Bounds for Gaussian Differential Privacy via Edgeworth\n  Expansion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CR cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets containing sensitive information are often sequentially analyzed by\nmany algorithms. This raises a fundamental question in differential privacy\nregarding how the overall privacy bound degrades under composition. To address\nthis question, we introduce a family of analytical and sharp privacy bounds\nunder composition using the Edgeworth expansion in the framework of the\nrecently proposed f-differential privacy. In contrast to the existing\ncomposition theorems using the central limit theorem, our new privacy bounds\nunder composition gain improved tightness by leveraging the refined\napproximation accuracy of the Edgeworth expansion. Our approach is easy to\nimplement and computationally efficient for any number of compositions. The\nsuperiority of these new bounds is confirmed by an asymptotic error analysis\nand an application to quantifying the overall privacy guarantees of noisy\nstochastic gradient descent used in training private deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 01:54:15 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 15:18:11 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Zheng", "Qinqing", ""], ["Dong", "Jinshuo", ""], ["Long", "Qi", ""], ["Su", "Weijie J.", ""]]}, {"id": "2003.04514", "submitter": "Homanga Bharadhwaj", "authors": "Samarth Sinha, Homanga Bharadhwaj, Anirudh Goyal, Hugo Larochelle,\n  Animesh Garg, Florian Shkurti", "title": "Diversity inducing Information Bottleneck in Model Ensembles", "comments": "AAAI 2021. Samarth Sinha* and Homanga Bharadhwaj* contributed equally\n  to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning models have achieved state-of-the-art performance on a\nnumber of vision tasks, generalization over high dimensional multi-modal data,\nand reliable predictive uncertainty estimation are still active areas of\nresearch. Bayesian approaches including Bayesian Neural Nets (BNNs) do not\nscale well to modern computer vision tasks, as they are difficult to train, and\nhave poor generalization under dataset-shift. This motivates the need for\neffective ensembles which can generalize and give reliable uncertainty\nestimates. In this paper, we target the problem of generating effective\nensembles of neural networks by encouraging diversity in prediction. We\nexplicitly optimize a diversity inducing adversarial loss for learning the\nstochastic latent variables and thereby obtain diversity in the output\npredictions necessary for modeling multi-modal data. We evaluate our method on\nbenchmark datasets: MNIST, CIFAR100, TinyImageNet and MIT Places 2, and\ncompared to the most competitive baselines show significant improvements in\nclassification accuracy, under a shift in the data distribution and in\nout-of-distribution detection. Code will be released in this url\nhttps://github.com/rvl-lab-utoronto/dibs\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 03:10:41 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 22:57:12 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 20:14:08 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Sinha", "Samarth", ""], ["Bharadhwaj", "Homanga", ""], ["Goyal", "Anirudh", ""], ["Larochelle", "Hugo", ""], ["Garg", "Animesh", ""], ["Shkurti", "Florian", ""]]}, {"id": "2003.04518", "submitter": "Yan Song", "authors": "Yan Song, Yingfeng Chen, Yujing Hu, Changjie Fan", "title": "Exploring Unknown States with Action Balance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is a key problem in reinforcement learning. Recently bonus-based\nmethods have achieved considerable successes in environments where exploration\nis difficult such as Montezuma's Revenge, which assign additional bonuses\n(e.g., intrinsic rewards) to guide the agent to rarely visited states. Since\nthe bonus is calculated according to the novelty of the next state after\nperforming an action, we call such methods as the next-state bonus methods.\nHowever, the next-state bonus methods force the agent to pay overmuch attention\nin exploring known states and ignore finding unknown states since the\nexploration is driven by the next state already visited, which may slow the\npace of finding reward in some environments. In this paper, we focus on\nimproving the effectiveness of finding unknown states and propose action\nbalance exploration, which balances the frequency of selecting each action at a\ngiven state and can be treated as an extension of upper confidence bound (UCB)\nto deep reinforcement learning. Moreover, we propose action balance RND that\ncombines the next-state bonus methods (e.g., random network distillation\nexploration, RND) and our action balance exploration to take advantage of both\nsides. The experiments on the grid world and Atari games demonstrate action\nbalance exploration has a better capability in finding unknown states and can\nimprove the performance of RND in some hard exploration environments\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 03:32:28 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 07:11:52 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Song", "Yan", ""], ["Chen", "Yingfeng", ""], ["Hu", "Yujing", ""], ["Fan", "Changjie", ""]]}, {"id": "2003.04521", "submitter": "Haotian Zhang", "authors": "Haotian Zhang, Jianyong Sun and Zongben Xu", "title": "Learning to be Global Optimizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancement of artificial intelligence has cast a new light on the\ndevelopment of optimization algorithm. This paper proposes to learn a two-phase\n(including a minimization phase and an escaping phase) global optimization\nalgorithm for smooth non-convex functions. For the minimization phase, a\nmodel-driven deep learning method is developed to learn the update rule of\ndescent direction, which is formalized as a nonlinear combination of historical\ninformation, for convex functions. We prove that the resultant algorithm with\nthe proposed adaptive direction guarantees convergence for convex functions.\nEmpirical study shows that the learned algorithm significantly outperforms some\nwell-known classical optimization algorithms, such as gradient descent,\nconjugate descent and BFGS, and performs well on ill-posed functions. The\nescaping phase from local optimum is modeled as a Markov decision process with\na fixed escaping policy. We further propose to learn an optimal escaping policy\nby reinforcement learning. The effectiveness of the escaping policies is\nverified by optimizing synthesized functions and training a deep neural network\nfor CIFAR image classification. The learned two-phase global optimization\nalgorithm demonstrates a promising global search capability on some benchmark\nfunctions and machine learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 03:46:25 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Zhang", "Haotian", ""], ["Sun", "Jianyong", ""], ["Xu", "Zongben", ""]]}, {"id": "2003.04567", "submitter": "Ronen Tamari", "authors": "Ronen Tamari, Gabriel Stanovsky, Dafna Shahaf and Reut Tsarfaty", "title": "Ecological Semantics: Programming Environments for Situated Language\n  Understanding", "comments": "Camera ready for Bridging AI and Cognitive Science (BAICS) workshop\n  at ICLR2020. For interactive demos, see https://eco-sem.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale natural language understanding (NLU) systems have made impressive\nprogress: they can be applied flexibly across a variety of tasks, and employ\nminimal structural assumptions. However, extensive empirical research has shown\nthis to be a double-edged sword, coming at the cost of shallow understanding:\ninferior generalization, grounding and explainability. Grounded language\nlearning approaches offer the promise of deeper understanding by situating\nlearning in richer, more structured training environments, but are limited in\nscale to relatively narrow, predefined domains. How might we enjoy the best of\nboth worlds: grounded, general NLU? Following extensive contemporary cognitive\nscience, we propose treating environments as \"first-class citizens\" in semantic\nrepresentations, worthy of research and development in their own right.\nImportantly, models should also be partners in the creation and configuration\nof environments, rather than just actors within them, as in existing\napproaches. To do so, we argue that models must begin to understand and program\nin the language of affordances (which define possible actions in a given\nsituation) both for online, situated discourse comprehension, as well as\nlarge-scale, offline common-sense knowledge mining. To this end we propose an\nenvironment-oriented ecological semantics, outlining theoretical and practical\napproaches towards implementation. We further provide actual demonstrations\nbuilding upon interactive fiction programming languages.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 08:24:41 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 07:48:05 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Tamari", "Ronen", ""], ["Stanovsky", "Gabriel", ""], ["Shahaf", "Dafna", ""], ["Tsarfaty", "Reut", ""]]}, {"id": "2003.04641", "submitter": "Yuhong Deng", "authors": "Yuhong Deng, Di Guo, Xiaofeng Guo, Naifu Zhang, Huaping Liu, Fuchun\n  Sun", "title": "MQA: Answering the Question via Robotic Manipulation", "comments": "have be accepted by Robotics: Science and Systems 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel task, Manipulation Question Answering\n(MQA), where the robot performs manipulation actions to change the environment\nin order to answer a given question. To solve this problem, a framework\nconsisting of a QA module and a manipulation module is proposed. For the QA\nmodule, we adopt the method for the Visual Question Answering (VQA) task. For\nthe manipulation module, a Deep Q Network (DQN) model is designed to generate\nmanipulation actions for the robot to interact with the environment. We\nconsider the situation where the robot continuously manipulating objects inside\na bin until the answer to the question is found. Besides, a novel dataset that\ncontains a variety of object models, scenarios and corresponding\nquestion-answer pairs is established in a simulation environment. Extensive\nexperiments have been conducted to validate the effectiveness of the proposed\nframework.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 11:30:09 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 08:46:48 GMT"}, {"version": "v3", "created": "Sun, 27 Jun 2021 13:44:50 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Deng", "Yuhong", ""], ["Guo", "Di", ""], ["Guo", "Xiaofeng", ""], ["Zhang", "Naifu", ""], ["Liu", "Huaping", ""], ["Sun", "Fuchun", ""]]}, {"id": "2003.04663", "submitter": "Rituraj Kaushik", "authors": "Rituraj Kaushik, Timoth\\'ee Anne and Jean-Baptiste Mouret", "title": "Fast Online Adaptation in Robotics through Meta-Learning Embeddings of\n  Simulated Priors", "comments": "2020 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS) | Video: http://tiny.cc/famle_video", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning algorithms can accelerate the model-based reinforcement\nlearning (MBRL) algorithms by finding an initial set of parameters for the\ndynamical model such that the model can be trained to match the actual dynamics\nof the system with only a few data-points. However, in the real world, a robot\nmight encounter any situation starting from motor failures to finding itself in\na rocky terrain where the dynamics of the robot can be significantly different\nfrom one another. In this paper, first, we show that when meta-training\nsituations (the prior situations) have such diverse dynamics, using a single\nset of meta-trained parameters as a starting point still requires a large\nnumber of observations from the real system to learn a useful model of the\ndynamics. Second, we propose an algorithm called FAMLE that mitigates this\nlimitation by meta-training several initial starting points (i.e., initial\nparameters) for training the model and allows the robot to select the most\nsuitable starting point to adapt the model to the current situation with only a\nfew gradient steps. We compare FAMLE to MBRL, MBRL with a meta-trained model\nwith MAML, and model-free policy search algorithm PPO for various simulated and\nreal robotic tasks, and show that FAMLE allows the robots to adapt to novel\ndamages in significantly fewer time-steps than the baselines.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 12:37:52 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 19:59:40 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Kaushik", "Rituraj", ""], ["Anne", "Timoth\u00e9e", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "2003.04664", "submitter": "R\\'emy Portelas", "authors": "R\\'emy Portelas, C\\'edric Colas, Lilian Weng, Katja Hofmann and\n  Pierre-Yves Oudeyer", "title": "Automatic Curriculum Learning For Deep RL: A Short Survey", "comments": "Accepted at IJCAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic Curriculum Learning (ACL) has become a cornerstone of recent\nsuccesses in Deep Reinforcement Learning (DRL).These methods shape the learning\ntrajectories of agents by challenging them with tasks adapted to their\ncapacities. In recent years, they have been used to improve sample efficiency\nand asymptotic performance, to organize exploration, to encourage\ngeneralization or to solve sparse reward problems, among others. The ambition\nof this work is dual: 1) to present a compact and accessible introduction to\nthe Automatic Curriculum Learning literature and 2) to draw a bigger picture of\nthe current state of the art in ACL to encourage the cross-breeding of existing\nconcepts and the emergence of new ideas.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 12:38:31 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 20:51:40 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Portelas", "R\u00e9my", ""], ["Colas", "C\u00e9dric", ""], ["Weng", "Lilian", ""], ["Hofmann", "Katja", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2003.04685", "submitter": "Zhenguo Nie", "authors": "Zhenguo Nie, Tong Lin, Haoliang Jiang, Levent Burak Kara", "title": "TopologyGAN: Topology Optimization Using Generative Adversarial Networks\n  Based on Physical Fields Over the Initial Domain", "comments": "18 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In topology optimization using deep learning, load and boundary conditions\nrepresented as vectors or sparse matrices often miss the opportunity to encode\na rich view of the design problem, leading to less than ideal generalization\nresults. We propose a new data-driven topology optimization model called\nTopologyGAN that takes advantage of various physical fields computed on the\noriginal, unoptimized material domain, as inputs to the generator of a\nconditional generative adversarial network (cGAN). Compared to a baseline cGAN,\nTopologyGAN achieves a nearly $3\\times$ reduction in the mean squared error and\na $2.5\\times$ reduction in the mean absolute error on test problems involving\npreviously unseen boundary conditions. Built on several existing network\nmodels, we also introduce a hybrid network called\nU-SE(Squeeze-and-Excitation)-ResNet for the generator that further increases\nthe overall accuracy. We publicly share our full implementation and trained\nnetwork.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 14:40:11 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 05:59:28 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Nie", "Zhenguo", ""], ["Lin", "Tong", ""], ["Jiang", "Haoliang", ""], ["Kara", "Levent Burak", ""]]}, {"id": "2003.04690", "submitter": "Timotheus Kampik", "authors": "Timotheus Kampik and Juan Carlos Nieves", "title": "JS-son -- A Lean, Extensible JavaScript Agent Programming Library", "comments": "Accepted for the post-proceedings of EMAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multitude of agent-oriented software engineering frameworks exist, most of\nwhich are developed by the academic multi-agent systems community. However,\nthese frameworks often impose programming paradigms on their users that are\nchallenging to learn for engineers who are used to modern high-level\nprogramming languages such as JavaScript and Python. To show how the adoption\nof agent-oriented programming by the software engineering mainstream can be\nfacilitated, we provide a lean JavaScript library prototype for implementing\nreasoning-loop agents. The library focuses on core agent programming concepts\nand refrains from imposing further restrictions on the programming approach. To\nillustrate its usefulness, we show how the library can be applied to\nmulti-agent systems simulations on the web, deployed to cloud-hosted\nfunction-as-a-service environments, and embedded in Python-based data science\ntools.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 13:27:59 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Kampik", "Timotheus", ""], ["Nieves", "Juan Carlos", ""]]}, {"id": "2003.04696", "submitter": "Fernando P\\'erez-Garc\\'ia", "authors": "Fernando P\\'erez-Garc\\'ia, Rachel Sparks and S\\'ebastien Ourselin", "title": "TorchIO: a Python library for efficient loading, preprocessing,\n  augmentation and patch-based sampling of medical images in deep learning", "comments": "Submitted to Computer Methods and Programs in Biomedicine. 27 pages,\n  7 figures. Documentation for TorchIO can be found at http://torchio.rtfd.io/", "journal-ref": "Computer Methods and Programs in Biomedicine (June 2021), p.\n  106236. ISSN: 0169-2607", "doi": "10.1016/j.cmpb.2021.106236", "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Processing of medical images such as MRI or CT presents unique challenges\ncompared to RGB images typically used in computer vision. These include a lack\nof labels for large datasets, high computational costs, and metadata to\ndescribe the physical properties of voxels. Data augmentation is used to\nartificially increase the size of the training datasets. Training with image\npatches decreases the need for computational power. Spatial metadata needs to\nbe carefully taken into account in order to ensure a correct alignment of\nvolumes.\n  We present TorchIO, an open-source Python library to enable efficient\nloading, preprocessing, augmentation and patch-based sampling of medical images\nfor deep learning. TorchIO follows the style of PyTorch and integrates standard\nmedical image processing libraries to efficiently process images during\ntraining of neural networks. TorchIO transforms can be composed, reproduced,\ntraced and extended. We provide multiple generic preprocessing and augmentation\noperations as well as simulation of MRI-specific artifacts.\n  Source code, comprehensive tutorials and extensive documentation for TorchIO\ncan be found at https://github.com/fepegar/torchio. The package can be\ninstalled from the Python Package Index running 'pip install torchio'. It\nincludes a command-line interface which allows users to apply transforms to\nimage files without using Python. Additionally, we provide a graphical\ninterface within a TorchIO extension in 3D Slicer to visualize the effects of\ntransforms.\n  TorchIO was developed to help researchers standardize medical image\nprocessing pipelines and allow them to focus on the deep learning experiments.\nIt encourages open science, as it supports reproducibility and is version\ncontrolled so that the software can be cited precisely. Due to its modularity,\nthe library is compatible with other frameworks for deep learning with medical\nimages.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 13:36:16 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 20:43:32 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 09:09:03 GMT"}, {"version": "v4", "created": "Thu, 3 Jun 2021 10:05:29 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["P\u00e9rez-Garc\u00eda", "Fernando", ""], ["Sparks", "Rachel", ""], ["Ourselin", "S\u00e9bastien", ""]]}, {"id": "2003.04707", "submitter": "Jonathan Francis", "authors": "Alessandro Oltramari, Jonathan Francis, Cory Henson, Kaixin Ma, and\n  Ruwan Wickramarachchi", "title": "Neuro-symbolic Architectures for Context Understanding", "comments": "In: Ilaria Tiddi, Freddy Lecue, Pascal Hitzler (eds.), Knowledge\n  Graphs for eXplainable AI -- Foundations, Applications and Challenges.\n  Studies on the Semantic Web, IOS Press, Amsterdam, 2020. arXiv admin note:\n  text overlap with arXiv:1910.14087", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational context understanding refers to an agent's ability to fuse\ndisparate sources of information for decision-making and is, therefore,\ngenerally regarded as a prerequisite for sophisticated machine reasoning\ncapabilities, such as in artificial intelligence (AI). Data-driven and\nknowledge-driven methods are two classical techniques in the pursuit of such\nmachine sense-making capability. However, while data-driven methods seek to\nmodel the statistical regularities of events by making observations in the\nreal-world, they remain difficult to interpret and they lack mechanisms for\nnaturally incorporating external knowledge. Conversely, knowledge-driven\nmethods, combine structured knowledge bases, perform symbolic reasoning based\non axiomatic principles, and are more interpretable in their inferential\nprocessing; however, they often lack the ability to estimate the statistical\nsalience of an inference. To combat these issues, we propose the use of hybrid\nAI methodology as a general framework for combining the strengths of both\napproaches. Specifically, we inherit the concept of neuro-symbolism as a way of\nusing knowledge-bases to guide the learning progress of deep neural networks.\nWe further ground our discussion in two applications of neuro-symbolism and, in\nboth cases, show that our systems maintain interpretability while achieving\ncomparable performance, relative to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 15:04:07 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Oltramari", "Alessandro", ""], ["Francis", "Jonathan", ""], ["Henson", "Cory", ""], ["Ma", "Kaixin", ""], ["Wickramarachchi", "Ruwan", ""]]}, {"id": "2003.04713", "submitter": "Xin-She Yang", "authors": "Qian Li, San-Yang Liu, Xin-She Yang", "title": "Neighborhood Information-based Probabilistic Algorithm for Network\n  Disintegration", "comments": "25 pages, 13 figures, 2 tables", "journal-ref": "Expert Systems with Applications, Volume 139, (2020), Article\n  112853", "doi": "10.1016/j.eswa.2019.112853", "report-no": null, "categories": "cs.SI cs.AI cs.NE math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many real-world applications can be modelled as complex networks, and such\nnetworks include the Internet, epidemic disease networks, transport networks,\npower grids, protein-folding structures and others. Network integrity and\nrobustness are important to ensure that crucial networks are protected and\nundesired harmful networks can be dismantled. Network structure and integrity\ncan be controlled by a set of key nodes, and to find the optimal combination of\nnodes in a network to ensure network structure and integrity can be an\nNP-complete problem. Despite extensive studies, existing methods have many\nlimitations and there are still many unresolved problems. This paper presents a\nprobabilistic approach based on neighborhood information and node importance,\nnamely, neighborhood information-based probabilistic algorithm (NIPA). We also\ndefine a new centrality-based importance measure (IM), which combines the\ncontribution ratios of the neighbor nodes of each target node and two-hop node\ninformation. Our proposed NIPA has been tested for different network benchmarks\nand compared with three other methods: optimal attack strategy (OAS), high\nbetweenness first (HBF) and high degree first (HDF). Experiments suggest that\nthe proposed NIPA is most effective among all four methods. In general, NIPA\ncan identify the most crucial node combination with higher effectiveness, and\nthe set of optimal key nodes found by our proposed NIPA is much smaller than\nthat by heuristic centrality prediction. In addition, many previously neglected\nweakly connected nodes are identified, which become a crucial part of the newly\nidentified optimal nodes. Thus, revised strategies for protection are\nrecommended to ensure the safeguard of network integrity. Further key issues\nand future research topics are also discussed.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 15:09:25 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Li", "Qian", ""], ["Liu", "San-Yang", ""], ["Yang", "Xin-She", ""]]}, {"id": "2003.04732", "submitter": "Balaji Ganesan", "authors": "Balaji Ganesan, Srinivas Parkala, Neeraj R Singh, Sumit Bhatia,\n  Gayatri Mishra, Matheen Ahmed Pasha, Hima Patel, Somashekar Naganna", "title": "Link Prediction using Graph Neural Networks for Master Data Management", "comments": "10 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning graph representations of n-ary relational data has a number of real\nworld applications like anti-money laundering, fraud detection, and customer\ndue diligence. Contact tracing of COVID19 positive persons could also be posed\nas a Link Prediction problem. Predicting links between people using Graph\nNeural Networks requires careful ethical and privacy considerations than in\ndomains where GNNs have typically been applied so far. We introduce novel\nmethods for anonymizing data, model training, explainability and verification\nfor Link Prediction in Master Data Management, and discuss our results.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 05:54:16 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 19:01:32 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Ganesan", "Balaji", ""], ["Parkala", "Srinivas", ""], ["Singh", "Neeraj R", ""], ["Bhatia", "Sumit", ""], ["Mishra", "Gayatri", ""], ["Pasha", "Matheen Ahmed", ""], ["Patel", "Hima", ""], ["Naganna", "Somashekar", ""]]}, {"id": "2003.04736", "submitter": "Theja Tulabandhula", "authors": "Theja Tulabandhula and Deeksha Sinha and Saketh Karra", "title": "Optimizing Revenue while showing Relevant Assortments at Scale", "comments": "53 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalable real-time assortment optimization has become essential in e-commerce\noperations due to the need for personalization and the availability of a large\nvariety of items. While this can be done when there are simplistic assortment\nchoices to be made, the optimization process becomes difficult when imposing\nconstraints on the collection of relevant assortments based on insights by\nstore-managers and historically well-performing assortments. We design fast and\nflexible algorithms based on variations of binary search that find the\n(approximately) optimal assortment in this difficult regime. In particular, we\nrevisit the problem of large-scale assortment optimization under the\nmultinomial logit choice model without any assumptions on the structure of the\nfeasible assortments. We speed up the comparison steps using advances in\nsimilarity search in the field of information retrieval/machine learning. For\nan arbitrary collection of assortments, our algorithms can find a solution in\ntime that is sub-linear in the number of assortments, and for the simpler case\nof cardinality constraints - linear in the number of items (existing methods\nare quadratic or worse). Empirical validations using a real world dataset (in\naddition to experiments using semi-synthetic data based on the Billion Prices\ndataset and several retail transaction datasets) show that our algorithms are\ncompetitive even when the number of items is $\\sim 10^5$ ($10\\times$ larger\ninstances than previously studied).\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 20:16:49 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 01:06:15 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Tulabandhula", "Theja", ""], ["Sinha", "Deeksha", ""], ["Karra", "Saketh", ""]]}, {"id": "2003.04770", "submitter": "Najla AL-Saati", "authors": "Najla Akram AL-Saati, Marrwa Abd-AlKareem Alabajee", "title": "A Comparative Study on Parameter Estimation in Software Reliability\n  Modeling using Swarm Intelligence", "comments": "7 pages", "journal-ref": "International Journal of Recent Research and Review, Vol. IX,\n  Issue 4, December 2016", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on a comparison between the performances of two well-known\nSwarm algorithms: Cuckoo Search (CS) and Firefly Algorithm (FA), in estimating\nthe parameters of Software Reliability Growth Models. This study is further\nreinforced using Particle Swarm Optimization (PSO) and Ant Colony Optimization\n(ACO). All algorithms are evaluated according to real software failure data,\nthe tests are performed and the obtained results are compared to show the\nperformance of each of the used algorithms. Furthermore, CS and FA are also\ncompared with each other on bases of execution time and iteration number.\nExperimental results show that CS is more efficient in estimating the\nparameters of SRGMs, and it has outperformed FA in addition to PSO and ACO for\nthe selected Data sets and employed models.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 16:35:42 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["AL-Saati", "Najla Akram", ""], ["Alabajee", "Marrwa Abd-AlKareem", ""]]}, {"id": "2003.04774", "submitter": "Alexander Thebelt", "authors": "Alexander Thebelt, Jan Kronqvist, Miten Mistry, Robert M. Lee, Nathan\n  Sudermann-Merx, Ruth Misener", "title": "ENTMOOT: A Framework for Optimization over Ensemble Tree Models", "comments": "33 pages, 10 figures, 2 tables", "journal-ref": null, "doi": "10.1016/j.compchemeng.2021.107343", "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient boosted trees and other regression tree models perform well in a\nwide range of real-world, industrial applications. These tree models (i) offer\ninsight into important prediction features, (ii) effectively manage sparse\ndata, and (iii) have excellent prediction capabilities. Despite their\nadvantages, they are generally unpopular for decision-making tasks and\nblack-box optimization, which is due to their difficult-to optimize structure\nand the lack of a reliable uncertainty measure. ENTMOOT is our new framework\nfor integrating (already trained) tree models into larger optimization\nproblems. The contributions of ENTMOOT include: (i) explicitly introducing a\nreliable uncertainty measure that is compatible with tree models, (ii) solving\nthe larger optimization problems that incorporate these uncertainty aware tree\nmodels, (iii) proving that the solutions are globally optimal, i.e. no better\nsolution exists. In particular, we show how the ENTMOOT approach allows a\nsimple integration of tree models into decision-making and black-box\noptimization, where it proves as a strong competitor to commonly-used\nframeworks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 14:34:07 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 00:16:58 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 15:10:36 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Thebelt", "Alexander", ""], ["Kronqvist", "Jan", ""], ["Mistry", "Miten", ""], ["Lee", "Robert M.", ""], ["Sudermann-Merx", "Nathan", ""], ["Misener", "Ruth", ""]]}, {"id": "2003.04792", "submitter": "Yanou Ramon", "authors": "Yanou Ramon, David Martens, Theodoros Evgeniou, Stiene Praet", "title": "Metafeatures-based Rule-Extraction for Classifiers on Behavioral and\n  Textual Data", "comments": "31 pages, 13 figures", "journal-ref": null, "doi": "10.1007/s10994-021-05981-0", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models on behavioral and textual data can result in highly\naccurate prediction models, but are often very difficult to interpret.\nRule-extraction techniques have been proposed to combine the desired predictive\naccuracy of complex \"black-box\" models with global explainability. However,\nrule-extraction in the context of high-dimensional, sparse data, where many\nfeatures are relevant to the predictions, can be challenging, as replacing the\nblack-box model by many rules leaves the user again with an incomprehensible\nexplanation. To address this problem, we develop and test a rule-extraction\nmethodology based on higher-level, less-sparse metafeatures. A key finding of\nour analysis is that metafeatures-based explanations are better at mimicking\nthe behavior of the black-box prediction model, as measured by the fidelity of\nexplanations.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 15:08:41 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 12:43:32 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 12:15:48 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ramon", "Yanou", ""], ["Martens", "David", ""], ["Evgeniou", "Theodoros", ""], ["Praet", "Stiene", ""]]}, {"id": "2003.04960", "submitter": "Sanmit Narvekar", "authors": "Sanmit Narvekar and Bei Peng and Matteo Leonetti and Jivko Sinapov and\n  Matthew E. Taylor and Peter Stone", "title": "Curriculum Learning for Reinforcement Learning Domains: A Framework and\n  Survey", "comments": null, "journal-ref": "Journal of Machine Learning Research 21(181):1-50, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning (RL) is a popular paradigm for addressing sequential\ndecision tasks in which the agent has only limited environmental feedback.\nDespite many advances over the past three decades, learning in many domains\nstill requires a large amount of interaction with the environment, which can be\nprohibitively expensive in realistic scenarios. To address this problem,\ntransfer learning has been applied to reinforcement learning such that\nexperience gained in one task can be leveraged when starting to learn the next,\nharder task. More recently, several lines of research have explored how tasks,\nor data samples themselves, can be sequenced into a curriculum for the purpose\nof learning a problem that may otherwise be too difficult to learn from\nscratch. In this article, we present a framework for curriculum learning (CL)\nin reinforcement learning, and use it to survey and classify existing CL\nmethods in terms of their assumptions, capabilities, and goals. Finally, we use\nour framework to find open problems and suggest directions for future RL\ncurriculum learning research.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 20:41:24 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 22:31:51 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Narvekar", "Sanmit", ""], ["Peng", "Bei", ""], ["Leonetti", "Matteo", ""], ["Sinapov", "Jivko", ""], ["Taylor", "Matthew E.", ""], ["Stone", "Peter", ""]]}, {"id": "2003.04970", "submitter": "Oana Cocarascu", "authors": "Oana Cocarascu, Elena Cabrio, Serena Villata, Francesca Toni", "title": "A Dataset Independent Set of Baselines for Relation Prediction in\n  Argument Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Argument Mining is the research area which aims at extracting argument\ncomponents and predicting argumentative relations (i.e.,support and attack)\nfrom text. In particular, numerous approaches have been proposed in the\nliterature to predict the relations holding between the arguments, and\napplication-specific annotated resources were built for this purpose. Despite\nthe fact that these resources have been created to experiment on the same task,\nthe definition of a single relation prediction method to be successfully\napplied to a significant portion of these datasets is an open research problem\nin Argument Mining. This means that none of the methods proposed in the\nliterature can be easily ported from one resource to another. In this paper, we\naddress this problem by proposing a set of dataset independent strong neural\nbaselines which obtain homogeneous results on all the datasets proposed in the\nliterature for the argumentative relation prediction task. Thus, our baselines\ncan be employed by the Argument Mining community to compare more effectively\nhow well a method performs on the argumentative relation prediction task.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 12:38:18 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Cocarascu", "Oana", ""], ["Cabrio", "Elena", ""], ["Villata", "Serena", ""], ["Toni", "Francesca", ""]]}, {"id": "2003.04976", "submitter": "Gaurav Pandey", "authors": "Gaurav Pandey, Dinesh Raghu and Sachindra Joshi", "title": "Mask & Focus: Conversation Modelling by Learning Concepts", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence to sequence models attempt to capture the correlation between all\nthe words in the input and output sequences. While this is quite useful for\nmachine translation where the correlation among the words is indeed quite\nstrong, it becomes problematic for conversation modelling where the correlation\nis often at a much abstract level. In contrast, humans tend to focus on the\nessential concepts discussed in the conversation context and generate responses\naccordingly. In this paper, we attempt to mimic this response generating\nmechanism by learning the essential concepts in the context and response in an\nunsupervised manner. The proposed model, referred to as Mask \\& Focus maps the\ninput context to a sequence of concepts which are then used to generate the\nresponse concepts. Together, the context and the response concepts generate the\nfinal response. In order to learn context concepts from the training data\nautomatically, we \\emph{mask} words in the input and observe the effect of\nmasking on response generation. We train our model to learn those response\nconcepts that have high mutual information with respect to the context\nconcepts, thereby guiding the model to \\emph{focus} on the context concepts.\nMask \\& Focus achieves significant improvement over the existing baselines in\nseveral established metrics for dialogues.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 15:11:55 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Pandey", "Gaurav", ""], ["Raghu", "Dinesh", ""], ["Joshi", "Sachindra", ""]]}, {"id": "2003.04980", "submitter": "Jonas Rieger", "authors": "Jonas Rieger, Lars Koppers, Carsten Jentsch, and J\\\"org Rahnenf\\\"uhrer", "title": "Improving Reliability of Latent Dirichlet Allocation by Assessing Its\n  Stability Using Clustering Techniques on Replicated Runs", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For organizing large text corpora topic modeling provides useful tools. A\nwidely used method is Latent Dirichlet Allocation (LDA), a generative\nprobabilistic model which models single texts in a collection of texts as\nmixtures of latent topics. The assignments of words to topics rely on initial\nvalues such that generally the outcome of LDA is not fully reproducible. In\naddition, the reassignment via Gibbs Sampling is based on conditional\ndistributions, leading to different results in replicated runs on the same text\ndata. This fact is often neglected in everyday practice. We aim to improve the\nreliability of LDA results. Therefore, we study the stability of LDA by\ncomparing assignments from replicated runs. We propose to quantify the\nsimilarity of two generated topics by a modified Jaccard coefficient. Using\nsuch similarities, topics can be clustered. A new pruning algorithm for\nhierarchical clustering results based on the idea that two LDA runs create\npairs of similar topics is proposed. This approach leads to the new measure\nS-CLOP ({\\bf S}imilarity of multiple sets by {\\bf C}lustering with {\\bf LO}cal\n{\\bf P}runing) for quantifying the stability of LDA models. We discuss some\ncharacteristics of this measure and illustrate it with an application to real\ndata consisting of newspaper articles from \\textit{USA Today}. Our results show\nthat the measure S-CLOP is useful for assessing the stability of LDA models or\nany other topic modeling procedure that characterize its topics by word\ndistributions. Based on the newly proposed measure for LDA stability, we\npropose a method to increase the reliability and hence to improve the\nreproducibility of empirical findings based on topic modeling. This increase in\nreliability is obtained by running the LDA several times and taking as\nprototype the most representative run, that is the LDA run with highest average\nsimilarity to all other runs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 07:10:18 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Rieger", "Jonas", ""], ["Koppers", "Lars", ""], ["Jentsch", "Carsten", ""], ["Rahnenf\u00fchrer", "J\u00f6rg", ""]]}, {"id": "2003.04984", "submitter": "Reza Fotohi", "authors": "Reza Fotohi", "title": "Securing of Unmanned Aerial Systems (UAS) against security threats using\n  human immune system", "comments": "29 pages, 12 figures, 10 tables, 8 equations, Journal", "journal-ref": "Reliability Engineering & System Safety, 193, 106675 (2020)", "doi": "10.1016/j.ress.2019.106675", "report-no": null, "categories": "cs.CR cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  UASs form a large part of the fighting ability of the advanced military\nforces. In particular, these systems that carry confidential information are\nsubject to security attacks. Accordingly, an Intrusion Detection System (IDS)\nhas been proposed in the proposed design to protect against the security\nproblems using the human immune system (HIS). The IDSs are used to detect and\nrespond to attempts to compromise the target system. Since the UASs operate in\nthe real world, the testing and validation of these systems with a variety of\nsensors is confronted with problems. This design is inspired by HIS. In the\nmapping, insecure signals are equivalent to an antigen that are detected by\nantibody-based training patterns and removed from the operation cycle. Among\nthe main uses of the proposed design are the quick detection of intrusive\nsignals and quarantining their activity. Moreover, SUAS-HIS method is evaluated\nhere via extensive simulations carried out in NS-3 environment. The simulation\nresults indicate that the UAS network performance metrics are improved in terms\nof false positive rate, false negative rate, detection rate, and packet\ndelivery rate.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 19:05:16 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Fotohi", "Reza", ""]]}, {"id": "2003.05012", "submitter": "Stephanie Milani", "authors": "Stephanie Milani, Nicholay Topin, Brandon Houghton, William H. Guss,\n  Sharada P. Mohanty, Keisuke Nakata, Oriol Vinyals, Noboru Sean Kuno", "title": "Retrospective Analysis of the 2019 MineRL Competition on Sample\n  Efficient Reinforcement Learning", "comments": "To appear in Proceedings of Machine Learning Research: NeurIPS 2019\n  Competition & Demonstration Track Postproceedings. 12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To facilitate research in the direction of sample efficient reinforcement\nlearning, we held the MineRL Competition on Sample Efficient Reinforcement\nLearning Using Human Priors at the Thirty-third Conference on Neural\nInformation Processing Systems (NeurIPS 2019). The primary goal of this\ncompetition was to promote the development of algorithms that use human\ndemonstrations alongside reinforcement learning to reduce the number of samples\nneeded to solve complex, hierarchical, and sparse environments. We describe the\ncompetition, outlining the primary challenge, the competition design, and the\nresources that we provided to the participants. We provide an overview of the\ntop solutions, each of which use deep reinforcement learning and/or imitation\nlearning. We also discuss the impact of our organizational decisions on the\ncompetition and future directions for improvement.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 21:39:52 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 03:03:17 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2020 17:06:17 GMT"}, {"version": "v4", "created": "Thu, 18 Jun 2020 16:54:23 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Milani", "Stephanie", ""], ["Topin", "Nicholay", ""], ["Houghton", "Brandon", ""], ["Guss", "William H.", ""], ["Mohanty", "Sharada P.", ""], ["Nakata", "Keisuke", ""], ["Vinyals", "Oriol", ""], ["Kuno", "Noboru Sean", ""]]}, {"id": "2003.05016", "submitter": "Stewart Jamieson", "authors": "Stewart Jamieson, Jonathan P. How, Yogesh Girdhar", "title": "Active Reward Learning for Co-Robotic Vision Based Exploration in\n  Bandwidth Limited Environments", "comments": "7 pages, 4 figures; accepted for presentation in IEEE Int. Conf. on\n  Robotics and Automation, ICRA '20, Paris, France, June 2020", "journal-ref": "2020 IEEE International Conference on Robotics and Automation\n  (ICRA), Paris, France, 2020, pp. 1806-1812", "doi": "10.1109/ICRA40945.2020.9196922", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel POMDP problem formulation for a robot that must\nautonomously decide where to go to collect new and scientifically relevant\nimages given a limited ability to communicate with its human operator. From\nthis formulation we derive constraints and design principles for the\nobservation model, reward model, and communication strategy of such a robot,\nexploring techniques to deal with the very high-dimensional observation space\nand scarcity of relevant training data. We introduce a novel active reward\nlearning strategy based on making queries to help the robot minimize path\n\"regret\" online, and evaluate it for suitability in autonomous visual\nexploration through simulations. We demonstrate that, in some bandwidth-limited\nenvironments, this novel regret-based criterion enables the robotic explorer to\ncollect up to 17% more reward per mission than the next-best criterion.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 21:57:33 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Jamieson", "Stewart", ""], ["How", "Jonathan P.", ""], ["Girdhar", "Yogesh", ""]]}, {"id": "2003.05055", "submitter": "Tao Gu", "authors": "Tao Gu, Xiao Hang Wang, Hung Keng Pung, Da Qing Zhang", "title": "An Ontology-based Context Model in Intelligent Environments", "comments": "arXiv admin note: text overlap with arXiv:0906.3925 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing becomes increasingly mobile and pervasive today; these changes\nimply that applications and services must be aware of and adapt to their\nchanging contexts in highly dynamic environments. Today, building context-aware\nsystems is a complex task due to lack of an appropriate infrastructure support\nin intelligent environments. A context-aware infrastructure requires an\nappropriate context model to represent, manipulate and access context\ninformation. In this paper, we propose a formal context model based on ontology\nusing OWL to address issues including semantic context representation, context\nreasoning and knowledge sharing, context classification, context dependency and\nquality of context. The main benefit of this model is the ability to reason\nabout various contexts. Based on our context model, we also present a\nService-Oriented Context-Aware Middleware (SOCAM) architecture for building of\ncontext-aware services.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 12:15:20 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Gu", "Tao", ""], ["Wang", "Xiao Hang", ""], ["Pung", "Hung Keng", ""], ["Zhang", "Da Qing", ""]]}, {"id": "2003.05104", "submitter": "Abeer M.Mahmoud", "authors": "Ibrahim M. Ahmed, Abeer M. Mahmoud", "title": "Development of an Expert System for Diabetic Type-2 Diet", "comments": null, "journal-ref": "International Journal of Computer Applications, 2014, 107(1)", "doi": "10.5120/18714-9932", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A successful intelligent control of patient food for treatment purpose must\ncombines patient interesting food list and doctors efficient treatment food\nlist. Actually, many rural communities in Sudan have extremely limited access\nto diabetic diet centers. People travel long distances to clinics or medical\nfacilities, and there is a shortage of medical experts in most of these\nfacilities. This results in slow service, and patients end up waiting long\nhours without receiving any attention. Hence diabetic diet expert systems can\nplay a significant role in such cases where medical experts are not readily\navailable. This paper presents the design and implementation of an intelligent\nmedical expert system for diabetes diet that intended to be used in Sudan. The\ndevelopment of the proposed expert system went through a number of stages such\nproblem and need identification, requirements analysis, knowledge acquisition,\nformalization, design and implementation. Visual prolog was used for designing\nthe graphical user interface and the implementation of the system. The proposed\nexpert system is a promising helpful tool that reduces the workload for\nphysicians and provides diabetics with simple and valuable assistance.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 09:34:44 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Ahmed", "Ibrahim M.", ""], ["Mahmoud", "Abeer M.", ""]]}, {"id": "2003.05117", "submitter": "Krishan Rana Mr", "authors": "Krishan Rana, Vibhavari Dasagi, Ben Talbot, Michael Milford and Niko\n  S\\\"underhauf", "title": "Multiplicative Controller Fusion: Leveraging Algorithmic Priors for\n  Sample-efficient Reinforcement Learning and Safe Sim-To-Real Transfer", "comments": "Accepted for presentation at IROS2020. Project site available at\n  https://sites.google.com/view/mcf-nav/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based approaches often outperform hand-coded algorithmic solutions\nfor many problems in robotics. However, learning long-horizon tasks on real\nrobot hardware can be intractable, and transferring a learned policy from\nsimulation to reality is still extremely challenging. We present a novel\napproach to model-free reinforcement learning that can leverage existing\nsub-optimal solutions as an algorithmic prior during training and deployment.\nDuring training, our gated fusion approach enables the prior to guide the\ninitial stages of exploration, increasing sample-efficiency and enabling\nlearning from sparse long-horizon reward signals. Importantly, the policy can\nlearn to improve beyond the performance of the sub-optimal prior since the\nprior's influence is annealed gradually. During deployment, the policy's\nuncertainty provides a reliable strategy for transferring a simulation-trained\npolicy to the real world by falling back to the prior controller in uncertain\nstates. We show the efficacy of our Multiplicative Controller Fusion approach\non the task of robot navigation and demonstrate safe transfer from simulation\nto the real world without any fine-tuning. The code for this project is made\npublicly available at https://sites.google.com/view/mcf-nav/home\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 05:12:26 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 04:30:15 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 07:02:39 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Rana", "Krishan", ""], ["Dasagi", "Vibhavari", ""], ["Talbot", "Ben", ""], ["Milford", "Michael", ""], ["S\u00fcnderhauf", "Niko", ""]]}, {"id": "2003.05119", "submitter": "Stella Biderman", "authors": "Stella Biderman", "title": "Magic: the Gathering is as Hard as Arithmetic", "comments": "pre-print, currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magic: the Gathering is a popular and famously complicated card game about\nmagical combat. Recently, several authors including Chatterjee and Ibsen-Jensen\n(2016) and Churchill, Biderman, and Herrick (2019) have investigated the\ncomputational complexity of playing Magic optimally. In this paper we show that\nthe ``mate-in-$n$'' problem for Magic is $\\Delta^0_n$-hard and that optimal\nplay in two-player Magic is non-arithmetic in general. These results apply to\nhow real Magic is played, can be achieved using standard-size tournament legal\ndecks, and do not rely on stochasticity or hidden information. Our paper builds\nupon the construction that Churchill, Biderman, and Herrick (2019) used to show\nthat this problem was at least as hard as the halting problem.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 05:42:28 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Biderman", "Stella", ""]]}, {"id": "2003.05161", "submitter": "Laura Ruis", "authors": "Laura Ruis, Jacob Andreas, Marco Baroni, Diane Bouchacourt, Brenden M.\n  Lake", "title": "A Benchmark for Systematic Generalization in Grounded Language\n  Understanding", "comments": "accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans easily interpret expressions that describe unfamiliar situations\ncomposed from familiar parts (\"greet the pink brontosaurus by the ferris\nwheel\"). Modern neural networks, by contrast, struggle to interpret novel\ncompositions. In this paper, we introduce a new benchmark, gSCAN, for\nevaluating compositional generalization in situated language understanding.\nGoing beyond a related benchmark that focused on syntactic aspects of\ngeneralization, gSCAN defines a language grounded in the states of a grid\nworld, facilitating novel evaluations of acquiring linguistically motivated\nrules. For example, agents must understand how adjectives such as 'small' are\ninterpreted relative to the current world state or how adverbs such as\n'cautiously' combine with new verbs. We test a strong multi-modal baseline\nmodel and a state-of-the-art compositional method finding that, in most cases,\nthey fail dramatically when generalization requires systematic compositional\nrules.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 08:40:15 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 17:02:02 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ruis", "Laura", ""], ["Andreas", "Jacob", ""], ["Baroni", "Marco", ""], ["Bouchacourt", "Diane", ""], ["Lake", "Brenden M.", ""]]}, {"id": "2003.05182", "submitter": "Dominique Beaini", "authors": "Dominique Beaini, Sofiane Achiche, Maxime Raison", "title": "Improving Convolutional Neural Networks Via Conservative Field\n  Regularisation and Integration", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Current research in convolutional neural networks (CNN) focuses mainly on\nchanging the architecture of the networks, optimizing the hyper-parameters and\nimproving the gradient descent. However, most work use only 3 standard families\nof operations inside the CNN, the convolution, the activation function, and the\npooling. In this work, we propose a new family of operations based on the\nGreen's function of the Laplacian, which allows the network to solve the\nLaplacian, to integrate any vector field and to regularize the field by forcing\nit to be conservative. Hence, the Green's function (GF) is the first operation\nthat regularizes the 2D or 3D feature space by forcing it to be conservative\nand physically interpretable, instead of regularizing the norm of the weights.\nOur results show that such regularization allows the network to learn faster,\nto have smoother training curves and to better generalize, without any\nadditional parameter. The current manuscript presents early results, more work\nis required to benchmark the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 09:29:48 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Beaini", "Dominique", ""], ["Achiche", "Sofiane", ""], ["Raison", "Maxime", ""]]}, {"id": "2003.05196", "submitter": "Nicolas Riesterer", "authors": "Nicolas Riesterer, Daniel Brand, Marco Ragni", "title": "Uncovering the Data-Related Limits of Human Reasoning Research: An\n  Analysis based on Recommender Systems", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding the fundamentals of human reasoning is central to the\ndevelopment of any system built to closely interact with humans. Cognitive\nscience pursues the goal of modeling human-like intelligence from a\ntheory-driven perspective with a strong focus on explainability. Syllogistic\nreasoning as one of the core domains of human reasoning research has seen a\nsurge of computational models being developed over the last years. However,\nrecent analyses of models' predictive performances revealed a stagnation in\nimprovement. We believe that most of the problems encountered in cognitive\nscience are not due to the specific models that have been developed but can be\ntraced back to the peculiarities of behavioral data instead.\n  Therefore, we investigate potential data-related reasons for the problems in\nhuman reasoning research by comparing model performances on human and\nartificially generated datasets. In particular, we apply collaborative\nfiltering recommenders to investigate the adversarial effects of\ninconsistencies and noise in data and illustrate the potential for data-driven\nmethods in a field of research predominantly concerned with gaining high-level\ntheoretical insight into a domain.\n  Our work (i) provides insight into the levels of noise to be expected from\nhuman responses in reasoning data, (ii) uncovers evidence for an upper-bound of\nperformance that is close to being reached urging for an extension of the\nmodeling task, and (iii) introduces the tools and presents initial results to\npioneer a new paradigm for investigating and modeling reasoning focusing on\npredicting responses for individual human reasoners.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 10:12:35 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Riesterer", "Nicolas", ""], ["Brand", "Daniel", ""], ["Ragni", "Marco", ""]]}, {"id": "2003.05258", "submitter": "Manolis Peponakis", "authors": "Manolis Peponakis, Anna Mastora, Sarantos Kapidakis, Martin Doerr", "title": "Expressiveness and machine processability of Knowledge Organization\n  Systems (KOS): An analysis of concepts and relations", "comments": "34 pages, 2 tables, 2 figures", "journal-ref": "International Journal on Digital Libraries, 20(4), 433-452 (2019)", "doi": "10.1007/s00799-019-00269-0", "report-no": null, "categories": "cs.DL cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This study considers the expressiveness (that is the expressive power or\nexpressivity) of different types of Knowledge Organization Systems (KOS) and\ndiscusses its potential to be machine-processable in the context of the\nSemantic Web. For this purpose, the theoretical foundations of KOS are reviewed\nbased on conceptualizations introduced by the Functional Requirements for\nSubject Authority Data (FRSAD) and the Simple Knowledge Organization System\n(SKOS); natural language processing techniques are also implemented. Applying a\ncomparative analysis, the dataset comprises a thesaurus (Eurovoc), a subject\nheadings system (LCSH) and a classification scheme (DDC). These are compared\nwith an ontology (CIDOC-CRM) by focusing on how they define and handle concepts\nand relations. It was observed that LCSH and DDC focus on the formalism of\ncharacter strings (nomens) rather than on the modelling of semantics; their\ndefinition of what constitutes a concept is quite fuzzy, and they comprise a\nlarge number of complex concepts. By contrast, thesauri have a coherent\ndefinition of what constitutes a concept, and apply a systematic approach to\nthe modelling of relations. Ontologies explicitly define diverse types of\nrelations, and are by their nature machine-processable. The paper concludes\nthat the potential of both the expressiveness and machine processability of\neach KOS is extensively regulated by its structural rules. It is harder to\nrepresent subject headings and classification schemes as semantic networks with\nnodes and arcs, while thesauri are more suitable for such a representation. In\naddition, a paradigm shift is revealed which focuses on the modelling of\nrelations between concepts, rather than the concepts themselves.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 12:35:52 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Peponakis", "Manolis", ""], ["Mastora", "Anna", ""], ["Kapidakis", "Sarantos", ""], ["Doerr", "Martin", ""]]}, {"id": "2003.05311", "submitter": "Xingyu Zhao", "authors": "Xingyu Zhao, Alec Banks, James Sharp, Valentin Robu, David Flynn,\n  Michael Fisher, Xiaowei Huang", "title": "A Safety Framework for Critical Systems Utilising Deep Neural Networks", "comments": "Accepted by SafeComp2020", "journal-ref": null, "doi": "10.1007/978-3-030-54549-9_16", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly sophisticated mathematical modelling processes from Machine\nLearning are being used to analyse complex data. However, the performance and\nexplainability of these models within practical critical systems requires a\nrigorous and continuous verification of their safe utilisation. Working towards\naddressing this challenge, this paper presents a principled novel safety\nargument framework for critical systems that utilise deep neural networks. The\napproach allows various forms of predictions, e.g., future reliability of\npassing some demands, or confidence on a required reliability level. It is\nsupported by a Bayesian analysis using operational data and the recent\nverification and validation techniques for deep learning. The prediction is\nconservative -- it starts with partial prior knowledge obtained from lifecycle\nactivities and then determines the worst-case prediction. Open challenges are\nalso identified.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 23:35:05 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 13:44:10 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 10:49:23 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Zhao", "Xingyu", ""], ["Banks", "Alec", ""], ["Sharp", "James", ""], ["Robu", "Valentin", ""], ["Flynn", "David", ""], ["Fisher", "Michael", ""], ["Huang", "Xiaowei", ""]]}, {"id": "2003.05320", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "How the Brain might use Division", "comments": null, "journal-ref": "WSEAS Transactions on Computer Research, ISSN / E-ISSN: 1991-8755\n  / 2415-1521, Volume 8, 2020, Art. #16, pp. 126-137", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most fundamental questions in Biology or Artificial Intelligence\nis how the human brain performs mathematical functions. How does a neural\narchitecture that may organise itself mostly through statistics, know what to\ndo? One possibility is to extract the problem to something more abstract. This\nbecomes clear when thinking about how the brain handles large numbers, for\nexample to the power of something, when simply summing to an answer is not\nfeasible. In this paper, the author suggests that the maths question can be\nanswered more easily if the problem is changed into one of symbol manipulation\nand not just number counting. If symbols can be compared and manipulated, maybe\nwithout understanding completely what they are, then the mathematical\noperations become relative and some of them might even be rote learned. The\nproposed system may also be suggested as an alternative to the traditional\ncomputer binary system. Any of the actual maths still breaks down into binary\noperations, while a more symbolic level above that can manipulate the numbers\nand reduce the problem size, thus making the binary operations simpler. An\ninteresting result of looking at this is the possibility of a new fractal\nequation resulting from division, that can be used as a measure of good fit and\nwould help the brain decide how to solve something through self-replacement and\na comparison with this good fit.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 14:12:45 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 15:08:19 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "2003.05370", "submitter": "Ernesto Jimenez-Ruiz", "authors": "Ernesto Jim\\'enez-Ruiz, Asan Agibetov, Jiaoyan Chen, Matthias Samwald,\n  Valerie Cross", "title": "Dividing the Ontology Alignment Task with Semantic Embeddings and\n  Logic-based Modules", "comments": "Accepted to the 24th European Conference on Artificial Intelligence\n  (ECAI 2020). arXiv admin note: text overlap with arXiv:1805.12402", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large ontologies still pose serious challenges to state-of-the-art ontology\nalignment systems. In this paper we present an approach that combines a neural\nembedding model and logic-based modules to accurately divide an input ontology\nmatching task into smaller and more tractable matching (sub)tasks. We have\nconducted a comprehensive evaluation using the datasets of the Ontology\nAlignment Evaluation Initiative. The results are encouraging and suggest that\nthe proposed method is adequate in practice and can be integrated within the\nworkflow of systems unable to cope with very large ontologies.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 14:44:12 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Jim\u00e9nez-Ruiz", "Ernesto", ""], ["Agibetov", "Asan", ""], ["Chen", "Jiaoyan", ""], ["Samwald", "Matthias", ""], ["Cross", "Valerie", ""]]}, {"id": "2003.05434", "submitter": "Silverio Mart\\'inez-Fern\\'andez", "authors": "Silverio Mart\\'inez-Fern\\'andez, Xavier Franch, Andreas Jedlitschka,\n  Marc Oriol, and Adam Trendowicz", "title": "Developing and Operating Artificial Intelligence Models in Trustworthy\n  Autonomous Systems", "comments": "9 pages, 1 figure, preprint. Accepted in RCIS 2021", "journal-ref": null, "doi": "10.1007/978-3-030-75018-3_14", "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Companies dealing with Artificial Intelligence (AI) models in Autonomous\nSystems (AS) face several problems, such as users' lack of trust in adverse or\nunknown conditions, gaps between software engineering and AI model development,\nand operation in a continuously changing operational environment. This\nwork-in-progress paper aims to close the gap between the development and\noperation of trustworthy AI-based AS by defining an approach that coordinates\nboth activities. We synthesize the main challenges of AI-based AS in industrial\nsettings. We reflect on the research efforts required to overcome these\nchallenges and propose a novel, holistic DevOps approach to put it into\npractice. We elaborate on four research directions: (a) increased users' trust\nby monitoring operational AI-based AS and identifying self-adaptation needs in\ncritical situations; (b) integrated agile process for the development and\nevolution of AI models and AS; (c) continuous deployment of different\ncontext-specific instances of AI models in a distributed setting of AS; and (d)\nholistic DevOps-based lifecycle for AI-based AS.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 17:52:30 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 09:21:38 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Mart\u00ednez-Fern\u00e1ndez", "Silverio", ""], ["Franch", "Xavier", ""], ["Jedlitschka", "Andreas", ""], ["Oriol", "Marc", ""], ["Trendowicz", "Adam", ""]]}, {"id": "2003.05562", "submitter": "Maxwell Nye", "authors": "Maxwell I. Nye, Armando Solar-Lezama, Joshua B. Tenenbaum, Brenden M.\n  Lake", "title": "Learning Compositional Rules via Neural Program Synthesis", "comments": "NeurIPS 2020. Code can be found at\n  https://github.com/mtensor/rulesynthesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many aspects of human reasoning, including language, require learning rules\nfrom very little data. Humans can do this, often learning systematic rules from\nvery few examples, and combining these rules to form compositional rule-based\nsystems. Current neural architectures, on the other hand, often fail to\ngeneralize in a compositional manner, especially when evaluated in ways that\nvary systematically from training. In this work, we present a neuro-symbolic\nmodel which learns entire rule systems from a small set of examples. Instead of\ndirectly predicting outputs from inputs, we train our model to induce the\nexplicit system of rules governing a set of previously seen examples, drawing\nupon techniques from the neural program synthesis literature. Our\nrule-synthesis approach outperforms neural meta-learning techniques in three\ndomains: an artificial instruction-learning domain used to evaluate human\nlearning, the SCAN challenge datasets, and learning rule-based translations of\nnumber words into integers for a wide range of human languages.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 01:06:48 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 19:48:43 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Nye", "Maxwell I.", ""], ["Solar-Lezama", "Armando", ""], ["Tenenbaum", "Joshua B.", ""], ["Lake", "Brenden M.", ""]]}, {"id": "2003.05574", "submitter": "Magdalena Biesialska", "authors": "Katarzyna Biesialska, Magdalena Biesialska and Henryk Rybinski", "title": "Sentiment Analysis with Contextual Embeddings and Self-Attention", "comments": "Accepted at the 25th International Symposium on Methodologies for\n  Intelligent Systems (ISMIS 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-59491-6_4", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural language the intended meaning of a word or phrase is often\nimplicit and depends on the context. In this work, we propose a simple yet\neffective method for sentiment analysis using contextual embeddings and a\nself-attention mechanism. The experimental results for three languages,\nincluding morphologically rich Polish and German, show that our model is\ncomparable to or even outperforms state-of-the-art models. In all cases the\nsuperiority of models leveraging contextual embeddings is demonstrated.\nFinally, this work is intended as a step towards introducing a universal,\nmultilingual sentiment classifier.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 02:19:51 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 23:02:42 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Biesialska", "Katarzyna", ""], ["Biesialska", "Magdalena", ""], ["Rybinski", "Henryk", ""]]}, {"id": "2003.05586", "submitter": "Pongpisit Thanasutives", "authors": "Pongpisit Thanasutives, Ken-ichi Fukui, Masayuki Numao, Boonserm\n  Kijsirikul", "title": "Encoder-Decoder Based Convolutional Neural Networks with\n  Multi-Scale-Aware Modules for Crowd Counting", "comments": "Accepted at ICPR 2020", "journal-ref": null, "doi": "10.1109/ICPR48806.2021.9413286", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose two modified neural networks based on dual path\nmulti-scale fusion networks (SFANet) and SegNet for accurate and efficient\ncrowd counting. Inspired by SFANet, the first model, which is named M-SFANet,\nis attached with atrous spatial pyramid pooling (ASPP) and context-aware module\n(CAN). The encoder of M-SFANet is enhanced with ASPP containing parallel atrous\nconvolutional layers with different sampling rates and hence able to extract\nmulti-scale features of the target object and incorporate larger context. To\nfurther deal with scale variation throughout an input image, we leverage the\nCAN module which adaptively encodes the scales of the contextual information.\nThe combination yields an effective model for counting in both dense and sparse\ncrowd scenes. Based on the SFANet decoder structure, M-SFANet's decoder has\ndual paths, for density map and attention map generation. The second model is\ncalled M-SegNet, which is produced by replacing the bilinear upsampling in\nSFANet with max unpooling that is used in SegNet. This change provides a faster\nmodel while providing competitive counting performance. Designed for high-speed\nsurveillance applications, M-SegNet has no additional multi-scale-aware module\nin order to not increase the complexity. Both models are encoder-decoder based\narchitectures and are end-to-end trainable. We conduct extensive experiments on\nfive crowd counting datasets and one vehicle counting dataset to show that\nthese modifications yield algorithms that could improve state-of-the-art crowd\ncounting methods. Codes are available at\nhttps://github.com/Pongpisit-Thanasutives/Variations-of-SFANet-for-Crowd-Counting.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 03:00:26 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 15:05:18 GMT"}, {"version": "v3", "created": "Sat, 28 Mar 2020 11:22:19 GMT"}, {"version": "v4", "created": "Mon, 13 Apr 2020 15:18:44 GMT"}, {"version": "v5", "created": "Wed, 25 Nov 2020 12:35:21 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Thanasutives", "Pongpisit", ""], ["Fukui", "Ken-ichi", ""], ["Numao", "Masayuki", ""], ["Kijsirikul", "Boonserm", ""]]}, {"id": "2003.05597", "submitter": "Xue Yang", "authors": "Xue Yang, Junchi Yan and Tao He", "title": "On the Arbitrary-Oriented Object Detection: Classification based\n  Approaches Revisited", "comments": "16 pages, 14 figures, 10 tables, journal version of CSL (ECCV2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arbitrary-oriented object detection has been a building block for rotation\nsensitive tasks. We first show that the problem of discontinuous boundaries\nsuffered in existing dominant regression-based rotation detectors, is caused by\nangular periodicity or corner ordering, according to the parameterization\nprotocol. We also show that the root cause is that the ideal predictions can be\nout of the defined range. Accordingly, we transform the angular prediction task\nfrom a regression problem to a classification one. For the resulting circularly\ndistributed angle classification problem, we first devise a Circular Smooth\nLabel (CSL) technique to handle the periodicity of angle and increase the error\ntolerance to adjacent angles. To reduce the excessive model parameters by CSL,\nwe further design a Gray Coded Label (GCL), which greatly reduces the length of\nthe encoding. Finally, we further develop an object heading detection module,\nwhich can be useful when the exact heading orientation information is needed\ne.g. for ship and plane heading detection. We release our OHD-SJTU dataset and\nOHDet detector for heading detection. Results on three large-scale public\ndatasets for aerial images i.e. DOTA, HRSC2016, OHD-SJTU, as well as scene text\ndataset ICDAR2015 and MLT, show the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 03:23:54 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 12:59:20 GMT"}, {"version": "v3", "created": "Sat, 27 Mar 2021 06:25:58 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Yang", "Xue", ""], ["Yan", "Junchi", ""], ["He", "Tao", ""]]}, {"id": "2003.05602", "submitter": "Yuening Li", "authors": "Yuening Li, Daochen Zha, Praveen Kumar Venugopal, Na Zou, and Xia Hu", "title": "PyODDS: An End-to-end Outlier Detection System with Automated Machine\n  Learning", "comments": "In Companion Proceedings of the Web Conference 2020 (WWW 20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection is an important task for various data mining applications.\nCurrent outlier detection techniques are often manually designed for specific\ndomains, requiring large human efforts of database setup, algorithm selection,\nand hyper-parameter tuning. To fill this gap, we present PyODDS, an automated\nend-to-end Python system for Outlier Detection with Database Support, which\nautomatically optimizes an outlier detection pipeline for a new data source at\nhand. Specifically, we define the search space in the outlier detection\npipeline, and produce a search strategy within the given search space. PyODDS\nenables end-to-end executions based on an Apache Spark backend server and a\nlight-weight database. It also provides unified interfaces and visualizations\nfor users with or without data science or machine learning background. In\nparticular, we demonstrate PyODDS on several real-world datasets, with\nquantification analysis and visualization results.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 03:30:30 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Li", "Yuening", ""], ["Zha", "Daochen", ""], ["Venugopal", "Praveen Kumar", ""], ["Zou", "Na", ""], ["Hu", "Xia", ""]]}, {"id": "2003.05610", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Ziqi Liu, Peilin Zhao, Jun Zhou, Xiaolong Li", "title": "Privacy Preserving Point-of-interest Recommendation Using Decentralized\n  Matrix Factorization", "comments": "Accepted by AAAI'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Points of interest (POI) recommendation has been drawn much attention\nrecently due to the increasing popularity of location-based networks, e.g.,\nFoursquare and Yelp. Among the existing approaches to POI recommendation,\nMatrix Factorization (MF) based techniques have proven to be effective.\nHowever, existing MF approaches suffer from two major problems: (1) Expensive\ncomputations and storages due to the centralized model training mechanism: the\ncentralized learners have to maintain the whole user-item rating matrix, and\npotentially huge low rank matrices. (2) Privacy issues: the users' preferences\nare at risk of leaking to malicious attackers via the centralized learner. To\nsolve these, we present a Decentralized MF (DMF) framework for POI\nrecommendation. Specifically, instead of maintaining all the low rank matrices\nand sensitive rating data for training, we propose a random walk based\ndecentralized training technique to train MF models on each user's end, e.g.,\ncell phone and Pad. By doing so, the ratings of each user are still kept on\none's own hand, and moreover, decentralized learning can be taken as\ndistributed learning with multi-learners (users), and thus alleviates the\ncomputation and storage issue. Experimental results on two real-world datasets\ndemonstrate that, comparing with the classic and state-of-the-art latent factor\nmodels, DMF significantly improvements the recommendation performance in terms\nof precision and recall.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 04:08:05 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Chen", "Chaochao", ""], ["Liu", "Ziqi", ""], ["Zhao", "Peilin", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""]]}, {"id": "2003.05730", "submitter": "Jintang Li", "authors": "Liang Chen, Jintang Li, Jiaying Peng, Tao Xie, Zengxu Cao, Kun Xu,\n  Xiangnan He, Zibin Zheng", "title": "A Survey of Adversarial Learning on Graphs", "comments": "TKDD under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models on graphs have achieved remarkable performance in\nvarious graph analysis tasks, e.g., node classification, link prediction and\ngraph clustering. However, they expose uncertainty and unreliability against\nthe well-designed inputs, i.e., adversarial examples. Accordingly, a line of\nstudies have emerged for both attack and defense addressed in different graph\nanalysis tasks, leading to the arms race in graph adversarial learning.\n  Despite the booming works, there still lacks a unified problem definition and\na comprehensive review. To bridge this gap, we investigate and summarize the\nexisting works on graph adversarial learning tasks systemically. Specifically,\nwe survey and unify the existing works w.r.t. attack and defense in graph\nanalysis tasks, and give appropriate definitions and taxonomies at the same\ntime. Besides, we emphasize the importance of related evaluation metrics,\ninvestigate and summarize them comprehensively. Hopefully, our works can\nprovide a comprehensive overview and offer insights for the relevant\nresearchers. More details of our works are available at\nhttps://github.com/gitgiter/Graph-Adversarial-Learning.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 12:48:00 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 13:43:57 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Chen", "Liang", ""], ["Li", "Jintang", ""], ["Peng", "Jiaying", ""], ["Xie", "Tao", ""], ["Cao", "Zengxu", ""], ["Xu", "Kun", ""], ["He", "Xiangnan", ""], ["Zheng", "Zibin", ""]]}, {"id": "2003.05746", "submitter": "Camille Bourgaux", "authors": "Meghyn Bienvenu and Camille Bourgaux", "title": "Querying and Repairing Inconsistent Prioritized Knowledge Bases:\n  Complexity Analysis and Links with Abstract Argumentation", "comments": "27 pages. To appear in the 17th International Conference on\n  Principles of Knowledge Representation and Reasoning (KR 2020) without the\n  appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the issue of inconsistency handling over\nprioritized knowledge bases (KBs), which consist of an ontology, a set of\nfacts, and a priority relation between conflicting facts. In the database\nsetting, a closely related scenario has been studied and led to the definition\nof three different notions of optimal repairs (global, Pareto, and completion)\nof a prioritized inconsistent database. After transferring the notions of\nglobally-, Pareto- and completion-optimal repairs to our setting, we study the\ndata complexity of the core reasoning tasks: query entailment under\ninconsistency-tolerant semantics based upon optimal repairs, existence of a\nunique optimal repair, and enumeration of all optimal repairs. Our results\nprovide a nearly complete picture of the data complexity of these tasks for\nontologies formulated in common DL-Lite dialects. The second contribution of\nour work is to clarify the relationship between optimal repairs and different\nnotions of extensions for (set-based) argumentation frameworks. Among our\nresults, we show that Pareto-optimal repairs correspond precisely to stable\nextensions (and often also to preferred extensions), and we propose a novel\nsemantics for prioritized KBs which is inspired by grounded extensions and\nenjoys favourable computational properties. Our study also yields some results\nof independent interest concerning preference-based argumentation frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 12:38:37 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 16:15:30 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Bienvenu", "Meghyn", ""], ["Bourgaux", "Camille", ""]]}, {"id": "2003.05809", "submitter": "Heiko Paulheim", "authors": "Jan Portisch, Michael Hladik, Heiko Paulheim", "title": "KGvec2go -- Knowledge Graph Embeddings as a Service", "comments": "to be published in the Proceedings of the International Conference on\n  Language Resources and Evaluation (LREC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present KGvec2go, a Web API for accessing and consuming\ngraph embeddings in a light-weight fashion in downstream applications.\nCurrently, we serve pre-trained embeddings for four knowledge graphs. We\nintroduce the service and its usage, and we show further that the trained\nmodels have semantic value by evaluating them on multiple semantic benchmarks.\nThe evaluation also reveals that the combination of multiple models can lead to\na better outcome than the best individual model.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 12:57:10 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Portisch", "Jan", ""], ["Hladik", "Michael", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2003.05817", "submitter": "Martin Naya-Varela", "authors": "M.Naya-Varela (1), A. Faina (2) and R. J. Duro (3) ((1) Universidade\n  da Coruna, (2) IT University of Copenhagen)", "title": "Some Experiments on the influence of Problem Hardness in Morphological\n  Development based Learning of Neural Controllers", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural beings undergo a morphological development process of their bodies\nwhile they are learning and adapting to the environments they face from infancy\nto adulthood. In fact, this is the period where the most important learning\npro-cesses, those that will support learning as adults, will take place.\nHowever, in artificial systems, this interaction between morphological\ndevelopment and learning, and its possible advantages, have seldom been\nconsidered. In this line, this paper seeks to provide some insights into how\nmorphological development can be harnessed in order to facilitate learning in\nem-bodied systems facing tasks or domains that are hard to learn. In\nparticular, here we will concentrate on whether morphological development can\nreally provide any advantage when learning complex tasks and whether its\nrelevance towards learning in-creases as tasks become harder. To this end, we\npresent the results of some initial experiments on the application of\nmorpho-logical development to learning to walk in three cases, that of a\nquadruped, a hexapod and that of an octopod. These results seem to confirm that\nas task learning difficulty increases the application of morphological\ndevelopment to learning becomes more advantageous.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 14:23:25 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Naya-Varela", "M.", ""], ["Faina", "A.", ""], ["Duro", "R. J.", ""]]}, {"id": "2003.05856", "submitter": "Massimo Caccia", "authors": "Massimo Caccia, Pau Rodriguez, Oleksiy Ostapenko, Fabrice Normandin,\n  Min Lin, Lucas Caccia, Issam Laradji, Irina Rish, Alexandre Lacoste, David\n  Vazquez, Laurent Charlin", "title": "Online Fast Adaptation and Knowledge Accumulation: a New Approach to\n  Continual Learning", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning studies agents that learn from streams of tasks without\nforgetting previous ones while adapting to new ones. Two recent\ncontinual-learning scenarios have opened new avenues of research. In\nmeta-continual learning, the model is pre-trained to minimize catastrophic\nforgetting of previous tasks. In continual-meta learning, the aim is to train\nagents for faster remembering of previous tasks through adaptation. In their\noriginal formulations, both methods have limitations. We stand on their\nshoulders to propose a more general scenario, OSAKA, where an agent must\nquickly solve new (out-of-distribution) tasks, while also requiring fast\nremembering. We show that current continual learning, meta-learning,\nmeta-continual learning, and continual-meta learning techniques fail in this\nnew scenario. We propose Continual-MAML, an online extension of the popular\nMAML algorithm as a strong baseline for this scenario. We empirically show that\nContinual-MAML is better suited to the new scenario than the aforementioned\nmethodologies, as well as standard continual learning and meta-learning\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 15:47:16 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 15:45:45 GMT"}, {"version": "v3", "created": "Wed, 20 Jan 2021 23:58:29 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Caccia", "Massimo", ""], ["Rodriguez", "Pau", ""], ["Ostapenko", "Oleksiy", ""], ["Normandin", "Fabrice", ""], ["Lin", "Min", ""], ["Caccia", "Lucas", ""], ["Laradji", "Issam", ""], ["Rish", "Irina", ""], ["Lacoste", "Alexandre", ""], ["Vazquez", "David", ""], ["Charlin", "Laurent", ""]]}, {"id": "2003.05861", "submitter": "Pablo Barros", "authors": "Pablo Barros, Anne C. Bloem, Inge M. Hootsmans, Lena M. Opheij, Romain\n  H.A. Toebosch, Emilia Barakova and Alessandra Sciutti", "title": "The Chef's Hat Simulation Environment for Reinforcement-Learning-Based\n  Agents", "comments": "Submitted to IROS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To achieve social interactions within Human-Robot Interaction (HRI)\nenvironments is a very challenging task. Most of the current research focuses\non Wizard-of-Oz approaches, which neglect the recent development of intelligent\nrobots. On the other hand, real-world scenarios usually do not provide the\nnecessary control and reproducibility which are needed for learning algorithms.\nIn this paper, we propose a virtual simulation environment that implements the\nChef's Hat card game, designed to be used in HRI scenarios, to provide a\ncontrollable and reproducible scenario for reinforcement-learning algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 15:52:49 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Barros", "Pablo", ""], ["Bloem", "Anne C.", ""], ["Hootsmans", "Inge M.", ""], ["Opheij", "Lena M.", ""], ["Toebosch", "Romain H. A.", ""], ["Barakova", "Emilia", ""], ["Sciutti", "Alessandra", ""]]}, {"id": "2003.05870", "submitter": "Francisco Javier Chiyah Garcia", "authors": "Francisco J. Chiyah Garcia, Jos\\'e Lopes, Helen Hastie", "title": "Natural Language Interaction to Facilitate Mental Models of Remote\n  Robots", "comments": "In Workshop on Mental Models of Robots at HRI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly complex and autonomous robots are being deployed in real-world\nenvironments with far-reaching consequences. High-stakes scenarios, such as\nemergency response or offshore energy platform and nuclear inspections, require\nrobot operators to have clear mental models of what the robots can and can't\ndo. However, operators are often not the original designers of the robots and\nthus, they do not necessarily have such clear mental models, especially if they\nare novice users. This lack of mental model clarity can slow adoption and can\nnegatively impact human-machine teaming. We propose that interaction with a\nconversational assistant, who acts as a mediator, can help the user with\nunderstanding the functionality of remote robots and increase transparency\nthrough natural language explanations, as well as facilitate the evaluation of\noperators' mental models.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 16:03:27 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Garcia", "Francisco J. Chiyah", ""], ["Lopes", "Jos\u00e9", ""], ["Hastie", "Helen", ""]]}, {"id": "2003.05878", "submitter": "Amitay Bar", "authors": "Amitay Bar, Ronen Talmon and Ron Meir", "title": "Option Discovery in the Absence of Rewards with Manifold Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Options have been shown to be an effective tool in reinforcement learning,\nfacilitating improved exploration and learning. In this paper, we present an\napproach based on spectral graph theory and derive an algorithm that\nsystematically discovers options without access to a specific reward or task\nassignment. As opposed to the common practice used in previous methods, our\nalgorithm makes full use of the spectrum of the graph Laplacian. Incorporating\nmodes associated with higher graph frequencies unravels domain subtleties,\nwhich are shown to be useful for option discovery. Using geometric and\nmanifold-based analysis, we present a theoretical justification for the\nalgorithm. In addition, we showcase its performance in several domains,\ndemonstrating clear improvements compared to competing methods.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 16:14:24 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 13:53:37 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Bar", "Amitay", ""], ["Talmon", "Ronen", ""], ["Meir", "Ron", ""]]}, {"id": "2003.05988", "submitter": "Hui Wang", "authors": "Hui Wang, Michael Emmerich, Mike Preuss, Aske Plaat", "title": "Analysis of Hyper-Parameters for Small Games: Iterations or Epochs in\n  Self-Play?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The landmark achievements of AlphaGo Zero have created great research\ninterest into self-play in reinforcement learning. In self-play, Monte Carlo\nTree Search is used to train a deep neural network, that is then used in tree\nsearches. Training itself is governed by many hyperparameters.There has been\nsurprisingly little research on design choices for hyper-parameter values and\nloss-functions, presumably because of the prohibitive computational cost to\nexplore the parameter space. In this paper, we investigate 12 hyper-parameters\nin an AlphaZero-like self-play algorithm and evaluate how these parameters\ncontribute to training. We use small games, to achieve meaningful exploration\nwith moderate computational effort. The experimental results show that training\nis highly sensitive to hyper-parameter choices. Through multi-objective\nanalysis we identify 4 important hyper-parameters to further assess. To start,\nwe find surprising results where too much training can sometimes lead to lower\nperformance. Our main result is that the number of self-play iterations\nsubsumes MCTS-search simulations, game-episodes, and training epochs. The\nintuition is that these three increase together as self-play iterations\nincrease, and that increasing them individually is sub-optimal. A consequence\nof our experiments is a direct recommendation for setting hyper-parameter\nvalues in self-play: the overarching outer-loop of self-play iterations should\nbe maximized, in favor of the three inner-loop hyper-parameters, which should\nbe set at lower values. A secondary result of our experiments concerns the\nchoice of optimization goals, for which we also provide recommendations.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 19:28:48 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Wang", "Hui", ""], ["Emmerich", "Michael", ""], ["Preuss", "Mike", ""], ["Plaat", "Aske", ""]]}, {"id": "2003.05993", "submitter": "Erik Wijmans", "authors": "Erik Wijmans, Julian Straub, Dhruv Batra, Irfan Essa, Judy Hoffman,\n  Ari Morcos", "title": "Analyzing Visual Representations in Embodied Navigation Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep reinforcement learning require a large amount of\ntraining data and generally result in representations that are often over\nspecialized to the target task. In this work, we present a methodology to study\nthe underlying potential causes for this specialization. We use the recently\nproposed projection weighted Canonical Correlation Analysis (PWCCA) to measure\nthe similarity of visual representations learned in the same environment by\nperforming different tasks.\n  We then leverage our proposed methodology to examine the task dependence of\nvisual representations learned on related but distinct embodied navigation\ntasks. Surprisingly, we find that slight differences in task have no measurable\neffect on the visual representation for both SqueezeNet and ResNet\narchitectures. We then empirically demonstrate that visual representations\nlearned on one task can be effectively transferred to a different task.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 19:43:59 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Wijmans", "Erik", ""], ["Straub", "Julian", ""], ["Batra", "Dhruv", ""], ["Essa", "Irfan", ""], ["Hoffman", "Judy", ""], ["Morcos", "Ari", ""]]}, {"id": "2003.06005", "submitter": "Karthikeyan Natesan Ramamurthy", "authors": "Karthikeyan Natesan Ramamurthy, Bhanukiran Vinzamuri, Yunfeng Zhang,\n  Amit Dhurandhar", "title": "Model Agnostic Multilevel Explanations", "comments": "21 pages, 9 figures, 1 table", "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, post-hoc local instance-level and global dataset-level\nexplainability of black-box models has received a lot of attention. Much less\nattention has been given to obtaining insights at intermediate or group levels,\nwhich is a need outlined in recent works that study the challenges in realizing\nthe guidelines in the General Data Protection Regulation (GDPR). In this paper,\nwe propose a meta-method that, given a typical local explainability method, can\nbuild a multilevel explanation tree. The leaves of this tree correspond to the\nlocal explanations, the root corresponds to the global explanation, and\nintermediate levels correspond to explanations for groups of data points that\nit automatically clusters. The method can also leverage side information, where\nusers can specify points for which they may want the explanations to be\nsimilar. We argue that such a multilevel structure can also be an effective\nform of communication, where one could obtain few explanations that\ncharacterize the entire dataset by considering an appropriate level in our\nexplanation tree. Explanations for novel test points can be cost-efficiently\nobtained by associating them with the closest training points. When the local\nexplainability technique is generalized additive (viz. LIME, GAMs), we develop\na fast approximate algorithm for building the multilevel tree and study its\nconvergence behavior. We validate the effectiveness of the proposed technique\nbased on two human studies -- one with experts and the other with non-expert\nusers -- on real world datasets, and show that we produce high fidelity sparse\nexplanations on several other public datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 20:18:00 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ramamurthy", "Karthikeyan Natesan", ""], ["Vinzamuri", "Bhanukiran", ""], ["Zhang", "Yunfeng", ""], ["Dhurandhar", "Amit", ""]]}, {"id": "2003.06016", "submitter": "Amy Zhang", "authors": "Amy Zhang, Clare Lyle, Shagun Sodhani, Angelos Filos, Marta\n  Kwiatkowska, Joelle Pineau, Yarin Gal, Doina Precup", "title": "Invariant Causal Prediction for Block MDPs", "comments": "Accepted to ICML 2020. 16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization across environments is critical to the successful application\nof reinforcement learning algorithms to real-world challenges. In this paper,\nwe consider the problem of learning abstractions that generalize in block MDPs,\nfamilies of environments with a shared latent state space and dynamics\nstructure over that latent space, but varying observations. We leverage tools\nfrom causal inference to propose a method of invariant prediction to learn\nmodel-irrelevance state abstractions (MISA) that generalize to novel\nobservations in the multi-environment setting. We prove that for certain\nclasses of environments, this approach outputs with high probability a state\nabstraction corresponding to the causal feature set with respect to the return.\nWe further provide more general bounds on model error and generalization error\nin the multi-environment setting, in the process showing a connection between\ncausal variable selection and the state abstraction framework for MDPs. We give\nempirical evidence that our methods work in both linear and nonlinear settings,\nattaining improved generalization over single- and multi-task baselines.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 21:03:01 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 18:01:02 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Zhang", "Amy", ""], ["Lyle", "Clare", ""], ["Sodhani", "Shagun", ""], ["Filos", "Angelos", ""], ["Kwiatkowska", "Marta", ""], ["Pineau", "Joelle", ""], ["Gal", "Yarin", ""], ["Precup", "Doina", ""]]}, {"id": "2003.06060", "submitter": "Ruixiang Zhang", "authors": "Tong Che, Ruixiang Zhang, Jascha Sohl-Dickstein, Hugo Larochelle, Liam\n  Paull, Yuan Cao, Yoshua Bengio", "title": "Your GAN is Secretly an Energy-based Model and You Should use\n  Discriminator Driven Latent Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the sum of the implicit generator log-density $\\log p_g$ of a\nGAN with the logit score of the discriminator defines an energy function which\nyields the true data density when the generator is imperfect but the\ndiscriminator is optimal, thus making it possible to improve on the typical\ngenerator (with implicit density $p_g$). To make that practical, we show that\nsampling from this modified density can be achieved by sampling in latent space\naccording to an energy-based model induced by the sum of the latent prior\nlog-density and the discriminator output score. This can be achieved by running\na Langevin MCMC in latent space and then applying the generator function, which\nwe call Discriminator Driven Latent Sampling~(DDLS). We show that DDLS is\nhighly efficient compared to previous methods which work in the\nhigh-dimensional pixel space and can be applied to improve on previously\ntrained GANs of many types. We evaluate DDLS on both synthetic and real-world\ndatasets qualitatively and quantitatively. On CIFAR-10, DDLS substantially\nimproves the Inception Score of an off-the-shelf pre-trained\nSN-GAN~\\citep{sngan} from $8.22$ to $9.09$ which is even comparable to the\nclass-conditional BigGAN~\\citep{biggan} model. This achieves a new\nstate-of-the-art in unconditional image synthesis setting without introducing\nextra parameters or additional training.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 23:33:50 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 03:31:07 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 17:57:49 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Che", "Tong", ""], ["Zhang", "Ruixiang", ""], ["Sohl-Dickstein", "Jascha", ""], ["Larochelle", "Hugo", ""], ["Paull", "Liam", ""], ["Cao", "Yuan", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2003.06071", "submitter": "Yulong Gu", "authors": "Yulong Gu, Yu Guan, Paolo Missier", "title": "Towards Learning Instantiated Logical Rules from Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiently inducing high-level interpretable regularities from knowledge\ngraphs (KGs) is an essential yet challenging task that benefits many downstream\napplications. In this work, we present GPFL, a probabilistic rule learner\noptimized to mine instantiated first-order logic rules from KGs. Instantiated\nrules contain constants extracted from KGs. Compared to abstract rules that\ncontain no constants, instantiated rules are capable of explaining and\nexpressing concepts in more details. GPFL utilizes a novel two-stage rule\ngeneration mechanism that first generalizes extracted paths into templates that\nare acyclic abstract rules until a certain degree of template saturation is\nachieved, then specializes the generated templates into instantiated rules.\nUnlike existing works that ground every mined instantiated rule for evaluation,\nGPFL shares groundings between structurally similar rules for collective\nevaluation. Moreover, we reveal the presence of overfitting rules, their impact\non the predictive performance, and the effectiveness of a simple validation\nmethod filtering out overfitting rules. Through extensive experiments on public\nbenchmark datasets, we show that GPFL 1.) significantly reduces the runtime on\nevaluating instantiated rules; 2.) discovers much more quality instantiated\nrules than existing works; 3.) improves the predictive performance of learned\nrules by removing overfitting rules via validation; 4.) is competitive on\nknowledge graph completion task compared to state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 00:32:46 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 11:11:19 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Gu", "Yulong", ""], ["Guan", "Yu", ""], ["Missier", "Paolo", ""]]}, {"id": "2003.06082", "submitter": "Bernadette Bucher", "authors": "Bernadette Bucher, Karl Schmeckpeper, Nikolai Matni, Kostas Daniilidis", "title": "An Adversarial Objective for Scalable Exploration", "comments": "Additional visualizations of our results are available on our website\n  at https://sites.google.com/view/action-for-better-prediction . Bernadette\n  Bucher and Karl Schmeckpeper contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based curiosity combines active learning approaches to optimal sampling\nwith the information gain based incentives for exploration presented in the\ncuriosity literature. Existing model-based curiosity methods look to\napproximate prediction uncertainty with approaches which struggle to scale to\nmany prediction-planning pipelines used in robotics tasks. We address these\nscalability issues with an adversarial curiosity method minimizing a score\ngiven by a discriminator network. This discriminator is optimized jointly with\na prediction model and enables our active learning approach to sample sequences\nof observations and actions which result in predictions considered the least\nrealistic by the discriminator. We demonstrate progressively increasing\nadvantages as compute is restricted of our adversarial curiosity approach over\nleading model-based exploration strategies in simulated environments. We\nfurther demonstrate the ability of our adversarial curiosity method to scale to\na robotic manipulation prediction-planning pipeline where we improve sample\nefficiency and prediction performance for a domain transfer problem.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 02:03:05 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 17:11:18 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 01:21:48 GMT"}, {"version": "v4", "created": "Wed, 11 Nov 2020 18:39:43 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Bucher", "Bernadette", ""], ["Schmeckpeper", "Karl", ""], ["Matni", "Nikolai", ""], ["Daniilidis", "Kostas", ""]]}, {"id": "2003.06085", "submitter": "Danfei Xu", "authors": "Ajay Mandlekar, Danfei Xu, Roberto Mart\\'in-Mart\\'in, Silvio Savarese,\n  Li Fei-Fei", "title": "Learning to Generalize Across Long-Horizon Tasks from Human\n  Demonstrations", "comments": "RSS 2020; First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning is an effective and safe technique to train robot policies\nin the real world because it does not depend on an expensive random exploration\nprocess. However, due to the lack of exploration, learning policies that\ngeneralize beyond the demonstrated behaviors is still an open challenge. We\npresent a novel imitation learning framework to enable robots to 1) learn\ncomplex real world manipulation tasks efficiently from a small number of human\ndemonstrations, and 2) synthesize new behaviors not contained in the collected\ndemonstrations. Our key insight is that multi-task domains often present a\nlatent structure, where demonstrated trajectories for different tasks intersect\nat common regions of the state space. We present Generalization Through\nImitation (GTI), a two-stage offline imitation learning algorithm that exploits\nthis intersecting structure to train goal-directed policies that generalize to\nunseen start and goal state combinations. In the first stage of GTI, we train a\nstochastic policy that leverages trajectory intersections to have the capacity\nto compose behaviors from different demonstration trajectories together. In the\nsecond stage of GTI, we collect a small set of rollouts from the unconditioned\nstochastic policy of the first stage, and train a goal-directed agent to\ngeneralize to novel start and goal configurations. We validate GTI in both\nsimulated domains and a challenging long-horizon robotic manipulation domain in\nthe real world. Additional results and videos are available at\nhttps://sites.google.com/view/gti2020/ .\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 02:25:28 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 05:17:45 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Mandlekar", "Ajay", ""], ["Xu", "Danfei", ""], ["Mart\u00edn-Mart\u00edn", "Roberto", ""], ["Savarese", "Silvio", ""], ["Fei-Fei", "Li", ""]]}, {"id": "2003.06169", "submitter": "Xinwei Wang", "authors": "Xinwei Wang, Guohua Wu, Lining Xing, Witold Pedrycz", "title": "Agile Earth observation satellite scheduling over 20 years:\n  formulations, methods and future directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agile satellites with advanced attitude maneuvering capability are the new\ngeneration of Earth observation satellites (EOSs). The continuous improvement\nin satellite technology and decrease in launch cost have boosted the\ndevelopment of agile EOSs (AEOSs). To efficiently employ the increasing\norbiting AEOSs, the AEOS scheduling problem (AEOSSP) aiming to maximize the\nentire observation profit while satisfying all complex operational constraints,\nhas received much attention over the past 20 years. The objectives of this\npaper are thus to summarize current research on AEOSSP, identify main\naccomplishments and highlight potential future research directions. To this\nend, general definitions of AEOSSP with operational constraints are described\ninitially, followed by its three typical variations including different\ndefinitions of observation profit, multi-objective function and autonomous\nmodel. A detailed literature review from 1997 up to 2019 is then presented in\nline with four different solution methods, i.e., exact method, heuristic,\nmetaheuristic and machine learning. Finally, we discuss a number of topics\nworth pursuing in the future.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 09:38:40 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Wang", "Xinwei", ""], ["Wu", "Guohua", ""], ["Xing", "Lining", ""], ["Pedrycz", "Witold", ""]]}, {"id": "2003.06171", "submitter": "Agnese Chiatti", "authors": "Agnese Chiatti, Enrico Motta, Enrico Daga", "title": "Towards a Framework for Visual Intelligence in Service Robotics:\n  Epistemic Requirements and Gap Analysis", "comments": null, "journal-ref": "In Proceedings of the 17th International Conference on Principles\n  of Knowledge Representation and Reasoning (KR 2020), Special Session on KR\n  and Robotics", "doi": "10.24963/kr.2020/93", "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key capability required by service robots operating in real-world, dynamic\nenvironments is that of Visual Intelligence, i.e., the ability to use their\nvision system, reasoning components and background knowledge to make sense of\ntheir environment. In this paper, we analyze the epistemic requirements for\nVisual Intelligence, both in a top-down fashion, using existing frameworks for\nhuman-like Visual Intelligence in the literature, and from the bottom up, based\non the errors emerging from object recognition trials in a real-world robotic\nscenario. Finally, we use these requirements to evaluate current knowledge\nbases for Service Robotics and to identify gaps in the support they provide for\nVisual Intelligence. These gaps provide the basis of a research agenda for\ndeveloping more effective knowledge representations for Visual Intelligence.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 09:41:05 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Chiatti", "Agnese", ""], ["Motta", "Enrico", ""], ["Daga", "Enrico", ""]]}, {"id": "2003.06212", "submitter": "I-Chen Wu", "authors": "Ti-Rong Wu, Ting-Han Wei, I-Chen Wu", "title": "Accelerating and Improving AlphaZero Using Population Based Training", "comments": "accepted by AAAI2020 as oral presentation. In this version,\n  supplementary materials are added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AlphaZero has been very successful in many games. Unfortunately, it still\nconsumes a huge amount of computing resources, the majority of which is spent\nin self-play. Hyperparameter tuning exacerbates the training cost since each\nhyperparameter configuration requires its own time to train one run, during\nwhich it will generate its own self-play records. As a result, multiple runs\nare usually needed for different hyperparameter configurations. This paper\nproposes using population based training (PBT) to help tune hyperparameters\ndynamically and improve strength during training time. Another significant\nadvantage is that this method requires a single run only, while incurring a\nsmall additional time cost, since the time for generating self-play records\nremains unchanged though the time for optimization is increased following the\nAlphaZero training algorithm. In our experiments for 9x9 Go, the PBT method is\nable to achieve a higher win rate for 9x9 Go than the baselines, each with its\nown hyperparameter configuration and trained individually. For 19x19 Go, with\nPBT, we are able to obtain improvements in playing strength. Specifically, the\nPBT agent can obtain up to 74% win rate against ELF OpenGo, an open-source\nstate-of-the-art AlphaZero program using a neural network of a comparable\ncapacity. This is compared to a saturated non-PBT agent, which achieves a win\nrate of 47% against ELF OpenGo under the same circumstances.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 11:56:14 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Wu", "Ti-Rong", ""], ["Wei", "Ting-Han", ""], ["Wu", "I-Chen", ""]]}, {"id": "2003.06265", "submitter": "Henri Kauhanen", "authors": "Henri Kauhanen", "title": "Stable variation in multidimensional competition", "comments": "28 pages, 14 figures", "journal-ref": "In A. Breitbarth, M. Bouzouita, L. Danckaert & M. Farasyn (eds.),\n  The determinants of diachronic stability, pp. 263-290. Amsterdam: John\n  Benjamins (2019)", "doi": "10.1075/la.254.11kau", "report-no": null, "categories": "cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fundamental Theorem of Language Change (Yang, 2000) implies the\nimpossibility of stable variation in the Variational Learning framework, but\nonly in the special case where two, and not more, grammatical variants compete.\nIntroducing the notion of an advantage matrix, I generalize Variational\nLearning to situations where the learner receives input generated by more than\ntwo grammars, and show that diachronically stable variation is an intrinsic\nfeature of several types of such multiple-grammar systems. This invites\nexperimentalists to take the possibility of stable variation seriously and\nidentifies one possible place where to look for it: situations of complex\nlanguage contact.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 17:40:57 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Kauhanen", "Henri", ""]]}, {"id": "2003.06347", "submitter": "Jennifer Renoux", "authors": "Jennifer Renoux, Uwe K\\\"ockemann, Amy Loutfi", "title": "Online Guest Detection in a Smart Home using Pervasive Sensors and\n  Probabilistic Reasoning", "comments": null, "journal-ref": "European Conference on Ambient Intelligence (pp. 74-89). Springer,\n  Cham, 2018", "doi": "10.1007/978-3-030-03062-9_6", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart home environments equipped with distributed sensor networks are capable\nof helping people by providing services related to health, emergency detection\nor daily routine management. A backbone to these systems relies often on the\nsystem's ability to track and detect activities performed by the users in their\nhome. Despite the continuous progress in the area of activity recognition in\nsmart homes, many systems make a strong underlying assumption that the number\nof occupants in the home at any given moment of time is always known.\nEstimating the number of persons in a Smart Home at each time step remains a\nchallenge nowadays. Indeed, unlike most (crowd) counting solution which are\nbased on computer vision techniques, the sensors considered in a Smart Home are\noften very simple and do not offer individually a good overview of the\nsituation. The data gathered needs therefore to be fused in order to infer\nuseful information. This paper aims at addressing this challenge and presents a\nprobabilistic approach able to estimate the number of persons in the\nenvironment at each time step. This approach works in two steps: first, an\nestimate of the number of persons present in the environment is done using a\nConstraint Satisfaction Problem solver, based on the topology of the sensor\nnetwork and the sensor activation pattern at this time point. Then, a Hidden\nMarkov Model refines this estimate by considering the uncertainty related to\nthe sensors. Using both simulated and real data, our method has been tested and\nvalidated on two smart homes of different sizes and configuration and\ndemonstrates the ability to accurately estimate the number of inhabitants.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 15:41:15 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Renoux", "Jennifer", ""], ["K\u00f6ckemann", "Uwe", ""], ["Loutfi", "Amy", ""]]}, {"id": "2003.06404", "submitter": "Ardi Tampuu", "authors": "Ardi Tampuu, Maksym Semikin, Naveed Muhammad, Dmytro Fishman and\n  Tambet Matiisen", "title": "A Survey of End-to-End Driving: Architectures and Training Methods", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2020", "doi": "10.1109/TNNLS.2020.3043505", "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving is of great interest to industry and academia alike. The\nuse of machine learning approaches for autonomous driving has long been\nstudied, but mostly in the context of perception. In this paper we take a\ndeeper look on the so called end-to-end approaches for autonomous driving,\nwhere the entire driving pipeline is replaced with a single neural network. We\nreview the learning methods, input and output modalities, network architectures\nand evaluation schemes in end-to-end driving literature. Interpretability and\nsafety are discussed separately, as they remain challenging for this approach.\nBeyond providing a comprehensive overview of existing methods, we conclude the\nreview with an architecture that combines the most promising elements of the\nend-to-end autonomous driving systems.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 17:42:58 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 13:55:45 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Tampuu", "Ardi", ""], ["Semikin", "Maksym", ""], ["Muhammad", "Naveed", ""], ["Fishman", "Dmytro", ""], ["Matiisen", "Tambet", ""]]}, {"id": "2003.06417", "submitter": "Deepak Pathak", "authors": "Scott Emmons, Ajay Jain, Michael Laskin, Thanard Kurutach, Pieter\n  Abbeel, Deepak Pathak", "title": "Sparse Graphical Memory for Robust Planning", "comments": "Accepted at NeurIPS 2020. Video and code at\n  https://mishalaskin.github.io/sgm/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To operate effectively in the real world, agents should be able to act from\nhigh-dimensional raw sensory input such as images and achieve diverse goals\nacross long time-horizons. Current deep reinforcement and imitation learning\nmethods can learn directly from high-dimensional inputs but do not scale well\nto long-horizon tasks. In contrast, classical graphical methods like A* search\nare able to solve long-horizon tasks, but assume that the state space is\nabstracted away from raw sensory input. Recent works have attempted to combine\nthe strengths of deep learning and classical planning; however, dominant\nmethods in this domain are still quite brittle and scale poorly with the size\nof the environment. We introduce Sparse Graphical Memory (SGM), a new data\nstructure that stores states and feasible transitions in a sparse memory. SGM\naggregates states according to a novel two-way consistency objective, adapting\nclassic state aggregation criteria to goal-conditioned RL: two states are\nredundant when they are interchangeable both as goals and as starting states.\nTheoretically, we prove that merging nodes according to two-way consistency\nleads to an increase in shortest path lengths that scales only linearly with\nthe merging threshold. Experimentally, we show that SGM significantly\noutperforms current state of the art methods on long horizon, sparse-reward\nvisual navigation tasks. Project video and code are available at\nhttps://mishalaskin.github.io/sgm/\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 17:59:32 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 18:55:04 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 21:37:49 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Emmons", "Scott", ""], ["Jain", "Ajay", ""], ["Laskin", "Michael", ""], ["Kurutach", "Thanard", ""], ["Abbeel", "Pieter", ""], ["Pathak", "Deepak", ""]]}, {"id": "2003.06423", "submitter": "Divyam Aggarwal", "authors": "Divyam Aggarwal, Dhish Kumar Saxena, Thomas B\\\"ack, Michael Emmerich", "title": "On Initializing Airline Crew Pairing Optimization for Large-scale\n  Complex Flight Networks", "comments": "17 pages, 9 figures, manuscript submitted for review in a refereed\n  journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.CO math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Crew pairing optimization (CPO) is critically important for any airline,\nsince its crew operating costs are second-largest, next to the fuel-cost. CPO\naims at generating a set of flight sequences (crew pairings) covering a\nflight-schedule, at minimum-cost, while satisfying several legality\nconstraints. For large-scale complex flight networks, billion-plus legal\npairings (variables) are possible, rendering their offline enumeration\nintractable and an exhaustive search for their minimum-cost full\nflight-coverage subset impractical. Even generating an initial feasible\nsolution (IFS: a manageable set of legal pairings covering all flights), which\ncould be subsequently optimized is a difficult (NP-complete) problem. Though,\nas part of a larger project the authors have developed a crew pairing optimizer\n(AirCROP), this paper dedicatedly focuses on IFS-generation through a novel\nheuristic based on divide-and-cover strategy and Integer Programming. For\nreal-world large and complex flight network datasets (including over 3200\nflights and 15 crew bases) provided by GE Aviation, the proposed heuristic\nshows upto a ten-fold speed improvement over another state-of-the-art approach.\nUnprecedentedly, this paper presents an empirical investigation of the impact\nof IFS-cost on the final (optimized) solution-cost, revealing that too low an\nIFS-cost does not necessarily imply faster convergence for AirCROP or even\nlower cost for the optimized solution.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 08:21:38 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Aggarwal", "Divyam", ""], ["Saxena", "Dhish Kumar", ""], ["B\u00e4ck", "Thomas", ""], ["Emmerich", "Michael", ""]]}, {"id": "2003.06474", "submitter": "Luchen Li", "authors": "Luchen Li, Ignacio Albert-Smet, and Aldo A. Faisal", "title": "Optimizing Medical Treatment for Sepsis in Intensive Care: from\n  Reinforcement Learning to Pre-Trial Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our aim is to establish a framework where reinforcement learning (RL) of\noptimizing interventions retrospectively allows us a regulatory compliant\npathway to prospective clinical testing of the learned policies in a clinical\ndeployment. We focus on infections in intensive care units which are one of the\nmajor causes of death and difficult to treat because of the complex and opaque\npatient dynamics, and the clinically debated, highly-divergent set of\nintervention policies required by each individual patient, yet intensive care\nunits are naturally data rich. In our work, we build on RL approaches in\nhealthcare (\"AI Clinicians\"), and learn off-policy continuous dosing policy of\npharmaceuticals for sepsis treatment using historical intensive care data under\npartially observable MDPs (POMDPs). POMPDs capture uncertainty in patient state\nbetter by taking in all historical information, yielding an efficient\nrepresentation, which we investigate through ablations. We compensate for the\nlack of exploration in our retrospective data by evaluating each encountered\nstate with a best-first tree search. We mitigate state distributional shift by\noptimizing our policy in the vicinity of the clinicians' compound policy.\nCrucially, we evaluate our model recommendations using not only conventional\npolicy evaluations but a novel framework that incorporates human experts: a\nmodel-agnostic pre-clinical evaluation method to estimate the accuracy and\nuncertainty of clinician's decisions versus our system recommendations when\nconfronted with the same individual patient history (\"shadow mode\").\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 20:31:47 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 19:42:46 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Li", "Luchen", ""], ["Albert-Smet", "Ignacio", ""], ["Faisal", "Aldo A.", ""]]}, {"id": "2003.06492", "submitter": "Renyan Feng", "authors": "Renyan Feng, Erman Acar, Stefan Schlobach, Yisong Wang, Wanwei Liu", "title": "On Sufficient and Necessary Conditions in Bounded CTL: A Forgetting\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation Tree Logic (CTL) is one of the central formalisms in formal\nverification. As a specification language, it is used to express a property\nthat the system at hand is expected to satisfy. From both the verification and\nthe system design points of view, some information content of such property\nmight become irrelevant for the system due to various reasons, e.g., it might\nbecome obsolete by time, or perhaps infeasible due to practical difficulties.\nThen, the problem arises on how to subtract such piece of information without\naltering the relevant system behaviour or violating the existing specifications\nover a given signature. Moreover, in such a scenario, two crucial notions are\ninformative: the strongest necessary condition (SNC) and the weakest sufficient\ncondition (WSC) of a given property. To address such a scenario in a principled\nway, we introduce a forgetting-based approach in CTL and show that it can be\nused to compute SNC and WSC of a property under a given model and over a given\nsignature. We study its theoretical properties and also show that our notion of\nforgetting satisfies existing essential postulates of knowledge forgetting.\nFurthermore, we analyse the computational complexity of some basic reasoning\ntasks for the fragment CTL_AF in particular.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 21:51:59 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 08:26:45 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 13:44:36 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Feng", "Renyan", ""], ["Acar", "Erman", ""], ["Schlobach", "Stefan", ""], ["Wang", "Yisong", ""], ["Liu", "Wanwei", ""]]}, {"id": "2003.06499", "submitter": "Hadi Abdi Khojasteh", "authors": "Hadi Abdi Khojasteh, Ebrahim Ansari, Mahdi Bohlouli", "title": "LSCP: Enhanced Large Scale Colloquial Persian Language Understanding", "comments": "6 pages, 2 figures, 3 tables, Accepted at the 12th International\n  Conference on Language Resources and Evaluation (LREC 2020)", "journal-ref": "https://www.aclweb.org/anthology/2020.lrec-1.776/", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language recognition has been significantly advanced in recent years by means\nof modern machine learning methods such as deep learning and benchmarks with\nrich annotations. However, research is still limited in low-resource formal\nlanguages. This consists of a significant gap in describing the colloquial\nlanguage especially for low-resourced ones such as Persian. In order to target\nthis gap for low resource languages, we propose a \"Large Scale Colloquial\nPersian Dataset\" (LSCP). LSCP is hierarchically organized in a semantic\ntaxonomy that focuses on multi-task informal Persian language understanding as\na comprehensive problem. This encompasses the recognition of multiple semantic\naspects in the human-level sentences, which naturally captures from the\nreal-world sentences. We believe that further investigations and processing, as\nwell as the application of novel algorithms and methods, can strengthen\nenriching computerized understanding and processing of low resource languages.\nThe proposed corpus consists of 120M sentences resulted from 27M tweets\nannotated with parsing tree, part-of-speech tags, sentiment polarity and\ntranslation in five different languages.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 22:24:14 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Khojasteh", "Hadi Abdi", ""], ["Ansari", "Ebrahim", ""], ["Bohlouli", "Mahdi", ""]]}, {"id": "2003.06507", "submitter": "Gabriel Lima", "authors": "Gabriel Lima, Meeyoung Cha, Chihyung Jeon, Kyungsin Park", "title": "The Punishment Gap: The Infeasible Public Attribution of Punishment to\n  AI and Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper revisits the debate around the legal personhood of AI and robots,\nwhich has been highly sensitive yet important in the face of broad adoption of\nautonomous and self-learning systems. We conducted a survey ($N$=3,315) to\nunderstand lay people's perceptions of this topic and analyzed how they would\nassign responsibility, awareness, and punishment to AI, robots, humans, and\nvarious entities that could be held liable under existing doctrines. Even\nthough people did not recognize any mental state for automated agents, they\nstill attributed punishment and responsibility to these entities. While the\nparticipants mostly agreed AI systems could be reformed given punishment, they\ndid not believe such punishment would achieve its retributive and deterrence\nfunctions. Moreover, participants were also unwilling to grant automated agents\nessential punishment preconditions, namely physical independence or assets. We\nterm this contradiction the punishment gap. We also observe the same punishment\ngap on a demographically representative sample of U.S. residents ($N$=244). We\ndiscuss implications of these findings for how legal and social decisions could\ninfluence how the public attributes responsibility and punishment to automated\nagents.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 23:19:58 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 02:55:49 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Lima", "Gabriel", ""], ["Cha", "Meeyoung", ""], ["Jeon", "Chihyung", ""], ["Park", "Kyungsin", ""]]}, {"id": "2003.06530", "submitter": "David Pastor-Escuredo", "authors": "David Pastor-Escuredo", "title": "Ethics in the digital era", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Ethics is an ancient matter for human kind, from the origin of civilizations\nethics have been related with the most relevant human concerns and determined\ncultures. Ethics was initially related to religion, politics and philosophy to\nthen be fragmented into specific communities of practice. The undergoing\ndigital revolution enabled by Artificial Intelligence and Data are bringing\nethical wicked problems in the social application of these technologies.\nHowever, a broader perspective is also necessary. We now face global and highly\ndynamics challenges that affect groups and individuals, specially those that\nare most vulnerable. Individual-oriented ethics are no longer sufficient, the\nnew ethic has to consider the several scales in which the current complex\nsociety is organized and the interconnections between different systems. Ethics\nshould also give a response to the systemic changes in behavior produced by\nexternal factors and threats. Furthermore, AI and digital technologies are\nglobal and make us more connected and smart but also more homogeneous,\npredictable and ultimately controllable. Ethic must take a stand to preserve\nand keep promoting individuals rights and uniqueness and cultural\nheterogeneity. Digital technologies have to the foundation for new models of\nsociety and help ensure ethical individual and collective values. For these\nreasons science has to be at the core of the new ethic as it helps understand\nthe complex world. Finally, AI has advanced through the ambition to humanize\nmatter, so we should expect ethics to give a response to the future status of\nmachines and their interactions with humans.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 01:32:11 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 21:06:07 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 03:27:08 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Pastor-Escuredo", "David", ""]]}, {"id": "2003.06551", "submitter": "Hadi Mansourifar", "authors": "Hadi Mansourifar, Lin Chen, Weidong Shi", "title": "Hybrid Cryptocurrency Pump and Dump Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly growing Cryptocurrency markets have become a hive for scammers\nto run pump and dump schemes which is considered as an anomalous activity in\nexchange markets. Anomaly detection in time series is challenging since\nexisting methods are not sufficient to detect the anomalies in all contexts. In\nthis paper, we propose a novel hybrid pump and dump detection method based on\ndistance and density metrics. First, we propose a novel automatic thresh-old\nsetting method for distance-based anomaly detection. Second, we propose a novel\nmetric called density score for density-based anomaly detection. Finally, we\nexploit the combination of density and distance metrics successfully as a\nhybrid approach. Our experiments show that, the proposed hybrid approach is\nreliable to detect the majority of alleged P & D activities in top ranked\nexchange pairs by outperforming both density-based and distance-based methods.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 04:38:01 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Mansourifar", "Hadi", ""], ["Chen", "Lin", ""], ["Shi", "Weidong", ""]]}, {"id": "2003.06592", "submitter": "Vladimir Ivashkin", "authors": "Vladimir Ivashkin", "title": "Image-to-image Neural Network for Addition and Subtraction of a Pair of\n  Not Very Large Numbers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Looking back at the history of calculators, one can see that they become less\nfunctional and more computationally expensive over time. A modern calculator\nruns on a personal computer and is drawn at 60 fps only to help us click a few\ndigits with a mouse pointer. A search engine is often used as a calculator,\nwhich means that nowadays we need the Internet just to add two numbers. In this\npaper, we propose to go further and train a convolutional neural network that\ntakes an image of a simple mathematical expression and generates an image of an\nanswer. This neural calculator works only with pairs of double-digit numbers\nand supports only addition and subtraction. Also, sometimes it makes mistakes.\nWe promise that the proposed calculator is a small step for man, but one giant\nleap for mankind.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 09:59:17 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Ivashkin", "Vladimir", ""]]}, {"id": "2003.06617", "submitter": "Ivars Dzalbs Mr", "authors": "Ivars Dzalbs, Tatiana Kalganova, Ian Dear", "title": "Imperialist Competitive Algorithm with Independence and Constrained\n  Assimilation for Solving 0-1 Multidimensional Knapsack Problem", "comments": "PPSN2020 Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multidimensional knapsack problem is a well-known constrained\noptimization problem with many real-world engineering applications. In order to\nsolve this NP-hard problem, a new modified Imperialist Competitive Algorithm\nwith Constrained Assimilation (ICAwICA) is presented. The proposed algorithm\nintroduces the concept of colony independence, a free will to choose between\nclassical ICA assimilation to empires imperialist or any other imperialist in\nthe population. Furthermore, a constrained assimilation process has been\nimplemented that combines classical ICA assimilation and revolution operators,\nwhile maintaining population diversity. This work investigates the performance\nof the proposed algorithm across 101 Multidimensional Knapsack Problem (MKP)\nbenchmark instances. Experimental results show that the algorithm is able to\nobtain an optimal solution in all small instances and presents very competitive\nresults for large MKP instances.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 12:19:31 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Dzalbs", "Ivars", ""], ["Kalganova", "Tatiana", ""], ["Dear", "Ian", ""]]}, {"id": "2003.06649", "submitter": "Nadjib Lazaar Dr", "authors": "Christian Bessiere, Clement Carbonnel, Anton Dries, Emmanuel Hebrard,\n  George Katsirelos, Nadjib Lazaar, Nina Narodytska, Claude-Guy Quimper, Kostas\n  Stergiou, Dimosthenis C. Tsouros, Toby Walsh", "title": "Partial Queries for Constraint Acquisition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning constraint networks is known to require a number of membership\nqueries exponential in the number of variables. In this paper, we learn\nconstraint networks by asking the user partial queries. That is, we ask the\nuser to classify assignments to subsets of the variables as positive or\nnegative. We provide an algorithm, called QUACQ, that, given a negative\nexample, focuses onto a constraint of the target network in a number of queries\nlogarithmic in the size of the example. The whole constraint network can then\nbe learned with a polynomial number of partial queries. We give information\ntheoretic lower bounds for learning some simple classes of constraint networks\nand show that our generic algorithm is optimal in some cases.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 14:43:45 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Bessiere", "Christian", ""], ["Carbonnel", "Clement", ""], ["Dries", "Anton", ""], ["Hebrard", "Emmanuel", ""], ["Katsirelos", "George", ""], ["Lazaar", "Nadjib", ""], ["Narodytska", "Nina", ""], ["Quimper", "Claude-Guy", ""], ["Stergiou", "Kostas", ""], ["Tsouros", "Dimosthenis C.", ""], ["Walsh", "Toby", ""]]}, {"id": "2003.06658", "submitter": "Ning Shi", "authors": "Ning Shi", "title": "Synonymous Generalization in Sequence-to-Sequence Recurrent Networks", "comments": "7 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When learning a language, people can quickly expand their understanding of\nthe unknown content by using compositional skills, such as from two words \"go\"\nand \"fast\" to a new phrase \"go fast.\" In recent work of Lake and Baroni (2017),\nmodern Sequence-to-Sequence(seq2seq) Recurrent Neural Networks (RNNs) can make\npowerful zero-shot generalizations in specifically controlled experiments.\nHowever, there is a missing regarding the property of such strong\ngeneralization and its precise requirements. This paper explores this positive\nresult in detail and defines this pattern as the synonymous generalization, an\nability to recognize an unknown sequence by decomposing the difference between\nit and a known sequence as corresponding existing synonyms. To better\ninvestigate it, I introduce a new environment called Colorful Extended Cleanup\nWorld (CECW), which consists of complex commands paired with logical\nexpressions. While demonstrating that sequential RNNs can perform synonymous\ngeneralizations on foreign commands, I conclude their prerequisites for\nsuccess. I also propose a data augmentation method, which is successfully\nverified on the Geoquery (GEO) dataset, as a novel application of synonymous\ngeneralization for real cases.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 15:27:29 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 15:59:26 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Shi", "Ning", ""]]}, {"id": "2003.06695", "submitter": "Mojtaba Noghabaei", "authors": "Gilmarie O'Neill, Matthew Ball, Yujing Liu, Mojtaba Noghabaei, and\n  Kevin Han", "title": "Toward Automated Virtual Assembly for Prefabricated Construction:\n  Construction Sequencing through Simulated BIM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To adhere to the stringent time and budget requirements of construction\nprojects, contractors are utilizing prefabricated construction methods to\nexpedite the construction process. Prefabricated construction methods require\nan adequate schedule and understanding by the contractors and constructors to\nbe successful. The specificity of prefabricated construction often leads to\ninefficient scheduling and costly rework time. The designer, contractor, and\nconstructors must have a strong understanding of the assembly process to\nexperience the full benefits of the method. At the root of understanding the\nassembly process is visualizing how the process is intended to be performed.\nCurrently, a virtual construction model is used to explain and better visualize\nthe construction process. However, creating a virtual construction model is\ncurrently time consuming and requires experienced personnel. The proposed\nsimulation of the virtual assembly will increase the automation of virtual\nconstruction modeling by implementing the data available in a building\ninformation modeling (BIM) model. This paper presents various factors (i.e.,\nformalization of construction sequence based on the level of development (LOD))\nthat needs to be addressed for the development of automated virtual assembly.\nTwo case studies are presented to demonstrate these factors.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 20:17:33 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["O'Neill", "Gilmarie", ""], ["Ball", "Matthew", ""], ["Liu", "Yujing", ""], ["Noghabaei", "Mojtaba", ""], ["Han", "Kevin", ""]]}, {"id": "2003.06709", "submitter": "Bei Peng", "authors": "Bei Peng, Tabish Rashid, Christian A. Schroeder de Witt,\n  Pierre-Alexandre Kamienny, Philip H. S. Torr, Wendelin B\\\"ohmer, Shimon\n  Whiteson", "title": "FACMAC: Factored Multi-Agent Centralised Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose FACtored Multi-Agent Centralised policy gradients (FACMAC), a new\nmethod for cooperative multi-agent reinforcement learning in both discrete and\ncontinuous action spaces. Like MADDPG, a popular multi-agent actor-critic\nmethod, our approach uses deep deterministic policy gradients to learn\npolicies. However, FACMAC learns a centralised but factored critic, which\ncombines per-agent utilities into the joint action-value function via a\nnon-linear monotonic function, as in QMIX, a popular multi-agent Q-learning\nalgorithm. However, unlike QMIX, there are no inherent constraints on factoring\nthe critic. We thus also employ a nonmonotonic factorisation and empirically\ndemonstrate that its increased representational capacity allows it to solve\nsome tasks that cannot be solved with monolithic, or monotonically factored\ncritics. In addition, FACMAC uses a centralised policy gradient estimator that\noptimises over the entire joint action space, rather than optimising over each\nagent's action space separately as in MADDPG. This allows for more coordinated\npolicy changes and fully reaps the benefits of a centralised critic. We\nevaluate FACMAC on variants of the multi-agent particle environments, a novel\nmulti-agent MuJoCo benchmark, and a challenging set of StarCraft II\nmicromanagement tasks. Empirical results demonstrate FACMAC's superior\nperformance over MADDPG and other baselines on all three domains.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 21:29:09 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 14:24:57 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 05:32:55 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 21:02:07 GMT"}, {"version": "v5", "created": "Fri, 7 May 2021 14:03:40 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Peng", "Bei", ""], ["Rashid", "Tabish", ""], ["de Witt", "Christian A. Schroeder", ""], ["Kamienny", "Pierre-Alexandre", ""], ["Torr", "Philip H. S.", ""], ["B\u00f6hmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2003.06858", "submitter": "Nguyen Thi Thanh Thuy", "authors": "Nguyen Thi Thanh Thuy, Ngo Xuan Bach, Tu Minh Phuong", "title": "Leveraging Foreign Language Labeled Data for Aspect-Based Opinion Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-based opinion mining is the task of identifying sentiment at the\naspect level in opinionated text, which consists of two subtasks: aspect\ncategory extraction and sentiment polarity classification. While aspect\ncategory extraction aims to detect and categorize opinion targets such as\nproduct features, sentiment polarity classification assigns a sentiment label,\ni.e. positive, negative, or neutral, to each identified aspect. Supervised\nlearning methods have been shown to deliver better accuracy for this task but\nthey require labeled data, which is costly to obtain, especially for\nresource-poor languages like Vietnamese. To address this problem, we present a\nsupervised aspect-based opinion mining method that utilizes labeled data from a\nforeign language (English in this case), which is translated to Vietnamese by\nan automated translation tool (Google Translate). Because aspects and opinions\nin different languages may be expressed by different words, we propose using\nword embeddings, in addition to other features, to reduce the vocabulary\ndifference between the original and translated texts, thus improving the\neffectiveness of aspect category extraction and sentiment polarity\nclassification processes. We also introduce an annotated corpus of aspect\ncategories and sentiment polarities extracted from restaurant reviews in\nVietnamese, and conduct a series of experiments on the corpus. Experimental\nresults demonstrate the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 15:53:53 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Thuy", "Nguyen Thi Thanh", ""], ["Bach", "Ngo Xuan", ""], ["Phuong", "Tu Minh", ""]]}, {"id": "2003.06868", "submitter": "Maximilian Schleich", "authors": "Leopoldo Bertossi, Jordan Li, Maximilian Schleich, Dan Suciu,\n  Zografoula Vagena", "title": "Causality-based Explanation of Classification Outcomes", "comments": "16 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple definition of an explanation for the outcome of a\nclassifier based on concepts from causality. We compare it with previously\nproposed notions of explanation, and study their complexity. We conduct an\nexperimental evaluation with two real datasets from the financial domain.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 17:00:37 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 04:24:18 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Bertossi", "Leopoldo", ""], ["Li", "Jordan", ""], ["Schleich", "Maximilian", ""], ["Suciu", "Dan", ""], ["Vagena", "Zografoula", ""]]}, {"id": "2003.06898", "submitter": "Fei Feng Ms.", "authors": "Fei Feng, Ruosong Wang, Wotao Yin, Simon S. Du, Lin F. Yang", "title": "Provably Efficient Exploration for Reinforcement Learning Using\n  Unsupervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the prevailing paradigm of using unsupervised learning for\nefficient exploration in reinforcement learning (RL) problems\n[tang2017exploration,bellemare2016unifying], we investigate when this paradigm\nis provably efficient. We study episodic Markov decision processes with rich\nobservations generated from a small number of latent states. We present a\ngeneral algorithmic framework that is built upon two components: an\nunsupervised learning algorithm and a no-regret tabular RL algorithm.\nTheoretically, we prove that as long as the unsupervised learning algorithm\nenjoys a polynomial sample complexity guarantee, we can find a near-optimal\npolicy with sample complexity polynomial in the number of latent states, which\nis significantly smaller than the number of observations. Empirically, we\ninstantiate our framework on a class of hard exploration problems to\ndemonstrate the practicality of our theory.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 19:23:59 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 18:17:18 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 23:48:01 GMT"}, {"version": "v4", "created": "Tue, 1 Dec 2020 01:04:54 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Feng", "Fei", ""], ["Wang", "Ruosong", ""], ["Yin", "Wotao", ""], ["Du", "Simon S.", ""], ["Yang", "Lin F.", ""]]}, {"id": "2003.06906", "submitter": "Rose Wang", "authors": "Rose E. Wang, J. Chase Kew, Dennis Lee, Tsang-Wei Edward Lee, Tingnan\n  Zhang, Brian Ichter, Jie Tan, Aleksandra Faust", "title": "Model-based Reinforcement Learning for Decentralized Multiagent\n  Rendezvous", "comments": "CoRL 2020. The video is available at: https://youtu.be/-ydXHUtPzWE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Collaboration requires agents to align their goals on the fly. Underlying the\nhuman ability to align goals with other agents is their ability to predict the\nintentions of others and actively update their own plans. We propose\nhierarchical predictive planning (HPP), a model-based reinforcement learning\nmethod for decentralized multiagent rendezvous. Starting with pretrained,\nsingle-agent point to point navigation policies and using noisy,\nhigh-dimensional sensor inputs like lidar, we first learn via self-supervision\nmotion predictions of all agents on the team. Next, HPP uses the prediction\nmodels to propose and evaluate navigation subgoals for completing the\nrendezvous task without explicit communication among agents. We evaluate HPP in\na suite of unseen environments, with increasing complexity and numbers of\nobstacles. We show that HPP outperforms alternative reinforcement learning,\npath planning, and heuristic-based baselines on challenging, unseen\nenvironments. Experiments in the real world demonstrate successful transfer of\nthe prediction models from sim to real world without any additional\nfine-tuning. Altogether, HPP removes the need for a centralized operator in\nmultiagent systems by combining model-based RL and inference methods, enabling\nagents to dynamically align plans.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 19:49:20 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 05:34:13 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Wang", "Rose E.", ""], ["Kew", "J. Chase", ""], ["Lee", "Dennis", ""], ["Lee", "Tsang-Wei Edward", ""], ["Zhang", "Tingnan", ""], ["Ichter", "Brian", ""], ["Tan", "Jie", ""], ["Faust", "Aleksandra", ""]]}, {"id": "2003.06920", "submitter": "Boris Ruf", "authors": "Boris Ruf, Chaouki Boutharouite, Marcin Detyniecki", "title": "Getting Fairness Right: Towards a Toolbox for Practitioners", "comments": "Accepted at the Workshop on Fair and Responsible AI at CHI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential risk of AI systems unintentionally embedding and reproducing\nbias has attracted the attention of machine learning practitioners and society\nat large. As policy makers are willing to set the standards of algorithms and\nAI techniques, the issue on how to refine existing regulation, in order to\nenforce that decisions made by automated systems are fair and\nnon-discriminatory, is again critical. Meanwhile, researchers have demonstrated\nthat the various existing metrics for fairness are statistically mutually\nexclusive and the right choice mostly depends on the use case and the\ndefinition of fairness.\n  Recognizing that the solutions for implementing fair AI are not purely\nmathematical but require the commitments of the stakeholders to define the\ndesired nature of fairness, this paper proposes to draft a toolbox which helps\npractitioners to ensure fair AI practices. Based on the nature of the\napplication and the available training data, but also on legal requirements and\nethical, philosophical and cultural dimensions, the toolbox aims to identify\nthe most appropriate fairness objective. This approach attempts to structure\nthe complex landscape of fairness metrics and, therefore, makes the different\navailable options more accessible to non-technical people. In the proven\nabsence of a silver bullet solution for fair AI, this toolbox intends to\nproduce the fairest AI systems possible with respect to their local context.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 20:53:50 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Ruf", "Boris", ""], ["Boutharouite", "Chaouki", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2003.07019", "submitter": "Manikandan Ravikiran", "authors": "Manikandan Ravikiran", "title": "Key Phrase Classification in Complex Assignments", "comments": "v1 preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Complex assignments typically consist of open-ended questions with large and\ndiverse content in the context of both classroom and online graduate programs.\nWith the sheer scale of these programs comes a variety of problems in peer and\nexpert feedback, including rogue reviews. As such with the hope of identifying\nimportant contents needed for the review, in this work we present a very first\nwork on key phrase classification with a detailed empirical study on\ntraditional and most recent language modeling approaches. From this study, we\nfind that the task of classification of key phrases is ambiguous at a human\nlevel producing Cohen's kappa of 0.77 on a new data set. Both pretrained\nlanguage models and simple TFIDF SVM classifiers produce similar results with a\nformer producing average of 0.6 F1 higher than the latter. We finally derive\npractical advice from our extensive empirical and model interpretability\nresults for those interested in key phrase classification from educational\nreports in the future.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 04:25:37 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Ravikiran", "Manikandan", ""]]}, {"id": "2003.07037", "submitter": "Meng Chen", "authors": "Meng Chen, Yang Liu, Xiaohui Yu", "title": "NLPMM: a Next Location Predictor with Markov Modeling", "comments": null, "journal-ref": "Pacific-Asia Conference on Knowledge Discovery and Data Mining,\n  186-197, 2014", "doi": "10.1007/978-3-319-06605-9_16", "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we solve the problem of predicting the next locations of the\nmoving objects with a historical dataset of trajectories. We present a Next\nLocation Predictor with Markov Modeling (NLPMM) which has the following\nadvantages: (1) it considers both individual and collective movement patterns\nin making prediction, (2) it is effective even when the trajectory data is\nsparse, (3) it considers the time factor and builds models that are suited to\ndifferent time periods. We have conducted extensive experiments in a real\ndataset, and the results demonstrate the superiority of NLPMM over existing\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 05:48:41 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Chen", "Meng", ""], ["Liu", "Yang", ""], ["Yu", "Xiaohui", ""]]}, {"id": "2003.07060", "submitter": "Mithun Chakraborty", "authors": "Nawal Benabbou, Mithun Chakraborty, Ayumi Igarashi, Yair Zick", "title": "Finding Fair and Efficient Allocations When Valuations Don't Add Up", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-57980-7_3", "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present new results on the fair and efficient allocation of\nindivisible goods to agents whose preferences correspond to {\\em matroid rank\nfunctions}. This is a versatile valuation class with several desirable\nproperties (such as monotonicity and submodularity), which naturally lends\nitself to a number of real-world domains. We use these properties to our\nadvantage; first, we show that when agent valuations are matroid rank\nfunctions, a socially optimal (i.e. utilitarian social welfare-maximizing)\nallocation that achieves envy-freeness up to one item (EF1) exists and is\ncomputationally tractable. We also prove that the Nash welfare-maximizing and\nthe leximin allocations both exhibit this fairness/efficiency combination, by\nshowing that they can be achieved by minimizing any symmetric strictly convex\nfunction over utilitarian optimal outcomes. To the best of our knowledge, this\nis the first valuation function class not subsumed by additive valuations for\nwhich it has been established that an allocation maximizing Nash welfare is\nEF1. Moreover, for a subclass of these valuation functions based on maximum\n(unweighted) bipartite matching, we show that a leximin allocation can be\ncomputed in polynomial time. Additionally, we explore possible extensions of\nour results to fairness criteria other than EF1 as well as to generalizations\nof the above valuation classes.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 07:42:27 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 03:16:39 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 05:35:19 GMT"}, {"version": "v4", "created": "Fri, 18 Jun 2021 05:21:10 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Benabbou", "Nawal", ""], ["Chakraborty", "Mithun", ""], ["Igarashi", "Ayumi", ""], ["Zick", "Yair", ""]]}, {"id": "2003.07096", "submitter": "Ahmed Maalel Dr", "authors": "Ahmed Maalel and Henda Ben Gh\\'ezala", "title": "Towards a Collaborative Approach to Decision Making Based on Ontology\n  and Multi-Agent System Application to crisis management", "comments": "6 pages, 4 figures", "journal-ref": "Procedia Computer Science 164 193,198 (2019)", "doi": "10.1016/j.procs.2019.12.172", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coordination and cooperation of all the stakeholders involved is a\ndecisive point for the control and the resolution of problems. In the\ninsecurity events, the resolution should refer to a plan that defines a general\nframework of the procedures to be undertaken and the instructions to be\ncomplied with; also, a more precise process must be defined by the actors to\ndeal with the case represented by the particular problem of the current\nsituation. Indeed, this process has to cope with a dynamic, unstable and\nunpredictable environment, due to the heterogeneity and multiplicity of\nstakeholders, and finally due to their possible geographical distribution. In\nthis article, we will present the first steps of validation of a collaborative\ndecision-making approach in the context of crisis situations such as road\naccidents. This approach is based on ontologies and multi-agent systems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 10:17:04 GMT"}], "update_date": "2020-06-14", "authors_parsed": [["Maalel", "Ahmed", ""], ["Gh\u00e9zala", "Henda Ben", ""]]}, {"id": "2003.07108", "submitter": "Fatih Semiz", "authors": "Fatih Semiz and Faruk Polat", "title": "A Job-Assignment Heuristic for Lifelong Multi-Agent Path Finding Problem\n  with Multiple Delivery Locations", "comments": "This paper has been withdrawn by the authors due to need for heavy\n  revise", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we proposed multiple job-assignment heuristics to generate\nlow-total-cost solutions and determine the best performing method amongst them.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 10:57:13 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 09:14:07 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Semiz", "Fatih", ""], ["Polat", "Faruk", ""]]}, {"id": "2003.07124", "submitter": "Fatih Semiz", "authors": "Fatih Semiz and Faruk Polat", "title": "Solving Area Coverage Problem with UAVs: A Vehicle Routing with Time\n  Windows Variation", "comments": null, "journal-ref": "Robotics and Autonomous Systems, 126, April 2020, 103435", "doi": "10.1016/j.robot.2020.103435", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real life, providing security for a set of large areas by covering the\narea with Unmanned Aerial Vehicles (UAVs) is a difficult problem that consist\nof multiple objectives. These difficulties are even greater if the area\ncoverage must continue throughout a specific time window. We address this by\nconsidering a Vehicle Routing Problem with Time Windows (VRPTW) variation in\nwhich capacity of agents is one and each customer (target area) must be\nsupplied with more than one vehicles simultaneously without violating time\nwindows. In this problem, our aim is to find a way to cover all areas with the\nnecessary number of UAVs during the time windows, minimize the total distance\ntraveled, and provide a fast solution by satisfying the additional constraint\nthat each agent has limited fuel. We present a novel algorithm that relies on\nclustering the target areas according to their time windows, and then\nincrementally generating transportation problems with each cluster and the\nready UAVs. Then we solve transportation problems with the simplex algorithm to\ngenerate the solution. The performance of the proposed algorithm and other\nimplemented algorithms to compare the solution quality is evaluated on example\nscenarios with practical problem sizes.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 11:27:21 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Semiz", "Fatih", ""], ["Polat", "Faruk", ""]]}, {"id": "2003.07182", "submitter": "Vincent Huang", "authors": "Bradley Butcher, Vincent S. Huang, Jeremy Reffin, Sema K. Sgaier,\n  Grace Charles, Novi Quadrianto", "title": "Causal datasheet: An approximate guide to practically assess Bayesian\n  networks in the real world", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.PF stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In solving real-world problems like changing healthcare-seeking behaviors,\ndesigning interventions to improve downstream outcomes requires an\nunderstanding of the causal links within the system. Causal Bayesian Networks\n(BN) have been proposed as one such powerful method. In real-world\napplications, however, confidence in the results of BNs are often moderate at\nbest. This is due in part to the inability to validate against some ground\ntruth, as the DAG is not available. This is especially problematic if the\nlearned DAG conflicts with pre-existing domain doctrine. At the policy level,\none must justify insights generated by such analysis, preferably accompanying\nthem with uncertainty estimation. Here we propose a causal extension to the\ndatasheet concept proposed by Gebru et al (2018) to include approximate BN\nperformance expectations for any given dataset. To generate the results for a\nprototype Causal Datasheet, we constructed over 30,000 synthetic datasets with\nproperties mirroring characteristics of real data. We then recorded the results\ngiven by state-of-the-art structure learning algorithms. These results were\nused to populate the Causal Datasheet, and recommendations were automatically\ngenerated dependent on expected performance. As a proof of concept, we used our\nCausal Datasheet Generation Tool (CDG-T) to assign expected performance\nexpectations to a maternal health survey we conducted in Uttar Pradesh, India.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 23:31:11 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Butcher", "Bradley", ""], ["Huang", "Vincent S.", ""], ["Reffin", "Jeremy", ""], ["Sgaier", "Sema K.", ""], ["Charles", "Grace", ""], ["Quadrianto", "Novi", ""]]}, {"id": "2003.07195", "submitter": "Martin Naya-Varela", "authors": "M.Naya-Varela (1), A. Faina (2) and R. J. Duro (1) ((1) Universidade\n  da Coruna, (2) IT University of Copenhagen)", "title": "An Experiment in Morphological Development for Learning ANN Based\n  Controllers", "comments": "10 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:2003.05817", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Morphological development is part of the way any human or animal learns. The\nlearning processes starts with the morphology at birth and progresses through\nchanging morphologies until adulthood is reached. Biologically, this seems to\nfacilitate learning and make it more robust. However, when this approach is\ntransferred to robotic systems, the results found in the literature are\ninconsistent: morphological development does not provide a learning advantage\nin every case. In fact, it can lead to poorer results than when learning with a\nfixed morphology. In this paper we analyze some of the issues involved by means\nof a simple, but very informative experiment in quadruped walking. From the\nresults obtained an initial series of insights on when and under what\nconditions to apply morphological development for learning are presented.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 14:29:06 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Naya-Varela", "M.", ""], ["Faina", "A.", ""], ["Duro", "R. J.", ""]]}, {"id": "2003.07270", "submitter": "Leila Karimi", "authors": "Leila Karimi, Maryam Aldairi, James Joshi, Mai Abdelhakim", "title": "An Automatic Attribute Based Access Control Policy Extraction from\n  Access Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid advances in computing and information technologies,\ntraditional access control models have become inadequate in terms of capturing\nfine-grained, and expressive security requirements of newly emerging\napplications. An attribute-based access control (ABAC) model provides a more\nflexible approach for addressing the authorization needs of complex and dynamic\nsystems. While organizations are interested in employing newer authorization\nmodels, migrating to such models pose as a significant challenge. Many\nlarge-scale businesses need to grant authorization to their user populations\nthat are potentially distributed across disparate and heterogeneous computing\nenvironments. Each of these computing environments may have its own access\ncontrol model. The manual development of a single policy framework for an\nentire organization is tedious, costly, and error-prone.\n  In this paper, we present a methodology for automatically learning ABAC\npolicy rules from access logs of a system to simplify the policy development\nprocess. The proposed approach employs an unsupervised learning-based algorithm\nfor detecting patterns in access logs and extracting ABAC authorization rules\nfrom these patterns. In addition, we present two policy improvement algorithms,\nincluding rule pruning and policy refinement algorithms to generate a higher\nquality mined policy. Finally, we implement a prototype of the proposed\napproach to demonstrate its feasibility.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 15:08:54 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 15:52:13 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 02:39:33 GMT"}, {"version": "v4", "created": "Sat, 30 Jan 2021 17:43:34 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Karimi", "Leila", ""], ["Aldairi", "Maryam", ""], ["Joshi", "James", ""], ["Abdelhakim", "Mai", ""]]}, {"id": "2003.07278", "submitter": "Qi Liu", "authors": "Qi Liu, Matt J. Kusner, Phil Blunsom", "title": "A Survey on Contextual Embeddings", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual embeddings, such as ELMo and BERT, move beyond global word\nrepresentations like Word2Vec and achieve ground-breaking performance on a wide\nrange of natural language processing tasks. Contextual embeddings assign each\nword a representation based on its context, thereby capturing uses of words\nacross varied contexts and encoding knowledge that transfers across languages.\nIn this survey, we review existing contextual embedding models, cross-lingual\npolyglot pre-training, the application of contextual embeddings in downstream\ntasks, model compression, and model analyses.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 15:22:22 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 10:49:17 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Liu", "Qi", ""], ["Kusner", "Matt J.", ""], ["Blunsom", "Phil", ""]]}, {"id": "2003.07344", "submitter": "Karan Sikka", "authors": "Karan Sikka, Andrew Silberfarb, John Byrnes, Indranil Sur, Ed Chow,\n  Ajay Divakaran, Richard Rohwer", "title": "Deep Adaptive Semantic Logic (DASL): Compiling Declarative Knowledge\n  into Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Deep Adaptive Semantic Logic (DASL), a novel framework for\nautomating the generation of deep neural networks that incorporates\nuser-provided formal knowledge to improve learning from data. We provide formal\nsemantics that demonstrate that our knowledge representation captures all of\nfirst order logic and that finite sampling from infinite domains converges to\ncorrect truth values. DASL's representation improves on prior neural-symbolic\nwork by avoiding vanishing gradients, allowing deeper logical structure, and\nenabling richer interactions between the knowledge and learning components. We\nillustrate DASL through a toy problem in which we add structure to an image\nclassification problem and demonstrate that knowledge of that structure reduces\ndata requirements by a factor of $1000$. We then evaluate DASL on a visual\nrelationship detection task and demonstrate that the addition of commonsense\nknowledge improves performance by $10.7\\%$ in a data scarce setting.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 17:37:25 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Sikka", "Karan", ""], ["Silberfarb", "Andrew", ""], ["Byrnes", "John", ""], ["Sur", "Indranil", ""], ["Chow", "Ed", ""], ["Divakaran", "Ajay", ""], ["Rohwer", "Richard", ""]]}, {"id": "2003.07347", "submitter": "Dave DeCaprio", "authors": "Dave DeCaprio, Joseph Gartner, Thadeus Burgess, Kristian Garcia,\n  Sarthak Kothari, Shaayan Sayed, Carol J. McCall (FSA, MPH)", "title": "Building a COVID-19 Vulnerability Index", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  COVID-19 is an acute respiratory disease that has been classified as a\npandemic by the World Health Organization. Characterization of this disease is\nstill in its early stages. However, it is known to have high mortality rates,\nparticularly among individuals with preexisting medical conditions. Creating\nmodels to identify individuals who are at the greatest risk for severe\ncomplications due to COVID-19 will be useful for outreach campaigns to help\nmitigate the disease's worst effects. While information specific to COVID-19 is\nlimited, a model using complications due to other upper respiratory infections\ncan be used as a proxy to help identify those individuals who are at the\ngreatest risk. We present the results for three models predicting such\ncomplications, with each model increasing predictive effectiveness at the\nexpense of ease of implementation.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 17:50:47 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 14:41:39 GMT"}, {"version": "v3", "created": "Sat, 18 Jul 2020 13:53:24 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["DeCaprio", "Dave", "", "FSA, MPH"], ["Gartner", "Joseph", "", "FSA, MPH"], ["Burgess", "Thadeus", "", "FSA, MPH"], ["Garcia", "Kristian", "", "FSA, MPH"], ["Kothari", "Sarthak", "", "FSA, MPH"], ["Sayed", "Shaayan", "", "FSA, MPH"], ["McCall", "Carol J.", "", "FSA, MPH"]]}, {"id": "2003.07370", "submitter": "Vivian Lai", "authors": "Vivian Lai, Samuel Carton, Chenhao Tan", "title": "Harnessing Explanations to Bridge AI and Humans", "comments": "4 pages, CHI 2020 Fair & Responsible AI Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are increasingly integrated into societally critical\napplications such as recidivism prediction and medical diagnosis, thanks to\ntheir superior predictive power. In these applications, however, full\nautomation is often not desired due to ethical and legal concerns. The research\ncommunity has thus ventured into developing interpretable methods that explain\nmachine predictions. While these explanations are meant to assist humans in\nunderstanding machine predictions and thereby allowing humans to make better\ndecisions, this hypothesis is not supported in many recent studies. To improve\nhuman decision-making with AI assistance, we propose future directions for\nclosing the gap between the efficacy of explanations and improvement in human\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 18:00:02 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Lai", "Vivian", ""], ["Carton", "Samuel", ""], ["Tan", "Chenhao", ""]]}, {"id": "2003.07385", "submitter": "Nikhil Krishnaswamy", "authors": "Nikhil Krishnaswamy and James Pustejovsky", "title": "A Formal Analysis of Multimodal Referring Strategies Under Common Ground", "comments": "9 pages (incl refs), 7 figures, 3 tables, proceedings of LREC 2020\n  (postponed due to COVID-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an analysis of computationally generated\nmixed-modality definite referring expressions using combinations of gesture and\nlinguistic descriptions. In doing so, we expose some striking formal semantic\nproperties of the interactions between gesture and language, conditioned on the\nintroduction of content into the common ground between the (computational)\nspeaker and (human) viewer, and demonstrate how these formal features can\ncontribute to training better models to predict viewer judgment of referring\nexpressions, and potentially to the generation of more natural and informative\nreferring expressions.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 18:08:52 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Krishnaswamy", "Nikhil", ""], ["Pustejovsky", "James", ""]]}, {"id": "2003.07417", "submitter": "Sina Ghiassian", "authors": "Sina Ghiassian, Banafsheh Rafiee, Yat Long Lo, Adam White", "title": "Improving Performance in Reinforcement Learning by Breaking\n  Generalization in Neural Networks", "comments": "10 pages; Accepted to AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning systems require good representations to work well. For\ndecades practical success in reinforcement learning was limited to small\ndomains. Deep reinforcement learning systems, on the other hand, are scalable,\nnot dependent on domain specific prior knowledge and have been successfully\nused to play Atari, in 3D navigation from pixels, and to control high degree of\nfreedom robots. Unfortunately, the performance of deep reinforcement learning\nsystems is sensitive to hyper-parameter settings and architecture choices. Even\nwell tuned systems exhibit significant instability both within a trial and\nacross experiment replications. In practice, significant expertise and trial\nand error are usually required to achieve good performance. One potential\nsource of the problem is known as catastrophic interference: when later\ntraining decreases performance by overriding previous learning. Interestingly,\nthe powerful generalization that makes Neural Networks (NN) so effective in\nbatch supervised learning might explain the challenges when applying them in\nreinforcement learning tasks. In this paper, we explore how online NN training\nand interference interact in reinforcement learning. We find that simply\nre-mapping the input observations to a high-dimensional space improves learning\nspeed and parameter sensitivity. We also show this preprocessing reduces\ninterference in prediction tasks. More practically, we provide a simple\napproach to NN training that is easy to implement, and requires little\nadditional computation. We demonstrate that our approach improves performance\nin both prediction and control with an extensive batch of experiments in\nclassic control domains.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 19:21:08 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Ghiassian", "Sina", ""], ["Rafiee", "Banafsheh", ""], ["Lo", "Yat Long", ""], ["White", "Adam", ""]]}, {"id": "2003.07425", "submitter": "Kayla Boggess", "authors": "Shenghui Chen, Kayla Boggess and Lu Feng", "title": "Towards Transparent Robotic Planning via Contrastive Explanations", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing explanations of chosen robotic actions can help to increase the\ntransparency of robotic planning and improve users' trust. Social sciences\nsuggest that the best explanations are contrastive, explaining not just why one\naction is taken, but why one action is taken instead of another. We formalize\nthe notion of contrastive explanations for robotic planning policies based on\nMarkov decision processes, drawing on insights from the social sciences. We\npresent methods for the automated generation of contrastive explanations with\nthree key factors: selectiveness, constrictiveness, and responsibility. The\nresults of a user study with 100 participants on the Amazon Mechanical Turk\nplatform show that our generated contrastive explanations can help to increase\nusers' understanding and trust of robotic planning policies while reducing\nusers' cognitive burden.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 19:44:31 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Chen", "Shenghui", ""], ["Boggess", "Kayla", ""], ["Feng", "Lu", ""]]}, {"id": "2003.07433", "submitter": "Mohammad Arif Ul Alam", "authors": "Mohammad Arif Ul Alam and Dhawal Kapadia", "title": "LAXARY: A Trustworthy Explainable Twitter Analysis Model for\n  Post-Traumatic Stress Disorder Assessment", "comments": "Accepted in SmartComp 2020 (SmartSys)", "journal-ref": "IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP 2020)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Veteran mental health is a significant national problem as large number of\nveterans are returning from the recent war in Iraq and continued military\npresence in Afghanistan. While significant existing works have investigated\ntwitter posts-based Post Traumatic Stress Disorder (PTSD) assessment using\nblackbox machine learning techniques, these frameworks cannot be trusted by the\nclinicians due to the lack of clinical explainability. To obtain the trust of\nclinicians, we explore the big question, can twitter posts provide enough\ninformation to fill up clinical PTSD assessment surveys that have been\ntraditionally trusted by clinicians? To answer the above question, we propose,\nLAXARY (Linguistic Analysis-based Exaplainable Inquiry) model, a novel\nExplainable Artificial Intelligent (XAI) model to detect and represent PTSD\nassessment of twitter users using a modified Linguistic Inquiry and Word Count\n(LIWC) analysis. First, we employ clinically validated survey tools for\ncollecting clinical PTSD assessment data from real twitter users and develop a\nPTSD Linguistic Dictionary using the PTSD assessment survey results. Then, we\nuse the PTSD Linguistic Dictionary along with machine learning model to fill up\nthe survey tools towards detecting PTSD status and its intensity of\ncorresponding twitter users. Our experimental evaluation on 210 clinically\nvalidated veteran twitter users provides promising accuracies of both PTSD\nclassification and its intensity estimation. We also evaluate our developed\nPTSD Linguistic Dictionary's reliability and validity.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 20:32:24 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 08:12:42 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Alam", "Mohammad Arif Ul", ""], ["Kapadia", "Dhawal", ""]]}, {"id": "2003.07492", "submitter": "Mohammad Arif Ul Alam", "authors": "Mohammad Arif Ul Alam, Nirmalya Roy, Sarah Holmes, Aryya Gangopadhyay,\n  Elizabeth Galik", "title": "AutoCogniSys: IoT Assisted Context-Aware Automatic Cognitive Health\n  Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cognitive impairment has become epidemic in older adult population. The\nrecent advent of tiny wearable and ambient devices, a.k.a Internet of Things\n(IoT) provides ample platforms for continuous functional and cognitive health\nassessment of older adults. In this paper, we design, implement and evaluate\nAutoCogniSys, a context-aware automated cognitive health assessment system,\ncombining the sensing powers of wearable physiological (Electrodermal Activity,\nPhotoplethysmography) and physical (Accelerometer, Object) sensors in\nconjunction with ambient sensors. We design appropriate signal processing and\nmachine learning techniques, and develop an automatic cognitive health\nassessment system in a natural older adults living environment. We validate our\napproaches using two datasets: (i) a naturalistic sensor data streams related\nto Activities of Daily Living and mental arousal of 22 older adults recruited\nin a retirement community center, individually living in their own apartments\nusing a customized inexpensive IoT system (IRB #HP-00064387) and (ii) a\npublicly available dataset for emotion detection. The performance of\nAutoCogniSys attests max. 93\\% of accuracy in assessing cognitive health of\nolder adults.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 01:44:59 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Alam", "Mohammad Arif Ul", ""], ["Roy", "Nirmalya", ""], ["Holmes", "Sarah", ""], ["Gangopadhyay", "Aryya", ""], ["Galik", "Elizabeth", ""]]}, {"id": "2003.07520", "submitter": "Shruthi Chari", "authors": "Shruthi Chari, Daniel M. Gruen, Oshani Seneviratne, Deborah L.\n  McGuinness", "title": "Foundations of Explainable Knowledge-Enabled Systems", "comments": "S. Chari, D. Gruen, O. Seneviratne, D. L. McGuinness, \"Foundations of\n  Explainable Knowledge-Enabled Systems\". In: Ilaria Tiddi, Freddy Lecue,\n  Pascal Hitzler (eds.), Knowledge Graphs for eXplainable AI -- Foundations,\n  Applications and Challenges. Studies on the Semantic Web, IOS Press,\n  Amsterdam, 2020, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explainability has been an important goal since the early days of Artificial\nIntelligence. Several approaches for producing explanations have been\ndeveloped. However, many of these approaches were tightly coupled with the\ncapabilities of the artificial intelligence systems at the time. With the\nproliferation of AI-enabled systems in sometimes critical settings, there is a\nneed for them to be explainable to end-users and decision-makers. We present a\nhistorical overview of explainable artificial intelligence systems, with a\nfocus on knowledge-enabled systems, spanning the expert systems, cognitive\nassistants, semantic applications, and machine learning domains. Additionally,\nborrowing from the strengths of past approaches and identifying gaps needed to\nmake explanations user- and context-focused, we propose new definitions for\nexplanations and explainable knowledge-enabled systems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 04:18:48 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Chari", "Shruthi", ""], ["Gruen", "Daniel M.", ""], ["Seneviratne", "Oshani", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "2003.07523", "submitter": "Shruthi Chari", "authors": "Shruthi Chari, Daniel M. Gruen, Oshani Seneviratne, Deborah L.\n  McGuinness", "title": "Directions for Explainable Knowledge-Enabled Systems", "comments": "S. Chari, D. M. Gruen, O. Seneviratne, D. L. McGuinness, \"Directions\n  for Explainable Knowledge-Enabled Systems\". In: Ilaria Tiddi, Freddy Lecue,\n  Pascal Hitzler (eds.), Knowledge Graphs for eXplainable AI -- Foundations,\n  Applications and Challenges. Studies on the Semantic Web, IOS Press,\n  Amsterdam, 2020, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interest in the field of Explainable Artificial Intelligence has been growing\nfor decades and has accelerated recently. As Artificial Intelligence models\nhave become more complex, and often more opaque, with the incorporation of\ncomplex machine learning techniques, explainability has become more critical.\nRecently, researchers have been investigating and tackling explainability with\na user-centric focus, looking for explanations to consider trustworthiness,\ncomprehensibility, explicit provenance, and context-awareness. In this chapter,\nwe leverage our survey of explanation literature in Artificial Intelligence and\nclosely related fields and use these past efforts to generate a set of\nexplanation types that we feel reflect the expanded needs of explanation for\ntoday's artificial intelligence applications. We define each type and provide\nan example question that would motivate the need for this style of explanation.\nWe believe this set of explanation types will help future system designers in\ntheir generation and prioritization of requirements and further help generate\nexplanations that are better aligned to users' and situational needs.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 04:34:29 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Chari", "Shruthi", ""], ["Gruen", "Daniel M.", ""], ["Seneviratne", "Oshani", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "2003.07596", "submitter": "Tomas Teijeiro", "authors": "Tomas Teijeiro and Paulo Felix", "title": "Construe: a software solution for the explanation-based interpretation\n  of time series", "comments": "Original Software Publication. 10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper presents a software implementation of a general framework for time\nseries interpretation based on abductive reasoning. The software provides a\ndata model and a set of algorithms to make inference to the best explanation of\na time series, resulting in a description in multiple abstraction levels of the\nprocesses underlying the time series. As a proof of concept, a comprehensive\nknowledge base for the electrocardiogram (ECG) domain is provided, so it can be\nused directly as a tool for ECG analysis. This tool has been successfully\nvalidated in several noteworthy problems, such as heartbeat classification or\natrial fibrillation detection.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 09:26:55 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Teijeiro", "Tomas", ""], ["Felix", "Paulo", ""]]}, {"id": "2003.07631", "submitter": "Wojciech Samek", "authors": "Wojciech Samek, Gr\\'egoire Montavon, Sebastian Lapuschkin, Christopher\n  J. Anders, Klaus-Robert M\\\"uller", "title": "Explaining Deep Neural Networks and Beyond: A Review of Methods and\n  Applications", "comments": "30 pages, 20 figures", "journal-ref": null, "doi": "10.1109/JPROC.2021.3060483", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the broader and highly successful usage of machine learning in industry\nand the sciences, there has been a growing demand for Explainable AI.\nInterpretability and explanation methods for gaining a better understanding\nabout the problem solving abilities and strategies of nonlinear Machine\nLearning, in particular, deep neural networks, are therefore receiving\nincreased attention. In this work we aim to (1) provide a timely overview of\nthis active emerging field, with a focus on 'post-hoc' explanations, and\nexplain its theoretical foundations, (2) put interpretability algorithms to a\ntest both from a theory and comparative evaluation perspective using extensive\nsimulations, (3) outline best practice aspects i.e. how to best include\ninterpretation methods into the standard usage of machine learning and (4)\ndemonstrate successful usage of explainable AI in a representative selection of\napplication scenarios. Finally, we discuss challenges and possible future\ndirections of this exciting foundational field of machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 10:45:51 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 12:39:41 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Samek", "Wojciech", ""], ["Montavon", "Gr\u00e9goire", ""], ["Lapuschkin", "Sebastian", ""], ["Anders", "Christopher J.", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "2003.07743", "submitter": "Wei Hu", "authors": "Zequn Sun and Qingheng Zhang and Wei Hu and Chengming Wang and Muhao\n  Chen and Farahnaz Akrami and Chengkai Li", "title": "A Benchmarking Study of Embedding-based Entity Alignment for Knowledge\n  Graphs", "comments": "Accepted in the 46th International Conference on Very Large Data\n  Bases (VLDB 2020)", "journal-ref": null, "doi": "10.14778/3407790.3407828", "report-no": null, "categories": "cs.CL cs.AI cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity alignment seeks to find entities in different knowledge graphs (KGs)\nthat refer to the same real-world object. Recent advancement in KG embedding\nimpels the advent of embedding-based entity alignment, which encodes entities\nin a continuous embedding space and measures entity similarities based on the\nlearned embeddings. In this paper, we conduct a comprehensive experimental\nstudy of this emerging field. We survey 23 recent embedding-based entity\nalignment approaches and categorize them based on their techniques and\ncharacteristics. We also propose a new KG sampling algorithm, with which we\ngenerate a set of dedicated benchmark datasets with various heterogeneity and\ndistributions for a realistic evaluation. We develop an open-source library\nincluding 12 representative embedding-based entity alignment approaches, and\nextensively evaluate these approaches, to understand their strengths and\nlimitations. Additionally, for several directions that have not been explored\nin current approaches, we perform exploratory experiments and report our\npreliminary findings for future studies. The benchmark datasets, open-source\nlibrary and experimental results are all accessible online and will be duly\nmaintained.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 05:32:06 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 00:47:26 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Sun", "Zequn", ""], ["Zhang", "Qingheng", ""], ["Hu", "Wei", ""], ["Wang", "Chengming", ""], ["Chen", "Muhao", ""], ["Akrami", "Farahnaz", ""], ["Li", "Chengkai", ""]]}, {"id": "2003.07745", "submitter": "Connor Basich", "authors": "Connor Basich, Justin Svegliato, Kyle Hollins Wray, Stefan Witwicki,\n  Joydeep Biswas, Shlomo Zilberstein", "title": "Learning to Optimize Autonomy in Competence-Aware Systems", "comments": "To be published in Proceedings of the 19th International Conference\n  on Autonomous Agents and Multiagent Systems (AAMAS 2020). 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interest in semi-autonomous systems (SAS) is growing rapidly as a paradigm to\ndeploy autonomous systems in domains that require occasional reliance on\nhumans. This paradigm allows service robots or autonomous vehicles to operate\nat varying levels of autonomy and offer safety in situations that require human\njudgment. We propose an introspective model of autonomy that is learned and\nupdated online through experience and dictates the extent to which the agent\ncan act autonomously in any given situation. We define a competence-aware\nsystem (CAS) that explicitly models its own proficiency at different levels of\nautonomy and the available human feedback. A CAS learns to adjust its level of\nautonomy based on experience to maximize overall efficiency, factoring in the\ncost of human assistance. We analyze the convergence properties of CAS and\nprovide experimental results for robot delivery and autonomous driving domains\nthat demonstrate the benefits of the approach.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 14:31:45 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Basich", "Connor", ""], ["Svegliato", "Justin", ""], ["Wray", "Kyle Hollins", ""], ["Witwicki", "Stefan", ""], ["Biswas", "Joydeep", ""], ["Zilberstein", "Shlomo", ""]]}, {"id": "2003.07781", "submitter": "Meng Chen", "authors": "Qingjie Liu, Yixuan Zuo, Xiaohui Yu, Meng Chen", "title": "TTDM: A Travel Time Difference Model for Next Location Prediction", "comments": null, "journal-ref": "2019 20th IEEE International Conference on Mobile Data Management\n  (MDM)", "doi": "10.1109/MDM.2019.00-54", "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next location prediction is of great importance for many location-based\napplications and provides essential intelligence to business and governments.\nIn existing studies, a common approach to next location prediction is to learn\nthe sequential transitions with massive historical trajectories based on\nconditional probability. Unfortunately, due to the time and space complexity,\nthese methods (e.g., Markov models) only use the just passed locations to\npredict next locations, without considering all the passed locations in the\ntrajectory. In this paper, we seek to enhance the prediction performance by\nconsidering the travel time from all the passed locations in the query\ntrajectory to a candidate next location. In particular, we propose a novel\nmethod, called Travel Time Difference Model (TTDM), which exploits the\ndifference between the shortest travel time and the actual travel time to\npredict next locations. Further, we integrate the TTDM with a Markov model via\na linear interpolation to yield a joint model, which computes the probability\nof reaching each possible next location and returns the top-rankings as\nresults. We have conducted extensive experiments on two real datasets: the\nvehicle passage record (VPR) data and the taxi trajectory data. The\nexperimental results demonstrate significant improvements in prediction\naccuracy over existing solutions. For example, compared with the Markov model,\nthe top-1 accuracy improves by 40% on the VPR data and by 15.6% on the Taxi\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 05:16:43 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Liu", "Qingjie", ""], ["Zuo", "Yixuan", ""], ["Yu", "Xiaohui", ""], ["Chen", "Meng", ""]]}, {"id": "2003.07800", "submitter": "Carsten Lutz", "authors": "Pablo Barcelo, Cristina Feier, Carsten Lutz, Andreas Pieris", "title": "When is Ontology-Mediated Querying Efficient?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In ontology-mediated querying, description logic (DL) ontologies are used to\nenrich incomplete data with domain knowledge which results in more complete\nanswers to queries. However, the evaluation of ontology-mediated queries (OMQs)\nover relational databases is computationally hard. This raises the question\nwhen OMQ evaluation is efficient, in the sense of being tractable in combined\ncomplexity or fixed-parameter tractable. We study this question for a range of\nontology-mediated query languages based on several important and widely-used\nDLs, using unions of conjunctive queries as the actual queries. For the DL ELHI\nextended with the bottom concept, we provide a characterization of the classes\nof OMQs that are fixed-parameter tractable. For its fragment EL extended with\ndomain and range restrictions and the bottom concept (which restricts the use\nof inverse roles), we provide a characterization of the classes of OMQs that\nare tractable in combined complexity. Both results are in terms of equivalence\nto OMQs of bounded tree width and rest on a reasonable assumption from\nparameterized complexity theory. They are similar in spirit to Grohe's seminal\ncharacterization of the tractable classes of conjunctive queries over\nrelational databases. We further study the complexity of the meta problem of\ndeciding whether a given OMQ is equivalent to an OMQ of bounded tree width,\nproviding several completeness results that range from NP to 2ExpTime,\ndepending on the DL used. We also consider the DL-Lite family of DLs, including\nmembers that admit functional roles.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 16:32:00 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 15:25:57 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Barcelo", "Pablo", ""], ["Feier", "Cristina", ""], ["Lutz", "Carsten", ""], ["Pieris", "Andreas", ""]]}, {"id": "2003.07813", "submitter": "Elif Surer", "authors": "Sinan Ariyurek, Aysu Betin-Can, Elif Surer", "title": "Enhancing the Monte Carlo Tree Search Algorithm for Video Game Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the effects of several Monte Carlo Tree Search (MCTS)\nmodifications for video game testing. Although MCTS modifications are highly\nstudied in game playing, their impacts on finding bugs are blank. We focused on\nbug finding in our previous study where we introduced synthetic and human-like\ntest goals and we used these test goals in Sarsa and MCTS agents to find bugs.\nIn this study, we extend the MCTS agent with several modifications for game\ntesting purposes. Furthermore, we present a novel tree reuse strategy. We\nexperiment with these modifications by testing them on three testbed games,\nfour levels each, that contain 45 bugs in total. We use the General Video Game\nArtificial Intelligence (GVG-AI) framework to create the testbed games and\ncollect 427 human tester trajectories using the GVG-AI framework. We analyze\nthe proposed modifications in three parts: we evaluate their effects on bug\nfinding performances of agents, we measure their success under two different\ncomputational budgets, and we assess their effects on human-likeness of the\nhuman-like agent. Our results show that MCTS modifications improve the bug\nfinding performance of the agents.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 16:52:53 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Ariyurek", "Sinan", ""], ["Betin-Can", "Aysu", ""], ["Surer", "Elif", ""]]}, {"id": "2003.08001", "submitter": "Farahnaz Akrami", "authors": "Farahnaz Akrami (1), Mohammed Samiul Saeef (1), Qingheng Zhang (2),\n  Wei Hu (2), Chengkai Li (1) ((1) Department of Computer Science and\n  Engineering, University of Texas at Arlington, (2) State Key Laboratory for\n  Novel Software Technology, Nanjing University)", "title": "Realistic Re-evaluation of Knowledge Graph Completion Methods: An\n  Experimental Study", "comments": "accepted to SIGMOD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the active research area of employing embedding models for knowledge graph\ncompletion, particularly for the task of link prediction, most prior studies\nused two benchmark datasets FB15k and WN18 in evaluating such models. Most\ntriples in these and other datasets in such studies belong to reverse and\nduplicate relations which exhibit high data redundancy due to semantic\nduplication, correlation or data incompleteness. This is a case of excessive\ndata leakage---a model is trained using features that otherwise would not be\navailable when the model needs to be applied for real prediction. There are\nalso Cartesian product relations for which every triple formed by the Cartesian\nproduct of applicable subjects and objects is a true fact. Link prediction on\nthe aforementioned relations is easy and can be achieved with even better\naccuracy using straightforward rules instead of sophisticated embedding models.\nA more fundamental defect of these models is that the link prediction scenario,\ngiven such data, is non-existent in the real-world. This paper is the first\nsystematic study with the main objective of assessing the true effectiveness of\nembedding models when the unrealistic triples are removed. Our experiment\nresults show these models are much less accurate than what we used to perceive.\nTheir poor accuracy renders link prediction a task without truly effective\nautomated solution. Hence, we call for re-investigation of possible effective\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 01:18:09 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Akrami", "Farahnaz", ""], ["Saeef", "Mohammed Samiul", ""], ["Zhang", "Qingheng", ""], ["Hu", "Wei", ""], ["Li", "Chengkai", ""]]}, {"id": "2003.08003", "submitter": "Xin Huang", "authors": "Xin Huang, Stephen G. McGill, Jonathan A. DeCastro, Luke Fletcher,\n  John J. Leonard, Brian C. Williams, Guy Rosman", "title": "CARPAL: Confidence-Aware Intent Recognition for Parallel Autonomy", "comments": "Accepted at ICRA'21/RA-L'21. Author version with 9 pages, 5 figures,\n  2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting driver intentions is a difficult and crucial task for advanced\ndriver assistance systems. Traditional confidence measures on predictions often\nignore the way predicted trajectories affect downstream decisions for safe\ndriving. In this paper, we propose a novel multi-task intent recognition neural\nnetwork that predicts not only probabilistic driver trajectories, but also\nutility statistics associated with the predictions for a given downstream task.\nWe establish a decision criterion for parallel autonomy that takes into account\nthe role of driver trajectory prediction in real-time decision making by\nreasoning about estimated task-specific utility statistics. We further improve\nthe robustness of our system by considering uncertainties in downstream\nplanning tasks that may lead to unsafe decisions. We test our online system on\na realistic urban driving dataset, and demonstrate its advantage in terms of\nrecall and fall-out metrics compared to baseline methods, and demonstrate its\neffectiveness in intervention and warning use cases.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 01:25:06 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 18:05:42 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Huang", "Xin", ""], ["McGill", "Stephen G.", ""], ["DeCastro", "Jonathan A.", ""], ["Fletcher", "Luke", ""], ["Leonard", "John J.", ""], ["Williams", "Brian C.", ""], ["Rosman", "Guy", ""]]}, {"id": "2003.08158", "submitter": "Tessa van der Heiden", "authors": "Tessa van der Heiden, Florian Mirus, Herke van Hoof", "title": "Social Navigation with Human Empowerment driven Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mobile robot navigation has seen extensive research in the last decades. The\naspect of collaboration with robots and humans sharing workspaces will become\nincreasingly important in the future. Therefore, the next generation of mobile\nrobots needs to be socially-compliant to be accepted by their human\ncollaborators. However, a formal definition of compliance is not\nstraightforward. On the other hand, empowerment has been used by artificial\nagents to learn complicated and generalized actions and also has been shown to\nbe a good model for biological behaviors. In this paper, we go beyond the\napproach of classical \\acf{RL} and provide our agent with intrinsic motivation\nusing empowerment. In contrast to self-empowerment, a robot employing our\napproach strives for the empowerment of people in its environment, so they are\nnot disturbed by the robot's presence and motion. In our experiments, we show\nthat our approach has a positive influence on humans, as it minimizes its\ndistance to humans and thus decreases human travel time while moving\nefficiently towards its own goal. An interactive user-study shows that our\nmethod is considered more social than other state-of-the-art approaches by the\nparticipants.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 11:16:07 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 13:13:41 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 11:49:39 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["van der Heiden", "Tessa", ""], ["Mirus", "Florian", ""], ["van Hoof", "Herke", ""]]}, {"id": "2003.08207", "submitter": "Miriam Enzi", "authors": "Miriam Enzi, Sophie N. Parragh, David Pisinger", "title": "Modeling and solving a vehicle-sharing problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the change in mobility patterns, we present a new modeling\napproach for the vehicle-sharing problem. We aim at assigning vehicles to\nuser-trips so as to maximize savings compared to other modes of transport. We\nbase our formulations on the minimum-cost and the multi-commodity flow problem.\nThese formulations make the problem applicable in daily operations. In the\nanalysis we discuss an optimal composition of a shared fleet, restricted sets\nof modes of transport, and variations of the objective function.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 11:12:20 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Enzi", "Miriam", ""], ["Parragh", "Sophie N.", ""], ["Pisinger", "David", ""]]}, {"id": "2003.08298", "submitter": "Rafael Pe\\~naloza", "authors": "Rafael Pe\\~naloza", "title": "Axiom Pinpointing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Axiom pinpointing refers to the task of finding the specific axioms in an\nontology which are responsible for a consequence to follow. This task has been\nstudied, under different names, in many research areas, leading to a\nreformulation and reinvention of techniques. In this work, we present a general\noverview to axiom pinpointing, providing the basic notions, different\napproaches for solving it, and some variations and applications which have been\nconsidered in the literature. This should serve as a starting point for\nresearchers interested in related problems, with an ample bibliography for\ndelving deeper into the details.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 15:55:54 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Pe\u00f1aloza", "Rafael", ""]]}, {"id": "2003.08316", "submitter": "Giuseppe Marra", "authors": "Luc De Raedt, Sebastijan Duman\\v{c}i\\'c, Robin Manhaeve, and Giuseppe\n  Marra", "title": "From Statistical Relational to Neuro-Symbolic Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuro-symbolic and statistical relational artificial intelligence both\nintegrate frameworks for learning with logical reasoning. This survey\nidentifies several parallels across seven different dimensions between these\ntwo fields. These cannot only be used to characterize and position\nneuro-symbolic artificial intelligence approaches but also to identify a number\nof directions for further research.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 16:15:46 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 16:03:51 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["De Raedt", "Luc", ""], ["Duman\u010di\u0107", "Sebastijan", ""], ["Manhaeve", "Robin", ""], ["Marra", "Giuseppe", ""]]}, {"id": "2003.08334", "submitter": "Huynh Van Luong", "authors": "Huynh Van Luong, Boris Joukovsky, Nikos Deligiannis", "title": "Interpretable Deep Recurrent Neural Networks via Unfolding Reweighted\n  $\\ell_1$-$\\ell_1$ Minimization: Architecture Design and Generalization\n  Analysis", "comments": "Pre-print: 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep unfolding methods---for example, the learned iterative shrinkage\nthresholding algorithm (LISTA)---design deep neural networks as learned\nvariations of optimization methods. These networks have been shown to achieve\nfaster convergence and higher accuracy than the original optimization methods.\nIn this line of research, this paper develops a novel deep recurrent neural\nnetwork (coined reweighted-RNN) by the unfolding of a reweighted\n$\\ell_1$-$\\ell_1$ minimization algorithm and applies it to the task of\nsequential signal reconstruction. To the best of our knowledge, this is the\nfirst deep unfolding method that explores reweighted minimization. Due to the\nunderlying reweighted minimization model, our RNN has a different\nsoft-thresholding function (alias, different activation functions) for each\nhidden unit in each layer. Furthermore, it has higher network expressivity than\nexisting deep unfolding RNN models due to the over-parameterizing weights.\nImportantly, we establish theoretical generalization error bounds for the\nproposed reweighted-RNN model by means of Rademacher complexity. The bounds\nreveal that the parameterization of the proposed reweighted-RNN ensures good\ngeneralization. We apply the proposed reweighted-RNN to the problem of video\nframe reconstruction from low-dimensional measurements, that is, sequential\nframe reconstruction. The experimental results on the moving MNIST dataset\ndemonstrate that the proposed deep reweighted-RNN significantly outperforms\nexisting RNN models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 17:02:10 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Van Luong", "Huynh", ""], ["Joukovsky", "Boris", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "2003.08353", "submitter": "Marc Brittain", "authors": "Marc Brittain, Xuxi Yang, Peng Wei", "title": "A Deep Multi-Agent Reinforcement Learning Approach to Autonomous\n  Separation Assurance", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel deep multi-agent reinforcement learning framework is proposed to\nidentify and resolve conflicts among a variable number of aircraft in a\nhigh-density, stochastic, and dynamic sector. Currently the sector capacity is\nconstrained by human air traffic controller's cognitive limitation. We\ninvestigate the feasibility of a new concept (autonomous separation assurance)\nand a new approach to push the sector capacity above human cognitive\nlimitation. We propose the concept of using distributed vehicle autonomy to\nensure separation, instead of a centralized sector air traffic controller. Our\nproposed framework utilizes Proximal Policy Optimization (PPO) that we modify\nto incorporate an attention network. This allows the agents to have access to\nvariable aircraft information in the sector in a scalable, efficient approach\nto achieve high traffic throughput under uncertainty. Agents are trained using\na centralized learning, decentralized execution scheme where one neural network\nis learned and shared by all agents. The proposed framework is validated on\nthree challenging case studies in the BlueSky air traffic control environment.\nNumerical results show the proposed framework significantly reduces offline\ntraining time, increases performance, and results in a more efficient policy.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 16:50:34 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 16:46:52 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Brittain", "Marc", ""], ["Yang", "Xuxi", ""], ["Wei", "Peng", ""]]}, {"id": "2003.08363", "submitter": "Xinwei Wang", "authors": "Chao Han, Yi Gu, Guohua Wu, Xinwei Wang", "title": "Simulated annealing based heuristic for multiple agile satellites\n  scheduling under cloud coverage uncertainty", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI physics.space-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agile satellites are the new generation of Earth observation satellites\n(EOSs) with stronger attitude maneuvering capability. Since optical remote\nsensing instruments equipped on satellites cannot see through the cloud, the\ncloud coverage has a significant influence on the satellite observation\nmissions. We are the first to address multiple agile EOSs scheduling problem\nunder cloud coverage uncertainty where the objective aims to maximize the\nentire observation profit. The chance constraint programming model is adopted\nto describe the uncertainty initially, and the observation profit under cloud\ncoverage uncertainty is then calculated via sample approximation method.\nSubsequently, an improved simulated annealing based heuristic combining a fast\ninsertion strategy is proposed for large-scale observation missions. The\nexperimental results show that the improved simulated annealing heuristic\noutperforms other algorithms for the multiple AEOSs scheduling problem under\ncloud coverage uncertainty, which verifies the efficiency and effectiveness of\nthe proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 16:37:26 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 07:34:40 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Han", "Chao", ""], ["Gu", "Yi", ""], ["Wu", "Guohua", ""], ["Wang", "Xinwei", ""]]}, {"id": "2003.08376", "submitter": "Xinshuo Weng", "authors": "Xinshuo Weng and Jianren Wang and Sergey Levine and Kris Kitani and\n  Nicholas Rhinehart", "title": "Inverting the Pose Forecasting Pipeline with SPF2: Sequential Pointcloud\n  Forecasting for Sequential Pose Forecasting", "comments": "Published in Conference on Robot Learning (CoRL), 2020. Project\n  webpage: http://www.xinshuoweng.com/projects/SPF2/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many autonomous systems forecast aspects of the future in order to aid\ndecision-making. For example, self-driving vehicles and robotic manipulation\nsystems often forecast future object poses by first detecting and tracking\nobjects. However, this detect-then-forecast pipeline is expensive to scale, as\npose forecasting algorithms typically require labeled sequences of object\nposes, which are costly to obtain in 3D space. Can we scale performance without\nrequiring additional labels? We hypothesize yes, and propose inverting the\ndetect-then-forecast pipeline. Instead of detecting, tracking and then\nforecasting the objects, we propose to first forecast 3D sensor data (e.g.,\npoint clouds with $100$k points) and then detect/track objects on the predicted\npoint cloud sequences to obtain future poses, i.e., a forecast-then-detect\npipeline. This inversion makes it less expensive to scale pose forecasting, as\nthe sensor data forecasting task requires no labels. Part of this work's focus\nis on the challenging first step -- Sequential Pointcloud Forecasting (SPF),\nfor which we also propose an effective approach, SPFNet. To compare our\nforecast-then-detect pipeline relative to the detect-then-forecast pipeline, we\npropose an evaluation procedure and two metrics. Through experiments on a\nrobotic manipulation dataset and two driving datasets, we show that SPFNet is\neffective for the SPF task, our forecast-then-detect pipeline outperforms the\ndetect-then-forecast approaches to which we compared, and that pose forecasting\nperformance improves with the addition of unlabeled data.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 17:54:28 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 16:08:10 GMT"}, {"version": "v3", "created": "Sat, 7 Nov 2020 02:48:22 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Weng", "Xinshuo", ""], ["Wang", "Jianren", ""], ["Levine", "Sergey", ""], ["Kitani", "Kris", ""], ["Rhinehart", "Nicholas", ""]]}, {"id": "2003.08445", "submitter": "Azalia Mirhoseini", "authors": "Anna Goldie and Azalia Mirhoseini", "title": "Placement Optimization with Deep Reinforcement Learning", "comments": "International Symposium on Physical Design (ISPD), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Placement Optimization is an important problem in systems and chip design,\nwhich consists of mapping the nodes of a graph onto a limited set of resources\nto optimize for an objective, subject to constraints. In this paper, we start\nby motivating reinforcement learning as a solution to the placement problem. We\nthen give an overview of what deep reinforcement learning is. We next formulate\nthe placement problem as a reinforcement learning problem and show how this\nproblem can be solved with policy gradient optimization. Finally, we describe\nlessons we have learned from training deep reinforcement learning policies\nacross a variety of placement optimization problems.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 19:20:37 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Goldie", "Anna", ""], ["Mirhoseini", "Azalia", ""]]}, {"id": "2003.08554", "submitter": "Xuerun Chen", "authors": "Xuerun Chen", "title": "Adjust Planning Strategies to Accommodate Reinforcement Learning Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In agent control issues, the idea of combining reinforcement learning and\nplanning has attracted much attention. Two methods focus on micro and macro\naction respectively. Their advantages would show together if there is a good\ncooperation between them. An essential for the cooperation is to find an\nappropriate boundary, assigning different functions to each method. Such\nboundary could be represented by parameters in a planning algorithm. In this\npaper, we create an optimization strategy for planning parameters, through\nanalysis to the connection of reaction and planning; we also create a\nnon-gradient method for accelerating the optimization. The whole algorithm can\nfind a satisfactory setting of planning parameters, making full use of reaction\ncapability of specific agents.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 03:35:10 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Chen", "Xuerun", ""]]}, {"id": "2003.08561", "submitter": "Sung Whan Yoon", "authors": "Sung Whan Yoon, Do-Yeon Kim, Jun Seo, Jaekyun Moon", "title": "XtarNet: Learning to Extract Task-Adaptive Representation for\n  Incremental Few-Shot Learning", "comments": "In Proceedings of the 37th International Conference on Machine\n  Learning (ICML) 2020, Vienna, Austria, PMLR 119; *Equal contribution", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning (ICML) 2020, Vienna, Austria, PMLR 119", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning novel concepts while preserving prior knowledge is a long-standing\nchallenge in machine learning. The challenge gets greater when a novel task is\ngiven with only a few labeled examples, a problem known as incremental few-shot\nlearning. We propose XtarNet, which learns to extract task-adaptive\nrepresentation (TAR) for facilitating incremental few-shot learning. The method\nutilizes a backbone network pretrained on a set of base categories while also\nemploying additional modules that are meta-trained across episodes. Given a new\ntask, the novel feature extracted from the meta-trained modules is mixed with\nthe base feature obtained from the pretrained model. The process of combining\ntwo different features provides TAR and is also controlled by meta-trained\nmodules. The TAR contains effective information for classifying both novel and\nbase categories. The base and novel classifiers quickly adapt to a given task\nby utilizing the TAR. Experiments on standard image datasets indicate that\nXtarNet achieves state-of-the-art incremental few-shot learning performance.\nThe concept of TAR can also be used in conjunction with existing incremental\nfew-shot learning methods; extensive simulation results in fact show that\napplying TAR enhances the known methods significantly.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 04:02:44 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 07:08:02 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Yoon", "Sung Whan", ""], ["Kim", "Do-Yeon", ""], ["Seo", "Jun", ""], ["Moon", "Jaekyun", ""]]}, {"id": "2003.08598", "submitter": "Philipp Wanko", "authors": "Dirk Abels, Julian Jordi, Max Ostrowski, Torsten Schaub, Ambra\n  Toletti, and Philipp Wanko", "title": "Train Scheduling with Hybrid Answer Set Programming", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 21 (2021) 317-347", "doi": "10.1017/S1471068420000046", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a solution to real-world train scheduling problems, involving\nrouting, scheduling, and optimization, based on Answer Set Programming (ASP).\nTo this end, we pursue a hybrid approach that extends ASP with difference\nconstraints to account for a fine-grained timing. More precisely, we\nexemplarily show how the hybrid ASP system clingo[DL] can be used to tackle\ndemanding planning-and-scheduling problems. In particular, we investigate how\nto boost performance by combining distinct ASP solving techniques, such as\napproximations and heuristics, with preprocessing and encoding techniques for\ntackling large-scale, real-world train scheduling instances. Under\nconsideration in Theory and Practice of Logic Programming (TPLP)\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 06:50:04 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Abels", "Dirk", ""], ["Jordi", "Julian", ""], ["Ostrowski", "Max", ""], ["Schaub", "Torsten", ""], ["Toletti", "Ambra", ""], ["Wanko", "Philipp", ""]]}, {"id": "2003.08615", "submitter": "Ali Balali", "authors": "Ali Balali, Masoud Asadpour, Ricardo Campos, Adam Jatowt", "title": "Joint Event Extraction along Shortest Dependency Paths using Graph\n  Convolutional Networks", "comments": null, "journal-ref": "Knowledge-Based Systems, Volume 210, Year 2020, Page 106492", "doi": "10.1016/j.knosys.2020.106492", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event extraction (EE) is one of the core information extraction tasks, whose\npurpose is to automatically identify and extract information about incidents\nand their actors from texts. This may be beneficial to several domains such as\nknowledge bases, question answering, information retrieval and summarization\ntasks, to name a few. The problem of extracting event information from texts is\nlongstanding and usually relies on elaborately designed lexical and syntactic\nfeatures, which, however, take a large amount of human effort and lack\ngeneralization. More recently, deep neural network approaches have been adopted\nas a means to learn underlying features automatically. However, existing\nnetworks do not make full use of syntactic features, which play a fundamental\nrole in capturing very long-range dependencies. Also, most approaches extract\neach argument of an event separately without considering associations between\narguments which ultimately leads to low efficiency, especially in sentences\nwith multiple events. To address the two above-referred problems, we propose a\nnovel joint event extraction framework that aims to extract multiple event\ntriggers and arguments simultaneously by introducing shortest dependency path\n(SDP) in the dependency graph. We do this by eliminating irrelevant words in\nthe sentence, thus capturing long-range dependencies. Also, an attention-based\ngraph convolutional network is proposed, to carry syntactically related\ninformation along the shortest paths between argument candidates that captures\nand aggregates the latent associations between arguments; a problem that has\nbeen overlooked by most of the literature. Our results show a substantial\nimprovement over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 07:48:38 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Balali", "Ali", ""], ["Asadpour", "Masoud", ""], ["Campos", "Ricardo", ""], ["Jatowt", "Adam", ""]]}, {"id": "2003.08717", "submitter": "Thierry Deruyttere", "authors": "Thierry Deruyttere, Guillem Collell, Marie-Francine Moens", "title": "Giving Commands to a Self-driving Car: A Multimodal Reasoner for Visual\n  Grounding", "comments": "Updated acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a new spatial memory module and a spatial reasoner for the Visual\nGrounding (VG) task. The goal of this task is to find a certain object in an\nimage based on a given textual query. Our work focuses on integrating the\nregions of a Region Proposal Network (RPN) into a new multi-step reasoning\nmodel which we have named a Multimodal Spatial Region Reasoner (MSRR). The\nintroduced model uses the object regions from an RPN as initialization of a 2D\nspatial memory and then implements a multi-step reasoning process scoring each\nregion according to the query, hence why we call it a multimodal reasoner. We\nevaluate this new model on challenging datasets and our experiments show that\nour model that jointly reasons over the object regions of the image and words\nof the query largely improves accuracy compared to current state-of-the-art\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 12:40:41 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 08:44:40 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 12:08:13 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Deruyttere", "Thierry", ""], ["Collell", "Guillem", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "2003.08727", "submitter": "Aleksander Czechowski", "authors": "Aleksander Czechowski, Frans A. Oliehoek", "title": "Decentralized MCTS via Learned Teammate Models", "comments": "Sole copyright holder is IJCAI, all rights reserved. Published\n  version available online: https://doi.org/10.24963/ijcai.2020/12", "journal-ref": "Proceedings of the Twenty-Ninth International Joint Conference on\n  Artificial Intelligence, pages 81--88, 2020", "doi": "10.24963/ijcai.2020/12", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized online planning can be an attractive paradigm for cooperative\nmulti-agent systems, due to improved scalability and robustness. A key\ndifficulty of such approach lies in making accurate predictions about the\ndecisions of other agents. In this paper, we present a trainable online\ndecentralized planning algorithm based on decentralized Monte Carlo Tree\nSearch, combined with models of teammates learned from previous episodic runs.\nBy only allowing one agent to adapt its models at a time, under the assumption\nof ideal policy approximation, successive iterations of our method are\nguaranteed to improve joint policies, and eventually lead to convergence to a\nNash equilibrium. We test the efficiency of the algorithm by performing\nexperiments in several scenarios of the spatial task allocation environment\nintroduced in [Claes et al., 2015]. We show that deep learning and\nconvolutional neural networks can be employed to produce accurate policy\napproximators which exploit the spatial features of the problem, and that the\nproposed algorithm improves over the baseline planning performance for\nparticularly challenging domain configurations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 13:10:20 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 15:39:36 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 18:42:03 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Czechowski", "Aleksander", ""], ["Oliehoek", "Frans A.", ""]]}, {"id": "2003.08744", "submitter": "Emilie Wirbel", "authors": "Thibault Buhet, and Emilie Wirbel and Andrei Bursuc and Xavier\n  Perrotton", "title": "PLOP: Probabilistic poLynomial Objects trajectory Planning for\n  autonomous driving", "comments": "Accepted at CorRL 2020 (matching camera-ready version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To navigate safely in urban environments, an autonomous vehicle (ego vehicle)\nmust understand and anticipate its surroundings, in particular the behavior and\nintents of other road users (neighbors). Most of the times, multiple decision\nchoices are acceptable for all road users (e.g., turn right or left, or\ndifferent ways of avoiding an obstacle), leading to a highly uncertain and\nmulti-modal decision space. We focus here on predicting multiple feasible\nfuture trajectories for both ego vehicle and neighbors through a probabilistic\nframework. We rely on a conditional imitation learning algorithm, conditioned\nby a navigation command for the ego vehicle (e.g., \"turn right\"). Our model\nprocesses ego vehicle front-facing camera images and bird-eye view grid,\ncomputed from Lidar point clouds, with detections of past and present objects,\nin order to generate multiple trajectories for both ego vehicle and its\nneighbors. Our approach is computationally efficient and relies only on\non-board sensors. We evaluate our method offline on the publicly available\ndataset nuScenes, achieving state-of-the-art performance, investigate the\nimpact of our architecture choices on online simulated experiments and show\npreliminary insights for real vehicle control\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 16:55:07 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 15:39:51 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 08:29:19 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Buhet", "Thibault", ""], ["Wirbel", "Emilie", ""], ["Bursuc", "Andrei", ""], ["Perrotton", "Xavier", ""]]}, {"id": "2003.08783", "submitter": "Paul Cohen", "authors": "Paul Cohen and Tomasz Loboda", "title": "Redistribution Systems and PRAM", "comments": "arXiv admin note: substantial text overlap with arXiv:1902.05677", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Redistribution systems iteratively redistribute mass between groups under the\ncontrol of rules. PRAM is a framework for building redistribution systems. We\ndiscuss the relationships between redistribution systems, agent-based systems,\ncompartmental models and Bayesian models. PRAM puts agent-based models on a\nsound probabilistic footing by reformulating them as redistribution systems.\nThis provides a basis for integrating agent-based and probabilistic models.\n\\pram/ extends the themes of probabilistic relational models and lifted\ninference to incorporate dynamical models and simulation. We illustrate PRAM\nwith an epidemiological example.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 01:36:28 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 01:32:37 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Cohen", "Paul", ""], ["Loboda", "Tomasz", ""]]}, {"id": "2003.08837", "submitter": "Christian Berghoff", "authors": "Christian Berghoff and Matthias Neu and Arndt von Twickel", "title": "Vulnerabilities of Connectionist AI Applications: Evaluation and Defence", "comments": "20 pages, 8 figures, 1 table", "journal-ref": null, "doi": "10.3389/fdata.2020.00023", "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article deals with the IT security of connectionist artificial\nintelligence (AI) applications, focusing on threats to integrity, one of the\nthree IT security goals. Such threats are for instance most relevant in\nprominent AI computer vision applications. In order to present a holistic view\non the IT security goal integrity, many additional aspects such as\ninterpretability, robustness and documentation are taken into account. A\ncomprehensive list of threats and possible mitigations is presented by\nreviewing the state-of-the-art literature. AI-specific vulnerabilities such as\nadversarial attacks and poisoning attacks as well as their AI-specific root\ncauses are discussed in detail. Additionally and in contrast to former reviews,\nthe whole AI supply chain is analysed with respect to vulnerabilities,\nincluding the planning, data acquisition, training, evaluation and operation\nphases. The discussion of mitigations is likewise not restricted to the level\nof the AI system itself but rather advocates viewing AI systems in the context\nof their supply chains and their embeddings in larger IT infrastructures and\nhardware devices. Based on this and the observation that adaptive attackers may\ncircumvent any single published AI-specific defence to date, the article\nconcludes that single protective measures are not sufficient but rather\nmultiple measures on different levels have to be combined to achieve a minimum\nlevel of IT security for AI applications.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 12:33:59 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Berghoff", "Christian", ""], ["Neu", "Matthias", ""], ["von Twickel", "Arndt", ""]]}, {"id": "2003.08876", "submitter": "Philip Becker-Ehmck", "authors": "Philip Becker-Ehmck, Maximilian Karl, Jan Peters, Patrick van der\n  Smagt", "title": "Learning to Fly via Deep Model-Based Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to control robots without requiring engineered models has been a\nlong-term goal, promising diverse and novel applications. Yet, reinforcement\nlearning has only achieved limited impact on real-time robot control due to its\nhigh demand of real-world interactions. In this work, by leveraging a learnt\nprobabilistic model of drone dynamics, we learn a thrust-attitude controller\nfor a quadrotor through model-based reinforcement learning. No prior knowledge\nof the flight dynamics is assumed; instead, a sequential latent variable model,\nused generatively and as an online filter, is learnt from raw sensory input.\nThe controller and value function are optimised entirely by propagating\nstochastic analytic gradients through generated latent trajectories. We show\nthat \"learning to fly\" can be achieved with less than 30 minutes of experience\nwith a single drone, and can be deployed solely using onboard computational\nresources and sensors, on a self-built drone.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 15:55:39 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 10:54:35 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2020 10:41:38 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Becker-Ehmck", "Philip", ""], ["Karl", "Maximilian", ""], ["Peters", "Jan", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "2003.08978", "submitter": "Reuben Feinman", "authors": "Reuben Feinman, Brenden M. Lake", "title": "Generating new concepts with hybrid neuro-symbolic models", "comments": "Published in Proceedings of the 42nd Annual Meeting of the Cognitive\n  Science Society, July 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human conceptual knowledge supports the ability to generate novel yet highly\nstructured concepts, and the form of this conceptual knowledge is of great\ninterest to cognitive scientists. One tradition has emphasized structured\nknowledge, viewing concepts as embedded in intuitive theories or organized in\ncomplex symbolic knowledge structures. A second tradition has emphasized\nstatistical knowledge, viewing conceptual knowledge as an emerging from the\nrich correlational structure captured by training neural networks and other\nstatistical models. In this paper, we explore a synthesis of these two\ntraditions through a novel neuro-symbolic model for generating new concepts.\nUsing simple visual concepts as a testbed, we bring together neural networks\nand symbolic probabilistic programs to learn a generative model of novel\nhandwritten characters. Two alternative models are explored with more generic\nneural network architectures. We compare each of these three models for their\nlikelihoods on held-out character classes and for the quality of their\nproductions, finding that our hybrid model learns the most convincing\nrepresentation and generalizes further from the training observations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 18:45:56 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 14:47:17 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 01:31:57 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Feinman", "Reuben", ""], ["Lake", "Brenden M.", ""]]}, {"id": "2003.09000", "submitter": "Simon Odense", "authors": "Simon Odense and Artur d'Avila Garcez", "title": "Layerwise Knowledge Extraction from Deep Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge extraction is used to convert neural networks into symbolic\ndescriptions with the objective of producing more comprehensible learning\nmodels. The central challenge is to find an explanation which is more\ncomprehensible than the original model while still representing that model\nfaithfully. The distributed nature of deep networks has led many to believe\nthat the hidden features of a neural network cannot be explained by logical\ndescriptions simple enough to be comprehensible. In this paper, we propose a\nnovel layerwise knowledge extraction method using M-of-N rules which seeks to\nobtain the best trade-off between the complexity and accuracy of rules\ndescribing the hidden features of a deep network. We show empirically that this\napproach produces rules close to an optimal complexity-error tradeoff. We apply\nthis method to a variety of deep networks and find that in the internal layers\nwe often cannot find rules with a satisfactory complexity and accuracy,\nsuggesting that rule extraction as a general purpose method for explaining the\ninternal logic of a neural network may be impossible. However, we also find\nthat the softmax layer in Convolutional Neural Networks and Autoencoders using\neither tanh or relu activation functions is highly explainable by rule\nextraction, with compact rules consisting of as little as 3 units out of 128\noften reaching over 99% accuracy. This shows that rule extraction can be a\nuseful component for explaining parts (or modules) of a deep neural network.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 19:46:45 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Odense", "Simon", ""], ["Garcez", "Artur d'Avila", ""]]}, {"id": "2003.09022", "submitter": "John Mern", "authors": "John Mern and Dorsa Sadigh and Mykel J. Kochenderfer", "title": "Exchangeable Input Representations for Reinforcement Learning", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poor sample efficiency is a major limitation of deep reinforcement learning\nin many domains. This work presents an attention-based method to project neural\nnetwork inputs into an efficient representation space that is invariant under\nchanges to input ordering. We show that our proposed representation results in\nan input space that is a factor of $m!$ smaller for inputs of $m$ objects. We\nalso show that our method is able to represent inputs over variable numbers of\nobjects. Our experiments demonstrate improvements in sample efficiency for\npolicy gradient methods on a variety of tasks. We show that our representation\nallows us to solve problems that are otherwise intractable when using na\\\"ive\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 21:18:55 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Mern", "John", ""], ["Sadigh", "Dorsa", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2003.09044", "submitter": "Ryan Hoque", "authors": "Ryan Hoque, Daniel Seita, Ashwin Balakrishna, Aditya Ganapathi, Ajay\n  Kumar Tanwani, Nawid Jamali, Katsu Yamane, Soshi Iba, Ken Goldberg", "title": "VisuoSpatial Foresight for Multi-Step, Multi-Task Fabric Manipulation", "comments": "Robotics: Science and Systems (RSS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic fabric manipulation has applications in home robotics, textiles,\nsenior care and surgery. Existing fabric manipulation techniques, however, are\ndesigned for specific tasks, making it difficult to generalize across different\nbut related tasks. We extend the Visual Foresight framework to learn fabric\ndynamics that can be efficiently reused to accomplish different fabric\nmanipulation tasks with a single goal-conditioned policy. We introduce\nVisuoSpatial Foresight (VSF), which builds on prior work by learning visual\ndynamics on domain randomized RGB images and depth maps simultaneously and\ncompletely in simulation. We experimentally evaluate VSF on multi-step fabric\nsmoothing and folding tasks against 5 baseline methods in simulation and on the\nda Vinci Research Kit (dVRK) surgical robot without any demonstrations at train\nor test time. Furthermore, we find that leveraging depth significantly improves\nperformance. RGBD data yields an 80% improvement in fabric folding success rate\nover pure RGB data. Code, data, videos, and supplementary material are\navailable at https://sites.google.com/view/fabric-vsf/.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 23:12:10 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 21:02:52 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 07:10:49 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Hoque", "Ryan", ""], ["Seita", "Daniel", ""], ["Balakrishna", "Ashwin", ""], ["Ganapathi", "Aditya", ""], ["Tanwani", "Ajay Kumar", ""], ["Jamali", "Nawid", ""], ["Yamane", "Katsu", ""], ["Iba", "Soshi", ""], ["Goldberg", "Ken", ""]]}, {"id": "2003.09140", "submitter": "Lasse Blaauwbroek", "authors": "Lasse Blaauwbroek, Josef Urban, and Herman Geuvers", "title": "Tactic Learning and Proving for the Coq Proof Assistant", "comments": "12 pages, 2 figures, 1 table. For the associated artefacts, see\n  https://doi.org/10.5281/zenodo.3693760", "journal-ref": "In LPAR, volume 73 of EPiC Series in Computing, pages 138-150.\n  Easychair, 2020", "doi": "10.29007/wg1q", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system that utilizes machine learning for tactic proof search in\nthe Coq Proof Assistant. In a similar vein as the TacticToe project for HOL4,\nour system predicts appropriate tactics and finds proofs in the form of tactic\nscripts. To do this, it learns from previous tactic scripts and how they are\napplied to proof states. The performance of the system is evaluated on the Coq\nStandard Library. Currently, our predictor can identify the correct tactic to\nbe applied to a proof state 23.4% of the time. Our proof searcher can fully\nautomatically prove 39.3% of the lemmas. When combined with the CoqHammer\nsystem, the two systems together prove 56.7% of the library's lemmas.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 08:22:30 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Blaauwbroek", "Lasse", ""], ["Urban", "Josef", ""], ["Geuvers", "Herman", ""]]}, {"id": "2003.09211", "submitter": "Himanshu Mangla", "authors": "Anmol Bhasin, Bharatram Natarajan, Gaurav Mathur and Himanshu Mangla", "title": "Parallel Intent and Slot Prediction using MLB Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intent and Slot Identification are two important tasks in Spoken Language\nUnderstanding (SLU). For a natural language utterance, there is a high\ncorrelation between these two tasks. A lot of work has been done on each of\nthese using Recurrent-Neural-Networks (RNN), Convolution Neural Networks (CNN)\nand Attention based models. Most of the past work used two separate models for\nintent and slot prediction. Some of them also used sequence-to-sequence type\nmodels where slots are predicted after evaluating the utterance-level intent.\nIn this work, we propose a parallel Intent and Slot Prediction technique where\nseparate Bidirectional Gated Recurrent Units (GRU) are used for each task. We\nposit the usage of MLB (Multimodal Low-rank Bilinear Attention Network) fusion\nfor improvement in performance of intent and slot learning. To the best of our\nknowledge, this is the first attempt of using such a technique on text based\nproblems. Also, our proposed methods outperform the existing state-of-the-art\nresults for both intent and slot prediction on two benchmark datasets\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 11:48:16 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Bhasin", "Anmol", ""], ["Natarajan", "Bharatram", ""], ["Mathur", "Gaurav", ""], ["Mangla", "Himanshu", ""]]}, {"id": "2003.09280", "submitter": "Andrea Cini", "authors": "Andrea Cini, Carlo D'Eramo, Jan Peters, Cesare Alippi", "title": "Deep Reinforcement Learning with Weighted Q-Learning", "comments": "Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overestimation of the maximum action-value is a well-known problem that\nhinders Q-Learning performance, leading to suboptimal policies and unstable\nlearning. Among several Q-Learning variants proposed to address this issue,\nWeighted Q-Learning (WQL) effectively reduces the bias and shows remarkable\nresults in stochastic environments. WQL uses a weighted sum of the estimated\naction-values, where the weights correspond to the probability of each\naction-value being the maximum; however, the computation of these probabilities\nis only practical in the tabular settings. In this work, we provide the\nmethodological advances to benefit from the WQL properties in Deep\nReinforcement Learning (DRL), by using neural networks with Dropout Variational\nInference as an effective approximation of deep Gaussian processes. In\nparticular, we adopt the Concrete Dropout variant to obtain calibrated\nestimates of epistemic uncertainty in DRL. We show that model uncertainty in\nDRL can be useful not only for action selection, but also action evaluation. We\nanalyze how the novel Weighted Deep Q-Learning algorithm reduces the bias\nw.r.t. relevant baselines and provide empirical evidence of its advantages on\nseveral representative benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 13:57:40 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 15:12:02 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Cini", "Andrea", ""], ["D'Eramo", "Carlo", ""], ["Peters", "Jan", ""], ["Alippi", "Cesare", ""]]}, {"id": "2003.09287", "submitter": "Zehao Wang", "authors": "Zehao Wang, Shicheng Zhang, Xiaoou Chen", "title": "Exploring Inherent Properties of the Monophonic Melody of Songs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Melody is one of the most important components in music. Unlike other\ncomponents in music theory, such as harmony and counterpoint, computable\nfeatures for melody is urgently in need. These features are highly demanded as\ndata-driven methods dominating the fields such as musical information retrieval\nand automatic music composition. To boost the performance of\ndeep-learning-related musical tasks, we propose a set of interpretable features\non monophonic melody for computational purposes. These features are defined not\nonly in mathematical form, but also with some considerations on composers\n'intuition. For example, the Melodic Center of Gravity can reflect the\nsentence-wise contour of the melody, the local / global melody dynamics\nquantifies the dynamics of a melody that couples pitch and time in a sentence.\nWe found that these features are considered by people universally in many\ngenres of songs, even for atonal composition practices. Hopefully, these\nmelodic features can provide nov el inspiration for future researchers as a\ntool in the field of MIR and automatic composition.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 14:13:16 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Wang", "Zehao", ""], ["Zhang", "Shicheng", ""], ["Chen", "Xiaoou", ""]]}, {"id": "2003.09301", "submitter": "Minh N. H. Nguyen Dr.", "authors": "Minh N. H. Nguyen, Shashi Raj Pandey, Kyi Thar, Nguyen H. Tran,\n  Mingzhe Chen, Walid Saad, and Choong Seon Hong", "title": "Distributed and Democratized Learning: Philosophy and Research\n  Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the availability of huge amounts of data and processing abilities,\ncurrent artificial intelligence (AI) systems are effective in solving complex\ntasks. However, despite the success of AI in different areas, the problem of\ndesigning AI systems that can truly mimic human cognitive capabilities such as\nartificial general intelligence, remains largely open. Consequently, many\nemerging cross-device AI applications will require a transition from\ntraditional centralized learning systems towards large-scale distributed AI\nsystems that can collaboratively perform multiple complex learning tasks. In\nthis paper, we propose a novel design philosophy called democratized learning\n(Dem-AI) whose goal is to build large-scale distributed learning systems that\nrely on the self-organization of distributed learning agents that are\nwell-connected, but limited in learning capabilities. Correspondingly, inspired\nby the societal groups of humans, the specialized groups of learning agents in\nthe proposed Dem-AI system are self-organized in a hierarchical structure to\ncollectively perform learning tasks more efficiently. As such, the Dem-AI\nlearning system can evolve and regulate itself based on the underlying duality\nof two processes which we call specialized and generalized processes. In this\nregard, we present a reference design as a guideline to realize future Dem-AI\nsystems, inspired by various interdisciplinary fields. Accordingly, we\nintroduce four underlying mechanisms in the design such as plasticity-stability\ntransition mechanism, self-organizing hierarchical structuring, specialized\nlearning, and generalization. Finally, we establish possible extensions and new\nchallenges for the existing learning approaches to provide better scalable,\nflexible, and more powerful learning systems with the new setting of Dem-AI.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 08:45:10 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 10:14:41 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Nguyen", "Minh N. H.", ""], ["Pandey", "Shashi Raj", ""], ["Thar", "Kyi", ""], ["Tran", "Nguyen H.", ""], ["Chen", "Mingzhe", ""], ["Saad", "Walid", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2003.09310", "submitter": "Fatih Semiz", "authors": "\\c{C}a\\u{g}lar Seylan, \\\"Ozg\\\"ur Sayg{\\i}n Bican, Fatih Semiz", "title": "\\.Insans{\\i}z Ara\\c{c}larla D\\\"uzlemsel Olmayan Ara\\c{c}lar{\\i}n\n  Taranmas{\\i}", "comments": "in Turkish language", "journal-ref": "Savunma Bilimleri Dergisi 11-1 (2012) 107-117", "doi": null, "report-no": null, "categories": "cs.AI cs.MA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of area coverage with unmanned vehicles, in other words,\ntraveling an area with an unmanned vehicle such as a robot or a UAV completely\nor partially with minimum cost, is increasing with the increase in usage of\nsuch vehicles today. Area coverage with unmanned vehicles is used today in the\nexploration of an area with UAVs, sweeping mines with robots, cleaning ground\nwith robots in large shopping malls, mowing lawn in a large area etc. The\nproblem has versions such as area coverage with a single unmanned vehicle, area\ncoverage with multiple unmanned vehicles, on-line area coverage (The map of the\narea that will be covered is not known before starting the coverage) with\nunmanned vehicles etc. In addition, the area may have obstacles that the\nvehicles cannot move over. Naturally, many researches are working on the\nproblem and a lot of researches have been done on the problem until today.\nSpanning tree coverage is one of the major approaches to the problem. In this\napproach, at the basic level, the planar area is divided into identical squares\naccording to the range of sight of the vehicle, and centers of these squares\nare assumed to be vertexes of a graph. The vertexes of this graph are connected\nwith the edges with unit costs and after finding the minimum spanning tree of\nthe graph, the vehicle strolls around the spanning tree. The method we propose\nsuggests a way to cover a non-planar area with unmanned vehicles. The method we\npropose also takes advantage of the spanning-tree coverage approach, but\ninstead of assigning unit costs to the edges, we assigned a weight to each edge\nusing slopes between vertexes those the edges connect. We have gotten\nnoticeably better results than the results we got when we did not consider the\nslope between two squares and used the classical spanning tree approach.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 14:07:55 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Seylan", "\u00c7a\u011flar", ""], ["Bican", "\u00d6zg\u00fcr Sayg\u0131n", ""], ["Semiz", "Fatih", ""]]}, {"id": "2003.09311", "submitter": "Anirban Chatterjee", "authors": "Anirban Chatterjee, Subhadip Paul, Uddipto Dutta, Smaranya Dey", "title": "Drift-Adjusted And Arbitrated Ensemble Framework For Time Series\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time Series Forecasting is at the core of many practical applications such as\nsales forecasting for business, rainfall forecasting for agriculture and many\nothers. Though this problem has been extensively studied for years, it is still\nconsidered a challenging problem due to complex and evolving nature of time\nseries data. Typical methods proposed for time series forecasting modeled\nlinear or non-linear dependencies between data observations. However it is a\ngenerally accepted notion that no one method is universally effective for all\nkinds of time series data. Attempts have been made to use dynamic and weighted\ncombination of heterogeneous and independent forecasting models and it has been\nfound to be a promising direction to tackle this problem. This method is based\non the assumption that different forecasters have different specialization and\nvarying performance for different distribution of data and weights are\ndynamically assigned to multiple forecasters accordingly. However in many\npractical time series data-set, the distribution of data slowly evolves with\ntime. We propose to employ a re-weighting based method to adjust the assigned\nweights to various forecasters in order to account for such distribution-drift.\nAn exhaustive testing was performed against both real-world and synthesized\ntime-series. Experimental results show the competitiveness of the method in\ncomparison to state-of-the-art approaches for combining forecasters and\nhandling drift.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 10:21:37 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Chatterjee", "Anirban", ""], ["Paul", "Subhadip", ""], ["Dutta", "Uddipto", ""], ["Dey", "Smaranya", ""]]}, {"id": "2003.09312", "submitter": "Nitish Nag", "authors": "Nitish Nag", "title": "Health State Estimation", "comments": "Ph.D. Dissertation @ University of California, Irvine", "journal-ref": "Proquest 2020, 307 pages", "doi": null, "report-no": "27743502", "categories": "cs.AI cs.CY cs.HC q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Life's most valuable asset is health. Continuously understanding the state of\nour health and modeling how it evolves is essential if we wish to improve it.\nGiven the opportunity that people live with more data about their life today\nthan any other time in history, the challenge rests in interweaving this data\nwith the growing body of knowledge to compute and model the health state of an\nindividual continually. This dissertation presents an approach to build a\npersonal model and dynamically estimate the health state of an individual by\nfusing multi-modal data and domain knowledge. The system is stitched together\nfrom four essential abstraction elements: 1. the events in our life, 2. the\nlayers of our biological systems (from molecular to an organism), 3. the\nfunctional utilities that arise from biological underpinnings, and 4. how we\ninteract with these utilities in the reality of daily life. Connecting these\nfour elements via graph network blocks forms the backbone by which we\ninstantiate a digital twin of an individual. Edges and nodes in this graph\nstructure are then regularly updated with learning techniques as data is\ncontinuously digested. Experiments demonstrate the use of dense and\nheterogeneous real-world data from a variety of personal and environmental\nsensors to monitor individual cardiovascular health state. State estimation and\nindividual modeling is the fundamental basis to depart from disease-oriented\napproaches to a total health continuum paradigm. Precision in predicting health\nrequires understanding state trajectory. By encasing this estimation within a\nnavigational approach, a systematic guidance framework can plan actions to\ntransition a current state towards a desired one. This work concludes by\npresenting this framework of combining the health state and personal graph\nmodel to perpetually plan and assist us in living life towards our goals.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 21:06:32 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Nag", "Nitish", ""]]}, {"id": "2003.09340", "submitter": "Khalil Ghorbal", "authors": "Joan Thibault and Khalil Ghorbal", "title": "Ordered Functional Decision Diagrams: A Functional Semantics For Binary\n  Decision Diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel framework, termed $\\lambda$DD, that revisits Binary\nDecision Diagrams from a purely functional point of view. The framework allows\nto classify the already existing variants, including the most recent ones like\nChain-DD and ESRBDD, as implementations of a special class of ordered models.\nWe enumerate, in a principled way, all the models of this class and isolate its\nmost expressive model. This new model, termed $\\lambda$DD-O-NUCX, is suitable\nfor both dense and sparse Boolean functions, and is moreover invariant by\nnegation. The canonicity of $\\lambda$DD-O-NUCX is formally verified using the\nCoq proof assistant. We furthermore give bounds on the size of the different\ndiagrams: the potential gain achieved by more expressive models can be at most\nlinear in the number of variables n.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 15:46:48 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 12:29:45 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 21:54:58 GMT"}, {"version": "v4", "created": "Tue, 21 Jul 2020 22:09:07 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Thibault", "Joan", ""], ["Ghorbal", "Khalil", ""]]}, {"id": "2003.09354", "submitter": "Varun Tolani", "authors": "Varun Tolani, Somil Bansal, Aleksandra Faust, Claire Tomlin", "title": "Visual Navigation Among Humans with Optimal Control as a Supervisor", "comments": "Project Website: https://smlbansal.github.io/LB-WayPtNav-DH/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real world visual navigation requires robots to operate in unfamiliar,\nhuman-occupied dynamic environments. Navigation around humans is especially\ndifficult because it requires anticipating their future motion, which can be\nquite challenging. We propose an approach that combines learning-based\nperception with model-based optimal control to navigate among humans based only\non monocular, first-person RGB images. Our approach is enabled by our novel\ndata-generation tool, HumANav that allows for photorealistic renderings of\nindoor environment scenes with humans in them, which are then used to train the\nperception module entirely in simulation. Through simulations and experiments\non a mobile robot, we demonstrate that the learned navigation policies can\nanticipate and react to humans without explicitly predicting future human\nmotion, generalize to previously unseen environments and human behaviors, and\ntransfer directly from simulation to reality. Videos describing our approach\nand experiments, as well as a demo of HumANav are available on the project\nwebsite.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 16:13:47 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 21:09:24 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Tolani", "Varun", ""], ["Bansal", "Somil", ""], ["Faust", "Aleksandra", ""], ["Tomlin", "Claire", ""]]}, {"id": "2003.09384", "submitter": "Anthony Constantinou", "authors": "Anthony Constantinou", "title": "Asian Handicap football betting with Rating-based Hybrid Bayesian\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the massive popularity of the Asian Handicap (AH) football betting\nmarket, it has not been adequately studied by the relevant literature. This\npaper combines rating systems with hybrid Bayesian networks and presents the\nfirst published model specifically developed for prediction and assessment of\nthe AH betting market. The results are based on 13 English Premier League\nseasons and are compared to the traditional 1X2 market. Different betting\nsituations have been examined including a) both average and maximum (best\navailable) market odds, b) all possible betting decision thresholds between\npredicted and published odds, c) optimisations for both return-on-investment\nand profit, and d) simple stake adjustments to investigate how the variance of\nreturns changes when targeting equivalent profit in both 1X2 and AH markets.\nWhile the AH market is found to share the inefficiencies of the traditional 1X2\nmarket, the findings reveal both interesting differences as well as\nsimilarities between the two.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 09:50:07 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Constantinou", "Anthony", ""]]}, {"id": "2003.09443", "submitter": "Tristan Karch", "authors": "Tristan Karch, C\\'edric Colas, Laetitia Teodorescu, Cl\\'ement\n  Moulin-Frier and Pierre-Yves Oudeyer", "title": "Deep Sets for Generalization in RL", "comments": "15 pages, 10 figures, published as a workshop Paper at ICLR: Beyond\n  tabula rasa in RL (BeTR-RL). arXiv admin note: substantial text overlap with\n  arXiv:2002.09253", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the idea of encoding object-centered representations\nin the design of the reward function and policy architectures of a\nlanguage-guided reinforcement learning agent. This is done using a combination\nof object-wise permutation invariant networks inspired from Deep Sets and\ngated-attention mechanisms. In a 2D procedurally-generated world where agents\ntargeting goals in natural language navigate and interact with objects, we show\nthat these architectures demonstrate strong generalization capacities to\nout-of-distribution goals. We study the generalization to varying numbers of\nobjects at test time and further extend the object-centered architectures to\ngoals involving relational reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 18:22:40 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Karch", "Tristan", ""], ["Colas", "C\u00e9dric", ""], ["Teodorescu", "Laetitia", ""], ["Moulin-Frier", "Cl\u00e9ment", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2003.09504", "submitter": "Fahad Sohrab", "authors": "Fahad Sohrab, Jenni Raitoharju, Alexandros Iosifidis, Moncef Gabbouj", "title": "Ellipsoidal Subspace Support Vector Data Description", "comments": null, "journal-ref": "IEEE Access, vol. 8, pp. 122013-122025, 2020", "doi": "10.1109/ACCESS.2020.3007123", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel method for transforming data into a\nlow-dimensional space optimized for one-class classification. The proposed\nmethod iteratively transforms data into a new subspace optimized for\nellipsoidal encapsulation of target class data. We provide both linear and\nnon-linear formulations for the proposed method. The method takes into account\nthe covariance of the data in the subspace; hence, it yields a more generalized\nsolution as compared to Subspace Support Vector Data Description for a\nhypersphere. We propose different regularization terms expressing the class\nvariance in the projected space. We compare the results with classic and\nrecently proposed one-class classification methods and achieve better results\nin the majority of cases. The proposed method is also noticed to converge much\nfaster than recently proposed Subspace Support Vector Data Description.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 21:31:03 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Sohrab", "Fahad", ""], ["Raitoharju", "Jenni", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2003.09529", "submitter": "Thibault Duhamel", "authors": "Thibault Duhamel, Mariane Maynard and Froduald Kabanza", "title": "Imagination-Augmented Deep Learning for Goal Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to infer the goal of people we observe, interact with, or read\nstories about is one of the hallmarks of human intelligence. A prominent idea\nin current goal-recognition research is to infer the likelihood of an agent's\ngoal from the estimations of the costs of plans to the different goals the\nagent might have. Different approaches implement this idea by relying only on\nhandcrafted symbolic representations. Their application to real-world settings\nis, however, quite limited, mainly because extracting rules for the factors\nthat influence goal-oriented behaviors remains a complicated task. In this\npaper, we introduce a novel idea of using a symbolic planner to compute\nplan-cost insights, which augment a deep neural network with an imagination\ncapability, leading to improved goal recognition accuracy in real and synthetic\ndomains compared to a symbolic recognizer or a deep-learning goal recognizer\nalone.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 23:07:34 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Duhamel", "Thibault", ""], ["Maynard", "Mariane", ""], ["Kabanza", "Froduald", ""]]}, {"id": "2003.09534", "submitter": "Yan  Li", "authors": "Qianli Shen, Yan Li, Haoming Jiang, Zhaoran Wang, Tuo Zhao", "title": "Deep Reinforcement Learning with Robust and Smooth Policy", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) has achieved great empirical successes in\nvarious domains. However, the large search space of neural networks requires a\nlarge amount of data, which makes the current RL algorithms not sample\nefficient. Motivated by the fact that many environments with continuous state\nspace have smooth transitions, we propose to learn a smooth policy that behaves\nsmoothly with respect to states. We develop a new framework -- \\textbf{S}mooth\n\\textbf{R}egularized \\textbf{R}einforcement \\textbf{L}earning\n($\\textbf{SR}^2\\textbf{L}$), where the policy is trained with\nsmoothness-inducing regularization. Such regularization effectively constrains\nthe search space, and enforces smoothness in the learned policy. Moreover, our\nproposed framework can also improve the robustness of policy against\nmeasurement error in the state space, and can be naturally extended to\ndistribubutionally robust setting. We apply the proposed framework to both\non-policy (TRPO) and off-policy algorithm (DDPG). Through extensive\nexperiments, we demonstrate that our method achieves improved sample efficiency\nand robustness.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 00:10:29 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 02:11:26 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 23:30:52 GMT"}, {"version": "v4", "created": "Sat, 15 Aug 2020 02:20:17 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Shen", "Qianli", ""], ["Li", "Yan", ""], ["Jiang", "Haoming", ""], ["Wang", "Zhaoran", ""], ["Zhao", "Tuo", ""]]}, {"id": "2003.09553", "submitter": "Sayna Ebrahimi", "authors": "Sayna Ebrahimi, Franziska Meier, Roberto Calandra, Trevor Darrell,\n  Marcus Rohrbach", "title": "Adversarial Continual Learning", "comments": "Accepted at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning aims to learn new tasks without forgetting previously\nlearned ones. We hypothesize that representations learned to solve each task in\na sequence have a shared structure while containing some task-specific\nproperties. We show that shared features are significantly less prone to\nforgetting and propose a novel hybrid continual learning framework that learns\na disjoint representation for task-invariant and task-specific features\nrequired to solve a sequence of tasks. Our model combines architecture growth\nto prevent forgetting of task-specific skills and an experience replay approach\nto preserve shared skills. We demonstrate our hybrid approach is effective in\navoiding forgetting and show it is superior to both architecture-based and\nmemory-based approaches on class incrementally learning of a single dataset as\nwell as a sequence of multiple datasets in image classification. Our code is\navailable at\n\\url{https://github.com/facebookresearch/Adversarial-Continual-Learning}.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 02:08:17 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 15:42:20 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Ebrahimi", "Sayna", ""], ["Meier", "Franziska", ""], ["Calandra", "Roberto", ""], ["Darrell", "Trevor", ""], ["Rohrbach", "Marcus", ""]]}, {"id": "2003.09579", "submitter": "Tai Vu", "authors": "Tai Vu, Leon Tran", "title": "FlapAI Bird: Training an Agent to Play Flappy Bird Using Reinforcement\n  Learning Techniques", "comments": "typos corrected, references added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning is one of the most popular approaches for automated\ngame playing. This method allows an agent to estimate the expected utility of\nits state in order to make optimal actions in an unknown environment. We seek\nto apply reinforcement learning algorithms to the game Flappy Bird. We\nimplement SARSA and Q-Learning with some modifications such as\n$\\epsilon$-greedy policy, discretization and backward updates. We find that\nSARSA and Q-Learning outperform the baseline, regularly achieving scores of\n1400+, with the highest in-game score of 2069.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 05:27:36 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 09:03:35 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Vu", "Tai", ""], ["Tran", "Leon", ""]]}, {"id": "2003.09643", "submitter": "Eduardo C\\'esar Garrido-Merch\\'an", "authors": "Eduardo C. Garrido Merch\\'an, Luis C. Jariego P\\'erez", "title": "Towards Automatic Bayesian Optimization: A first step involving\n  acquisition functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimization is the state of the art technique for the optimization\nof black boxes, i.e., functions where we do not have access to their analytical\nexpression nor its gradients, they are expensive to evaluate and its evaluation\nis noisy. The most popular application of bayesian optimization is the\nautomatic hyperparameter tuning of machine learning algorithms, where we obtain\nthe best configuration of machine learning algorithms by optimizing the\nestimation of the generalization error of these algorithms. Despite being\napplied with success, bayesian optimization methodologies also have\nhyperparameters that need to be configured such as the probabilistic surrogate\nmodel or the acquisition function used. A bad decision over the configuration\nof these hyperparameters implies obtaining bad quality results. Typically,\nthese hyperparameters are tuned by making assumptions of the objective function\nthat we want to evaluate but there are scenarios where we do not have any prior\ninformation about the objective function. In this paper, we propose a first\nattempt over automatic bayesian optimization by exploring several heuristics\nthat automatically tune the acquisition function of bayesian optimization. We\nillustrate the effectiveness of these heurisitcs in a set of benchmark problems\nand a hyperparameter tuning problem of a machine learning algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 12:22:45 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 15:48:37 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Merch\u00e1n", "Eduardo C. Garrido", ""], ["P\u00e9rez", "Luis C. Jariego", ""]]}, {"id": "2003.09660", "submitter": "Zitao Liu", "authors": "Yang Hao, Wenbiao Ding, Zitao Liu", "title": "NeuCrowd: Neural Sampling Network for Representation Learning with\n  Crowdsourced Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning approaches require a massive amount of discriminative\ntraining data, which is unavailable in many scenarios, such as healthcare,\nsmart city, education, etc. In practice, people refer to crowdsourcing to get\nannotated labels. However, due to issues like data privacy, budget limitation,\nshortage of domain-specific annotators, the number of crowdsourced labels is\nstill very limited. Moreover, because of annotators' diverse expertises,\ncrowdsourced labels are often inconsistent. Thus, directly applying existing\nsupervised representation learning (SRL) algorithms may easily get the\noverfitting problem and yield suboptimal solutions. In this paper, we propose\n\\emph{NeuCrowd}, a unified framework for SRL from crowdsourced labels. The\nproposed framework (1) creates a sufficient number of high-quality\n\\emph{n}-tuplet training samples by utilizing safety-aware sampling and robust\nanchor generation; and (2) automatically learns a neural sampling network that\nadaptively learns to select effective samples for SRL networks. The proposed\nframework is evaluated on both one synthetic and three real-world data sets.\nThe results show that our approach outperforms a wide range of state-of-the-art\nbaselines in terms of prediction accuracy and AUC. To encourage the\nreproducible results, we make our code publicly available at\n\\url{https://github.com/crowd-data-mining/NeuCrowd}.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 13:38:18 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 15:46:33 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 02:02:24 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Hao", "Yang", ""], ["Ding", "Wenbiao", ""], ["Liu", "Zitao", ""]]}, {"id": "2003.09661", "submitter": "Xinyang Deng", "authors": "Xinyang Deng", "title": "Basic concepts, definitions, and methods in D number theory", "comments": "28 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a generalization of Dempster-Shafer theory, D number theory (DNT) aims to\nprovide a framework to deal with uncertain information with non-exclusiveness\nand incompleteness. Although there are some advances on DNT in previous\nstudies, however, they lack of systematicness, and many important issues have\nnot yet been solved. In this paper, several crucial aspects in constructing a\nperfect and systematic framework of DNT are considered. At first the\nnon-exclusiveness in DNT is formally defined and discussed. Secondly, a method\nto combine multiple D numbers is proposed by extending previous exclusive\nconflict redistribution (ECR) rule. Thirdly, a new pair of belief and\nplausibility measures for D numbers are defined and many desirable properties\nare satisfied by the proposed measures. Fourthly, the combination of\ninformation-incomplete D numbers is studied specially to show how to deal with\nthe incompleteness of information in DNT. In this paper, we mainly give\nrelative math definitions, properties, and theorems, concrete examples and\napplications will be considered in the future study.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 13:42:29 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Deng", "Xinyang", ""]]}, {"id": "2003.09698", "submitter": "Mario Alviano", "authors": "Mario Alviano and Marco Manna", "title": "Large-scale Ontological Reasoning via Datalog", "comments": "15 pages, 2 tables, 1 figure, 2 algorithms, under review for the book\n  Studies on the Semantic Web Series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning over OWL 2 is a very expensive task in general, and therefore the\nW3C identified tractable profiles exhibiting good computational properties.\nOntological reasoning for many fragments of OWL 2 can be reduced to the\nevaluation of Datalog queries. This paper surveys some of these compilations,\nand in particular the one addressing queries over Horn-$\\mathcal{SHIQ}$\nknowledge bases and its implementation in DLV2 enanched by a new version of the\nMagic Sets algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 16:51:02 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Alviano", "Mario", ""], ["Manna", "Marco", ""]]}, {"id": "2003.09712", "submitter": "Adish Singla", "authors": "Rati Devidze, Farnam Mansouri, Luis Haug, Yuxin Chen, Adish Singla", "title": "Understanding the Power and Limitations of Teaching with Imperfect\n  Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine teaching studies the interaction between a teacher and a\nstudent/learner where the teacher selects training examples for the learner to\nlearn a specific task. The typical assumption is that the teacher has perfect\nknowledge of the task---this knowledge comprises knowing the desired learning\ntarget, having the exact task representation used by the learner, and knowing\nthe parameters capturing the learning dynamics of the learner. Inspired by\nreal-world applications of machine teaching in education, we consider the\nsetting where teacher's knowledge is limited and noisy, and the key research\nquestion we study is the following: When does a teacher succeed or fail in\neffectively teaching a learner using its imperfect knowledge? We answer this\nquestion by showing connections to how imperfect knowledge affects the\nteacher's solution of the corresponding machine teaching problem when\nconstructing optimal teaching sets. Our results have important implications for\ndesigning robust teaching algorithms for real-world applications.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 17:53:26 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Devidze", "Rati", ""], ["Mansouri", "Farnam", ""], ["Haug", "Luis", ""], ["Chen", "Yuxin", ""], ["Singla", "Adish", ""]]}, {"id": "2003.09746", "submitter": "Shushman Choudhury", "authors": "Shushman Choudhury, Nate Gruver, Mykel J. Kochenderfer", "title": "Adaptive Informative Path Planning with Multimodal Sensing", "comments": "First two authors contributed equally; International Conference on\n  Automated Planning and Scheduling (ICAPS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive Informative Path Planning (AIPP) problems model an agent tasked with\nobtaining information subject to resource constraints in unknown, partially\nobservable environments. Existing work on AIPP has focused on representing\nobservations about the world as a result of agent movement. We formulate the\nmore general setting where the agent may choose between different sensors at\nthe cost of some energy, in addition to traversing the environment to gather\ninformation. We call this problem AIPPMS (MS for Multimodal Sensing). AIPPMS\nrequires reasoning jointly about the effects of sensing and movement in terms\nof both energy expended and information gained. We frame AIPPMS as a Partially\nObservable Markov Decision Process (POMDP) and solve it with online planning.\nOur approach is based on the Partially Observable Monte Carlo Planning\nframework with modifications to ensure constraint feasibility and a heuristic\nrollout policy tailored for AIPPMS. We evaluate our method on two domains: a\nsimulated search-and-rescue scenario and a challenging extension to the classic\nRockSample problem. We find that our approach outperforms a classic AIPP\nalgorithm that is modified for AIPPMS, as well as online planning using a\nrandom rollout policy.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 20:28:57 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Choudhury", "Shushman", ""], ["Gruver", "Nate", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2003.09772", "submitter": "Mo Yu", "authors": "Shiyu Chang, Yang Zhang, Mo Yu, Tommi S. Jaakkola", "title": "Invariant Rationalization", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selective rationalization improves neural network interpretability by\nidentifying a small subset of input features -- the rationale -- that best\nexplains or supports the prediction. A typical rationalization criterion, i.e.\nmaximum mutual information (MMI), finds the rationale that maximizes the\nprediction performance based only on the rationale. However, MMI can be\nproblematic because it picks up spurious correlations between the input\nfeatures and the output. Instead, we introduce a game-theoretic invariant\nrationalization criterion where the rationales are constrained to enable the\nsame predictor to be optimal across different environments. We show both\ntheoretically and empirically that the proposed rationales can rule out\nspurious correlations, generalize better to different test scenarios, and align\nbetter with human judgments. Our data and code are available.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 00:50:27 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Chang", "Shiyu", ""], ["Zhang", "Yang", ""], ["Yu", "Mo", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "2003.09868", "submitter": "Nilanjan  Dey", "authors": "Simon James Fong, Gloria Li, Nilanjan Dey, Ruben Gonzalez Crespo,\n  Enrique Herrera-Viedma", "title": "Composite Monte Carlo Decision Making under High Uncertainty of Novel\n  Coronavirus Epidemic Using Hybridized Deep Learning and Fuzzy Rule Induction", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.PE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the advent of the novel coronavirus epidemic since December 2019,\ngovernments and authorities have been struggling to make critical decisions\nunder high uncertainty at their best efforts. Composite Monte-Carlo (CMC)\nsimulation is a forecasting method which extrapolates available data which are\nbroken down from multiple correlated/casual micro-data sources into many\npossible future outcomes by drawing random samples from some probability\ndistributions. For instance, the overall trend and propagation of the infested\ncases in China are influenced by the temporal-spatial data of the nearby cities\naround the Wuhan city (where the virus is originated from), in terms of the\npopulation density, travel mobility, medical resources such as hospital beds\nand the timeliness of quarantine control in each city etc. Hence a CMC is\nreliable only up to the closeness of the underlying statistical distribution of\na CMC, that is supposed to represent the behaviour of the future events, and\nthe correctness of the composite data relationships. In this paper, a case\nstudy of using CMC that is enhanced by deep learning network and fuzzy rule\ninduction for gaining better stochastic insights about the epidemic development\nis experimented. Instead of applying simplistic and uniform assumptions for a\nMC which is a common practice, a deep learning-based CMC is used in conjunction\nof fuzzy rule induction techniques. As a result, decision makers are benefited\nfrom a better fitted MC outputs complemented by min-max rules that foretell\nabout the extreme ranges of future possibilities with respect to the epidemic.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 11:58:43 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Fong", "Simon James", ""], ["Li", "Gloria", ""], ["Dey", "Nilanjan", ""], ["Crespo", "Ruben Gonzalez", ""], ["Herrera-Viedma", "Enrique", ""]]}, {"id": "2003.09963", "submitter": "Mohammed Ibrahim", "authors": "Mohammed Salah Ibrahim and Doaa Waleed Al-Dulaimee", "title": "Design Multimedia Expert Diagnosing Diseases System Using Fuzzy Logic\n  (MEDDSFL)", "comments": "arXiv admin: text overlap with arXiv:1006.4544, arXiv:1401.0245 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we designed an efficient expert system to diagnose diseases for\nhuman beings. The system depended on several clinical features for different\ndiseases which will be used as knowledge base for this system. We used fuzzy\nlogic system which is one of the most expert systems techniques that used in\nbuilding knowledge base of expert systems. Fuzzy logic will be used to\ninference the results of disease diagnosing. We also provided the system with\nmultimedia such as videos, pictures and information for most of disease that\nhave been achieved in our system. The system implemented using Matlab ToolBox\nand fifteen diseases were studied. Five cases for normal, affected and\nunaffected people's different diseases have been tested on this system. The\nresults show that system was able to predict the status whether a human has a\ndisease or not accurately. All system results are reported in tables and\ndiscussed in detail.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 18:28:13 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Ibrahim", "Mohammed Salah", ""], ["Al-Dulaimee", "Doaa Waleed", ""]]}, {"id": "2003.10011", "submitter": "Yusheng Xiang", "authors": "Yusheng Xiang and Marcus Geimer", "title": "Optimization of Operation Strategy for Primary Torque based hydrostatic\n  Drivetrain using Artificial Intelligence", "comments": "9 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new primary torque control concept for hydrostatics mobile machines was\nintroduced in 2018. The mentioned concept controls the pressure in a closed\ncircuit by changing the angle of the hydraulic pump to achieve the desired\npressure based on a feedback system. Thanks to this concept, a series of\nadvantages are expected. However, while working in a Y cycle, the primary\ntorque-controlled wheel loader has worse performance in efficiency compared to\nsecondary controlled earthmover due to lack of recuperation ability.\nAlternatively, we use deep learning algorithms to improve machines'\nregeneration performance. In this paper, we firstly make a potential analysis\nto show the benefit by utilizing the regeneration process, followed by\nproposing a series of CRDNNs, which combine CNN, RNN, and DNN, to precisely\ndetect Y cycles. Compared to existing algorithms, the CRDNN with bi-directional\nLSTMs has the best accuracy, and the CRDNN with LSTMs has a comparable\nperformance but much fewer training parameters. Based on our dataset including\n119 truck loading cycles, our best neural network shows a 98.2% test accuracy.\nTherefore, even with a simple regeneration process, our algorithm can improve\nthe holistic efficiency of mobile machines up to 9% during Y cycle processes if\nprimary torque concept is used.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 22:16:39 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 13:49:26 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Xiang", "Yusheng", ""], ["Geimer", "Marcus", ""]]}, {"id": "2003.10024", "submitter": "Tristan Cazenave", "authors": "Tristan Cazenave", "title": "Generalized Nested Rollout Policy Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nested Rollout Policy Adaptation (NRPA) is a Monte Carlo search algorithm for\nsingle player games. In this paper we propose to generalize NRPA with a\ntemperature and a bias and to analyze theoretically the algorithms. The\ngeneralized algorithm is named GNRPA. Experiments show it improves on NRPA for\ndifferent application domains: SameGame and the Traveling Salesman Problem with\nTime Windows.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 23:12:18 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Cazenave", "Tristan", ""]]}, {"id": "2003.10025", "submitter": "Ion Matei Dr.", "authors": "Ion Matei, Johan de Kleer, Christoforos Somarakis, Rahul Rai and John\n  S. Baras", "title": "Interpretable machine learning models: a physics-based view", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand changes in physical systems and facilitate decisions,\nexplaining how model predictions are made is crucial. We use model-based\ninterpretability, where models of physical systems are constructed by composing\nbasic constructs that explain locally how energy is exchanged and transformed.\nWe use the port Hamiltonian (p-H) formalism to describe the basic constructs\nthat contain physically interpretable processes commonly found in the behavior\nof physical systems. We describe how we can build models out of the p-H\nconstructs and how we can train them. In addition we show how we can impose\nphysical properties such as dissipativity that ensure numerical stability of\nthe training process. We give examples on how to build and train models for\ndescribing the behavior of two physical systems: the inverted pendulum and\nswarm dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 23:17:19 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Matei", "Ion", ""], ["de Kleer", "Johan", ""], ["Somarakis", "Christoforos", ""], ["Rai", "Rahul", ""], ["Baras", "John S.", ""]]}, {"id": "2003.10073", "submitter": "Hideyoshi Yanagisawa", "authors": "Hideyoshi Yanagisawa", "title": "Information-Theoretic Free Energy as Emotion Potential: Emotional\n  Valence as a Function of Complexity and Novelty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study extends the mathematical model of emotion dimensions that we\npreviously proposed (Yanagisawa, et al. 2019, Front Comput Neurosci) to\nconsider perceived complexity as well as novelty, as a source of arousal\npotential. Berlyne's hedonic function of arousal potential (or the inverse\nU-shaped curve, the so-called Wundt curve) is assumed. We modeled the arousal\npotential as information contents to be processed in the brain after sensory\nstimuli are perceived (or recognized), which we termed sensory surprisal. We\nmathematically demonstrated that sensory surprisal represents free energy, and\nit is equivalent to a summation of information gain (or information from\nnovelty) and perceived complexity (or information from complexity), which are\nthe collative variables forming the arousal potential. We demonstrated\nempirical evidence with visual stimuli (profile shapes of butterfly) supporting\nthe hypothesis that the summation of perceived novelty and complexity shapes\nthe inverse U-shaped beauty function. We discussed the potential of free energy\nas a mathematical principle explaining emotion initiators.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 04:10:23 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Yanagisawa", "Hideyoshi", ""]]}, {"id": "2003.10212", "submitter": "Jerrin Thomas Panachakel", "authors": "Jerrin Thomas Panachakel, Nandagopal Netrakanti Vinayak, Maanvi Nunna,\n  A.G. Ramakrishnan and Kanishka Sharma", "title": "An Improved EEG Acquisition Protocol Facilitates Localized Neural\n  Activation", "comments": "Preprint of the paper presented at ComNet 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes improvements in the electroencephalogram (EEG) recording\nprotocols for motor imagery through the introduction of actual motor movement\nand/or somatosensory cues. The results obtained demonstrate the advantage of\nrequiring the subjects to perform motor actions following the trials of\nimagery. By introducing motor actions in the protocol, the subjects are able to\nperform actual motor planning, rather than just visualizing the motor movement,\nthus greatly improving the ease with which the motor movements can be imagined.\nThis study also probes the added advantage of administering somatosensory cues\nin the subject, as opposed to the conventional auditory/visual cues. These\nchanges in the protocol show promise in terms of the aptness of the spatial\nfilters obtained on the data, on application of the well-known common spatial\npattern (CSP) algorithms. The regions highlighted by the spatial filters are\nmore localized and consistent across the subjects when the protocol is\naugmented with somatosensory stimuli. Hence, we suggest that this may prove to\nbe a better EEG acquisition protocol for detecting brain activation in response\nto intended motor commands in (clinically) paralyzed/locked-in patients.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 04:46:40 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Panachakel", "Jerrin Thomas", ""], ["Vinayak", "Nandagopal Netrakanti", ""], ["Nunna", "Maanvi", ""], ["Ramakrishnan", "A. G.", ""], ["Sharma", "Kanishka", ""]]}, {"id": "2003.10249", "submitter": "Mohammad Etemad", "authors": "Mohammad Etemad, Nader Zare, Mahtab Sarvmaili, Amilcar Soares, Bruno\n  Brandoli Machado, Stan Matwin", "title": "Using Deep Reinforcement Learning Methods for Autonomous Vessels in 2D\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned Surface Vehicles technology (USVs) is an exciting topic that\nessentially deploys an algorithm to safely and efficiently performs a mission.\nAlthough reinforcement learning is a well-known approach to modeling such a\ntask, instability and divergence may occur when combining off-policy and\nfunction approximation. In this work, we used deep reinforcement learning\ncombining Q-learning with a neural representation to avoid instability. Our\nmethodology uses deep q-learning and combines it with a rolling wave planning\napproach on agile methodology. Our method contains two critical parts in order\nto perform missions in an unknown environment. The first is a path planner that\nis responsible for generating a potential effective path to a destination\nwithout considering the details of the root. The latter is a decision-making\nmodule that is responsible for short-term decisions on avoiding obstacles\nduring the near future steps of USV exploitation within the context of the\nvalue function. Simulations were performed using two algorithms: a basic\nvanilla vessel navigator (VVN) as a baseline and an improved one for the vessel\nnavigator with a planner and local view (VNPLV). Experimental results show that\nthe proposed method enhanced the performance of VVN by 55.31 on average for\nlong-distance missions. Our model successfully demonstrated obstacle avoidance\nby means of deep reinforcement learning using planning adaptive paths in\nunknown environments.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 12:58:58 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Etemad", "Mohammad", ""], ["Zare", "Nader", ""], ["Sarvmaili", "Mahtab", ""], ["Soares", "Amilcar", ""], ["Machado", "Bruno Brandoli", ""], ["Matwin", "Stan", ""]]}, {"id": "2003.10286", "submitter": "Xuehai He", "authors": "Xuehai He, Yichen Zhang, Luntian Mou, Eric Xing, Pengtao Xie", "title": "PathVQA: 30000+ Questions for Medical Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is it possible to develop an \"AI Pathologist\" to pass the board-certified\nexamination of the American Board of Pathology? To achieve this goal, the first\nstep is to create a visual question answering (VQA) dataset where the AI agent\nis presented with a pathology image together with a question and is asked to\ngive the correct answer. Our work makes the first attempt to build such a\ndataset. Different from creating general-domain VQA datasets where the images\nare widely accessible and there are many crowdsourcing workers available and\ncapable of generating question-answer pairs, developing a medical VQA dataset\nis much more challenging. First, due to privacy concerns, pathology images are\nusually not publicly available. Second, only well-trained pathologists can\nunderstand pathology images, but they barely have time to help create datasets\nfor AI research. To address these challenges, we resort to pathology textbooks\nand online digital libraries. We develop a semi-automated pipeline to extract\npathology images and captions from textbooks and generate question-answer pairs\nfrom captions using natural language processing. We collect 32,799 open-ended\nquestions from 4,998 pathology images where each question is manually checked\nto ensure correctness. To our best knowledge, this is the first dataset for\npathology VQA. Our dataset will be released publicly to promote research in\nmedical VQA.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 17:55:41 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["He", "Xuehai", ""], ["Zhang", "Yichen", ""], ["Mou", "Luntian", ""], ["Xing", "Eric", ""], ["Xie", "Pengtao", ""]]}, {"id": "2003.10294", "submitter": "Ryan Beal Mr.", "authors": "Ryan Beal, Georgios Chalkiadakis, Timothy J. Norman and Sarvapali D.\n  Ramchurn", "title": "Optimising Game Tactics for Football", "comments": "AAMAS 2020 Pre-Print Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel approach to optimise tactical and strategic\ndecision making in football (soccer). We model the game of football as a\nmulti-stage game which is made up from a Bayesian game to model the pre-match\ndecisions and a stochastic game to model the in-match state transitions and\ndecisions. Using this formulation, we propose a method to predict the\nprobability of game outcomes and the payoffs of team actions. Building upon\nthis, we develop algorithms to optimise team formation and in-game tactics with\ndifferent objectives. Empirical evaluation of our approach on real-world\ndatasets from 760 matches shows that by using optimised tactics from our\nBayesian and stochastic games, we can increase a team chances of winning by up\nto 16.1\\% and 3.4\\% respectively.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 14:24:45 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Beal", "Ryan", ""], ["Chalkiadakis", "Georgios", ""], ["Norman", "Timothy J.", ""], ["Ramchurn", "Sarvapali D.", ""]]}, {"id": "2003.10303", "submitter": "David Conal Higgins", "authors": "David Higgins and Vince I. Madai", "title": "From Bit To Bedside: A Practical Framework For Artificial Intelligence\n  Product Development In Healthcare", "comments": "30 pages, 4 figures", "journal-ref": "Advanced Intelligent Systems, 2020, 2000052", "doi": "10.1002/aisy.202000052", "report-no": null, "categories": "cs.CY cs.AI cs.HC stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Artificial Intelligence (AI) in healthcare holds great potential to expand\naccess to high-quality medical care, whilst reducing overall systemic costs.\nDespite hitting the headlines regularly and many publications of\nproofs-of-concept, certified products are failing to breakthrough to the\nclinic. AI in healthcare is a multi-party process with deep knowledge required\nin multiple individual domains. The lack of understanding of the specific\nchallenges in the domain is, therefore, the major contributor to the failure to\ndeliver on the big promises. Thus, we present a decision perspective framework,\nfor the development of AI-driven biomedical products, from conception to market\nlaunch. Our framework highlights the risks, objectives and key results which\nare typically required to proceed through a three-phase process to the market\nlaunch of a validated medical AI product. We focus on issues related to\nClinical validation, Regulatory affairs, Data strategy and Algorithmic\ndevelopment. The development process we propose for AI in healthcare software\nstrongly diverges from modern consumer software development processes. We\nhighlight the key time points to guide founders, investors and key stakeholders\nthroughout their relevant part of the process. Our framework should be seen as\na template for innovation frameworks, which can be used to coordinate team\ncommunications and responsibilities towards a reasonable product development\nroadmap, thus unlocking the potential of AI in medicine.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 14:42:18 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Higgins", "David", ""], ["Madai", "Vince I.", ""]]}, {"id": "2003.10325", "submitter": "Antoine Boutet", "authors": "Claude Rosin Ngueveu (UQAM), Antoine Boutet (PRIVATICS), Carole\n  Frindel (CREATIS), S\\'ebastien Gambs (UQAM), Th\\'eo Jourdan (CREATIS,\n  PRIVATICS), Claude Rosin", "title": "DYSAN: Dynamically sanitizing motion sensor data against sensitive\n  inferences through adversarial networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread adoption of the quantified self movement, an increasing\nnumber of users rely on mobile applications to monitor their physical activity\nthrough their smartphones. Granting to applications a direct access to sensor\ndata expose users to privacy risks. Indeed, usually these motion sensor data\nare transmitted to analytics applications hosted on the cloud leveraging\nmachine learning models to provide feedback on their health to users. However,\nnothing prevents the service provider to infer private and sensitive\ninformation about a user such as health or demographic attributes.In this\npaper, we present DySan, a privacy-preserving framework to sanitize motion\nsensor data against unwanted sensitive inferences (i.e., improving privacy)\nwhile limiting the loss of accuracy on the physical activity monitoring (i.e.,\nmaintaining data utility). To ensure a good trade-off between utility and\nprivacy, DySan leverages on the framework of Generative Adversarial Network\n(GAN) to sanitize the sensor data. More precisely, by learning in a competitive\nmanner several networks, DySan is able to build models that sanitize motion\ndata against inferences on a specified sensitive attribute (e.g., gender) while\nmaintaining a high accuracy on activity recognition. In addition, DySan\ndynamically selects the sanitizing model which maximize the privacy according\nto the incoming data. Experiments conducted on real datasets demonstrate that\nDySan can drasticallylimit the gender inference to 47% while only reducing the\naccuracy of activity recognition by 3%.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 15:16:43 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 13:57:46 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Ngueveu", "Claude Rosin", "", "UQAM"], ["Boutet", "Antoine", "", "PRIVATICS"], ["Frindel", "Carole", "", "CREATIS"], ["Gambs", "S\u00e9bastien", "", "UQAM"], ["Jourdan", "Th\u00e9o", "", "CREATIS,\n  PRIVATICS"], ["Rosin", "Claude", ""]]}, {"id": "2003.10365", "submitter": "Chris Michael", "authors": "Chris J. Michael, Dina Acklin, Jaelle Scheuerman", "title": "On Interactive Machine Learning and the Potential of Cognitive Feedback", "comments": "14 pages, 2 figures, submitted and accepted to the 2nd Workshop on\n  Deep Models and Artificial Intelligence for Defense Applications: Potentials,\n  Theories, Practices, Tools and Risks sponsored by the Association for the\n  Advancement of Artificial Intelligence in cooperation with the Stanford\n  University Computer Science Department", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to increase productivity, capability, and data exploitation,\nnumerous defense applications are experiencing an integration of\nstate-of-the-art machine learning and AI into their architectures. Especially\nfor defense applications, having a human analyst in the loop is of high\ninterest due to quality control, accountability, and complex subject matter\nexpertise not readily automated or replicated by AI. However, many applications\nare suffering from a very slow transition. This may be in large part due to\nlack of trust, usability, and productivity, especially when adapting to\nunforeseen classes and changes in mission context. Interactive machine learning\nis a newly emerging field in which machine learning implementations are\ntrained, optimized, evaluated, and exploited through an intuitive\nhuman-computer interface. In this paper, we introduce interactive machine\nlearning and explain its advantages and limitations within the context of\ndefense applications. Furthermore, we address several of the shortcomings of\ninteractive machine learning by discussing how cognitive feedback may inform\nfeatures, data, and results in the state of the art. We define the three\ntechniques by which cognitive feedback may be employed: self reporting,\nimplicit cognitive feedback, and modeled cognitive feedback. The advantages and\ndisadvantages of each technique are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 16:28:14 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Michael", "Chris J.", ""], ["Acklin", "Dina", ""], ["Scheuerman", "Jaelle", ""]]}, {"id": "2003.10378", "submitter": "James Goodman", "authors": "James Goodman and Simon Lucas", "title": "Weighting NTBEA for Game AI Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The N-Tuple Bandit Evolutionary Algorithm (NTBEA) has proven very effective\nin optimising algorithm parameters in Game AI. A potential weakness is the use\nof a simple average of all component Tuples in the model. This study\ninvestigates a refinement to the N-Tuple model used in NTBEA by weighting these\ncomponent Tuples by their level of information and specificity of match. We\nintroduce weighting functions to the model to obtain Weighted- NTBEA and test\nthis on four benchmark functions and two game environments. These tests show\nthat vanilla NTBEA is the most reliable and performant of the algorithms\ntested. Furthermore we show that given an iteration budget it is better to\nexecute several independent NTBEA runs, and use part of the budget to find the\nbest recommendation from these runs.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 16:44:28 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 14:52:11 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Goodman", "James", ""], ["Lucas", "Simon", ""]]}, {"id": "2003.10412", "submitter": "Caleb Belth", "authors": "Caleb Belth, Xinyi Zheng, Jilles Vreeken, Danai Koutra", "title": "What is Normal, What is Strange, and What is Missing in a Knowledge\n  Graph: Unified Characterization via Inductive Summarization", "comments": "10 pages, plus 2 pages of references. 5 figures. Accepted at The Web\n  Conference 2020", "journal-ref": null, "doi": "10.1145/3366423.3380189", "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge graphs (KGs) store highly heterogeneous information about the world\nin the structure of a graph, and are useful for tasks such as question\nanswering and reasoning. However, they often contain errors and are missing\ninformation. Vibrant research in KG refinement has worked to resolve these\nissues, tailoring techniques to either detect specific types of errors or\ncomplete a KG.\n  In this work, we introduce a unified solution to KG characterization by\nformulating the problem as unsupervised KG summarization with a set of\ninductive, soft rules, which describe what is normal in a KG, and thus can be\nused to identify what is abnormal, whether it be strange or missing. Unlike\nfirst-order logic rules, our rules are labeled, rooted graphs, i.e., patterns\nthat describe the expected neighborhood around a (seen or unseen) node, based\non its type, and information in the KG. Stepping away from the traditional\nsupport/confidence-based rule mining techniques, we propose KGist, Knowledge\nGraph Inductive SummarizaTion, which learns a summary of inductive rules that\nbest compress the KG according to the Minimum Description Length principle---a\nformulation that we are the first to use in the context of KG rule mining. We\napply our rules to three large KGs (NELL, DBpedia, and Yago), and tasks such as\ncompression, various types of error detection, and identification of incomplete\ninformation. We show that KGist outperforms task-specific, supervised and\nunsupervised baselines in error detection and incompleteness identification,\n(identifying the location of up to 93% of missing entities---over 10% more than\nbaselines), while also being efficient for large knowledge graphs.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 17:38:31 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Belth", "Caleb", ""], ["Zheng", "Xinyi", ""], ["Vreeken", "Jilles", ""], ["Koutra", "Danai", ""]]}, {"id": "2003.10423", "submitter": "Xiaolong Wang", "authors": "Qian Long, Zihan Zhou, Abhibav Gupta, Fei Fang, Yi Wu, Xiaolong Wang", "title": "Evolutionary Population Curriculum for Scaling Multi-Agent Reinforcement\n  Learning", "comments": "The project page is https://sites.google.com/view/epciclr2020 .The\n  source code is released at https://github.com/qian18long/epciclr2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent games, the complexity of the environment can grow\nexponentially as the number of agents increases, so it is particularly\nchallenging to learn good policies when the agent population is large. In this\npaper, we introduce Evolutionary Population Curriculum (EPC), a curriculum\nlearning paradigm that scales up Multi-Agent Reinforcement Learning (MARL) by\nprogressively increasing the population of training agents in a stage-wise\nmanner. Furthermore, EPC uses an evolutionary approach to fix an objective\nmisalignment issue throughout the curriculum: agents successfully trained in an\nearly stage with a small population are not necessarily the best candidates for\nadapting to later stages with scaled populations. Concretely, EPC maintains\nmultiple sets of agents in each stage, performs mix-and-match and fine-tuning\nover these sets and promotes the sets of agents with the best adaptability to\nthe next stage. We implement EPC on a popular MARL algorithm, MADDPG, and\nempirically show that our approach consistently outperforms baselines by a\nlarge margin as the number of agents grows exponentially.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 17:49:39 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Long", "Qian", ""], ["Zhou", "Zihan", ""], ["Gupta", "Abhibav", ""], ["Fang", "Fei", ""], ["Wu", "Yi", ""], ["Wang", "Xiaolong", ""]]}, {"id": "2003.10480", "submitter": "Andrea Loreggia", "authors": "Roberta Calegari, Andrea Loreggia, Emiliano Lorini, Francesca Rossi,\n  Giovanni Sartor", "title": "Modeling Contrary-to-Duty with CP-nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a ceteris-paribus semantics for deontic logic, a state of affairs where a\nlarger set of prescriptions is respected is preferable to a state of affairs\nwhere some of them are violated. Conditional preference nets (CP-nets) are a\ncompact formalism to express and analyse ceteris paribus preferences, which\nnice computational properties. This paper shows how deontic concepts can be\ncaptured through conditional preference models. A restricted deontic logic will\nbe defined, and mapped into conditional preference nets. We shall also show how\nto model contrary to duties obligations in CP-nets and how to capture in this\nformalism the distinction between strong and weak permission.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 18:23:18 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Calegari", "Roberta", ""], ["Loreggia", "Andrea", ""], ["Lorini", "Emiliano", ""], ["Rossi", "Francesca", ""], ["Sartor", "Giovanni", ""]]}, {"id": "2003.10520", "submitter": "Christopher Bamford", "authors": "Chris Bamford, Simon Lucas", "title": "Neural Game Engine: Accurate learning of generalizable forward models\n  from pixels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access to a fast and easily copied forward model of a game is essential for\nmodel-based reinforcement learning and for algorithms such as Monte Carlo tree\nsearch, and is also beneficial as a source of unlimited experience data for\nmodel-free algorithms. Learning forward models is an interesting and important\nchallenge in order to address problems where a model is not available. Building\nupon previous work on the Neural GPU, this paper introduces the Neural Game\nEngine, as a way to learn models directly from pixels. The learned models are\nable to generalise to different size game levels to the ones they were trained\non without loss of accuracy. Results on 10 deterministic General Video Game AI\ngames demonstrate competitive performance, with many of the games models being\nlearned perfectly both in terms of pixel predictions and reward predictions.\nThe pre-trained models are available through the OpenAI Gym interface and are\navailable publicly for future research here:\n\\url{https://github.com/Bam4d/Neural-Game-Engine}\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 20:04:55 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 20:50:35 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Bamford", "Chris", ""], ["Lucas", "Simon", ""]]}, {"id": "2003.10598", "submitter": "Hassam Sheikh", "authors": "Hassam Ullah Sheikh and Ladislau B\\\"ol\\\"oni", "title": "Multi-Agent Reinforcement Learning for Problems with Combined Individual\n  and Team Reward", "comments": "Accepted for publication at International Joint Conference on Neural\n  Networks (IJCNN-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many cooperative multi-agent problems require agents to learn individual\ntasks while contributing to the collective success of the group. This is a\nchallenging task for current state-of-the-art multi-agent reinforcement\nalgorithms that are designed to either maximize the global reward of the team\nor the individual local rewards. The problem is exacerbated when either of the\nrewards is sparse leading to unstable learning. To address this problem, we\npresent Decomposed Multi-Agent Deep Deterministic Policy Gradient (DE-MADDPG):\na novel cooperative multi-agent reinforcement learning framework that\nsimultaneously learns to maximize the global and local rewards. We evaluate our\nsolution on the challenging defensive escort team problem and show that our\nsolution achieves a significantly better and more stable performance than the\ndirect adaptation of the MADDPG algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 00:55:37 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Sheikh", "Hassam Ullah", ""], ["B\u00f6l\u00f6ni", "Ladislau", ""]]}, {"id": "2003.10768", "submitter": "Javier Del Ser Dr.", "authors": "Eneko Osaba, Aritz D. Martinez, Jesus L. Lobo, Javier Del Ser and\n  Francisco Herrera", "title": "Multifactorial Cellular Genetic Algorithm (MFCGA): Algorithmic Design,\n  Performance Comparison and Genetic Transferability Analysis", "comments": "Accepted for its presentation at WCCI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitasking optimization is an incipient research area which is lately\ngaining a notable research momentum. Unlike traditional optimization paradigm\nthat focuses on solving a single task at a time, multitasking addresses how\nmultiple optimization problems can be tackled simultaneously by performing a\nsingle search process. The main objective to achieve this goal efficiently is\nto exploit synergies between the problems (tasks) to be optimized, helping each\nother via knowledge transfer (thereby being referred to as Transfer\nOptimization). Furthermore, the equally recent concept of Evolutionary\nMultitasking (EM) refers to multitasking environments adopting concepts from\nEvolutionary Computation as their inspiration for the simultaneous solving of\nthe problems under consideration. As such, EM approaches such as the\nMultifactorial Evolutionary Algorithm (MFEA) has shown a remarkable success\nwhen dealing with multiple discrete, continuous, single-, and/or\nmulti-objective optimization problems. In this work we propose a novel\nalgorithmic scheme for Multifactorial Optimization scenarios - the\nMultifactorial Cellular Genetic Algorithm (MFCGA) - that hinges on concepts\nfrom Cellular Automata to implement mechanisms for exchanging knowledge among\nproblems. We conduct an extensive performance analysis of the proposed MFCGA\nand compare it to the canonical MFEA under the same algorithmic conditions and\nover 15 different multitasking setups (encompassing different reference\ninstances of the discrete Traveling Salesman Problem). A further contribution\nof this analysis beyond performance benchmarking is a quantitative examination\nof the genetic transferability among the problem instances, eliciting an\nempirical demonstration of the synergies emerged between the different\noptimization tasks along the MFCGA search process.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 11:03:55 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Osaba", "Eneko", ""], ["Martinez", "Aritz D.", ""], ["Lobo", "Jesus L.", ""], ["Del Ser", "Javier", ""], ["Herrera", "Francisco", ""]]}, {"id": "2003.10903", "submitter": "Bj\\\"orn Lindenberg", "authors": "Bj\\\"orn Lindenberg, Jonas Nordqvist, Karl-Olof Lindahl", "title": "Distributional Reinforcement Learning with Ensembles", "comments": "15 pages, 2 figures", "journal-ref": "Algorithms 2020, 13, 118", "doi": "10.3390/a13050118", "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that ensemble methods often provide enhanced performance in\nreinforcement learning. In this paper, we explore this concept further by using\ngroup-aided training within the distributional reinforcement learning paradigm.\nSpecifically, we propose an extension to categorical reinforcement learning,\nwhere distributional learning targets are implicitly based on the total\ninformation gathered by an ensemble. We empirically show that this may lead to\nmuch more robust initial learning, a stronger individual performance level, and\ngood efficiency on a per-sample basis.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 14:59:54 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 15:49:49 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Lindenberg", "Bj\u00f6rn", ""], ["Nordqvist", "Jonas", ""], ["Lindahl", "Karl-Olof", ""]]}, {"id": "2003.10910", "submitter": "Vikram Krishnamurthy", "authors": "Vikram Krishnamurthy", "title": "Quickest Change Detection of Time Inconsistent Anticipatory Agents.\n  Human-Sensor and Cyber-Physical Systems", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2021.3050977", "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In behavioral economics, human decision makers are modeled as anticipatory\nagents that make decisions by taking into account the probability of future\ndecisions (plans). We consider cyber-physical systems involving the interaction\nbetween anticipatory agents and statistical detection. A sensing device records\nthe decisions of an anticipatory agent. Given these decisions, how can the\nsensing device achieve quickest detection of a change in the anticipatory\nsystem? From a decision theoretic point of view, anticipatory models are time\ninconsistent meaning that Bellman's principle of optimality does not hold. The\nappropriate formalism is the subgame Nash equilibrium. We show that the\ninteraction between anticipatory agents and sequential quickest detection\nresults in unusual (nonconvex) structure of the quickest change detection\npolicy. Our methodology yields a useful framework for situation awareness\nsystems and anticipatory human decision makers interacting with sequential\ndetectors.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 15:50:32 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 03:27:20 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 11:23:16 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Krishnamurthy", "Vikram", ""]]}, {"id": "2003.10923", "submitter": "Omar Bouhamed", "authors": "Omar Bouhamed, Hakim Ghazzai, Hichem Besbes and Yehia Massoud", "title": "Autonomous UAV Navigation: A DDPG-based Deep Reinforcement Learning\n  Approach", "comments": "This paper is accepted for publication in IEEE International\n  Symposium on Circuits and Systems (ISCAS'20), Seville, Spain, Oct. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an autonomous UAV path planning framework using\ndeep reinforcement learning approach. The objective is to employ a self-trained\nUAV as a flying mobile unit to reach spatially distributed moving or static\ntargets in a given three dimensional urban area. In this approach, a Deep\nDeterministic Policy Gradient (DDPG) with continuous action space is designed\nto train the UAV to navigate through or over the obstacles to reach its\nassigned target. A customized reward function is developed to minimize the\ndistance separating the UAV and its destination while penalizing collisions.\nNumerical simulations investigate the behavior of the UAV in learning the\nenvironment and autonomously determining trajectories for different selected\nscenarios.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 19:33:00 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Bouhamed", "Omar", ""], ["Ghazzai", "Hakim", ""], ["Besbes", "Hichem", ""], ["Massoud", "Yehia", ""]]}, {"id": "2003.10942", "submitter": "Pascal Van Hentenryck", "authors": "Connor Riley and Pascal Van Hentenryck and Enpeng Yuan", "title": "Real-Time Dispatching of Large-Scale Ride-Sharing Systems: Integrating\n  Optimization, Machine Learning, and Model Predictive Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the dispatching of large-scale real-time ride-sharing\nsystems to address congestion issues faced by many cities. The goal is to serve\nall customers (service guarantees) with a small number of vehicles while\nminimizing waiting times under constraints on ride duration. This paper\nproposes an end-to-end approach that tightly integrates a state-of-the-art\ndispatching algorithm, a machine-learning model to predict zone-to-zone demand\nover time, and a model predictive control optimization to relocate idle\nvehicles. Experiments using historic taxi trips in New York City indicate that\nthis integration decreases average waiting times by about 30% over all test\ncases and reaches close to 55% on the largest instances for high-demand zones.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 16:05:25 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Riley", "Connor", ""], ["Van Hentenryck", "Pascal", ""], ["Yuan", "Enpeng", ""]]}, {"id": "2003.11001", "submitter": "Maxime Mulamba Ke Tchomba", "authors": "Maxime Mulamba, Jayanta Mandi, Rocsildes Canoy, Tias Guns", "title": "Hybrid Classification and Reasoning for Image-based Constraint Solving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increased interest in solving complex constrained problems where\npart of the input is not given as facts but received as raw sensor data such as\nimages or speech. We will use \"visual sudoku\" as a prototype problem, where the\ngiven cell digits are handwritten and provided as an image thereof. In this\ncase, one first has to train and use a classifier to label the images, so that\nthe labels can be used for solving the problem. In this paper, we explore the\nhybridization of classifying the images with the reasoning of a constraint\nsolver. We show that pure constraint reasoning on predictions does not give\nsatisfactory results. Instead, we explore the possibilities of a tighter\nintegration, by exposing the probabilistic estimates of the classifier to the\nconstraint solver. This allows joint inference on these probabilistic\nestimates, where we use the solver to find the maximum likelihood solution. We\nexplore the trade-off between the power of the classifier and the power of the\nconstraint reasoning, as well as further integration through the additional use\nof structural knowledge. Furthermore, we investigate the effect of calibration\nof the probabilistic estimates on the reasoning. Our results show that such\nhybrid approaches vastly outperform a separate approach, which encourages a\nfurther integration of prediction (probabilities) and constraint solving.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 17:39:49 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Mulamba", "Maxime", ""], ["Mandi", "Jayanta", ""], ["Canoy", "Rocsildes", ""], ["Guns", "Tias", ""]]}, {"id": "2003.11082", "submitter": "Claudia Schulz", "authors": "Claudia Schulz, Damir Juric", "title": "Can Embeddings Adequately Represent Medical Terminology? New Large-Scale\n  Medical Term Similarity Datasets Have the Answer!", "comments": "Accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of embeddings trained on medical data have emerged, but it\nremains unclear how well they represent medical terminology, in particular\nwhether the close relationship of semantically similar medical terms is encoded\nin these embeddings. To date, only small datasets for testing medical term\nsimilarity are available, not allowing to draw conclusions about the\ngeneralisability of embeddings to the enormous amount of medical terms used by\ndoctors. We present multiple automatically created large-scale medical term\nsimilarity datasets and confirm their high quality in an annotation study with\ndoctors. We evaluate state-of-the-art word and contextual embeddings on our new\ndatasets, comparing multiple vector similarity metrics and word vector\naggregation techniques. Our results show that current embeddings are limited in\ntheir ability to adequately encode medical terms. The novel datasets thus form\na challenging new benchmark for the development of medical embeddings able to\naccurately represent the whole medical terminology.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 19:18:34 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Schulz", "Claudia", ""], ["Juric", "Damir", ""]]}, {"id": "2003.11102", "submitter": "Pedro Braga", "authors": "Hansenclever F. Bassani, Renie A. Delgado, Jose Nilton de O. Lima\n  Junior, Heitor R. Medeiros, Pedro H. M. Braga and Alain Tapp", "title": "Learning to Play Soccer by Reinforcement and Applying Sim-to-Real to\n  Compete in the Real World", "comments": null, "journal-ref": "LatinX in AI Research Workshop at NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work presents an application of Reinforcement Learning (RL) for the\ncomplete control of real soccer robots of the IEEE Very Small Size Soccer\n(VSSS), a traditional league in the Latin American Robotics Competition (LARC).\nIn the VSSS league, two teams of three small robots play against each other. We\npropose a simulated environment in which continuous or discrete control\npolicies can be trained, and a Sim-to-Real method to allow using the obtained\npolicies to control a robot in the real world. The results show that the\nlearned policies display a broad repertoire of behaviors that are difficult to\nspecify by hand. This approach, called VSSS-RL, was able to beat the\nhuman-designed policy for the striker of the team ranked 3rd place in the 2018\nLARC, in 1-vs-1 matches.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 20:23:18 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Bassani", "Hansenclever F.", ""], ["Delgado", "Renie A.", ""], ["Junior", "Jose Nilton de O. Lima", ""], ["Medeiros", "Heitor R.", ""], ["Braga", "Pedro H. M.", ""], ["Tapp", "Alain", ""]]}, {"id": "2003.11118", "submitter": "Justin Gottschlich", "authors": "Fangke Ye, Shengtian Zhou, Anand Venkat, Ryan Marcus, Paul Petersen,\n  Jesmin Jahan Tithi, Tim Mattson, Tim Kraska, Pradeep Dubey, Vivek Sarkar,\n  Justin Gottschlich", "title": "Context-Aware Parse Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The simplified parse tree (SPT) presented in Aroma, a state-of-the-art code\nrecommendation system, is a tree-structured representation used to infer code\nsemantics by capturing program \\emph{structure} rather than program\n\\emph{syntax}. This is a departure from the classical abstract syntax tree,\nwhich is principally driven by programming language syntax. While we believe a\nsemantics-driven representation is desirable, the specifics of an SPT's\nconstruction can impact its performance. We analyze these nuances and present a\nnew tree structure, heavily influenced by Aroma's SPT, called a\n\\emph{context-aware parse tree} (CAPT). CAPT enhances SPT by providing a richer\nlevel of semantic representation. Specifically, CAPT provides additional\nbinding support for language-specific techniques for adding\nsemantically-salient features, and language-agnostic techniques for removing\nsyntactically-present but semantically-irrelevant features. Our research\nquantitatively demonstrates the value of our proposed semantically-salient\nfeatures, enabling a specific CAPT configuration to be 39\\% more accurate than\nSPT across the 48,610 programs we analyzed.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 21:19:14 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Ye", "Fangke", ""], ["Zhou", "Shengtian", ""], ["Venkat", "Anand", ""], ["Marcus", "Ryan", ""], ["Petersen", "Paul", ""], ["Tithi", "Jesmin Jahan", ""], ["Mattson", "Tim", ""], ["Kraska", "Tim", ""], ["Dubey", "Pradeep", ""], ["Sarkar", "Vivek", ""], ["Gottschlich", "Justin", ""]]}, {"id": "2003.11126", "submitter": "Ali Mousavi", "authors": "Ali Mousavi, Lihong Li, Qiang Liu, Denny Zhou", "title": "Black-box Off-policy Estimation for Infinite-Horizon Reinforcement\n  Learning", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy estimation for long-horizon problems is important in many\nreal-life applications such as healthcare and robotics, where high-fidelity\nsimulators may not be available and on-policy evaluation is expensive or\nimpossible. Recently, \\cite{liu18breaking} proposed an approach that avoids the\n\\emph{curse of horizon} suffered by typical importance-sampling-based methods.\nWhile showing promising results, this approach is limited in practice as it\nrequires data be drawn from the \\emph{stationary distribution} of a\n\\emph{known} behavior policy. In this work, we propose a novel approach that\neliminates such limitations. In particular, we formulate the problem as solving\nfor the fixed point of a certain operator. Using tools from Reproducing Kernel\nHilbert Spaces (RKHSs), we develop a new estimator that computes importance\nratios of stationary distributions, without knowledge of how the off-policy\ndata are collected. We analyze its asymptotic consistency and finite-sample\ngeneralization. Experiments on benchmarks verify the effectiveness of our\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 21:44:51 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Mousavi", "Ali", ""], ["Li", "Lihong", ""], ["Liu", "Qiang", ""], ["Zhou", "Denny", ""]]}, {"id": "2003.11334", "submitter": "Mete Tuluhan Akbulut", "authors": "M.Tuluhan Akbulut, Erhan Oztop, M.Yunus Seker, Honghu Xue, Ahmet E.\n  Tekden and Emre Ugur", "title": "ACNMP: Skill Transfer and Task Extrapolation through Learning from\n  Demonstration and Reinforcement Learning via Representation Sharing", "comments": "CoRL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To equip robots with dexterous skills, an effective approach is to first\ntransfer the desired skill via Learning from Demonstration (LfD), then let the\nrobot improve it by self-exploration via Reinforcement Learning (RL). In this\npaper, we propose a novel LfD+RL framework, namely Adaptive Conditional Neural\nMovement Primitives (ACNMP), that allows efficient policy improvement in novel\nenvironments and effective skill transfer between different agents. This is\nachieved through exploiting the latent representation learned by the underlying\nConditional Neural Process (CNP) model, and simultaneous training of the model\nwith supervised learning (SL) for acquiring the demonstrated trajectories and\nvia RL for new trajectory discovery. Through simulation experiments, we show\nthat (i) ACNMP enables the system to extrapolate to situations where pure LfD\nfails; (ii) Simultaneous training of the system through SL and RL preserves the\nshape of demonstrations while adapting to novel situations due to the shared\nrepresentations used by both learners; (iii) ACNMP enables order-of-magnitude\nsample-efficient RL in extrapolation of reaching tasks compared to the existing\napproaches; (iv) ACNMPs can be used to implement skill transfer between robots\nhaving different morphology, with competitive learning speeds and importantly\nwith less number of assumptions compared to the state-of-the-art approaches.\nFinally, we show the real-world suitability of ACNMPs through real robot\nexperiments that involve obstacle avoidance, pick and place and pouring\nactions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 11:28:12 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 12:37:28 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 09:39:59 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Akbulut", "M. Tuluhan", ""], ["Oztop", "Erhan", ""], ["Seker", "M. Yunus", ""], ["Xue", "Honghu", ""], ["Tekden", "Ahmet E.", ""], ["Ugur", "Emre", ""]]}, {"id": "2003.11336", "submitter": "Joseph Bullock", "authors": "Joseph Bullock, Alexandra Luccioni, Katherine Hoffmann Pham, Cynthia\n  Sin Nga Lam, Miguel Luengo-Oroz", "title": "Mapping the Landscape of Artificial Intelligence Applications against\n  COVID-19", "comments": "39 pages, v2: much larger to reflect the significant increase in the\n  size of the body of literature, v3: uploaded with JAIR page numbers and\n  references", "journal-ref": "Journal of Artificial Intelligence Research 69 (2020) 807-845", "doi": "10.1613/jair.1.12162", "report-no": null, "categories": "cs.CY cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19, the disease caused by the SARS-CoV-2 virus, has been declared a\npandemic by the World Health Organization, which has reported over 18 million\nconfirmed cases as of August 5, 2020. In this review, we present an overview of\nrecent studies using Machine Learning and, more broadly, Artificial\nIntelligence, to tackle many aspects of the COVID-19 crisis. We have identified\napplications that address challenges posed by COVID-19 at different scales,\nincluding: molecular, by identifying new or existing drugs for treatment;\nclinical, by supporting diagnosis and evaluating prognosis based on medical\nimaging and non-invasive measures; and societal, by tracking both the epidemic\nand the accompanying infodemic using multiple data sources. We also review\ndatasets, tools, and resources needed to facilitate Artificial Intelligence\nresearch, and discuss strategic considerations related to the operational\nimplementation of multidisciplinary partnerships and open science. We highlight\nthe need for international cooperation to maximize the potential of AI in this\nand future pandemics.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 12:30:33 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 16:50:22 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 14:35:21 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Bullock", "Joseph", ""], ["Luccioni", "Alexandra", ""], ["Pham", "Katherine Hoffmann", ""], ["Lam", "Cynthia Sin Nga", ""], ["Luengo-Oroz", "Miguel", ""]]}, {"id": "2003.11370", "submitter": "Martin Thomas Horsch", "authors": "Martin Thomas Horsch and Silvia Chiacchiera and Bj\\\"orn Schembera and\n  Michael A. Seaton and Ilian T. Todorov", "title": "Semantic interoperability based on the European Materials and Modelling\n  Ontology and its ontological paradigm: Mereosemiotics", "comments": "The co-authors M.T.H. and B.S. acknowledge funding from the German\n  Research Foundation (DFG) through the National Research Data Infrastructure\n  for Catalysis-Related Sciences (NFDI4Cat) within the National Research Data\n  Infrastructure (NFDI) programme of the Joint Science Conference (GWK)", "journal-ref": null, "doi": "10.5281/zenodo.3902900", "report-no": "Inprodat e.V. technical report no. 2020-B", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The European Materials and Modelling Ontology (EMMO) has recently been\nadvanced in the computational molecular engineering and multiscale modelling\ncommunities as a top-level ontology, aiming to support semantic\ninteroperability and data integration solutions, e.g., for research data\ninfrastructures. The present work explores how top-level ontologies that are\nbased on the same paradigm - the same set of fundamental postulates - as the\nEMMO can be applied to models of physical systems and their use in\ncomputational engineering practice. This paradigm, which combines mereology (in\nits extension as mereotopology) and semiotics (following Peirce's approach), is\nhere referred to as mereosemiotics. Multiple conceivable ways of implementing\nmereosemiotics are compared, and the design space consisting of the possible\ntypes of top-level ontologies following this paradigm is characterized.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 13:19:55 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 11:19:52 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 16:00:45 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 10:08:42 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Horsch", "Martin Thomas", ""], ["Chiacchiera", "Silvia", ""], ["Schembera", "Bj\u00f6rn", ""], ["Seaton", "Michael A.", ""], ["Todorov", "Ilian T.", ""]]}, {"id": "2003.11393", "submitter": "Eneko Osaba", "authors": "Eneko Osaba", "title": "Dise\\~no e implementaci\\'on de una meta-heur\\'istica multi-poblacional\n  de optimizaci\\'on combinatoria enfocada a la resoluci\\'on de problemas de\n  asignaci\\'on de rutas a veh\\'iculos", "comments": "228 pages, in Spanish, 25 figures, This is my PhD thesis in the\n  University of Deusto, Bilbao, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation is an essential area in the nowadays society, both for\nbusiness sector and citizenry. There are different kinds of transportation\nsystems, each one with its own characteristics. In the same way, various areas\nof knowledge can deal efficiently with the transport planning. The majority of\nthe problems related with the transport and logistics have common\ncharacteristics, so they can be modeled as optimization problems, being able to\nsee them as special cases of other generic problems. These problems fit into\nthe combinatorial optimization field. Much of the problems of this type have an\nexceptional complexity. A great amount of meta-heuristics can be found the\nliterature, each one with its advantages and disadvantages. Due to the high\ncomplexity of combinatorial optimization problems, there is no technique able\nto solve all these problems optimally. This fact makes the fields of\ncombinatorial optimization and vehicle routing problems be a hot topic of\nresearch. This doctoral thesis will focus its efforts on developing a new\nmeta-heuristic to solve different kind of vehicle routing problems. The\npresented technique offers an added value compared to existing methods, either\nin relation to the performance, and the contribution of conceptual originality.\nWith the aim of validating the proposed model, the results obtained by the\ndeveloped meta-heuristic have been compared with the ones obtained by other\nfour algorithms of similar philosophy. Four well-known routing problems have\nbeen used in this experimentation, as well as two classical combinatorial\noptimization problems. In addition to the comparisons based on parameters such\nas the mean, or the standard deviation, two different statistical tests have\nbeen carried out. Thanks to these tests it can be affirmed that the proposed\nmeta-heuristic is competitive in terms of performance and conceptual\noriginality.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 14:43:41 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Osaba", "Eneko", ""]]}, {"id": "2003.11458", "submitter": "Denis Kleyko", "authors": "Denis Kleyko and Ross W. Gayler and Evgeny Osipov", "title": "Commentaries on \"Learning Sensorimotor Control with Neuromorphic\n  Sensors: Toward Hyperdimensional Active Perception\" [Science Robotics Vol. 4\n  Issue 30 (2019) 1-10", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This correspondence comments on the findings reported in a recent Science\nRobotics article by Mitrokhin et al. [1]. The main goal of this commentary is\nto expand on some of the issues touched on in that article. Our experience is\nthat hyperdimensional computing is very different from other approaches to\ncomputation and that it can take considerable exposure to its concepts before\nattaining practically useful understanding. Therefore, in order to provide an\noverview of the area to the first time reader of [1], the commentary includes a\nbrief historic overview as well as connects the findings of the article to a\nlarger body of literature existing in the area.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 15:53:58 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Kleyko", "Denis", ""], ["Gayler", "Ross W.", ""], ["Osipov", "Evgeny", ""]]}, {"id": "2003.11618", "submitter": "Jingzhou Liu", "authors": "Jingzhou Liu, Wenhu Chen, Yu Cheng, Zhe Gan, Licheng Yu, Yiming Yang,\n  Jingjing Liu", "title": "VIOLIN: A Large-Scale Dataset for Video-and-Language Inference", "comments": "Accepted to CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new task, Video-and-Language Inference, for joint multimodal\nunderstanding of video and text. Given a video clip with aligned subtitles as\npremise, paired with a natural language hypothesis based on the video content,\na model needs to infer whether the hypothesis is entailed or contradicted by\nthe given video clip. A new large-scale dataset, named Violin\n(VIdeO-and-Language INference), is introduced for this task, which consists of\n95,322 video-hypothesis pairs from 15,887 video clips, spanning over 582 hours\nof video. These video clips contain rich content with diverse temporal\ndynamics, event shifts, and people interactions, collected from two sources:\n(i) popular TV shows, and (ii) movie clips from YouTube channels. In order to\naddress our new multimodal inference task, a model is required to possess\nsophisticated reasoning skills, from surface-level grounding (e.g., identifying\nobjects and characters in the video) to in-depth commonsense reasoning (e.g.,\ninferring causal relations of events in the video). We present a detailed\nanalysis of the dataset and an extensive evaluation over many strong baselines,\nproviding valuable insights on the challenges of this new task.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 20:39:05 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Liu", "Jingzhou", ""], ["Chen", "Wenhu", ""], ["Cheng", "Yu", ""], ["Gan", "Zhe", ""], ["Yu", "Licheng", ""], ["Yang", "Yiming", ""], ["Liu", "Jingjing", ""]]}, {"id": "2003.11619", "submitter": "Christopher Snyder", "authors": "Christopher Snyder, Sriram Vishwanath", "title": "Deep Networks as Logical Circuits: Generalization and Interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Not only are Deep Neural Networks (DNNs) black box models, but also we\nfrequently conceptualize them as such. We lack good interpretations of the\nmechanisms linking inputs to outputs. Therefore, we find it difficult to\nanalyze in human-meaningful terms (1) what the network learned and (2) whether\nthe network learned. We present a hierarchical decomposition of the DNN\ndiscrete classification map into logical (AND/OR) combinations of intermediate\n(True/False) classifiers of the input. Those classifiers that can not be\nfurther decomposed, called atoms, are (interpretable) linear classifiers. Taken\ntogether, we obtain a logical circuit with linear classifier inputs that\ncomputes the same label as the DNN. This circuit does not structurally resemble\nthe network architecture, and it may require many fewer parameters, depending\non the configuration of weights. In these cases, we obtain simultaneously an\ninterpretation and generalization bound (for the original DNN), connecting two\nfronts which have historically been investigated separately. Unlike compression\ntechniques, our representation is. We motivate the utility of this perspective\nby studying DNNs in simple, controlled settings, where we obtain superior\ngeneralization bounds despite using only combinatorial information (e.g. no\nmargin information). We demonstrate how to \"open the black box\" on the MNIST\ndataset. We show that the learned, internal, logical computations correspond to\nsemantically meaningful (unlabeled) categories that allow DNN descriptions in\nplain English. We improve the generalization of an already trained network by\ninterpreting, diagnosing, and replacing components the logical circuit that is\nthe DNN.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 20:39:53 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 15:29:28 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Snyder", "Christopher", ""], ["Vishwanath", "Sriram", ""]]}, {"id": "2003.11628", "submitter": "Eneko Osaba", "authors": "Eneko Osaba, Javier Del Ser, Xin-She Yang, Andres Iglesias and Akemi\n  Galvez", "title": "COEBA: A Coevolutionary Bat Algorithm for Discrete Evolutionary\n  Multitasking", "comments": "13 pages, 0 figures, paper submitted and accepted in the 11th\n  workshop Computational Optimization, Modelling and Simulation (COMS 2020),\n  part of the International Conference on Computational Science (ICCS 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-50426-7_19", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitasking optimization is an emerging research field which has attracted\nlot of attention in the scientific community. The main purpose of this paradigm\nis how to solve multiple optimization problems or tasks simultaneously by\nconducting a single search process. The main catalyst for reaching this\nobjective is to exploit possible synergies and complementarities among the\ntasks to be optimized, helping each other by virtue of the transfer of\nknowledge among them (thereby being referred to as Transfer Optimization). In\nthis context, Evolutionary Multitasking addresses Transfer Optimization\nproblems by resorting to concepts from Evolutionary Computation for\nsimultaneous solving the tasks at hand. This work contributes to this trend by\nproposing a novel algorithmic scheme for dealing with multitasking\nenvironments. The proposed approach, coined as Coevolutionary Bat Algorithm,\nfinds its inspiration in concepts from both co-evolutionary strategies and the\nmetaheuristic Bat Algorithm. We compare the performance of our proposed method\nwith that of its Multifactorial Evolutionary Algorithm counterpart over 15\ndifferent multitasking setups, composed by eight reference instances of the\ndiscrete Traveling Salesman Problem. The experimentation and results stemming\ntherefrom support the main hypothesis of this study: the proposed\nCoevolutionary Bat Algorithm is a promising meta-heuristic for solving\nEvolutionary Multitasking scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 13:37:43 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Osaba", "Eneko", ""], ["Del Ser", "Javier", ""], ["Yang", "Xin-She", ""], ["Iglesias", "Andres", ""], ["Galvez", "Akemi", ""]]}, {"id": "2003.11631", "submitter": "Jasper De Bock", "authors": "Jasper De Bock", "title": "Choice functions based on sets of strict partial orders: an axiomatic\n  characterisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for choosing from a set of options are often based on a strict\npartial order on these options, or on a set of such partial orders. I here\nprovide a very general axiomatic characterisation for choice functions of this\nform. It includes as special cases axiomatic characterisations for choice\nfunctions based on (sets of) total orders, (sets of) weak orders, (sets of)\ncoherent lower previsions and (sets of) probability measures.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 21:00:57 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 15:36:07 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["De Bock", "Jasper", ""]]}, {"id": "2003.11637", "submitter": "Pravin Game", "authors": "Pravin S Game, Dr. Vinod Vaze, Dr. Emmanuel M", "title": "Bio-inspired Optimization: metaheuristic algorithms for optimization", "comments": null, "journal-ref": "pp. 1-9, (17-18 January 2020)", "doi": null, "report-no": "ISBN- 978-819-20113-4-9", "categories": "cs.NE cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In today's day and time solving real-world complex problems has become\nfundamentally vital and critical task. Many of these are combinatorial\nproblems, where optimal solutions are sought rather than exact solutions.\nTraditional optimization methods are found to be effective for small scale\nproblems. However, for real-world large scale problems, traditional methods\neither do not scale up or fail to obtain optimal solutions or they end-up\ngiving solutions after a long running time. Even earlier artificial\nintelligence based techniques used to solve these problems could not give\nacceptable results. However, last two decades have seen many new methods in AI\nbased on the characteristics and behaviors of the living organisms in the\nnature which are categorized as bio-inspired or nature inspired optimization\nalgorithms. These methods, are also termed meta-heuristic optimization methods,\nhave been proved theoretically and implemented using simulation as well used to\ncreate many useful applications. They have been used extensively to solve many\nindustrial and engineering complex problems due to being easy to understand,\nflexible, simple to adapt to the problem at hand and most importantly their\nability to come out of local optima traps. This local optima avoidance property\nhelps in finding global optimal solutions. This paper is aimed at understanding\nhow nature has inspired many optimization algorithms, basic categorization of\nthem, major bio-inspired optimization algorithms invented in recent time with\ntheir applications.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:26:34 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Game", "Pravin S", ""], ["Vaze", "Dr. Vinod", ""], ["M", "Dr. Emmanuel", ""]]}, {"id": "2003.11641", "submitter": "Rafet Durgut", "authors": "Rafet Durgut", "title": "Improved Binary Artificial Bee Colony Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Artificial Bee Colony (ABC) algorithm is an evolutionary optimization\nalgorithm based on swarm intelligence and inspired by the honey bees' food\nsearch behavior. Since the ABC algorithm has been developed to achieve optimal\nsolutions by searching in the continuous search space, modification is required\nto apply this method to binary optimization problems. In this paper, we improve\nthe ABC algorithm to solve binary optimization problems and call it the\nimproved binary Artificial Bee Colony (ibinABC). The proposed method consists\nof an update mechanism based on fitness values and processing different number\nof decision variables. Thus, we aim to prevent the ABC algorithm from getting\nstuck in a local minimum by increasing its exploration ability. We compare the\nibinABC algorithm with three variants of the ABC and other meta-heuristic\nalgorithms in the literature. For comparison, we use the wellknown OR-Library\ndataset containing 15 problem instances prepared for the uncapacitated facility\nlocation problem. Computational results show that the proposed method is\nsuperior to other methods in terms of convergence speed and robustness. The\nsource code of the algorithm will be available on GitHub after reviewing\nprocess\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 17:22:52 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 17:27:22 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Durgut", "Rafet", ""]]}, {"id": "2003.11642", "submitter": "Jordan Ott", "authors": "Jordan Ott", "title": "Giving Up Control: Neurons as Reinforcement Learning Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence has historically relied on planning, heuristics, and\nhandcrafted approaches designed by experts. All the while claiming to pursue\nthe creation of Intelligence. This approach fails to acknowledge that\nintelligence emerges from the dynamics within a complex system. Neurons in the\nbrain are governed by local rules, where no single neuron, or group of neurons,\ncoordinates or controls the others. This local structure gives rise to the\nappropriate dynamics in which intelligence can emerge. Populations of neurons\nmust compete with their neighbors for resources, inhibition, and activity\nrepresentation. At the same time, they must cooperate, so the population and\norganism can perform high-level functions. To this end, we introduce modeling\nneurons as reinforcement learning agents. Where each neuron may be viewed as an\nindependent actor, trying to maximize its own self-interest. By framing\nlearning in this way, we open the door to an entirely new approach to building\nintelligent systems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 04:47:40 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Ott", "Jordan", ""]]}, {"id": "2003.11706", "submitter": "Mehrzad Saremi", "authors": "Mehrzad Saremi", "title": "A Critique on the Interventional Detection of Causal Relationships", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interventions are of fundamental importance in Pearl's probabilistic\ncausality regime. In this paper, we will inspect how interventions influence\nthe interpretation of causation in causal models in specific situation. To this\nend, we will introduce a priori relationships as non-causal relationships in a\ncausal system. Then, we will proceed to discuss the cases that interventions\ncan lead to spurious causation interpretations. This includes the\ninterventional detection of a priori relationships, and cases where the\ninterventional detection of causality forms structural causal models that are\nnot valid in natural situations. We will also discuss other properties of a\npriori relations and SCMs that have a priori information in their structural\nequations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 02:16:05 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Saremi", "Mehrzad", ""]]}, {"id": "2003.11708", "submitter": "Ali Anaissi", "authors": "Seid Miad Zandavi, Vera Chung, Ali Anaissi", "title": "Multi-User Remote lab: Timetable Scheduling Using Simplex Nondominated\n  Sorting Genetic Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scheduling of multi-user remote laboratories is modeled as a multimodal\nfunction for the proposed optimization algorithm. The hybrid optimization\nalgorithm, hybridization of the Nelder-Mead Simplex algorithm and Non-dominated\nSorting Genetic Algorithm (NSGA), is proposed to optimize the timetable problem\nfor the remote laboratories to coordinate shared access. The proposed algorithm\nutilizes the Simplex algorithm in terms of exploration, and NSGA for sorting\nlocal optimum points with consideration of potential areas. The proposed\nalgorithm is applied to difficult nonlinear continuous multimodal functions,\nand its performance is compared with hybrid Simplex Particle Swarm\nOptimization, Simplex Genetic Algorithm, and other heuristic algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 02:31:50 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Zandavi", "Seid Miad", ""], ["Chung", "Vera", ""], ["Anaissi", "Ali", ""]]}, {"id": "2003.11778", "submitter": "Max Kleiman-Weiner", "authors": "Rose E. Wang, Sarah A. Wu, James A. Evans, Joshua B. Tenenbaum, David\n  C. Parkes, Max Kleiman-Weiner", "title": "Too many cooks: Bayesian inference for coordinating multi-agent\n  collaboration", "comments": "Rose E. Wang and Sarah A. Wu contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaboration requires agents to coordinate their behavior on the fly,\nsometimes cooperating to solve a single task together and other times dividing\nit up into sub-tasks to work on in parallel. Underlying the human ability to\ncollaborate is theory-of-mind, the ability to infer the hidden mental states\nthat drive others to act. Here, we develop Bayesian Delegation, a decentralized\nmulti-agent learning mechanism with these abilities. Bayesian Delegation\nenables agents to rapidly infer the hidden intentions of others by inverse\nplanning. We test Bayesian Delegation in a suite of multi-agent Markov decision\nprocesses inspired by cooking problems. On these tasks, agents with Bayesian\nDelegation coordinate both their high-level plans (e.g. what sub-task they\nshould work on) and their low-level actions (e.g. avoiding getting in each\nother's way). In a self-play evaluation, Bayesian Delegation outperforms\nalternative algorithms. Bayesian Delegation is also a capable ad-hoc\ncollaborator and successfully coordinates with other agent types even in the\nabsence of prior experience. Finally, in a behavioral experiment, we show that\nBayesian Delegation makes inferences similar to human observers about the\nintent of others. Together, these results demonstrate the power of Bayesian\nDelegation for decentralized multi-agent collaboration.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 07:43:13 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 00:59:13 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Wang", "Rose E.", ""], ["Wu", "Sarah A.", ""], ["Evans", "James A.", ""], ["Tenenbaum", "Joshua B.", ""], ["Parkes", "David C.", ""], ["Kleiman-Weiner", "Max", ""]]}, {"id": "2003.11881", "submitter": "Daniel J. Mankowitz", "authors": "Gabriel Dulac-Arnold and Nir Levine and Daniel J. Mankowitz and Jerry\n  Li and Cosmin Paduraru and Sven Gowal and Todd Hester", "title": "An empirical investigation of the challenges of real-world reinforcement\n  learning", "comments": "arXiv admin note: text overlap with arXiv:1904.12901", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has proven its worth in a series of artificial\ndomains, and is beginning to show some successes in real-world scenarios.\nHowever, much of the research advances in RL are hard to leverage in real-world\nsystems due to a series of assumptions that are rarely satisfied in practice.\nIn this work, we identify and formalize a series of independent challenges that\nembody the difficulties that must be addressed for RL to be commonly deployed\nin real-world systems. For each challenge, we define it formally in the context\nof a Markov Decision Process, analyze the effects of the challenge on\nstate-of-the-art learning algorithms, and present some existing attempts at\ntackling it. We believe that an approach that addresses our set of proposed\nchallenges would be readily deployable in a large number of real world\nproblems. Our proposed challenges are implemented in a suite of continuous\ncontrol environments called the realworldrl-suite which we propose an as an\nopen-source benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 11:05:41 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 13:02:59 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Dulac-Arnold", "Gabriel", ""], ["Levine", "Nir", ""], ["Mankowitz", "Daniel J.", ""], ["Li", "Jerry", ""], ["Paduraru", "Cosmin", ""], ["Gowal", "Sven", ""], ["Hester", "Todd", ""]]}, {"id": "2003.11917", "submitter": "Cameron Buckner", "authors": "Cameron Buckner", "title": "Adversarial Examples and the Deeper Riddle of Induction: The Need for a\n  Theory of Artifacts in Deep Learning", "comments": "24 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is currently the most widespread and successful technology in\nartificial intelligence. It promises to push the frontier of scientific\ndiscovery beyond current limits. However, skeptics have worried that deep\nneural networks are black boxes, and have called into question whether these\nadvances can really be deemed scientific progress if humans cannot understand\nthem. Relatedly, these systems also possess bewildering new vulnerabilities:\nmost notably a susceptibility to \"adversarial examples\". In this paper, I argue\nthat adversarial examples will become a flashpoint of debate in philosophy and\ndiverse sciences. Specifically, new findings concerning adversarial examples\nhave challenged the consensus view that the networks' verdicts on these cases\nare caused by overfitting idiosyncratic noise in the training set, and may\ninstead be the result of detecting predictively useful \"intrinsic features of\nthe data geometry\" that humans cannot perceive (Ilyas et al., 2019). These\nresults should cause us to re-examine responses to one of the deepest puzzles\nat the intersection of philosophy and science: Nelson Goodman's \"new riddle\" of\ninduction. Specifically, they raise the possibility that progress in a number\nof sciences will depend upon the detection and manipulation of useful features\nthat humans find inscrutable. Before we can evaluate this possibility, however,\nwe must decide which (if any) of these inscrutable features are real but\navailable only to \"alien\" perception and cognition, and which are distinctive\nartifacts of deep learning-for artifacts like lens flares or Gibbs phenomena\ncan be similarly useful for prediction, but are usually seen as obstacles to\nscientific theorizing. Thus, machine learning researchers urgently need to\ndevelop a theory of artifacts for deep neural networks, and I conclude by\nsketching some initial directions for this area of research.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 16:24:25 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Buckner", "Cameron", ""]]}, {"id": "2003.11919", "submitter": "Patrick Hart C", "authors": "Patrick Hart and Alois Knoll", "title": "Counterfactual Policy Evaluation for Decision-Making in Autonomous\n  Driving", "comments": "Accepted at IROS 2020 PLC Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based approaches, such as reinforcement and imitation learning are\ngaining popularity in decision-making for autonomous driving. However, learned\npolicies often fail to generalize and cannot handle novel situations well.\nAsking and answering questions in the form of \"Would a policy perform well if\nthe other agents had behaved differently?\" can shed light on whether a policy\nhas seen similar situations during training and generalizes well. In this work,\na counterfactual policy evaluation is introduced that makes use of\ncounterfactual worlds - worlds in which the behaviors of others are non-actual.\nIf a policy can handle all counterfactual worlds well, it either has seen\nsimilar situations during training or it generalizes well and is deemed to be\nfit enough to be executed in the actual world. Additionally, by performing the\ncounterfactual policy evaluation, causal relations and the influence of\nchanging vehicle's behaviors on the surrounding vehicles becomes evident. To\nvalidate the proposed method, we learn a policy using reinforcement learning\nfor a lane merging scenario. In the application-phase, the policy is only\nexecuted after the counterfactual policy evaluation has been performed and if\nthe policy is found to be safe enough. We show that the proposed approach\nsignificantly decreases the collision-rate whilst maintaining a high\nsuccess-rate.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 10:02:30 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 16:10:19 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 14:30:42 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Hart", "Patrick", ""], ["Knoll", "Alois", ""]]}, {"id": "2003.11922", "submitter": "Marco Baroni", "authors": "Marco Baroni", "title": "Rat big, cat eaten! Ideas for a useful deep-agent protolanguage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep-agent communities developing their own language-like communication\nprotocol are a hot (or at least warm) topic in AI. Such agents could be very\nuseful in machine-machine and human-machine interaction scenarios long before\nthey have evolved a protocol as complex as human language. Here, I propose a\nsmall set of priorities we should focus on, if we want to get as fast as\npossible to a stage where deep agents speak a useful protolanguage.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 18:41:26 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Baroni", "Marco", ""]]}, {"id": "2003.11941", "submitter": "Wen-Ji Zhou", "authors": "Guangda Huzhang, Zhen-Jia Pang, Yongqing Gao, Yawen Liu, Weijie Shen,\n  Wen-Ji Zhou, Qing Da, An-Xiang Zeng, Han Yu, and Yang Yu, and Zhi-Hua Zhou", "title": "AliExpress Learning-To-Rank: Maximizing Online Model Performance without\n  Going Online", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-to-rank (LTR) has become a key technology in E-commerce\napplications. Most existing LTR approaches follow a supervised learning\nparadigm from offline labeled data collected from the online system. However,\nit has been noticed that previous LTR models can have a good validation\nperformance over offline validation data but have a poor online performance,\nand vice versa, which implies a possible large inconsistency between the\noffline and online evaluation. We investigate and confirm in this paper that\nsuch inconsistency exists and can have a significant impact on AliExpress\nSearch. Reasons for the inconsistency include the ignorance of item context\nduring the learning, and the offline data set is insufficient for learning the\ncontext. Therefore, this paper proposes an evaluator-generator framework for\nLTR with item context. The framework consists of an evaluator that generalizes\nto evaluate recommendations involving the context, and a generator that\nmaximizes the evaluator score by reinforcement learning, and a discriminator\nthat ensures the generalization of the evaluator. Extensive experiments in\nsimulation environments and AliExpress Search online system show that, firstly,\nthe classic data-based metrics on the offline dataset can show significant\ninconsistency with online performance, and can even be misleading. Secondly,\nthe proposed evaluator score is significantly more consistent with the online\nperformance than common ranking metrics. Finally, as the consequence, our\nmethod achieves a significant improvement (\\textgreater$2\\%$) in terms of\nConversion Rate (CR) over the industrial-level fine-tuned model in online A/B\ntests.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 10:27:44 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 13:09:47 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 02:09:02 GMT"}, {"version": "v4", "created": "Tue, 28 Jul 2020 05:14:10 GMT"}, {"version": "v5", "created": "Thu, 31 Dec 2020 10:04:48 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Huzhang", "Guangda", ""], ["Pang", "Zhen-Jia", ""], ["Gao", "Yongqing", ""], ["Liu", "Yawen", ""], ["Shen", "Weijie", ""], ["Zhou", "Wen-Ji", ""], ["Da", "Qing", ""], ["Zeng", "An-Xiang", ""], ["Yu", "Han", ""], ["Yu", "Yang", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "2003.11973", "submitter": "Ziyi Zhao", "authors": "Ziyi Zhao, Haowen Fang, Zhao Jin, Qinru Qiu", "title": "GISNet: Graph-Based Information Sharing Network For Vehicle Trajectory\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The trajectory prediction is a critical and challenging problem in the design\nof an autonomous driving system. Many AI-oriented companies, such as Google\nWaymo, Uber and DiDi, are investigating more accurate vehicle trajectory\nprediction algorithms. However, the prediction performance is governed by lots\nof entangled factors, such as the stochastic behaviors of surrounding vehicles,\nhistorical information of self-trajectory, and relative positions of neighbors,\netc. In this paper, we propose a novel graph-based information sharing network\n(GISNet) that allows the information sharing between the target vehicle and its\nsurrounding vehicles. Meanwhile, the model encodes the historical trajectory\ninformation of all the vehicles in the scene. Experiments are carried out on\nthe public NGSIM US-101 and I-80 Dataset and the prediction performance is\nmeasured by the Root Mean Square Error (RMSE). The quantitative and qualitative\nexperimental results show that our model significantly improves the trajectory\nprediction accuracy, by up to 50.00%, compared to existing models.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 03:24:31 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Zhao", "Ziyi", ""], ["Fang", "Haowen", ""], ["Jin", "Zhao", ""], ["Qiu", "Qinru", ""]]}, {"id": "2003.12012", "submitter": "Kaiping Zheng", "authors": "Kaiping Zheng, Shaofeng Cai, Horng Ruey Chua, Wei Wang, Kee Yuan\n  Ngiam, Beng Chin Ooi", "title": "TRACER: A Framework for Facilitating Accurate and Interpretable\n  Analytics for High Stakes Applications", "comments": "A version of this preprint will appear in ACM SIGMOD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high stakes applications such as healthcare and finance analytics, the\ninterpretability of predictive models is required and necessary for domain\npractitioners to trust the predictions. Traditional machine learning models,\ne.g., logistic regression (LR), are easy to interpret in nature. However, many\nof these models aggregate time-series data without considering the temporal\ncorrelations and variations. Therefore, their performance cannot match up to\nrecurrent neural network (RNN) based models, which are nonetheless difficult to\ninterpret. In this paper, we propose a general framework TRACER to facilitate\naccurate and interpretable predictions, with a novel model TITV devised for\nhealthcare analytics and other high stakes applications such as financial\ninvestment and risk management. Different from LR and other existing RNN-based\nmodels, TITV is designed to capture both the time-invariant and the\ntime-variant feature importance using a feature-wise transformation subnetwork\nand a self-attention subnetwork, for the feature influence shared over the\nentire time series and the time-related importance respectively. Healthcare\nanalytics is adopted as a driving use case, and we note that the proposed\nTRACER is also applicable to other domains, e.g., fintech. We evaluate the\naccuracy of TRACER extensively in two real-world hospital datasets, and our\ndoctors/clinicians further validate the interpretability of TRACER in both the\npatient level and the feature level. Besides, TRACER is also validated in a\nhigh stakes financial application and a critical temperature forecasting\napplication. The experimental results confirm that TRACER facilitates both\naccurate and interpretable analytics for high stakes applications.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 15:06:05 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Zheng", "Kaiping", ""], ["Cai", "Shaofeng", ""], ["Chua", "Horng Ruey", ""], ["Wang", "Wei", ""], ["Ngiam", "Kee Yuan", ""], ["Ooi", "Beng Chin", ""]]}, {"id": "2003.12141", "submitter": "Francesco Fusco", "authors": "Bradley Eck, Francesco Fusco, Robert Gormally, Mark Purcell, Seshu\n  Tirupathi", "title": "Scalable Deployment of AI Time-series Models for IoT", "comments": null, "journal-ref": "Workshop AI for Internet of Things, IJCAI 2019", "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IBM Research Castor, a cloud-native system for managing and deploying large\nnumbers of AI time-series models in IoT applications, is described. Modelling\ncode templates, in Python and R, following a typical machine-learning workflow\nare supported. A knowledge-based approach to managing model and time-series\ndata allows the use of general semantic concepts for expressing feature\nengineering tasks. Model templates can be programmatically deployed against\nspecific instances of semantic concepts, thus supporting model reuse and\nautomated replication as the IoT application grows. Deployed models are\nautomatically executed in parallel leveraging a serverless cloud computing\nframework. The complete history of trained model versions and rolling-horizon\npredictions is persisted, thus enabling full model lineage and traceability.\nResults from deployments in real-world smart-grid live forecasting applications\nare reported. Scalability of executing up to tens of thousands of AI modelling\ntasks is also evaluated.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 14:27:25 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Eck", "Bradley", ""], ["Fusco", "Francesco", ""], ["Gormally", "Robert", ""], ["Purcell", "Mark", ""], ["Tirupathi", "Seshu", ""]]}, {"id": "2003.12145", "submitter": "Navdeep Kaur", "authors": "Navdeep Kaur and Gautam Kunapuli and Sriraam Natarajan", "title": "Knowledge Graph Alignment using String Edit Distance", "comments": "Position Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel knowledge graph alignment technique based\nupon string edit distance that exploits the type information between entities\nand can find similarity between relations of any arity\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 22:11:39 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 00:31:35 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Kaur", "Navdeep", ""], ["Kunapuli", "Gautam", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "2003.12168", "submitter": "Julian Theis", "authors": "Julian Theis and Houshang Darabi", "title": "Adversarial System Variant Approximation to Quantify Process Model\n  Generalization", "comments": null, "journal-ref": "IEEE Access, vol. 8, pp. 194410-194427, 2020", "doi": "10.1109/ACCESS.2020.3033450", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In process mining, process models are extracted from event logs using process\ndiscovery algorithms and are commonly assessed using multiple quality\ndimensions. While the metrics that measure the relationship of an extracted\nprocess model to its event log are well-studied, quantifying the level by which\na process model can describe the unobserved behavior of its underlying system\nfalls short in the literature. In this paper, a novel deep learning-based\nmethodology called Adversarial System Variant Approximation (AVATAR) is\nproposed to overcome this issue. Sequence Generative Adversarial Networks are\ntrained on the variants contained in an event log with the intention to\napproximate the underlying variant distribution of the system behavior.\nUnobserved realistic variants are sampled either directly from the Sequence\nGenerative Adversarial Network or by leveraging the Metropolis-Hastings\nalgorithm. The degree by which a process model relates to its underlying\nunknown system behavior is then quantified based on the realistic observed and\nestimated unobserved variants using established process model quality metrics.\nSignificant performance improvements in revealing realistic unobserved variants\nare demonstrated in a controlled experiment on 15 ground truth systems.\nAdditionally, the proposed methodology is experimentally tested and evaluated\nto quantify the generalization of 60 discovered process models with respect to\ntheir systems.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 22:06:18 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 01:34:13 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Theis", "Julian", ""], ["Darabi", "Houshang", ""]]}, {"id": "2003.12172", "submitter": "Dianlei Xu", "authors": "Dianlei Xu, Tong Li, Yong Li, Xiang Su, Sasu Tarkoma, Tao Jiang, Jon\n  Crowcroft, Pan Hui", "title": "Edge Intelligence: Architectures, Challenges, and Applications", "comments": "53 pages, 37 figures, survey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge intelligence refers to a set of connected systems and devices for data\ncollection, caching, processing, and analysis in locations close to where data\nis captured based on artificial intelligence. The aim of edge intelligence is\nto enhance the quality and speed of data processing and protect the privacy and\nsecurity of the data. Although recently emerged, spanning the period from 2011\nto now, this field of research has shown explosive growth over the past five\nyears. In this paper, we present a thorough and comprehensive survey on the\nliterature surrounding edge intelligence. We first identify four fundamental\ncomponents of edge intelligence, namely edge caching, edge training, edge\ninference, and edge offloading, based on theoretical and practical results\npertaining to proposed and deployed systems. We then aim for a systematic\nclassification of the state of the solutions by examining research results and\nobservations for each of the four components and present a taxonomy that\nincludes practical problems, adopted techniques, and application goals. For\neach category, we elaborate, compare and analyse the literature from the\nperspectives of adopted techniques, objectives, performance, advantages and\ndrawbacks, etc. This survey article provides a comprehensive introduction to\nedge intelligence and its application areas. In addition, we summarise the\ndevelopment of the emerging research field and the current state-of-the-art and\ndiscuss the important open issues and possible theoretical and technical\nsolutions.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 22:24:56 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 14:40:56 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Xu", "Dianlei", ""], ["Li", "Tong", ""], ["Li", "Yong", ""], ["Su", "Xiang", ""], ["Tarkoma", "Sasu", ""], ["Jiang", "Tao", ""], ["Crowcroft", "Jon", ""], ["Hui", "Pan", ""]]}, {"id": "2003.12205", "submitter": "Huiqiang Zhong", "authors": "Huiqiang Zhong and Cunxiang Yin and Xiaohui Wu and Jinchang Luo and\n  JiaWei He", "title": "AirRL: A Reinforcement Learning Approach to Urban Air Quality Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban air pollution has become a major environmental problem that threatens\npublic health. It has become increasingly important to infer fine-grained urban\nair quality based on existing monitoring stations. One of the challenges is how\nto effectively select some relevant stations for air quality inference. In this\npaper, we propose a novel model based on reinforcement learning for urban air\nquality inference. The model consists of two modules: a station selector and an\nair quality regressor. The station selector dynamically selects the most\nrelevant monitoring stations when inferring air quality. The air quality\nregressor takes in the selected stations and makes air quality inference with\ndeep neural network. We conduct experiments on a real-world air quality dataset\nand our approach achieves the highest performance compared with several popular\nsolutions, and the experiments show significant effectiveness of proposed model\nin tackling problems of air quality inference.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 02:04:00 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Zhong", "Huiqiang", ""], ["Yin", "Cunxiang", ""], ["Wu", "Xiaohui", ""], ["Luo", "Jinchang", ""], ["He", "JiaWei", ""]]}, {"id": "2003.12218", "submitter": "Xuan Wang", "authors": "Xuan Wang, Xiangchen Song, Bangzheng Li, Yingjun Guan, Jiawei Han", "title": "Comprehensive Named Entity Recognition on CORD-19 with Distant or Weak\n  Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We created this CORD-NER dataset with comprehensive named entity recognition\n(NER) on the COVID-19 Open Research Dataset Challenge (CORD-19) corpus\n(2020-03-13). This CORD-NER dataset covers 75 fine-grained entity types: In\naddition to the common biomedical entity types (e.g., genes, chemicals and\ndiseases), it covers many new entity types related explicitly to the COVID-19\nstudies (e.g., coronaviruses, viral proteins, evolution, materials, substrates\nand immune responses), which may benefit research on COVID-19 related virus,\nspreading mechanisms, and potential vaccines. CORD-NER annotation is a\ncombination of four sources with different NER methods. The quality of CORD-NER\nannotation surpasses SciSpacy (over 10% higher on the F1 score based on a\nsample set of documents), a fully supervised BioNER tool. Moreover, CORD-NER\nsupports incrementally adding new documents as well as adding new entity types\nwhen needed by adding dozens of seeds as the input examples. We will constantly\nupdate CORD-NER based on the incremental updates of the CORD-19 corpus and the\nimprovement of our system.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 03:35:46 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 01:42:54 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 01:19:09 GMT"}, {"version": "v4", "created": "Fri, 10 Apr 2020 04:07:24 GMT"}, {"version": "v5", "created": "Wed, 15 Apr 2020 19:37:16 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Wang", "Xuan", ""], ["Song", "Xiangchen", ""], ["Li", "Bangzheng", ""], ["Guan", "Yingjun", ""], ["Han", "Jiawei", ""]]}, {"id": "2003.12239", "submitter": "Philip Amortila", "authors": "Philip Amortila, Doina Precup, Prakash Panangaden, Marc G. Bellemare", "title": "A Distributional Analysis of Sampling-Based Reinforcement Learning\n  Algorithms", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a distributional approach to theoretical analyses of reinforcement\nlearning algorithms for constant step-sizes. We demonstrate its effectiveness\nby presenting simple and unified proofs of convergence for a variety of\ncommonly-used methods. We show that value-based methods such as TD($\\lambda$)\nand $Q$-Learning have update rules which are contractive in the space of\ndistributions of functions, thus establishing their exponentially fast\nconvergence to a stationary distribution. We demonstrate that the stationary\ndistribution obtained by any algorithm whose target is an expected Bellman\nupdate has a mean which is equal to the true value function. Furthermore, we\nestablish that the distributions concentrate around their mean as the step-size\nshrinks. We further analyse the optimistic policy iteration algorithm, for\nwhich the contraction property does not hold, and formulate a probabilistic\npolicy improvement property which entails the convergence of the algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 05:13:29 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Amortila", "Philip", ""], ["Precup", "Doina", ""], ["Panangaden", "Prakash", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "2003.12331", "submitter": "Raluca Gaina", "authors": "Raluca D. Gaina, Sam Devlin, Simon M. Lucas, Diego Perez-Liebana", "title": "Rolling Horizon Evolutionary Algorithms for General Video Game Playing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Game-playing Evolutionary Algorithms, specifically Rolling Horizon\nEvolutionary Algorithms, have recently managed to beat the state of the art in\nwin rate across many video games. However, the best results in a game are\nhighly dependent on the specific configuration of modifications and hybrids\nintroduced over several papers, each adding additional parameters to the core\nalgorithm. Further, the best previously published parameters have been found\nfrom only a few human-picked combinations, as the possibility space has grown\nbeyond exhaustive search. This paper presents the state of the art in Rolling\nHorizon Evolutionary Algorithms, combining all modifications described in\nliterature, as well as new ones, for a large resultant hybrid. We then use a\nparameter optimiser, the N-Tuple Bandit Evolutionary Algorithm, to find the\nbest combination of parameters in 20 games from the General Video Game AI\nFramework. Further, we analyse the algorithm's parameters and some interesting\ncombinations revealed through the optimisation process. Lastly, we find new\nstate of the art solutions on several games by automatically exploring the\nlarge parameter space of RHEA.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 11:19:10 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 14:03:28 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Gaina", "Raluca D.", ""], ["Devlin", "Sam", ""], ["Lucas", "Simon M.", ""], ["Perez-Liebana", "Diego", ""]]}, {"id": "2003.12353", "submitter": "Naoya Arakawa", "authors": "Naoya Arakawa", "title": "Planning with Brain-inspired AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This article surveys engineering and neuroscientific models of planning as a\ncognitive function, which is regarded as a typical function of fluid\nintelligence in the discussion of general intelligence. It aims to present\nexisting planning models as references for realizing the planning function in\nbrain-inspired AI or artificial general intelligence (AGI). It also proposes\nthemes for the research and development of brain-inspired AI from the viewpoint\nof tasks and architecture.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 02:17:08 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Arakawa", "Naoya", ""]]}, {"id": "2003.12381", "submitter": "Daniel Leite", "authors": "Charles Aguiar, Daniel Leite", "title": "Unsupervised Fuzzy eIX: Evolving Internal-eXternal Fuzzy Clustering", "comments": "8 pages, 9 figures, IEEE Conference on Evolving and Adaptive\n  Intelligent Systems (EAIS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-varying classifiers, namely, evolving classifiers, play an important\nrole in a scenario in which information is available as a never-ending online\ndata stream. We present a new unsupervised learning method for numerical data\ncalled evolving Internal-eXternal Fuzzy clustering method (Fuzzy eIX). We\ndevelop the notion of double-boundary fuzzy granules and elaborate on its\nimplications. Type 1 and type 2 fuzzy inference systems can be obtained from\nthe projection of Fuzzy eIX granules. We perform the principle of the balanced\ninformation granularity within Fuzzy eIX classifiers to achieve a higher level\nof model understandability. Internal and external granules are updated from a\nnumerical data stream at the same time that the global granular structure of\nthe classifier is autonomously evolved. A synthetic nonstationary problem\ncalled Rotation of Twin Gaussians shows the behavior of the classifier. The\nFuzzy eIX classifier could keep up with its accuracy in a scenario in which\noffline-trained classifiers would clearly have their accuracy drastically\ndropped.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 16:17:27 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Aguiar", "Charles", ""], ["Leite", "Daniel", ""]]}, {"id": "2003.12383", "submitter": "Xander Wilcke", "authors": "W.X. Wilcke (1), P. Bloem (1), V. de Boer (1), R.H. van t Veer (2),\n  F.A.H. van Harmelen (1) ((1) Department of Computer Science Vrije\n  Universiteit Amsterdam The Netherlands, (2) Geodan Amsterdam The Netherlands)", "title": "End-to-End Entity Classification on Multimodal Knowledge Graphs", "comments": "Submitted to the 17th International Conference on Principles of\n  Knowledge Representation and Reasoning (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end multimodal learning on knowledge graphs has been left largely\nunaddressed. Instead, most end-to-end models such as message passing networks\nlearn solely from the relational information encoded in graphs' structure: raw\nvalues, or literals, are either omitted completely or are stripped from their\nvalues and treated as regular nodes. In either case we lose potentially\nrelevant information which could have otherwise been exploited by our learning\nmethods. To avoid this, we must treat literals and non-literals as separate\ncases. We must also address each modality separately and accordingly: numbers,\ntexts, images, geometries, et cetera. We propose a multimodal message passing\nnetwork which not only learns end-to-end from the structure of graphs, but also\nfrom their possibly divers set of multimodal node features. Our model uses\ndedicated (neural) encoders to naturally learn embeddings for node features\nbelonging to five different types of modalities, including images and\ngeometries, which are projected into a joint representation space together with\ntheir relational information. We demonstrate our model on a node classification\ntask, and evaluate the effect that each modality has on the overall\nperformance. Our result supports our hypothesis that including information from\nmultiple modalities can help our models obtain a better overall performance.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 14:57:52 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Wilcke", "W. X.", ""], ["Bloem", "P.", ""], ["de Boer", "V.", ""], ["Veer", "R. H. van t", ""], ["van Harmelen", "F. A. H.", ""]]}, {"id": "2003.12439", "submitter": "Jun Liu", "authors": "Jiawei Wu, Jianxue Li, Yang Xiao, Jun Liu", "title": "Towards Cognitive Routing based on Deep Reinforcement Learning", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Routing is one of the key functions for stable operation of network\ninfrastructure. Nowadays, the rapid growth of network traffic volume and\nchanging of service requirements call for more intelligent routing methods than\nbefore. Towards this end, we propose a definition of cognitive routing and an\nimplementation approach based on Deep Reinforcement Learning (DRL). To\nfacilitate the research of DRL-based cognitive routing, we introduce a\nsimulator named RL4Net for DRL-based routing algorithm development and\nsimulation. Then, we design and implement a DDPG-based routing algorithm. The\nsimulation results on an example network topology show that the DDPG-based\nrouting algorithm achieves better performance than OSPF and random weight\nalgorithms. It demonstrate the preliminary feasibility and potential advantage\nof cognitive routing for future network.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 03:32:43 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Wu", "Jiawei", ""], ["Li", "Jianxue", ""], ["Xiao", "Yang", ""], ["Liu", "Jun", ""]]}, {"id": "2003.12508", "submitter": "Romit Beed Mr", "authors": "Romit S Beed, Sunita Sarkar and Arindam Roy", "title": "Bayesian Hierarchical Multi-Objective Optimization for Vehicle Parking\n  Route Discovery", "comments": "10 pages, 2 Figures, 3 Tables, journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering an optimal route to the most feasible parking lot has been a\nmatter of concern for any driver which aggravates further during peak hours of\nthe day and at congested places leading to considerable wastage of time and\nfuel. This paper proposes a Bayesian hierarchical technique for obtaining the\nmost optimal route to a parking lot. The route selection is based on\nconflicting objectives and hence the problem belongs to the domain of\nmulti-objective optimization. A probabilistic data driven method has been used\nto overcome the inherent problem of weight selection in the popular weighted\nsum technique. The weights of these conflicting objectives have been refined\nusing a Bayesian hierarchical model based on Multinomial and Dirichlet prior.\nGenetic algorithm has been used to obtain optimal solutions. Simulated data has\nbeen used to obtain routes which are in close agreement with real life\nsituations.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 16:15:53 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Beed", "Romit S", ""], ["Sarkar", "Sunita", ""], ["Roy", "Arindam", ""]]}, {"id": "2003.12526", "submitter": "Thiago Miranda", "authors": "Thiago Zafalon Miranda, Diorge Brognara Sardinha, M\\'arcio Porto\n  Basgalupp, Yaochu Jin, Ricardo Cerri", "title": "Generation of Consistent Sets of Multi-Label Classification Rules with a\n  Multi-Objective Evolutionary Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification consists in classifying an instance into two or\nmore classes simultaneously. It is a very challenging task present in many\nreal-world applications, such as classification of biology, image, video,\naudio, and text. Recently, the interest in interpretable classification models\nhas grown, partially as a consequence of regulations such as the General Data\nProtection Regulation. In this context, we propose a multi-objective\nevolutionary algorithm that generates multiple rule-based multi-label\nclassification models, allowing users to choose among models that offer\ndifferent compromises between predictive power and interpretability. An\nimportant contribution of this work is that different from most algorithms,\nwhich usually generate models based on lists (ordered collections) of rules,\nour algorithm generates models based on sets (unordered collections) of rules,\nincreasing interpretability. Also, by employing a conflict avoidance algorithm\nduring the rule-creation, every rule within a given model is guaranteed to be\nconsistent with every other rule in the same model. Thus, no conflict\nresolution strategy is required, evolving simpler models. We conducted\nexperiments on synthetic and real-world datasets and compared our results with\nstate-of-the-art algorithms in terms of predictive performance (F-Score) and\ninterpretability (model size), and demonstrate that our best models had\ncomparable F-Score and smaller model sizes.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 16:43:10 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Miranda", "Thiago Zafalon", ""], ["Sardinha", "Diorge Brognara", ""], ["Basgalupp", "M\u00e1rcio Porto", ""], ["Jin", "Yaochu", ""], ["Cerri", "Ricardo", ""]]}, {"id": "2003.12530", "submitter": "Renata Pelissari", "authors": "Renata Pelissari and Leonardo Tomazeli Duarte", "title": "Identification of Choquet capacity in multicriteria sorting problems\n  through stochastic inverse analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multicriteria decision aiding (MCDA), the Choquet integral has been used\nas an aggregation operator to deal with the case of interacting decision\ncriteria. While the application of the Choquet integral for ranking problems\nhave been receiving most of the attention, this paper rather focuses on\nmulticriteria sorting problems (MCSP). In the Choquet integral context, a\npractical problem that arises is related to the elicitation of parameters known\nas the Choquet capacities. We address the problem of Choquet capacity\nidentification for MCSP by applying the Stochastic Acceptability Multicriteri\nAnalysis (SMAA), proposing the SMAA-S-Choquet method. The proposed method is\nalso able to model uncertain data that may be present in both decision matrix\nand limiting profiles, the latter a parameter associated with the sorting\nproblematic. We also introduce two new descriptive measures in order to conduct\nreverse analysis regarding the capacities: the Scenario Acceptability Index and\nthe Scenario Central Capacity vector.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 16:46:09 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Pelissari", "Renata", ""], ["Duarte", "Leonardo Tomazeli", ""]]}, {"id": "2003.12587", "submitter": "Nozer Singpurwalla D", "authors": "Nozer Singpurwalla", "title": "Adversarial Stress Testing of Lifetime Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we put forward the viewpoint that the notion of stress testing\nfinancial institutions and engineered systems can also be made viable appropos\nthe stress testing an individual's strength of conviction in a probability\ndistribution. The difference is interpretation and perspective. To make our\ncase we consider a game theoretic setup entailing two players, an adversarial\nC, and an amicable M.The underlying metrics entail a de Finetti style 2 sided\nbet with asymmetric payoffs as a way to give meaning to lifetime distributions,\nan adversarial stress testing function, and a maximization of the expected\nutility of betting scores via the Kullback Liebler discrimination.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 18:13:30 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Singpurwalla", "Nozer", ""]]}, {"id": "2003.12613", "submitter": "Xuezhou Zhang", "authors": "Xuezhou Zhang, Yuzhe Ma, Adish Singla, Xiaojin Zhu", "title": "Adaptive Reward-Poisoning Attacks against Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reward-poisoning attacks against reinforcement learning (RL), an attacker\ncan perturb the environment reward $r_t$ into $r_t+\\delta_t$ at each step, with\nthe goal of forcing the RL agent to learn a nefarious policy. We categorize\nsuch attacks by the infinity-norm constraint on $\\delta_t$: We provide a lower\nthreshold below which reward-poisoning attack is infeasible and RL is certified\nto be safe; we provide a corresponding upper threshold above which the attack\nis feasible. Feasible attacks can be further categorized as non-adaptive where\n$\\delta_t$ depends only on $(s_t,a_t, s_{t+1})$, or adaptive where $\\delta_t$\ndepends further on the RL agent's learning process at time $t$. Non-adaptive\nattacks have been the focus of prior works. However, we show that under mild\nconditions, adaptive attacks can achieve the nefarious policy in steps\npolynomial in state-space size $|S|$, whereas non-adaptive attacks require\nexponential steps. We provide a constructive proof that a Fast Adaptive Attack\nstrategy achieves the polynomial rate. Finally, we show that empirically an\nattacker can find effective reward-poisoning attacks using state-of-the-art\ndeep RL techniques.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 19:46:23 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 21:02:31 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Zhang", "Xuezhou", ""], ["Ma", "Yuzhe", ""], ["Singla", "Adish", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "2003.12694", "submitter": "Yuchen Lu", "authors": "Yuchen Lu, Soumye Singhal, Florian Strub, Olivier Pietquin, Aaron\n  Courville", "title": "Countering Language Drift with Seeded Iterated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Pretraining on human corpus and then finetuning in a simulator has become a\nstandard pipeline for training a goal-oriented dialogue agent. Nevertheless, as\nsoon as the agents are finetuned to maximize task completion, they suffer from\nthe so-called language drift phenomenon: they slowly lose syntactic and\nsemantic properties of language as they only focus on solving the task. In this\npaper, we propose a generic approach to counter language drift called Seeded\niterated learning (SIL). We periodically refine a pretrained student agent by\nimitating data sampled from a newly generated teacher agent. At each time step,\nthe teacher is created by copying the student agent, before being finetuned to\nmaximize task completion. SIL does not require external syntactic constraint\nnor semantic knowledge, making it a valuable task-agnostic finetuning protocol.\nWe evaluate SIL in a toy-setting Lewis Game, and then scale it up to the\ntranslation game with natural language. In both settings, SIL helps counter\nlanguage drift as well as it improves the task completion compared to\nbaselines.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 03:45:31 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 03:24:46 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2020 19:26:54 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Lu", "Yuchen", ""], ["Singhal", "Soumye", ""], ["Strub", "Florian", ""], ["Pietquin", "Olivier", ""], ["Courville", "Aaron", ""]]}, {"id": "2003.12718", "submitter": "Gaole He", "authors": "Gaole He, Junyi Li, Wayne Xin Zhao, Peiju Liu and Ji-Rong Wen", "title": "Mining Implicit Entity Preference from User-Item Interaction Data for\n  Knowledge Graph Completion via Adversarial Learning", "comments": "11 pages, 4 figures, 6 tables. Accepted as WWW 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of Knowledge Graph Completion (KGC) aims to automatically infer the\nmissing fact information in Knowledge Graph (KG). In this paper, we take a new\nperspective that aims to leverage rich user-item interaction data (user\ninteraction data for short) for improving the KGC task. Our work is inspired by\nthe observation that many KG entities correspond to online items in application\nsystems. However, the two kinds of data sources have very different intrinsic\ncharacteristics, and it is likely to hurt the original performance using simple\nfusion strategy. To address this challenge, we propose a novel adversarial\nlearning approach by leveraging user interaction data for the KGC task. Our\ngenerator is isolated from user interaction data, and serves to improve the\nperformance of the discriminator. The discriminator takes the learned useful\ninformation from user interaction data as input, and gradually enhances the\nevaluation capacity in order to identify the fake samples generated by the\ngenerator. To discover implicit entity preference of users, we design an\nelaborate collaborative learning algorithms based on graph neural networks,\nwhich will be jointly optimized with the discriminator. Such an approach is\neffective to alleviate the issues about data heterogeneity and semantic\ncomplexity for the KGC task. Extensive experiments on three real-world datasets\nhave demonstrated the effectiveness of our approach on the KGC task.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 05:47:33 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 07:29:19 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 07:07:22 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["He", "Gaole", ""], ["Li", "Junyi", ""], ["Zhao", "Wayne Xin", ""], ["Liu", "Peiju", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2003.12828", "submitter": "Albert Buchard", "authors": "Albert Buchard, Baptiste Bouvier, Giulia Prando, Rory Beard, Michail\n  Livieratos, Dan Busbridge, Daniel Thompson, Jonathan Richens, Yuanzhao Zhang,\n  Adam Baker, Yura Perov, Kostis Gourgoulias, Saurabh Johri", "title": "Learning medical triage from clinicians using Deep Q-Learning", "comments": "17 pages, 4 figures, 3 tables, preprint, in press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical Triage is of paramount importance to healthcare systems, allowing for\nthe correct orientation of patients and allocation of the necessary resources\nto treat them adequately. While reliable decision-tree methods exist to triage\npatients based on their presentation, those trees implicitly require human\ninference and are not immediately applicable in a fully automated setting. On\nthe other hand, learning triage policies directly from experts may correct for\nsome of the limitations of hard-coded decision-trees. In this work, we present\na Deep Reinforcement Learning approach (a variant of DeepQ-Learning) to triage\npatients using curated clinical vignettes. The dataset, consisting of 1374\nclinical vignettes, was created by medical doctors to represent real-life\ncases. Each vignette is associated with an average of 3.8 expert triage\ndecisions given by medical doctors relying solely on medical history. We show\nthat this approach is on a par with human performance, yielding safe triage\ndecisions in 94% of cases, and matching expert decisions in 85% of cases. The\ntrained agent learns when to stop asking questions, acquires optimized decision\npolicies requiring less evidence than supervised approaches, and adapts to the\nnovelty of a situation by asking for more information. Overall, we demonstrate\nthat a Deep Reinforcement Learning approach can learn effective medical triage\npolicies directly from expert decisions, without requiring expert knowledge\nengineering. This approach is scalable and can be deployed in healthcare\nsettings or geographical regions with distinct triage specifications, or where\ntrained experts are scarce, to improve decision making in the early stage of\ncare.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 16:07:41 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 16:39:37 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Buchard", "Albert", ""], ["Bouvier", "Baptiste", ""], ["Prando", "Giulia", ""], ["Beard", "Rory", ""], ["Livieratos", "Michail", ""], ["Busbridge", "Dan", ""], ["Thompson", "Daniel", ""], ["Richens", "Jonathan", ""], ["Zhang", "Yuanzhao", ""], ["Baker", "Adam", ""], ["Perov", "Yura", ""], ["Gourgoulias", "Kostis", ""], ["Johri", "Saurabh", ""]]}, {"id": "2003.12857", "submitter": "Chen Wei", "authors": "Chen Wei, Chuang Niu, Yiping Tang, Yue Wang, Haihong Hu, Jimin Liang", "title": "NPENAS: Neural Predictor Guided Evolution for Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) is a promising method for automatically\ndesign neural architectures. NAS adopts a search strategy to explore the\npredefined search space to find outstanding performance architecture with the\nminimum searching costs. Bayesian optimization and evolutionary algorithms are\ntwo commonly used search strategies, but they suffer from computationally\nexpensive, challenge to implement or inefficient exploration ability. In this\npaper, we propose a neural predictor guided evolutionary algorithm to enhance\nthe exploration ability of EA for NAS (NPENAS) and design two kinds of neural\npredictors. The first predictor is defined from Bayesian optimization and we\npropose a graph-based uncertainty estimation network as a surrogate model that\nis easy to implement and computationally efficient. The second predictor is a\ngraph-based neural network that directly outputs the performance prediction of\nthe input neural architecture. The NPENAS using the two neural predictors are\ndenoted as NPENAS-BO and NPENAS-NP respectively. In addition, we introduce a\nnew random architecture sampling method to overcome the drawbacks of the\nexisting sampling method. Extensive experiments demonstrate the superiority of\nNPENAS. Quantitative results on three NAS search spaces indicate that both\nNPENAS-BO and NPENAS-NP outperform most existing NAS algorithms, with NPENAS-BO\nachieving state-of-the-art performance on NASBench-201 and NPENAS-NP on\nNASBench-101 and DARTS, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 17:56:31 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 16:32:49 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 06:22:06 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Wei", "Chen", ""], ["Niu", "Chuang", ""], ["Tang", "Yiping", ""], ["Wang", "Yue", ""], ["Hu", "Haihong", ""], ["Liang", "Jimin", ""]]}, {"id": "2003.12900", "submitter": "Georg Rehm", "authors": "Juli\\'an Moreno-Schneider and Georg Rehm and Elena Montiel-Ponsoda and\n  V\\'ictor Rodriguez-Doncel and Artem Revenko and Sotirios Karampatakis and\n  Maria Khvalchik and Christian Sageder and Jorge Gracia and Filippo Maganza", "title": "Orchestrating NLP Services for the Legal Domain", "comments": "Proceedings of the 12th Language Resources and Evaluation Conference\n  (LREC 2020). To appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legal technology is currently receiving a lot of attention from various\nangles. In this contribution we describe the main technical components of a\nsystem that is currently under development in the European innovation project\nLynx, which includes partners from industry and research. The key contribution\nof this paper is a workflow manager that enables the flexible orchestration of\nworkflows based on a portfolio of Natural Language Processing and Content\nCuration services as well as a Multilingual Legal Knowledge Graph that contains\nsemantic information and meaningful references to legal documents. We also\ndescribe different use cases with which we experiment and develop prototypical\nsolutions.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 22:10:48 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Moreno-Schneider", "Juli\u00e1n", ""], ["Rehm", "Georg", ""], ["Montiel-Ponsoda", "Elena", ""], ["Rodriguez-Doncel", "V\u00edctor", ""], ["Revenko", "Artem", ""], ["Karampatakis", "Sotirios", ""], ["Khvalchik", "Maria", ""], ["Sageder", "Christian", ""], ["Gracia", "Jorge", ""], ["Maganza", "Filippo", ""]]}, {"id": "2003.12909", "submitter": "Adish Singla", "authors": "Amin Rakhsha, Goran Radanovic, Rati Devidze, Xiaojin Zhu, Adish Singla", "title": "Policy Teaching via Environment Poisoning: Training-time Adversarial\n  Attacks against Reinforcement Learning", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a security threat to reinforcement learning where an attacker\npoisons the learning environment to force the agent into executing a target\npolicy chosen by the attacker. As a victim, we consider RL agents whose\nobjective is to find a policy that maximizes average reward in undiscounted\ninfinite-horizon problem settings. The attacker can manipulate the rewards or\nthe transition dynamics in the learning environment at training-time and is\ninterested in doing so in a stealthy manner. We propose an optimization\nframework for finding an \\emph{optimal stealthy attack} for different measures\nof attack cost. We provide sufficient technical conditions under which the\nattack is feasible and provide lower/upper bounds on the attack cost. We\ninstantiate our attacks in two settings: (i) an \\emph{offline} setting where\nthe agent is doing planning in the poisoned environment, and (ii) an\n\\emph{online} setting where the agent is learning a policy using a\nregret-minimization framework with poisoned feedback. Our results show that the\nattacker can easily succeed in teaching any target policy to the victim under\nmild conditions and highlight a significant security threat to reinforcement\nlearning agents in practice.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 23:22:28 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 00:07:20 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Rakhsha", "Amin", ""], ["Radanovic", "Goran", ""], ["Devidze", "Rati", ""], ["Zhu", "Xiaojin", ""], ["Singla", "Adish", ""]]}, {"id": "2003.12924", "submitter": "Christian Henkel", "authors": "Christian Henkel and Marc Toussaint", "title": "Optimized Directed Roadmap Graph for Multi-Agent Path Finding Using\n  Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach called Optimized Directed Roadmap Graph (ODRM).\nIt is a method to build a directed roadmap graph that allows for collision\navoidance in multi-robot navigation. This is a highly relevant problem, for\nexample for industrial autonomous guided vehicles. The core idea of ODRM is,\nthat a directed roadmap can encode inherent properties of the environment which\nare useful when agents have to avoid each other in that same environment. Like\nProbabilistic Roadmaps (PRMs), ODRM's first step is generating samples from\nC-space. In a second step, ODRM optimizes vertex positions and edge directions\nby Stochastic Gradient Descent (SGD). This leads to emergent properties like\nedges parallel to walls and patterns similar to two-lane streets or\nroundabouts. Agents can then navigate on this graph by searching their path\nindependently and solving occurring agent-agent collisions at run-time. Using\nthe graphs generated by ODRM compared to a non-optimized graph significantly\nfewer agent-agent collisions happen. We evaluate our roadmap with both,\ncentralized and decentralized planners. Our experiments show that with ODRM\neven a simple centralized planner can solve problems with high numbers of\nagents that other multi-agent planners can not solve. Additionally, we use\nsimulated robots with decentralized planners and online collision avoidance to\nshow how agents are a lot faster on our roadmap than on standard grid maps.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 02:18:31 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Henkel", "Christian", ""], ["Toussaint", "Marc", ""]]}, {"id": "2003.12948", "submitter": "Chongzhen Zhang", "authors": "Chongzhen Zhang, Jianrui Wang, Gary G. Yen, Chaoqiang Zhao, Qiyu Sun,\n  Yang Tang, Feng Qian, and J\\\"urgen Kurths", "title": "When Autonomous Systems Meet Accuracy and Transferability through AI: A\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With widespread applications of artificial intelligence (AI), the\ncapabilities of the perception, understanding, decision-making and control for\nautonomous systems have improved significantly in the past years. When\nautonomous systems consider the performance of accuracy and transferability,\nseveral AI methods, like adversarial learning, reinforcement learning (RL) and\nmeta-learning, show their powerful performance. Here, we review the\nlearning-based approaches in autonomous systems from the perspectives of\naccuracy and transferability. Accuracy means that a well-trained model shows\ngood results during the testing phase, in which the testing set shares a same\ntask or a data distribution with the training set. Transferability means that\nwhen a well-trained model is transferred to other testing domains, the accuracy\nis still good. Firstly, we introduce some basic concepts of transfer learning\nand then present some preliminaries of adversarial learning, RL and\nmeta-learning. Secondly, we focus on reviewing the accuracy or transferability\nor both of them to show the advantages of adversarial learning, like generative\nadversarial networks (GANs), in typical computer vision tasks in autonomous\nsystems, including image style transfer, image superresolution, image\ndeblurring/dehazing/rain removal, semantic segmentation, depth estimation,\npedestrian detection and person re-identification (re-ID). Then, we further\nreview the performance of RL and meta-learning from the aspects of accuracy or\ntransferability or both of them in autonomous systems, involving pedestrian\ntracking, robot navigation and robotic manipulation. Finally, we discuss\nseveral challenges and future topics for using adversarial learning, RL and\nmeta-learning in autonomous systems.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 04:50:22 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 02:27:09 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 02:05:38 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhang", "Chongzhen", ""], ["Wang", "Jianrui", ""], ["Yen", "Gary G.", ""], ["Zhao", "Chaoqiang", ""], ["Sun", "Qiyu", ""], ["Tang", "Yang", ""], ["Qian", "Feng", ""], ["Kurths", "J\u00fcrgen", ""]]}, {"id": "2003.13084", "submitter": "Daniel Garijo", "authors": "Daniel Garijo and Mar\\'ia Poveda-Villal\\'on", "title": "Best Practices for Implementing FAIR Vocabularies and Ontologies on the\n  Web", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the adoption of Semantic Web technologies, an increasing number of\nvocabularies and ontologies have been developed in different domains, ranging\nfrom Biology to Agronomy or Geosciences. However, many of these ontologies are\nstill difficult to find, access and understand by researchers due to a lack of\ndocumentation, URI resolving issues, versioning problems, etc. In this chapter\nwe describe guidelines and best practices for creating accessible,\nunderstandable and reusable ontologies on the Web, using standard practices and\npointing to existing tools and frameworks developed by the Semantic Web\ncommunity. We illustrate our guidelines with concrete examples, in order to\nhelp researchers implement these practices in their future vocabularies.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 17:40:04 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Garijo", "Daniel", ""], ["Poveda-Villal\u00f3n", "Mar\u00eda", ""]]}, {"id": "2003.13085", "submitter": "Yongyuan Liang", "authors": "Yongyuan Liang, Bangwei Li", "title": "Parallel Knowledge Transfer in Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning is a standard framework for modeling\nmulti-agent interactions applied in real-world scenarios. Inspired by\nexperience sharing in human groups, learning knowledge parallel reusing between\nagents can potentially promote team learning performance, especially in\nmulti-task environments. When all agents interact with the environment and\nlearn simultaneously, how each independent agent selectively learns from other\nagents' behavior knowledge is a problem that we need to solve. This paper\nproposes a novel knowledge transfer framework in MARL, PAT (Parallel\nAttentional Transfer). We design two acting modes in PAT, student mode and\nself-learning mode. Each agent in our approach trains a decentralized student\nactor-critic to determine its acting mode at each time step. When agents are\nunfamiliar with the environment, the shared attention mechanism in student mode\neffectively selects learning knowledge from other agents to decide agents'\nactions. PAT outperforms state-of-the-art empirical evaluation results against\nthe prior advising approaches. Our approach not only significantly improves\nteam learning rate and global performance, but also is flexible and\ntransferable to be applied in various multi-agent systems.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 17:42:00 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Liang", "Yongyuan", ""], ["Li", "Bangwei", ""]]}, {"id": "2003.13159", "submitter": "Tanel Tammet", "authors": "Tanel Tammet", "title": "Extending Automated Deduction for Commonsense Reasoning", "comments": "19 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense reasoning has long been considered as one of the holy grails of\nartificial intelligence. Most of the recent progress in the field has been\nachieved by novel machine learning algorithms for natural language processing.\nHowever, without incorporating logical reasoning, these algorithms remain\narguably shallow. With some notable exceptions, developers of practical\nautomated logic-based reasoners have mostly avoided focusing on the problem.\nThe paper argues that the methods and algorithms used by existing automated\nreasoners for classical first-order logic can be extended towards commonsense\nreasoning. Instead of devising new specialized logics we propose a framework of\nextensions to the mainstream resolution-based search methods to make these\ncapable of performing search tasks for practical commonsense reasoning with\nreasonable efficiency. The proposed extensions mostly rely on operating on\nordinary proof trees and are devised to handle commonsense knowledge bases\ncontaining inconsistencies, default rules, taxonomies, topics, relevance,\nconfidence and similarity measures. We claim that machine learning is best\nsuited for the construction of commonsense knowledge bases while the extended\nlogic-based methods would be well-suited for actually answering queries from\nthese knowledge bases.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 23:17:16 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Tammet", "Tanel", ""]]}, {"id": "2003.13450", "submitter": "Son-Il Kwak", "authors": "I.M. Son, S.I. Kwak, U.J. Han, J.H. Pak, M. Han, J.R. Pyon, U.S. Ryu", "title": "A Novel Fuzzy Approximate Reasoning Method Based on Extended Distance\n  Measure in SISO Fuzzy System", "comments": "24 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an original method of fuzzy approximate reasoning that\ncan open a new direction of research in the uncertainty inference of Artificial\nIntelligence(AI) and Computational Intelligence(CI). Fuzzy modus ponens (FMP)\nand fuzzy modus tollens(FMT) are two fundamental and basic models of general\nfuzzy approximate reasoning in various fuzzy systems. And the reductive\nproperty is one of the essential and important properties in the approximate\nreasoning theory and it is a lot of applications. This paper suggests a kind of\nextended distance measure (EDM) based approximate reasoning method in the\nsingle input single output(SISO) fuzzy system with discrete fuzzy set vectors\nof different dimensions. The EDM based fuzzy approximate reasoning method is\nconsists of two part, i.e., FMP-EDM and FMT-EDM. The distance measure based\nfuzzy reasoning method that the dimension of the antecedent discrete fuzzy set\nis equal to one of the consequent discrete fuzzy set has already solved in\nother paper. In this paper discrete fuzzy set vectors of different dimensions\nmean that the dimension of the antecedent discrete fuzzy set differs from one\nof the consequent discrete fuzzy set in the SISO fuzzy system. That is, this\npaper is based on EDM. The experimental results highlight that the proposed\napproximate reasoning method is comparatively clear and effective with respect\nto the reductive property, and in accordance with human thinking than existing\nfuzzy reasoning methods.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 02:31:53 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Son", "I. M.", ""], ["Kwak", "S. I.", ""], ["Han", "U. J.", ""], ["Pak", "J. H.", ""], ["Han", "M.", ""], ["Pyon", "J. R.", ""], ["Ryu", "U. S.", ""]]}, {"id": "2003.13532", "submitter": "Jamal Toutouh", "authors": "Jamal Toutouh, Erik Hemberg, and Una-May O'Reilly", "title": "Re-purposing Heterogeneous Generative Ensembles with Evolutionary\n  Computation", "comments": "Accepted as a full paper for the Genetic and Evolutionary Computation\n  Conference - GECCO'20", "journal-ref": null, "doi": "10.1145/3377930.3390229", "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are popular tools for generative\nmodeling. The dynamics of their adversarial learning give rise to convergence\npathologies during training such as mode and discriminator collapse. In machine\nlearning, ensembles of predictors demonstrate better results than a single\npredictor for many tasks. In this study, we apply two evolutionary algorithms\n(EAs) to create ensembles to re-purpose generative models, i.e., given a set of\nheterogeneous generators that were optimized for one objective (e.g., minimize\nFrechet Inception Distance), create ensembles of them for optimizing a\ndifferent objective (e.g., maximize the diversity of the generated samples).\nThe first method is restricted by the exact size of the ensemble and the second\nmethod only restricts the upper bound of the ensemble size. Experimental\nanalysis on the MNIST image benchmark demonstrates that both EA ensembles\ncreation methods can re-purpose the models, without reducing their original\nfunctionality. The EA-based demonstrate significantly better performance\ncompared to other heuristic-based methods. When comparing both evolutionary,\nthe one with only an upper size bound on the ensemble size is the best.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 15:04:40 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 17:48:34 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Toutouh", "Jamal", ""], ["Hemberg", "Erik", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "2003.13590", "submitter": "Tao Qin Dr.", "authors": "Junjie Li, Sotetsu Koyamada, Qiwei Ye, Guoqing Liu, Chao Wang, Ruihan\n  Yang, Li Zhao, Tao Qin, Tie-Yan Liu, Hsiao-Wuen Hon", "title": "Suphx: Mastering Mahjong with Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) has achieved great success in many domains, and\ngame AI is widely regarded as its beachhead since the dawn of AI. In recent\nyears, studies on game AI have gradually evolved from relatively simple\nenvironments (e.g., perfect-information games such as Go, chess, shogi or\ntwo-player imperfect-information games such as heads-up Texas hold'em) to more\ncomplex ones (e.g., multi-player imperfect-information games such as\nmulti-player Texas hold'em and StartCraft II). Mahjong is a popular\nmulti-player imperfect-information game worldwide but very challenging for AI\nresearch due to its complex playing/scoring rules and rich hidden information.\nWe design an AI for Mahjong, named Suphx, based on deep reinforcement learning\nwith some newly introduced techniques including global reward prediction,\noracle guiding, and run-time policy adaptation. Suphx has demonstrated stronger\nperformance than most top human players in terms of stable rank and is rated\nabove 99.99% of all the officially ranked human players in the Tenhou platform.\nThis is the first time that a computer program outperforms most top human\nplayers in Mahjong.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 16:18:16 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 03:46:55 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Li", "Junjie", ""], ["Koyamada", "Sotetsu", ""], ["Ye", "Qiwei", ""], ["Liu", "Guoqing", ""], ["Wang", "Chao", ""], ["Yang", "Ruihan", ""], ["Zhao", "Li", ""], ["Qin", "Tao", ""], ["Liu", "Tie-Yan", ""], ["Hon", "Hsiao-Wuen", ""]]}, {"id": "2003.13633", "submitter": "Francisco \\'Alvarez", "authors": "F. Mart\\'inez-\\'Alvarez, G. Asencio-Cort\\'es, J. F. Torres, D.\n  Guti\\'errez-Avil\\'es, L. Melgar-Garc\\'ia, R. P\\'erez-Chac\\'on, C.\n  Rubio-Escudero, J. C. Riquelme, A. Troncoso", "title": "Coronavirus Optimization Algorithm: A bioinspired metaheuristic based on\n  the COVID-19 propagation model", "comments": "30 pages, 4 figures", "journal-ref": null, "doi": "10.1089/big.2020.0051", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel bioinspired metaheuristic is proposed in this work, simulating how\nthe coronavirus spreads and infects healthy people. From an initial individual\n(the patient zero), the coronavirus infects new patients at known rates,\ncreating new populations of infected people. Every individual can either die or\ninfect and, afterwards, be sent to the recovered population. Relevant terms\nsuch as re-infection probability, super-spreading rate or traveling rate are\nintroduced in the model in order to simulate as accurately as possible the\ncoronavirus activity. The Coronavirus Optimization Algorithm has two major\nadvantages compared to other similar strategies. First, the input parameters\nare already set according to the disease statistics, preventing researchers\nfrom initializing them with arbitrary values. Second, the approach has the\nability of ending after several iterations, without setting this value either.\nInfected population initially grows at an exponential rate but after some\niterations, when considering social isolation measures and the high number\nrecovered and dead people, the number of infected people starts decreasing in\nsubsequent iterations. Furthermore, a parallel multi-virus version is proposed\nin which several coronavirus strains evolve over time and explore wider search\nspace areas in less iterations. Finally, the metaheuristic has been combined\nwith deep learning models, in order to find optimal hyperparameters during the\ntraining phase. As application case, the problem of electricity load time\nseries forecasting has been addressed, showing quite remarkable performance.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 17:10:02 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 11:28:04 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Mart\u00ednez-\u00c1lvarez", "F.", ""], ["Asencio-Cort\u00e9s", "G.", ""], ["Torres", "J. F.", ""], ["Guti\u00e9rrez-Avil\u00e9s", "D.", ""], ["Melgar-Garc\u00eda", "L.", ""], ["P\u00e9rez-Chac\u00f3n", "R.", ""], ["Rubio-Escudero", "C.", ""], ["Riquelme", "J. C.", ""], ["Troncoso", "A.", ""]]}, {"id": "2003.13661", "submitter": "Ruihan Yang", "authors": "Ruihan Yang, Huazhe Xu, Yi Wu, Xiaolong Wang", "title": "Multi-Task Reinforcement Learning with Soft Modularization", "comments": "Our project page: https://rchalyang.github.io/SoftModule", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning is a very challenging problem in reinforcement learning.\nWhile training multiple tasks jointly allow the policies to share parameters\nacross different tasks, the optimization problem becomes non-trivial: It\nremains unclear what parameters in the network should be reused across tasks,\nand how the gradients from different tasks may interfere with each other. Thus,\ninstead of naively sharing parameters across tasks, we introduce an explicit\nmodularization technique on policy representation to alleviate this\noptimization issue. Given a base policy network, we design a routing network\nwhich estimates different routing strategies to reconfigure the base network\nfor each task. Instead of directly selecting routes for each task, our\ntask-specific policy uses a method called soft modularization to softly combine\nall the possible routes, which makes it suitable for sequential tasks. We\nexperiment with various robotics manipulation tasks in simulation and show our\nmethod improves both sample efficiency and performance over strong baselines by\na large margin.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 17:47:04 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 07:14:11 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Yang", "Ruihan", ""], ["Xu", "Huazhe", ""], ["Wu", "Yi", ""], ["Wang", "Xiaolong", ""]]}, {"id": "2003.13668", "submitter": "Sam Vente", "authors": "Sam Vente (1), Angelika Kimmig (1), Alun Preece (1), Federico Cerutti\n  (2) ((1) Cardiff University, (2) University of Brescia)", "title": "Increasing negotiation performance at the edge of the network", "comments": "Accepted for presentation at The 7th International Conference on\n  Agreement Technologies (AT 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Automated negotiation has been used in a variety of distributed settings,\nsuch as privacy in the Internet of Things (IoT) devices and power distribution\nin Smart Grids. The most common protocol under which these agents negotiate is\nthe Alternating Offers Protocol (AOP). Under this protocol, agents cannot\nexpress any additional information to each other besides a counter offer. This\ncan lead to unnecessarily long negotiations when, for example, negotiations are\nimpossible, risking to waste bandwidth that is a precious resource at the edge\nof the network. While alternative protocols exist which alleviate this problem,\nthese solutions are too complex for low power devices, such as IoT sensors\noperating at the edge of the network. To improve this bottleneck, we introduce\nan extension to AOP called Alternating Constrained Offers Protocol (ACOP), in\nwhich agents can also express constraints to each other. This allows agents to\nboth search the possibility space more efficiently and recognise impossible\nsituations sooner. We empirically show that agents using ACOP can significantly\nreduce the number of messages a negotiation takes, independently of the\nstrategy agents choose. In particular, we show our method significantly reduces\nthe number of messages when an agreement is not possible. Furthermore, when an\nagreement is possible it reaches this agreement sooner with no negative effect\non the utility.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 17:52:59 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Vente", "Sam", "", "Cardiff University"], ["Kimmig", "Angelika", "", "Cardiff University"], ["Preece", "Alun", "", "Cardiff University"], ["Cerutti", "Federico", "", "University of Brescia"]]}, {"id": "2003.13676", "submitter": "Pieter Libin", "authors": "Pieter Libin, Arno Moonens, Timothy Verstraeten, Fabian\n  Perez-Sanjines, Niel Hens, Philippe Lemey, Ann Now\\'e", "title": "Deep reinforcement learning for large-scale epidemic control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epidemics of infectious diseases are an important threat to public health and\nglobal economies. Yet, the development of prevention strategies remains a\nchallenging process, as epidemics are non-linear and complex processes. For\nthis reason, we investigate a deep reinforcement learning approach to\nautomatically learn prevention strategies in the context of pandemic influenza.\nFirstly, we construct a new epidemiological meta-population model, with 379\npatches (one for each administrative district in Great Britain), that\nadequately captures the infection process of pandemic influenza. Our model\nbalances complexity and computational efficiency such that the use of\nreinforcement learning techniques becomes attainable. Secondly, we set up a\nground truth such that we can evaluate the performance of the 'Proximal Policy\nOptimization' algorithm to learn in a single district of this epidemiological\nmodel. Finally, we consider a large-scale problem, by conducting an experiment\nwhere we aim to learn a joint policy to control the districts in a community of\n11 tightly coupled districts, for which no ground truth can be established.\nThis experiment shows that deep reinforcement learning can be used to learn\nmitigation policies in complex epidemiological models with a large state space.\nMoreover, through this experiment, we demonstrate that there can be an\nadvantage to consider collaboration between districts when designing prevention\nstrategies.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 17:57:09 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Libin", "Pieter", ""], ["Moonens", "Arno", ""], ["Verstraeten", "Timothy", ""], ["Perez-Sanjines", "Fabian", ""], ["Hens", "Niel", ""], ["Lemey", "Philippe", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "2003.13741", "submitter": "Karl Kurzer", "authors": "Karl Kurzer, Christoph H\\\"ortnagl, J. Marius Z\\\"ollner", "title": "Parallelization of Monte Carlo Tree Search in Continuous Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo Tree Search (MCTS) has proven to be capable of solving\nchallenging tasks in domains such as Go, chess and Atari. Previous research has\ndeveloped parallel versions of MCTS, exploiting today's multiprocessing\narchitectures. These studies focused on versions of MCTS for the discrete case.\nOur work builds upon existing parallelization strategies and extends them to\ncontinuous domains. In particular, leaf parallelization and root\nparallelization are studied and two final selection strategies that are\nrequired to handle continuous states in root parallelization are proposed. The\nevaluation of the resulting parallelized continuous MCTS is conducted using a\nchallenging cooperative multi-agent system trajectory planning task in the\ndomain of automated vehicles.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 18:43:59 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Kurzer", "Karl", ""], ["H\u00f6rtnagl", "Christoph", ""], ["Z\u00f6llner", "J. Marius", ""]]}, {"id": "2003.13754", "submitter": "Connor Coley", "authors": "Connor W. Coley, Natalie S. Eyke, Klavs F. Jensen", "title": "Autonomous discovery in the chemical sciences part I: Progress", "comments": "Revised version available at 10.1002/anie.201909987", "journal-ref": null, "doi": "10.1002/anie.201909987", "report-no": null, "categories": "q-bio.QM cs.AI cs.RO stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This two-part review examines how automation has contributed to different\naspects of discovery in the chemical sciences. In this first part, we describe\na classification for discoveries of physical matter (molecules, materials,\ndevices), processes, and models and how they are unified as search problems. We\nthen introduce a set of questions and considerations relevant to assessing the\nextent of autonomy. Finally, we describe many case studies of discoveries\naccelerated by or resulting from computer assistance and automation from the\ndomains of synthetic chemistry, drug discovery, inorganic chemistry, and\nmaterials science. These illustrate how rapid advancements in hardware\nautomation and machine learning continue to transform the nature of\nexperimentation and modelling.\n  Part two reflects on these case studies and identifies a set of open\nchallenges for the field.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 19:11:31 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Coley", "Connor W.", ""], ["Eyke", "Natalie S.", ""], ["Jensen", "Klavs F.", ""]]}, {"id": "2003.13755", "submitter": "Connor Coley", "authors": "Connor W. Coley, Natalie S. Eyke, Klavs F. Jensen", "title": "Autonomous discovery in the chemical sciences part II: Outlook", "comments": "Revised version available at 10.1002/anie.201909989", "journal-ref": null, "doi": "10.1002/anie.201909989", "report-no": null, "categories": "q-bio.QM cs.AI cs.RO stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This two-part review examines how automation has contributed to different\naspects of discovery in the chemical sciences. In this second part, we reflect\non a selection of exemplary studies. It is increasingly important to articulate\nwhat the role of automation and computation has been in the scientific process\nand how that has or has not accelerated discovery. One can argue that even the\nbest automated systems have yet to ``discover'' despite being incredibly useful\nas laboratory assistants. We must carefully consider how they have been and can\nbe applied to future problems of chemical discovery in order to effectively\ndesign and interact with future autonomous platforms.\n  The majority of this article defines a large set of open research directions,\nincluding improving our ability to work with complex data, build empirical\nmodels, automate both physical and computational experiments for validation,\nselect experiments, and evaluate whether we are making progress toward the\nultimate goal of autonomous discovery. Addressing these practical and\nmethodological challenges will greatly advance the extent to which autonomous\nsystems can make meaningful discoveries.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 19:11:35 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Coley", "Connor W.", ""], ["Eyke", "Natalie S.", ""], ["Jensen", "Klavs F.", ""]]}, {"id": "2003.13806", "submitter": "Luca Capezzuto", "authors": "Luca Capezzuto and Danesh Tarapore and Sarvapali D. Ramchurn", "title": "Anytime and Efficient Coalition Formation with Spatial and Temporal\n  Constraints", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Coalition Formation with Spatial and Temporal constraints Problem (CFSTP)\nis a multi-agent task scheduling problem where the tasks are spatially\ndistributed, with deadlines and workloads, and the number of agents is\ntypically much smaller than the number of tasks, thus the agents have to form\ncoalitions in order to maximise the number of completed tasks. The current\nstate-of-the-art CFSTP solver, the Coalition Formation with Look-Ahead (CFLA)\nalgorithm, has two main limitations. First, its time complexity is exponential\nwith the number of agents. Second, as we show, its look-ahead technique is not\neffective in real-world scenarios, such as open multi-agent systems, where new\ntasks can appear at any time. In this work, we study its design and define an\nextension, called Coalition Formation with Improved Look-Ahead (CFLA2), which\nachieves better performance. Since we cannot eliminate the limitations of CFLA\nin CFLA2, we also develop a novel algorithm to solve the CFSTP, the first to be\nanytime, efficient and with provable guarantees, called Cluster-based Coalition\nFormation (CCF). We empirically show that, in settings where the look-ahead\ntechnique is highly effective, CCF completes up to 30% (resp. 10%) more tasks\nthan CFLA (resp. CFLA2) while being up to four orders of magnitude faster. Our\nresults affirm CCF as the new state-of-the-art algorithm to solve the CFSTP.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 20:42:56 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 22:13:51 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 16:23:55 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Capezzuto", "Luca", ""], ["Tarapore", "Danesh", ""], ["Ramchurn", "Sarvapali D.", ""]]}, {"id": "2003.13833", "submitter": "Georg Rehm", "authors": "Georg Rehm and Katrin Marheinecke and Stefanie Hegele and Stelios\n  Piperidis and Kalina Bontcheva and Jan Haji\\v{c} and Khalid Choukri and\n  Andrejs Vasi\\c{l}jevs and Gerhard Backfried and Christoph Prinz and Jos\\'e\n  Manuel G\\'omez P\\'erez and Luc Meertens and Paul Lukowicz and Josef van\n  Genabith and Andrea L\\\"osch and Philipp Slusallek and Morten Irgens and\n  Patrick Gatellier and Joachim K\\\"ohler and Laure Le Bars and Dimitra\n  Anastasiou and Albina Auksori\\=ut\\.e and N\\'uria Bel and Ant\\'onio Branco and\n  Gerhard Budin and Walter Daelemans and Koenraad De Smedt and Radovan\n  Garab\\'ik and Maria Gavriilidou and Dagmar Gromann and Svetla Koeva and Simon\n  Krek and Cvetana Krstev and Krister Lind\\'en and Bernardo Magnini and Jan\n  Odijk and Maciej Ogrodniczuk and Eir\\'ikur R\\\"ognvaldsson and Mike Rosner and\n  Bolette Sandford Pedersen and Inguna Skadi\\c{n}a and Marko Tadi\\'c and Dan\n  Tufi\\c{s} and Tam\\'as V\\'aradi and Kadri Vider and Andy Way and Fran\\c{c}ois\n  Yvon", "title": "The European Language Technology Landscape in 2020: Language-Centric and\n  Human-Centric AI for Cross-Cultural Communication in Multilingual Europe", "comments": "Proceedings of the 12th Language Resources and Evaluation Conference\n  (LREC 2020). To appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingualism is a cultural cornerstone of Europe and firmly anchored in\nthe European treaties including full language equality. However, language\nbarriers impacting business, cross-lingual and cross-cultural communication are\nstill omnipresent. Language Technologies (LTs) are a powerful means to break\ndown these barriers. While the last decade has seen various initiatives that\ncreated a multitude of approaches and technologies tailored to Europe's\nspecific needs, there is still an immense level of fragmentation. At the same\ntime, AI has become an increasingly important concept in the European\nInformation and Communication Technology area. For a few years now, AI,\nincluding many opportunities, synergies but also misconceptions, has been\novershadowing every other topic. We present an overview of the European LT\nlandscape, describing funding programmes, activities, actions and challenges in\nthe different countries with regard to LT, including the current state of play\nin industry and the LT market. We present a brief overview of the main\nLT-related activities on the EU level in the last ten years and develop\nstrategic guidance with regard to four key dimensions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 21:42:45 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Rehm", "Georg", ""], ["Marheinecke", "Katrin", ""], ["Hegele", "Stefanie", ""], ["Piperidis", "Stelios", ""], ["Bontcheva", "Kalina", ""], ["Haji\u010d", "Jan", ""], ["Choukri", "Khalid", ""], ["Vasi\u013cjevs", "Andrejs", ""], ["Backfried", "Gerhard", ""], ["Prinz", "Christoph", ""], ["P\u00e9rez", "Jos\u00e9 Manuel G\u00f3mez", ""], ["Meertens", "Luc", ""], ["Lukowicz", "Paul", ""], ["van Genabith", "Josef", ""], ["L\u00f6sch", "Andrea", ""], ["Slusallek", "Philipp", ""], ["Irgens", "Morten", ""], ["Gatellier", "Patrick", ""], ["K\u00f6hler", "Joachim", ""], ["Bars", "Laure Le", ""], ["Anastasiou", "Dimitra", ""], ["Auksori\u016bt\u0117", "Albina", ""], ["Bel", "N\u00faria", ""], ["Branco", "Ant\u00f3nio", ""], ["Budin", "Gerhard", ""], ["Daelemans", "Walter", ""], ["De Smedt", "Koenraad", ""], ["Garab\u00edk", "Radovan", ""], ["Gavriilidou", "Maria", ""], ["Gromann", "Dagmar", ""], ["Koeva", "Svetla", ""], ["Krek", "Simon", ""], ["Krstev", "Cvetana", ""], ["Lind\u00e9n", "Krister", ""], ["Magnini", "Bernardo", ""], ["Odijk", "Jan", ""], ["Ogrodniczuk", "Maciej", ""], ["R\u00f6gnvaldsson", "Eir\u00edkur", ""], ["Rosner", "Mike", ""], ["Pedersen", "Bolette Sandford", ""], ["Skadi\u0146a", "Inguna", ""], ["Tadi\u0107", "Marko", ""], ["Tufi\u015f", "Dan", ""], ["V\u00e1radi", "Tam\u00e1s", ""], ["Vider", "Kadri", ""], ["Way", "Andy", ""], ["Yvon", "Fran\u00e7ois", ""]]}, {"id": "2003.13839", "submitter": "Qignrui Zhang", "authors": "Qingrui Zhang and Wei Pan and Vasso Reppa", "title": "Model-Reference Reinforcement Learning Control of Autonomous Surface\n  Vehicles with Uncertainties", "comments": "9 pages, 10 figures,", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.RO cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel model-reference reinforcement learning control\nmethod for uncertain autonomous surface vehicles. The proposed control combines\na conventional control method with deep reinforcement learning. With the\nconventional control, we can ensure the learning-based control law provides\nclosed-loop stability for the overall system, and potentially increase the\nsample efficiency of the deep reinforcement learning. With the reinforcement\nlearning, we can directly learn a control law to compensate for modeling\nuncertainties. In the proposed control, a nominal system is employed for the\ndesign of a baseline control law using a conventional control approach. The\nnominal system also defines the desired performance for uncertain autonomous\nvehicles to follow. In comparison with traditional deep reinforcement learning\nmethods, our proposed learning-based control can provide stability guarantees\nand better sample efficiency. We demonstrate the performance of the new\nalgorithm via extensive simulation results.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 22:02:13 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Zhang", "Qingrui", ""], ["Pan", "Wei", ""], ["Reppa", "Vasso", ""]]}, {"id": "2003.13861", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "A Pebble in the AI Race", "comments": "To appear in the Druk Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bhutan is sometimes described as \\a pebble between two boulders\", a small\ncountry caught between the two most populous nations on earth: India and China.\nThis pebble is, however, about to be caught up in a vortex: the transformation\nof our economic, political and social orders by new technologies like\nArtificial Intelligence. What can a small nation like Bhutan hope to do in the\nface of such change? What should the nation do, not just to weather this storm,\nbut to become a better place in which to live?\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 23:11:50 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "2003.13949", "submitter": "Zhentao Tang", "authors": "Zhentao Tang, Yuanheng Zhu, Dongbin Zhao, Simon M. Lucas", "title": "Enhanced Rolling Horizon Evolution Algorithm with Opponent Model\n  Learning: Results for the Fighting Game AI Competition", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fighting Game AI Competition (FTGAIC) provides a challenging benchmark\nfor 2-player video game AI. The challenge arises from the large action space,\ndiverse styles of characters and abilities, and the real-time nature of the\ngame. In this paper, we propose a novel algorithm that combines Rolling Horizon\nEvolution Algorithm (RHEA) with opponent model learning. The approach is\nreadily applicable to any 2-player video game. In contrast to conventional\nRHEA, an opponent model is proposed and is optimized by supervised learning\nwith cross-entropy and reinforcement learning with policy gradient and\nQ-learning respectively, based on history observations from opponent. The model\nis learned during the live gameplay. With the learned opponent model, the\nextended RHEA is able to make more realistic plans based on what the opponent\nis likely to do. This tends to lead to better results. We compared our approach\ndirectly with the bots from the FTGAIC 2018 competition, and found our method\nto significantly outperform all of them, for all three character. Furthermore,\nour proposed bot with the policy-gradient-based opponent model is the only one\nwithout using Monte-Carlo Tree Search (MCTS) among top five bots in the 2019\ncompetition in which it achieved second place, while using much less domain\nknowledge than the winner.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 04:44:33 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Tang", "Zhentao", ""], ["Zhu", "Yuanheng", ""], ["Zhao", "Dongbin", ""], ["Lucas", "Simon M.", ""]]}, {"id": "2003.13956", "submitter": "Gong Cheng", "authors": "Yawei Sun, Lingling Zhang, Gong Cheng, Yuzhong Qu", "title": "SPARQA: Skeleton-based Semantic Parsing for Complex Questions over\n  Knowledge Bases", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Semantic parsing transforms a natural language question into a formal query\nover a knowledge base. Many existing methods rely on syntactic parsing like\ndependencies. However, the accuracy of producing such expressive formalisms is\nnot satisfying on long complex questions. In this paper, we propose a novel\nskeleton grammar to represent the high-level structure of a complex question.\nThis dedicated coarse-grained formalism with a BERT-based parsing algorithm\nhelps to improve the accuracy of the downstream fine-grained semantic parsing.\nBesides, to align the structure of a question with the structure of a knowledge\nbase, our multi-strategy method combines sentence-level and word-level\nsemantics. Our approach shows promising performance on several datasets.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 05:12:31 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Sun", "Yawei", ""], ["Zhang", "Lingling", ""], ["Cheng", "Gong", ""], ["Qu", "Yuzhong", ""]]}, {"id": "2003.14027", "submitter": "Rohit Murali", "authors": "Rohit Murali, Suravi Patnaik, Stephen Cranefield", "title": "Mining International Political Norms from the GDELT Database", "comments": "16 pages, 2 figures, pre-print for International Workshop on\n  Coordination, Organizations, Institutions, Norms and Ethics for Governance of\n  Multi-Agent Systems (COINE), co-located with AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers have long been interested in the role that norms can play in\ngoverning agent actions in multi-agent systems. Much work has been done on\nformalising normative concepts from human society and adapting them for the\ngovernment of open software systems, and on the simulation of normative\nprocesses in human and artificial societies. However, there has been\ncomparatively little work on applying normative MAS mechanisms to understanding\nthe norms in human society.\n  This work investigates this issue in the context of international politics.\nUsing the GDELT dataset, containing machine-encoded records of international\nevents extracted from news reports, we extracted bilateral sequences of\ninter-country events and applied a Bayesian norm mining mechanism to identify\nnorms that best explained the observed behaviour. A statistical evaluation\nshowed that the normative model fitted the data significantly better than a\nprobabilistic discrete event model.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 08:48:37 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 16:11:13 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Murali", "Rohit", ""], ["Patnaik", "Suravi", ""], ["Cranefield", "Stephen", ""]]}, {"id": "2003.14093", "submitter": "Harshad Khadilkar", "authors": "Harshad Khadilkar, Tanuja Ganu, Deva P Seetharam", "title": "Optimising Lockdown Policies for Epidemic Control using Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.AI cs.LG q-bio.PE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of the ongoing Covid-19 pandemic, several reports and studies\nhave attempted to model and predict the spread of the disease. There is also\nintense debate about policies for limiting the damage, both to health and to\nthe economy. On the one hand, the health and safety of the population is the\nprincipal consideration for most countries. On the other hand, we cannot ignore\nthe potential for long-term economic damage caused by strict nation-wide\nlockdowns. In this working paper, we present a quantitative way to compute\nlockdown decisions for individual cities or regions, while balancing health and\neconomic considerations. Furthermore, these policies are learnt automatically\nby the proposed algorithm, as a function of disease parameters (infectiousness,\ngestation period, duration of symptoms, probability of death) and population\ncharacteristics (density, movement propensity). We account for realistic\nconsiderations such as imperfect lockdowns, and show that the policy obtained\nusing reinforcement learning is a viable quantitative approach towards\nlockdowns.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 11:04:18 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 11:28:25 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Khadilkar", "Harshad", ""], ["Ganu", "Tanuja", ""], ["Seetharam", "Deva P", ""]]}, {"id": "2003.14132", "submitter": "Andreas Maier", "authors": "Patrick Krauss, Andreas Maier", "title": "Will we ever have Conscious Machines?", "comments": null, "journal-ref": "Front. Comput. Neurosci., 22, Dec 2020", "doi": "10.3389/fncom.2020.556544", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The question of whether artificial beings or machines could become self-aware\nor consciousness has been a philosophical question for centuries. The main\nproblem is that self-awareness cannot be observed from an outside perspective\nand the distinction of whether something is really self-aware or merely a\nclever program that pretends to do so cannot be answered without access to\naccurate knowledge about the mechanism's inner workings. We review the current\nstate-of-the-art regarding these developments and investigate common machine\nlearning approaches with respect to their potential ability to become\nself-aware. We realise that many important algorithmic steps towards machines\nwith a core consciousness have already been devised. For human-level\nintelligence, however, many additional techniques have to be discovered.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 12:09:50 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Krauss", "Patrick", ""], ["Maier", "Andreas", ""]]}, {"id": "2003.14210", "submitter": "Valentin Khrulkov", "authors": "Sergey Kolesnikov and Valentin Khrulkov", "title": "Sample Efficient Ensemble Learning with Catalyst.RL", "comments": "arXiv admin note: substantial text overlap with arXiv:1903.00027", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Catalyst.RL, an open-source PyTorch framework for reproducible and\nsample efficient reinforcement learning (RL) research. Main features of\nCatalyst.RL include large-scale asynchronous distributed training, efficient\nimplementations of various RL algorithms and auxiliary tricks, such as n-step\nreturns, value distributions, hyperbolic reinforcement learning, etc. To\ndemonstrate the effectiveness of Catalyst.RL, we applied it to a physics-based\nreinforcement learning challenge \"NeurIPS 2019: Learn to Move -- Walk Around\"\nwith the objective to build a locomotion controller for a human musculoskeletal\nmodel. The environment is computationally expensive, has a high-dimensional\ncontinuous action space and is stochastic. Our team took the 2nd place,\ncapitalizing on the ability of Catalyst.RL to train high-quality and\nsample-efficient RL agents in only a few hours of training time. The\nimplementation along with experiments is open-sourced so results can be\nreproduced and novel ideas tried out.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 12:45:35 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 22:17:13 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Kolesnikov", "Sergey", ""], ["Khrulkov", "Valentin", ""]]}, {"id": "2003.14324", "submitter": "Eva Vanmassenhove", "authors": "Eva Vanmassenhove", "title": "On the Integration of LinguisticFeatures into Statistical and Neural\n  Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New machine translations (MT) technologies are emerging rapidly and with\nthem, bold claims of achieving human parity such as: (i) the results produced\napproach \"accuracy achieved by average bilingual human translators\" (Wu et al.,\n2017b) or (ii) the \"translation quality is at human parity when compared to\nprofessional human translators\" (Hassan et al., 2018) have seen the light of\nday (Laubli et al., 2018). Aside from the fact that many of these papers craft\ntheir own definition of human parity, these sensational claims are often not\nsupported by a complete analysis of all aspects involved in translation.\nEstablishing the discrepancies between the strengths of statistical approaches\nto MT and the way humans translate has been the starting point of our research.\nBy looking at MT output and linguistic theory, we were able to identify some\nremaining issues. The problems range from simple number and gender agreement\nerrors to more complex phenomena such as the correct translation of aspectual\nvalues and tenses. Our experiments confirm, along with other studies\n(Bentivogli et al., 2016), that neural MT has surpassed statistical MT in many\naspects. However, some problems remain and others have emerged. We cover a\nseries of problems related to the integration of specific linguistic features\ninto statistical and neural MT, aiming to analyse and provide a solution to\nsome of them. Our work focuses on addressing three main research questions that\nrevolve around the complex relationship between linguistics and MT in general.\nWe identify linguistic information that is lacking in order for automatic\ntranslation systems to produce more accurate translations and integrate\nadditional features into the existing pipelines. We identify overgeneralization\nor 'algorithmic bias' as a potential drawback of neural MT and link it to many\nof the remaining linguistic issues.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 16:03:38 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Vanmassenhove", "Eva", ""]]}, {"id": "2003.14332", "submitter": "Marius Buliga", "authors": "Marius Buliga", "title": "Artificial chemistry experiments with chemlambda, lambda calculus,\n  interaction combinators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT math.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Given a graph rewrite system, a graph G is a quine graph if it has a non-void\nmaximal collection of non-conflicting matches of left patterns of graphs\nrewrites, such that after the parallel application of the rewrites we obtain a\ngraph isomorphic with G. Such graphs exhibit a metabolism, they can multiply or\nthey can die, when reduced by a random rewriting algorithm.\n  These are introductory notes to the pages of artificial chemistry experiments\nwith chemlambda, lambda calculus or interaction combinators, available from the\nentry page https://chemlambda.github.io/index.html . The experiments are\nbundled into pages, all of them based on a library of programs, on a database\nwhich contains hundreds of graphs and on a database of about 150 pages of text\ncomments and a collection of more than 200 animations, most of them which can\nbe re-done live, via the programs. There are links to public repositories of\nother contributors to these experiments, with versions of these programs in\npython, haskell, awk or javascript.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 16:15:18 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Buliga", "Marius", ""]]}, {"id": "2003.14415", "submitter": "Samuel Albanie", "authors": "Samuel Albanie, Jaime Thewmore, Robert McCraith, Joao F. Henriques", "title": "State-of-Art-Reviewing: A Radical Proposal to Improve Scientific\n  Publication", "comments": "SIGBOVIK 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer review forms the backbone of modern scientific manuscript evaluation.\nBut after two hundred and eighty-nine years of egalitarian service to the\nscientific community, does this protocol remain fit for purpose in 2020? In\nthis work, we answer this question in the negative (strong reject, high\nconfidence) and propose instead State-Of-the-Art Review (SOAR), a neoteric\nreviewing pipeline that serves as a 'plug-and-play' replacement for peer\nreview. At the heart of our approach is an interpretation of the review process\nas a multi-objective, massively distributed and extremely-high-latency\noptimisation, which we scalarise and solve efficiently for PAC and CMT-optimal\nsolutions. We make the following contributions: (1) We propose a highly\nscalable, fully automatic methodology for review, drawing inspiration from\nbest-practices from premier computer vision and machine learning conferences;\n(2) We explore several instantiations of our approach and demonstrate that SOAR\ncan be used to both review prints and pre-review pre-prints; (3) We wander\nlistlessly in vain search of catharsis from our latest rounds of savage CVPR\nrejections.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 17:58:36 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Albanie", "Samuel", ""], ["Thewmore", "Jaime", ""], ["McCraith", "Robert", ""], ["Henriques", "Joao F.", ""]]}]