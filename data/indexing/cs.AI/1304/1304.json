[{"id": "1304.0030", "submitter": "Mark Levin", "authors": "Mark Sh. Levin", "title": "Note on Combinatorial Engineering Frameworks for Hierarchical Modular\n  Systems", "comments": "11 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper briefly describes a basic set of special combinatorial engineering\nframeworks for solving complex problems in the field of hierarchical modular\nsystems. The frameworks consist of combinatorial problems (and corresponding\nmodels), which are interconnected/linked (e.g., by preference relation).\nMainly, hierarchical morphological system model is used. The list of basic\nstandard combinatorial engineering (technological) frameworks is the following:\n(1) design of system hierarchical model, (2) combinatorial synthesis\n('bottom-up' process for system design), (3) system evaluation, (4) detection\nof system bottlenecks, (5) system improvement (re-design, upgrade), (6)\nmulti-stage design (design of system trajectory), (7) combinatorial modeling of\nsystem evolution/development and system forecasting. The combinatorial\nengineering frameworks are targeted to maintenance of some system life cycle\nstages. The list of main underlaying combinatorial optimization problems\ninvolves the following: knapsack problem, multiple-choice problem, assignment\nproblem, spanning trees, morphological clique problem.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2013 21:25:35 GMT"}], "update_date": "2013-04-02", "authors_parsed": [["Levin", "Mark Sh.", ""]]}, {"id": "1304.0100", "submitter": "Diederik Aerts", "authors": "Diederik Aerts and Sandro Sozzo", "title": "Entanglement Zoo I: Foundational and Structural Aspects", "comments": "11 pages", "journal-ref": "Quantum Interaction. Lecture Notes in Computer Science, 8369, pp.\n  84-96, 2014", "doi": "10.1007/978-3-642-54943-4_8", "report-no": null, "categories": "cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We put forward a general classification for a structural description of the\nentanglement present in compound entities experimentally violating Bell's\ninequalities, making use of a new entanglement scheme that we developed\nrecently. Our scheme, although different from the traditional one, is\ncompletely compatible with standard quantum theory, and enables quantum\nmodeling in complex Hilbert space for different types of situations. Namely,\nsituations where entangled states and product measurements appear ('customary\nquantum modeling'), and situations where states and measurements and evolutions\nbetween measurements are entangled ('nonlocal box modeling', 'nonlocal\nnon-marginal box modeling'). The role played by Tsirelson's bound and marginal\ndistribution law is emphasized. Specific quantum models are worked out in\ndetail in complex Hilbert space within this new entanglement scheme.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2013 12:41:48 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2013 15:57:52 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["Aerts", "Diederik", ""], ["Sozzo", "Sandro", ""]]}, {"id": "1304.0102", "submitter": "Diederik Aerts", "authors": "Diederik Aerts and Sandro Sozzo", "title": "Entanglement Zoo II: Examples in Physics and Cognition", "comments": "11 pages", "journal-ref": "Quantum Interaction. Lecture Notes in Computer Science, 8369, pp.\n  97-109, 2014", "doi": "10.1007/978-3-642-54943-4_9", "report-no": null, "categories": "cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have recently presented a general scheme enabling quantum modeling of\ndifferent types of situations that violate Bell's inequalities. In this paper,\nwe specify this scheme for a combination of two concepts. We work out a quantum\nHilbert space model where 'entangled measurements' occur in addition to the\nexpected 'entanglement between the component concepts', or 'state\nentanglement'. We extend this result to a macroscopic physical entity, the\n'connected vessels of water', which maximally violates Bell's inequalities. We\nenlighten the structural and conceptual analogies between the cognitive and\nphysical situations which are both examples of a nonlocal non-marginal box\nmodeling in our classification.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2013 12:46:29 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2013 16:04:15 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["Aerts", "Diederik", ""], ["Sozzo", "Sandro", ""]]}, {"id": "1304.0145", "submitter": "Soumya  Kambhampati", "authors": "Soumya C. Kambhampati, Thomas Liu", "title": "Phase Transition and Network Structure in Realistic SAT Problems", "comments": null, "journal-ref": "Published as student abstract in Proceedings of AAAI 2013\n  (National Conference on Artificial Intelligence)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental question in Computer Science is understanding when a specific\nclass of problems go from being computationally easy to hard. Because of its\ngenerality and applications, the problem of Boolean Satisfiability (aka SAT) is\noften used as a vehicle for investigating this question. A signal result from\nthese studies is that the hardness of SAT problems exhibits a dramatic\neasy-to-hard phase transition with respect to the problem constrainedness. Past\nstudies have however focused mostly on SAT instances generated using uniform\nrandom distributions, where all constraints are independently generated, and\nthe problem variables are all considered of equal importance. These assumptions\nare unfortunately not satisfied by most real problems. Our project aims for a\ndeeper understanding of hardness of SAT problems that arise in practice. We\nstudy two key questions: (i) How does easy-to-hard transition change with more\nrealistic distributions that capture neighborhood sensitivity and\nrich-get-richer aspects of real problems and (ii) Can these changes be\nexplained in terms of the network properties (such as node centrality and\nsmall-worldness) of the clausal networks of the SAT problems. Our results,\nbased on extensive empirical studies and network analyses, provide important\nstructural and computational insights into realistic SAT problems. Our\nextensive empirical studies show that SAT instances from realistic\ndistributions do exhibit phase transition, but the transition occurs sooner (at\nlower values of constrainedness) than the instances from uniform random\ndistribution. We show that this behavior can be explained in terms of their\nclausal network properties such as eigenvector centrality and small-worldness\n(measured indirectly in terms of the clustering coefficients and average node\ndistance).\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2013 23:21:56 GMT"}], "update_date": "2013-04-02", "authors_parsed": [["Kambhampati", "Soumya C.", ""], ["Liu", "Thomas", ""]]}, {"id": "1304.0160", "submitter": "Nabarun Mondal Mr", "authors": "Nabarun Mondal and Partha P. Ghosh", "title": "Parallel Computation Is ESS", "comments": "Submitted to Theoretical Computer Science - Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are enormous amount of examples of Computation in nature, exemplified\nacross multiple species in biology. One crucial aim for these computations\nacross all life forms their ability to learn and thereby increase the chance of\ntheir survival. In the current paper a formal definition of autonomous learning\nis proposed. From that definition we establish a Turing Machine model for\nlearning, where rule tables can be added or deleted, but can not be modified.\nSequential and parallel implementations of this model are discussed. It is\nfound that for general purpose learning based on this model, the\nimplementations capable of parallel execution would be evolutionarily stable.\nThis is proposed to be of the reasons why in Nature parallelism in computation\nis found in abundance.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2013 06:45:47 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2013 19:54:16 GMT"}, {"version": "v3", "created": "Thu, 11 Apr 2013 16:41:02 GMT"}, {"version": "v4", "created": "Sun, 14 Apr 2013 16:03:07 GMT"}, {"version": "v5", "created": "Thu, 18 Apr 2013 17:37:38 GMT"}, {"version": "v6", "created": "Sun, 24 Nov 2013 16:37:10 GMT"}, {"version": "v7", "created": "Sun, 1 Dec 2013 11:16:28 GMT"}, {"version": "v8", "created": "Wed, 25 Dec 2013 16:18:54 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Mondal", "Nabarun", ""], ["Ghosh", "Partha P.", ""]]}, {"id": "1304.0564", "submitter": "Tyler J. VanderWeele", "authors": "Tyler J. VanderWeele, Ilya Shpitser", "title": "On the definition of a confounder", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1058 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 1, 196-220", "doi": "10.1214/12-AOS1058", "report-no": "IMS-AOS-AOS1058", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The causal inference literature has provided a clear formal definition of\nconfounding expressed in terms of counterfactual independence. The literature\nhas not, however, come to any consensus on a formal definition of a confounder,\nas it has given priority to the concept of confounding over that of a\nconfounder. We consider a number of candidate definitions arising from various\nmore informal statements made in the literature. We consider the properties\nsatisfied by each candidate definition, principally focusing on (i) whether\nunder the candidate definition control for all \"confounders\" suffices to\ncontrol for \"confounding\" and (ii) whether each confounder in some context\nhelps eliminate or reduce confounding bias. Several of the candidate\ndefinitions do not have these two properties. Only one candidate definition of\nthose considered satisfies both properties. We propose that a \"confounder\" be\ndefined as a pre-exposure covariate C for which there exists a set of other\ncovariates X such that effect of the exposure on the outcome is unconfounded\nconditional on (X,C) but such that for no proper subset of (X,C) is the effect\nof the exposure on the outcome unconfounded given the subset. We also provide a\nconditional analogue of the above definition; and we propose a variable that\nhelps reduce bias but not eliminate bias be referred to as a \"surrogate\nconfounder.\" These definitions are closely related to those given by Robins and\nMorgenstern [Comput. Math. Appl. 14 (1987) 869-916]. The implications that hold\namong the various candidate definitions are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2013 08:54:00 GMT"}], "update_date": "2013-04-03", "authors_parsed": [["VanderWeele", "Tyler J.", ""], ["Shpitser", "Ilya", ""]]}, {"id": "1304.0620", "submitter": "A. Anonymous", "authors": "Heng Zhang, Yan Zhang", "title": "Disjunctive Logic Programs versus Normal Logic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the expressive power of disjunctive and normal logic\nprograms under the stable model semantics over finite, infinite, or arbitrary\nstructures. A translation from disjunctive logic programs into normal logic\nprograms is proposed and then proved to be sound over infinite structures. The\nequivalence of expressive power of two kinds of logic programs over arbitrary\nstructures is shown to coincide with that over finite structures, and coincide\nwith whether or not NP is closed under complement. Over finite structures, the\nintranslatability from disjunctive logic programs to normal logic programs is\nalso proved if arities of auxiliary predicates and functions are bounded in a\ncertain way.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2013 12:59:41 GMT"}], "update_date": "2013-04-03", "authors_parsed": [["Zhang", "Heng", ""], ["Zhang", "Yan", ""]]}, {"id": "1304.0640", "submitter": "Louis-Charles Caron", "authors": "Louis-Charles Caron, \\and Michiel D'Haene, \\and Fr\\'ed\\'eric Mailhot,\n  \\and Benjamin Schrauwen, \\and Jean Rouat", "title": "Event management for large scale event-driven digital hardware spiking\n  neural networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2013.02.005", "report-no": null, "categories": "cs.NE cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interest in brain-like computation has led to the design of a plethora of\ninnovative neuromorphic systems. Individually, spiking neural networks (SNNs),\nevent-driven simulation and digital hardware neuromorphic systems get a lot of\nattention. Despite the popularity of event-driven SNNs in software, very few\ndigital hardware architectures are found. This is because existing hardware\nsolutions for event management scale badly with the number of events. This\npaper introduces the structured heap queue, a pipelined digital hardware data\nstructure, and demonstrates its suitability for event management. The\nstructured heap queue scales gracefully with the number of events, allowing the\nefficient implementation of large scale digital hardware event-driven SNNs. The\nscaling is linear for memory, logarithmic for logic resources and constant for\nprocessing time. The use of the structured heap queue is demonstrated on\nfield-programmable gate array (FPGA) with an image segmentation experiment and\na SNN of 65~536 neurons and 513~184 synapses. Events can be processed at the\nrate of 1 every 7 clock cycles and a 406$\\times$158 pixel image is segmented in\n200 ms.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2013 14:18:02 GMT"}], "update_date": "2013-04-03", "authors_parsed": [["Caron", "Louis-Charles", ""], ["D'Haene", "\\and Michiel", ""], ["Mailhot", "\\and Fr\u00e9d\u00e9ric", ""], ["Schrauwen", "\\and Benjamin", ""], ["Rouat", "\\and Jean", ""]]}, {"id": "1304.0715", "submitter": "Ladislau B\\\"ol\\\"oni", "authors": "Ladislau B\\\"ol\\\"oni", "title": "A cookbook of translating English to Xapi", "comments": null, "journal-ref": null, "doi": null, "report-no": "XTR-001", "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Xapagy cognitive architecture had been designed to perform narrative\nreasoning: to model and mimic the activities performed by humans when\nwitnessing, reading, recalling, narrating and talking about stories. Xapagy\ncommunicates with the outside world using Xapi, a simplified, \"pidgin\" language\nwhich is strongly tied to the internal representation model (instances, scenes\nand verb instances) and reasoning techniques (shadows and headless shadows).\nWhile not fully a semantic equivalent of natural language, Xapi can represent a\nwide range of complex stories. We illustrate the representation technique used\nin Xapi through examples taken from folk physics, folk psychology as well as\nsome more unusual literary examples. We argue that while the Xapi model\nrepresents a conceptual shift from the English representation, the mapping is\nlogical and consistent, and a trained knowledge engineer can translate between\nEnglish and Xapi at near-native speed.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2013 22:17:19 GMT"}], "update_date": "2013-04-03", "authors_parsed": [["B\u00f6l\u00f6ni", "Ladislau", ""]]}, {"id": "1304.0806", "submitter": "Faruk Karaaslan", "authors": "Faruk Karaaslan, Naim Cagman, Saban Yilmaz", "title": "IFP-Intuitionistic fuzzy soft set theory and its applications", "comments": "This paper has been withdrawn by the author due to a crucial errors\n  in the notation and some problems in the algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this work, we present definition of intuitionistic fuzzy parameterized\n(IFP) intuitionistic fuzzy soft set and its operations. Then we define\nIFP-aggregation operator to form IFP-intuitionistic fuzzy soft-decision-making\nmethod which allows constructing more efficient decision processes.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2013 22:10:00 GMT"}, {"version": "v2", "created": "Fri, 18 Mar 2016 08:12:43 GMT"}, {"version": "v3", "created": "Sun, 17 Apr 2016 19:56:30 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Karaaslan", "Faruk", ""], ["Cagman", "Naim", ""], ["Yilmaz", "Saban", ""]]}, {"id": "1304.0844", "submitter": "Nina Narodytska", "authors": "Serge Gaspers, Thomas Kalinowski, Nina Narodytska, Toby Walsh", "title": "Coalitional Manipulation for Schulze's Rule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Schulze's rule is used in the elections of a large number of organizations\nincluding Wikimedia and Debian. Part of the reason for its popularity is the\nlarge number of axiomatic properties, like monotonicity and Condorcet\nconsistency, which it satisfies. We identify a potential shortcoming of\nSchulze's rule: it is computationally vulnerable to manipulation. In\nparticular, we prove that computing an unweighted coalitional manipulation\n(UCM) is polynomial for any number of manipulators. This result holds for both\nthe unique winner and the co-winner versions of UCM. This resolves an open\nquestion stated by Parkes and Xia (2012). We also prove that computing a\nweighted coalitional manipulation (WCM) is polynomial for a bounded number of\ncandidates. Finally, we discuss the relation between the unique winner UCM\nproblem and the co-winner UCM problem and argue that they have substantially\ndifferent necessary and sufficient conditions for the existence of a successful\nmanipulation.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 05:14:08 GMT"}], "update_date": "2013-04-04", "authors_parsed": [["Gaspers", "Serge", ""], ["Kalinowski", "Thomas", ""], ["Narodytska", "Nina", ""], ["Walsh", "Toby", ""]]}, {"id": "1304.0897", "submitter": "Martin Suda", "authors": "Martin Suda", "title": "Duality in STRIPS planning", "comments": "6 pages (two columns), 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a duality mapping between STRIPS planning tasks. By exchanging\nthe initial and goal conditions, taking their respective complements, and\nswapping for every action its precondition and delete list, one obtains for\nevery STRIPS task its dual version, which has a solution if and only if the\noriginal does. This is proved by showing that the described transformation\nessentially turns progression (forward search) into regression (backward\nsearch) and vice versa.\n  The duality sheds new light on STRIPS planning by allowing a transfer of\nideas from one search approach to the other. It can be used to construct new\nalgorithms from old ones, or (equivalently) to obtain new benchmarks from\nexisting ones. Experiments show that the dual versions of IPC benchmarks are in\ngeneral quite difficult for modern planners. This may be seen as a new\nchallenge. On the other hand, the cases where the dual versions are easier to\nsolve demonstrate that the duality can also be made useful in practice.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 10:08:56 GMT"}], "update_date": "2013-04-04", "authors_parsed": [["Suda", "Martin", ""]]}, {"id": "1304.0913", "submitter": "Morteza Ansarinia", "authors": "Ahmad Salahi, Morteza Ansarinia", "title": "Predicting Network Attacks Using Ontology-Driven Inference", "comments": "9 pages", "journal-ref": "International Journal of Information and Communication Technology\n  (IJICT), Volume 4, Issue 1, 2012", "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph knowledge models and ontologies are very powerful modeling and re\nasoning tools. We propose an effective approach to model network attacks and\nattack prediction which plays important roles in security management. The goals\nof this study are: First we model network attacks, their prerequisites and\nconsequences using knowledge representation methods in order to provide\ndescription logic reasoning and inference over attack domain concepts. And\nsecondly, we propose an ontology-based system which predicts potential attacks\nusing inference and observing information which provided by sensory inputs. We\ngenerate our ontology and evaluate corresponding methods using CAPEC, CWE, and\nCVE hierarchical datasets. Results from experiments show significant capability\nimprovements comparing to traditional hierarchical and relational models.\nProposed method also reduces false alarms and improves intrusion detection\neffectiveness.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 11:04:38 GMT"}], "update_date": "2013-04-04", "authors_parsed": [["Salahi", "Ahmad", ""], ["Ansarinia", "Morteza", ""]]}, {"id": "1304.1014", "submitter": "Emanuele Frandi", "authors": "Hector Allende, Emanuele Frandi, Ricardo Nanculef, Claudio Sartori", "title": "A Novel Frank-Wolfe Algorithm. Analysis and Applications to Large-Scale\n  SVM Training", "comments": "REVISED VERSION (October 2013) -- Title and abstract have been\n  revised. Section 5 was added. Some proofs have been summarized (full-length\n  proofs available in the previous version)", "journal-ref": "Information Sciences 285, 66-99, 2014", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a renewed interest in the machine learning community\nfor variants of a sparse greedy approximation procedure for concave\noptimization known as {the Frank-Wolfe (FW) method}. In particular, this\nprocedure has been successfully applied to train large-scale instances of\nnon-linear Support Vector Machines (SVMs). Specializing FW to SVM training has\nallowed to obtain efficient algorithms but also important theoretical results,\nincluding convergence analysis of training algorithms and new characterizations\nof model sparsity.\n  In this paper, we present and analyze a novel variant of the FW method based\non a new way to perform away steps, a classic strategy used to accelerate the\nconvergence of the basic FW procedure. Our formulation and analysis is focused\non a general concave maximization problem on the simplex. However, the\nspecialization of our algorithm to quadratic forms is strongly related to some\nclassic methods in computational geometry, namely the Gilbert and MDM\nalgorithms.\n  On the theoretical side, we demonstrate that the method matches the\nguarantees in terms of convergence rate and number of iterations obtained by\nusing classic away steps. In particular, the method enjoys a linear rate of\nconvergence, a result that has been recently proved for MDM on quadratic forms.\n  On the practical side, we provide experiments on several classification\ndatasets, and evaluate the results using statistical tests. Experiments show\nthat our method is faster than the FW method with classic away steps, and works\nwell even in the cases in which classic away steps slow down the algorithm.\nFurthermore, these improvements are obtained without sacrificing the predictive\naccuracy of the obtained SVM model.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 17:15:43 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2013 09:50:26 GMT"}], "update_date": "2015-10-27", "authors_parsed": [["Allende", "Hector", ""], ["Frandi", "Emanuele", ""], ["Nanculef", "Ricardo", ""], ["Sartori", "Claudio", ""]]}, {"id": "1304.1081", "submitter": "Michael P. Wellman", "authors": "Michael P. Wellman", "title": "Exploiting Functional Dependencies in Qualitative Probabilistic\n  Reasoning", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-2-9", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional dependencies restrict the potential interactions among variables\nconnected in a probabilistic network. This restriction can be exploited in\nqualitative probabilistic reasoning by introducing deterministic variables and\nmodifying the inference rules to produce stronger conclusions in the presence\nof functional relations. I describe how to accomplish these modifications in\nqualitative probabilistic networks by exhibiting the update procedures for\ngraphical transformations involving probabilistic and deterministic variables\nand combinations. A simple example demonstrates that the augmented scheme can\nreduce qualitative ambiguity that would arise without the special treatment of\nfunctional dependency. Analysis of qualitative synergy reveals that new\nhigher-order relations are required to reason effectively about synergistic\ninteractions among deterministic variables.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:54:31 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Wellman", "Michael P.", ""]]}, {"id": "1304.1082", "submitter": "Max Henrion", "authors": "Max Henrion, Marek J. Druzdzel", "title": "Qualitative Propagation and Scenario-based Explanation of Probabilistic\n  Reasoning", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-10-20", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comprehensible explanations of probabilistic reasoning are a prerequisite for\nwider acceptance of Bayesian methods in expert systems and decision support\nsystems. A study of human reasoning under uncertainty suggests two different\nstrategies for explaining probabilistic reasoning: The first, qualitative\nbelief propagation, traces the qualitative effect of evidence through a belief\nnetwork from one variable to the next. This propagation algorithm is an\nalternative to the graph reduction algorithms of Wellman (1988) for inference\nin qualitative probabilistic networks. It is based on a qualitative analysis of\nintercausal reasoning, which is a generalization of Pearl's \"explaining away\",\nand an alternative to Wellman's definition of qualitative synergy. The other,\nScenario-based reasoning, involves the generation of alternative causal\n\"stories\" accounting for the evidence. Comparing a few of the most probable\nscenarios provides an approximate way to explain the results of probabilistic\nreasoning. Both schemes employ causal as well as probabilistic knowledge.\nProbabilities may be presented as phrases and/or numbers. Users can control the\nstyle, abstraction and completeness of explanations.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:54:37 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Henrion", "Max", ""], ["Druzdzel", "Marek J.", ""]]}, {"id": "1304.1083", "submitter": "Thomas R. Shultz", "authors": "Thomas R. Shultz", "title": "Managing Uncertainty in Rule Based Cognitive Models", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": "Proceedings of the Sixth Conference on Uncertainty in Artificial\n  Intelligence (1990) (pp. 21-26)", "doi": null, "report-no": "UAI-P-1990-PG-21-26", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An experiment replicated and extended recent findings on psychologically\nrealistic ways of modeling propagation of uncertainty in rule based reasoning.\nWithin a single production rule, the antecedent evidence can be summarized by\ntaking the maximum of disjunctively connected antecedents and the minimum of\nconjunctively connected antecedents. The maximum certainty factor attached to\neach of the rule's conclusions can be sealed down by multiplication with this\nsummarized antecedent certainty. Heckerman's modified certainty factor\ntechnique can be used to combine certainties for common conclusions across\nproduction rules.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:54:42 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Shultz", "Thomas R.", ""]]}, {"id": "1304.1084", "submitter": "Yizong Cheng", "authors": "Yizong Cheng", "title": "Context-Dependent Similarity", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-27-31", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribute weighting and differential weighting, two major mechanisms for\ncomputing context-dependent similarity or dissimilarity measures are studied\nand compared. A dissimilarity measure based on subset size in the context is\nproposed and its metrization and application are given. It is also shown that\nwhile all attribute weighting dissimilarity measures are metrics differential\nweighting dissimilarity measures are usually non-metric.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:54:46 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Cheng", "Yizong", ""]]}, {"id": "1304.1085", "submitter": "David Heckerman", "authors": "David Heckerman", "title": "Similarity Networks for the Construction of Multiple-Faults Belief\n  Networks", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-32-39", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A similarity network is a tool for constructing belief networks for the\ndiagnosis of a single fault. In this paper, we examine modifications to the\nsimilarity-network representation that facilitate the construction of belief\nnetworks for the diagnosis of multiple coexisting faults.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:54:52 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:57:34 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Heckerman", "David", ""]]}, {"id": "1304.1086", "submitter": "Dekang Lin", "authors": "Dekang Lin, Randy Goebel", "title": "Integrating Probabilistic, Taxonomic and Causal Knowledge in Abductive\n  Diagnosis", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-40-45", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an abductive diagnosis theory that integrates probabilistic,\ncausal and taxonomic knowledge. Probabilistic knowledge allows us to select the\nmost likely explanation; causal knowledge allows us to make reasonable\nindependence assumptions; taxonomic knowledge allows causation to be modeled at\ndifferent levels of detail, and allows observations be described in different\nlevels of precision. Unlike most other approaches where a causal explanation is\na hypothesis that one or more causative events occurred, we define an\nexplanation of a set of observations to be an occurrence of a chain of\ncausation events. These causation events constitute a scenario where all the\nobservations are true. We show that the probabilities of the scenarios can be\ncomputed from the conditional probabilities of the causation events. Abductive\nreasoning is inherently complex even if only modest expressive power is\nallowed. However, our abduction algorithm is exponential only in the number of\nobservations to be explained, and is polynomial in the size of the knowledge\nbase. This contrasts with many other abduction procedures that are exponential\nin the size of the knowledge base.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:54:58 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Lin", "Dekang", ""], ["Goebel", "Randy", ""]]}, {"id": "1304.1087", "submitter": "David L Poole", "authors": "David L. Poole, Gregory M. Provan", "title": "What is an Optimal Diagnosis?", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-46-53", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within diagnostic reasoning there have been a number of proposed definitions\nof a diagnosis, and thus of the most likely diagnosis, including most probable\nposterior hypothesis, most probable interpretation, most probable covering\nhypothesis, etc. Most of these approaches assume that the most likely diagnosis\nmust be computed, and that a definition of what should be computed can be made\na priori, independent of what the diagnosis is used for. We argue that the\ndiagnostic problem, as currently posed, is incomplete: it does not consider how\nthe diagnosis is to be used, or the utility associated with the treatment of\nthe abnormalities. In this paper we analyze several well-known definitions of\ndiagnosis, showing that the different definitions of the most likely diagnosis\nhave different qualitative meanings, even given the same input data. We argue\nthat the most appropriate definition of (optimal) diagnosis needs to take into\naccount the utility of outcomes and what the diagnosis is used for.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:55:03 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Poole", "David L.", ""], ["Provan", "Gregory M.", ""]]}, {"id": "1304.1088", "submitter": "Edward H. Herskovits", "authors": "Edward H. Herskovits, Gregory F. Cooper", "title": "Kutato: An Entropy-Driven System for Construction of Probabilistic\n  Expert Systems from Databases", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-54-63", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kutato is a system that takes as input a database of cases and produces a\nbelief network that captures many of the dependence relations represented by\nthose data. This system incorporates a module for determining the entropy of a\nbelief network and a module for constructing belief networks based on entropy\ncalculations. Kutato constructs an initial belief network in which all\nvariables in the database are assumed to be marginally independent. The entropy\nof this belief network is calculated, and that arc is added that minimizes the\nentropy of the resulting belief network. Conditional probabilities for an arc\nare obtained directly from the database. This process continues until an\nentropy-based threshold is reached. We have tested the system by generating\ndatabases from networks using the probabilistic logic-sampling method, and then\nusing those databases as input to Kutato. The system consistently reproduces\nthe original belief networks with high fidelity.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:55:08 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Herskovits", "Edward H.", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1304.1089", "submitter": "John S. Breese", "authors": "John S. Breese, Eric J. Horvitz", "title": "Ideal Reformulation of Belief Networks", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-64-72", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The intelligent reformulation or restructuring of a belief network can\ngreatly increase the efficiency of inference. However, time expended for\nreformulation is not available for performing inference. Thus, under time\npressure, there is a tradeoff between the time dedicated to reformulating the\nnetwork and the time applied to the implementation of a solution. We\ninvestigate this partition of resources into time applied to reformulation and\ntime used for inference. We shall describe first general principles for\ncomputing the ideal partition of resources under uncertainty. These principles\nhave applicability to a wide variety of problems that can be divided into\ninterdependent phases of problem solving. After, we shall present results of\nour empirical study of the problem of determining the ideal amount of time to\ndevote to searching for clusters in belief networks. In this work, we acquired\nand made use of probability distributions that characterize (1) the performance\nof alternative heuristic search methods for reformulating a network instance\ninto a set of cliques, and (2) the time for executing inference procedures on\nvarious belief networks. Given a preference model describing the value of a\nsolution as a function of the delay required for its computation, the system\nselects an ideal time to devote to reformulation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:55:14 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Breese", "John S.", ""], ["Horvitz", "Eric J.", ""]]}, {"id": "1304.1090", "submitter": "David Einav", "authors": "David Einav, Michael R. Fehling", "title": "Computationally-Optimal Real-Resource Strategies", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-73-81", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on managing the cost of deliberation before action. In\nmany problems, the overall quality of the solution reflects costs incurred and\nresources consumed in deliberation as well as the cost and benefit of\nexecution, when both the resource consumption in deliberation phase, and the\ncosts in deliberation and execution are uncertain and may be described by\nprobability distribution functions. A feasible (in terms of resource\nconsumption) strategy that minimizes the expected total cost is termed\ncomputationally-optimal. For a situation with several independent,\nuninterruptible methods to solve the problem, we develop a\npseudopolynomial-time algorithm to construct generate-and-test computationally\noptimal strategy. We show this strategy-construction problem to be NP-complete,\nand apply Bellman's Optimality Principle to solve it efficiently.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:55:20 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Einav", "David", ""], ["Fehling", "Michael R.", ""]]}, {"id": "1304.1091", "submitter": "David Heckerman", "authors": "David Heckerman, Eric J. Horvitz", "title": "Problem Formulation as the Reduction of a Decision Model", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-82-89", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we extend the QMRDT probabilistic model for the domain of\ninternal medicine to include decisions about treatments. In addition, we\ndescribe how we can use the comprehensive decision model to construct a simpler\ndecision model for a specific patient. In so doing, we transform the task of\nproblem formulation to that of narrowing of a larger problem.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:55:26 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:53:50 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Heckerman", "David", ""], ["Horvitz", "Eric J.", ""]]}, {"id": "1304.1092", "submitter": "Robert P. Goldman", "authors": "Robert P. Goldman, Eugene Charniak", "title": "Dynamic Construction of Belief Networks", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-90-97", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for incrementally constructing belief networks. We have\ndeveloped a network-construction language similar to a forward-chaining\nlanguage using data dependencies, but with additional features for specifying\ndistributions. Using this language, we can define parameterized classes of\nprobabilistic models. These parameterized models make it possible to apply\nprobabilistic reasoning to problems for which it is impractical to have a\nsingle large static model.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:55:31 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Goldman", "Robert P.", ""], ["Charniak", "Eugene", ""]]}, {"id": "1304.1093", "submitter": "Solomon Eyal Shimony", "authors": "Solomon Eyal Shimony, Eugene Charniak", "title": "A New Algorithm for Finding MAP Assignments to Belief Networks", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-98-105", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for finding maximum a-posterior) (MAP) assignments\nof values to belief networks. The belief network is compiled into a network\nconsisting only of nodes with boolean (i.e. only 0 or 1) conditional\nprobabilities. The MAP assignment is then found using a best-first search on\nthe resulting network. We argue that, as one would anticipate, the algorithm is\nexponential for the general case, but only linear in the size of the network\nfor poly trees.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:55:36 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Shimony", "Solomon Eyal", ""], ["Charniak", "Eugene", ""]]}, {"id": "1304.1094", "submitter": "K. Bayse", "authors": "K. Bayse, M. Lejter, Keiji Kanazawa", "title": "Reducing Uncertainty in Navigation and Exploration", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-106-113", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant problem in designing mobile robot control systems involves\ncoping with the uncertainty that arises in moving about in an unknown or\npartially unknown environment and relying on noisy or ambiguous sensor data to\nacquire knowledge about that environment. We describe a control system that\nchooses what activity to engage in next on the basis of expectations about how\nthe information re- turned as a result of a given activity will improve 2 its\nknowledge about the spatial layout of its environment. Certain of the\nhigher-level components of the control system are specified in terms of\nprobabilistic decision models whose output is used to mediate the behavior of\nlower-level control components responsible for movement and sensing.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:55:42 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Bayse", "K.", ""], ["Lejter", "M.", ""], ["Kanazawa", "Keiji", ""]]}, {"id": "1304.1095", "submitter": "Ingo Beinlich", "authors": "Ingo Beinlich, Edward H. Herskovits", "title": "Ergo: A Graphical Environment for Constructing Bayesian", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-114-121", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an environment that considerably simplifies the process of\ngenerating Bayesian belief networks. The system has been implemented on readily\navailable, inexpensive hardware, and provides clarity and high performance. We\npresent an introduction to Bayesian belief networks, discuss algorithms for\ninference with these networks, and delineate the classes of problems that can\nbe solved with this paradigm. We then describe the hardware and software that\nconstitute the system, and illustrate Ergo's use with several example\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:55:48 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Beinlich", "Ingo", ""], ["Herskovits", "Edward H.", ""]]}, {"id": "1304.1096", "submitter": "John S. Breese", "authors": "John S. Breese, Kenneth W. Fertig", "title": "Decision Making with Interval Influence Diagrams", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-122-129", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous work (Fertig and Breese, 1989; Fertig and Breese, 1990) we\ndefined a mechanism for performing probabilistic reasoning in influence\ndiagrams using interval rather than point-valued probabilities. In this paper\nwe extend these procedures to incorporate decision nodes and interval-valued\nvalue functions in the diagram. We derive the procedures for chance node\nremoval (calculating expected value) and decision node removal (optimization)\nin influence diagrams where lower bounds on probabilities are stored at each\nchance node and interval bounds are stored on the value function associated\nwith the diagram's value node. The output of the algorithm are a set of\nadmissible alternatives for each decision variable and a set of bounds on\nexpected value based on the imprecision in the input. The procedure can be\nviewed as an approximation to a full e-dimensional sensitivity analysis where n\nare the number of imprecise probability distributions in the input. We show the\ntransformations are optimal and sound. The performance of the algorithm on an\ninfluence diagrams is investigated and compared to an exact algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:55:54 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Breese", "John S.", ""], ["Fertig", "Kenneth W.", ""]]}, {"id": "1304.1097", "submitter": "R. Martin Chavez", "authors": "R. Martin Chavez, Gregory F. Cooper", "title": "A Randomized Approximation Algorithm of Logic Sampling", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-130-135", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, researchers in decision analysis and artificial intelligence\n(AI) have used Bayesian belief networks to build models of expert opinion.\nUsing standard methods drawn from the theory of computational complexity,\nworkers in the field have shown that the problem of exact probabilistic\ninference on belief networks almost certainly requires exponential computation\nin the worst ease [3]. We have previously described a randomized approximation\nscheme, called BN-RAS, for computation on belief networks [ 1, 2, 4]. We gave\nprecise analytic bounds on the convergence of BN-RAS and showed how to trade\nrunning time for accuracy in the evaluation of posterior marginal\nprobabilities. We now extend our previous results and demonstrate the\ngenerality of our framework by applying similar mathematical techniques to the\nanalysis of convergence for logic sampling [7], an alternative simulation\nalgorithm for probabilistic inference.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:55:59 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Chavez", "R. Martin", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1304.1098", "submitter": "A. Elfes", "authors": "A. Elfes", "title": "Occupancy Grids: A Stochastic Spatial Representation for Active Robot\n  Perception", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-136-146", "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide an overview of a new framework for robot perception,\nreal-world modelling, and navigation that uses a stochastic tesselated\nrepresentation of spatial information called the Occupancy Grid. The Occupancy\nGrid is a multi-dimensional random field model that maintains probabilistic\nestimates of the occupancy state of each cell in a spatial lattice. Bayesian\nestimation mechanisms employing stochastic sensor models allow incremental\nupdating of the Occupancy Grid using multi-view, multi-sensor data, composition\nof multiple maps, decision-making, and incorporation of robot and sensor\nposition uncertainty. We present the underlying stochastic formulation of the\nOccupancy Grid framework, and discuss its application to a variety of robotic\ntusks. These include range-based mapping, multi-sensor integration,\npath-planning and obstacle avoidance, handling of robot position uncertainty,\nincorporation of pre-compiled maps, recovery of geometric representations, and\nother related problems. The experimental results show that the Occupancy Grid\napproach generates dense world models, is robust under sensor uncertainty and\nerrors, and allows explicit handling of uncertainty. It supports the\ndevelopment of robust and agile sensor interpretation methods, incremental\ndiscovery procedures, and composition of information from multiple sources.\nFurthermore, the results illustrate that robotic tasks can be addressed through\noperations performed di- rectly on the Occupancy Grid, and that these\noperations have strong parallels to operations performed in the image\nprocessing domain.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:56:06 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Elfes", "A.", ""]]}, {"id": "1304.1099", "submitter": "Peter Haddawy", "authors": "Peter Haddawy", "title": "Time, Chance, and Action", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-147-154", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To operate intelligently in the world, an agent must reason about its\nactions. The consequences of an action are a function of both the state of the\nworld and the action itself. Many aspects of the world are inherently\nstochastic, so a representation for reasoning about actions must be able to\nexpress chances of world states as well as indeterminacy in the effects of\nactions and other events. This paper presents a propositional temporal\nprobability logic for representing and reasoning about actions. The logic can\nrepresent the probability that facts hold and events occur at various times. It\ncan represent the probability that actions and other events affect the future.\nIt can represent concurrent actions and conditions that hold or change during\nexecution of an action. The model of probability relates probabilities over\ntime. The logical language integrates both modal and probabilistic constructs\nand can thus represent and distinguish between possibility, probability, and\ntruth. Several examples illustrating the use of the logic are given.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:56:11 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Haddawy", "Peter", ""]]}, {"id": "1304.1100", "submitter": "Michael C. Horsch", "authors": "Michael C. Horsch, David L. Poole", "title": "A Dynamic Approach to Probabilistic Inference", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-155-161", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a framework for dynamically constructing Bayesian\nnetworks. We introduce the notion of a background knowledge base of schemata,\nwhich is a collection of parameterized conditional probability statements.\nThese schemata explicitly separate the general knowledge of properties an\nindividual may have from the specific knowledge of particular individuals that\nmay have these properties. Knowledge of individuals can be combined with this\nbackground knowledge to create Bayesian networks, which can then be used in any\npropagation scheme. We discuss the theory and assumptions necessary for the\nimplementation of dynamic Bayesian networks, and indicate where our approach\nmay be useful.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:56:17 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Horsch", "Michael C.", ""], ["Poole", "David L.", ""]]}, {"id": "1304.1101", "submitter": "Frank Jensen", "authors": "Frank Jensen, S. K. Anderson", "title": "Approximations in Bayesian Belief Universe for Knowledge Based Systems", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-162-169", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When expert systems based on causal probabilistic networks (CPNs) reach a\ncertain size and complexity, the \"combinatorial explosion monster\" tends to be\npresent. We propose an approximation scheme that identifies rarely occurring\ncases and excludes these from being processed as ordinary cases in a CPN-based\nexpert system. Depending on the topology and the probability distributions of\nthe CPN, the numbers (representing probabilities of state combinations) in the\nunderlying numerical representation can become very small. Annihilating these\nnumbers and utilizing the resulting sparseness through data structuring\ntechniques often results in several orders of magnitude of improvement in the\nconsumption of computer resources. Bounds on the errors introduced into a\nCPN-based expert system through approximations are established. Finally,\nreports on empirical studies of applying the approximation scheme to a\nreal-world CPN are given.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:56:23 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Jensen", "Frank", ""], ["Anderson", "S. K.", ""]]}, {"id": "1304.1102", "submitter": "Paul E. Lehner", "authors": "Paul E. Lehner", "title": "Robust Inference Policies", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-170-179", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A series of monte carlo studies were performed to assess the extent to which\ndifferent inference procedures robustly output reasonable belief values in the\ncontext of increasing levels of judgmental imprecision. It was found that, when\ncompared to an equal-weights linear model, the Bayesian procedures are more\nlikely to deduce strong support for a hypothesis. But, the Bayesian procedures\nare also more likely to strongly support the wrong hypothesis. Bayesian\ntechniques are more powerful, but are also more error prone.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:56:28 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Lehner", "Paul E.", ""]]}, {"id": "1304.1103", "submitter": "L. Liu", "authors": "L. Liu, Y. Ma, D. Wilkins, Z. Bian, X. Ying", "title": "Minimum Error Tree Decomposition", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-180-185", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a generalization of previous methods for constructing\ntree-structured belief network with hidden variables. The major new feature of\nthe described method is the ability to produce a tree decomposition even when\nthere are errors in the correlation data among the input variables. This is an\nimportant extension of existing methods since the correlational coefficients\nusually cannot be measured with precision. The technique involves using a\ngreedy search algorithm that locally minimizes an error function.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:56:34 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Liu", "L.", ""], ["Ma", "Y.", ""], ["Wilkins", "D.", ""], ["Bian", "Z.", ""], ["Ying", "X.", ""]]}, {"id": "1304.1104", "submitter": "J. W. Miller", "authors": "J. W. Miller, R. M. Goodman", "title": "A Polynomial Time Algorithm for Finding Bayesian Probabilities from\n  Marginal Constraints", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-186-193", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method of calculating probability values from a system of marginal\nconstraints is presented. Previous systems for finding the probability of a\nsingle attribute have either made an independence assumption concerning the\nevidence or have required, in the worst case, time exponential in the number of\nattributes of the system. In this paper a closed form solution to the\nprobability of an attribute given the evidence is found. The closed form\nsolution, however does not enforce the (non-linear) constraint that all terms\nin the underlying distribution be positive. The equation requires O(r^3) steps\nto evaluate, where r is the number of independent marginal constraints\ndescribing the system at the time of evaluation. Furthermore, a marginal\nconstraint may be exchanged with a new constraint, and a new solution\ncalculated in O(r^2) steps. This method is appropriate for calculating\nprobabilities in a real time expert system\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:56:39 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Miller", "J. W.", ""], ["Goodman", "R. M.", ""]]}, {"id": "1304.1105", "submitter": "Richard E. Neapolitan", "authors": "Richard E. Neapolitan, James Kenevan", "title": "Computation of Variances in Causal Networks", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-194-203", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The causal (belief) network is a well-known graphical structure for\nrepresenting independencies in a joint probability distribution. The exact\nmethods and the approximation methods, which perform probabilistic inference in\ncausal networks, often treat the conditional probabilities which are stored in\nthe network as certain values. However, if one takes either a subjectivistic or\na limiting frequency approach to probability, one can never be certain of\nprobability values. An algorithm for probabilistic inference should not only be\ncapable of reporting the inferred probabilities; it should also be capable of\nreporting the uncertainty in these probabilities relative to the uncertainty in\nthe probabilities which are stored in the network. In section 2 of this paper a\nmethod is given for determining the prior variances of the probabilities of all\nthe nodes. Section 3 contains an approximation method for determining the\nvariances in inferred probabilities.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:56:45 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Neapolitan", "Richard E.", ""], ["Kenevan", "James", ""]]}, {"id": "1304.1106", "submitter": "Keung-Chi Ng", "authors": "Keung-Chi Ng, Bruce Abramson", "title": "A Sensitivity Analysis of Pathfinder", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-204-211", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge elicitation is one of the major bottlenecks in expert system\ndesign. Systems based on Bayes nets require two types of information--network\nstructure and parameters (or probabilities). Both must be elicited from the\ndomain expert. In general, parameters have greater opacity than structure, and\nmore time is spent in their refinement than in any other phase of elicitation.\nThus, it is important to determine the point of diminishing returns, beyond\nwhich further refinements will promise little (if any) improvement. Sensitivity\nanalyses address precisely this issue--the sensitivity of a model to the\nprecision of its parameters. In this paper, we report the results of a\nsensitivity analysis of Pathfinder, a Bayes net based system for diagnosing\npathologies of the lymph system. This analysis is intended to shed some light\non the relative importance of structure and parameters to system performance,\nas well as the sensitivity of a system based on a Bayes net to noise in its\nassessed parameters.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:56:51 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Ng", "Keung-Chi", ""], ["Abramson", "Bruce", ""]]}, {"id": "1304.1107", "submitter": "Sampath Srinivas", "authors": "Sampath Srinivas, John S. Breese", "title": "IDEAL: A Software Package for Analysis of Influence Diagrams", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-212-219", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IDEAL (Influence Diagram Evaluation and Analysis in Lisp) is a software\nenvironment for creation and evaluation of belief networks and influence\ndiagrams. IDEAL is primarily a research tool and provides an implementation of\nmany of the latest developments in belief network and influence diagram\nevaluation in a unified framework. This paper describes IDEAL and some lessons\nlearned during its development.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:56:56 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Srinivas", "Sampath", ""], ["Breese", "John S.", ""]]}, {"id": "1304.1108", "submitter": "Tom S. Verma", "authors": "Tom S. Verma, Judea Pearl", "title": "On the Equivalence of Causal Models", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-220-227", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientists often use directed acyclic graphs (days) to model the qualitative\nstructure of causal theories, allowing the parameters to be estimated from\nobservational data. Two causal models are equivalent if there is no experiment\nwhich could distinguish one from the other. A canonical representation for\ncausal models is presented which yields an efficient graphical criterion for\ndeciding equivalence, and provides a theoretical basis for extracting causal\nstructures from empirical data. This representation is then extended to the\nmore general case of an embedded causal model, that is, a dag in which only a\nsubset of the variables are observable. The canonical representation presented\nhere yields an efficient algorithm for determining when two embedded causal\nmodels reflect the same dependency information. This algorithm leads to a model\ntheoretic definition of causation in terms of statistical dependencies.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:57:02 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Verma", "Tom S.", ""], ["Pearl", "Judea", ""]]}, {"id": "1304.1109", "submitter": "Lambert E. Wixson", "authors": "Lambert E. Wixson", "title": "Application of Confidence Intervals to the Autonomous Acquisition of\n  High-level Spatial Knowledge", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-228-236", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objects in the world usually appear in context, participating in spatial\nrelationships and interactions that are predictable and expected. Knowledge of\nthese contexts can be used in the task of using a mobile camera to search for a\nspecified object in a room. We call this the object search task. This paper is\nconcerned with representing this knowledge in a manner facilitating its\napplication to object search while at the same time lending itself to\nautonomous learning by a robot. The ability for the robot to learn such\nknowledge without supervision is crucial due to the vast number of possible\nrelationships that can exist for any given set of objects. Moreover, since a\nrobot will not have an infinite amount of time to learn, it must be able to\ndetermine an order in which to look for possible relationships so as to\nmaximize the rate at which new knowledge is gained. In effect, there must be a\n\"focus of interest\" operator that allows the robot to choose which examples are\nlikely to convey the most new information and should be examined first. This\npaper demonstrates how a representation based on statistical confidence\nintervals allows the construction of a system that achieves the above goals. An\nalgorithm, based on the Highest Impact First heuristic, is presented as a means\nfor providing a \"focus of interest\" with which to control the learning process,\nand examples are given.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:57:08 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Wixson", "Lambert E.", ""]]}, {"id": "1304.1110", "submitter": "Ross D. Shachter", "authors": "Ross D. Shachter, Stig K. Andersen, Kim-Leng Poh", "title": "Directed Reduction Algorithms and Decomposable Graphs", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-237-244", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there have been intense research efforts to develop\nefficient methods for probabilistic inference in probabilistic influence\ndiagrams or belief networks. Many people have concluded that the best methods\nare those based on undirected graph structures, and that those methods are\ninherently superior to those based on node reduction operations on the\ninfluence diagram. We show here that these two approaches are essentially the\nsame, since they are explicitly or implicity building and operating on the same\nunderlying graphical structures. In this paper we examine those graphical\nstructures and show how this insight can lead to an improved class of directed\nreduction methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:57:14 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Shachter", "Ross D.", ""], ["Andersen", "Stig K.", ""], ["Poh", "Kim-Leng", ""]]}, {"id": "1304.1111", "submitter": "Wilson X. Wen", "authors": "Wilson X. Wen", "title": "Optimal Decomposition of Belief Networks", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-245-256", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, optimum decomposition of belief networks is discussed. Some\nmethods of decomposition are examined and a new method - the method of Minimum\nTotal Number of States (MTNS) - is proposed. The problem of optimum belief\nnetwork decomposition under our framework, as under all the other frameworks,\nis shown to be NP-hard. According to the computational complexity analysis, an\nalgorithm of belief network decomposition is proposed in (Wee, 1990a) based on\nsimulated annealing.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:57:20 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Wen", "Wilson X.", ""]]}, {"id": "1304.1112", "submitter": "Michelle Baker", "authors": "Michelle Baker, Terrance E. Boult", "title": "Pruning Bayesian Networks for Efficient Computation", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-257-264", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes the circumstances under which Bayesian networks can be\npruned in order to reduce computational complexity without altering the\ncomputation for variables of interest. Given a problem instance which consists\nof a query and evidence for a set of nodes in the network, it is possible to\ndelete portions of the network which do not participate in the computation for\nthe query. Savings in computational complexity can be large when the original\nnetwork is not singly connected. Results analogous to those described in this\npaper have been derived before [Geiger, Verma, and Pearl 89, Shachter 88] but\nthe implications for reducing complexity of the computations in Bayesian\nnetworks have not been stated explicitly. We show how a preprocessing step can\nbe used to prune a Bayesian network prior to using standard algorithms to solve\na given problem instance. We also show how our results can be used in a\nparallel distributed implementation in order to achieve greater savings. We\ndefine a computationally equivalent subgraph of a Bayesian network. The\nalgorithm developed in [Geiger, Verma, and Pearl 89] is modified to construct\nthe subgraphs described in this paper with O(e) complexity, where e is the\nnumber of edges in the Bayesian network. Finally, we define a minimal\ncomputationally equivalent subgraph and prove that the subgraphs described are\nminimal.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:57:25 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Baker", "Michelle", ""], ["Boult", "Terrance E.", ""]]}, {"id": "1304.1113", "submitter": "Jonathan Stillman", "authors": "Jonathan Stillman", "title": "On Heuristics for Finding Loop Cutsets in Multiply-Connected Belief\n  Networks", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-265-272", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new heuristic algorithm for the problem of finding minimum\nsize loop cutsets in multiply connected belief networks. We compare this\nalgorithm to that proposed in [Suemmondt and Cooper, 1988]. We provide lower\nbounds on the performance of these algorithms with respect to one another and\nwith respect to optimal. We demonstrate that no heuristic algorithm for this\nproblem cam be guaranteed to produce loop cutsets within a constant difference\nfrom optimal. We discuss experimental results based on randomly generated\nnetworks, and discuss future work and open questions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:57:31 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Stillman", "Jonathan", ""]]}, {"id": "1304.1114", "submitter": "Jaap Suermondt", "authors": "Jaap Suermondt, Gregory F. Cooper, David Heckerman", "title": "A Combination of Cutset Conditioning with Clique-Tree Propagation in the\n  Pathfinder System", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-273-280", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cutset conditioning and clique-tree propagation are two popular methods for\nperforming exact probabilistic inference in Bayesian belief networks. Cutset\nconditioning is based on decomposition of a subset of network nodes, whereas\nclique-tree propagation depends on aggregation of nodes. We describe a means to\ncombine cutset conditioning and clique- tree propagation in an approach called\naggregation after decomposition (AD). We discuss the application of the AD\nmethod in the Pathfinder system, a medical expert system that offers assistance\nwith diagnosis in hematopathology.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:57:38 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Suermondt", "Jaap", ""], ["Cooper", "Gregory F.", ""], ["Heckerman", "David", ""]]}, {"id": "1304.1115", "submitter": "Enrique H. Ruspini", "authors": "Enrique H. Ruspini", "title": "Possibility as Similarity: the Semantics of Fuzzy Logic", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-281-289", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses fundamental issues on the nature of the concepts and\nstructures of fuzzy logic, focusing, in particular, on the conceptual and\nfunctional differences that exist between probabilistic and possibilistic\napproaches. A semantic model provides the basic framework to define\npossibilistic structures and concepts by means of a function that quantifies\nproximity, closeness, or resemblance between pairs of possible worlds. The\nresulting model is a natural extension, based on multiple conceivability\nrelations, of the modal logic concepts of necessity and possibility. By\ncontrast, chance-oriented probabilistic concepts and structures rely on\nmeasures of set extension that quantify the proportion of possible worlds where\na proposition is true. Resemblance between possible worlds is quantified by a\ngeneralized similarity relation: a function that assigns a number between O and\n1 to every pair of possible worlds. Using this similarity relation, which is a\nform of numerical complement of a classic metric or distance, it is possible to\ndefine and interpret the major constructs and methods of fuzzy logic:\nconditional and unconditioned possibility and necessity distributions and the\ngeneralized modus ponens of Zadeh.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:57:44 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Ruspini", "Enrique H.", ""]]}, {"id": "1304.1116", "submitter": "Soumitra Dutta", "authors": "Soumitra Dutta, Piero P. Bonissone", "title": "Integrating Case-Based and Rule-Based Reasoning: the Possibilistic\n  Connection", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-290-300", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rule based reasoning (RBR) and case based reasoning (CBR) have emerged as two\nimportant and complementary reasoning methodologies in artificial intelligence\n(Al). For problem solving in complex, real world situations, it is useful to\nintegrate RBR and CBR. This paper presents an approach to achieve a compact and\nseamless integration of RBR and CBR within the base architecture of rules. The\npaper focuses on the possibilistic nature of the approximate reasoning\nmethodology common to both CBR and RBR. In CBR, the concept of similarity is\ncasted as the complement of the distance between cases. In RBR the transitivity\nof similarity is the basis for the approximate deductions based on the\ngeneralized modus ponens. It is shown that the integration of CBR and RBR is\npossible without altering the inference engine of RBR. This integration is\nillustrated in the financial domain of mergers and acquisitions. These ideas\nhave been implemented in a prototype system called MARS.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:57:49 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Dutta", "Soumitra", ""], ["Bonissone", "Piero P.", ""]]}, {"id": "1304.1117", "submitter": "Ronald R. Yager", "authors": "Ronald R. Yager", "title": "Credibility Discounting in the Theory of Approximate Reasoning", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-301-306", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are concerned with the problem of introducing credibility type information\ninto reasoning systems. The concept of credibility allows us to discount\ninformation provided by agents. An important characteristic of this kind of\nprocedure is that a complete lack of credibility rather than resulting in the\nnegation of the information provided results in the nullification of the\ninformation provided. We suggest a representational scheme for credibility\nqualification in the theory of approximate reasoning. We discuss the concept of\nrelative credibility. By this idea we mean to indicate situations in which the\ncredibility of a piece of evidence is determined by its compatibility with\nhigher priority evidence. This situation leads to structures very much in the\nspirit of nonmonotonic reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:57:54 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Yager", "Ronald R.", ""]]}, {"id": "1304.1118", "submitter": "Didier Dubois", "authors": "Didier Dubois, Henri Prade", "title": "Updating with Belief Functions, Ordinal Conditioning Functions and\n  Possibility Measures", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-307-316", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses how a measure of uncertainty representing a state of\nknowledge can be updated when a new information, which may be pervaded with\nuncertainty, becomes available. This problem is considered in various\nframework, namely: Shafer's evidence theory, Zadeh's possibility theory,\nSpohn's theory of epistemic states. In the two first cases, analogues of\nJeffrey's rule of conditioning are introduced and discussed. The relations\nbetween Spohn's model and possibility theory are emphasized and Spohn's\nupdating rule is contrasted with the Jeffrey-like rule of conditioning in\npossibility theory. Recent results by Shenoy on the combination of ordinal\nconditional functions are reinterpreted in the language of possibility theory.\nIt is shown that Shenoy's combination rule has a well-known possibilistic\ncounterpart.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:58:00 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Dubois", "Didier", ""], ["Prade", "Henri", ""]]}, {"id": "1304.1119", "submitter": "Ronald Fagin", "authors": "Ronald Fagin, Joseph Y. Halpern", "title": "A New Approach to Updating Beliefs", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-317-325", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a new notion of conditional belief, which plays the same role for\nDempster-Shafer belief functions as conditional probability does for\nprobability functions. Our definition is different from the standard definition\ngiven by Dempster, and avoids many of the well-known problems of that\ndefinition. Just as the conditional probability Pr (lB) is a probability\nfunction which is the result of conditioning on B being true, so too our\nconditional belief function Bel (lB) is a belief function which is the result\nof conditioning on B being true. We define the conditional belief as the lower\nenvelope (that is, the inf) of a family of conditional probability functions,\nand provide a closed form expression for it. An alternate way of understanding\nour definition of conditional belief is provided by considering ideas from an\nearlier paper [Fagin and Halpern, 1989], where we connect belief functions with\ninner measures. In particular, we show here how to extend the definition of\nconditional probability to non measurable sets, in order to get notions of\ninner and outer conditional probabilities, which can be viewed as best\napproximations to the true conditional probability, given our lack of\ninformation. Our definition of conditional belief turns out to be an exact\nanalogue of our definition of inner conditional probability.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:58:06 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Fagin", "Ronald", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "1304.1120", "submitter": "Philippe Smets", "authors": "Philippe Smets", "title": "The Transferable Belief Model and Other Interpretations of\n  Dempster-Shafer's Model", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-326-333", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dempster-Shafer's model aims at quantifying degrees of belief But there are\nso many interpretations of Dempster-Shafer's theory in the literature that it\nseems useful to present the various contenders in order to clarify their\nrespective positions. We shall successively consider the classical probability\nmodel, the upper and lower probabilities model, Dempster's model, the\ntransferable belief model, the evidentiary value model, the provability or\nnecessity model. None of these models has received the qualification of\nDempster-Shafer. In fact the transferable belief model is our interpretation\nnot of Dempster's work but of Shafer's work as presented in his book (Shafer\n1976, Smets 1988). It is a ?purified' form of Dempster-Shafer's model in which\nany connection with probability concept has been deleted. Any model for belief\nhas at least two components: one static that describes our state of belief, the\nother dynamic that explains how to update our belief given new pieces of\ninformation. We insist on the fact that both components must be considered in\norder to study these models. Too many authors restrict themselves to the static\ncomponent and conclude that Dempster-Shafer theory is the same as some other\ntheory. But once the dynamic component is considered, these conclusions break\ndown. Any comparison based only on the static component is too restricted. The\ndynamic component must also be considered as the originality of the models\nbased on belief functions lies in its dynamic component.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:58:12 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Smets", "Philippe", ""]]}, {"id": "1304.1121", "submitter": "Prakash P. Shenoy", "authors": "Prakash P. Shenoy, Glenn Shafer", "title": "Valuation-Based Systems for Discrete Optimization", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-334-343", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes valuation-based systems for representing and solving\ndiscrete optimization problems. In valuation-based systems, we represent\ninformation in an optimization problem using variables, sample spaces of\nvariables, a set of values, and functions that map sample spaces of sets of\nvariables to the set of values. The functions, called valuations, represent the\nfactors of an objective function. Solving the optimization problem involves\nusing two operations called combination and marginalization. Combination tells\nus how to combine the factors of the joint objective function. Marginalization\nis either maximization or minimization. Solving an optimization problem can be\nsimply described as finding the marginal of the joint objective function for\nthe empty set. We state some simple axioms that combination and marginalization\nneed to satisfy to enable us to solve an optimization problem using local\ncomputation. For optimization problems, the solution method of valuation-based\nsystems reduces to non-serial dynamic programming. Thus our solution method for\nVBS can be regarded as an abstract description of dynamic programming. And our\naxioms can be viewed as conditions that permit the use of dynamic programming.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:58:17 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Shenoy", "Prakash P.", ""], ["Shafer", "Glenn", ""]]}, {"id": "1304.1122", "submitter": "Robert Kennes", "authors": "Robert Kennes, Philippe Smets", "title": "Computational Aspects of the Mobius Transform", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-344-351", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we associate with every (directed) graph G a transformation\ncalled the Mobius transformation of the graph G. The Mobius transformation of\nthe graph (O) is of major significance for Dempster-Shafer theory of evidence.\nHowever, because it is computationally very heavy, the Mobius transformation\ntogether with Dempster's rule of combination is a major obstacle to the use of\nDempster-Shafer theory for handling uncertainty in expert systems. The major\ncontribution of this paper is the discovery of the 'fast Mobius\ntransformations' of (O). These 'fast Mobius transformations' are the fastest\nalgorithms for computing the Mobius transformation of (O). As an easy but\nuseful application, we provide, via the commonality function, an algorithm for\ncomputing Dempster's rule of combination which is much faster than the usual\none.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:58:24 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Kennes", "Robert", ""], ["Smets", "Philippe", ""]]}, {"id": "1304.1123", "submitter": "Alessandro Saffiotti", "authors": "Alessandro Saffiotti", "title": "Using Dempster-Shafer Theory in Knowledge Representation", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-352-361", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we suggest marrying Dempster-Shafer (DS) theory with Knowledge\nRepresentation (KR). Born out of this marriage is the definition of\n\"Dempster-Shafer Belief Bases\", abstract data types representing uncertain\nknowledge that use DS theory for representing strength of belief about our\nknowledge, and the linguistic structures of an arbitrary KR system for\nrepresenting the knowledge itself. A formal result guarantees that both the\nproperties of the given KR system and of DS theory are preserved. The general\nmodel is exemplified by defining DS Belief Bases where First Order Logic and\n(an extension of) KRYPTON are used as KR systems. The implementation problem is\nalso touched upon.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:58:30 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Saffiotti", "Alessandro", ""]]}, {"id": "1304.1124", "submitter": "Hamid R. Berenji", "authors": "Hamid R. Berenji, Yung-Yaw Chen, Chuen-Chien Lee, Jyh-Shing Jang, S.\n  Murugesan", "title": "A Hierarchical Approach to Designing Approximate Reasoning-Based\n  Controllers for Dynamic Physical Systems", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-362-369", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new technique for the design of approximate reasoning\nbased controllers for dynamic physical systems with interacting goals. In this\napproach, goals are achieved based on a hierarchy defined by a control\nknowledge base and remain highly interactive during the execution of the\ncontrol task. The approach has been implemented in a rule-based computer\nprogram which is used in conjunction with a prototype hardware system to solve\nthe cart-pole balancing problem in real-time. It provides a complementary\napproach to the conventional analytical control methodology, and is of\nsubstantial use where a precise mathematical model of the process being\ncontrolled is not available.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:58:36 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Berenji", "Hamid R.", ""], ["Chen", "Yung-Yaw", ""], ["Lee", "Chuen-Chien", ""], ["Jang", "Jyh-Shing", ""], ["Murugesan", "S.", ""]]}, {"id": "1304.1125", "submitter": "L. W. Chang", "authors": "L. W. Chang, Rangasami L. Kashyap", "title": "Evidence Combination and Reasoning and Its Application to Real-World\n  Problem-Solving", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-370-377", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a new mathematical procedure is presented for combining\ndifferent pieces of evidence which are represented in the interval form to\nreflect our knowledge about the truth of a hypothesis. Evidences may be\ncorrelated to each other (dependent evidences) or conflicting in supports\n(conflicting evidences). First, assuming independent evidences, we propose a\nmethodology to construct combination rules which obey a set of essential\nproperties. The method is based on a geometric model. We compare results\nobtained from Dempster-Shafer's rule and the proposed combination rules with\nboth conflicting and non-conflicting data and show that the values generated by\nproposed combining rules are in tune with our intuition in both cases.\nSecondly, in the case that evidences are known to be dependent, we consider\nextensions of the rules derived for handling conflicting evidence. The\nperformance of proposed rules are shown by different examples. The results show\nthat the proposed rules reasonably make decision under dependent evidences\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:58:42 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Chang", "L. W.", ""], ["Kashyap", "Rangasami L.", ""]]}, {"id": "1304.1126", "submitter": "F. Correa da Silva", "authors": "F. Correa da Silva, Alan Bundy", "title": "On Some Equivalence Relations between Incidence Calculus and\n  Dempster-Shafer Theory of Evidence", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-378-383", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incidence Calculus and Dempster-Shafer Theory of Evidence are both theories\nto describe agents' degrees of belief in propositions, thus being appropriate\nto represent uncertainty in reasoning systems. This paper presents a\nstraightforward equivalence proof between some special cases of these theories.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:58:47 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["da Silva", "F. Correa", ""], ["Bundy", "Alan", ""]]}, {"id": "1304.1127", "submitter": "Mary McLeish", "authors": "Mary McLeish, P. Yao, T. Stirtzinger", "title": "Using Belief Functions for Uncertainty Management and Knowledge\n  Acquisition: An Expert Application", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-384-391", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes recent work on an ongoing project in medical diagnosis\nat the University of Guelph. A domain on which experts are not very good at\npinpointing a single disease outcome is explored. On-line medical data is\navailable over a relatively short period of time. Belief Functions\n(Dempster-Shafer theory) are first extracted from data and then modified with\nexpert opinions. Several methods for doing this are compared and results show\nthat one formulation statistically outperforms the others, including a method\nsuggested by Shafer. Expert opinions and statistically derived information\nabout dependencies among symptoms are also compared. The benefits of using\nuncertainty management techniques as methods for knowledge acquisition from\ndata are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:58:53 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["McLeish", "Mary", ""], ["Yao", "P.", ""], ["Stirtzinger", "T.", ""]]}, {"id": "1304.1128", "submitter": "Robert Fung", "authors": "Robert Fung, S. L. Crawford, Lee A. Appelbaum, Richard M. Tong", "title": "An Architecture for Probabilistic Concept-Based Information Retrieval", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-392-404", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While concept-based methods for information retrieval can provide improved\nperformance over more conventional techniques, they require large amounts of\neffort to acquire the concepts and their qualitative and quantitative\nrelationships. This paper discusses an architecture for probabilistic\nconcept-based information retrieval which addresses the knowledge acquisition\nproblem. The architecture makes use of the probabilistic networks technology\nfor representing and reasoning about concepts and includes a knowledge\nacquisition component which partially automates the construction of concept\nknowledge bases from data. We describe two experiments that apply the\narchitecture to the task of retrieving documents about terrorism from a set of\ndocuments from the Reuters news service. The experiments provide positive\nevidence that the architecture design is feasible and that there are advantages\nto concept-based methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:58:58 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Fung", "Robert", ""], ["Crawford", "S. L.", ""], ["Appelbaum", "Lee A.", ""], ["Tong", "Richard M.", ""]]}, {"id": "1304.1129", "submitter": "A. J. Hanson", "authors": "A. J. Hanson", "title": "Amplitude-Based Approach to Evidence Accumulation", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-405-414", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We point out the need to use probability amplitudes rather than probabilities\nto model evidence accumulation in decision processes involving real physical\nsensors. Optical information processing systems are given as typical examples\nof systems that naturally gather evidence in this manner. We derive a new,\namplitude-based generalization of the Hough transform technique used for object\nrecognition in machine vision. We argue that one should use complex Hough\naccumulators and square their magnitudes to get a proper probabilistic\ninterpretation of the likelihood that an object is present. Finally, we suggest\nthat probability amplitudes may have natural applications in connectionist\nmodels, as well as in formulating knowledge-based reasoning problems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:59:04 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Hanson", "A. J.", ""]]}, {"id": "1304.1130", "submitter": "Kathryn Blackmond Laskey", "authors": "Kathryn Blackmond Laskey", "title": "A Probabilistic Reasoning Environment", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-415-422", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework is presented for a computational theory of probabilistic\nargument. The Probabilistic Reasoning Environment encodes knowledge at three\nlevels. At the deepest level are a set of schemata encoding the system's domain\nknowledge. This knowledge is used to build a set of second-level arguments,\nwhich are structured for efficient recapture of the knowledge used to construct\nthem. Finally, at the top level is a Bayesian network constructed from the\narguments. The system is designed to facilitate not just propagation of beliefs\nand assimilation of evidence, but also the dynamic process of constructing a\nbelief network, evaluating its adequacy, and revising it when necessary.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:59:09 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Laskey", "Kathryn Blackmond", ""]]}, {"id": "1304.1131", "submitter": "Hung-Trung Nguyen", "authors": "Hung-Trung Nguyen", "title": "On Non-monotonic Conditional Reasoning", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-423-427", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note is concerned with a formal analysis of the problem of non-monotonic\nreasoning in intelligent systems, especially when the uncertainty is taken into\naccount in a quantitative way. A firm connection between logic and probability\nis established by introducing conditioning notions by means of formal\nstructures that do not rely on quantitative measures. The associated\nconditional logic, compatible with conditional probability evaluations, is\nnon-monotonic relative to additional evidence. Computational aspects of\nconditional probability logic are mentioned. The importance of this development\nlies on its role to provide a conceptual basis for various forms of evidence\ncombination and on its significance to unify multi-valued and non-monotonic\nlogics\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:59:14 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Nguyen", "Hung-Trung", ""]]}, {"id": "1304.1132", "submitter": "Michael Pittarelli", "authors": "Michael Pittarelli", "title": "Decisions with Limited Observations over a Finite Product Space: the\n  Klir Effect", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-428-435", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probability estimation by maximum entropy reconstruction of an initial\nrelative frequency estimate from its projection onto a hypergraph model of the\napproximate conditional independence relations exhibited by it is investigated.\nThe results of this study suggest that use of this estimation technique may\nimprove the quality of decisions that must be made on the basis of limited\nobservations over a decomposable finite product space.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:59:20 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Pittarelli", "Michael", ""]]}, {"id": "1304.1133", "submitter": "Stuart Russell", "authors": "Stuart Russell", "title": "Fine-Grained Decision-Theoretic Search Control", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-436-442", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-theoretic control of search has previously used as its basic unit.\nof computation the generation and evaluation of a complete set of successors.\nAlthough this simplifies analysis, it results in some lost opportunities for\npruning and satisficing. This paper therefore extends the analysis of the value\nof computation to cover individual successor evaluations. The analytic\ntechniques used may prove useful for control of reasoning in more general\nsettings. A formula is developed for the expected value of a node, k of whose n\nsuccessors have been evaluated. This formula is used to estimate the value of\nexpanding further successors, using a general formula for the value of a\ncomputation in game-playing developed in earlier work. We exhibit an improved\nversion of the MGSS* algorithm, giving empirical results for the game of\nOthello.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:59:26 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Russell", "Stuart", ""]]}, {"id": "1304.1134", "submitter": "Nic Wilson", "authors": "Nic Wilson", "title": "Rules, Belief Functions and Default Logic", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-443-449", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a natural framework for rules, based on belief\nfunctions, which includes a repre- sentation of numerical rules, default rules\nand rules allowing and rules not allowing contraposition. In particular it\njustifies the use of the Dempster-Shafer Theory for representing a particular\nclass of rules, Belief calculated being a lower probability given certain\nindependence assumptions on an underlying space. It shows how a belief function\nframework can be generalised to other logics, including a general Monte-Carlo\nalgorithm for calculating belief, and how a version of Reiter's Default Logic\ncan be seen as a limiting case of a belief function formalism.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:59:32 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Wilson", "Nic", ""]]}, {"id": "1304.1135", "submitter": "Michael S. K. M. Wong", "authors": "Michael S. K. M. Wong, P. Lingras", "title": "Combination of Evidence Using the Principle of Minimum Information Gain", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-450-459", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important aspects in any treatment of uncertain information\nis the rule of combination for updating the degrees of uncertainty. The theory\nof belief functions uses the Dempster rule to combine two belief functions\ndefined by independent bodies of evidence. However, with limited dependency\ninformation about the accumulated belief the Dempster rule may lead to\nunsatisfactory results. The present study suggests a method to determine the\naccumulated belief based on the premise that the information gain from the\ncombination process should be minimum. This method provides a mechanism that is\nequivalent to the Bayes rule when all the conditional probabilities are\navailable and to the Dempster rule when the normalization constant is equal to\none. The proposed principle of minimum information gain is shown to be\nequivalent to the maximum entropy formalism, a special case of the principle of\nminimum cross-entropy. The application of this principle results in a monotonic\nincrease in belief with accumulation of consistent evidence. The suggested\napproach may provide a more reasonable criterion for identifying conflicts\namong various bodies of evidence.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:59:37 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Wong", "Michael S. K. M.", ""], ["Lingras", "P.", ""]]}, {"id": "1304.1136", "submitter": "Thomas D. Wu", "authors": "Thomas D. Wu", "title": "Probabilistic Evaluation of Candidates and Symptom Clustering for\n  Multidisorder Diagnosis", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-460-467", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper derives a formula for computing the conditional probability of a\nset of candidates, where a candidate is a set of disorders that explain a given\nset of positive findings. Such candidate sets are produced by a recent method\nfor multidisorder diagnosis called symptom clustering. A symptom clustering\nrepresents a set of candidates compactly as a cartesian product of differential\ndiagnoses. By evaluating the probability of a candidate set, then, a large set\nof candidates can be validated or pruned simultaneously. The probability of a\ncandidate set is then specialized to obtain the probability of a single\ncandidate. Unlike earlier results, the equation derived here allows the\nspecification of positive, negative, and unknown symptoms and does not make\nassumptions about disorders not in the candidate.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:59:43 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Wu", "Thomas D.", ""]]}, {"id": "1304.1137", "submitter": "John Yen", "authors": "John Yen, Piero P. Bonissone", "title": "Extending Term Subsumption systems for Uncertainty Management", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-468-474", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major difficulty in developing and maintaining very large knowledge bases\noriginates from the variety of forms in which knowledge is made available to\nthe KB builder. The objective of this research is to bring together two\ncomplementary knowledge representation schemes: term subsumption languages,\nwhich represent and reason about defining characteristics of concepts, and\nproximate reasoning models, which deal with uncertain knowledge and data in\nexpert systems. Previous works in this area have primarily focused on\nprobabilistic inheritance. In this paper, we address two other important issues\nregarding the integration of term subsumption-based systems and approximate\nreasoning models. First, we outline a general architecture that specifies the\ninteractions between the deductive reasoner of a term subsumption system and an\napproximate reasoner. Second, we generalize the semantics of terminological\nlanguage so that terminological knowledge can be used to make plausible\ninferences. The architecture, combined with the generalized semantics, forms\nthe foundation of a synergistic tight integration of term subsumption systems\nand approximate reasoning models.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:59:48 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Yen", "John", ""], ["Bonissone", "Piero P.", ""]]}, {"id": "1304.1138", "submitter": "Kuo-Chu Chang", "authors": "Kuo-Chu Chang, Robert Fung", "title": "Refinement and Coarsening of Bayesian Networks", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-475-482", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In almost all situation assessment problems, it is useful to dynamically\ncontract and expand the states under consideration as assessment proceeds.\nContraction is most often used to combine similar events or low probability\nevents together in order to reduce computation. Expansion is most often used to\nmake distinctions of interest which have significant probability in order to\nimprove the quality of the assessment. Although other uncertainty calculi,\nnotably Dempster-Shafer [Shafer, 1976], have addressed these operations, there\nhas not yet been any approach of refining and coarsening state spaces for the\nBayesian Network technology. This paper presents two operations for refining\nand coarsening the state space in Bayesian Networks. We also discuss their\npractical implications for knowledge acquisition.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 13:59:54 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Chang", "Kuo-Chu", ""], ["Fung", "Robert", ""]]}, {"id": "1304.1139", "submitter": "Gerhard Paa{\\ss}", "authors": "Gerhard Paa{\\ss}", "title": "Second Order Probabilities for Uncertain and Conflicting Evidence", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-483-490", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the elicitation of probabilities from human experts is\nconsidered as a measurement process, which may be disturbed by random\n'measurement noise'. Using Bayesian concepts a second order probability\ndistribution is derived reflecting the uncertainty of the input probabilities.\nThe algorithm is based on an approximate sample representation of the basic\nprobabilities. This sample is continuously modified by a stochastic simulation\nprocedure, the Metropolis algorithm, such that the sequence of successive\nsamples corresponds to the desired posterior distribution. The procedure is\nable to combine inconsistent probabilities according to their reliability and\nis applicable to general inference networks with arbitrary structure.\nDempster-Shafer probability mass functions may be included using specific\nmeasurement distributions. The properties of the approach are demonstrated by\nnumerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 14:00:00 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Paa\u00df", "Gerhard", ""]]}, {"id": "1304.1140", "submitter": "Linda C. van der Gaag", "authors": "Linda C. van der Gaag", "title": "Computing Probability Intervals Under Independency Constraints", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-491-497", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many AI researchers argue that probability theory is only capable of dealing\nwith uncertainty in situations where a full specification of a joint\nprobability distribution is available, and conclude that it is not suitable for\napplication in knowledge-based systems. Probability intervals, however,\nconstitute a means for expressing incompleteness of information. We present a\nmethod for computing such probability intervals for probabilities of interest\nfrom a partial specification of a joint probability distribution. Our method\nimproves on earlier approaches by allowing for independency relationships\nbetween statistical variables to be exploited.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 14:00:05 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["van der Gaag", "Linda C.", ""]]}, {"id": "1304.1141", "submitter": "Michael Shwe", "authors": "Michael Shwe, Gregory F. Cooper", "title": "An Empirical Analysis of Likelihood-Weighting Simulation on a Large,\n  Multiply-Connected Belief Network", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-498-508", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyzed the convergence properties of likelihood- weighting algorithms on\na two-level, multiply connected, belief-network representation of the QMR\nknowledge base of internal medicine. Specifically, on two difficult diagnostic\ncases, we examined the effects of Markov blanket scoring, importance sampling,\ndemonstrating that the Markov blanket scoring and self-importance sampling\nsignificantly improve the convergence of the simulation on our model.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 14:00:12 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Shwe", "Michael", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1304.1142", "submitter": "David Sher", "authors": "David Sher", "title": "Towards a Normative Theory of Scientific Evidence", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-509-517", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A scientific reasoning system makes decisions using objective evidence in the\nform of independent experimental trials, propositional axioms, and constraints\non the probabilities of events. As a first step towards this goal, we propose a\nsystem that derives probability intervals from objective evidence in those\nforms. Our reasoning system can manage uncertainty about data and rules in a\nrule based expert system. We expect that our system will be particularly\napplicable to diagnosis and analysis in domains with a wealth of experimental\nevidence such as medicine. We discuss limitations of this solution and propose\nfuture directions for this research. This work can be considered a\ngeneralization of Nilsson's \"probabilistic logic\" [Nil86] to intervals and\nexperimental observations.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 14:00:17 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Sher", "David", ""]]}, {"id": "1304.1143", "submitter": "Mary McLeish", "authors": "Mary McLeish", "title": "A Model for Non-Monotonic Reasoning Using Dempster's Rule", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-518-528", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considerable attention has been given to the problem of non-monotonic\nreasoning in a belief function framework. Earlier work (M. Ginsberg) proposed\nsolutions introducing meta-rules which recognized conditional independencies in\na probabilistic sense. More recently an e-calculus formulation of default\nreasoning (J. Pearl) shows that the application of Dempster's rule to a\nnon-monotonic situation produces erroneous results. This paper presents a new\nbelief function interpretation of the problem which combines the rules in a way\nwhich is more compatible with probabilistic results and respects conditions of\nindependence necessary for the application of Dempster's combination rule. A\nnew general framework for combining conflicting evidence is also proposed in\nwhich the normalization factor becomes modified. This produces more intuitively\nacceptable results.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 14:00:23 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["McLeish", "Mary", ""]]}, {"id": "1304.1144", "submitter": "Philippe Smets", "authors": "Philippe Smets, Yen-Teh Hsia", "title": "Default Reasoning and the Transferable Belief Model", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-529-537", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inappropriate use of Dempster's rule of combination has led some authors to\nreject the Dempster-Shafer model, arguing that it leads to supposedly\nunacceptable conclusions when defaults are involved. A most classic example is\nabout the penguin Tweety. This paper will successively present: the origin of\nthe miss-management of the Tweety example; two types of default; the correct\nsolution for both types based on the transferable belief model (our\ninterpretation of the Dempster-Shafer model (Shafer 1976, Smets 1988)); Except\nwhen explicitly stated, all belief functions used in this paper are simple\nsupport functions, i.e. belief functions for which only one proposition (the\nfocus) of the frame of discernment receives a positive basic belief mass with\nthe remaining mass being given to the tautology. Each belief function will be\ndescribed by its focus and the weight of the focus (e.g. m(A)=.9). Computation\nof the basic belief masses are always performed by vacuously extending each\nbelief function to the product space built from all variables involved,\ncombining them on that space by Dempster's rule of combination, and projecting\nthe result to the space corresponding to each individual variable.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 14:00:29 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Smets", "Philippe", ""], ["Hsia", "Yen-Teh", ""]]}, {"id": "1304.1145", "submitter": "Dan Geiger", "authors": "Dan Geiger, David Heckerman", "title": "Separable and transitive graphoids", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-538-545", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine three probabilistic formulations of the sentence a and b are\ntotally unrelated with respect to a given set of variables U. First, two\nvariables a and b are totally independent if they are independent given any\nvalue of any subset of the variables in U. Second, two variables are totally\nuncoupled if U can be partitioned into two marginally independent sets\ncontaining a and b respectively. Third, two variables are totally disconnected\nif the corresponding nodes are disconnected in every belief network\nrepresentation. We explore the relationship between these three formulations of\nunrelatedness and explain their relevance to the process of acquiring\nprobabilistic knowledge from human experts.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 14:00:34 GMT"}, {"version": "v2", "created": "Sun, 19 May 2013 19:42:17 GMT"}, {"version": "v3", "created": "Sat, 16 May 2015 23:58:55 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Geiger", "Dan", ""], ["Heckerman", "David", ""]]}, {"id": "1304.1146", "submitter": "Bo Chamberlain", "authors": "Bo Chamberlain, Finn Verner Jensen, Frank Jensen, Torsten Nordahl", "title": "Analysis in HUGIN of Data Conflict", "comments": "Appears in Proceedings of the Sixth Conference on Uncertainty in\n  Artificial Intelligence (UAI1990)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1990-PG-546-554", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After a brief introduction to causal probabilistic networks and the HUGIN\napproach, the problem of conflicting data is discussed. A measure of conflict\nis defined, and it is used in the medical diagnostic system MUNIN. Finally, it\nis discussed how to distinguish between conflicting data and a rare case.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 14:00:40 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Chamberlain", "Bo", ""], ["Jensen", "Finn Verner", ""], ["Jensen", "Frank", ""], ["Nordahl", "Torsten", ""]]}, {"id": "1304.1402", "submitter": "Bernardo Cuenca Grau", "authors": "Bernardo Cuenca Grau, Boris Motik, Giorgos Stoilos, Ian Horrocks", "title": "Computing Datalog Rewritings beyond Horn Ontologies", "comments": "14 pages. To appear at IJCAI 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rewriting-based approaches for answering queries over an OWL 2 DL ontology\nhave so far been developed mainly for Horn fragments of OWL 2 DL. In this\npaper, we study the possibilities of answering queries over non-Horn ontologies\nusing datalog rewritings. We prove that this is impossible in general even for\nvery simple ontology languages, and even if PTIME = NP. Furthermore, we present\na resolution-based procedure for $\\SHI$ ontologies that, in case it terminates,\nproduces a datalog rewriting of the ontology. Our procedure necessarily\nterminates on DL-Lite_{bool}^H ontologies---an extension of OWL 2 QL with\ntransitive roles and Boolean connectives.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2013 15:31:45 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2013 10:49:12 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Grau", "Bernardo Cuenca", ""], ["Motik", "Boris", ""], ["Stoilos", "Giorgos", ""], ["Horrocks", "Ian", ""]]}, {"id": "1304.1491", "submitter": "Fahiem Bacchus", "authors": "Fahiem Bacchus", "title": "Lp : A Logic for Statistical Information", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-1-6", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This extended abstract presents a logic, called Lp, that is capable of\nrepresenting and reasoning with a wide variety of both qualitative and\nquantitative statistical information. The advantage of this logical formalism\nis that it offers a declarative representation of statistical knowledge;\nknowledge represented in this manner can be used for a variety of reasoning\ntasks. The logic differs from previous work in probability logics in that it\nuses a probability distribution over the domain of discourse, whereas most\nprevious work (e.g., Nilsson [2], Scott et al. [3], Gaifinan [4], Fagin et al.\n[5]) has investigated the attachment of probabilities to the sentences of the\nlogic (also, see Halpern [6] and Bacchus [7] for further discussion of the\ndifferences). The logic Lp possesses some further important features. First, Lp\nis a superset of first order logic, hence it can represent ordinary logical\nassertions. This means that Lp provides a mechanism for integrating statistical\ninformation and reasoning about uncertainty into systems based solely on logic.\nSecond, Lp possesses transparent semantics, based on sets and probabilities of\nthose sets. Hence, knowledge represented in Lp can be understood in terms of\nthe simple primative concepts of sets and probabilities. And finally, the there\nis a sound proof theory that has wide coverage (the proof theory is complete\nfor certain classes of models). The proof theory captures a sufficient range of\nvalid inferences to subsume most previous probabilistic uncertainty reasoning\nsystems. For example, the linear constraints like those generated by Nilsson's\nprobabilistic entailment [2] can be generated by the proof theory, and the\nBayesian inference underlying belief nets [8] can be performed. In addition,\nthe proof theory integrates quantitative and qualitative reasoning as well as\nstatistical and logical reasoning. In the next section we briefly examine\nprevious work in probability logics, comparing it to Lp. Then we present some\nof the varieties of statistical information that Lp is capable of expressing.\nAfter this we present, briefly, the syntax, semantics, and proof theory of the\nlogic. We conclude with a few examples of knowledge representation and\nreasoning in Lp, pointing out the advantages of the declarative representation\noffered by Lp. We close with a brief discussion of probabilities as degrees of\nbelief, indicating how such probabilities can be generated from statistical\nknowledge encoded in Lp. The reader who is interested in a more complete\ntreatment should consult Bacchus [7].\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:36:47 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Bacchus", "Fahiem", ""]]}, {"id": "1304.1492", "submitter": "Kenneth Basye", "authors": "Kenneth Basye, Thomas L. Dean", "title": "Map Learning with Indistinguishable Locations", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-7-13", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearly all spatial reasoning problems involve uncertainty of one sort or\nanother. Uncertainty arises due to the inaccuracies of sensors used in\nmeasuring distances and angles. We refer to this as directional uncertainty.\nUncertainty also arises in combining spatial information when one location is\nmistakenly identified with another. We refer to this as recognition\nuncertainty. Most problems in constructing spatial representations (maps) for\nthe purpose of navigation involve both directional and recognition uncertainty.\nIn this paper, we show that a particular class of spatial reasoning problems\ninvolving the construction of representations of large-scale space can be\nsolved efficiently even in the presence of directional and recognition\nuncertainty. We pay particular attention to the problems that arise due to\nrecognition uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:36:53 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Basye", "Kenneth", ""], ["Dean", "Thomas L.", ""]]}, {"id": "1304.1493", "submitter": "Carlo Berzuini", "authors": "Carlo Berzuini, Riccardo Bellazzi, Silvana Quaglini", "title": "Temporal Reasoning with Probabilities", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-14-21", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore representations of temporal knowledge based upon the\nformalism of Causal Probabilistic Networks (CPNs). Two different\n?continuous-time? representations are proposed. In the first, the CPN includes\nvariables representing ?event-occurrence times?, possibly on different time\nscales, and variables representing the ?state? of the system at these times. In\nthe second, the CPN describes the influences between random variables with\nvalues in () representing dates, i.e. time-points associated with the\noccurrence of relevant events. However, structuring a system of inter-related\ndates as a network where all links commit to a single specific notion of cause\nand effect is in general far from trivial and leads to severe difficulties. We\nclaim that we should recognize explicitly different kinds of relation between\ndates, such as ?cause?, ?inhibition?, ?competition?, etc., and propose a method\nwhereby these relations are coherently embedded in a CPN using additional\nauxiliary nodes corresponding to \"instrumental\" variables. Also discussed,\nthough not covered in detail, is the topic concerning how the quantitative\nspecifications to be inserted in a temporal CPN can be learned from specific\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:36:59 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Berzuini", "Carlo", ""], ["Bellazzi", "Riccardo", ""], ["Quaglini", "Silvana", ""]]}, {"id": "1304.1494", "submitter": "Piero P. Bonissone", "authors": "Piero P. Bonissone", "title": "Now that I Have a Good Theory of Uncertainty, What Else Do I Need?", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-22-33", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rather than discussing the isolated merits of a nominative theory of\nuncertainty, this paper focuses on a class of problems, referred to as Dynamic\nClassification Problem (DCP), which requires the integration of many theories,\nincluding a prescriptive theory of uncertainty. We start by analyzing the\nDynamic Classification Problem and by defining its induced requirements on a\nsupporting (plausible) reasoning system. We provide a summary of the underlying\ntheory (based on the semantics of many-valed logics) and illustrate the\nconstraints imposed upon it to ensure the modularity and computational\nperformance required by the applications. We describe the technologies used for\nknowledge engineering (such as object-based simulator to exercise requirements,\nand development tools to build the Knowledge Base and functionally validate\nit). We emphasize the difference between development environment and run-time\nsystem, describe the rule cross-compiler, and the real-time inference engine\nwith meta-reasoning capabilities. Finally, we illustrate how our proposed\ntechnology satisfies the pop's requirements and analyze some of the lessons\nreamed from its applications to situation assessment problems for Pilot's\nAssociate and Submarine Commander Associate.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:37:05 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Bonissone", "Piero P.", ""]]}, {"id": "1304.1495", "submitter": "Piero P. Bonissone", "authors": "Piero P. Bonissone, David A. Cyrluk, James W. Goodwin, Jonathan\n  Stillman", "title": "Uncertainty and Incompleteness", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-34-45", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two major difficulties in using default logics are their intractability and\nthe problem of selecting among multiple extensions. We propose an approach to\nthese problems based on integrating nommonotonic reasoning with plausible\nreasoning based on triangular norms. A previously proposed system for reasoning\nwith uncertainty (RUM) performs uncertain monotonic inferences on an acyclic\ngraph. We have extended RUM to allow nommonotonic inferences and cycles within\nnonmonotonic rules. By restricting the size and complexity of the nommonotonic\ncycles we can still perform efficient inferences. Uncertainty measures provide\na basis for deciding among multiple defaults. Different algorithms and\nheuristics for finding the optimal defaults are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:37:11 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Bonissone", "Piero P.", ""], ["Cyrluk", "David A.", ""], ["Goodwin", "James W.", ""], ["Stillman", "Jonathan", ""]]}, {"id": "1304.1496", "submitter": "Lashon B. Booker", "authors": "Lashon B. Booker, Naveen Hota, Connie Loggia Ramsey", "title": "BaRT: A Bayesian Reasoning Tool for Knowledge Based Systems", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-46-53", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the technology for building knowledge based systems has matured, important\nlessons have been learned about the relationship between the architecture of a\nsystem and the nature of the problems it is intended to solve. We are\nimplementing a knowledge engineering tool called BART that is designed with\nthese lessons in mind. BART is a Bayesian reasoning tool that makes belief\nnetworks and other probabilistic techniques available to knowledge engineers\nbuilding classificatory problem solvers. BART has already been used to develop\na decision aid for classifying ship images, and it is currently being used to\nmanage uncertainty in systems concerned with analyzing intelligence reports.\nThis paper discusses how state-of-the-art probabilistic methods fit naturally\ninto a knowledge based approach to classificatory problem solving, and\ndescribes the current capabilities of BART.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:37:17 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Booker", "Lashon B.", ""], ["Hota", "Naveen", ""], ["Ramsey", "Connie Loggia", ""]]}, {"id": "1304.1497", "submitter": "Eugene Charniak", "authors": "Eugene Charniak, Robert P. Goldman", "title": "Plan Recognition in Stories and in Life", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-54-59", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plan recognition does not work the same way in stories and in \"real life\"\n(people tend to jump to conclusions more in stories). We present a theory of\nthis, for the particular case of how objects in stories (or in life) influence\nplan recognition decisions. We provide a Bayesian network formalization of a\nsimple first-order theory of plans, and show how a particular network parameter\nseems to govern the difference between \"life-like\" and \"story-like\" response.\nWe then show why this parameter would be influenced (in the desired way) by a\nmodel of speaker (or author) topic selection which assumes that facts in\nstories are typically \"relevant\".\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:37:23 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Charniak", "Eugene", ""], ["Goldman", "Robert P.", ""]]}, {"id": "1304.1498", "submitter": "R. Martin Chavez", "authors": "R. Martin Chavez, Gregory F. Cooper", "title": "An Empirical Evaluation of a Randomized Algorithm for Probabilistic\n  Inference", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-60-70", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, researchers in decision analysis and artificial intelligence\n(Al) have used Bayesian belief networks to build models of expert opinion.\nUsing standard methods drawn from the theory of computational complexity,\nworkers in the field have shown that the problem of probabilistic inference in\nbelief networks is difficult and almost certainly intractable. K N ET, a\nsoftware environment for constructing knowledge-based systems within the\naxiomatic framework of decision theory, contains a randomized approximation\nscheme for probabilistic inference. The algorithm can, in many circumstances,\nperform efficient approximate inference in large and richly interconnected\nmodels of medical diagnosis. Unlike previously described stochastic algorithms\nfor probabilistic inference, the randomized approximation scheme computes a\npriori bounds on running time by analyzing the structure and contents of the\nbelief network. In this article, we describe a randomized algorithm for\nprobabilistic inference and analyze its performance mathematically. Then, we\ndevote the major portion of the paper to a discussion of the algorithm's\nempirical behavior. The results indicate that the generation of good trials\n(that is, trials whose distribution closely matches the true distribution),\nrather than the computation of numerous mediocre trials, dominates the\nperformance of stochastic simulation. Key words: probabilistic inference,\nbelief networks, stochastic simulation, computational complexity theory,\nrandomized algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:37:29 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Chavez", "R. Martin", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1304.1499", "submitter": "Marvin S. Cohen", "authors": "Marvin S. Cohen", "title": "Decision Making \"Biases\" and Support for Assumption-Based Higher-Order\n  Reasoning", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-71-80", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unaided human decision making appears to systematically violate consistency\nconstraints imposed by normative theories; these biases in turn appear to\njustify the application of formal decision-analytic models. It is argued that\nboth claims are wrong. In particular, we will argue that the \"confirmation\nbias\" is premised on an overly narrow view of how conflicting evidence is and\nought to be handled. Effective decision aiding should focus on supporting the\ncontral processes by means of which knowledge is extended into novel situations\nand in which assumptions are adopted, utilized, and revised. The Non- Monotonic\nProbabilist represents initial work toward such an aid.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:37:35 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Cohen", "Marvin S.", ""]]}, {"id": "1304.1500", "submitter": "Didier Dubois", "authors": "Didier Dubois, Jerome Lang, Henri Prade", "title": "Automated Reasoning Using Possibilistic Logic: Semantics, Belief\n  Revision and Variable Certainty Weights", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-81-87", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper an approach to automated deduction under uncertainty,based on\npossibilistic logic, is proposed ; for that purpose we deal with clauses\nweighted by a degree which is a lower bound of a necessity or a possibility\nmeasure, according to the nature of the uncertainty. Two resolution rules are\nused for coping with the different situations, and the refutation method can be\ngeneralized. Besides the lower bounds are allowed to be functions of variables\ninvolved in the clause, which gives hypothetical reasoning capabilities. The\nrelation between our approach and the idea of minimizing abnormality is briefly\ndiscussed. In case where only lower bounds of necessity measures are involved,\na semantics is proposed, in which the completeness of the extended resolution\nprinciple is proved. Moreover deduction from a partially inconsistent knowledge\nbase can be managed in this approach and displays some form of\nnon-monotonicity.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:37:41 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Dubois", "Didier", ""], ["Lang", "Jerome", ""], ["Prade", "Henri", ""]]}, {"id": "1304.1501", "submitter": "Christopher Elsaesser", "authors": "Christopher Elsaesser, Max Henrion", "title": "How Much More Probable is \"Much More Probable\"? Verbal Expressions for\n  Probability Updates", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-88-94", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference systems should be able to explain their reasoning to\nusers, translating from numerical to natural language. Previous empirical work\nhas investigated the correspondence between absolute probabilities and\nlinguistic phrases. This study extends that work to the correspondence between\nchanges in probabilities (updates) and relative probability phrases, such as\n\"much more likely\" or \"a little less likely.\" Subjects selected such phrases to\nbest describe numerical probability updates. We examined three hypotheses about\nthe correspondence, and found the most descriptively accurate of these three to\nbe that each such phrase corresponds to a fixed difference in probability\n(rather than fixed ratio of probabilities or of odds). The empirically derived\nphrase selection function uses eight phrases and achieved a 72% accuracy in\ncorrespondence with the subjects' actual usage.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:37:47 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Elsaesser", "Christopher", ""], ["Henrion", "Max", ""]]}, {"id": "1304.1502", "submitter": "Henri Farrency", "authors": "Henri Farrency, Henri Prade", "title": "Positive and Negative Explanations of Uncertain Reasoning in the\n  Framework of Possibility Theory", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-95-101", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach for developing the explanation capabilities\nof rule-based expert systems managing imprecise and uncertain knowledge. The\ntreatment of uncertainty takes place in the framework of possibility theory\nwhere the available information concerning the value of a logical or numerical\nvariable is represented by a possibility distribution which restricts its more\nor less possible values. We first discuss different kinds of queries asking for\nexplanations before focusing on the two following types : i) how, a particular\npossibility distribution is obtained (emphasizing the main reasons only) ; ii)\nwhy in a computed possibility distribution, a particular value has received a\npossibility degree which is so high, so low or so contrary to the expectation.\nThe approach is based on the exploitation of equations in max-min algebra. This\nformalism includes the limit case of certain and precise information.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:37:53 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Farrency", "Henri", ""], ["Prade", "Henri", ""]]}, {"id": "1304.1503", "submitter": "Kenneth W. Fertig", "authors": "Kenneth W. Fertig, John S. Breese", "title": "Interval Influence Diagrams", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-102-111", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a mechanism for performing probabilistic reasoning in influence\ndiagrams using interval rather than point valued probabilities. We derive the\nprocedures for node removal (corresponding to conditional expectation) and arc\nreversal (corresponding to Bayesian conditioning) in influence diagrams where\nlower bounds on probabilities are stored at each node. The resulting bounds for\nthe transformed diagram are shown to be optimal within the class of constraints\non probability distributions that can be expressed exclusively as lower bounds\non the component probabilities of the diagram. Sequences of these operations\ncan be performed to answer probabilistic queries with indeterminacies in the\ninput and for performing sensitivity analysis on an influence diagram. The\nstorage requirements and computational complexity of this approach are\ncomparable to those for point-valued probabilistic inference mechanisms, making\nthe approach attractive for performing sensitivity analysis and where\nprobability information is not available. Limited empirical data on an\nimplementation of the methodology are provided.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:37:59 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Fertig", "Kenneth W.", ""], ["Breese", "John S.", ""]]}, {"id": "1304.1504", "submitter": "Robert Fung", "authors": "Robert Fung, Kuo-Chu Chang", "title": "Weighing and Integrating Evidence for Stochastic Simulation in Bayesian\n  Networks", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-112-117", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic simulation approaches perform probabilistic inference in Bayesian\nnetworks by estimating the probability of an event based on the frequency that\nthe event occurs in a set of simulation trials. This paper describes the\nevidence weighting mechanism, for augmenting the logic sampling stochastic\nsimulation algorithm [Henrion, 1986]. Evidence weighting modifies the logic\nsampling algorithm by weighting each simulation trial by the likelihood of a\nnetwork's evidence given the sampled state node values for that trial. We also\ndescribe an enhancement to the basic algorithm which uses the evidential\nintegration technique [Chin and Cooper, 1987]. A comparison of the basic\nevidence weighting mechanism with the Markov blanket algorithm [Pearl, 1987],\nthe logic sampling algorithm, and the evidence integration algorithm is\npresented. The comparison is aided by analyzing the performance of the\nalgorithms in a simple example network.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:38:05 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Fung", "Robert", ""], ["Chang", "Kuo-Chu", ""]]}, {"id": "1304.1505", "submitter": "Dan Geiger", "authors": "Dan Geiger, Tom S. Verma, Judea Pearl", "title": "d-Separation: From Theorems to Algorithms", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-118-125", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An efficient algorithm is developed that identifies all independencies\nimplied by the topology of a Bayesian network. Its correctness and maximality\nstems from the soundness and completeness of d-separation with respect to\nprobability theory. The algorithm runs in time O (l E l) where E is the number\nof edges in the network.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:38:11 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Geiger", "Dan", ""], ["Verma", "Tom S.", ""], ["Pearl", "Judea", ""]]}, {"id": "1304.1506", "submitter": "Maria Angeles Gil", "authors": "Maria Angeles Gil, Pramod Jain", "title": "The Effects of Perfect and Sample Information on Fuzzy Utilities in\n  Decision-Making", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-126-133", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we first consider a Bayesian framework and model the \"utility\nfunction\" in terms of fuzzy random variables. On the basis of this model, we\ndefine the \"prior (fuzzy) expected utility\" associated with each action, and\nthe corresponding \"posterior (fuzzy) expected utility given sample information\nfrom a random experiment\". The aim of this paper is to analyze how sample\ninformation can affect the expected utility. In this way, by using some fuzzy\npreference relations, we conclude that sample information allows a decision\nmaker to increase the expected utility on the average. The upper bound on the\nvalue of the expected utility is when the decision maker has perfect\ninformation. Applications of this work to the field of artificial intelligence\nare presented through two examples.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:38:16 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Gil", "Maria Angeles", ""], ["Jain", "Pramod", ""]]}, {"id": "1304.1507", "submitter": "Moises Goldszmidt", "authors": "Moises Goldszmidt, Judea Pearl", "title": "Deciding Consistency of Databases Containing Defeasible and Strict\n  Information", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-134-141", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a norm of consistency for a mixed set of defeasible and strict\nsentences, based on a probabilistic semantics. This norm establishes a clear\ndistinction between knowledge bases depicting exceptions and those containing\noutright contradictions. We then define a notion of entailment based also on\nprobabilistic considerations and provide a characterization of the relation\nbetween consistency and entailment. We derive necessary and sufficient\nconditions for consistency, and provide a simple decision procedure for testing\nconsistency and deciding whether a sentence is entailed by a database. Finally,\nit is shown that if al1 sentences are Horn clauses, consistency and entailment\ncan be tested in polynomial time.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:38:23 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Goldszmidt", "Moises", ""], ["Pearl", "Judea", ""]]}, {"id": "1304.1508", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern", "title": "The Relationship between Knowledge, Belief and Certainty", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-142-151", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the relation between knowledge and certainty, where a fact is\nknown if it is true at all worlds an agent considers possible and is certain if\nit holds with probability 1. We identify certainty with probabilistic belief.\nWe show that if we assume one fixed probability assignment, then the logic\nKD45, which has been identified as perhaps the most appropriate for belief,\nprovides a complete axiomatization for reasoning about certainty. Just as an\nagent may believe a fact although phi is false, he may be certain that a fact\nphi, is true although phi is false. However, it is easy to see that an agent\ncan have such false (probabilistic) beliefs only at a set of worlds of\nprobability 0. If we restrict attention to structures where all worlds have\npositive probability, then S5 provides a complete axiomatization. If we\nconsider a more general setting, where there might be a different probability\nassignment at each world, then by placing appropriate conditions on the support\nof the probability function (the set of worlds which have non-zero\nprobability), we can capture many other well-known modal logics, such as T and\nS4. Finally, we consider which axioms characterize structures satisfying\nMiller's principle.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:38:29 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Halpern", "Joseph Y.", ""]]}, {"id": "1304.1509", "submitter": "Othar Hansson", "authors": "Othar Hansson, Andy Mayer", "title": "Heuristic Search as Evidential Reasoning", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-152-161", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BPS, the Bayesian Problem Solver, applies probabilistic inference and\ndecision-theoretic control to flexible, resource-constrained problem-solving.\nThis paper focuses on the Bayesian inference mechanism in BPS, and contrasts it\nwith those of traditional heuristic search techniques. By performing sound\ninference, BPS can outperform traditional techniques with significantly less\ncomputational effort. Empirical tests on the Eight Puzzle show that after only\na few hundred node expansions, BPS makes better decisions than does the best\nexisting algorithm after several million node expansions\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:38:35 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Hansson", "Othar", ""], ["Mayer", "Andy", ""]]}, {"id": "1304.1510", "submitter": "David Heckerman", "authors": "David Heckerman, John S. Breese, Eric J. Horvitz", "title": "The Compilation of Decision Models", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-162-173", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and analyze the problem of the compilation of decision models\nfrom a decision-theoretic perspective. The techniques described allow us to\nevaluate various configurations of compiled knowledge given the nature of\nevidential relationships in a domain, the utilities associated with alternative\nactions, the costs of run-time delays, and the costs of memory. We describe\nprocedures for selecting a subset of the total observations available to be\nincorporated into a compiled situation-action mapping, in the context of a\nbinary decision with conditional independence of evidence. The methods allow us\nto incrementally select the best pieces of evidence to add to the set of\ncompiled knowledge in an engineering setting. After presenting several\napproaches to compilation, we exercise one of the methods to provide insight\ninto the relationship between the distribution over weights of evidence and the\npreferred degree of compilation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:38:41 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Heckerman", "David", ""], ["Breese", "John S.", ""], ["Horvitz", "Eric J.", ""]]}, {"id": "1304.1511", "submitter": "David Heckerman", "authors": "David Heckerman", "title": "A Tractable Inference Algorithm for Diagnosing Multiple Diseases", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-174-181", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine a probabilistic model for the diagnosis of multiple diseases. In\nthe model, diseases and findings are represented as binary variables. Also,\ndiseases are marginally independent, features are conditionally independent\ngiven disease instances, and diseases interact to produce findings via a noisy\nOR-gate. An algorithm for computing the posterior probability of each disease,\ngiven a set of observed findings, called quickscore, is presented. The time\ncomplexity of the algorithm is O(nm-2m+), where n is the number of diseases, m+\nis the number of positive findings and m- is the number of negative findings.\nAlthough the time complexity of quickscore i5 exponential in the number of\npositive findings, the algorithm is useful in practice because the number of\nobserved positive findings is usually far less than the number of diseases\nunder consideration. Performance results for quickscore applied to a\nprobabilistic version of Quick Medical Reference (QMR) are provided.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:38:47 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Heckerman", "David", ""]]}, {"id": "1304.1512", "submitter": "Eric J. Horvitz", "authors": "Eric J. Horvitz, Jaap Suermondt, Gregory F. Cooper", "title": "Bounded Conditioning: Flexible Inference for Decisions under Scarce\n  Resources", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-182-193", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a graceful approach to probabilistic inference called bounded\nconditioning. Bounded conditioning monotonically refines the bounds on\nposterior probabilities in a belief network with computation, and converges on\nfinal probabilities of interest with the allocation of a complete resource\nfraction. The approach allows a reasoner to exchange arbitrary quantities of\ncomputational resource for incremental gains in inference quality. As such,\nbounded conditioning holds promise as a useful inference technique for\nreasoning under the general conditions of uncertain and varying reasoning\nresources. The algorithm solves a probabilistic bounding problem in complex\nbelief networks by breaking the problem into a set of mutually exclusive,\ntractable subproblems and ordering their solution by the expected effect that\neach subproblem will have on the final answer. We introduce the algorithm,\ndiscuss its characterization, and present its performance on several belief\nnetworks, including a complex model for reasoning about problems in\nintensive-care medicine.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:38:53 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Horvitz", "Eric J.", ""], ["Suermondt", "Jaap", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1304.1513", "submitter": "A. C. Kak", "authors": "A. C. Kak, K. M. Andress, C. Lopez-Abadia, M. S. Carroll, J. R. Lewis", "title": "Hierarchical Evidence Accumulation in the Pseiki System and Experiments\n  in Model-Driven Mobile Robot Navigation", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-194-207", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we will review the process of evidence accumulation in the\nPSEIKI system for expectation-driven interpretation of images of 3-D scenes.\nExpectations are presented to PSEIKI as a geometrical hierarchy of\nabstractions. PSEIKI's job is then to construct abstraction hierarchies in the\nperceived image taking cues from the abstraction hierarchies in the\nexpectations. The Dempster-Shafer formalism is used for associating belief\nvalues with the different possible labels for the constructed abstractions in\nthe perceived image. This system has been used successfully for autonomous\nnavigation of a mobile robot in indoor environments.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:38:59 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Kak", "A. C.", ""], ["Andress", "K. M.", ""], ["Lopez-Abadia", "C.", ""], ["Carroll", "M. S.", ""], ["Lewis", "J. R.", ""]]}, {"id": "1304.1514", "submitter": "Harold P. Lehmann", "authors": "Harold P. Lehmann", "title": "A Decision-Theoretic Model for Using Scientific Data", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-208-215", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Artificial Intelligence systems depend on the agent's updating its\nbeliefs about the world on the basis of experience. Experiments constitute one\ntype of experience, so scientific methodology offers a natural environment for\nexamining the issues attendant to using this class of evidence. This paper\npresents a framework which structures the process of using scientific data from\nresearch reports for the purpose of making decisions, using decision analysis\nas the basis for the structure and using medical research as the general\nscientific domain. The structure extends the basic influence diagram for\nupdating belief in an object domain parameter of interest by expanding the\nparameter into four parts: those of the patient, the population, the study\nsample, and the effective study sample. The structure uses biases to perform\nthe transformation of one parameter into another, so that, for instance,\nselection biases, in concert with the population parameter, yield the study\nsample parameter. The influence diagram structure provides decision theoretic\njustification for practices of good clinical research such as randomized\nassignment and blindfolding of care providers. The model covers most research\ndesigns used in medicine: case-control studies, cohort studies, and controlled\nclinical trials, and provides an architecture to separate clearly between\nstatistical knowledge and domain knowledge. The proposed general model can be\nthe basis for clinical epidemiological advisory systems, when coupled with\nheuristic pruning of irrelevant biases; of statistical workstations, when the\ncomputational machinery for calculation of posterior distributions is added;\nand of meta-analytic reviews, when multiple studies may impact on a single\npopulation parameter.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:39:05 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Lehmann", "Harold P.", ""]]}, {"id": "1304.1515", "submitter": "Paul E. Lehner", "authors": "Paul E. Lehner, Theresa M. Mullin, Marvin S. Cohen", "title": "When Should a Decision Maker Ignore the Advice of a Decision Aid?", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-216-223", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper argues that the principal difference between decision aids and\nmost other types of information systems is the greater reliance of decision\naids on fallible algorithms--algorithms that sometimes generate incorrect\nadvice. It is shown that interactive problem solving with a decision aid that\nis based on a fallible algorithm can easily result in aided performance which\nis poorer than unaided performance, even if the algorithm, by itself, performs\nsignificantly better than the unaided decision maker. This suggests that unless\ncertain conditions are satisfied, using a decision aid as an aid is\ncounterproductive. Some conditions under which a decision aid is best used as\nan aid are derived.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:39:11 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Lehner", "Paul E.", ""], ["Mullin", "Theresa M.", ""], ["Cohen", "Marvin S.", ""]]}, {"id": "1304.1516", "submitter": "Paul E. Lehner", "authors": "Paul E. Lehner", "title": "Inference Policies", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-224-232", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is suggested that an AI inference system should reflect an inference\npolicy that is tailored to the domain of problems to which it is applied -- and\nfurthermore that an inference policy need not conform to any general theory of\nrational inference or induction. We note, for instance, that Bayesian reasoning\nabout the probabilistic characteristics of an inference domain may result in\nthe specification of an nonBayesian procedure for reasoning within the\ninference domain. In this paper, the idea of an inference policy is explored in\nsome detail. To support this exploration, the characteristics of some standard\nand nonstandard inference policies are examined.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:39:17 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Lehner", "Paul E.", ""]]}, {"id": "1304.1517", "submitter": "Tod S. Levitt", "authors": "Tod S. Levitt, John Mark Agosta, Thomas O. Binford", "title": "Model-based Influence Diagrams for Machine Vision", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-233-244", "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show an approach to automated control of machine vision systems based on\nincremental creation and evaluation of a particular family of influence\ndiagrams that represent hypotheses of imagery interpretation and possible\nsubsequent processing decisions. In our approach, model-based machine vision\ntechniques are integrated with hierarchical Bayesian inference to provide a\nframework for representing and matching instances of objects and relationships\nin imagery and for accruing probabilities to rank order conflicting scene\ninterpretations. We extend a result of Tatman and Shachter to show that the\nsequence of processing decisions derived from evaluating the diagrams at each\nstage is the same as the sequence that would have been derived by evaluating\nthe final influence diagram that contains all random variables created during\nthe run of the vision system.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:39:23 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Levitt", "Tod S.", ""], ["Agosta", "John Mark", ""], ["Binford", "Thomas O.", ""]]}, {"id": "1304.1518", "submitter": "Ronald P. Loui", "authors": "Ronald P. Loui", "title": "Defeasible Decisions: What the Proposal is and isn't", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-245-252", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In two recent papers, I have proposed a description of decision analysis that\ndiffers from the Bayesian picture painted by Savage, Jeffrey and other classic\nauthors. Response to this view has been either overly enthusiastic or unduly\npessimistic. In this paper I try to place the idea in its proper place, which\nmust be somewhere in between. Looking at decision analysis as defeasible\nreasoning produces a framework in which planning and decision theory can be\nintegrated, but work on the details has barely begun. It also produces a\nframework in which the meta-decision regress can be stopped in a reasonable\nway, but it does not allow us to ignore meta-level decisions. The heuristics\nfor producing arguments that I have presented are only supposed to be\nsuggestive; but they are not open to the egregious errors about which some have\nworried. And though the idea is familiar to those who have studied heuristic\nsearch, it is somewhat richer because the control of dialectic is more\ninteresting than the deepening of search.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:39:29 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Loui", "Ronald P.", ""]]}, {"id": "1304.1519", "submitter": "Mary McLeish", "authors": "Mary McLeish, P. Yao, M. Cecile, T. Stirtzinger", "title": "Experiments Using Belief Functions and Weights of Evidence incorporating\n  Statistical Data and Expert Opinions", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-253-264", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents some ideas and results of using uncertainty management\nmethods in the presence of data in preference to other statistical and machine\nlearning methods. A medical domain is used as a test-bed with data available\nfrom a large hospital database system which collects symptom and outcome\ninformation about patients. Data is often missing, of many variable types and\nsample sizes for particular outcomes is not large. Uncertainty management\nmethods are useful for such domains and have the added advantage of allowing\nfor expert modification of belief values originally obtained from data.\nMethodological considerations for using belief functions on statistical data\nare dealt with in some detail. Expert opinions are Incorporated at various\nlevels of the project development and results are reported on an application to\nliver disease diagnosis. Recent results contrasting the use of weights of\nevidence and logistic regression on another medical domain are also presented.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:39:35 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["McLeish", "Mary", ""], ["Yao", "P.", ""], ["Cecile", "M.", ""], ["Stirtzinger", "T.", ""]]}, {"id": "1304.1520", "submitter": "W. R. Moninger", "authors": "W. R. Moninger, J. A. Flueck, C. Lusk, W. F. Roberts", "title": "Shootout-89: A Comparative Evaluation of Knowledge-based Systems that\n  Forecast Severe Weather", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-265-271", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the summer of 1989, the Forecast Systems Laboratory of the National\nOceanic and Atmospheric Administration sponsored an evaluation of artificial\nintelligence-based systems that forecast severe convective storms. The\nevaluation experiment, called Shootout-89, took place in Boulder, and focussed\non storms over the northeastern Colorado foothills and plains (Moninger, et\nal., 1990). Six systems participated in Shootout-89. These included traditional\nexpert systems, an analogy-based system, and a system developed using methods\nfrom the cognitive science/judgment analysis tradition. Each day of the\nexercise, the systems generated 2 to 9 hour forecasts of the probabilities of\noccurrence of: non significant weather, significant weather, and severe\nweather, in each of four regions in northeastern Colorado. A verification\ncoordinator working at the Denver Weather Service Forecast Office gathered\nground-truth data from a network of observers. Systems were evaluated on the\nbasis of several measures of forecast skill, and on other metrics such as\ntimeliness, ease of learning, and ease of use. Systems were generally easy to\noperate, however the various systems required substantially different levels of\nmeteorological expertise on the part of their users--reflecting the various\noperational environments for which the systems had been designed. Systems\nvaried in their statistical behavior, but on this difficult forecast problem,\nthe systems generally showed a skill approximately equal to that of persistence\nforecasts and climatological (historical frequency) forecasts. The two systems\nthat appeared best able to discriminate significant from non significant\nweather events were traditional expert systems. Both of these systems required\nthe operator to make relatively sophisticated meteorological judgments. We are\nunable, based on only one summer's worth of data, to determine the extent to\nwhich the greater skill of the two systems was due to the content of their\nknowledge bases, or to the subjective judgments of the operator. A follow-on\nexperiment, Shootout-91, is currently being planned. Interested potential\nparticipants are encouraged to contact the author at the address above.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:39:40 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Moninger", "W. R.", ""], ["Flueck", "J. A.", ""], ["Lusk", "C.", ""], ["Roberts", "W. F.", ""]]}, {"id": "1304.1521", "submitter": "Eric Neufeld", "authors": "Eric Neufeld, J. D. Horton", "title": "Conditioning on Disjunctive Knowledge: Defaults and Probabilities", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-272-278", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many writers have observed that default logics appear to contain the \"lottery\nparadox\" of probability theory. This arises when a default \"proof by\ncontradiction\" lets us conclude that a typical X is not a Y where Y is an\nunusual subclass of X. We show that there is a similar problem with default\n\"proof by cases\" and construct a setting where we might draw a different\nconclusion knowing a disjunction than we would knowing any particular disjunct.\nThough Reiter's original formalism is capable of representing this distinction,\nother approaches are not. To represent and reason about this case, default\nlogicians must specify how a \"typical\" individual is selected. The problem is\nclosely related to Simpson's paradox of probability theory. If we accept a\nsimple probabilistic account of defaults based on the notion that one\nproposition may favour or increase belief in another, the \"multiple extension\nproblem\" for both conjunctive and disjunctive knowledge vanishes.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:39:46 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Neufeld", "Eric", ""], ["Horton", "J. D.", ""]]}, {"id": "1304.1522", "submitter": "Michael Pittarelli", "authors": "Michael Pittarelli", "title": "Maximum Uncertainty Procedures for Interval-Valued Probability\n  Distributions", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-279-286", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measures of uncertainty and divergence are introduced for interval-valued\nprobability distributions and are shown to have desirable mathematical\nproperties. A maximum uncertainty inference procedure for marginal interval\ndistributions is presented. A technique for reconstruction of interval\ndistributions from projections is developed based on this inference procedure\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:39:51 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Pittarelli", "Michael", ""]]}, {"id": "1304.1523", "submitter": "Gregory M. Provan", "authors": "Gregory M. Provan", "title": "A Logical Interpretation of Dempster-Shafer Theory, with Application to\n  Visual Recognition", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-287-294", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate Dempster Shafer Belief functions in terms of Propositional Logic\nusing the implicit notion of provability underlying Dempster Shafer Theory.\nGiven a set of propositional clauses, assigning weights to certain\npropositional literals enables the Belief functions to be explicitly computed\nusing Network Reliability techniques. Also, the logical procedure corresponding\nto updating Belief functions using Dempster's Rule of Combination is shown.\nThis analysis formalizes the implementation of Belief functions within an\nAssumption-based Truth Maintenance System (ATMS). We describe the extension of\nan ATMS-based visual recognition system, VICTORS, with this logical formulation\nof Dempster Shafer theory. Without Dempster Shafer theory, VICTORS computes all\npossible visual interpretations (i.e. all logical models) without determining\nthe best interpretation(s). Incorporating Dempster Shafer theory enables\noptimal visual interpretations to be computed and a logical semantics to be\nmaintained.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:39:57 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Provan", "Gregory M.", ""]]}, {"id": "1304.1524", "submitter": "Peter Sember", "authors": "Peter Sember, Ingrid Zukerman", "title": "Strategies for Generating Micro Explanations for Bayesian Belief\n  Networks", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-295-302", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Belief Networks have been largely overlooked by Expert Systems\npractitioners on the grounds that they do not correspond to the human inference\nmechanism. In this paper, we introduce an explanation mechanism designed to\ngenerate intuitive yet probabilistically sound explanations of inferences drawn\nby a Bayesian Belief Network. In particular, our mechanism accounts for the\nresults obtained due to changes in the causal and the evidential support of a\nnode.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:40:04 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Sember", "Peter", ""], ["Zukerman", "Ingrid", ""]]}, {"id": "1304.1525", "submitter": "Ross D. Shachter", "authors": "Ross D. Shachter", "title": "Evidence Absorption and Propagation through Evidence Reversals", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-303-310", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The arc reversal/node reduction approach to probabilistic inference is\nextended to include the case of instantiated evidence by an operation called\n\"evidence reversal.\" This not only provides a technique for computing posterior\njoint distributions on general belief networks, but also provides insight into\nthe methods of Pearl [1986b] and Lauritzen and Spiegelhalter [1988]. Although\nit is well understood that the latter two algorithms are closely related, in\nfact all three algorithms are identical whenever the belief network is a\nforest.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:40:10 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Shachter", "Ross D.", ""]]}, {"id": "1304.1526", "submitter": "Ross D. Shachter", "authors": "Ross D. Shachter, Mark Alan Peot", "title": "Simulation Approaches to General Probabilistic Inference on Belief\n  Networks", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-311-318", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of algorithms have been developed to solve probabilistic inference\nproblems on belief networks. These algorithms can be divided into two main\ngroups: exact techniques which exploit the conditional independence revealed\nwhen the graph structure is relatively sparse, and probabilistic sampling\ntechniques which exploit the \"conductance\" of an embedded Markov chain when the\nconditional probabilities have non-extreme values. In this paper, we\ninvestigate a family of \"forward\" Monte Carlo sampling techniques similar to\nLogic Sampling [Henrion, 1988] which appear to perform well even in some\nmultiply connected networks with extreme conditional probabilities, and thus\nwould be generally applicable. We consider several enhancements which reduce\nthe posterior variance using this approach and propose a framework and criteria\nfor choosing when to use those enhancements.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:40:16 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Shachter", "Ross D.", ""], ["Peot", "Mark Alan", ""]]}, {"id": "1304.1527", "submitter": "Philippe Smets", "authors": "Philippe Smets", "title": "Decision under Uncertainty", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-319-326", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive axiomatically the probability function that should be used to make\ndecisions given any form of underlying uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:40:21 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Smets", "Philippe", ""]]}, {"id": "1304.1528", "submitter": "Michael Smithson", "authors": "Michael Smithson", "title": "Freedom: A Measure of Second-order Uncertainty for Intervalic\n  Probability Schemes", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-327-334", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses a new measure that is adaptable to certain intervalic\nprobability frameworks, possibility theory, and belief theory. As such, it has\nthe potential for wide use in knowledge engineering, expert systems, and\nrelated problems in the human sciences. This measure (denoted here by F) has\nbeen introduced in Smithson (1988) and is more formally discussed in Smithson\n(1989a)o Here, I propose to outline the conceptual basis for F and compare its\nproperties with other measures of second-order uncertainty. I will argue that F\nis an indicator of nonspecificity or alternatively, of freedom, as\ndistinguished from either ambiguity or vagueness.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:40:27 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Smithson", "Michael", ""]]}, {"id": "1304.1529", "submitter": "David J. Spiegelhalter", "authors": "David J. Spiegelhalter, Rodney C. Franklin, Kate Bull", "title": "Assessment, Criticism and Improvement of Imprecise Subjective\n  Probabilities for a Medical Expert System", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-335-342", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three paediatric cardiologists assessed nearly 1000 imprecise subjective\nconditional probabilities for a simple belief network representing congenital\nheart disease, and the quality of the assessments has been measured using\nprospective data on 200 babies. Quality has been assessed by a Brier scoring\nrule, which decomposes into terms measuring lack of discrimination and\nreliability. The results are displayed for each of 27 diseases and 24\nquestions, and generally the assessments are reliable although there was a\ntendency for the probabilities to be too extreme. The imprecision allows the\njudgements to be converted to implicit samples, and by combining with the\nobserved data the probabilities naturally adapt with experience. This appears\nto be a practical procedure even for reasonably large expert systems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:40:33 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Spiegelhalter", "David J.", ""], ["Franklin", "Rodney C.", ""], ["Bull", "Kate", ""]]}, {"id": "1304.1530", "submitter": "Sampath Srinivas", "authors": "Sampath Srinivas, Stuart Russell, Alice M. Agogino", "title": "Automated Construction of Sparse Bayesian Networks from Unstructured\n  Probabilistic Models and Domain Information", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-343-350", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm for automated construction of a sparse Bayesian network given an\nunstructured probabilistic model and causal domain information from an expert\nhas been developed and implemented. The goal is to obtain a network that\nexplicitly reveals as much information regarding conditional independence as\npossible. The network is built incrementally adding one node at a time. The\nexpert's information and a greedy heuristic that tries to keep the number of\narcs added at each step to a minimum are used to guide the search for the next\nnode to add. The probabilistic model is a predicate that can answer queries\nabout independencies in the domain. In practice the model can be implemented in\nvarious ways. For example, the model could be a statistical independence test\noperating on empirical data or a deductive prover operating on a set of\nindependence statements about the domain.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:40:38 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Srinivas", "Sampath", ""], ["Russell", "Stuart", ""], ["Agogino", "Alice M.", ""]]}, {"id": "1304.1531", "submitter": "Thomas M. Strat", "authors": "Thomas M. Strat", "title": "Making Decisions with Belief Functions", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-351-360", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A primary motivation for reasoning under uncertainty is to derive decisions\nin the face of inconclusive evidence. However, Shafer's theory of belief\nfunctions, which explicitly represents the underconstrained nature of many\nreasoning problems, lacks a formal procedure for making decisions. Clearly,\nwhen sufficient information is not available, no theory can prescribe actions\nwithout making additional assumptions. Faced with this situation, some\nassumption must be made if a clearly superior choice is to emerge. In this\npaper we offer a probabilistic interpretation of a simple assumption that\ndisambiguates decision problems represented with belief functions. We prove\nthat it yields expected values identical to those obtained by a probabilistic\nanalysis that makes the same assumption. In addition, we show how the decision\nanalysis methodology frequently employed in probabilistic reasoning can be\nextended for use with belief functions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:40:45 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Strat", "Thomas M.", ""]]}, {"id": "1304.1532", "submitter": "Michael J. Swain", "authors": "Michael J. Swain, Lambert E. Wixson, Paul B. Chou", "title": "Efficient Parallel Estimation for Markov Random Fields", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-361-368", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new, deterministic, distributed MAP estimation algorithm for\nMarkov Random Fields called Local Highest Confidence First (Local HCF). The\nalgorithm has been applied to segmentation problems in computer vision and its\nperformance compared with stochastic algorithms. The experiments show that\nLocal HCF finds better estimates than stochastic algorithms with much less\ncomputation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:40:50 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Swain", "Michael J.", ""], ["Wixson", "Lambert E.", ""], ["Chou", "Paul B.", ""]]}, {"id": "1304.1533", "submitter": "David S. Vaughan", "authors": "David S. Vaughan, Bruce M. Perrin, Robert M. Yadrick", "title": "Comparing Expert Systems Built Using Different Uncertain Inference\n  Systems", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-369-376", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study compares the inherent intuitiveness or usability of the most\nprominent methods for managing uncertainty in expert systems, including those\nof EMYCIN, PROSPECTOR, Dempster-Shafer theory, fuzzy set theory, simplified\nprobability theory (assuming marginal independence), and linear regression\nusing probability estimates. Participants in the study gained experience in a\nsimple, hypothetical problem domain through a series of learning trials. They\nwere then randomly assigned to develop an expert system using one of the six\nUncertain Inference Systems (UISs) listed above. Performance of the resulting\nsystems was then compared. The results indicate that the systems based on the\nPROSPECTOR and EMYCIN models were significantly less accurate for certain types\nof problems compared to systems based on the other UISs. Possible reasons for\nthese differences are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:40:56 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Vaughan", "David S.", ""], ["Perrin", "Bruce M.", ""], ["Yadrick", "Robert M.", ""]]}, {"id": "1304.1534", "submitter": "Wilson X. Wen", "authors": "Wilson X. Wen", "title": "Directed Cycles in Belief Networks", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-377-384", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most difficult task in probabilistic reasoning may be handling directed\ncycles in belief networks. To the best knowledge of this author, there is no\nserious discussion of this problem at all in the literature of probabilistic\nreasoning so far.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:41:02 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Wen", "Wilson X.", ""]]}, {"id": "1304.1535", "submitter": "Yang Xiang", "authors": "Yang Xiang, Michael P. Beddoes, David L Poole", "title": "Can Uncertainty Management be Realized in a Finite Totally Ordered\n  Probability Algebra?", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-385-393", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the feasibility of using finite totally ordered probability\nmodels under Alelinnas's Theory of Probabilistic Logic [Aleliunas, 1988] is\ninvestigated. The general form of the probability algebra of these models is\nderived and the number of possible algebras with given size is deduced. Based\non this analysis, we discuss problems of denominator-indifference and\nambiguity-generation that arise in reasoning by cases and abductive reasoning.\nAn example is given that illustrates how these problems arise. The\ninvestigation shows that a finite probability model may be of very limited\nusage.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:41:07 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Xiang", "Yang", ""], ["Beddoes", "Michael P.", ""], ["Poole", "David L", ""]]}, {"id": "1304.1536", "submitter": "Ronald R. Yager", "authors": "Ronald R. Yager", "title": "Normalization and the Representation of Nonmonotonic Knowledge in the\n  Theory of Evidence", "comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1989-PG-394-403", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the Dempster-Shafer theory of evidence. We introduce a concept of\nmonotonicity which is related to the diminution of the range between belief and\nplausibility. We show that the accumulation of knowledge in this framework\nexhibits a nonmonotonic property. We show how the belief structure can be used\nto represent typical or commonsense knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:41:14 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Yager", "Ronald R.", ""]]}, {"id": "1304.1628", "submitter": "Denis Berthier", "authors": "Denis Berthier (DSI)", "title": "Pattern-Based Constraint Satisfaction and Logic Puzzles", "comments": null, "journal-ref": "Pattern-Based Constraint Satisfaction and Logic Puzzles (2012) 484", "doi": null, "report-no": null, "categories": "cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pattern-Based Constraint Satisfaction and Logic Puzzles develops a pure\nlogic, pattern-based perspective of solving the finite Constraint Satisfaction\nProblem (CSP), with emphasis on finding the \"simplest\" solution. Different ways\nof reasoning with the constraints are formalised by various families of\n\"resolution rules\", each of them carrying its own notion of simplicity. A large\npart of the book illustrates the power of the approach by applying it to\nvarious popular logic puzzles. It provides a unified view of how to model and\nsolve them, even though they involve very different types of constraints:\nobvious symmetric ones in Sudoku, non-symmetric but transitive ones\n(inequalities) in Futoshiki, topological and geometric ones in Map colouring,\nNumbrix and Hidato, and even much more complex non-binary arithmetic ones in\nKakuro (or Cross Sums). It also shows that the most familiar techniques for\nthese puzzles can indeed be understood as mere application-specific\npresentations of the general rules. Sudoku is used as the main example\nthroughout the book, making it also an advanced level sequel to \"The Hidden\nLogic of Sudoku\" (another book by the same author), with: many examples of\nrelationships among different rules and of exceptional situations; comparisons\nof the resolution potential of various families of rules; detailed statistics\nof puzzles hardness; analysis of extreme instances.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2013 07:43:51 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Berthier", "Denis", "", "DSI"]]}, {"id": "1304.1672", "submitter": "Daniele Loiacono", "authors": "Daniele Loiacono and Luigi Cardamone and Pier Luca Lanzi", "title": "Simulated Car Racing Championship: Competition Software Manual", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manual describes the competition software for the Simulated Car Racing\nChampionship, an international competition held at major conferences in the\nfield of Evolutionary Computation and in the field of Computational\nIntelligence and Games. It provides an overview of the architecture, the\ninstructions to install the software and to run the simple drivers provided in\nthe package, the description of the sensors and the actuators.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2013 10:42:14 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2013 10:17:33 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Loiacono", "Daniele", ""], ["Cardamone", "Luigi", ""], ["Lanzi", "Pier Luca", ""]]}, {"id": "1304.1684", "submitter": "Emad Saad", "authors": "Emad Saad", "title": "Probability Aggregates in Probability Answer Set Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Probability answer set programming is a declarative programming that has been\nshown effective for representing and reasoning about a variety of probability\nreasoning tasks. However, the lack of probability aggregates, e.g. {\\em\nexpected values}, in the language of disjunctive hybrid probability logic\nprograms (DHPP) disallows the natural and concise representation of many\ninteresting problems. In this paper, we extend DHPP to allow arbitrary\nprobability aggregates. We introduce two types of probability aggregates; a\ntype that computes the expected value of a classical aggregate, e.g., the\nexpected value of the minimum, and a type that computes the probability of a\nclassical aggregate, e.g, the probability of sum of values. In addition, we\ndefine a probability answer set semantics for DHPP with arbitrary probability\naggregates including monotone, antimonotone, and nonmonotone probability\naggregates. We show that the proposed probability answer set semantics of DHPP\nsubsumes both the original probability answer set semantics of DHPP and the\nclassical answer set semantics of classical disjunctive logic programs with\nclassical aggregates, and consequently subsumes the classical answer set\nsemantics of the original disjunctive logic programs. We show that the proposed\nprobability answer sets of DHPP with probability aggregates are minimal\nprobability models and hence incomparable, which is an important property for\nnonmonotonic probability reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2013 11:39:31 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Saad", "Emad", ""]]}, {"id": "1304.1819", "submitter": "Pierre Lison", "authors": "Pierre Lison", "title": "Model-based Bayesian Reinforcement Learning for Dialogue Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning methods are increasingly used to optimise dialogue\npolicies from experience. Most current techniques are model-free: they directly\nestimate the utility of various actions, without explicit model of the\ninteraction dynamics. In this paper, we investigate an alternative strategy\ngrounded in model-based Bayesian reinforcement learning. Bayesian inference is\nused to maintain a posterior distribution over the model parameters, reflecting\nthe model uncertainty. This parameter distribution is gradually refined as more\ndata is collected and simultaneously used to plan the agent's actions. Within\nthis learning framework, we carried out experiments with two alternative\nformalisations of the transition model, one encoded with standard multinomial\ndistributions, and one structured with probabilistic rules. We demonstrate the\npotential of our approach with empirical results on a user simulator\nconstructed from Wizard-of-Oz data in a human-robot interaction scenario. The\nresults illustrate in particular the benefits of capturing prior domain\nknowledge with high-level rules.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2013 20:47:02 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Lison", "Pierre", ""]]}, {"id": "1304.1827", "submitter": "Emad Saad", "authors": "Emad Saad", "title": "Fuzzy Aggregates in Fuzzy Answer Set Programming", "comments": "arXiv admin note: substantial text overlap with arXiv:1304.1684", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Fuzzy answer set programming is a declarative framework for representing and\nreasoning about knowledge in fuzzy environments. However, the unavailability of\nfuzzy aggregates in disjunctive fuzzy logic programs, DFLP, with fuzzy answer\nset semantics prohibits the natural and concise representation of many\ninteresting problems. In this paper, we extend DFLP to allow arbitrary fuzzy\naggregates. We define fuzzy answer set semantics for DFLP with arbitrary fuzzy\naggregates including monotone, antimonotone, and nonmonotone fuzzy aggregates.\nWe show that the proposed fuzzy answer set semantics subsumes both the original\nfuzzy answer set semantics of DFLP and the classical answer set semantics of\nclassical disjunctive logic programs with classical aggregates, and\nconsequently subsumes the classical answer set semantics of classical\ndisjunctive logic programs. We show that the proposed fuzzy answer sets of DFLP\nwith fuzzy aggregates are minimal fuzzy models and hence incomparable, which is\nan important property for nonmonotonic fuzzy reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2013 21:47:16 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Saad", "Emad", ""]]}, {"id": "1304.2024", "submitter": "Trong Nghia Hoang", "authors": "Trong Nghia Hoang and Kian Hsiang Low", "title": "A General Framework for Interacting Bayes-Optimally with Self-Interested\n  Agents using Arbitrary Parametric Model and Model Prior", "comments": "23rd International Joint Conference on Artificial Intelligence (IJCAI\n  2013), Extended version with proofs, 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Bayesian reinforcement learning (BRL) have shown that\nBayes-optimality is theoretically achievable by modeling the environment's\nlatent dynamics using Flat-Dirichlet-Multinomial (FDM) prior. In\nself-interested multi-agent environments, the transition dynamics are mainly\ncontrolled by the other agent's stochastic behavior for which FDM's\nindependence and modeling assumptions do not hold. As a result, FDM does not\nallow the other agent's behavior to be generalized across different states nor\nspecified using prior domain knowledge. To overcome these practical limitations\nof FDM, we propose a generalization of BRL to integrate the general class of\nparametric models and model priors, thus allowing practitioners' domain\nknowledge to be exploited to produce a fine-grained and compact representation\nof the other agent's behavior. Empirical evaluation shows that our approach\noutperforms existing multi-agent reinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2013 17:00:37 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2013 11:34:51 GMT"}, {"version": "v3", "created": "Sun, 16 Mar 2014 15:10:35 GMT"}], "update_date": "2014-03-18", "authors_parsed": [["Hoang", "Trong Nghia", ""], ["Low", "Kian Hsiang", ""]]}, {"id": "1304.2339", "submitter": "John Mark Agosta", "authors": "John Mark Agosta", "title": "The structure of Bayes nets for vision recognition", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-1-7", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is part of a study whose goal is to show the effciency of using\nBayes networks to carry out model based vision calculations. [Binford et al.\n1987] Recognition proceeds by drawing up a network model from the object's\ngeometric and functional description that predicts the appearance of an object.\nThen this network is used to find the object within a photographic image. Many\nexisting and proposed techniques for vision recognition resemble the\nuncertainty calculations of a Bayes net. In contrast, though, they lack a\nderivation from first principles, and tend to rely on arbitrary parameters that\nwe hope to avoid by a network model. The connectedness of the network depends\non what independence considerations can be identified in the vision problem.\nGreater independence leads to easier calculations, at the expense of the net's\nexpressiveness. Once this trade-off is made and the structure of the network is\ndetermined, it should be possible to tailor a solution technique for it. This\npaper explores the use of a network with multiply connected paths, drawing on\nboth techniques of belief networks [Pearl 86] and influence diagrams. We then\ndemonstrate how one formulation of a multiply connected network can be solved.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:41:36 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Agosta", "John Mark", ""]]}, {"id": "1304.2340", "submitter": "Romas Aleliunas", "authors": "Romas Aleliunas", "title": "Summary of A New Normative Theory of Probabilistic Logic", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-8-14", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By probabilistic logic I mean a normative theory of belief that explains how\na body of evidence affects one's degree of belief in a possible hypothesis. A\nnew axiomatization of such a theory is presented which avoids a finite\nadditivity axiom, yet which retains many useful inference rules. Many of the\nexamples of this theory--its models do not use numerical probabilities. Put\nanother way, this article gives sharper answers to the two questions: 1.What\nkinds of sets can used as the range of a probability function? 2.Under what\nconditions is the range set of a probability function isomorphic to the set of\nreal numbers in the interval 10,1/ with the usual arithmetical operations?\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:41:42 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Aleliunas", "Romas", ""]]}, {"id": "1304.2341", "submitter": "Fahiem Bacchus", "authors": "Fahiem Bacchus", "title": "Probability Distributions Over Possible Worlds", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-15-21", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Probabilistic Logic Nilsson uses the device of a probability distribution\nover a set of possible worlds to assign probabilities to the sentences of a\nlogical language. In his paper Nilsson concentrated on inference and associated\ncomputational issues. This paper, on the other hand, examines the probabilistic\nsemantics in more detail, particularly for the case of first-order languages,\nand attempts to explain some of the features and limitations of this form of\nprobability logic. It is pointed out that the device of assigning probabilities\nto logical sentences has certain expressive limitations. In particular,\nstatistical assertions are not easily expressed by such a device. This leads to\ncertain difficulties with attempts to give probabilistic semantics to default\nreasoning using probabilities assigned to logical sentences.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:41:48 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Bacchus", "Fahiem", ""]]}, {"id": "1304.2342", "submitter": "Paul K. Black", "authors": "Paul K. Black, Kathryn Blackmond Laskey", "title": "Hierarchical Evidence and Belief Functions", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-22-29", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dempster/Shafer (D/S) theory has been advocated as a way of representing\nincompleteness of evidence in a system's knowledge base. Methods now exist for\npropagating beliefs through chains of inference. This paper discusses how rules\nwith attached beliefs, a common representation for knowledge in automated\nreasoning systems, can be transformed into the joint belief functions required\nby propagation algorithms. A rule is taken as defining a conditional belief\nfunction on the consequent given the antecedents. It is demonstrated by example\nthat different joint belief functions may be consistent with a given set of\nrules. Moreover, different representations of the same rules may yield\ndifferent beliefs on the consequent hypotheses.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:41:53 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Black", "Paul K.", ""], ["Laskey", "Kathryn Blackmond", ""]]}, {"id": "1304.2343", "submitter": "John S. Breese", "authors": "John S. Breese, Michael R. Fehling", "title": "Decision-Theoretic Control of Problem Solving: Principles and\n  Architecture", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-30-37", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach to the design of autonomous, real-time\nsystems operating in uncertain environments. We address issues of problem\nsolving and reflective control of reasoning under uncertainty in terms of two\nfundamental elements: l) a set of decision-theoretic models for selecting among\nalternative problem-solving methods and 2) a general computational architecture\nfor resource-bounded problem solving. The decisiontheoretic models provide a\nset of principles for choosing among alternative problem-solving methods based\non their relative costs and benefits, where benefits are characterized in terms\nof the value of information provided by the output of a reasoning activity. The\noutput may be an estimate of some uncertain quantity or a recommendation for\naction. The computational architecture, called Schemer-ll, provides for\ninterleaving of and communication among various problem-solving subsystems.\nThese subsystems provide alternative approaches to information gathering,\nbelief refinement, solution construction, and solution execution. In\nparticular, the architecture provides a mechanism for interrupting the\nsubsystems in response to critical events. We provide a decision theoretic\naccount for scheduling problem-solving elements and for critical-event-driven\ninterruption of activities in an architecture such as Schemer-II.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:41:57 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Breese", "John S.", ""], ["Fehling", "Michael R.", ""]]}, {"id": "1304.2344", "submitter": "M. Cecile", "authors": "M. Cecile, Mary McLeish, P. Pascoe, W. Taylor", "title": "Induction and Uncertainty Management Techniques Applied to Veterinary\n  Medical Diagnosis", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-38-48", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses a project undertaken between the Departments of\nComputing Science, Statistics, and the College of Veterinary Medicine to design\na medical diagnostic system. On-line medical data has been collected in the\nhospital database system for several years. A number of induction methods are\nbeing used to extract knowledge from the data in an attempt to improve upon\nsimple diagnostic charts used by the clinicians. They also enhance the results\nof classical statistical methods - finding many more significant variables. The\nsecond part of the paper describes an essentially Bayesian method of evidence\ncombination using fuzzy events at an initial step. Results are presented and\ncomparisons are made with other methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:42:03 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Cecile", "M.", ""], ["McLeish", "Mary", ""], ["Pascoe", "P.", ""], ["Taylor", "W.", ""]]}, {"id": "1304.2345", "submitter": "R. Martin Chavez", "authors": "R. Martin Chavez, Gregory F. Cooper", "title": "KNET: Integrating Hypermedia and Bayesian Modeling", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-49-54", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  KNET is a general-purpose shell for constructing expert systems based on\nbelief networks and decision networks. Such networks serve as graphical\nrepresentations for decision models, in which the knowledge engineer must\ndefine clearly the alternatives, states, preferences, and relationships that\nconstitute a decision basis. KNET contains a knowledge-engineering core written\nin Object Pascal and an interface that tightly integrates HyperCard, a\nhypertext authoring tool for the Apple Macintosh computer, into a novel\nexpert-system architecture. Hypertext and hypermedia have become increasingly\nimportant in the storage management, and retrieval of information. In broad\nterms, hypermedia deliver heterogeneous bits of information in dynamic,\nextensively cross-referenced packages. The resulting KNET system features a\ncoherent probabilistic scheme for managing uncertainty, an objectoriented\ngraphics editor for drawing and manipulating decision networks, and HyperCard's\npotential for quickly constructing flexible and friendly user interfaces. We\nenvision KNET as a useful prototyping tool for our ongoing research on a\nvariety of Bayesian reasoning problems, including tractable representation,\ninference, and explanation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:42:09 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Chavez", "R. Martin", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1304.2346", "submitter": "Gregory F. Cooper", "authors": "Gregory F. Cooper", "title": "A Method for Using Belief Networks as Influence Diagrams", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-55-63", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates a method for using belief-network algorithms to solve\ninfluence diagram problems. In particular, both exact and approximation\nbelief-network algorithms may be applied to solve influence-diagram problems.\nMore generally, knowing the relationship between belief-network and\ninfluence-diagram problems may be useful in the design and development of more\nefficient influence diagram algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:42:15 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Cooper", "Gregory F.", ""]]}, {"id": "1304.2347", "submitter": "Bruce D'Ambrosio", "authors": "Bruce D'Ambrosio", "title": "Process, Structure, and Modularity in Reasoning with Uncertainty", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-64-72", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational mechanisms for uncertainty management must support interactive\nand incremental problem formulation, inference, hypothesis testing, and\ndecision making. However, most current uncertainty inference systems\nconcentrate primarily on inference, and provide no support for the larger\nissues. We present a computational approach to uncertainty management which\nprovides direct support for the dynamic, incremental aspect of this task, while\nat the same time permitting direct representation of the structure of\nevidential relationships. At the same time, we show that this approach responds\nto the modularity concerns of Heckerman and Horvitz [Heck87]. This paper\nemphasizes examples of the capabilities of this approach. Another paper\n[D'Am89] details the representations and algorithms involved.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:42:20 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["D'Ambrosio", "Bruce", ""]]}, {"id": "1304.2348", "submitter": "Thomas L. Dean", "authors": "Thomas L. Dean, Keiji Kanazawa", "title": "Probabilistic Causal Reasoning", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-73-80", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the future is an important component of decision making. In most\nsituations, however, there is not enough information to make accurate\npredictions. In this paper, we develop a theory of causal reasoning for\npredictive inference under uncertainty. We emphasize a common type of\nprediction that involves reasoning about persistence: whether or not a\nproposition once made true remains true at some later time. We provide a\ndecision procedure with a polynomial-time algorithm for determining the\nprobability of the possible consequences of a set events and initial\nconditions. The integration of simple probability theory with temporal\nprojection enables us to circumvent problems that nonmonotonic temporal\nreasoning schemes have in dealing with persistence. The ideas in this paper\nhave been implemented in a prototype system that refines a database of causal\nrules in the course of applying those rules to construct and carry out plans in\na manufacturing domain.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:42:26 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Dean", "Thomas L.", ""], ["Kanazawa", "Keiji", ""]]}, {"id": "1304.2349", "submitter": "Didier Dubois", "authors": "Didier Dubois, Henri Prade", "title": "Modeling uncertain and vague knowledge in possibility and evidence\n  theories", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-81-89", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper advocates the usefulness of new theories of uncertainty for the\npurpose of modeling some facets of uncertain knowledge, especially vagueness,\nin AI. It can be viewed as a partial reply to Cheeseman's (among others)\ndefense of probability.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:42:31 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Dubois", "Didier", ""], ["Prade", "Henri", ""]]}, {"id": "1304.2350", "submitter": "Soumitra Dutta", "authors": "Soumitra Dutta", "title": "A Temporal Logic for Uncertain Events and An Outline of A Possible\n  Implementation in An Extension of PROLOG", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-90-97", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is uncertainty associated with the occurrence of many events in real\nlife. In this paper we develop a temporal logic to deal with such uncertain\nevents and outline a possible implementation in an extension of PROLOG. Events\nare represented as fuzzy sets with the membership function giving the\npossibility of occurrence of the event in a given interval of time. The\ndeveloped temporal logic is simple but powerful. It can determine effectively\nthe various temporal relations between uncertain events or their combinations.\nPROLOG provides a uniform substrate on which to effectively implement such a\ntemporal logic for uncertain events\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:42:37 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Dutta", "Soumitra", ""]]}, {"id": "1304.2351", "submitter": "Christoph F. Eick", "authors": "Christoph F. Eick", "title": "Uncertainty Management for Fuzzy Decision Support Systems", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-98-108", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new approach for uncertainty management for fuzzy, rule based decision\nsupport systems is proposed: The domain expert's knowledge is expressed by a\nset of rules that frequently refer to vague and uncertain propositions. The\ncertainty of propositions is represented using intervals [a, b] expressing that\nthe proposition's probability is at least a and at most b. Methods and\ntechniques for computing the overall certainty of fuzzy compound propositions\nthat have been defined by using logical connectives 'and', 'or' and 'not' are\nintroduced. Different inference schemas for applying fuzzy rules by using modus\nponens are discussed. Different algorithms for combining evidence that has been\nreceived from different rules for the same proposition are provided. The\nrelationship of the approach to other approaches is analyzed and its problems\nof knowledge acquisition and knowledge representation are discussed in some\ndetail. The basic concepts of a rule-based programming language called PICASSO,\nfor which the approach is a theoretical foundation, are outlined.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:42:43 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Eick", "Christoph F.", ""]]}, {"id": "1304.2352", "submitter": "Alan M. Frisch", "authors": "Alan M. Frisch, Peter Haddawy", "title": "Probability as a Modal Operator", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-109-118", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper argues for a modal view of probability. The syntax and semantics\nof one particularly strong probability logic are discussed and some examples of\nthe use of the logic are provided. We show that it is both natural and useful\nto think of probability as a modal operator. Contrary to popular belief in AI,\na probability ranging between 0 and 1 represents a continuum between\nimpossibility and necessity, not between simple falsity and truth. The present\nwork provides a clear semantics for quantification into the scope of the\nprobability operator and for higher-order probabilities. Probability logic is a\nlanguage for expressing both probabilistic and logical concepts.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:42:49 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Frisch", "Alan M.", ""], ["Haddawy", "Peter", ""]]}, {"id": "1304.2353", "submitter": "Li-Min Fu", "authors": "Li-Min Fu", "title": "Truth Maintenance Under Uncertainty", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-119-126", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of resolving errors under uncertainty in a\nrule-based system. A new approach has been developed that reformulates this\nproblem as a neural-network learning problem. The strength and the fundamental\nlimitations of this approach are explored and discussed. The main result is\nthat neural heuristics can be applied to solve some but not all problems in\nrule-based systems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:42:55 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Fu", "Li-Min", ""]]}, {"id": "1304.2354", "submitter": "Stephen I. Gallant", "authors": "Stephen I. Gallant", "title": "Bayesian Assessment of a Connectionist Model for Fault Detection", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-127-135", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A previous paper [2] showed how to generate a linear discriminant network\n(LDN) that computes likely faults for a noisy fault detection problem by using\na modification of the perceptron learning algorithm called the pocket\nalgorithm. Here we compare the performance of this connectionist model with\nperformance of the optimal Bayesian decision rule for the example that was\npreviously described. We find that for this particular problem the\nconnectionist model performs about 97% as well as the optimal Bayesian\nprocedure. We then define a more general class of noisy single-pattern boolean\n(NSB) fault detection problems where each fault corresponds to a single\n:pattern of boolean instrument readings and instruments are independently\nnoisy. This is equivalent to specifying that instrument readings are\nprobabilistic but conditionally independent given any particular fault. We\nprove:\n  1. The optimal Bayesian decision rule for every NSB fault detection problem\nis representable by an LDN containing no intermediate nodes. (This slightly\nextends a result first published by Minsky & Selfridge.) 2. Given an NSB fault\ndetection problem, then with arbitrarily high probability after sufficient\niterations the pocket algorithm will generate an LDN that computes an optimal\nBayesian decision rule for that problem. In practice we find that a reasonable\nnumber of iterations of the pocket algorithm produces a network with good, but\nnot optimal, performance.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:43:01 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Gallant", "Stephen I.", ""]]}, {"id": "1304.2355", "submitter": "Dan Geiger", "authors": "Dan Geiger, Judea Pearl", "title": "On the Logic of Causal Models", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-136-147", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the role of Directed Acyclic Graphs (DAGs) as a\nrepresentation of conditional independence relationships. We show that DAGs\noffer polynomially sound and complete inference mechanisms for inferring\nconditional independence relationships from a given causal set of such\nrelationships. As a consequence, d-separation, a graphical criterion for\nidentifying independencies in a DAG, is shown to uncover more valid\nindependencies then any other criterion. In addition, we employ the Armstrong\nproperty of conditional independence to show that the dependence relationships\ndisplayed by a DAG are inherently consistent, i.e. for every DAG D there exists\nsome probability distribution P that embodies all the conditional\nindependencies displayed in D and none other.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:43:07 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Geiger", "Dan", ""], ["Pearl", "Judea", ""]]}, {"id": "1304.2356", "submitter": "Othar Hansson", "authors": "Othar Hansson, Andy Mayer", "title": "The Optimality of Satisficing Solutions", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-148-157", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses a prevailing assumption in single-agent heuristic search\ntheory- that problem-solving algorithms should guarantee shortest-path\nsolutions, which are typically called optimal. Optimality implies a metric for\njudging solution quality, where the optimal solution is the solution with the\nhighest quality. When path-length is the metric, we will distinguish such\nsolutions as p-optimal.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:43:12 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Hansson", "Othar", ""], ["Mayer", "Andy", ""]]}, {"id": "1304.2357", "submitter": "David Heckerman", "authors": "David Heckerman", "title": "An Empirical Comparison of Three Inference Methods", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-158-169", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an empirical evaluation of three inference methods for\nuncertain reasoning is presented in the context of Pathfinder, a large expert\nsystem for the diagnosis of lymph-node pathology. The inference procedures\nevaluated are (1) Bayes' theorem, assuming evidence is conditionally\nindependent given each hypothesis; (2) odds-likelihood updating, assuming\nevidence is conditionally independent given each hypothesis and given the\nnegation of each hypothesis; and (3) a inference method related to the\nDempster-Shafer theory of belief. Both expert-rating and decision-theoretic\nmetrics are used to compare the diagnostic accuracy of the inference methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:43:18 GMT"}, {"version": "v2", "created": "Sun, 17 May 2015 00:00:15 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Heckerman", "David", ""]]}, {"id": "1304.2358", "submitter": "Daniel Hunter", "authors": "Daniel Hunter", "title": "Parallel Belief Revision", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-170-177", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a formal system of belief revision developed by Wolfgang\nSpohn and shows that this system has a parallel implementation that can be\nderived from an influence diagram in a manner similar to that in which Bayesian\nnetworks are derived. The proof rests upon completeness results for an\naxiomatization of the notion of conditional independence, with the Spohn system\nbeing used as a semantics for the relation of conditional independence.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:43:24 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Hunter", "Daniel", ""]]}, {"id": "1304.2359", "submitter": "Pramod Jain", "authors": "Pramod Jain, Alice M. Agogino", "title": "Stochastic Sensitivity Analysis Using Fuzzy Influence Diagrams", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-178-188", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The practice of stochastic sensitivity analysis described in the decision\nanalysis literature is a testimonial to the need for considering deviations\nfrom precise point estimates of uncertainty. We propose the use of Bayesian\nfuzzy probabilities within an influence diagram computational scheme for\nperforming sensitivity analysis during the solution of probabilistic inference\nand decision problems. Unlike other parametric approaches, the proposed scheme\ndoes not require resolving the problem for the varying probability point\nestimates. We claim that the solution to fuzzy influence diagrams provides as\nmuch information as the classical point estimate approach plus additional\ninformation concerning stochastic sensitivity. An example based on diagnostic\ndecision making in microcomputer assembly is used to illustrate this idea. We\nclaim that the solution to fuzzy influence diagrams provides as much\ninformation as the classical point estimate approach plus additional interval\ninformation that is useful for stochastic sensitivity analysis.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:43:30 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Jain", "Pramod", ""], ["Agogino", "Alice M.", ""]]}, {"id": "1304.2360", "submitter": "Holly B. Jimison", "authors": "Holly B. Jimison", "title": "A Representation of Uncertainty to Aid Insight into Decision Models", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-189-196", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world models can be characterized as weak, meaning that there is\nsignificant uncertainty in both the data input and inferences. This lack of\ndeterminism makes it especially difficult for users of computer decision aids\nto understand and have confidence in the models. This paper presents a\nrepresentation for uncertainty and utilities that serves as a framework for\ngraphical summary and computer-generated explanation of decision models. The\napplication described that tests the methodology is a computer decision aid\ndesigned to enhance the clinician-patient consultation process for patients\nwith angina (chest pain due to lack of blood flow to the heart muscle). The\nangina model is represented as a Bayesian decision network. Additionally, the\nprobabilities and utilities are treated as random variables with probability\ndistributions on their range of possible values. The initial distributions\nrepresent information on all patients with anginal symptoms, and the approach\nallows for rapid tailoring to more patientspecific distributions. This\nframework provides a metric for judging the importance of each variable in the\nmodel dynamically.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:43:36 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Jimison", "Holly B.", ""]]}, {"id": "1304.2361", "submitter": "Carl Kadie", "authors": "Carl Kadie", "title": "Rational Nonmonotonic Reasoning", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-197-204", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonmonotonic reasoning is a pattern of reasoning that allows an agent to make\nand retract (tentative) conclusions from inconclusive evidence. This paper\ngives a possible-worlds interpretation of the nonmonotonic reasoning problem\nbased on standard decision theory and the emerging probability logic. The\nsystem's central principle is that a tentative conclusion is a decision to make\na bet, not an assertion of fact. The system is rational, and as sound as the\nproof theory of its underlying probability log.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:43:41 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Kadie", "Carl", ""]]}, {"id": "1304.2362", "submitter": "Jayant Kalagnanam", "authors": "Jayant Kalagnanam, Max Henrion", "title": "A Comparison of Decision Analysis and Expert Rules for Sequential\n  Diagnosis", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-205-212", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has long been debate about the relative merits of decision theoretic\nmethods and heuristic rule-based approaches for reasoning under uncertainty. We\nreport an experimental comparison of the performance of the two approaches to\ntroubleshooting, specifically to test selection for fault diagnosis. We use as\nexperimental testbed the problem of diagnosing motorcycle engines. The first\napproach employs heuristic test selection rules obtained from expert mechanics.\nWe compare it with the optimal decision analytic algorithm for test selection\nwhich employs estimated component failure probabilities and test costs. The\ndecision analytic algorithm was found to reduce the expected cost (i.e. time)\nto arrive at a diagnosis by an average of 14% relative to the expert rules.\nSensitivity analysis shows the results are quite robust to inaccuracy in the\nprobability and cost estimates. This difference suggests some interesting\nimplications for knowledge acquisition.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:43:47 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Kalagnanam", "Jayant", ""], ["Henrion", "Max", ""]]}, {"id": "1304.2363", "submitter": "Suk Wah Kwok", "authors": "Suk Wah Kwok, Chris Carter", "title": "Multiple decision trees", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-213-220", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes experiments, on two domains, to investigate the effect\nof averaging over predictions of multiple decision trees, instead of using a\nsingle tree. Other authors have pointed out theoretical and commonsense reasons\nfor preferring the multiple tree approach. Ideally, we would like to consider\npredictions from all trees, weighted by their probability. However, there is a\nvast number of different trees, and it is difficult to estimate the probability\nof each tree. We sidestep the estimation problem by using a modified version of\nthe ID3 algorithm to build good trees, and average over only these trees. Our\nresults are encouraging. For each domain, we managed to produce a small number\nof good trees. We find that it is best to average across sets of trees with\ndifferent structure; this usually gives better performance than any of the\nconstituent trees, including the ID3 tree.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:43:53 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Kwok", "Suk Wah", ""], ["Carter", "Chris", ""]]}, {"id": "1304.2364", "submitter": "Henry E. Kyburg Jr.", "authors": "Henry E. Kyburg Jr", "title": "Probabilistic Inference and Probabilistic Reasoning", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-221-228", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty enters into human reasoning and inference in at least two ways.\nIt is reasonable to suppose that there will be roles for these distinct uses of\nuncertainty also in automated reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:43:58 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Kyburg", "Henry E.", "Jr"]]}, {"id": "1304.2365", "submitter": "Henry E. Kyburg Jr.", "authors": "Henry E. Kyburg Jr", "title": "Probabilistic and Non-Monotonic Inference", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-229-236", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (l) I have enough evidence to render the sentence S probable. (la) So,\nrelative to what I know, it is rational of me to believe S. (2) Now that I have\nmore evidence, S may no longer be probable. (2a) So now, relative to what I\nknow, it is not rational of me to believe S. These seem a perfectly ordinary,\ncommon sense, pair of situations. Generally and vaguely, I take them to embody\nwhat I shall call probabilistic inference. This form of inference is clearly\nnon-monotonic. Relatively few people have taken this form of inference, based\non high probability, to serve as a foundation for non-monotonic logic or for a\nlogical or defeasible inference. There are exceptions: Jane Nutter [16] thinks\nthat sometimes probability has something to do with non-monotonic reasoning.\nJudea Pearl [ 17] has recently been exploring the possibility. There are any\nnumber of people whom one might call probability enthusiasts who feel that\nprobability provides all the answers by itself, with no need of help from\nlogic. Cheeseman [1], Henrion [5] and others think it useful to look at a\ndistribution of probabilities over a whole algebra of statements, to update\nthat distribution in the light of new evidence, and to use the latest updated\ndistribution of probability over the algebra as a basis for planning and\ndecision making. A slightly weaker form of this approach is captured by Nilsson\n[15], where one assumes certain probabilities for certain statements, and\ninfers the probabilities, or constraints on the probabilities of other\nstatement. None of this corresponds to what I call probabilistic inference. All\nof the inference that is taking place, either in Bayesian updating, or in\nprobabilistic logic, is strictly deductive. Deductive inference, particularly\nthat concerned with the distribution of classical probabilities or chances, is\nof great importance. But this is not to say that there is no important role for\nwhat earlier logicians have called \"ampliative\" or \"inductive\" or \"scientific\"\ninference, in which the conclusion goes beyond the premises, asserts more than\ndo the premises. This depends on what David Israel [6] has called \"real rules\nof inference\". It is characteristic of any such logic or inference procedure\nthat it can go wrong: that statements accepted at one point may be rejected at\na later point. Research underlying the results reported here has been partially\nsupported by the Signals Warfare Center of the United States Army.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:44:04 GMT"}], "update_date": "2016-11-26", "authors_parsed": [["Kyburg", "Henry E.", "Jr"]]}, {"id": "1304.2366", "submitter": "Henry E. Kyburg Jr.", "authors": "Henry E. Kyburg Jr", "title": "Epistemological Relevance and Statistical Knowledge", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-237-244", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many years, at least since McCarthy and Hayes (1969), writers have\nlamented, and attempted to compensate for, the alleged fact that we often do\nnot have adequate statistical knowledge for governing the uncertainty of\nbelief, for making uncertain inferences, and the like. It is hardly ever\nspelled out what \"adequate statistical knowledge\" would be, if we had it, and\nhow adequate statistical knowledge could be used to control and regulate\nepistemic uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:44:10 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Kyburg", "Henry E.", "Jr"]]}, {"id": "1304.2367", "submitter": "Tod S. Levitt", "authors": "Tod S. Levitt, Thomas O. Binford, Gil J. Ettinger, Patrice Gelband", "title": "Utility-Based Control for Computer Vision", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-245-256", "categories": "cs.CV cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several key issues arise in implementing computer vision recognition of world\nobjects in terms of Bayesian networks. Computational efficiency is a driving\nforce. Perceptual networks are very deep, typically fifteen levels of\nstructure. Images are wide, e.g., an unspecified-number of edges may appear\nanywhere in an image 512 x 512 pixels or larger. For efficiency, we dynamically\ninstantiate hypotheses of observed objects. The network is not fixed, but is\ncreated incrementally at runtime. Generation of hypotheses of world objects and\nindexing of models for recognition are important, but they are not considered\nhere [4,11]. This work is aimed at near-term implementation with parallel\ncomputation in a radar surveillance system, ADRIES [5, 15], and a system for\nindustrial part recognition, SUCCESSOR [2]. For many applications, vision must\nbe faster to be practical and so efficiently controlling the machine vision\nprocess is critical. Perceptual operators may scan megapixels and may require\nminutes of computation time. It is necessary to avoid unnecessary sensor\nactions and computation. Parallel computation is available at several levels of\nprocessor capability. The potential for parallel, distributed computation for\nhigh-level vision means distributing non-homogeneous computations. This paper\naddresses the problem of task control in machine vision systems based on\nBayesian probability models. We separate control and inference to extend the\nprevious work [3] to maximize utility instead of probability. Maximizing\nutility allows adopting perceptual strategies for efficient information\ngathering with sensors and analysis of sensor data. Results of controlling\nmachine vision via utility to recognize military situations are presented in\nthis paper. Future work extends this to industrial part recognition for\nSUCCESSOR.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:44:16 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Levitt", "Tod S.", ""], ["Binford", "Thomas O.", ""], ["Ettinger", "Gil J.", ""], ["Gelband", "Patrice", ""]]}, {"id": "1304.2368", "submitter": "Ronald P. Loui", "authors": "Ronald P. Loui", "title": "Evidential Reasoning in a Network Usage Prediction Testbed", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-257-265", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on empirical work aimed at comparing evidential reasoning\ntechniques. While there is prima facie evidence for some conclusions, this i6\nwork in progress; the present focus is methodology, with the goal that\nsubsequent results be meaningful. The domain is a network of UNIX* cycle\nservers, and the task is to predict properties of the state of the network from\npartial descriptions of the state. Actual data from the network are taken and\nused for blindfold testing in a betting game that allows abstention. The focal\ntechnique has been Kyburg's method for reasoning with data of varying relevance\nto a particular query, though the aim is to be able eventually to compare\nvarious uncertainty calculi. The conclusions are not novel, but are\ninstructive. 1. All of the calculi performed better than human subjects, so\nunbiased access to sample experience is apparently of value. 2. Performance\ndepends on metric: (a) when trials are repeated, net = gains - losses favors\nmethods that place many bets, if the probability of placing a correct bet is\nsufficiently high; that is, it favors point-valued formalisms; (b) yield =\ngains/(gains + lossee) favors methods that bet only when sure to bet correctly;\nthat is, it favors interval-valued formalisms. 3. Among the calculi, there were\nno clear winners or losers. Methods are identified for eliminating the bias of\nthe net as a performance criterion and for separating the calculi effectively:\nin both cases by posting odds for the betting game in the appropriate way.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:44:22 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Loui", "Ronald P.", ""]]}, {"id": "1304.2369", "submitter": "Richard E. Neapolitan", "authors": "Richard E. Neapolitan, James Kenevan", "title": "Justifying the Principle of Interval Constraints", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-266-274", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When knowledge is obtained from a database, it is only possible to deduce\nconfidence intervals for probability values. With confidence intervals\nreplacing point values, the results in the set covering model include interval\nconstraints for the probabilities of mutually exclusive and exhaustive\nexplanations. The Principle of Interval Constraints ranks these explanations by\ndetermining the expected values of the probabilities based on distributions\ndetermined from the interval, constraints. This principle was developed using\nthe Classical Approach to probability. This paper justifies the Principle of\nInterval Constraints with a more rigorous statement of the Classical Approach\nand by defending the concept of probabilities of probabilities.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:44:27 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Neapolitan", "Richard E.", ""], ["Kenevan", "James", ""]]}, {"id": "1304.2370", "submitter": "Eric Neufeld", "authors": "Eric Neufeld, David L Poole", "title": "Probabilistic Semantics and Defaults", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-275-282", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is much interest in providing probabilistic semantics for defaults but\nmost approaches seem to suffer from one of two problems: either they require\nnumbers, a problem defaults were intended to avoid, or they generate peculiar\nside effects. Rather than provide semantics for defaults, we address the\nproblem defaults were intended to solve: that of reasoning under uncertainty\nwhere numeric probability distributions are not available. We describe a\nnon-numeric formalism called an inference graph based on standard probability\ntheory, conditional independence and sentences of favouring where a favours b -\nfavours(a, b) - p(a|b) > p(a). The formalism seems to handle the examples from\nthe nonmonotonic literature. Most importantly, the sentences of our system can\nbe verified by performing an appropriate experiment in the semantic domain.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:44:33 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Neufeld", "Eric", ""], ["Poole", "David L", ""]]}, {"id": "1304.2371", "submitter": "Michael Pittarelli", "authors": "Michael Pittarelli", "title": "Decision Making with Linear Constraints on Probabilities", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-283-290", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques for decision making with knowledge of linear constraints on\ncondition probabilities are examined. These constraints arise naturally in many\nsituations: upper and lower condition probabilities are known; an ordering\namong the probabilities is determined; marginal probabilities or bounds on such\nprobabilities are known, e.g., data are available in the form of a\nprobabilistic database (Cavallo and Pittarelli, 1987a); etc. Standard\nsituations of decision making under risk and uncertainty may also be\ncharacterized by linear constraints. Each of these types of information may be\nrepresented by a convex polyhedron of numerically determinate condition\nprobabilities. A uniform approach to decision making under risk, uncertainty,\nand partial uncertainty based on a generalized version of a criterion of\nHurwicz is proposed, Methods for processing marginal probabilities to improve\ndecision making using any of the criteria discussed are presented.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:44:38 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Pittarelli", "Michael", ""]]}, {"id": "1304.2372", "submitter": "Thomas F. Reid", "authors": "Thomas F. Reid, Gregory S. Parnell", "title": "Maintenance in Probabilistic Knowledge-Based Systems", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-291-298", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments using directed acyclical graphs (i.e., influence diagrams\nand Bayesian networks) for knowledge representation have lessened the problems\nof using probability in knowledge-based systems (KBS). Most current research\ninvolves the efficient propagation of new evidence, but little has been done\nconcerning the maintenance of domain-specific knowledge, which includes the\nprobabilistic information about the problem domain. By making use of\nconditional independencies represented in she graphs, however, probability\nassessments are required only for certain variables when the knowledge base is\nupdated. The purpose of this study was to investigate, for those variables\nwhich require probability assessments, ways to reduce the amount of new\nknowledge required from the expert when updating probabilistic information in a\nprobabilistic knowledge-based system. Three special cases (ignored outcome,\nsplit outcome, and assumed constraint outcome) were identified under which many\nof the original probabilities (those already in the knowledge-base) do not need\nto be reassessed when maintenance is required.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:44:46 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Reid", "Thomas F.", ""], ["Parnell", "Gregory S.", ""]]}, {"id": "1304.2373", "submitter": "Ross D. Shachter", "authors": "Ross D. Shachter", "title": "A Linear Approximation Method for Probabilistic Inference", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-299-306", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approximation method is presented for probabilistic inference with\ncontinuous random variables. These problems can arise in many practical\nproblems, in particular where there are \"second order\" probabilities. The\napproximation, based on the Gaussian influence diagram, iterates over linear\napproximations to the inference problem.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:44:52 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Shachter", "Ross D.", ""]]}, {"id": "1304.2374", "submitter": "Prakash P. Shenoy", "authors": "Prakash P. Shenoy, Glenn Shafer", "title": "An Axiomatic Framework for Bayesian and Belief-function Propagation", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-307-314", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe an abstract framework and axioms under which exact\nlocal computation of marginals is possible. The primitive objects of the\nframework are variables and valuations. The primitive operators of the\nframework are combination and marginalization. These operate on valuations. We\nstate three axioms for these operators and we derive the possibility of local\ncomputation from the axioms. Next, we describe a propagation scheme for\ncomputing marginals of a valuation when we have a factorization of the\nvaluation on a hypertree. Finally we show how the problem of computing\nmarginals of joint probability distributions and joint belief functions fits\nthe general framework.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:44:57 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Shenoy", "Prakash P.", ""], ["Shafer", "Glenn", ""]]}, {"id": "1304.2375", "submitter": "Wolfgang Spohn", "authors": "Wolfgang Spohn", "title": "A General Non-Probabilistic Theory of Inductive Reasoning", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-315-322", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probability theory, epistemically interpreted, provides an excellent, if not\nthe best available account of inductive reasoning. This is so because there are\ngeneral and definite rules for the change of subjective probabilities through\ninformation or experience; induction and belief change are one and same topic,\nafter all. The most basic of these rules is simply to conditionalize with\nrespect to the information received; and there are similar and more general\nrules. 1 Hence, a fundamental reason for the epistemological success of\nprobability theory is that there at all exists a well-behaved concept of\nconditional probability. Still, people have, and have reasons for, various\nconcerns over probability theory. One of these is my starting point:\nIntuitively, we have the notion of plain belief; we believe propositions2 to be\ntrue (or to be false or neither). Probability theory, however, offers no formal\ncounterpart to this notion. Believing A is not the same as having probability 1\nfor A, because probability 1 is incorrigible3; but plain belief is clearly\ncorrigible. And believing A is not the same as giving A a probability larger\nthan some 1 - c, because believing A and believing B is usually taken to be\nequivalent to believing A & B.4 Thus, it seems that the formal representation\nof plain belief has to take a non-probabilistic route. Indeed, representing\nplain belief seems easy enough: simply represent an epistemic state by the set\nof all propositions believed true in it or, since I make the common assumption\nthat plain belief is deductively closed, by the conjunction of all propositions\nbelieved true in it. But this does not yet provide a theory of induction, i.e.\nan answer to the question how epistemic states so represented are changed\ntbrough information or experience. There is a convincing partial answer: if the\nnew information is compatible with the old epistemic state, then the new\nepistemic state is simply represented by the conjunction of the new information\nand the old beliefs. This answer is partial because it does not cover the quite\ncommon case where the new information is incompatible with the old beliefs. It\nis, however, important to complete the answer and to cover this case, too;\notherwise, we would not represent plain belief as conigible. The crucial\nproblem is that there is no good completion. When epistemic states are\nrepresented simply by the conjunction of all propositions believed true in it,\nthe answer cannot be completed; and though there is a lot of fruitful work, no\nother representation of epistemic states has been proposed, as far as I know,\nwhich provides a complete solution to this problem. In this paper, I want to\nsuggest such a solution. In [4], I have more fully argued that this is the only\nsolution, if certain plausible desiderata are to be satisfied. Here, in section\n2, I will be content with formally defining and intuitively explaining my\nproposal. I will compare my proposal with probability theory in section 3. It\nwill turn out that the theory I am proposing is structurally homomorphic to\nprobability theory in important respects and that it is thus equally easily\nimplementable, but moreover computationally simpler. Section 4 contains a very\nbrief comparison with various kinds of logics, in particular conditional logic,\nwith Shackle's functions of potential surprise and related theories, and with\nthe Dempster - Shafer theory of belief functions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:45:03 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Spohn", "Wolfgang", ""]]}, {"id": "1304.2376", "submitter": "Spencer Star", "authors": "Spencer Star", "title": "Generating Decision Structures and Causal Explanations for Decision\n  Making", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-323-334", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines two related problems that are central to developing an\nautonomous decision-making agent, such as a robot. Both problems require\ngenerating structured representafions from a database of unstructured\ndeclarative knowledge that includes many facts and rules that are irrelevant in\nthe problem context. The first problem is how to generate a well structured\ndecision problem from such a database. The second problem is how to generate,\nfrom the same database, a well-structured explanation of why some possible\nworld occurred. In this paper it is shown that the problem of generating the\nappropriate decision structure or explanation is intractable without\nintroducing further constraints on the knowledge in the database. The paper\nproposes that the problem search space can be constrained by adding knowledge\nto the database about causal relafions between events. In order to determine\nthe causal knowledge that would be most useful, causal theories for\ndeterministic and indeterministic universes are proposed. A program that uses\nsome of these causal constraints has been used to generate explanations about\nfaulty plans. The program shows the expected increase in efficiency as the\ncausal constraints are introduced.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:45:09 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Star", "Spencer", ""]]}, {"id": "1304.2377", "submitter": "Jaap Suermondt", "authors": "Jaap Suermondt, Gregory F. Cooper", "title": "Updating Probabilities in Multiply-Connected Belief Networks", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-335-343", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on probability updates in multiply-connected belief\nnetworks. Pearl has designed the method of conditioning, which enables us to\napply his algorithm for belief updates in singly-connected networks to\nmultiply-connected belief networks by selecting a loop-cutset for the network\nand instantiating these loop-cutset nodes. We discuss conditions that need to\nbe satisfied by the selected nodes. We present a heuristic algorithm for\nfinding a loop-cutset that satisfies these conditions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:45:15 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Suermondt", "Jaap", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1304.2378", "submitter": "Bjornar Tessem", "authors": "Bjornar Tessem, Lars Johan Ersland", "title": "Handling uncertainty in a system for text-symbol context analysis", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-344-351", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In pattern analysis, information regarding an object can often be drawn from\nits surroundings. This paper presents a method for handling uncertainty when\nusing context of symbols and texts for analyzing technical drawings. The method\nis based on Dempster-Shafer theory and possibility theory.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:45:21 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Tessem", "Bjornar", ""], ["Ersland", "Lars Johan", ""]]}, {"id": "1304.2379", "submitter": "Tom S. Verma", "authors": "Tom S. Verma, Judea Pearl", "title": "Causal Networks: Semantics and Expressiveness", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-352-359", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependency knowledge of the form \"x is independent of y once z is known\"\ninvariably obeys the four graphoid axioms, examples include probabilistic and\ndatabase dependencies. Often, such knowledge can be represented efficiently\nwith graphical structures such as undirected graphs and directed acyclic graphs\n(DAGs). In this paper we show that the graphical criterion called d-separation\nis a sound rule for reading independencies from any DAG based on a causal input\nlist drawn from a graphoid. The rule may be extended to cover DAGs that\nrepresent functional dependencies as well as conditional dependencies.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:45:27 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Verma", "Tom S.", ""], ["Pearl", "Judea", ""]]}, {"id": "1304.2380", "submitter": "Wilson X. Wen", "authors": "Wilson X. Wen", "title": "MCE Reasoning in Recursive Causal Networks", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-360-367", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A probabilistic method of reasoning under uncertainty is proposed based on\nthe principle of Minimum Cross Entropy (MCE) and concept of Recursive Causal\nModel (RCM). The dependency and correlations among the variables are described\nin a special language BNDL (Belief Networks Description Language). Beliefs are\npropagated among the clauses of the BNDL programs representing the underlying\nprobabilistic distributions. BNDL interpreters in both Prolog and C has been\ndeveloped and the performance of the method is compared with those of the\nothers.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:45:33 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Wen", "Wilson X.", ""]]}, {"id": "1304.2381", "submitter": "Ronald R. Yager", "authors": "Ronald R. Yager", "title": "Nonmonotonic Reasoning via Possibility Theory", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-368-373", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the operation of possibility qualification and show how. this\nmodal-like operator can be used to represent \"typical\" or default knowledge in\na theory of nonmonotonic reasoning. We investigate the representational power\nof this approach by looking at a number of prototypical problems from the\nnonmonotonic reasoning literature. In particular we look at the so called Yale\nshooting problem and its relation to priority in default reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:45:38 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Yager", "Ronald R.", ""]]}, {"id": "1304.2382", "submitter": "Alexander Yeh", "authors": "Alexander Yeh", "title": "Predicting the Likely Behaviors of Continuous Nonlinear Systems in\n  Equilibrium", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-374-381", "categories": "cs.SY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a method for predicting the likely behaviors of\ncontinuous nonlinear systems in equilibrium in which the input values can vary.\nThe method uses a parameterized equation model and a lower bound on the input\njoint density to bound the likelihood that some behavior will occur, such as a\nstate variable being inside a given numeric range. Using a bound on the density\ninstead of the density itself is desirable because often the input density's\nparameters and shape are not exactly known. The new method is called SAB after\nits basic operations: split the input value space into smaller regions, and\nthen bound those regions' possible behaviors and the probability of being in\nthem. SAB finds rough bounds at first, and then refines them as more time is\ngiven. In contrast to other researchers' methods, SAB can (1) find all the\npossible system behaviors, and indicate how likely they are, (2) does not\napproximate the distribution of possible outcomes without some measure of the\nerror magnitude, (3) does not use discretized variable values, which limit the\nevents one can find probability bounds for, (4) can handle density bounds, and\n(5) can handle such criteria as two state variables both being inside a numeric\nrange.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:45:44 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Yeh", "Alexander", ""]]}, {"id": "1304.2383", "submitter": "John Yen", "authors": "John Yen", "title": "Generalizing the Dempster-Shafer Theory to Fuzzy Sets", "comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1988-PG-382-391", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the desire to apply the Dempster-Shafer theory to complex real world\nproblems where the evidential strength is often imprecise and vague, several\nattempts have been made to generalize the theory. However, the important\nconcept in the D-S theory that the belief and plausibility functions are lower\nand upper probabilities is no longer preserved in these generalizations. In\nthis paper, we describe a generalized theory of evidence where the degree of\nbelief in a fuzzy set is obtained by minimizing the probability of the fuzzy\nset under the constraints imposed by a basic probability assignment. To\nformulate the probabilistic constraint of a fuzzy focal element, we decompose\nit into a set of consonant non-fuzzy focal elements. By generalizing the\ncompatibility relation to a possibility theory, we are able to justify our\ngeneralization to Dempster's rule based on possibility distribution. Our\ngeneralization not only extends the application of the D-S theory but also\nillustrates a way that probability theory and fuzzy set theory can be combined\nto deal with different kinds of uncertain information in AI systems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:45:50 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Yen", "John", ""]]}, {"id": "1304.2384", "submitter": "Emad Saad", "authors": "Emad Saad", "title": "Logical Fuzzy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We present a logical framework to represent and reason about fuzzy\noptimization problems based on fuzzy answer set optimization programming. This\nis accomplished by allowing fuzzy optimization aggregates, e.g., minimum and\nmaximum in the language of fuzzy answer set optimization programming to allow\nminimization or maximization of some desired criteria under fuzzy environments.\nWe show the application of the proposed logical fuzzy optimization framework\nunder the fuzzy answer set optimization programming to the fuzzy water\nallocation optimization problem.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2013 21:57:03 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Saad", "Emad", ""]]}, {"id": "1304.2418", "submitter": "Minyar Sassi", "authors": "Hanene Rezgui and Minyar Sassi-Hidri", "title": "Mod\\`ele flou d'expression des pr\\'ef\\'erences bas\\'e sur les CP-Nets", "comments": "2 pages, EGC 2013", "journal-ref": "13\\`eme Conf\\'erence Francophone sur l'Extraction et la Gestion\n  des Connaissances (EGC), pp. 27-28, 2013", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article addresses the problem of expressing preferences in flexible\nqueries while basing on a combination of the fuzzy logic theory and Conditional\nPreference Networks or CP-Nets.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2013 16:29:20 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Rezgui", "Hanene", ""], ["Sassi-Hidri", "Minyar", ""]]}, {"id": "1304.2538", "submitter": "M.M.A. Hashem", "authors": "K.M. Motahar Hossain, Zahir Raihan and M.M.A. Hashem", "title": "On Appropriate Selection of Fuzzy Aggregation Operators in Medical\n  Decision Support System", "comments": null, "journal-ref": "Procs. of the 8th International Conference on Computer &\n  Information Technology (ICCIT 2005), pp. 563-568, Dhaka, Bangladesh, December\n  28-30, (2005)", "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Decision Support System (DSS) contains more than one antecedent and the\ndegrees of strength of the antecedents need to be combined to determine the\noverall strength of the rule consequent. The membership values of the\nlinguistic variables in Fuzzy have to be combined using an aggregation\noperator. But it is not feasible to predefine the form of aggregation operators\nin decision making. Instead, each rule should be found based on the feeling of\nthe experts and on their actual decision pattern over the set of typical\nexamples. Thus this work illustrates how the choice of aggregation operators is\nintended to mimic human decision making and can be selected and adjusted to fit\nempirical data, a series of test cases. Both parametrized and nonparametrized\naggregation operators are adapted to fit empirical data. Moreover, they\nprovided compensatory properties and, therefore, seemed to produce a better\ndecision support system. To solve the problem, a threshold point from the\noutput of the aggregation operators is chosen as the separation point between\ntwo classes. The best achieved accuracy is chosen as the appropriate\naggregation operator. Thus a medical decision can be generated which is very\nclose to a practitioner's guideline.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2013 11:25:13 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Hossain", "K. M. Motahar", ""], ["Raihan", "Zahir", ""], ["Hashem", "M. M. A.", ""]]}, {"id": "1304.2694", "submitter": "Mathias Niepert", "authors": "Mathias Niepert", "title": "Symmetry-Aware Marginal Density Estimation", "comments": "To appear in proceedings of AAAI 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Rao-Blackwell theorem is utilized to analyze and improve the scalability\nof inference in large probabilistic models that exhibit symmetries. A novel\nmarginal density estimator is introduced and shown both analytically and\nempirically to outperform standard estimators by several orders of magnitude.\nThe developed theory and algorithms apply to a broad class of probabilistic\nmodels including statistical relational models considered not susceptible to\nlifted probabilistic inference.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2013 18:47:47 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Niepert", "Mathias", ""]]}, {"id": "1304.2711", "submitter": "Paul K. Black", "authors": "Paul K. Black", "title": "Is Shafer General Bayes?", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-2-9", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the relationship between Shafer's belief functions and\nconvex sets of probability distributions. Kyburg's (1986) result showed that\nbelief function models form a subset of the class of closed convex probability\ndistributions. This paper emphasizes the importance of Kyburg's result by\nlooking at simple examples involving Bernoulli trials. Furthermore, it is shown\nthat many convex sets of probability distributions generate the same belief\nfunction in the sense that they support the same lower and upper values. This\nhas implications for a decision theoretic extension. Dempster's rule of\ncombination is also compared with Bayes' rule of conditioning.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:46:18 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Black", "Paul K.", ""]]}, {"id": "1304.2712", "submitter": "Paul Cohen", "authors": "Paul Cohen, Glenn Shafer, Prakash P. Shenoy", "title": "Modifiable Combining Functions", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-10-21", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modifiable combining functions are a synthesis of two common approaches to\ncombining evidence. They offer many of the advantages of these approaches and\navoid some disadvantages. Because they facilitate the acquisition,\nrepresentation, explanation, and modification of knowledge about combinations\nof evidence, they are proposed as a tool for knowledge engineers who build\nsystems that reason under uncertainty, not as a normative theory of evidence.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:46:23 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Cohen", "Paul", ""], ["Shafer", "Glenn", ""], ["Shenoy", "Prakash P.", ""]]}, {"id": "1304.2713", "submitter": "Daniel Hunter", "authors": "Daniel Hunter", "title": "Dempster-Shafer vs. Probabilistic Logic", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-22-29", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of evidence in Dempster-Shafer theory is compared with the\ncombination of evidence in probabilistic logic. Sufficient conditions are\nstated for these two methods to agree. It is then shown that these conditions\nare minimal in the sense that disagreement can occur when any one of them is\nremoved. An example is given in which the traditional assumption of conditional\nindependence of evidence on hypotheses holds and a uniform prior is assumed,\nbut probabilistic logic and Dempster's rule give radically different results\nfor the combination of two evidence events.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:46:27 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Hunter", "Daniel", ""]]}, {"id": "1304.2714", "submitter": "Henry E. Kyburg Jr.", "authors": "Henry E. Kyburg Jr", "title": "Higher Order Probabilities", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-30-38", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of writers have supposed that for the full specification of belief,\nhigher order probabilities are required. Some have even supposed that there may\nbe an unending sequence of higher order probabilities of probabilities of\nprobabilities.... In the present paper we show that higher order probabilities\ncan always be replaced by the marginal distributions of joint probability\ndistributions. We consider both the case in which higher order probabilities\nare of the same sort as lower order probabilities and that in which higher\norder probabilities are distinct in character, as when lower order\nprobabilities are construed as frequencies and higher order probabilities are\nconstrued as subjective degrees of belief. In neither case do higher order\nprobabilities appear to offer any advantages, either conceptually or\ncomputationally.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:46:32 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Kyburg", "Henry E.", "Jr"]]}, {"id": "1304.2715", "submitter": "Kathryn Blackmond Laskey", "authors": "Kathryn Blackmond Laskey", "title": "Belief in Belief Functions: An Examination of Shafer's Canonical\n  Examples", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-39-46", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the canonical examples underlying Shafer-Dempster theory, beliefs over the\nhypotheses of interest are derived from a probability model for a set of\nauxiliary hypotheses. Beliefs are derived via a compatibility relation\nconnecting the auxiliary hypotheses to subsets of the primary hypotheses. A\nbelief function differs from a Bayesian probability model in that one does not\ncondition on those parts of the evidence for which no probabilities are\nspecified. The significance of this difference in conditioning assumptions is\nillustrated with two examples giving rise to identical belief functions but\ndifferent Bayesian probability distributions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:46:37 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Laskey", "Kathryn Blackmond", ""]]}, {"id": "1304.2716", "submitter": "Judea Pearl", "authors": "Judea Pearl", "title": "Do We Need Higher-Order Probabilities and, If So, What Do They Mean?", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-47-60", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The apparent failure of individual probabilistic expressions to distinguish\nuncertainty about truths from uncertainty about probabilistic assessments have\nprompted researchers to seek formalisms where the two types of uncertainties\nare given notational distinction. This paper demonstrates that the desired\ndistinction is already a built-in feature of classical probabilistic models,\nthus, specialized notations are unnecessary.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:46:42 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Pearl", "Judea", ""]]}, {"id": "1304.2717", "submitter": "Matthew Self", "authors": "Matthew Self, Peter Cheeseman", "title": "Bayesian Prediction for Artificial Intelligence", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-61-69", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that the common method used for making predictions under\nuncertainty in A1 and science is in error. This method is to use currently\navailable data to select the best model from a given class of models-this\nprocess is called abduction-and then to use this model to make predictions\nabout future data. The correct method requires averaging over all the models to\nmake a prediction-we call this method transduction. Using transduction, an AI\nsystem will not give misleading results when basing predictions on small\namounts of data, when no model is clearly best. For common classes of models we\nshow that the optimal solution can be given in closed form.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:46:47 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Self", "Matthew", ""], ["Cheeseman", "Peter", ""]]}, {"id": "1304.2718", "submitter": "John Yen", "authors": "John Yen", "title": "Can Evidence Be Combined in the Dempster-Shafer Theory", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-70-76", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dempster's rule of combination has been the most controversial part of the\nDempster-Shafer (D-S) theory. In particular, Zadeh has reached a conjecture on\nthe noncombinability of evidence from a relational model of the D-S theory. In\nthis paper, we will describe another relational model where D-S masses are\nrepresented as conditional granular distributions. By comparing it with Zadeh's\nrelational model, we will show how Zadeh's conjecture on combinability does not\naffect the applicability of Dempster's rule in our model.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:46:52 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Yen", "John", ""]]}, {"id": "1304.2719", "submitter": "John B. Bacon", "authors": "John B. Bacon", "title": "An Interesting Uncertainty-Based Combinatoric Problem in Spare Parts\n  Forecasting: The FRED System", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-78-85", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The domain of spare parts forecasting is examined, and is found to present\nunique uncertainty based problems in the architectural design of a\nknowledge-based system. A mixture of different uncertainty paradigms is\nrequired for the solution, with an intriguing combinatoric problem arising from\nan uncertain choice of inference engines. Thus, uncertainty in the system is\nmanifested in two different meta-levels. The different uncertainty paradigms\nand meta-levels must be integrated into a functioning whole. FRED is an example\nof a difficult real-world domain to which no existing uncertainty approach is\ncompletely appropriate. This paper discusses the architecture of FRED,\nhighlighting: the points of uncertainty and other interesting features of the\ndomain, the specific implications of those features on the system design\n(including the combinatoric explosions), their current implementation & future\nplans,and other problems and issues with the architecture.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:46:57 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Bacon", "John B.", ""]]}, {"id": "1304.2720", "submitter": "Thomas O. Binford", "authors": "Thomas O. Binford, Tod S. Levitt, Wallace B. Mann", "title": "Bayesian Inference in Model-Based Machine Vision", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-86-97", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a preliminary version of visual interpretation integrating multiple\nsensors in SUCCESSOR, an intelligent, model-based vision system. We pursue a\nthorough integration of hierarchical Bayesian inference with comprehensive\nphysical representation of objects and their relations in a system for\nreasoning with geometry, surface materials and sensor models in machine vision.\nBayesian inference provides a framework for accruing_ probabilities to rank\norder hypotheses.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:47:03 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Binford", "Thomas O.", ""], ["Levitt", "Tod S.", ""], ["Mann", "Wallace B.", ""]]}, {"id": "1304.2721", "submitter": "Gautam Biswas", "authors": "Gautam Biswas, Teywansh S. Anand", "title": "Using the Dempster-Shafer Scheme in a Diagnostic Expert System Shell", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-98-105", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses an expert system shell that integrates rule-based\nreasoning and the Dempster-Shafer evidence combination scheme. Domain knowledge\nis stored as rules with associated belief functions. The reasoning component\nuses a combination of forward and backward inferencing mechanisms to allow\ninteraction with users in a mixed-initiative format.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:47:07 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Biswas", "Gautam", ""], ["Anand", "Teywansh S.", ""]]}, {"id": "1304.2722", "submitter": "Homer L. Chin", "authors": "Homer L. Chin, Gregory F. Cooper", "title": "Stochastic Simulation of Bayesian Belief Networks", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-106-113", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines Bayesian belief network inference using simulation as a\nmethod for computing the posterior probabilities of network variables.\nSpecifically, it examines the use of a method described by Henrion, called\nlogic sampling, and a method described by Pearl, called stochastic simulation.\nWe first review the conditions under which logic sampling is computationally\ninfeasible. Such cases motivated the development of the Pearl's stochastic\nsimulation algorithm. We have found that this stochastic simulation algorithm,\nwhen applied to certain networks, leads to much slower than expected\nconvergence to the true posterior probabilities. This behavior is a result of\nthe tendency for local areas in the network to become fixed through many\nsimulation cycles. The time required to obtain significant convergence can be\nmade arbitrarily long by strengthening the probabilistic dependency between\nnodes. We propose the use of several forms of graph modification, such as graph\npruning, arc reversal, and node reduction, in order to convert some networks\ninto formats that are computationally more efficient for simulation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:47:13 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Chin", "Homer L.", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1304.2723", "submitter": "Steve Hanks", "authors": "Steve Hanks", "title": "Temporal Reasoning About Uncertain Worlds", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-114-122", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a program that manages a database of temporally scoped beliefs.\nThe basic functionality of the system includes maintaining a network of\nconstraints among time points, supporting a variety of fetches, mediating the\napplication of causal rules, monitoring intervals of time for the addition of\nnew facts, and managing data dependencies that keep the database consistent. At\nthis level the system operates independent of any measure of belief or belief\ncalculus. We provide an example of how an application program mi9ght use this\nfunctionality to implement a belief calculus.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:47:17 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Hanks", "Steve", ""]]}, {"id": "1304.2724", "submitter": "David Heckerman", "authors": "David Heckerman, Holly B. Jimison", "title": "A Perspective on Confidence and Its Use in Focusing Attention During\n  Knowledge Acquisition", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-123-131", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a representation of partial confidence in belief and preference\nthat is consistent with the tenets of decision-theory. The fundamental insight\nunderlying the representation is that if a person is not completely confident\nin a probability or utility assessment, additional modeling of the assessment\nmay improve decisions to which it is relevant. We show how a traditional\ndecision-analytic approach can be used to balance the benefits of additional\nmodeling with associated costs. The approach can be used during knowledge\nacquisition to focus the attention of a knowledge engineer or expert on parts\nof a decision model that deserve additional refinement.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:47:22 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Heckerman", "David", ""], ["Jimison", "Holly B.", ""]]}, {"id": "1304.2725", "submitter": "Max Henrion", "authors": "Max Henrion", "title": "Practical Issues in Constructing a Bayes' Belief Network", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-132-139", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayes belief networks and influence diagrams are tools for constructing\ncoherent probabilistic representations of uncertain knowledge. The process of\nconstructing such a network to represent an expert's knowledge is used to\nillustrate a variety of techniques which can facilitate the process of\nstructuring and quantifying uncertain relationships. These include some\ngeneralizations of the \"noisy OR gate\" concept. Sensitivity analysis of generic\nelements of Bayes' networks provides insight into when rough probability\nassessments are sufficient and when greater precision may be important.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:47:27 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Henrion", "Max", ""]]}, {"id": "1304.2726", "submitter": "Michael C. Higgins", "authors": "Michael C. Higgins", "title": "NAIVE: A Method for Representing Uncertainty and Temporal Relationships\n  in an Automated Reasoner", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-140-147", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes NAIVE, a low-level knowledge representation language and\ninferencing process. NAIVE has been designed for reasoning about\nnondeterministic dynamic systems like those found in medicine. Knowledge is\nrepresented in a graph structure consisting of nodes, which correspond to the\nvariables describing the system of interest, and arcs, which correspond to the\nprocedures used to infer the value of a variable from the values of other\nvariables. The value of a variable can be determined at an instant in time,\nover a time interval or for a series of times. Information about the value of a\nvariable is expressed as a probability density function which quantifies the\nlikelihood of each possible value. The inferencing process uses these\nprobability density functions to propagate uncertainty. NAIVE has been used to\ndevelop medical knowledge bases including over 100 variables.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:47:31 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Higgins", "Michael C.", ""]]}, {"id": "1304.2727", "submitter": "Henry E. Kyburg Jr.", "authors": "Henry E. Kyburg Jr", "title": "Objective Probability", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-148-155", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distinction is sometimes made between \"statistical\" and \"subjective\"\nprobabilities. This is based on a distinction between \"unique\" events and\n\"repeatable\" events. We argue that this distinction is untenable, since all\nevents are \"unique\" and all events belong to \"kinds\", and offer a conception of\nprobability for A1 in which (1) all probabilities are based on -- possibly\nvague -- statistical knowledge, and (2) every statement in the language has a\nprobability. This conception of probability can be applied to very rich\nlanguages.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:47:36 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Kyburg", "Henry E.", "Jr"]]}, {"id": "1304.2728", "submitter": "Silvio Ursic", "authors": "Silvio Ursic", "title": "Coefficients of Relations for Probabilistic Reasoning", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-156-162", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Definitions and notations with historical references are given for some\nnumerical coefficients commonly used to quantify relations among collections of\nobjects for the purpose of expressing approximate knowledge and probabilistic\nreasoning.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:47:41 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Ursic", "Silvio", ""]]}, {"id": "1304.2729", "submitter": "Ben P. Wise", "authors": "Ben P. Wise", "title": "Satisfaction of Assumptions is a Weak Predictor of Performance", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-163-169", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates a methodology for examining the accuracy of uncertain\ninference systems (UIS), after their parameters have been optimized, and does\nso for several common UIS's. This methodology may be used to test the accuracy\nwhen either the prior assumptions or updating formulae are not exactly\nsatisfied. Surprisingly, these UIS's were revealed to be no more accurate on\nthe average than a simple linear regression. Moreover, even on prior\ndistributions which were deliberately biased so as give very good accuracy,\nthey were less accurate than the simple probabilistic model which assumes\nmarginal independence between inputs. This demonstrates that the importance of\nupdating formulae can outweigh that of prior assumptions. Thus, when UIS's are\njudged by their final accuracy after optimization, we get completely different\nresults than when they are judged by whether or not their prior assumptions are\nperfectly satisfied.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:47:45 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Wise", "Ben P.", ""]]}, {"id": "1304.2730", "submitter": "Lei Xu", "authors": "Lei Xu, Judea Pearl", "title": "Structuring Causal Tree Models with Continuous Variables", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-170-179", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of invoking auxiliary, unobservable\nvariables to facilitate the structuring of causal tree models for a given set\nof continuous variables. Paralleling the treatment of bi-valued variables in\n[Pearl 1986], we show that if a collection of coupled variables are governed by\na joint normal distribution and a tree-structured representation exists, then\nboth the topology and all internal relationships of the tree can be uncovered\nby observing pairwise dependencies among the observed variables (i.e., the\nleaves of the tree). Furthermore, the conditions for normally distributed\nvariables are less restrictive than those governing bi-valued variables. The\nresult extends the applications of causal tree models which were found useful\nin evidential reasoning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:47:50 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Xu", "Lei", ""], ["Pearl", "Judea", ""]]}, {"id": "1304.2731", "submitter": "John Yen", "authors": "John Yen", "title": "Implementing Evidential Reasoning in Expert Systems", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-180-188", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dempster-Shafer theory has been extended recently for its application to\nexpert systems. However, implementing the extended D-S reasoning model in\nrule-based systems greatly complicates the task of generating informative\nexplanations. By implementing GERTIS, a prototype system for diagnosing\nrheumatoid arthritis, we show that two kinds of knowledge are essential for\nexplanation generation: (l) taxonomic class relationships between hypotheses\nand (2) pointers to the rules that significantly contribute to belief in the\nhypothesis. As a result, the knowledge represented in GERTIS is richer and more\ncomplex than that of conventional rule-based systems. GERTIS not only\ndemonstrates the feasibility of rule-based evidential-reasoning systems, but\nalso suggests ways to generate better explanations, and to explicitly represent\nvarious useful relationships among hypotheses and rules.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:47:55 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Yen", "John", ""]]}, {"id": "1304.2732", "submitter": "Wray L. Buntine", "authors": "Wray L. Buntine", "title": "Decision Tree Induction Systems: A Bayesian Analysis", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-190-197", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision tree induction systems are being used for knowledge acquisition in\nnoisy domains. This paper develops a subjective Bayesian interpretation of the\ntask tackled by these systems and the heuristic methods they use. It is argued\nthat decision tree systems implicitly incorporate a prior belief that the\nsimpler (in terms of decision tree complexity) of two hypotheses be preferred,\nall else being equal, and that they perform a greedy search of the space of\ndecision rules to find one in which there is strong posterior belief. A number\nof improvements to these systems are then suggested.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:48:00 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Buntine", "Wray L.", ""]]}, {"id": "1304.2733", "submitter": "Richard A. Caruana", "authors": "Richard A. Caruana", "title": "The Automatic Training of Rule Bases that Use Numerical Uncertainty\n  Representations", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-198-204", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of numerical uncertainty representations allows better modeling of\nsome aspects of human evidential reasoning. It also makes knowledge acquisition\nand system development, test, and modification more difficult. We propose that\nwhere possible, the assignment and/or refinement of rule weights should be\nperformed automatically. We present one approach to performing this training -\nnumerical optimization - and report on the results of some preliminary tests in\ntraining rule bases. We also show that truth maintenance can be used to make\ntraining more efficient and ask some epistemological questions raised by\ntraining rule weights.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:48:04 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Caruana", "Richard A.", ""]]}, {"id": "1304.2734", "submitter": "Norman C. Dalkey", "authors": "Norman C. Dalkey", "title": "The Inductive Logic of Information Systems", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-205-211", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An inductive logic can be formulated in which the elements are not\npropositions or probability distributions, but information systems. The logic\nis complete for information systems with binary hypotheses, i.e., it applies to\nall such systems. It is not complete for information systems with more than two\nhypotheses, but applies to a subset of such systems. The logic is inductive in\nthat conclusions are more informative than premises. Inferences using the\nformalism have a strong justification in terms of the expected value of the\nderived information system.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:48:09 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Dalkey", "Norman C.", ""]]}, {"id": "1304.2735", "submitter": "Stephen I. Gallant", "authors": "Stephen I. Gallant", "title": "Automated Generation of Connectionist Expert Systems for Problems\n  Involving Noise and Redundancy", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-212-221", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When creating an expert system, the most difficult and expensive task is\nconstructing a knowledge base. This is particularly true if the problem\ninvolves noisy data and redundant measurements. This paper shows how to modify\nthe MACIE process for generating connectionist expert systems from training\nexamples so that it can accommodate noisy and redundant data. The basic idea is\nto dynamically generate appropriate training examples by constructing both a\n'deep' model and a noise model for the underlying problem. The use of\nwinner-take-all groups of variables is also discussed. These techniques are\nillustrated with a small example that would be very difficult for standard\nexpert system approaches.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:48:14 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Gallant", "Stephen I.", ""]]}, {"id": "1304.2736", "submitter": "George Rebane", "authors": "George Rebane, Judea Pearl", "title": "The Recovery of Causal Poly-Trees from Statistical Data", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-222-228", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poly-trees are singly connected causal networks in which variables may arise\nfrom multiple causes. This paper develops a method of recovering ply-trees from\nempirically measured probability distributions of pairs of variables. The\nmethod guarantees that, if the measured distributions are generated by a causal\nprocess structured as a ply-tree then the topological structure of such tree\ncan be recovered precisely and, in addition, the causal directionality of the\nbranches can be determined up to the maximum extent possible. The method also\npinpoints the minimum (if any) external semantics required to determine the\ncausal relationships among the variables considered.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:48:18 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Rebane", "George", ""], ["Pearl", "Judea", ""]]}, {"id": "1304.2737", "submitter": "Ross D. Shachter", "authors": "Ross D. Shachter, David M. Eddy, Vic Hasselblad, Robert Wolpert", "title": "A Heuristic Bayesian Approach to Knowledge Acquisition: Application to\n  Analysis of Tissue-Type Plasminogen Activator", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-229-236", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a heuristic Bayesian method for computing probability\ndistributions from experimental data, based upon the multivariate normal form\nof the influence diagram. An example illustrates its use in medical technology\nassessment. This approach facilitates the integration of results from different\nstudies, and permits a medical expert to make proper assessments without\nconsiderable statistical training.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:48:23 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Shachter", "Ross D.", ""], ["Eddy", "David M.", ""], ["Hasselblad", "Vic", ""], ["Wolpert", "Robert", ""]]}, {"id": "1304.2738", "submitter": "Spencer Star", "authors": "Spencer Star", "title": "Theory-Based Inductive Learning: An Integration of Symbolic and\n  Quantitative Methods", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-237-248", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this paper is to propose a method that will generate a\ncausal explanation of observed events in an uncertain world and then make\ndecisions based on that explanation. Feedback can cause the explanation and\ndecisions to be modified. I call the method Theory-Based Inductive Learning\n(T-BIL). T-BIL integrates deductive learning, based on a technique called\nExplanation-Based Generalization (EBG) from the field of machine learning, with\ninductive learning methods from Bayesian decision theory. T-BIL takes as inputs\n(1) a decision problem involving a sequence of related decisions over time, (2)\na training example of a solution to the decision problem in one period, and (3)\nthe domain theory relevant to the decision problem. T-BIL uses these inputs to\nconstruct a probabilistic explanation of why the training example is an\ninstance of a solution to one stage of the sequential decision problem. This\nexplanation is then generalized to cover a more general class of instances and\nis used as the basis for making the next-stage decisions. As the outcomes of\neach decision are observed, the explanation is revised, which in turn affects\nthe subsequent decisions. A detailed example is presented that uses T-BIL to\nsolve a very general stochastic adaptive control problem for an autonomous\nmobile robot.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:48:28 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Star", "Spencer", ""]]}, {"id": "1304.2739", "submitter": "Piero P. Bonissone", "authors": "Piero P. Bonissone", "title": "Using T-Norm Based Uncertainty Calculi in a Naval Situation Assessment\n  Application", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-250-261", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RUM (Reasoning with Uncertainty Module), is an integrated software tool based\non a KEE, a frame system implemented in an object oriented language. RUM's\narchitecture is composed of three layers: representation, inference, and\ncontrol. The representation layer is based on frame-like data structures that\ncapture the uncertainty information used in the inference layer and the\nuncertainty meta-information used in the control layer. The inference layer\nprovides a selection of five T-norm based uncertainty calculi with which to\nperform the intersection, detachment, union, and pooling of information. The\ncontrol layer uses the meta-information to select the appropriate calculus for\neach context and to resolve eventual ignorance or conflict in the information.\nThis layer also provides a context mechanism that allows the system to focus on\nthe relevant portion of the knowledge base, and an uncertain-belief revision\nsystem that incrementally updates the certainty values of well-formed formulae\n(wffs) in an acyclic directed deduction graph. RUM has been tested and\nvalidated in a sequence of experiments in both naval and aerial situation\nassessment (SA), consisting of correlating reports and tracks, locating and\nclassifying platforms, and identifying intents and threats. An example of naval\nsituation assessment is illustrated. The testbed environment for developing\nthese experiments has been provided by LOTTA, a symbolic simulator implemented\nin Flavors. This simulator maintains time-varying situations in a multi-player\nantagonistic game where players must make decisions in light of uncertain and\nincomplete data. RUM has been used to assist one of the LOTTA players to\nperform the SA task.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:48:34 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Bonissone", "Piero P.", ""]]}, {"id": "1304.2740", "submitter": "Yizong Cheng", "authors": "Yizong Cheng, Rangasami L. Kashyap", "title": "A Study of Associative Evidential Reasoning", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-262-269", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evidential reasoning is cast as the problem of simplifying the\nevidence-hypothesis relation and constructing combination formulas that possess\ncertain testable properties. Important classes of evidence as identifiers,\nannihilators, and idempotents and their roles in determining binary operations\non intervals of reals are discussed. The appropriate way of constructing\nformulas for combining evidence and their limitations, for instance, in\nrobustness, are presented.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:48:39 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Cheng", "Yizong", ""], ["Kashyap", "Rangasami L.", ""]]}, {"id": "1304.2741", "submitter": "I. R. Goodman", "authors": "I. R. Goodman", "title": "A Measure-Free Approach to Conditioning", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-270-277", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an earlier paper, a new theory of measurefree \"conditional\" objects was\npresented. In this paper, emphasis is placed upon the motivation of the theory.\nThe central part of this motivation is established through an example involving\na knowledge-based system. In order to evaluate combination of evidence for this\nsystem, using observed data, auxiliary at tribute and diagnosis variables, and\ninference rules connecting them, one must first choose an appropriate algebraic\nlogic description pair (ALDP): a formal language or syntax followed by a\ncompatible logic or semantic evaluation (or model). Three common choices- for\nthis highly non-unique choice - are briefly discussed, the logics being\nClassical Logic, Fuzzy Logic, and Probability Logic. In all three,the key\noperator representing implication for the inference rules is interpreted as the\noften-used disjunction of a negation (b => a) = (b'v a), for any events a,b.\n  However, another reasonable interpretation of the implication operator is\nthrough the familiar form of probabilistic conditioning. But, it can be shown -\nquite surprisingly - that the ALDP corresponding to Probability Logic cannot be\nused as a rigorous basis for this interpretation! To fill this gap, a new ALDP\nis constructed consisting of \"conditional objects\", extending ordinary\nProbability Logic, and compatible with the desired conditional probability\ninterpretation of inference rules. It is shown also that this choice of ALDP\nleads to feasible computations for the combination of evidence evaluation in\nthe example. In addition, a number of basic properties of conditional objects\nand the resulting Conditional Probability Logic are given, including a\ncharacterization property and a developed calculus of relations.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:48:45 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Goodman", "I. R.", ""]]}, {"id": "1304.2742", "submitter": "Peter Haddawy", "authors": "Peter Haddawy, Alan M. Frisch", "title": "Convergent Deduction for Probabilistic Logic", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-278-286", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the semantics and proof theory of Nilsson's\nprobabilistic logic, outlining both the benefits of its well-defined model\ntheory and the drawbacks of its proof theory. Within Nilsson's semantic\nframework, we derive a set of inference rules which are provably sound. The\nresulting proof system, in contrast to Nilsson's approach, has the important\nfeature of convergence - that is, the inference process proceeds by computing\nincreasingly narrow probability intervals which converge from above and below\non the smallest entailed probability interval. Thus the procedure can be\nstopped at any time to yield partial information concerning the smallest\nentailed interval.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:48:49 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Haddawy", "Peter", ""], ["Frisch", "Alan M.", ""]]}, {"id": "1304.2743", "submitter": "Ze-Nian Li", "authors": "Ze-Nian Li", "title": "Comparisons of Reasoning Mechanisms for Computer Vision", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-287-294", "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An evidential reasoning mechanism based on the Dempster-Shafer theory of\nevidence is introduced. Its performance in real-world image analysis is\ncompared with other mechanisms based on the Bayesian formalism and a simple\nweight combination method.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:48:54 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Li", "Ze-Nian", ""]]}, {"id": "1304.2744", "submitter": "Donald H. Mitchell", "authors": "Donald H. Mitchell, Steven A. Harp, David K. Simkin", "title": "A Knowledge Engineer's Comparison of Three Evidence Aggregation Methods", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-297-304", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The comparisons of uncertainty calculi from the last two Uncertainty\nWorkshops have all used theoretical probabilistic accuracy as the sole metric.\nWhile mathematical correctness is important, there are other factors which\nshould be considered when developing reasoning systems. These other factors\ninclude, among other things, the error in uncertainty measures obtainable for\nthe problem and the effect of this error on the performance of the resulting\nsystem.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:48:59 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Mitchell", "Donald H.", ""], ["Harp", "Steven A.", ""], ["Simkin", "David K.", ""]]}, {"id": "1304.2745", "submitter": "Eric Neufeld", "authors": "Eric Neufeld, David L Poole", "title": "Towards Solving the Multiple Extension Problem: Combining Defaults and\n  Probabilities", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-305-312", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multiple extension problem arises frequently in diagnostic and default\ninference. That is, we can often use any of a number of sets of defaults or\npossible hypotheses to explain observations or make Predictions. In default\ninference, some extensions seem to be simply wrong and we use qualitative\ntechniques to weed out the unwanted ones. In the area of diagnosis, however,\nthe multiple explanations may all seem reasonable, however improbable. Choosing\namong them is a matter of quantitative preference. Quantitative preference\nworks well in diagnosis when knowledge is modelled causally. Here we suggest a\nframework that combines probabilities and defaults in a single unified\nframework that retains the semantics of diagnosis as construction of\nexplanations from a fixed set of possible hypotheses. We can then compute\nprobabilities incrementally as we construct explanations. Here we describe a\nbranch and bound algorithm that maintains a set of all partial explanations\nwhile exploring a most promising one first. A most probable explanation is\nfound first if explanations are partially ordered.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:49:04 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Neufeld", "Eric", ""], ["Poole", "David L", ""]]}, {"id": "1304.2746", "submitter": "Richard M. Tong", "authors": "Richard M. Tong, Lee A. Appelbaum", "title": "Problem Structure and Evidential Reasoning", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-313-320", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our previous series of studies to investigate the role of evidential\nreasoning in the RUBRIC system for full-text document retrieval (Tong et al.,\n1985; Tong and Shapiro, 1985; Tong and Appelbaum, 1987), we identified the\nimportant role that problem structure plays in the overall performance of the\nsystem. In this paper, we focus on these structural elements (which we now call\n\"semantic structure\") and show how explicit consideration of their properties\nreduces what previously were seen as difficult evidential reasoning problems to\nmore tractable questions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:49:09 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Tong", "Richard M.", ""], ["Appelbaum", "Lee A.", ""]]}, {"id": "1304.2747", "submitter": "Michael P. Wellman", "authors": "Michael P. Wellman, David Heckerman", "title": "The Role of Calculi in Uncertain Inference Systems", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-321-331", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the controversy about methods for automated decision making has\nfocused on specific calculi for combining beliefs or propagating uncertainty.\nWe broaden the debate by (1) exploring the constellation of secondary tasks\nsurrounding any primary decision problem, and (2) identifying knowledge\nengineering concerns that present additional representational tradeoffs. We\nargue on pragmatic grounds that the attempt to support all of these tasks\nwithin a single calculus is misguided. In the process, we note several\nuncertain reasoning objectives that conflict with the Bayesian ideal of\ncomplete specification of probabilities and utilities. In response, we advocate\ntreating the uncertainty calculus as an object language for reasoning\nmechanisms that support the secondary tasks. Arguments against Bayesian\ndecision theory are weakened when the calculus is relegated to this role.\nArchitectures for uncertainty handling that take statements in the calculus as\nobjects to be reasoned about offer the prospect of retaining normative status\nwith respect to decision making while supporting the other tasks in uncertain\nreasoning.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:49:15 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Wellman", "Michael P.", ""], ["Heckerman", "David", ""]]}, {"id": "1304.2748", "submitter": "Ben P. Wise", "authors": "Ben P. Wise, Bruce M. Perrin, David S. Vaughan, Robert M. Yadrick", "title": "The Role of Tuning Uncertain Inference Systems", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-332-339", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study examined the effects of \"tuning\" the parameters of the incremental\nfunction of MYCIN, the independent function of PROSPECTOR, a probability model\nthat assumes independence, and a simple additive linear equation. me parameters\nof each of these models were optimized to provide solutions which most nearly\napproximated those from a full probability model for a large set of simple\nnetworks. Surprisingly, MYCIN, PROSPECTOR, and the linear equation performed\nequivalently; the independence model was clearly more accurate on the networks\nstudied.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:49:20 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Wise", "Ben P.", ""], ["Perrin", "Bruce M.", ""], ["Vaughan", "David S.", ""], ["Yadrick", "Robert M.", ""]]}, {"id": "1304.2749", "submitter": "Minchuan Zhang", "authors": "Minchuan Zhang, Su-shing Chen", "title": "Evidential Reasoning in Image Understanding", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-340-346", "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present some results of evidential reasoning in\nunderstanding multispectral images of remote sensing systems. The\nDempster-Shafer approach of combination of evidences is pursued to yield\ncontextual classification results, which are compared with previous results of\nthe Bayesian context free classification, contextual classifications of dynamic\nprogramming and stochastic relaxation approaches.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:49:25 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Zhang", "Minchuan", ""], ["Chen", "Su-shing", ""]]}, {"id": "1304.2750", "submitter": "Lashon B. Booker", "authors": "Lashon B. Booker, Naveen Hota, Gavin Hemphill", "title": "Implementing a Bayesian Scheme for Revising Belief Commitments", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-348-354", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our previous work on classifying complex ship images [1,2] has evolved into\nan effort to develop software tools for building and solving generic\nclassification problems. Managing the uncertainty associated with feature data\nand other evidence is an important issue in this endeavor. Bayesian techniques\nfor managing uncertainty [7,12,13] have proven to be useful for managing\nseveral of the belief maintenance requirements of classification problem\nsolving. One such requirement is the need to give qualitative explanations of\nwhat is believed. Pearl [11] addresses this need by computing what he calls a\nbelief commitment-the most probable instantiation of all hypothesis variables\ngiven the evidence available. Before belief commitments can be computed, the\nstraightforward implementation of Pearl's procedure involves finding an\nanalytical solution to some often difficult optimization problems. We describe\nan efficient implementation of this procedure using tensor products that solves\nthese problems enumeratively and avoids the need for case by case analysis. The\nprocedure is thereby made more practical to use in the general case.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:49:30 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Booker", "Lashon B.", ""], ["Hota", "Naveen", ""], ["Hemphill", "Gavin", ""]]}, {"id": "1304.2751", "submitter": "John S. Breese", "authors": "John S. Breese, Edison Tse", "title": "Integrating Logical and Probabilistic Reasoning for Decision Making", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-355-362", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a representation and a set of inference methods that combine\nlogic programming techniques with probabilistic network representations for\nuncertainty (influence diagrams). The techniques emphasize the dynamic\nconstruction and solution of probabilistic and decision-theoretic models for\ncomplex and uncertain domains. Given a query, a logical proof is produced if\npossible; if not, an influence diagram based on the query and the knowledge of\nthe decision domain is produced and subsequently solved. A uniform declarative,\nfirst-order, knowledge representation is combined with a set of integrated\ninference procedures for logical, probabilistic, and decision-theoretic\nreasoning.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:49:35 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Breese", "John S.", ""], ["Tse", "Edison", ""]]}, {"id": "1304.2752", "submitter": "Stephen Chiu", "authors": "Stephen Chiu, Masaki Togai", "title": "Compiling Fuzzy Logic Control Rules to Hardware Implementations", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-363-371", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major aspect of human reasoning involves the use of approximations.\nParticularly in situations where the decision-making process is under stringent\ntime constraints, decisions are based largely on approximate, qualitative\nassessments of the situations. Our work is concerned with the application of\napproximate reasoning to real-time control. Because of the stringent processing\nspeed requirements in such applications, hardware implementations of fuzzy\nlogic inferencing are being pursued. We describe a programming environment for\ntranslating fuzzy control rules into hardware realizations. Two methods of\nhardware realizations are possible. The First is based on a special purpose\nchip for fuzzy inferencing. The second is based on a simple memory chip. The\nability to directly translate a set of decision rules into hardware\nimplementations is expected to make fuzzy control an increasingly practical\napproach to the control of complex systems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:49:40 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Chiu", "Stephen", ""], ["Togai", "Masaki", ""]]}, {"id": "1304.2753", "submitter": "Paul Cohen", "authors": "Paul Cohen", "title": "Steps Towards Programs that Manage Uncertainty", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-372-379", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning under uncertainty in Al hats come to mean assessing the credibility\nof hypotheses inferred from evidence. But techniques for assessing credibility\ndo not tell a problem solver what to do when it is uncertain. This is the focus\nof our current research. We have developed a medical expert system called MUM,\nfor Managing Uncertainty in Medicine, that plans diagnostic sequences of\nquestions, tests, and treatments. This paper describes the kinds of problems\nthat MUM was designed to solve and gives a brief description of its\narchitecture. More recently, we have built an empty version of MUM called MU,\nand used it to reimplement MUM and a small diagnostic system for plant\npathology. The latter part of the paper describes the features of MU that make\nit appropriate for building expert systems that manage uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:49:44 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Cohen", "Paul", ""]]}, {"id": "1304.2754", "submitter": "Gregory F. Cooper", "authors": "Gregory F. Cooper", "title": "An Algorithm for Computing Probabilistic Propositions", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-380-385", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method for computing probabilistic propositions is presented. It assumes\nthe availability of a single external routine for computing the probability of\none instantiated variable, given a conjunction of other instantiated variables.\nIn particular, the method allows belief network algorithms to calculate general\nprobabilistic propositions over nodes in the network. Although in the worst\ncase the time complexity of the method is exponential in the size of a query,\nit is polynomial in the size of a number of common types of queries.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:49:49 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Cooper", "Gregory F.", ""]]}, {"id": "1304.2755", "submitter": "Bruce D'Ambrosio", "authors": "Bruce D'Ambrosio", "title": "Combining Symbolic and Numeric Approaches to Uncertainty Management", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-386-393", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A complete approach to reasoning under uncertainty requires support for\nincremental and interactive formulation and revision of, as well as reasoning\nwith, models of the problem domain capable of representing our uncertainty. We\npresent a hybrid reasoning scheme which combines symbolic and numeric methods\nfor uncertainty management to provide efficient and effective support for each\nof these tasks. The hybrid is based on symbolic techniques adapted from\nAssumption-based Truth Maintenance systems (ATMS), combined with numeric\nmethods adapted from the Dempster/Shafer theory of evidence, as extended in\nBaldwin's Support Logic Programming system. The hybridization is achieved by\nviewing an ATMS as a symbolic algebra system for uncertainty calculations. This\ntechnique has several major advantages over conventional methods for performing\ninference with numeric certainty estimates in addition to the ability to\ndynamically determine hypothesis spaces, including improved management of\ndependent and partially independent evidence, faster run-time evaluation of\npropositional certainties, the ability to query the certainty value of a\nproposition from multiple perspectives, and the ability to incrementally extend\nor revise domain models.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:49:54 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["D'Ambrosio", "Bruce", ""]]}, {"id": "1304.2756", "submitter": "Christopher Elsaesser", "authors": "Christopher Elsaesser", "title": "Explanation of Probabilistic Inference for Decision Support Systems", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-394-403", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An automated explanation facility for Bayesian conditioning aimed at\nimproving user acceptance of probability-based decision support systems has\nbeen developed. The domain-independent facility is based on an information\nprocessing perspective on reasoning about conditional evidence that accounts\nboth for biased and normative inferences. Experimental results indicate that\nthe facility is both acceptable to naive users and effective in improving\nunderstanding.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:49:58 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Elsaesser", "Christopher", ""]]}, {"id": "1304.2757", "submitter": "Greg Hager", "authors": "Greg Hager, Max Mintz", "title": "Estimation Procedures for Robust Sensor Control", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-404-411", "categories": "cs.SY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many robotic sensor estimation problems can characterized in terms of\nnonlinear measurement systems. These systems are contaminated with noise and\nmay be underdetermined from a single observation. In order to get reliable\nestimation results, the system must choose views which result in an\noverdetermined system. This is the sensor control problem. Accurate and\nreliable sensor control requires an estimation procedure which yields both\nestimates and measures of its own performance. In the case of nonlinear\nmeasurement systems, computationally simple closed-form estimation solutions\nmay not exist. However, approximation techniques provide viable alternatives.\nIn this paper, we evaluate three estimation techniques: the extended Kalman\nfilter, a discrete Bayes approximation, and an iterative Bayes approximation.\nWe present mathematical results and simulation statistics illustrating\noperating conditions where the extended Kalman filter is inappropriate for\nsensor control, and discuss issues in the use of the discrete Bayes\napproximation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:50:04 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Hager", "Greg", ""], ["Mintz", "Max", ""]]}, {"id": "1304.2758", "submitter": "Ross D. Shachter", "authors": "Ross D. Shachter, Leonard Bertrand", "title": "Efficient Inference on Generalized Fault Diagrams", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-413-420", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalized fault diagram, a data structure for failure analysis based on\nthe influence diagram, is defined. Unlike the fault tree, this structure allows\nfor dependence among the basic events and replicated logical elements. A\nheuristic procedure is developed for efficient processing of these structures.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:50:09 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Shachter", "Ross D.", ""], ["Bertrand", "Leonard", ""]]}, {"id": "1304.2759", "submitter": "Eric J. Horvitz", "authors": "Eric J. Horvitz", "title": "Reasoning About Beliefs and Actions Under Computational Resource\n  Constraints", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-429-447", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although many investigators affirm a desire to build reasoning systems that\nbehave consistently with the axiomatic basis defined by probability theory and\nutility theory, limited resources for engineering and computation can make a\ncomplete normative analysis impossible. We attempt to move discussion beyond\nthe debate over the scope of problems that can be handled effectively to cases\nwhere it is clear that there are insufficient computational resources to\nperform an analysis deemed as complete. Under these conditions, we stress the\nimportance of considering the expected costs and benefits of applying\nalternative approximation procedures and heuristics for computation and\nknowledge acquisition. We discuss how knowledge about the structure of user\nutility can be used to control value tradeoffs for tailoring inference to\nalternative contexts. We address the notion of real-time rationality, focusing\non the application of knowledge about the expected timewise-refinement\nabilities of reasoning strategies to balance the benefits of additional\ncomputation with the costs of acting with a partial result. We discuss the\nbenefits of applying decision theory to control the solution of difficult\nproblems given limitations and uncertainty in reasoning resources.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:50:20 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Horvitz", "Eric J.", ""]]}, {"id": "1304.2760", "submitter": "Thomas Slack", "authors": "Thomas Slack", "title": "Advantages and a Limitation of Using LEG Nets in a Real-TIme Problem", "comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1987-PG-421-428", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After experimenting with a number of non-probabilistic methods for dealing\nwith uncertainty many researchers reaffirm a preference for probability methods\n[1] [2], although this remains controversial. The importance of being able to\nform decisions from incomplete data in diagnostic problems has highlighted\nprobabilistic methods [5] which compute posterior probabilities from prior\ndistributions in a way similar to Bayes Rule, and thus are called Bayesian\nmethods. This paper documents the use of a Bayesian method in a real time\nproblem which is similar to medical diagnosis in that there is a need to form\ndecisions and take some action without complete knowledge of conditions in the\nproblem domain. This particular method has a limitation which is discussed.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2013 20:44:01 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Slack", "Thomas", ""]]}, {"id": "1304.2797", "submitter": "Emad Saad", "authors": "Emad Saad", "title": "Logical Fuzzy Preferences", "comments": "arXiv admin note: substantial text overlap with arXiv:1304.2384", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We present a unified logical framework for representing and reasoning about\nboth quantitative and qualitative preferences in fuzzy answer set programming,\ncalled fuzzy answer set optimization programs. The proposed framework is vital\nto allow defining quantitative preferences over the possible outcomes of\nqualitative preferences. We show the application of fuzzy answer set\noptimization programs to the course scheduling with fuzzy preferences problem.\nTo the best of our knowledge, this development is the first to consider a\nlogical framework for reasoning about quantitative preferences, in general, and\nreasoning about both quantitative and qualitative preferences in particular.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2013 22:10:22 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Saad", "Emad", ""]]}, {"id": "1304.2799", "submitter": "Emad Saad", "authors": "Emad Saad", "title": "Nested Aggregates in Answer Sets: An Application to a Priori\n  Optimization", "comments": "arXiv admin note: text overlap with arXiv:1304.2384", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We allow representing and reasoning in the presence of nested multiple\naggregates over multiple variables and nested multiple aggregates over\nfunctions involving multiple variables in answer sets, precisely, in answer set\noptimization programming and in answer set programming. We show the\napplicability of the answer set optimization programming with nested multiple\naggregates and the answer set programming with nested multiple aggregates to\nthe Probabilistic Traveling Salesman Problem, a fundamental a priori\noptimization problem in Operation Research.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2013 22:27:33 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Saad", "Emad", ""]]}, {"id": "1304.2888", "submitter": "Nicolas Bredeche", "authors": "Nicolas Bredeche, Jean-Marc Montanier, Berend Weel, Evert Haasdijk", "title": "Roborobo! a Fast Robot Simulator for Swarm and Collective Robotics", "comments": "2 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Roborobo! is a multi-platform, highly portable, robot simulator for\nlarge-scale collective robotics experiments. Roborobo! is coded in C++, and\nfollows the KISS guideline (\"Keep it simple\"). Therefore, its external\ndependency is solely limited to the widely available SDL library for fast 2D\nGraphics. Roborobo! is based on a Khepera/ePuck model. It is targeted for fast\nsingle and multi-robots simulation, and has already been used in more than a\ndozen published research mainly concerned with evolutionary swarm robotics,\nincluding environment-driven self-adaptation and distributed evolutionary\noptimization, as well as online onboard embodied evolution and embodied\nmorphogenesis.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2013 09:44:52 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Bredeche", "Nicolas", ""], ["Montanier", "Jean-Marc", ""], ["Weel", "Berend", ""], ["Haasdijk", "Evert", ""]]}, {"id": "1304.3075", "submitter": "Shoshana Abel", "authors": "Shoshana Abel", "title": "Application of Evidential Reasoning to Helicopter Flight Path Control", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-1-6", "categories": "cs.AI cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a methodology for research and development of the\ninferencing and knowledge representation aspects of an Expert System approach\nfor performing reasoning under uncertainty in support of a real time vehicle\nguidance and navigation system. Such a system could be of major benefit for\nnon-terrain following low altitude flight systems operating in foreign hostile\nenvironments such as might be experienced by NOE helicopter or similar mission\ncraft. An innovative extension of the evidential reasoning methodology, termed\nthe Sum-and-Lattice-Points Method, has been developed. The research and\ndevelopment effort presented in this paper consists of a formal mathematical\ndevelopment of the Sum-and-Lattice-Points Method, its formulation and\nrepresentation in a parallel environment, prototype software development of the\nmethod within an expert system, and initial testing of the system within the\nconfines of the vehicle guidance system.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:51:00 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Abel", "Shoshana", ""]]}, {"id": "1304.3076", "submitter": "Stephen W. Barth", "authors": "Stephen W. Barth, Steven W. Norton", "title": "Knowledge Engineering Within A Generalized Bayesian Framework", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-7-16", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the ongoing debate over the representation of uncertainty in\nArtificial Intelligence, Cheeseman, Lemmer, Pearl, and others have argued that\nprobability theory, and in particular the Bayesian theory, should be used as\nthe basis for the inference mechanisms of Expert Systems dealing with\nuncertainty. In order to pursue the issue in a practical setting, sophisticated\ntools for knowledge engineering are needed that allow flexible and\nunderstandable interaction with the underlying knowledge representation\nschemes. This paper describes a Generalized Bayesian framework for building\nexpert systems which function in uncertain domains, using algorithms proposed\nby Lemmer. It is neither rule-based nor frame-based, and requires a new system\nof knowledge engineering tools. The framework we describe provides a\nknowledge-based system architecture with an inference engine, explanation\ncapability, and a unique aid for building consistent knowledge bases.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:51:06 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Barth", "Stephen W.", ""], ["Norton", "Steven W.", ""]]}, {"id": "1304.3077", "submitter": "Moshe Ben-Bassat", "authors": "Moshe Ben-Bassat", "title": "Taxonomy, Structure, and Implementation of Evidential Reasoning", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-17-28", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental elements of evidential reasoning problems are described,\nfollowed by a discussion of the structure of various types of problems.\nBayesian inference networks and state space formalism are used as the tool for\nproblem representation.\n  A human-oriented decision making cycle for solving evidential reasoning\nproblems is described and illustrated for a military situation assessment\nproblem. The implementation of this cycle may serve as the basis for an expert\nsystem shell for evidential reasoning; i.e. a situation assessment processor.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:51:12 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Ben-Bassat", "Moshe", ""]]}, {"id": "1304.3078", "submitter": "Lashon B. Booker", "authors": "Lashon B. Booker, Naveen Hota", "title": "Probabilistic Reasoning About Ship Images", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-29-36", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important aspects of current expert systems technology is the\nability to make causal inferences about the impact of new evidence. When the\ndomain knowledge and problem knowledge are uncertain and incomplete Bayesian\nreasoning has proven to be an effective way of forming such inferences [3,4,8].\nWhile several reasoning schemes have been developed based on Bayes Rule, there\nhas been very little work examining the comparative effectiveness of these\nschemes in a real application. This paper describes a knowledge based system\nfor ship classification [1], originally developed using the PROSPECTOR updating\nmethod [2], that has been reimplemented to use the inference procedure\ndeveloped by Pearl and Kim [4,5]. We discuss our reasons for making this\nchange, the implementation of the new inference engine, and the comparative\nperformance of the two versions of the system.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:51:17 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Booker", "Lashon B.", ""], ["Hota", "Naveen", ""]]}, {"id": "1304.3079", "submitter": "Kaihu Chen", "authors": "Kaihu Chen", "title": "Towards The Inductive Acquisition of Temporal Knowledge", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-37-42", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to predict the future in a given domain can be acquired by\ndiscovering empirically from experience certain temporal patterns that tend to\nrepeat unerringly. Previous works in time series analysis allow one to make\nquantitative predictions on the likely values of certain linear variables.\nSince certain types of knowledge are better expressed in symbolic forms, making\nqualitative predictions based on symbolic representations require a different\napproach. A domain independent methodology called TIM (Time based Inductive\nMachine) for discovering potentially uncertain temporal patterns from real time\nobservations using the technique of inductive inference is described here.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:51:22 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Chen", "Kaihu", ""]]}, {"id": "1304.3080", "submitter": "Su-shing Chen", "authors": "Su-shing Chen", "title": "Some Extensions of Probabilistic Logic", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-43-48", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In [12], Nilsson proposed the probabilistic logic in which the truth values\nof logical propositions are probability values between 0 and 1. It is\napplicable to any logical system for which the consistency of a finite set of\npropositions can be established. The probabilistic inference scheme reduces to\nthe ordinary logical inference when the probabilities of all propositions are\neither 0 or 1. This logic has the same limitations of other probabilistic\nreasoning systems of the Bayesian approach. For common sense reasoning,\nconsistency is not a very natural assumption. We have some well known examples:\n{Dick is a Quaker, Quakers are pacifists, Republicans are not pacifists, Dick\nis a Republican}and {Tweety is a bird, birds can fly, Tweety is a penguin}. In\nthis paper, we shall propose some extensions of the probabilistic logic. In the\nsecond section, we shall consider the space of all interpretations, consistent\nor not. In terms of frames of discernment, the basic probability assignment\n(bpa) and belief function can be defined. Dempster's combination rule is\napplicable. This extension of probabilistic logic is called the evidential\nlogic in [ 1]. For each proposition s, its belief function is represented by an\ninterval [Spt(s), Pls(s)]. When all such intervals collapse to single points,\nthe evidential logic reduces to probabilistic logic (in the generalized version\nof not necessarily consistent interpretations). Certainly, we get Nilsson's\nprobabilistic logic by further restricting to consistent interpretations. In\nthe third section, we shall give a probabilistic interpretation of\nprobabilistic logic in terms of multi-dimensional random variables. This\ninterpretation brings the probabilistic logic into the framework of probability\ntheory. Let us consider a finite set S = {sl, s2, ..., Sn) of logical\npropositions. Each proposition may have true or false values; and may be\nconsidered as a random variable. We have a probability distribution for each\nproposition. The e-dimensional random variable (sl,..., Sn) may take values in\nthe space of all interpretations of 2n binary vectors. We may compute absolute\n(marginal), conditional and joint probability distributions. It turns out that\nthe permissible probabilistic interpretation vector of Nilsson [12] consists of\nthe joint probabilities of S. Inconsistent interpretations will not appear, by\nsetting their joint probabilities to be zeros. By summing appropriate joint\nprobabilities, we get probabilities of individual propositions or subsets of\npropositions. Since the Bayes formula and other techniques are valid for\ne-dimensional random variables, the probabilistic logic is actually very close\nto the Bayesian inference schemes. In the last section, we shall consider a\nrelaxation scheme for probabilistic logic. In this system, not only new\nevidences will update the belief measures of a collection of propositions, but\nalso constraint satisfaction among these propositions in the relational network\nwill revise these measures. This mechanism is similar to human reasoning which\nis an evaluative process converging to the most satisfactory result. The main\nidea arises from the consistent labeling problem in computer vision. This\nmethod is originally applied to scene analysis of line drawings. Later, it is\napplied to matching, constraint satisfaction and multi sensor fusion by several\nauthors [8], [16] (and see references cited there). Recently, this method is\nused in knowledge aggregation by Landy and Hummel [9].\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:51:27 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Chen", "Su-shing", ""]]}, {"id": "1304.3081", "submitter": "Ping-Chung Chi", "authors": "Ping-Chung Chi, Dana Nau", "title": "Predicting The Performance of Minimax and Product in Game-Tree", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-49-56", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discovery that the minimax decision rule performs poorly in some games\nhas sparked interest in possible alternatives to minimax. Until recently, the\nonly games in which minimax was known to perform poorly were games which were\nmainly of theoretical interest. However, this paper reports results showing\npoor performance of minimax in a more common game called kalah. For the kalah\ngames tested, a non-minimax decision rule called the product rule performs\nsignificantly better than minimax.\n  This paper also discusses a possible way to predict whether or not minimax\nwill perform well in a game when compared to product. A parameter called the\nrate of heuristic flaw (rhf) has been found to correlate positively with the.\nperformance of product against minimax. Both analytical and experimental\nresults are given that appear to support the predictive power of rhf.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:51:32 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Chi", "Ping-Chung", ""], ["Nau", "Dana", ""]]}, {"id": "1304.3082", "submitter": "A. Julian Craddock", "authors": "A. Julian Craddock, Roger A. Browse", "title": "Reasoning With Uncertain Knowledge", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-57-62", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model of knowledge representation is described in which propositional facts\nand the relationships among them can be supported by other facts. The set of\nknowledge which can be supported is called the set of cognitive units, each\nhaving associated descriptions of their explicit and implicit support\nstructures, summarizing belief and reliability of belief. This summary is\nprecise enough to be useful in a computational model while remaining\ndescriptive of the underlying symbolic support structure. When a fact supports\nanother supportive relationship between facts we call this meta-support. This\nfacilitates reasoning about both the propositional knowledge. and the support\nstructures underlying it.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:51:38 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Craddock", "A. Julian", ""], ["Browse", "Roger A.", ""]]}, {"id": "1304.3083", "submitter": "Norman C. Dalkey", "authors": "Norman C. Dalkey", "title": "Models vs. Inductive Inference for Dealing With Probabilistic Knowledge", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-63-70", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two different approaches to dealing with probabilistic knowledge are examined\n-models and inductive inference. Examples of the first are: influence diagrams\n[1], Bayesian networks [2], log-linear models [3, 4]. Examples of the second\nare: games-against nature [5, 6] varieties of maximum-entropy methods [7, 8,\n9], and the author's min-score induction [10]. In the modeling approach, the\nbasic issue is manageability, with respect to data elicitation and computation.\nThus, it is assumed that the pertinent set of users in some sense knows the\nrelevant probabilities, and the problem is to format that knowledge in a way\nthat is convenient to input and store and that allows computation of the\nanswers to current questions in an expeditious fashion. The basic issue for the\ninductive approach appears at first sight to be very different. In this\napproach it is presumed that the relevant probabilities are only partially\nknown, and the problem is to extend that incomplete information in a reasonable\nway to answer current questions. Clearly, this approach requires that some form\nof induction be invoked. Of course, manageability is an important additional\nconcern. Despite their seeming differences, the two approaches have a fair\namount in common, especially with respect to the structural framework they\nemploy. Roughly speaking, this framework involves identifying clusters of\nvariables which strongly interact, establishing marginal probability\ndistributions on the clusters, and extending the subdistributions to a more\ncomplete distribution, usually via a product formalism. The product extension\nis justified on the modeling approach in terms of assumed conditional\nindependence; in the inductive approach the product form arises from an\ninductive rule.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:51:44 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Dalkey", "Norman C.", ""]]}, {"id": "1304.3084", "submitter": "Brian Falkenhainer", "authors": "Brian Falkenhainer", "title": "Towards a General-Purpose Belief Maintenance System", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-71-76", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There currently exists a gap between the theories proposed by the probability\nand uncertainty and the needs of Artificial Intelligence research. These\ntheories primarily address the needs of expert systems, using knowledge\nstructures which must be pre-compiled and remain static in structure during\nruntime. Many Al systems require the ability to dynamically add and remove\nparts of the current knowledge structure (e.g., in order to examine what the\nworld would be like for different causal theories). This requires more\nflexibility than existing uncertainty systems display. In addition, many Al\nresearchers are only interested in using \"probabilities\" as a means of\nobtaining an ordering, rather than attempting to derive an accurate\nprobabilistic account of a situation. This indicates the need for systems which\nstress ease of use and don't require extensive probability information when one\ncannot (or doesn't wish to) provide such information. This paper attempts to\nhelp reconcile the gap between approaches to uncertainty and the needs of many\nAI systems by examining the control issues which arise, independent of a\nparticular uncertainty calculus. when one tries to satisfy these needs. Truth\nMaintenance Systems have been used extensively in problem solving tasks to help\norganize a set of facts and detect inconsistencies in the believed state of the\nworld. These systems maintain a set of true/false propositions and their\nassociated dependencies. However, situations often arise in which we are unsure\nof certain facts or in which the conclusions we can draw from available\ninformation are somewhat uncertain. The non-monotonic TMS 12] was an attempt at\nreasoning when all the facts are not known, but it fails to take into account\ndegrees of belief and how available evidence can combine to strengthen a\nparticular belief. This paper addresses the problem of probabilistic reasoning\nas it applies to Truth Maintenance Systems. It describes a belief Maintenance\nSystem that manages a current set of beliefs in much the same way that a TMS\nmanages a set of true/false propositions. If the system knows that belief in\nfact is dependent in some way upon belief in fact2, then it automatically\nmodifies its belief in facts when new information causes a change in belief of\nfact2. It models the behavior of a TMS, replacing its 3-valued logic (true,\nfalse, unknown) with an infinite valued logic, in such a way as to reduce to a\nstandard TMS if all statements are given in absolute true/false terms. Belief\nMaintenance Systems can, therefore, be thought of as a generalization of Truth\nMaintenance Systems, whose possible reasoning tasks are a superset of those for\na TMS.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:51:49 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Falkenhainer", "Brian", ""]]}, {"id": "1304.3085", "submitter": "B. R. Fox", "authors": "B. R. Fox, Karl G. Kempf", "title": "Planning, Scheduling, and Uncertainty in the Sequence of Future Events", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-77-84", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scheduling in the factory setting is compounded by computational complexity\nand temporal uncertainty. Together, these two factors guarantee that the\nprocess of constructing an optimal schedule will be costly and the chances of\nexecuting that schedule will be slight. Temporal uncertainty in the task\nexecution time can be offset by several methods: eliminate uncertainty by\ncareful engineering, restore certainty whenever it is lost, reduce the\nuncertainty by using more accurate sensors, and quantify and circumscribe the\nremaining uncertainty. Unfortunately, these methods focus exclusively on the\nsources of uncertainty and fail to apply knowledge of the tasks which are to be\nscheduled. A complete solution must adapt the schedule of activities to be\nperformed according to the evolving state of the production world. The example\nof vision-directed assembly is presented to illustrate that the principle of\nleast commitment, in the creation of a plan, in the representation of a\nschedule, and in the execution of a schedule, enables a robot to operate\nintelligently and efficiently, even in the presence of considerable uncertainty\nin the sequence of future events.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:51:55 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Fox", "B. R.", ""], ["Kempf", "Karl G.", ""]]}, {"id": "1304.3086", "submitter": "Pascal Fua", "authors": "Pascal Fua", "title": "Deriving And Combining Continuous Possibility Functions in the Framework\n  of Evidential Reasoning", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-85-90", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To develop an approach to utilizing continuous statistical information within\nthe Dempster- Shafer framework, we combine methods proposed by Strat and by\nShafero We first derive continuous possibility and mass functions from\nprobability-density functions. Then we propose a rule for combining such\nevidence that is simpler and more efficiently computed than Dempster's rule. We\ndiscuss the relationship between Dempster's rule and our proposed rule for\ncombining evidence over continuous frames.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:52:00 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Fua", "Pascal", ""]]}, {"id": "1304.3087", "submitter": "Benjamin N. Grosof", "authors": "Benjamin N. Grosof", "title": "Non-Monotonicity in Probabilistic Reasoning", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-91-98", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We start by defining an approach to non-monotonic probabilistic reasoning in\nterms of non-monotonic categorical (true-false) reasoning. We identify a type\nof non-monotonic probabilistic reasoning, akin to default inheritance, that is\ncommonly found in practice, especially in \"evidential\" and \"Bayesian\"\nreasoning. We formulate this in terms of the Maximization of Conditional\nIndependence (MCI), and identify a variety of applications for this sort of\ndefault. We propose a formalization using Pointwise Circumscription. We compare\nMCI to Maximum Entropy, another kind of non-monotonic principle, and conclude\nby raising a number of open questions\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:52:05 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Grosof", "Benjamin N.", ""]]}, {"id": "1304.3088", "submitter": "Greg Hager", "authors": "Greg Hager, Hugh F. Durrant-Whyte", "title": "Information and Multi-Sensor Coordination", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-99-108", "categories": "cs.SY cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The control and integration of distributed, multi-sensor perceptual systems\nis a complex and challenging problem. The observations or opinions of different\nsensors are often disparate incomparable and are usually only partial views.\nSensor information is inherently uncertain and in addition the individual\nsensors may themselves be in error with respect to the system as a whole. The\nsuccessful operation of a multi-sensor system must account for this uncertainty\nand provide for the aggregation of disparate information in an intelligent and\nrobust manner. We consider the sensors of a multi-sensor system to be members\nor agents of a team, able to offer opinions and bargain in group decisions. We\nwill analyze the coordination and control of this structure using a theory of\nteam decision-making. We present some new analytic results on multi-sensor\naggregation and detail a simulation which we use to investigate our ideas. This\nsimulation provides a basis for the analysis of complex agent structures\ncooperating in the presence of uncertainty. The results of this study are\ndiscussed with reference to multi-sensor robot systems, distributed Al and\ndecision making under uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:52:12 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Hager", "Greg", ""], ["Durrant-Whyte", "Hugh F.", ""]]}, {"id": "1304.3089", "submitter": "Shohara L. Hardt", "authors": "Shohara L. Hardt", "title": "Flexible Interpretations: A Computational Model for Dynamic Uncertainty\n  Assessment", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-109-114", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The investigations reported in this paper center on the process of dynamic\nuncertainty assessment during interpretation tasks in real domain. In\nparticular, we are interested here in the nature of the control structure of\ncomputer programs that can support multiple interpretation and smooth\ntransitions between them, in real time. Each step of the processing involves\nthe interpretation of one input item and the appropriate re-establishment of\nthe system's confidence of the correctness of its interpretation(s).\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:52:17 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Hardt", "Shohara L.", ""]]}, {"id": "1304.3090", "submitter": "David Heckerman", "authors": "David Heckerman, Eric J. Horvitz", "title": "The Myth of Modularity in Rule-Based Systems", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-115-122", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we examine the concept of modularity, an often cited advantage\nof the ruled-based representation methodology. We argue that the notion of\nmodularity consists of two distinct concepts which we call syntactic modularity\nand semantic modularity. We argue that when reasoning under certainty, it is\nreasonable to regard the rule-based approach as both syntactically and\nsemantically modular. However, we argue that in the case of plausible\nreasoning, rules are syntactically modular but are rarely semantically modular.\nTo illustrate this point, we examine a particular approach for managing\nuncertainty in rule-based systems called the MYCIN certainty factor model. We\nformally define the concept of semantic modularity with respect to the\ncertainty factor model and discuss logical consequences of the definition. We\nshow that the assumption of semantic modularity imposes strong restrictions on\nrules in a knowledge base. We argue that such restrictions are rarely valid in\npractical applications. Finally, we suggest how the concept of semantic\nmodularity can be relaxed in a manner that makes it appropriate for plausible\nreasoning.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:52:23 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Heckerman", "David", ""], ["Horvitz", "Eric J.", ""]]}, {"id": "1304.3091", "submitter": "David Heckerman", "authors": "David Heckerman", "title": "An Axiomatic Framework for Belief Updates", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-123-128", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the 1940's, a physicist named Cox provided the first formal justification\nfor the axioms of probability based on the subjective or Bayesian\ninterpretation. He showed that if a measure of belief satisfies several\nfundamental properties, then the measure must be some monotonic transformation\nof a probability. In this paper, measures of change in belief or belief updates\nare examined. In the spirit of Cox, properties for a measure of change in\nbelief are enumerated. It is shown that if a measure satisfies these\nproperties, it must satisfy other restrictive conditions. For example, it is\nshown that belief updates in a probabilistic context must be equal to some\nmonotonic transformation of a likelihood ratio. It is hoped that this formal\nexplication of the belief update paradigm will facilitate critical discussion\nand useful extensions of the approach.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:52:28 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Heckerman", "David", ""]]}, {"id": "1304.3092", "submitter": "Steven J. Henkind", "authors": "Steven J. Henkind", "title": "Imprecise Meanings as a Cause of Uncertainty in Medical Knowledge-Based\n  Systems", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-129-134", "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a considerable amount of work on uncertainty in\nknowledge-based systems. This work has generally been concerned with\nuncertainty arising from the strength of inferences and the weight of evidence.\nIn this paper we discuss another type of uncertainty: that which is due to\nimprecision in the underlying primitives used to represent the knowledge of the\nsystem. In particular, a given word may denote many similar but not identical\nentities. Such words are said to be lexically imprecise. Lexical imprecision\nhas caused widespread problems in many areas. Unless this phenomenon is\nrecognized and appropriately handled, it can degrade the performance of\nknowledge-based systems. In particular, it can lead to difficulties with the\nuser interface, and with the inferencing processes of these systems. Some\ntechniques are suggested for coping with this phenomenon.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:52:35 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Henkind", "Steven J.", ""]]}, {"id": "1304.3093", "submitter": "Robert Hummel", "authors": "Robert Hummel, Michael Landy", "title": "Evidence as Opinions of Experts", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-135-144", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a viewpoint on the Dempster/Shafer 'Theory of Evidence', and\nprovide an interpretation which regards the combination formulas as statistics\nof the opinions of \"experts\". This is done by introducing spaces with binary\noperations that are simpler to interpret or simpler to implement than the\nstandard combination formula, and showing that these spaces can be mapped\nhomomorphically onto the Dempster/Shafer theory of evidence space. The experts\nin the space of \"opinions of experts\" combine information in a Bayesian\nfashion. We present alternative spaces for the combination of evidence\nsuggested by this viewpoint.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:52:40 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Hummel", "Robert", ""], ["Landy", "Michael", ""]]}, {"id": "1304.3094", "submitter": "Charles I. Kalme", "authors": "Charles I. Kalme", "title": "Decision Under Uncertainty in Diagnosis", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-145-150", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the incorporation of uncertainty in diagnostic reasoning\nbased on the set covering model of Reggia et. al. extended to what in the\nArtificial Intelligence dichotomy between deep and compiled (shallow, surface)\nknowledge based diagnosis may be viewed as the generic form at the compiled end\nof the spectrum. A major undercurrent in this is advocating the need for a\nstrong underlying model and an integrated set of support tools for carrying\nsuch a model in order to deal with uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:52:45 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Kalme", "Charles I.", ""]]}, {"id": "1304.3095", "submitter": "Henry E. Kyburg Jr.", "authors": "Henry E. Kyburg Jr", "title": "Knowledge and Uncertainty", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-151-158", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One purpose -- quite a few thinkers would say the main purpose -- of seeking\nknowledge about the world is to enhance our ability to make good decisions. An\nitem of knowledge that can make no conceivable difference with regard to\nanything we might do would strike many as frivolous. Whether or not we want to\nbe philosophical pragmatists in this strong sense with regard to everything we\nmight want to enquire about, it seems a perfectly appropriate attitude to adopt\ntoward artificial knowledge systems. If is granted that we are ultimately\nconcerned with decisions, then some constraints are imposed on our measures of\nuncertainty at the level of decision making. If our measure of uncertainty is\nreal-valued, then it isn't hard to show that it must satisfy the classical\nprobability axioms. For example, if an act has a real-valued utility U(E) if\nthe event E obtains, and the same real-valued utility if the denial of E\nobtains, so that U(E) = U(-E), then the expected utility of that act must be\nU(E), and that must be the same as the uncertainty-weighted average of the\nreturns of the act, p-U(E) + q-U('E), where p and q represent the uncertainty\nof E and-E respectively. But then we must have p + q = 1.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:52:50 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Kyburg", "Henry E.", "Jr"]]}, {"id": "1304.3096", "submitter": "Kathryn Blackmond Laskey", "authors": "Kathryn Blackmond Laskey, Marvin S. Cohen", "title": "An Application of Non-Monotonic Probabilistic Reasoning to Air Force\n  Threat Correlation", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-159-166", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches to expert systems' reasoning under uncertainty fail to\ncapture the iterative revision process characteristic of intelligent human\nreasoning. This paper reports on a system, called the Non-monotonic\nProbabilist, or NMP (Cohen, et al., 1985). When its inferences result in\nsubstantial conflict, NMP examines and revises the assumptions underlying the\ninferences until conflict is reduced to acceptable levels. NMP has been\nimplemented in a demonstration computer-based system, described below, which\nsupports threat correlation and in-flight route replanning by Air Force pilots.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:52:56 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Laskey", "Kathryn Blackmond", ""], ["Cohen", "Marvin S.", ""]]}, {"id": "1304.3097", "submitter": "Tod S. Levitt", "authors": "Tod S. Levitt", "title": "Bayesian Inference for Radar Imagery Based Surveillance", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-167-174", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in creating an automated or semi-automated system with the\ncapability of taking a set of radar imagery, collection parameters and a priori\nmap and other tactical data, and producing likely interpretations of the\npossible military situations given the available evidence. This paper is\nconcerned with the problem of the interpretation and computation of certainty\nor belief in the conclusions reached by such a system.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:53:02 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Levitt", "Tod S.", ""]]}, {"id": "1304.3098", "submitter": "Ze-Nian Li", "authors": "Ze-Nian Li, Leonard Uhr", "title": "Evidential Reasoning in Parallel Hierarchical Vision Programs", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-175-182", "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an efficient adaptation and application of the\nDempster-Shafer theory of evidence, one that can be used effectively in a\nmassively parallel hierarchical system for visual pattern perception. It\ndescribes the techniques used, and shows in an extended example how they serve\nto improve the system's performance as it applies a multiple-level set of\nprocesses.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:53:08 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Li", "Ze-Nian", ""], ["Uhr", "Leonard", ""]]}, {"id": "1304.3099", "submitter": "Ronald P. Loui", "authors": "Ronald P. Loui", "title": "Computing Reference Classes", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-183-188", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For any system with limited statistical knowledge, the combination of\nevidence and the interpretation of sampling information require the\ndetermination of the right reference class (or of an adequate one). The present\nnote (1) discusses the use of reference classes in evidential reasoning, and\n(2) discusses implementations of Kyburg's rules for reference classes. This\npaper contributes the first frank discussion of how much of Kyburg's system is\nneeded to be powerful, how much can be computed effectively, and how much is\nphilosophical fat.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:53:13 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Loui", "Ronald P.", ""]]}, {"id": "1304.3100", "submitter": "Uttam Mukhopadhyay", "authors": "Uttam Mukhopadhyay", "title": "An Uncertainty Management Calculus for Ordering Searches in Distributed\n  Dynamic Databases", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-189-192", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MINDS is a distributed system of cooperating query engines that customize,\ndocument retrieval for each user in a dynamic environment. It improves its\nperformance and adapts to changing patterns of document distribution by\nobserving system-user interactions and modifying the appropriate certainty\nfactors, which act as search control parameters. It argued here that the\nuncertainty management calculus must account for temporal precedence,\nreliability of evidence, degree of support for a proposition, and saturation\neffects. The calculus presented here possesses these features. Some results\nobtained with this scheme are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:53:17 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Mukhopadhyay", "Uttam", ""]]}, {"id": "1304.3101", "submitter": "Steven W. Norton", "authors": "Steven W. Norton", "title": "An Explanation Mechanism for Bayesian Inferencing Systems", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-193-200", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explanation facilities are a particularly important feature of expert system\nframeworks. It is an area in which traditional rule-based expert system\nframeworks have had mixed results. While explanations about control are well\nhandled, facilities are needed for generating better explanations concerning\nknowledge base content. This paper approaches the explanation problem by\nexamining the effect an event has on a variable of interest within a symmetric\nBayesian inferencing system. We argue that any effect measure operating in this\ncontext must satisfy certain properties. Such a measure is proposed. It forms\nthe basis for an explanation facility which allows the user of the Generalized\nBayesian Inferencing System to question the meaning of the knowledge base. That\nfacility is described in detail.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:53:23 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Norton", "Steven W.", ""]]}, {"id": "1304.3102", "submitter": "Judea Pearl", "authors": "Judea Pearl", "title": "Distributed Revision of Belief Commitment in Multi-Hypothesis\n  Interpretations", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-201-210", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the applications of belief-networks to include the\nrevision of belief commitments, i.e., the categorical acceptance of a subset of\nhypotheses which, together, constitute the most satisfactory explanation of the\nevidence at hand. A coherent model of non-monotonic reasoning is established\nand distributed algorithms for belief revision are presented. We show that, in\nsingly connected networks, the most satisfactory explanation can be found in\nlinear time by a message-passing algorithm similar to the one used in belief\nupdating. In multiply-connected networks, the problem may be exponentially hard\nbut, if the network is sparse, topological considerations can be used to render\nthe interpretation task tractable. In general, finding the most probable\ncombination of hypotheses is no more complex than computing the degree of\nbelief for any individual hypothesis. Applications to medical diagnosis are\nillustrated.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:53:29 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Pearl", "Judea", ""]]}, {"id": "1304.3103", "submitter": "Igor Roizer", "authors": "Igor Roizer, Judea Pearl", "title": "Learning Link-Probabilities in Causal Trees", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-211-214", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A learning algorithm is presented which given the structure of a causal tree,\nwill estimate its link probabilities by sequential measurements on the leaves\nonly. Internal nodes of the tree represent conceptual (hidden) variables\ninaccessible to observation. The method described is incremental, local,\nefficient, and remains robust to measurement imprecisions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:53:34 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Roizer", "Igor", ""], ["Pearl", "Judea", ""]]}, {"id": "1304.3104", "submitter": "Enrique H. Ruspini", "authors": "Enrique H. Ruspini", "title": "Approximate Deduction in Single Evidential Bodies", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-215-222", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Results on approximate deduction in the context of the calculus of evidence\nof Dempster-Shafer and the theory of interval probabilities are reported.\nApproximate conditional knowledge about the truth of conditional propositions\nwas assumed available and expressed as sets of possible values (actually\nnumeric intervals) of conditional probabilities. Under different\ninterpretations of this conditional knowledge, several formulas were produced\nto integrate unconditioned estimates (assumed given as sets of possible values\nof unconditioned probabilities) with conditional estimates. These formulas are\ndiscussed together with the computational characteristics of the methods\nderived from them. Of particular importance is one such evidence integration\nformulation, produced under a belief oriented interpretation, which\nincorporates both modus ponens and modus tollens inferential mechanisms, allows\nintegration of conditioned and unconditioned knowledge without resorting to\niterative or sequential approximations, and produces elementary mass\ndistributions as outputs using similar distributions as inputs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:53:39 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Ruspini", "Enrique H.", ""]]}, {"id": "1304.3105", "submitter": "Shimon Schocken", "authors": "Shimon Schocken", "title": "The Rational and Computational Scope of Probabilistic Rule-Based Expert\n  Systems", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-223-228", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Belief updating schemes in artificial intelligence may be viewed as three\ndimensional languages, consisting of a syntax (e.g. probabilities or certainty\nfactors), a calculus (e.g. Bayesian or CF combination rules), and a semantics\n(i.e. cognitive interpretations of competing formalisms). This paper studies\nthe rational scope of those languages on the syntax and calculus grounds. In\nparticular, the paper presents an endomorphism theorem which highlights the\nlimitations imposed by the conditional independence assumptions implicit in the\nCF calculus. Implications of the theorem to the relationship between the CF and\nthe Bayesian languages and the Dempster-Shafer theory of evidence are\npresented. The paper concludes with a discussion of some implications on\nrule-based knowledge engineering in uncertain domains.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:53:46 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Schocken", "Shimon", ""]]}, {"id": "1304.3106", "submitter": "Stanley M. Schwartz", "authors": "Stanley M. Schwartz, Jonathan Baron, John R. Clarke", "title": "A Causal Bayesian Model for the Diagnosis of Appendicitis", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-229-236", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The causal Bayesian approach is based on the assumption that effects (e.g.,\nsymptoms) that are not conditionally independent with respect to some causal\nagent (e.g., a disease) are conditionally independent with respect to some\nintermediate state caused by the agent, (e.g., a pathological condition). This\npaper describes the development of a causal Bayesian model for the diagnosis of\nappendicitis. The paper begins with a description of the standard Bayesian\napproach to reasoning about uncertainty and the major critiques it faces. The\npaper then lays the theoretical groundwork for the causal extension of the\nBayesian approach, and details specific improvements we have developed. The\npaper then goes on to describe our knowledge engineering and implementation and\nthe results of a test of the system. The paper concludes with a discussion of\nhow the causal Bayesian approach deals with the criticisms of the standard\nBayesian model and why it is superior to alternative approaches to reasoning\nabout uncertainty popular in the Al community.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:53:52 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Schwartz", "Stanley M.", ""], ["Baron", "Jonathan", ""], ["Clarke", "John R.", ""]]}, {"id": "1304.3107", "submitter": "Ross D. Shachter", "authors": "Ross D. Shachter, David Heckerman", "title": "A Backwards View for Assessment", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-237-242", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much artificial intelligence research focuses on the problem of deducing the\nvalidity of unobservable propositions or hypotheses from observable evidence.!\nMany of the knowledge representation techniques designed for this problem\nencode the relationship between evidence and hypothesis in a directed manner.\nMoreover, the direction in which evidence is stored is typically from evidence\nto hypothesis.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:53:57 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Shachter", "Ross D.", ""], ["Heckerman", "David", ""]]}, {"id": "1304.3108", "submitter": "Ross D. Shachter", "authors": "Ross D. Shachter", "title": "DAVID: Influence Diagram Processing System for the Macintosh", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-243-248", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence diagrams are a directed graph representation for uncertainties as\nprobabilities. The graph distinguishes between those variables which are under\nthe control of a decision maker (decisions, shown as rectangles) and those\nwhich are not (chances, shown as ovals), as well as explicitly denoting a goal\nfor solution (value, shown as a rounded rectangle.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:54:03 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Shachter", "Ross D.", ""]]}, {"id": "1304.3109", "submitter": "Prakash P. Shenoy", "authors": "Prakash P. Shenoy, Glenn Shafer, Khaled Mellouli", "title": "Propagation of Belief Functions: A Distributed Approach", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-249-260", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a scheme for propagating belief functions in\ncertain kinds of trees using only local computations. This scheme generalizes\nthe computational scheme proposed by Shafer and Logan1 for diagnostic trees of\nthe type studied by Gordon and Shortliffe, and the slightly more general scheme\ngiven by Shafer for hierarchical evidence. It also generalizes the scheme\nproposed by Pearl for Bayesian causal trees (see Shenoy and Shafer). Pearl's\ncausal trees and Gordon and Shortliffe's diagnostic trees are both ways of\nbreaking the evidence that bears on a large problem down into smaller items of\nevidence that bear on smaller parts of the problem so that these smaller\nproblems can be dealt with one at a time. This localization of effort is often\nessential in order to make the process of probability judgment feasible, both\nfor the person who is making probability judgments and for the machine that is\ncombining them. The basic structure for our scheme is a type of tree that\ngeneralizes both Pearl's and Gordon and Shortliffe's trees. Trees of this\ngeneral type permit localized computation in Pearl's sense. They are based on\nqualitative judgments of conditional independence. We believe that the scheme\nwe describe here will prove useful in expert systems. It is now clear that the\nsuccessful propagation of probabilities or certainty factors in expert systems\nrequires much more structure than can be provided in a pure production-system\nframework. Bayesian schemes, on the other hand, often make unrealistic demands\nfor structure. The propagation of belief functions in trees and more general\nnetworks stands on a middle ground where some sensible and useful things can be\ndone. We would like to emphasize that the basic idea of local computation for\npropagating probabilities is due to Judea Pearl. It is a very innovative idea;\nwe do not believe that it can be found in the Bayesian literature prior to\nPearl's work. We see our contribution as extending the usefulness of Pearl's\nidea by generalizing it from Bayesian probabilities to belief functions. In the\nnext section, we give a brief introduction to belief functions. The notions of\nqualitative independence for partitions and a qualitative Markov tree are\nintroduced in Section III. Finally, in Section IV, we describe a scheme for\npropagating belief functions in qualitative Markov trees.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:54:09 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Shenoy", "Prakash P.", ""], ["Shafer", "Glenn", ""], ["Mellouli", "Khaled", ""]]}, {"id": "1304.3110", "submitter": "David Sher", "authors": "David Sher", "title": "Appropriate and Inappropriate Estimation Techniques", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-261-266", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mode {also called MAP} estimation, mean estimation and median estimation are\nexamined here to determine when they can be safely used to derive {posterior)\ncost minimizing estimates. (These are all Bayes procedures, using the mode.\nmean. or median of the posterior distribution). It is found that modal\nestimation only returns cost minimizing estimates when the cost function is\n0-t. If the cost function is a function of distance then mean estimation only\nreturns cost minimizing estimates when the cost function is squared distance\nfrom the true value and median estimation only returns cost minimizing\nestimates when the cost function ts the distance from the true value. Results\nare presented on the goodness or modal estimation with non 0-t cost functions\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:54:15 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Sher", "David", ""]]}, {"id": "1304.3111", "submitter": "Randall Smith", "authors": "Randall Smith, Matthew Self, Peter Cheeseman", "title": "Estimating Uncertain Spatial Relationships in Robotics", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-267-288", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a representation for spatial information, called\nthe stochastic map, and associated procedures for building it, reading\ninformation from it, and revising it incrementally as new information is\nobtained. The map contains the estimates of relationships among objects in the\nmap, and their uncertainties, given all the available information. The\nprocedures provide a general solution to the problem of estimating uncertain\nrelative spatial relationships. The estimates are probabilistic in nature, an\nadvance over the previous, very conservative, worst-case approaches to the\nproblem. Finally, the procedures are developed in the context of\nstate-estimation and filtering theory, which provides a solid basis for\nnumerous extensions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:54:21 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Smith", "Randall", ""], ["Self", "Matthew", ""], ["Cheeseman", "Peter", ""]]}, {"id": "1304.3112", "submitter": "Masaki Togai", "authors": "Masaki Togai, Hiroyuki Watanabe", "title": "A VLSI Design and Implementation for a Real-Time Approximate Reasoning", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-289-296", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The role of inferencing with uncertainty is becoming more important in\nrule-based expert systems (ES), since knowledge given by a human expert is\noften uncertain or imprecise. We have succeeded in designing a VLSI chip which\ncan perform an entire inference process based on fuzzy logic. The design of the\nVLSI fuzzy inference engine emphasizes simplicity, extensibility, and\nefficiency (operational speed and layout area). It is fabricated in 2.5 um CMOS\ntechnology. The inference engine consists of three major components; a rule set\nmemory, an inference processor, and a controller. In this implementation, a\nrule set memory is realized by a read only memory (ROM). The controller\nconsists of two counters. In the inference processor, one data path is laid out\nfor each rule. The number of the inference rule can be increased adding more\ndata paths to the inference processor. All rules are executed in parallel, but\neach rule is processed serially. The logical structure of fuzzy inference\nproposed in the current paper maps nicely onto the VLSI structure. A two-phase\nnonoverlapping clocking scheme is used. Timing tests indicate that the\ninference engine can operate at approximately 20.8 MHz. This translates to an\nexecution speed of approximately 80,000 Fuzzy Logical Inferences Per Second\n(FLIPS), and indicates that the inference engine is suitable for a demanding\nreal-time application. The potential applications include decision-making in\nthe area of command and control for intelligent robot systems, process control,\nmissile and aircraft guidance, and other high performance machines.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:54:27 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Togai", "Masaki", ""], ["Watanabe", "Hiroyuki", ""]]}, {"id": "1304.3113", "submitter": "Richard M. Tong", "authors": "Richard M. Tong, Lee A. Appelbaum, D. G. Shapiro", "title": "A General Purpose Inference Engine for Evidential Reasoning Research", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-297-302", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to report on the most recent developments in our\nongoing investigation of the representation and manipulation of uncertainty in\nautomated reasoning systems. In our earlier studies (Tong and Shapiro, 1985) we\ndescribed a series of experiments with RUBRIC (Tong et al., 1985), a system for\nfull-text document retrieval, that generated some interesting insights into the\neffects of choosing among a class of scalar valued uncertainty calculi. [n\norder to extend these results we have begun a new series of experiments with a\nlarger class of representations and calculi, and to help perform these\nexperiments we have developed a general purpose inference engine.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:54:33 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Tong", "Richard M.", ""], ["Appelbaum", "Lee A.", ""], ["Shapiro", "D. G.", ""]]}, {"id": "1304.3114", "submitter": "Silvio Ursic", "authors": "Silvio Ursic", "title": "Generalizing Fuzzy Logic Probabilistic Inferences", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-303-310", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear representations for a subclass of boolean symmetric functions selected\nby a parity condition are shown to constitute a generalization of the linear\nconstraints on probabilities introduced by Boole. These linear constraints are\nnecessary to compute probabilities of events with relations between the.\narbitrarily specified with propositional calculus boolean formulas.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:54:38 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Ursic", "Silvio", ""]]}, {"id": "1304.3115", "submitter": "Michael P. Wellman", "authors": "Michael P. Wellman", "title": "Qualitative Probabilistic Networks for Planning Under Uncertainty", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-311-318", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian networks provide a probabilistic semantics for qualitative\nassertions about likelihood. A qualitative reasoner based on an algebra over\nthese assertions can derive further conclusions about the influence of actions.\nWhile the conclusions are much weaker than those computed from complete\nprobability distributions, they are still valuable for suggesting potential\nactions, eliminating obviously inferior plans, identifying important tradeoffs,\nand explaining probabilistic models.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:54:44 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Wellman", "Michael P.", ""]]}, {"id": "1304.3116", "submitter": "Ben P. Wise", "authors": "Ben P. Wise", "title": "Experimentally Comparing Uncertain Inference Systems to Probability", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-319-332", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the biases and performance of several uncertain inference\nsystems: Mycin, a variant of Mycin. and a simplified version of probability\nusing conditional independence assumptions. We present axiomatic arguments for\nusing Minimum Cross Entropy inference as the best way to do uncertain\ninference. For Mycin and its variant we found special situations where its\nperformance was very good, but also situations where performance was worse than\nrandom guessing, or where data was interpreted as having the opposite of its\ntrue import We have found that all three of these systems usually gave accurate\nresults, and that the conditional independence assumptions gave the most robust\nresults. We illustrate how the Importance of biases may be quantitatively\nassessed and ranked. Considerations of robustness might be a critical factor is\nselecting UlS's for a given application.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:54:50 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Wise", "Ben P.", ""]]}, {"id": "1304.3117", "submitter": "Robert M. Yadrick", "authors": "Robert M. Yadrick, Bruce M. Perrin, David S. Vaughan, Peter D. Holden,\n  Karl G. Kempf", "title": "Evaluation of Uncertain Inference Models I: PROSPECTOR", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-333-338", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the accuracy of the PROSPECTOR model for uncertain\nreasoning. PROSPECTOR's solutions for a large number of computer-generated\ninference networks were compared to those obtained from probability theory and\nminimum cross-entropy calculations. PROSPECTOR's answers were generally\naccurate for a restricted subset of problems that are consistent with its\nassumptions. However, even within this subset, we identified conditions under\nwhich PROSPECTOR's performance deteriorates.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:54:56 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Yadrick", "Robert M.", ""], ["Perrin", "Bruce M.", ""], ["Vaughan", "David S.", ""], ["Holden", "Peter D.", ""], ["Kempf", "Karl G.", ""]]}, {"id": "1304.3118", "submitter": "Ronald R. Yager", "authors": "Ronald R. Yager", "title": "On Implementing Usual Values", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-339-346", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many cases commonsense knowledge consists of knowledge of what is usual.\nIn this paper we develop a system for reasoning with usual information. This\nsystem is based upon the fact that these pieces of commonsense information\ninvolve both a probabilistic aspect and a granular aspect. We implement this\nsystem with the aid of possibility-probability granules.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:55:01 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Yager", "Ronald R.", ""]]}, {"id": "1304.3119", "submitter": "Lotfi Zadeh", "authors": "Lotfi Zadeh, Anca Ralescu", "title": "On the Combinality of Evidence in the Dempster-Shafer Theory", "comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1986-PG-347-349", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current versions of the Dempster-Shafer theory, the only essential\nrestriction on the validity of the rule of combination is that the sources of\nevidence must be statistically independent. Under this assumption, it is\npermissible to apply the Dempster-Shafer rule to two or mere distinct\nprobability distributions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:55:05 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Zadeh", "Lotfi", ""], ["Ralescu", "Anca", ""]]}, {"id": "1304.3144", "submitter": "Emad Saad", "authors": "Emad Saad", "title": "Logical Probability Preferences", "comments": "arXiv admin note: substantial text overlap with arXiv:1304.2384,\n  arXiv:1304.2797", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We present a unified logical framework for representing and reasoning about\nboth probability quantitative and qualitative preferences in probability answer\nset programming, called probability answer set optimization programs. The\nproposed framework is vital to allow defining probability quantitative\npreferences over the possible outcomes of qualitative preferences. We show the\napplication of probability answer set optimization programs to a variant of the\nwell-known nurse restoring problem, called the nurse restoring with probability\npreferences problem. To the best of our knowledge, this development is the\nfirst to consider a logical framework for reasoning about probability\nquantitative preferences, in general, and reasoning about both probability\nquantitative and qualitative preferences in particular.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2013 22:18:18 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Saad", "Emad", ""]]}, {"id": "1304.3208", "submitter": "Denis Berthier Pr.", "authors": "Denis Berthier", "title": "From Constraints to Resolution Rules, Part I: Conceptual Framework", "comments": "International Joint Conferences on Computer, Information, Systems\n  Sciences and Engineering (CISSE 08), December 5-13, 2008, Springer. Also a\n  chapter of the book \"Advanced Techniques in Computing Sciences and Software\n  Engineering\", Khaled Elleithy Editor, pp. 165-170, Springer, 2010, ISBN\n  9789094136599", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world problems naturally appear as constraints satisfaction\nproblems (CSP), for which very efficient algorithms are known. Most of these\ninvolve the combination of two techniques: some direct propagation of\nconstraints between variables (with the goal of reducing their sets of possible\nvalues) and some kind of structured search (depth-first, breadth-first,...).\nBut when such blind search is not possible or not allowed or when one wants a\n'constructive' or a 'pattern-based' solution, one must devise more complex\npropagation rules instead. In this case, one can introduce the notion of a\ncandidate (a 'still possible' value for a variable). Here, we give this\nintuitive notion a well defined logical status, from which we can define the\nconcepts of a resolution rule and a resolution theory. In order to keep our\nanalysis as concrete as possible, we illustrate each definition with the well\nknown Sudoku example. Part I proposes a general conceptual framework based on\nfirst order logic; with the introduction of chains and braids, Part II will\ngive much deeper results.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2013 06:37:20 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Berthier", "Denis", ""]]}, {"id": "1304.3210", "submitter": "Denis Berthier Pr.", "authors": "Denis Berthier", "title": "From Constraints to Resolution Rules, Part II: chains, braids,\n  confluence and T&E", "comments": "International Joint Conferences on Computer, Information, Systems\n  Sciences and Engineering (CISSE 08), December 5-13, 2008, Springer. Also a\n  chapter of the book 'Advanced Techniques in Computing Sciences and Software\n  Engineering', Khaled Elleithy Editor, pp. 171-176, Springer, 2010, ISBN\n  9789094136599", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this Part II, we apply the general theory developed in Part I to a\ndetailed analysis of the Constraint Satisfaction Problem (CSP). We show how\nspecific types of resolution rules can be defined. In particular, we introduce\nthe general notions of a chain and a braid. As in Part I, these notions are\nillustrated in detail with the Sudoku example - a problem known to be\nNP-complete and which is therefore typical of a broad class of hard problems.\nFor Sudoku, we also show how far one can go in 'approximating' a CSP with a\nresolution theory and we give an empirical statistical analysis of how the\nvarious puzzles, corresponding to different sets of entries, can be classified\nalong a natural scale of complexity. For any CSP, we also prove the confluence\nproperty of some Resolution Theories based on braids and we show how it can be\nused to define different resolution strategies. Finally, we prove that, in any\nCSP, braids have the same solving capacity as Trial-and-Error (T&E) with no\nguessing and we comment this result in the Sudoku case.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2013 06:40:22 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Berthier", "Denis", ""]]}, {"id": "1304.3418", "submitter": "Benjamin N. Grosof", "authors": "Benjamin N. Grosof", "title": "An Inequality Paradigm for Probabilistic Knowledge", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-1-8", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an inequality paradigm for probabilistic reasoning based on a\nlogic of upper and lower bounds on conditional probabilities. We investigate a\nfamily of probabilistic logics, generalizing the work of Nilsson [14]. We\ndevelop a variety of logical notions for probabilistic reasoning, including\nsoundness, completeness justification; and convergence: reduction of a theory\nto a simpler logical class. We argue that a bound view is especially useful for\ndescribing the semantics of probabilistic knowledge representation and for\ndescribing intermediate states of probabilistic inference and updating. We show\nthat the Dempster-Shafer theory of evidence is formally identical to a special\ncase of our generalized probabilistic logic. Our paradigm thus incorporates\nboth Bayesian \"rule-based\" approaches and avowedly non-Bayesian \"evidential\"\napproaches such as MYCIN and DempsterShafer. We suggest how to integrate the\ntwo \"schools\", and explore some possibilities for novel synthesis of a variety\nof ideas in probabilistic reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:55:33 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Grosof", "Benjamin N.", ""]]}, {"id": "1304.3419", "submitter": "David Heckerman", "authors": "David Heckerman", "title": "Probabilistic Interpretations for MYCIN's Certainty Factors", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-9-20", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the quantities used by MYCIN to reason with uncertainty,\ncalled certainty factors. It is shown that the original definition of certainty\nfactors is inconsistent with the functions used in MYCIN to combine the\nquantities. This inconsistency is used to argue for a redefinition of certainty\nfactors in terms of the intuitively appealing desiderata associated with the\ncombining functions. It is shown that this redefinition accommodates an\nunlimited number of probabilistic interpretations. These interpretations are\nshown to be monotonic transformations of the likelihood ratio p(EIH)/p(El H).\nThe construction of these interpretations provides insight into the assumptions\nimplicit in the certainty factor model. In particular, it is shown that if\nuncertainty is to be propagated through an inference network in accordance with\nthe desiderata, evidence must be conditionally independent given the hypothesis\nand its negation and the inference network must have a tree structure. It is\nemphasized that assumptions implicit in the model are rarely true in practical\napplications. Methods for relaxing the assumptions are suggested.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:55:40 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Heckerman", "David", ""]]}, {"id": "1304.3420", "submitter": "Daniel Hunter", "authors": "Daniel Hunter", "title": "Uncertain Reasoning Using Maximum Entropy Inference", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-21-27", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of maximum entropy inference in reasoning with uncertain information\nis commonly justified by an information-theoretic argument. This paper\ndiscusses a possible objection to this information-theoretic justification and\nshows how it can be met. I then compare maximum entropy inference with certain\nother currently popular methods for uncertain reasoning. In making such a\ncomparison, one must distinguish between static and dynamic theories of degrees\nof belief: a static theory concerns the consistency conditions for degrees of\nbelief at a given time; whereas a dynamic theory concerns how one's degrees of\nbelief should change in the light of new information. It is argued that maximum\nentropy is a dynamic theory and that a complete theory of uncertain reasoning\ncan be gotten by combining maximum entropy inference with probability theory,\nwhich is a static theory. This total theory, I argue, is much better grounded\nthan are other theories of uncertain reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:55:46 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Hunter", "Daniel", ""]]}, {"id": "1304.3421", "submitter": "Rodney W. Johnson", "authors": "Rodney W. Johnson", "title": "Independence and Bayesian Updating Methods", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-28-30", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Duda, Hart, and Nilsson have set forth a method for rule-based inference\nsystems to use in updating the probabilities of hypotheses on the basis of\nmultiple items of new evidence. Pednault, Zucker, and Muresan claimed to give\nconditions under which independence assumptions made by Duda et al. preclude\nupdating-that is, prevent the evidence from altering the probabilities of the\nhypotheses. Glymour refutes Pednault et al.'s claim with a counterexample of a\nrather special form (one item of evidence is incompatible with all but one of\nthe hypotheses); he raises, but leaves open, the question whether their result\nwould be true with an added assumption to rule out such special cases. We show\nthat their result does not hold even with the added assumption, but that it can\nnevertheless be largely salvaged. Namely, under the conditions assumed by\nPednault et al., at most one of the items of evidence can alter the probability\nof any given hypothesis; thus, although updating is possible, multiple updating\nfor any of the hypotheses is precluded.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:55:51 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Johnson", "Rodney W.", ""]]}, {"id": "1304.3422", "submitter": "Judea Pearl", "authors": "Judea Pearl", "title": "A Constraint Propagation Approach to Probabilistic Reasoning", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-31-42", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper demonstrates that strict adherence to probability theory does not\npreclude the use of concurrent, self-activated constraint-propagation\nmechanisms for managing uncertainty. Maintaining local records of\nsources-of-belief allows both predictive and diagnostic inferences to be\nactivated simultaneously and propagate harmoniously towards a stable\nequilibrium.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:55:56 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Pearl", "Judea", ""]]}, {"id": "1304.3423", "submitter": "John E. Shore", "authors": "John E. Shore", "title": "Relative Entropy, Probabilistic Inference and AI", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-43-47", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various properties of relative entropy have led to its widespread use in\ninformation theory. These properties suggest that relative entropy has a role\nto play in systems that attempt to perform inference in terms of probability\ndistributions. In this paper, I will review some basic properties of relative\nentropy as well as its role in probabilistic inference. I will also mention\nbriefly a few existing and potential applications of relative entropy to\nso-called artificial intelligence (AI).\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:56:01 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Shore", "John E.", ""]]}, {"id": "1304.3424", "submitter": "Ray Solomonoff", "authors": "Ray Solomonoff", "title": "Foundations of Probability Theory for AI - The Application of\n  Algorithmic Probability to Problems in Artificial Intelligence", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-48-56", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper covers two topics: first an introduction to Algorithmic Complexity\nTheory: how it defines probability, some of its characteristic properties and\npast successful applications. Second, we apply it to problems in A.I. - where\nit promises to give near optimum search procedures for two very broad classes\nof problems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:56:07 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Solomonoff", "Ray", ""]]}, {"id": "1304.3425", "submitter": "Piero P. Bonissone", "authors": "Piero P. Bonissone, Keith S. Decker", "title": "Selecting Uncertainty Calculi and Granularity: An Experiment in\n  Trading-Off Precision and Complexity", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-57-66", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The management of uncertainty in expert systems has usually been left to ad\nhoc representations and rules of combinations lacking either a sound theory or\nclear semantics. The objective of this paper is to establish a theoretical\nbasis for defining the syntax and semantics of a small subset of calculi of\nuncertainty operating on a given term set of linguistic statements of\nlikelihood. Each calculus is defined by specifying a negation, a conjunction\nand a disjunction operator. Families of Triangular norms and conorms constitute\nthe most general representations of conjunction and disjunction operators.\nThese families provide us with a formalism for defining an infinite number of\ndifferent calculi of uncertainty. The term set will define the uncertainty\ngranularity, i.e. the finest level of distinction among different\nquantifications of uncertainty. This granularity will limit the ability to\ndifferentiate between two similar operators. Therefore, only a small finite\nsubset of the infinite number of calculi will produce notably different\nresults. This result is illustrated by two experiments where nine and eleven\ndifferent calculi of uncertainty are used with three term sets containing five,\nnine, and thirteen elements, respectively. Finally, the use of context\ndependent rule set is proposed to select the most appropriate calculus for any\ngiven situation. Such a rule set will be relatively small since it must only\ndescribe the selection policies for a small number of calculi (resulting from\nthe analyzed trade-off between complexity and precision).\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:56:13 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Bonissone", "Piero P.", ""], ["Decker", "Keith S.", ""]]}, {"id": "1304.3426", "submitter": "Marvin S. Cohen", "authors": "Marvin S. Cohen", "title": "A Framework for Non-Monotonic Reasoning About Probabilistic Assumptions", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-67-75", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attempts to replicate probabilistic reasoning in expert systems have\ntypically overlooked a critical ingredient of that process. Probabilistic\nanalysis typically requires extensive judgments regarding interdependencies\namong hypotheses and data, and regarding the appropriateness of various\nalternative models. The application of such models is often an iterative\nprocess, in which the plausibility of the results confirms or disconfirms the\nvalidity of assumptions made in building the model. In current expert systems,\nby contrast, probabilistic information is encapsulated within modular rules\n(involving, for example, \"certainty factors\"), and there is no mechanism for\nreviewing the overall form of the probability argument or the validity of the\njudgments entering into it.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:56:20 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Cohen", "Marvin S.", ""]]}, {"id": "1304.3427", "submitter": "Robert Fung", "authors": "Robert Fung, Chee Yee Chong", "title": "Metaprobability and Dempster-Shafer in Evidential Reasoning", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-76-83", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evidential reasoning in expert systems has often used ad-hoc uncertainty\ncalculi. Although it is generally accepted that probability theory provides a\nfirm theoretical foundation, researchers have found some problems with its use\nas a workable uncertainty calculus. Among these problems are representation of\nignorance, consistency of probabilistic judgements, and adjustment of a priori\njudgements with experience. The application of metaprobability theory to\nevidential reasoning is a new approach to solving these problems.\nMetaprobability theory can be viewed as a way to provide soft or hard\nconstraints on beliefs in much the same manner as the Dempster-Shafer theory\nprovides constraints on probability masses on subsets of the state space. Thus,\nwe use the Dempster-Shafer theory, an alternative theory of evidential\nreasoning to illuminate metaprobability theory as a theory of evidential\nreasoning. The goal of this paper is to compare how metaprobability theory and\nDempster-Shafer theory handle the adjustment of beliefs with evidence with\nrespect to a particular thought experiment. Sections 2 and 3 give brief\ndescriptions of the metaprobability and Dempster-Shafer theories.\nMetaprobability theory deals with higher order probabilities applied to\nevidential reasoning. Dempster-Shafer theory is a generalization of probability\ntheory which has evolved from a theory of upper and lower probabilities.\nSection 4 describes a thought experiment and the metaprobability and\nDempsterShafer analysis of the experiment. The thought experiment focuses on\nforming beliefs about a population with 6 types of members {1, 2, 3, 4, 5, 6}.\nA type is uniquely defined by the values of three features: A, B, C. That is,\nif the three features of one member of the population were known then its type\ncould be ascertained. Each of the three features has two possible values, (e.g.\nA can be either \"a0\" or \"al\"). Beliefs are formed from evidence accrued from\ntwo sensors: sensor A, and sensor B. Each sensor senses the corresponding\ndefining feature. Sensor A reports that half of its observations are \"a0\" and\nhalf the observations are 'al'. Sensor B reports that half of its observations\nare ``b0,' and half are \"bl\". Based on these two pieces of evidence, what\nshould be the beliefs on the distribution of types in the population? Note that\nthe third feature is not observed by any sensor.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:56:26 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Fung", "Robert", ""], ["Chong", "Chee Yee", ""]]}, {"id": "1304.3428", "submitter": "Matthew L. Ginsberg", "authors": "Matthew L. Ginsberg", "title": "Implementing Probabilistic Reasoning", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-84-90", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General problems in analyzing information in a probabilistic database are\nconsidered. The practical difficulties (and occasional advantages) of storing\nuncertain data, of using it conventional forward- or backward-chaining\ninference engines, and of working with a probabilistic version of resolution\nare discussed. The background for this paper is the incorporation of uncertain\nreasoning facilities in MRS, a general-purpose expert system building tool.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:56:32 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Ginsberg", "Matthew L.", ""]]}, {"id": "1304.3429", "submitter": "Glenn Shafer", "authors": "Glenn Shafer", "title": "Probability Judgement in Artificial Intelligence", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-91-98", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with two theories of probability judgment: the\nBayesian theory and the theory of belief functions. It illustrates these\ntheories with some simple examples and discusses some of the issues that arise\nwhen we try to implement them in expert systems. The Bayesian theory is well\nknown; its main ideas go back to the work of Thomas Bayes (1702-1761). The\ntheory of belief functions, often called the Dempster-Shafer theory in the\nartificial intelligence community, is less well known, but it has even older\nantecedents; belief-function arguments appear in the work of George Hooper\n(16401723) and James Bernoulli (1654-1705). For elementary expositions of the\ntheory of belief functions, see Shafer (1976, 1985).\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:56:37 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Shafer", "Glenn", ""]]}, {"id": "1304.3430", "submitter": "Ben P. Wise", "authors": "Ben P. Wise, Max Henrion", "title": "A Framework for Comparing Uncertain Inference Systems to Probability", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-99-108", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several different uncertain inference systems (UISs) have been developed for\nrepresenting uncertainty in rule-based expert systems. Some of these, such as\nMycin's Certainty Factors, Prospector, and Bayes' Networks were designed as\napproximations to probability, and others, such as Fuzzy Set Theory and\nDempsterShafer Belief Functions were not. How different are these UISs in\npractice, and does it matter which you use? When combining and propagating\nuncertain information, each UIS must, at least by implication, make certain\nassumptions about correlations not explicily specified. The maximum entropy\nprinciple with minimum cross-entropy updating, provides a way of making\nassumptions about the missing specification that minimizes the additional\ninformation assumed, and thus offers a standard against which the other UISs\ncan be compared. We describe a framework for the experimental comparison of the\nperformance of different UISs, and provide some illustrative results.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:56:43 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Wise", "Ben P.", ""], ["Henrion", "Max", ""]]}, {"id": "1304.3431", "submitter": "Norman C. Dalkey", "authors": "Norman C. Dalkey", "title": "Inductive Inference and the Representation of Uncertainty", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-109-116", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The form and justification of inductive inference rules depend strongly on\nthe representation of uncertainty. This paper examines one generic\nrepresentation, namely, incomplete information. The notion can be formalized by\npresuming that the relevant probabilities in a decision problem are known only\nto the extent that they belong to a class K of probability distributions. The\nconcept is a generalization of a frequent suggestion that uncertainty be\nrepresented by intervals or ranges on probabilities. To make the representation\nuseful for decision making, an inductive rule can be formulated which\ndetermines, in a well-defined manner, a best approximation to the unknown\nprobability, given the set K. In addition, the knowledge set notion entails a\nnatural procedure for updating -- modifying the set K given new evidence.\nSeveral non-intuitive consequences of updating emphasize the differences\nbetween inference with complete and inference with incomplete information.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:56:49 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Dalkey", "Norman C.", ""]]}, {"id": "1304.3432", "submitter": "Stephen Jose Hanson", "authors": "Stephen Jose Hanson, Malcolm Bauer", "title": "Machine Learning, Clustering, and Polymorphy", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-117-128", "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a machine induction program (WITT) that attempts to\nmodel human categorization. Properties of categories to which human subjects\nare sensitive includes best or prototypical members, relative contrasts between\nputative categories, and polymorphy (neither necessary or sufficient features).\nThis approach represents an alternative to usual Artificial Intelligence\napproaches to generalization and conceptual clustering which tend to focus on\nnecessary and sufficient feature rules, equivalence classes, and simple search\nand match schemes. WITT is shown to be more consistent with human\ncategorization while potentially including results produced by more traditional\nclustering schemes. Applications of this approach in the domains of expert\nsystems and information retrieval are also discussed.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:56:55 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Hanson", "Stephen Jose", ""], ["Bauer", "Malcolm", ""]]}, {"id": "1304.3433", "submitter": "Larry Rendell", "authors": "Larry Rendell", "title": "Induction, of and by Probability", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-129-134", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines some methods and ideas underlying the author's successful\nprobabilistic learning systems(PLS), which have proven uniquely effective and\nefficient in generalization learning or induction. While the emerging\nprinciples are generally applicable, this paper illustrates them in heuristic\nsearch, which demands noise management and incremental learning. In our\napproach, both task performance and learning are guided by probability.\nProbabilities are incrementally normalized and revised, and their errors are\nlocated and corrected.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:57:01 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Rendell", "Larry", ""]]}, {"id": "1304.3434", "submitter": "David S. Vaughan", "authors": "David S. Vaughan, Bruce M. Perrin, Robert M. Yadrick, Peter D. Holden,\n  Karl G. Kempf", "title": "An Odds Ratio Based Inference Engine", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-135-142", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expert systems applications that involve uncertain inference can be\nrepresented by a multidimensional contingency table. These tables offer a\ngeneral approach to inferring with uncertain evidence, because they can embody\nany form of association between any number of pieces of evidence and\nconclusions. (Simpler models may be required, however, if the number of pieces\nof evidence bearing on a conclusion is large.) This paper presents a method of\nusing these tables to make uncertain inferences without assumptions of\nconditional independence among pieces of evidence or heuristic combining rules.\nAs evidence is accumulated, new joint probabilities are calculated so as to\nmaintain any dependencies among the pieces of evidence that are found in the\ncontingency table. The new conditional probability of the conclusion is then\ncalculated directly from these new joint probabilities and the conditional\nprobabilities in the contingency table.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:57:05 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Vaughan", "David S.", ""], ["Perrin", "Bruce M.", ""], ["Yadrick", "Robert M.", ""], ["Holden", "Peter D.", ""], ["Kempf", "Karl G.", ""]]}, {"id": "1304.3435", "submitter": "Moshe Ben-Bassat", "authors": "Moshe Ben-Bassat, Oded Maler", "title": "A Framework for Control Strategies in Uncertain Inference Networks", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-143-151", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control Strategies for hierarchical tree-like probabilistic inference\nnetworks are formulated and investigated. Strategies that utilize staged\nlook-ahead and temporary focus on subgoals are formalized and refined using the\nDepth Vector concept that serves as a tool for defining the 'virtual tree'\nregarded by the control strategy. The concept is illustrated by four types of\ncontrol strategies for three-level trees that are characterized according to\ntheir Depth Vector, and according to the way they consider intermediate nodes\nand the role that they let these nodes play. INFERENTI is a computerized\ninference system written in Prolog, which provides tools for exercising a\nvariety of control strategies. The system also provides tools for simulating\ntest data and for comparing the relative average performance under different\nstrategies.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:57:11 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Ben-Bassat", "Moshe", ""], ["Maler", "Oded", ""]]}, {"id": "1304.3436", "submitter": "Henry Hamburger", "authors": "Henry Hamburger", "title": "Combining Uncertain Estimates", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-152-159", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a real expert system, one may have unreliable, unconfident, conflicting\nestimates of the value for a particular parameter. It is important for decision\nmaking that the information present in this aggregate somehow find its way into\nuse. We cast the problem of representing and combining uncertain estimates as\nselection of two kinds of functions, one to determine an estimate, the other\nits uncertainty. The paper includes a long list of properties that such\nfunctions should satisfy, and it presents one method that satisfies them.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:57:16 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Hamburger", "Henry", ""]]}, {"id": "1304.3437", "submitter": "John F. Lemmer", "authors": "John F. Lemmer", "title": "Confidence Factors, Empiricism and the Dempster-Shafer Theory of\n  Evidence", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-160-176", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The issue of confidence factors in Knowledge Based Systems has become\nincreasingly important and Dempster-Shafer (DS) theory has become increasingly\npopular as a basis for these factors. This paper discusses the need for an\nempirical lnterpretatlon of any theory of confidence factors applied to\nKnowledge Based Systems and describes an empirical lnterpretatlon of DS theory\nsuggesting that the theory has been extensively misinterpreted. For the\nessentially syntactic DS theory, a model is developed based on sample spaces,\nthe traditional semantic model of probability theory. This model is used to\nshow that, if belief functions are based on reasonably accurate sampling or\nobservation of a sample space, then the beliefs and upper probabilities as\ncomputed according to DS theory cannot be interpreted as frequency ratios.\nSince many proposed applications of DS theory use belief functions in\nsituations with statistically derived evidence (Wesley [1]) and seem to appeal\nto statistical intuition to provide an lnterpretatlon of the results as has\nGarvey [2], it may be argued that DS theory has often been misapplied.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:57:24 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Lemmer", "John F.", ""]]}, {"id": "1304.3438", "submitter": "Alan Bundy", "authors": "Alan Bundy", "title": "Incidence Calculus: A Mechanism for Probabilistic Reasoning", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-177-184", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mechanisms for the automation of uncertainty are required for expert systems.\nSometimes these mechanisms need to obey the properties of probabilistic\nreasoning. A purely numeric mechanism, like those proposed so far, cannot\nprovide a probabilistic logic with truth functional connectives. We propose an\nalternative mechanism, Incidence Calculus, which is based on a representation\nof uncertainty using sets of points, which might represent situations, models\nor possible worlds. Incidence Calculus does provide a probabilistic logic with\ntruth functional connectives.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:57:29 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Bundy", "Alan", ""]]}, {"id": "1304.3439", "submitter": "Benjamin N. Grosof", "authors": "Benjamin N. Grosof", "title": "Evidential Confirmation as Transformed Probability", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-185-192", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A considerable body of work in AI has been concerned with aggregating\nmeasures of confirmatory and disconfirmatory evidence for a common set of\npropositions. Claiming classical probability to be inadequate or inappropriate,\nseveral researchers have gone so far as to invent new formalisms and methods.\nWe show how to represent two major such alternative approaches to evidential\nconfirmation not only in terms of transformed (Bayesian) probability, but also\nin terms of each other. This unifies two of the leading approaches to\nconfirmation theory, by showing that a revised MYCIN Certainty Factor method\n[12] is equivalent to a special case of Dempster-Shafer theory. It yields a\nwell-understood axiomatic basis, i.e. conditional independence, to interpret\nprevious work on quantitative confirmation theory. It substantially resolves\nthe \"taxe-them-or-leave-them\" problem of priors: MYCIN had to leave them out,\nwhile PROSPECTOR had to have them in. It recasts some of confirmation theory's\nadvantages in terms of the psychological accessibility of probabilistic\ninformation in different (transformed) formats. Finally, it helps to unify the\nrepresentation of uncertain reasoning (see also [11]).\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:57:35 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Grosof", "Benjamin N.", ""]]}, {"id": "1304.3440", "submitter": "Ronald P. Loui", "authors": "Ronald P. Loui", "title": "Interval-Based Decisions for Reasoning Systems", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-193-200", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This essay looks at decision-making with interval-valued probability\nmeasures. Existing decision methods have either supplemented expected utility\nmethods with additional criteria of optimality, or have attempted to supplement\nthe interval-valued measures. We advocate a new approach, which makes the\nfollowing questions moot: 1. which additional criteria to use, and 2. how wide\nintervals should be. In order to implement the approach, we need more\nepistemological information. Such information can be generated by a rule of\nacceptance with a parameter that allows various attitudes toward error, or can\nsimply be declared. In sketch, the argument is: 1. probability intervals are\nuseful and natural in All. systems; 2. wide intervals avoid error, but are\nuseless in some risk sensitive decision-making; 3. one may obtain narrower\nintervals if one is less cautious; 4. if bodies of knowledge can be ordered by\ntheir caution, one should perform the decision analysis with the acceptable\nbody of knowledge that is the most cautious, of those that are useful. The\nresulting behavior differs from that of a behavioral probabilist (a Bayesian)\nbecause in the proposal, 5. intervals based on successive bodies of knowledge\nare not always nested; 6. if the agent uses a probability for a particular\ndecision, she need not commit to that probability for credence or future\ndecision; and 7. there may be no acceptable body of knowledge that is useful;\nhence, sometimes no decision is mandated.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:57:41 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Loui", "Ronald P.", ""]]}, {"id": "1304.3441", "submitter": "James E. Corter", "authors": "James E. Corter, Mark A. Gluck", "title": "Machine Generalization and Human Categorization: An\n  Information-Theoretic View", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-201-207", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In designing an intelligent system that must be able to explain its reasoning\nto a human user, or to provide generalizations that the human user finds\nreasonable, it may be useful to take into consideration psychological data on\nwhat types of concepts and categories people naturally use. The psychological\nliterature on concept learning and categorization provides strong evidence that\ncertain categories are more easily learned, recalled, and recognized than\nothers. We show here how a measure of the informational value of a category\npredicts the results of several important categorization experiments better\nthan standard alternative explanations. This suggests that information-based\napproaches to machine generalization may prove particularly useful and natural\nfor human users of the systems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:57:47 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Corter", "James E.", ""], ["Gluck", "Mark A.", ""]]}, {"id": "1304.3442", "submitter": "Samuel Holtzman", "authors": "Samuel Holtzman, John S. Breese", "title": "Exact Reasoning Under Uncertainty", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-208-216", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on designing expert systems to support decision making in\ncomplex, uncertain environments. In this context, our research indicates that\nstrictly probabilistic representations, which enable the use of\ndecision-theoretic reasoning, are highly preferable to recently proposed\nalternatives (e.g., fuzzy set theory and Dempster-Shafer theory). Furthermore,\nwe discuss the language of influence diagrams and a corresponding methodology\n-decision analysis -- that allows decision theory to be used effectively and\nefficiently as a decision-making aid. Finally, we use RACHEL, a system that\nhelps infertile couples select medical treatments, to illustrate the\nmethodology of decision analysis as basis for expert decision systems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:57:53 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Holtzman", "Samuel", ""], ["Breese", "John S.", ""]]}, {"id": "1304.3443", "submitter": "Alf C. Zimmer", "authors": "Alf C. Zimmer", "title": "The Estimation of Subjective Probabilities via Categorical Judgments of\n  Uncertainty", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-217-224", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theoretically as well as experimentally it is investigated how people\nrepresent their knowledge in order to make decisions or to share their\nknowledge with others. Experiment 1 probes into the ways how people 6ather\ninformation about the frequencies of events and how the requested response\nmode, that is, numerical vs. verbal estimates interferes with this knowledge.\nThe least interference occurs if the subjects are allowed to give verbal\nresponses. From this it is concluded that processing knowledge about\nuncertainty categorically, that is, by means of verbal expressions, imposes\nless mental work load on the decision matter than numerical processing.\nPossibility theory is used as a framework for modeling the individual usage of\nverbal categories for grades of uncertainty. The 'elastic' constraints on the\nverbal expressions for every sing1e subject are determined in Experiment 2 by\nmeans of sequential calibration. In further experiments it is shown that the\nsuperiority of the verbal processing of knowledge about uncertainty guise\ngenerally reduces persistent biases reported in the literature: conservatism\n(Experiment 3) and neg1igence of regression (Experiment 4). The reanalysis of\nHormann's data reveal that in verbal Judgments people exhibit sensitivity for\nbase rates and are not prone to the conjunction fallacy. In a final experiment\n(5) about predictions in a real-life situation it turns out that in a numerical\nforecasting task subjects restricted themselves to those parts of their\nknowledge which are numerical. On the other hand subjects in a verbal\nforecasting task accessed verbally as well as numerically stated knowledge.\nForecasting is structurally related to the estimation of probabilities for rare\nevents insofar as supporting and contradicting arguments have to be evaluated\nand the choice of the final Judgment has to be Justified according to the\nevidence brought forward. In order to assist people in such choice situations a\nformal model for the interactive checking of arguments has been developed. The\nmodel transforms the normal-language quantifiers used in the arguments into\nfuzzy numbers and evaluates the given train of arguments by means of fuzzy\nnumerica1 operations. Ambiguities in the meanings of quantifiers are resolved\ninteractively.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:57:59 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Zimmer", "Alf C.", ""]]}, {"id": "1304.3444", "submitter": "Bruce Abramson", "authors": "Bruce Abramson", "title": "A Cure for Pathological Behavior in Games that Use Minimax", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-225-231", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional approach to choosing moves in game-playing programs is the\nminimax procedure. The general belief underlying its use is that increasing\nsearch depth improves play. Recent research has shown that given certain\nsimplifying assumptions about a game tree's structure, this belief is\nerroneous: searching deeper decreases the probability of making a correct move.\nThis phenomenon is called game tree pathology. Among these simplifying\nassumptions is uniform depth of win/loss (terminal) nodes, a condition which is\nnot true for most real games. Analytic studies in [10] have shown that if every\nnode in a pathological game tree is made terminal with probability exceeding a\ncertain threshold, the resulting tree is nonpathological. This paper considers\na new evaluation function which recognizes increasing densities of forced wins\nat deeper levels in the tree. This property raises two points that strengthen\nthe hypothesis that uniform win depth causes pathology. First, it proves\nmathematically that as search deepens, an evaluation function that does not\nexplicitly check for certain forced win patterns becomes decreasingly likely to\nforce wins. This failing predicts the pathological behavior of the original\nevaluation function. Second, it shows empirically that despite recognizing\nfewer mid-game wins than the theoretically predicted minimum, the new function\nis nonpathological.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:58:05 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Abramson", "Bruce", ""]]}, {"id": "1304.3445", "submitter": "Dana Nau", "authors": "Dana Nau, Paul Purdom, Chun-Hung Tzeng", "title": "An Evaluation of Two Alternatives to Minimax", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-232-236", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of Artificial Intelligence, traditional approaches to choosing\nmoves in games involve the we of the minimax algorithm. However, recent\nresearch results indicate that minimizing may not always be the best approach.\nIn this paper we summarize the results of some measurements on several model\ngames with several different evaluation functions. These measurements, which\nare presented in detail in [NPT], show that there are some new algorithms that\ncan make significantly better use of evaluation function values than the\nminimax algorithm does.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:58:11 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Nau", "Dana", ""], ["Purdom", "Paul", ""], ["Tzeng", "Chun-Hung", ""]]}, {"id": "1304.3446", "submitter": "Ross D. Shachter", "authors": "Ross D. Shachter", "title": "Intelligent Probabilistic Inference", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-237-244", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of practical probabilistic models on the computer demands a\nconvenient representation for the available knowledge and an efficient\nalgorithm to perform inference. An appealing representation is the influence\ndiagram, a network that makes explicit the random variables in a model and\ntheir probabilistic dependencies. Recent advances have developed solution\nprocedures based on the influence diagram. In this paper, we examine the\nfundamental properties that underlie those techniques, and the information\nabout the probabilistic structure that is available in the influence diagram\nrepresentation. The influence diagram is a convenient representation for\ncomputer processing while also being clear and non-mathematical. It displays\nprobabilistic dependence precisely, in a way that is intuitive for decision\nmakers and experts to understand and communicate. As a result, the same\ninfluence diagram can be used to build, assess and analyze a model,\nfacilitating changes in the formulation and feedback from sensitivity analysis.\nThe goal in this paper is to determine arbitrary conditional probability\ndistributions from a given probabilistic model. Given qualitative information\nabout the dependence of the random variables in the model we can, for a\nspecific conditional expression, specify precisely what quantitative\ninformation we need to be able to determine the desired conditional probability\ndistribution. It is also shown how we can find that probability distribution by\nperforming operations locally, that is, over subspaces of the joint\ndistribution. In this way, we can exploit the conditional independence present\nin the model to avoid having to construct or manipulate the full joint\ndistribution. These results are extended to include maximal processing when the\ninformation available is incomplete, and optimal decision making in an\nuncertain environment. Influence diagrams as a computer-aided modeling tool\nwere developed by Miller, Merkofer, and Howard [5] and extended by Howard and\nMatheson [2]. Good descriptions of how to use them in modeling are in Owen [7]\nand Howard and Matheson [2]. The notion of solving a decision problem through\ninfluence diagrams was examined by Olmsted [6] and such an algorithm was\ndeveloped by Shachter [8]. The latter paper also shows how influence diagrams\ncan be used to perform a variety of sensitivity analyses. This paper extends\nthose results by developing a theory of the properties of the diagram that are\nused by the algorithm, and the information needed to solve arbitrary\nprobability inference problems. Section 2 develops the notation and the\nframework for the paper and the relationship between influence diagrams and\njoint probability distributions. The general probabilistic inference problem is\nposed in Section 3. In Section 4 the transformations on the diagram are\ndeveloped and then put together into a solution procedure in Section 5. In\nSection 6, this procedure is used to calculate the information requirement to\nsolve an inference problem and the maximal processing that can be performed\nwith incomplete information. Section 7 contains a summary of results.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:58:16 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Shachter", "Ross D.", ""]]}, {"id": "1304.3448", "submitter": "John Fox", "authors": "John Fox", "title": "Strong & Weak Methods: A Logical View of Uncertainty", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-253-257", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last few years has seen a growing debate about techniques for managing\nuncertainty in AI systems. Unfortunately this debate has been cast as a rivalry\nbetween AI methods and classical probability based ones. Three arguments for\nextending the probability framework of uncertainty are presented, none of which\nimply a challenge to classical methods. These are (1) explicit representation\nof several types of uncertainty, specifically possibility and plausibility, as\nwell as probability, (2) the use of weak methods for uncertainty management in\nproblems which are poorly defined, and (3) symbolic representation of different\nuncertainty calculi and methods for choosing between them.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:58:28 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Fox", "John", ""]]}, {"id": "1304.3449", "submitter": "Lester Ingber", "authors": "Lester Ingber", "title": "Statistical Mechanics Algorithm for Response to Targets (SMART)", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-258-264", "categories": "cs.CE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is proposed to apply modern methods of nonlinear nonequilibrium\nstatistical mechanics to develop software algorithms that will optimally\nrespond to targets within short response times with minimal computer resources.\nThis Statistical Mechanics Algorithm for Response to Targets (SMART) can be\ndeveloped with a view towards its future implementation into a hardwired\nStatistical Algorithm Multiprocessor (SAM) to enhance the efficiency and speed\nof response to targets (SMART_SAM).\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:58:34 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Ingber", "Lester", ""]]}, {"id": "1304.3450", "submitter": "Tod S. Levitt", "authors": "Tod S. Levitt", "title": "Probabilistic Conflict Resolution in Hierarchical Hypothesis Spaces", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-265-272", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence applications such as industrial robotics, military\nsurveillance, and hazardous environment clean-up, require situation\nunderstanding based on partial, uncertain, and ambiguous or erroneous evidence.\nIt is necessary to evaluate the relative likelihood of multiple possible\nhypotheses of the (current) situation faced by the decision making program.\nOften, the evidence and hypotheses are hierarchical in nature. In image\nunderstanding tasks, for example, evidence begins with raw imagery, from which\nambiguous features are extracted which have multiple possible aggregations\nproviding evidential support for the presence of multiple hypothesis of objects\nand terrain, which in turn aggregate in multiple ways to provide partial\nevidence for different interpretations of the ambient scene. Information fusion\nfor military situation understanding has a similar evidence/hypothesis\nhierarchy from multiple sensor through message level interpretations, and also\nprovides evidence at multiple levels of the doctrinal hierarchy of military\nforces.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:58:40 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Levitt", "Tod S.", ""]]}, {"id": "1304.3451", "submitter": "Gerald Shao-Hung Liu", "authors": "Gerald Shao-Hung Liu", "title": "Knowledge Structures and Evidential Reasoning in Decision Analysis", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-273-282", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The roles played by decision factors in making complex subject are decisions\nare characterized by how these factors affect the overall decision. Evidence\nthat partially matches a factor is evaluated, and then effective computational\nrules are applied to these roles to form an appropriate aggregation of the\nevidence. The use of this technique supports the expression of deeper levels of\ncausality, and may also preserve the cognitive structure of the decision maker\nbetter than the usual weighting methods, certainty-factor or other\nprobabilistic models can.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:58:46 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Liu", "Gerald Shao-Hung", ""]]}, {"id": "1304.3489", "submitter": "Emad Saad", "authors": "Emad Saad", "title": "Logical Stochastic Optimization", "comments": "arXiv admin note: substantial text overlap with arXiv:1304.2384,\n  arXiv:1304.2797, arXiv:1304.1684, arXiv:1304.3144", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We present a logical framework to represent and reason about stochastic\noptimization problems based on probability answer set programming. This is\nestablished by allowing probability optimization aggregates, e.g., minimum and\nmaximum in the language of probability answer set programming to allow\nminimization or maximization of some desired criteria under the probabilistic\nenvironments. We show the application of the proposed logical stochastic\noptimization framework under the probability answer set programming to two\nstages stochastic optimization problems with recourse.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2013 06:54:24 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Saad", "Emad", ""]]}, {"id": "1304.3733", "submitter": "Diederik Aerts", "authors": "Diederik Aerts and Sandro Sozzo", "title": "General Quantum Hilbert Space Modeling Scheme for Entanglement", "comments": "11 pages. arXiv admin note: text overlap with arXiv:1304.0100", "journal-ref": "Proceedings of the Seventh International Conference on Quantum,\n  Nano and Micro Technologies (pp. 25-31), Eds. V. Ovchinnikov and P. Dini,\n  IARIA, 2013", "doi": null, "report-no": null, "categories": "quant-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We work out a classification scheme for quantum modeling in Hilbert space of\nany kind of composite entity violating Bell's inequalities and exhibiting\nentanglement. Our theoretical framework includes situations with entangled\nstates and product measurements ('customary quantum situation'), and also\nsituations with both entangled states and entangled measurements ('nonlocal box\nsituation', 'nonlocal non-marginal box situation'). We show that entanglement\nis structurally a joint property of states and measurements. Furthermore,\nentangled measurements enable quantum modeling of situations that are usually\nbelieved to be 'beyond quantum'. Our results are also extended from pure states\nto quantum mixtures.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2013 20:33:49 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["Aerts", "Diederik", ""], ["Sozzo", "Sandro", ""]]}, {"id": "1304.3762", "submitter": "Mark Burgin", "authors": "Mark Burgin and Eugene Eberbach", "title": "Evolutionary Turing in the Context of Evolutionary Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the roots of evolutionary computation was the idea of Turing about\nunorganized machines. The goal of this work is the development of foundations\nfor evolutionary computations, connecting Turing's ideas and the contemporary\nstate of art in evolutionary computations. To achieve this goal, we develop a\ngeneral approach to evolutionary processes in the computational context,\nbuilding mathematical models of computational systems, functioning of which is\nbased on evolutionary processes, and studying properties of such systems.\nOperations with evolutionary machines are described and it is explored when\ndefinite classes of evolutionary machines are closed with respect to basic\noperations with these machines. We also study such properties as linguistic and\nfunctional equivalence of evolutionary machines and their classes, as well as\ncomputational power of evolutionary machines and their classes, comparing of\nevolutionary machines to conventional automata, such as finite automata or\nTuring machines.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 02:16:46 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Burgin", "Mark", ""], ["Eberbach", "Eugene", ""]]}, {"id": "1304.3763", "submitter": "M.M.A. Hashem", "authors": "Md. Rakib Hassan, Md. Kamrul Hasan and M.M.A. Hashem", "title": "An Improved ACS Algorithm for the Solutions of Larger TSP Problems", "comments": null, "journal-ref": "Procs. of the 3rd International Conference on Electrical,\n  Electronics and Computer Engineering (ICEECE 2003), pp. 201-206, Dhaka,\n  Bangladesh, December 22-24, (2003)", "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving large traveling salesman problem (TSP) in an efficient way is a\nchallenging area for the researchers of computer science. This paper presents a\nmodified version of the ant colony system (ACS) algorithm called Red-Black Ant\nColony System (RB-ACS) for the solutions of TSP which is the most prominent\nmember of the combinatorial optimization problem. RB-ACS uses the concept of\nant colony system together with the parallel search of genetic algorithm for\nobtaining the optimal solutions quickly. In this paper, it is shown that the\nproposed RB-ACS algorithm yields significantly better performance than the\nexisting best-known algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 02:30:23 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Hassan", "Md. Rakib", ""], ["Hasan", "Md. Kamrul", ""], ["Hashem", "M. M. A.", ""]]}, {"id": "1304.3842", "submitter": "Craig Boutilier", "authors": "Craig Boutilier, Moises Goldszmidt", "title": "Proceedings of the Sixteenth Conference on Uncertainty in Artificial\n  Intelligence (2000)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI2000", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Sixteenth Conference on Uncertainty in\nArtificial Intelligence, which was held in San Francisco, CA, June 30 - July 3,\n2000\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 20:21:00 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 04:11:05 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Boutilier", "Craig", ""], ["Goldszmidt", "Moises", ""]]}, {"id": "1304.3843", "submitter": "Kathryn Laskey", "authors": "Kathryn Laskey, Henri Prade", "title": "Proceedings of the Fifteenth Conference on Uncertainty in Artificial\n  Intelligence (1999)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI1999", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Fifteenth Conference on Uncertainty in\nArtificial Intelligence, which was held in Stockholm Sweden, July 30 - August\n1, 1999\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 20:29:18 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 04:10:01 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Laskey", "Kathryn", ""], ["Prade", "Henri", ""]]}, {"id": "1304.3844", "submitter": "Gregory Cooper", "authors": "Gregory Cooper, Serafin Moral", "title": "Proceedings of the Fourteenth Conference on Uncertainty in Artificial\n  Intelligence (1998)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI1998", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Fourteenth Conference on Uncertainty in\nArtificial Intelligence, which was held in Madison, WI, July 24-26, 1998\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 20:34:30 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 04:08:44 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Cooper", "Gregory", ""], ["Moral", "Serafin", ""]]}, {"id": "1304.3846", "submitter": "Dan Geiger", "authors": "Dan Geiger, Prakash Shenoy", "title": "Proceedings of the Thirteenth Conference on Uncertainty in Artificial\n  Intelligence (1997)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI1997", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Thirteenth Conference on Uncertainty in\nArtificial Intelligence, which was held in Providence, RI, August 1-3, 1997\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 20:44:25 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Geiger", "Dan", ""], ["Shenoy", "Prakash", ""]]}, {"id": "1304.3847", "submitter": "Eric Horvitz", "authors": "Eric Horvitz, Finn Jensen", "title": "Proceedings of the Twelfth Conference on Uncertainty in Artificial\n  Intelligence (1996)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI1996", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Twelfth Conference on Uncertainty in\nArtificial Intelligence, which was held in Portland, OR, August 1-4, 1996\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 20:49:49 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 04:06:12 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Horvitz", "Eric", ""], ["Jensen", "Finn", ""]]}, {"id": "1304.3848", "submitter": "Philippe Besnard", "authors": "Philippe Besnard, Steve Hanks", "title": "Proceedings of the Eleventh Conference on Uncertainty in Artificial\n  Intelligence (1995)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI1995", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Eleventh Conference on Uncertainty in\nArtificial Intelligence, which was held in Montreal, QU, August 18-20, 1995\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 20:53:46 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 04:04:46 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Besnard", "Philippe", ""], ["Hanks", "Steve", ""]]}, {"id": "1304.3849", "submitter": "Ramon Lopez de Mantaras", "authors": "Ramon Lopez de Mantaras, David Poole", "title": "Proceedings of the Tenth Conference on Uncertainty in Artificial\n  Intelligence (1994)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI1994", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Tenth Conference on Uncertainty in Artificial\nIntelligence, which was held in Seattle, WA, July 29-31, 1994\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 20:58:41 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["de Mantaras", "Ramon Lopez", ""], ["Poole", "David", ""]]}, {"id": "1304.3851", "submitter": "David Heckerman", "authors": "David Heckerman, E. Mamdani", "title": "Proceedings of the Ninth Conference on Uncertainty in Artificial\n  Intelligence (1993)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI1993", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Ninth Conference on Uncertainty in Artificial\nIntelligence, which was held in Washington, DC, July 9-11, 1993\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 21:03:12 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Heckerman", "David", ""], ["Mamdani", "E.", ""]]}, {"id": "1304.3852", "submitter": "Bruce D'Ambrosio", "authors": "Bruce D'Ambrosio, Didier Dubois, Philippe Smets, Michael Wellman", "title": "Proceedings of the Eighth Conference on Uncertainty in Artificial\n  Intelligence (1992)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI1992", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Eighth Conference on Uncertainty in Artificial\nIntelligence, which was held in Stanford, CA, July 17-19, 1992\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 21:10:50 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["D'Ambrosio", "Bruce", ""], ["Dubois", "Didier", ""], ["Smets", "Philippe", ""], ["Wellman", "Michael", ""]]}, {"id": "1304.3853", "submitter": "Piero Bonissone", "authors": "Piero Bonissone, Bruce D'Ambrosio, Philippe Smets", "title": "Proceedings of the Seventh Conference on Uncertainty in Artificial\n  Intelligence (1991)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI1991", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Seventh Conference on Uncertainty in\nArtificial Intelligence, which was held in Los Angeles, CA, July 13-15, 1991\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 21:18:04 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Bonissone", "Piero", ""], ["D'Ambrosio", "Bruce", ""], ["Smets", "Philippe", ""]]}, {"id": "1304.3854", "submitter": "Piero Bonissone", "authors": "Piero Bonissone, Max Henrion, Laveen Kanal, John Lemmer", "title": "Proceedings of the Sixth Conference on Uncertainty in Artificial\n  Intelligence (1990)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI1990", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Sixth Conference on Uncertainty in Artificial\nIntelligence, which was held in Cambridge, MA, Jul 27 - Jul 29, 1990\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 21:21:17 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 04:03:18 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Bonissone", "Piero", ""], ["Henrion", "Max", ""], ["Kanal", "Laveen", ""], ["Lemmer", "John", ""]]}, {"id": "1304.3855", "submitter": "Max Henrion", "authors": "Max Henrion, Laveen Kanal, John Lemmer, Ross Shachter", "title": "Proceedings of the Fifth Conference on Uncertainty in Artificial\n  Intelligence (1989)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI1989", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Fifth Conference on Uncertainty in Artificial\nIntelligence, which was held in Windsor, ON, August 18-20, 1989\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 21:26:12 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Henrion", "Max", ""], ["Kanal", "Laveen", ""], ["Lemmer", "John", ""], ["Shachter", "Ross", ""]]}, {"id": "1304.3856", "submitter": "Laveen Kanal", "authors": "Laveen Kanal, John Lemmer, Tod Levitt, Ross Shachter", "title": "Proceedings of the Fourth Conference on Uncertainty in Artificial\n  Intelligence (1988)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI1988", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Fourth Conference on Uncertainty in Artificial\nIntelligence, which was held in Minneapolis, MN, July 10-12, 1988\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 21:30:26 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Kanal", "Laveen", ""], ["Lemmer", "John", ""], ["Levitt", "Tod", ""], ["Shachter", "Ross", ""]]}, {"id": "1304.3857", "submitter": "Laveen Kanal", "authors": "Laveen Kanal, John Lemmer, Tod Levitt", "title": "Proceedings of the Third Conference on Uncertainty in Artificial\n  Intelligence (1987)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI1987", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Third Conference on Uncertainty in Artificial\nIntelligence, which was held in Seattle, WA, July 10-12, 1987\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 21:34:06 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Kanal", "Laveen", ""], ["Lemmer", "John", ""], ["Levitt", "Tod", ""]]}, {"id": "1304.3859", "submitter": "Laveen Kanal", "authors": "Laveen Kanal, John Lemmer", "title": "Proceedings of the Second Conference on Uncertainty in Artificial\n  Intelligence (1986)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI1986", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Second Conference on Uncertainty in Artificial\nIntelligence, which was held in Philadelphia, PA, August 8-10, 1986\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 21:37:12 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Kanal", "Laveen", ""], ["Lemmer", "John", ""]]}, {"id": "1304.3860", "submitter": "Adrian Groza", "authors": "Ioan Alfred Letia and Adrian Groza", "title": "Justificatory and Explanatory Argumentation for Committing Agents", "comments": null, "journal-ref": "ARGMAS 2012", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the interaction between agents we can have an explicative discourse, when\ncommunicating preferences or intentions, and a normative discourse, when\nconsidering normative knowledge. For justifying their actions our agents are\nendowed with a Justification and Explanation Logic (JEL), capable to cover both\nthe justification for their commitments and explanations why they had to act in\nthat way, due to the current situation in the environment. Social commitments\nare used to formalise justificatory and explanatory patterns. The combination\nof ex- planation, justification, and commitments\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 21:51:32 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Letia", "Ioan Alfred", ""], ["Groza", "Adrian", ""]]}, {"id": "1304.3879", "submitter": "Valmi Dufour-Lussier", "authors": "Valmi Dufour-Lussier (INRIA Nancy - Grand Est / LORIA), Florence Le\n  Ber (ICube), Jean Lieber (INRIA Nancy - Grand Est / LORIA), Emmanuel Nauer\n  (INRIA Nancy - Grand Est / LORIA)", "title": "Automatic case acquisition from texts for process-oriented case-based\n  reasoning", "comments": "Sous presse, publication pr\\'evue en 2013", "journal-ref": "Information Systems (2012)", "doi": "10.1016/j.is.2012.11.014", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a method for the automatic acquisition of a rich case\nrepresentation from free text for process-oriented case-based reasoning. Case\nengineering is among the most complicated and costly tasks in implementing a\ncase-based reasoning system. This is especially so for process-oriented\ncase-based reasoning, where more expressive case representations are generally\nused and, in our opinion, actually required for satisfactory case adaptation.\nIn this context, the ability to acquire cases automatically from procedural\ntexts is a major step forward in order to reason on processes. We therefore\ndetail a methodology that makes case acquisition from processes described as\nfree text possible, with special attention given to assembly instruction texts.\nThis methodology extends the techniques we used to extract actions from cooking\nrecipes. We argue that techniques taken from natural language processing are\nrequired for this task, and that they give satisfactory results. An evaluation\nbased on our implemented prototype extracting workflows from recipe texts is\nprovided.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2013 05:52:11 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Dufour-Lussier", "Valmi", "", "INRIA Nancy - Grand Est / LORIA"], ["Ber", "Florence Le", "", "ICube"], ["Lieber", "Jean", "", "INRIA Nancy - Grand Est / LORIA"], ["Nauer", "Emmanuel", "", "INRIA Nancy - Grand Est / LORIA"]]}, {"id": "1304.3940", "submitter": "Antonio Lieto", "authors": "Antonio Lieto and Fabiana Vernero", "title": "Unveiling the link between logical fallacies and web persuasion", "comments": "6 pages, 3 figures, in proceedings of the WebSci'13 Conference,\n  Paris, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade Human-Computer Interaction (HCI) has started to focus\nattention on forms of persuasive interaction where computer technologies have\nthe goal of changing users behavior and attitudes according to a predefined\ndirection. In this work, we hypothesize a strong connection between logical\nfallacies (forms of reasoning which are logically invalid but cognitively\neffective) and some common persuasion strategies adopted within web\ntechnologies. With the aim of empirically evaluating our hypothesis, we carried\nout a pilot study on a sample of 150 e-commerce websites.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2013 19:48:07 GMT"}, {"version": "v2", "created": "Thu, 9 May 2013 10:48:55 GMT"}], "update_date": "2013-05-10", "authors_parsed": [["Lieto", "Antonio", ""], ["Vernero", "Fabiana", ""]]}, {"id": "1304.3999", "submitter": "Bruno Scherrer", "authors": "Matthieu Geist, Bruno Scherrer (INRIA Lorraine - LORIA)", "title": "Off-policy Learning with Eligibility Traces: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the framework of Markov Decision Processes, off-policy learning, that is\nthe problem of learning a linear approximation of the value function of some\nfixed policy from one trajectory possibly generated by some other policy. We\nbriefly review on-policy learning algorithms of the literature (gradient-based\nand least-squares-based), adopting a unified algorithmic view. Then, we\nhighlight a systematic approach for adapting them to off-policy learning with\neligibility traces. This leads to some known algorithms - off-policy\nLSTD(\\lambda), LSPE(\\lambda), TD(\\lambda), TDC/GQ(\\lambda) - and suggests new\nextensions - off-policy FPKF(\\lambda), BRM(\\lambda), gBRM(\\lambda),\nGTD2(\\lambda). We describe a comprehensive algorithmic derivation of all\nalgorithms in a recursive and memory-efficent form, discuss their known\nconvergence properties and illustrate their relative empirical behavior on\nGarnet problems. Our experiments suggest that the most standard algorithms on\nand off-policy LSTD(\\lambda)/LSPE(\\lambda) - and TD(\\lambda) if the feature\nspace dimension is too large for a least-squares approach - perform the best.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2013 06:51:33 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Geist", "Matthieu", "", "INRIA Lorraine - LORIA"], ["Scherrer", "Bruno", "", "INRIA Lorraine - LORIA"]]}, {"id": "1304.4028", "submitter": "M.M.A. Hashem", "authors": "Kawser Wazed Nafi, Tonny Shekha Kar, Amjad Hossain and M.M.A Hashem", "title": "A Fuzzy Logic Based Certain Trust Model for E-Commerce", "comments": "Accepted for the Procs. of the IEEE 2013 International Conference on\n  Informatics, Electronics and Vision (ICIEV 2013), pp.XX-XX, Dhaka,\n  Bangladesh, May 17-18, (2013)", "journal-ref": "Procs. of the IEEE 2013 International Conference on Informatics,\n  Electronics and Vision (ICIEV 2013), pp.XX-XX, Dhaka, Bangladesh, May 17-18,\n  (2013)", "doi": "10.1109/ICIEV.2013.6572693", "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trustworthiness especially for service oriented system is very important\ntopic now a day in IT field of the whole world. There are many successful\nE-commerce organizations presently run in the whole world, but E-commerce has\nnot reached its full potential. The main reason behind this is lack of Trust of\npeople in e-commerce. Again, proper models are still absent for calculating\ntrust of different e-commerce organizations. Most of the present trust models\nare subjective and have failed to account vagueness and ambiguity of different\ndomain. In this paper we have proposed a new fuzzy logic based Certain Trust\nmodel which considers these ambiguity and vagueness of different domain. Fuzzy\nBased Certain Trust Model depends on some certain values given by experts and\ndevelopers. can be applied in a system like cloud computing, internet, website,\ne-commerce, etc. to ensure trustworthiness of these platforms. In this paper we\nshow, although fuzzy works with uncertainties, proposed model works with some\ncertain values. Some experimental results and validation of the model with\nlinguistics terms are shown at the last part of the paper.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2013 09:28:46 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Nafi", "Kawser Wazed", ""], ["Kar", "Tonny Shekha", ""], ["Hossain", "Amjad", ""], ["Hashem", "M. M. A", ""]]}, {"id": "1304.4182", "submitter": "Laveen Kanal", "authors": "Laveen Kanal, John Lemmer", "title": "Proceedings of the First Conference on Uncertainty in Artificial\n  Intelligence (1985)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI1985", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the First Conference on Uncertainty in Artificial\nIntelligence, which was held in Los Angeles, CA, July 10-12, 1985\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2013 17:35:22 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 03:59:55 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Kanal", "Laveen", ""], ["Lemmer", "John", ""]]}, {"id": "1304.4371", "submitter": "Joel Lang", "authors": "Joel Lang and James Henderson", "title": "Efficient Computation of Mean Truncated Hitting Times on Very Large\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work has shown the effectiveness of random walk hitting times as a\nmeasure of dissimilarity in a variety of graph-based learning problems such as\ncollaborative filtering, query suggestion or finding paraphrases. However,\napplication of hitting times has been limited to small datasets because of\ncomputational restrictions. This paper develops a new approximation algorithm\nwith which hitting times can be computed on very large, disk-resident graphs,\nmaking their application possible to problems which were previously out of\nreach. This will potentially benefit a range of large-scale problems.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2013 09:11:16 GMT"}], "update_date": "2013-04-17", "authors_parsed": [["Lang", "Joel", ""], ["Henderson", "James", ""]]}, {"id": "1304.4379", "submitter": "Jan Noessner", "authors": "Jan Noessner, Mathias Niepert, Heiner Stuckenschmidt", "title": "RockIt: Exploiting Parallelism and Symmetry for MAP Inference in\n  Statistical Relational Models", "comments": "To appear in proceedings of AAAI 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RockIt is a maximum a-posteriori (MAP) query engine for statistical\nrelational models. MAP inference in graphical models is an optimization problem\nwhich can be compiled to integer linear programs (ILPs). We describe several\nadvances in translating MAP queries to ILP instances and present the novel\nmeta-algorithm cutting plane aggregation (CPA). CPA exploits local\ncontext-specific symmetries and bundles up sets of linear constraints. The\nresulting counting constraints lead to more compact ILPs and make the symmetry\nof the ground model more explicit to state-of-the-art ILP solvers. Moreover,\nRockIt parallelizes most parts of the MAP inference pipeline taking advantage\nof ubiquitous shared-memory multi-core architectures.\n  We report on extensive experiments with Markov logic network (MLN) benchmarks\nshowing that RockIt outperforms the state-of-the-art systems Alchemy, Markov\nTheBeast, and Tuffy both in terms of efficiency and quality of results.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2013 09:29:58 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2013 10:19:58 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Noessner", "Jan", ""], ["Niepert", "Mathias", ""], ["Stuckenschmidt", "Heiner", ""]]}, {"id": "1304.4415", "submitter": "Lakhdar Sais", "authors": "Said Jabbour and Lakhdar Sais and Yakoub Salhi", "title": "Mining to Compact CNF Propositional Formulae", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a first application of data mining techniques to\npropositional satisfiability. Our proposed Mining4SAT approach aims to discover\nand to exploit hidden structural knowledge for reducing the size of\npropositional formulae in conjunctive normal form (CNF). Mining4SAT combines\nboth frequent itemset mining techniques and Tseitin's encoding for a compact\nrepresentation of CNF formulae. The experiments of our Mining4SAT approach show\ninteresting reductions of the sizes of many application instances taken from\nthe last SAT competitions.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2013 12:26:41 GMT"}], "update_date": "2013-04-17", "authors_parsed": [["Jabbour", "Said", ""], ["Sais", "Lakhdar", ""], ["Salhi", "Yakoub", ""]]}, {"id": "1304.4910", "submitter": "Divyanshu Vats", "authors": "Divyanshu Vats and Robert Nowak", "title": "A Junction Tree Framework for Undirected Graphical Model Selection", "comments": "This paper will appear in the Journal of Machine Learning Research\n  (JMLR). See http://www.ima.umn.edu/~dvats/JunctionTreeUGMS.html for code", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An undirected graphical model is a joint probability distribution defined on\nan undirected graph G*, where the vertices in the graph index a collection of\nrandom variables and the edges encode conditional independence relationships\namong random variables. The undirected graphical model selection (UGMS) problem\nis to estimate the graph G* given observations drawn from the undirected\ngraphical model. This paper proposes a framework for decomposing the UGMS\nproblem into multiple subproblems over clusters and subsets of the separators\nin a junction tree. The junction tree is constructed using a graph that\ncontains a superset of the edges in G*. We highlight three main properties of\nusing junction trees for UGMS. First, different regularization parameters or\ndifferent UGMS algorithms can be used to learn different parts of the graph.\nThis is possible since the subproblems we identify can be solved independently\nof each other. Second, under certain conditions, a junction tree based UGMS\nalgorithm can produce consistent results with fewer observations than the usual\nrequirements of existing algorithms. Third, both our theoretical and\nexperimental results show that the junction tree framework does a significantly\nbetter job at finding the weakest edges in a graph than existing methods. This\nproperty is a consequence of both the first and second properties. Finally, we\nnote that our framework is independent of the choice of the UGMS algorithm and\ncan be used as a wrapper around standard UGMS algorithms for more accurate\ngraph estimation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2013 18:29:06 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2013 17:30:46 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Vats", "Divyanshu", ""], ["Nowak", "Robert", ""]]}, {"id": "1304.4925", "submitter": "Manfred Eppe", "authors": "Manfred Eppe, Mehul Bhatt, Frank Dylla", "title": "h-approximation: History-Based Approximation of Possible World Semantics\n  as ASP", "comments": "12th International Conference on Logic Programming and Nonmonotonic\n  Reasoning (LPNMR 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approximation of the Possible Worlds Semantics (PWS) for action\nplanning. A corresponding planning system is implemented by a transformation of\nthe action specification to an Answer-Set Program. A novelty is support for\npostdiction wrt. (a) the plan existence problem in our framework can be solved\nin NP, as compared to $\\Sigma_2^P$ for non-approximated PWS of Baral(2000); and\n(b) the planner generates optimal plans wrt. a minimal number of actions in\n$\\Delta_2^P$. We demo the planning system with standard problems, and\nillustrate its integration in a larger software framework for robot control in\na smart home.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2013 19:28:42 GMT"}, {"version": "v2", "created": "Wed, 22 May 2013 18:14:53 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2013 10:42:46 GMT"}, {"version": "v4", "created": "Fri, 14 Jun 2013 12:24:13 GMT"}], "update_date": "2013-06-17", "authors_parsed": [["Eppe", "Manfred", ""], ["Bhatt", "Mehul", ""], ["Dylla", "Frank", ""]]}, {"id": "1304.4965", "submitter": "Mark Levin", "authors": "Mark Sh. Levin", "title": "Improvement/Extension of Modular Systems as Combinatorial Reengineering\n  (Survey)", "comments": "24 pages, 28 figures, 14 tables. arXiv admin note: text overlap with\n  arXiv:1212.1735", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes development (improvement/extension) approaches for\ncomposite (modular) systems (as combinatorial reengineering). The following\nsystem improvement/extension actions are considered: (a) improvement of systems\ncomponent(s) (e.g., improvement of a system component, replacement of a system\ncomponent); (b) improvement of system component interconnection\n(compatibility); (c) joint improvement improvement of system components(s) and\ntheir interconnection; (d) improvement of system structure (replacement of\nsystem part(s), addition of a system part, deletion of a system part,\nmodification of system structure). The study of system improvement approaches\ninvolve some crucial issues: (i) scales for evaluation of system components and\ncomponent compatibility (quantitative scale, ordinal scale, poset-like scale,\nscale based on interval multiset estimate), (ii) evaluation of integrated\nsystem quality, (iii) integration methods to obtain the integrated system\nquality. The system improvement/extension strategies can be examined as\nseleciton/combination of the improvement action(s) above and as modification of\nsystem structure. The strategies are based on combinatorial optimization\nproblems (e.g., multicriteria selection, knapsack problem, multiple choice\nproblem, combinatorial synthesis based on morphological clique problem,\nassignment/reassignment problem, graph recoloring problem, spanning problems,\nhotlink assignment). Here, heuristics are used. Various system\nimprovement/extension strategies are presented including illustrative numerical\nexamples.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2013 20:41:05 GMT"}], "update_date": "2013-04-19", "authors_parsed": [["Levin", "Mark Sh.", ""]]}, {"id": "1304.5051", "submitter": "Arnab Bhattacharya", "authors": "Shubhadip Mitra, Partha Dutta, Arnab Bhattacharya", "title": "Constraint Satisfaction over Generalized Staircase Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key research interests in the area of Constraint Satisfaction\nProblem (CSP) is to identify tractable classes of constraints and develop\nefficient solutions for them. In this paper, we introduce generalized staircase\n(GS) constraints which is an important generalization of one such tractable\nclass found in the literature, namely, staircase constraints. GS constraints\nare of two kinds, down staircase (DS) and up staircase (US). We first examine\nseveral properties of GS constraints, and then show that arc consistency is\nsufficient to determine a solution to a CSP over DS constraints. Further, we\npropose an optimal O(cd) time and space algorithm to compute arc consistency\nfor GS constraints where c is the number of constraints and d is the size of\nthe largest domain. Next, observing that arc consistency is not necessary for\nsolving a DSCSP, we propose a more efficient algorithm for solving it. With\nregard to US constraints, arc consistency is not known to be sufficient to\ndetermine a solution, and therefore, methods such as path consistency or\nvariable elimination are required. Since arc consistency acts as a subroutine\nfor these existing methods, replacing it by our optimal O(cd) arc consistency\nalgorithm produces a more efficient method for solving a USCSP.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2013 08:42:22 GMT"}], "update_date": "2013-04-19", "authors_parsed": [["Mitra", "Shubhadip", ""], ["Dutta", "Partha", ""], ["Bhattacharya", "Arnab", ""]]}, {"id": "1304.5159", "submitter": "Trong Nghia Hoang", "authors": "Trong Nghia Hoang, Kian Hsiang Low", "title": "Interactive POMDP Lite: Towards Practical Planning to Predict and\n  Exploit Intentions for Interacting with Self-Interested Agents", "comments": "23rd International Joint Conference on Artificial Intelligence (IJCAI\n  2013), Extended version with proofs, 24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in non-cooperative multi-agent systems is that of developing\nefficient planning algorithms for intelligent agents to interact and perform\neffectively among boundedly rational, self-interested agents (e.g., humans).\nThe practicality of existing works addressing this challenge is being\nundermined due to either the restrictive assumptions of the other agents'\nbehavior, the failure in accounting for their rationality, or the prohibitively\nexpensive cost of modeling and predicting their intentions. To boost the\npracticality of research in this field, we investigate how intention prediction\ncan be efficiently exploited and made practical in planning, thereby leading to\nefficient intention-aware planning frameworks capable of predicting the\nintentions of other agents and acting optimally with respect to their predicted\nintentions. We show that the performance losses incurred by the resulting\nplanning policies are linearly bounded by the error of intention prediction.\nEmpirical evaluations through a series of stochastic games demonstrate that our\npolicies can achieve better and more robust performance than the\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2013 15:11:25 GMT"}], "update_date": "2013-04-19", "authors_parsed": [["Hoang", "Trong Nghia", ""], ["Low", "Kian Hsiang", ""]]}, {"id": "1304.5185", "submitter": "Roman Kontchakov", "authors": "Alessandro Artale and Roman Kontchakov and Frank Wolter and Michael\n  Zakharyaschev", "title": "Temporal Description Logic for Ontology-Based Data Access (Extended\n  Version)", "comments": "Full version of the IJCAI 2013 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our aim is to investigate ontology-based data access over temporal data with\nvalidity time and ontologies capable of temporal conceptual modelling. To this\nend, we design a temporal description logic, TQL, that extends the standard\nontology language OWL 2 QL, provides basic means for temporal conceptual\nmodelling and ensures first-order rewritability of conjunctive queries for\nsuitably defined data instances with validity time.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2013 16:50:16 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2013 18:27:41 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Artale", "Alessandro", ""], ["Kontchakov", "Roman", ""], ["Wolter", "Frank", ""], ["Zakharyaschev", "Michael", ""]]}, {"id": "1304.5409", "submitter": "Carsten Gottschlich", "authors": "Carsten Gottschlich and Stephan Huckemann", "title": "Separating the Real from the Synthetic: Minutiae Histograms as\n  Fingerprints of Fingerprints", "comments": null, "journal-ref": "IET Biometrics, vol. 3, no. 4, pp. 291-301, Dec. 2014", "doi": "10.1049/iet-bmt.2013.0065", "report-no": null, "categories": "cs.CV cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we show that by the current state-of-the-art synthetically\ngenerated fingerprints can easily be discriminated from real fingerprints. We\npropose a method based on second order extended minutiae histograms (MHs) which\ncan distinguish between real and synthetic prints with very high accuracy. MHs\nprovide a fixed-length feature vector for a fingerprint which are invariant\nunder rotation and translation. This 'test of realness' can be applied to\nsynthetic fingerprints produced by any method. In this work, tests are\nconducted on the 12 publicly available databases of FVC2000, FVC2002 and\nFVC2004 which are well established benchmarks for evaluating the performance of\nfingerprint recognition algorithms; 3 of these 12 databases consist of\nartificial fingerprints generated by the SFinGe software. Additionally, we\nevaluate the discriminative performance on a database of synthetic fingerprints\ngenerated by the software of Bicz versus real fingerprint images. We conclude\nwith suggestions for the improvement of synthetic fingerprint generation.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2013 13:21:13 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2014 11:28:08 GMT"}, {"version": "v3", "created": "Wed, 15 Oct 2014 14:04:46 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Gottschlich", "Carsten", ""], ["Huckemann", "Stephan", ""]]}, {"id": "1304.5449", "submitter": "Christophe Lecoutre", "authors": "Christophe Lecoutre and Nicolas Paris and Olivier Roussel and\n  S\\'ebastien Tabary", "title": "Solving WCSP by Extraction of Minimal Unsatisfiable Cores", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usual techniques to solve WCSP are based on cost transfer operations coupled\nwith a branch and bound algorithm. In this paper, we focus on an approach\nintegrating extraction and relaxation of Minimal Unsatisfiable Cores in order\nto solve this problem. We decline our approach in two ways: an incomplete,\ngreedy, algorithm and a complete one.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2013 15:36:53 GMT"}], "update_date": "2013-04-22", "authors_parsed": [["Lecoutre", "Christophe", ""], ["Paris", "Nicolas", ""], ["Roussel", "Olivier", ""], ["Tabary", "S\u00e9bastien", ""]]}, {"id": "1304.5479", "submitter": "Ronald de Haan", "authors": "Ronald de Haan, Iyad Kanj, Stefan Szeider", "title": "Local Backbones", "comments": "A previous version appeared in the proceedings of the 16th\n  International Conference on Theory and Applications of Satisfiability Testing\n  (SAT 2013)", "journal-ref": "Proceedings of SAT 2013, LNCS 7962, pp. 377-393, 2013", "doi": "10.1007/978-3-642-39071-5_28", "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A backbone of a propositional CNF formula is a variable whose truth value is\nthe same in every truth assignment that satisfies the formula. The notion of\nbackbones for CNF formulas has been studied in various contexts. In this paper,\nwe introduce local variants of backbones, and study the computational\ncomplexity of detecting them. In particular, we consider k-backbones, which are\nbackbones for sub-formulas consisting of at most k clauses, and iterative\nk-backbones, which are backbones that result after repeated instantiations of\nk-backbones. We determine the parameterized complexity of deciding whether a\nvariable is a k-backbone or an iterative k-backbone for various restricted\nformula classes, including Horn, definite Horn, and Krom. We also present some\nfirst empirical results regarding backbones for CNF-Satisfiability (SAT). The\nempirical results we obtain show that a large fraction of the backbones of\nstructured SAT instances are local, in contrast to random instances, which\nappear to have few local backbones.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2013 16:59:11 GMT"}, {"version": "v2", "created": "Thu, 23 May 2013 14:23:29 GMT"}, {"version": "v3", "created": "Fri, 18 Jul 2014 14:54:29 GMT"}], "update_date": "2014-07-21", "authors_parsed": [["de Haan", "Ronald", ""], ["Kanj", "Iyad", ""], ["Szeider", "Stefan", ""]]}, {"id": "1304.5530", "submitter": "Rachael  Tappenden Dr", "authors": "Rachael Tappenden and Peter Richt\\'arik and Jacek Gondzio", "title": "Inexact Coordinate Descent: Complexity and Preconditioning", "comments": "32 pages, 6 tables, 2 figures, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of minimizing a convex function using a\nrandomized block coordinate descent method. One of the key steps at each\niteration of the algorithm is determining the update to a block of variables.\nExisting algorithms assume that in order to compute the update, a particular\nsubproblem is solved exactly. In his work we relax this requirement, and allow\nfor the subproblem to be solved inexactly, leading to an inexact block\ncoordinate descent method. Our approach incorporates the best known results for\nexact updates as a special case. Moreover, these theoretical guarantees are\ncomplemented by practical considerations: the use of iterative techniques to\ndetermine the update as well as the use of preconditioning for further\nacceleration.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2013 20:02:04 GMT"}, {"version": "v2", "created": "Wed, 10 Dec 2014 17:10:49 GMT"}], "update_date": "2014-12-11", "authors_parsed": [["Tappenden", "Rachael", ""], ["Richt\u00e1rik", "Peter", ""], ["Gondzio", "Jacek", ""]]}, {"id": "1304.5550", "submitter": "Adrian Groza", "authors": "Adrian Groza, Gabriel Barbur, Bogdan Blaga", "title": "OntoRich - A Support Tool for Semi-Automatic Ontology Enrichment and\n  Evaluation", "comments": "ACAM 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the OntoRich framework, a support tool for semi-automatic\nontology enrichment and evaluation. The WordNet is used to extract candidates\nfor dynamic ontology enrichment from RSS streams. With the integration of\nOpenNLP the system gains access to syntactic analysis of the RSS news. The\nenriched ontologies are evaluated against several qualitative metrics.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2013 21:17:19 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Groza", "Adrian", ""], ["Barbur", "Gabriel", ""], ["Blaga", "Bogdan", ""]]}, {"id": "1304.5554", "submitter": "Adrian Groza", "authors": "Adrian Groza and Sergiu Indrie", "title": "Enacting Social Argumentative Machines in Semantic Wikipedia", "comments": "UBICC 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research advocates the idea of combining argumentation theory with the\nsocial web technology, aiming to enact large scale or mass argumentation. The\nproposed framework allows mass-collaborative editing of structured arguments in\nthe style of semantic wikipedia. The long term goal is to apply the abstract\nmachinery of argumentation theory to more practical applications based on human\ngenerated arguments, such as deliberative democracy, business negotiation, or\nself-care. The ARGNET system was developed based on ther Semantic MediaWiki\nframework and on the Argument Interchange Format (AIF) ontology.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2013 21:36:59 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Groza", "Adrian", ""], ["Indrie", "Sergiu", ""]]}, {"id": "1304.5566", "submitter": "Michael Cotterell", "authors": "Michael E. Cotterell, Terrance Medina", "title": "A Markov Model for Ontology Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosion of available data along with the need to integrate and utilize\nthat data has led to a pressing interest in data integration techniques. In\nterms of Semantic Web technologies, Ontology Alignment is a key step in the\nprocess of integrating heterogeneous knowledge bases. In this paper, we present\nthe Edge Confidence technique, a modification and improvement over the popular\nSimilarity Flooding technique for Ontology Alignment.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2013 00:25:50 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Cotterell", "Michael E.", ""], ["Medina", "Terrance", ""]]}, {"id": "1304.5610", "submitter": "Bruno Scherrer", "authors": "Boris Lesner (INRIA Nancy - Grand Est / LORIA), Bruno Scherrer (INRIA\n  Nancy - Grand Est / LORIA)", "title": "Tight Performance Bounds for Approximate Modified Policy Iteration with\n  Non-Stationary Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider approximate dynamic programming for the infinite-horizon\nstationary $\\gamma$-discounted optimal control problem formalized by Markov\nDecision Processes. While in the exact case it is known that there always\nexists an optimal policy that is stationary, we show that when using value\nfunction approximation, looking for a non-stationary policy may lead to a\nbetter performance guarantee. We define a non-stationary variant of MPI that\nunifies a broad family of approximate DP algorithms of the literature. For this\nalgorithm we provide an error propagation analysis in the form of a performance\nbound of the resulting policies that can improve the usual performance bound by\na factor $O(1-\\gamma)$, which is significant when the discount factor $\\gamma$\nis close to 1. Doing so, our approach unifies recent results for Value and\nPolicy Iteration. Furthermore, we show, by constructing a specific\ndeterministic MDP, that our performance guarantee is tight.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2013 08:45:37 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Lesner", "Boris", "", "INRIA Nancy - Grand Est / LORIA"], ["Scherrer", "Bruno", "", "INRIA\n  Nancy - Grand Est / LORIA"]]}, {"id": "1304.5705", "submitter": "Rajendra Bera", "authors": "Rajendra K. Bera", "title": "A novice looks at emotional cognition", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling emotional-cognition is in a nascent stage and therefore wide-open\nfor new ideas and discussions. In this paper the author looks at the modeling\nproblem by bringing in ideas from axiomatic mathematics, information theory,\ncomputer science, molecular biology, non-linear dynamical systems and quantum\ncomputing and explains how ideas from these disciplines may have applications\nin modeling emotional-cognition.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2013 08:08:38 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Bera", "Rajendra K.", ""]]}, {"id": "1304.5810", "submitter": "Marcelo Arenas", "authors": "Marcelo Arenas, Elena Botoeva, Diego Calvanese, and Vladislav Ryzhikov", "title": "Exchanging OWL 2 QL Knowledge Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge base exchange is an important problem in the area of data exchange\nand knowledge representation, where one is interested in exchanging information\nbetween a source and a target knowledge base connected through a mapping. In\nthis paper, we study this fundamental problem for knowledge bases and mappings\nexpressed in OWL 2 QL, the profile of OWL 2 based on the description logic\nDL-Lite_R. More specifically, we consider the problem of computing universal\nsolutions, identified as one of the most desirable translations to be\nmaterialized, and the problem of computing UCQ-representations, which optimally\ncapture in a target TBox the information that can be extracted from a source\nTBox and a mapping by means of unions of conjunctive queries. For the former we\nprovide a novel automata-theoretic technique, and complexity results that range\nfrom NP to EXPTIME, while for the latter we show NLOGSPACE-completeness.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2013 23:03:06 GMT"}, {"version": "v2", "created": "Fri, 3 May 2013 12:05:57 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2013 21:10:21 GMT"}], "update_date": "2013-07-03", "authors_parsed": [["Arenas", "Marcelo", ""], ["Botoeva", "Elena", ""], ["Calvanese", "Diego", ""], ["Ryzhikov", "Vladislav", ""]]}, {"id": "1304.5822", "submitter": "Satyen Kale", "authors": "Arpita Ghosh, Satyen Kale, Kevin Lang, Benjamin Moseley", "title": "Bargaining for Revenue Shares on Tree Trading Networks", "comments": "An extended abstract of this paper appears in Proceedings of IJCAI\n  2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study trade networks with a tree structure, where a seller with a single\nindivisible good is connected to buyers, each with some value for the good, via\na unique path of intermediaries. Agents in the tree make multiplicative revenue\nshare offers to their parent nodes, who choose the best offer and offer part of\nit to their parent, and so on; the winning path is determined by who finally\nmakes the highest offer to the seller. In this paper, we investigate how these\nrevenue shares might be set via a natural bargaining process between agents on\nthe tree, specifically, egalitarian bargaining between endpoints of each edge\nin the tree. We investigate the fixed point of this system of bargaining\nequations and prove various desirable for this solution concept, including (i)\nexistence, (ii) uniqueness, (iii) efficiency, (iv) membership in the core, (v)\nstrict monotonicity, (vi) polynomial-time computability to any given accuracy.\nFinally, we present numerical evidence that asynchronous dynamics with randomly\nordered updates always converges to the fixed point, indicating that the fixed\npoint shares might arise from decentralized bargaining amongst agents on the\ntrade network.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 01:28:33 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Ghosh", "Arpita", ""], ["Kale", "Satyen", ""], ["Lang", "Kevin", ""], ["Moseley", "Benjamin", ""]]}, {"id": "1304.5863", "submitter": "Dimitrios Diochnos", "authors": "Dimitrios I. Diochnos", "title": "Commonsense Reasoning and Large Network Analysis: A Computational Study\n  of ConceptNet 4", "comments": "152 pages, 99 tables, 23 figures (76 sub-figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report a computational study of ConceptNet 4 is performed using tools\nfrom the field of network analysis. Part I describes the process of extracting\nthe data from the SQL database that is available online, as well as how the\nclosure of the input among the assertions in the English language is computed.\nThis part also performs a validation of the input as well as checks for the\nconsistency of the entire database. Part II investigates the structural\nproperties of ConceptNet 4. Different graphs are induced from the knowledge\nbase by fixing different parameters. The degrees and the degree distributions\nare examined, the number and sizes of connected components, the transitivity\nand clustering coefficient, the cores, information related to shortest paths in\nthe graphs, and cliques. Part III investigates non-overlapping, as well as\noverlapping communities that are found in ConceptNet 4. Finally, Part IV\ndescribes an investigation on rules.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 07:45:22 GMT"}, {"version": "v2", "created": "Sun, 23 Jun 2013 23:05:51 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Diochnos", "Dimitrios I.", ""]]}, {"id": "1304.5892", "submitter": "Toby Walsh", "authors": "Thomas Kalinowski and Nina Nardoytska and Toby Walsh", "title": "A Social Welfare Optimal Sequential Allocation Procedure", "comments": "To appear in the Proceedings of IJCAI 2013, International Joint\n  Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a simple sequential allocation procedure for sharing indivisible\nitems between agents in which agents take turns to pick items. Supposing\nadditive utilities and independence between the agents, we show that the\nexpected utility of each agent is computable in polynomial time. Using this\nresult, we prove that the expected utilitarian social welfare is maximized when\nagents take alternate turns. We also argue that this mechanism remains optimal\nwhen agents behave strategically\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 09:38:56 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2013 02:05:17 GMT"}], "update_date": "2013-04-24", "authors_parsed": [["Kalinowski", "Thomas", ""], ["Nardoytska", "Nina", ""], ["Walsh", "Toby", ""]]}, {"id": "1304.5897", "submitter": "Isis Truck", "authors": "Mohammed-Amine Abchir and Isis Truck", "title": "Towards an Extension of the 2-tuple Linguistic Model to Deal With\n  Unbalanced Linguistic Term sets", "comments": null, "journal-ref": "Kybernetika, 2013", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the domain of Computing with words (CW), fuzzy linguistic approaches are\nknown to be relevant in many decision-making problems. Indeed, they allow us to\nmodel the human reasoning in replacing words, assessments, preferences,\nchoices, wishes... by ad hoc variables, such as fuzzy sets or more\nsophisticated variables.\n  This paper focuses on a particular model: Herrera & Martinez' 2-tuple\nlinguistic model and their approach to deal with unbalanced linguistic term\nsets. It is interesting since the computations are accomplished without loss of\ninformation while the results of the decision-making processes always refer to\nthe initial linguistic term set. They propose a fuzzy partition which\ndistributes data on the axis by using linguistic hierarchies to manage the\nnon-uniformity. However, the required input (especially the density around the\nterms) taken by their fuzzy partition algorithm may be considered as too much\ndemanding in a real-world application, since density is not always easy to\ndetermine. Moreover, in some limit cases (especially when two terms are very\nclosed semantically to each other), the partition doesn't comply with the data\nthemselves, it isn't close to the reality. Therefore we propose to modify the\nrequired input, in order to offer a simpler and more faithful partition. We\nhave added an extension to the package jFuzzyLogic and to the corresponding\nscript language FCL. This extension supports both 2-tuple models: Herrera &\nMartinez' and ours. In addition to the partition algorithm, we present two\naggregation algorithms: the arithmetic means and the addition. We also discuss\nthese kinds of 2-tuple models.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 09:54:07 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Abchir", "Mohammed-Amine", ""], ["Truck", "Isis", ""]]}, {"id": "1304.5961", "submitter": "Andreas Pfandler", "authors": "Andreas Pfandler, Stefan R\\\"ummele, Stefan Szeider", "title": "Backdoors to Abduction", "comments": "12 pages, a short version will appear in the proceedings of the 23rd\n  International Joint Conference on Artificial Intelligence (IJCAI 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abductive reasoning (or Abduction, for short) is among the most fundamental\nAI reasoning methods, with a broad range of applications, including fault\ndiagnosis, belief revision, and automated planning. Unfortunately, Abduction is\nof high computational complexity; even propositional Abduction is\n\\Sigma_2^P-complete and thus harder than NP and coNP. This complexity barrier\nrules out the existence of a polynomial transformation to propositional\nsatisfiability (SAT). In this work we use structural properties of the\nAbduction instance to break this complexity barrier. We utilize the problem\nstructure in terms of small backdoor sets. We present fixed-parameter tractable\ntransformations from Abduction to SAT, which make the power of today's SAT\nsolvers available to Abduction.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 14:23:11 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Pfandler", "Andreas", ""], ["R\u00fcmmele", "Stefan", ""], ["Szeider", "Stefan", ""]]}, {"id": "1304.5970", "submitter": "Thierry  Petit", "authors": "Nina Narodytska, Thierry Petit, Mohamed Siala and Toby Walsh", "title": "Three Generalizations of the FOCUS Constraint", "comments": null, "journal-ref": "IJCAI 2013 proceedings", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The FOCUS constraint expresses the notion that solutions are concentrated. In\npractice, this constraint suffers from the rigidity of its semantics. To tackle\nthis issue, we propose three generalizations of the FOCUS constraint. We\nprovide for each one a complete filtering algorithm as well as discussing\ndecompositions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 14:48:58 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Narodytska", "Nina", ""], ["Petit", "Thierry", ""], ["Siala", "Mohamed", ""], ["Walsh", "Toby", ""]]}, {"id": "1304.6078", "submitter": "Adrian Groza", "authors": "Ioan Alfred Letia and Adrian Groza", "title": "Automating the Dispute Resolution in Task Dependency Network", "comments": "IAT 2005. arXiv admin note: substantial text overlap with\n  arXiv:1304.5545", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When perturbation or unexpected events do occur, agents need protocols for\nrepairing or reforming the supply chain. Unfortunate contingency could increase\ntoo much the cost of performance, while breaching the current contract may be\nmore efficient. In our framework the principles of contract law are applied to\nset penalties: expectation damages, opportunity cost, reliance damages, and\nparty design remedies, and they are introduced in the task dependency model\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2013 21:47:03 GMT"}], "update_date": "2013-04-24", "authors_parsed": [["Letia", "Ioan Alfred", ""], ["Groza", "Adrian", ""]]}, {"id": "1304.6174", "submitter": "Nicholas Mattei", "authors": "Nicholas Mattei, Nina Narodytska, and Toby Walsh", "title": "How Hard Is It to Control an Election by Breaking Ties?", "comments": "Revised and expanded version including longer proofs and additional\n  results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of controlling the result of an\nelection by breaking ties strategically. This problem is equivalent to the\nproblem of deciding the winner of an election under parallel universes\ntie-breaking. When the chair of the election is only asked to break ties to\nchoose between one of the co-winners, the problem is trivially easy. However,\nin multi-round elections, we prove that it can be NP-hard for the chair to\ncompute how to break ties to ensure a given result. Additionally, we show that\nthe form of the tie-breaking function can increase the opportunities for\ncontrol. Indeed, we prove that it can be NP-hard to control an election by\nbreaking ties even with a two-stage voting rule.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2013 05:58:29 GMT"}, {"version": "v2", "created": "Thu, 29 May 2014 04:48:08 GMT"}], "update_date": "2014-05-30", "authors_parsed": [["Mattei", "Nicholas", ""], ["Narodytska", "Nina", ""], ["Walsh", "Toby", ""]]}, {"id": "1304.6383", "submitter": "Constantinos Panagiotakopoulos", "authors": "Constantinos Panagiotakopoulos and Petroula Tsampouka", "title": "The Stochastic Gradient Descent for the Primal L1-SVM Optimization\n  Revisited", "comments": "In v2 the numerical results are obtained using the latest release 1.7\n  of Cygwin and the g++ compiler version 4.5.3. We also consider in the\n  experiments the algorithms SvmSgd and SGD-QN. A slightly shorter version of\n  this paper appeared in ECML/PKDD 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reconsider the stochastic (sub)gradient approach to the unconstrained\nprimal L1-SVM optimization. We observe that if the learning rate is inversely\nproportional to the number of steps, i.e., the number of times any training\npattern is presented to the algorithm, the update rule may be transformed into\nthe one of the classical perceptron with margin in which the margin threshold\nincreases linearly with the number of steps. Moreover, if we cycle repeatedly\nthrough the possibly randomly permuted training set the dual variables defined\nnaturally via the expansion of the weight vector as a linear combination of the\npatterns on which margin errors were made are shown to obey at the end of each\ncomplete cycle automatically the box constraints arising in dual optimization.\nThis renders the dual Lagrangian a running lower bound on the primal objective\ntending to it at the optimum and makes available an upper bound on the relative\naccuracy achieved which provides a meaningful stopping criterion. In addition,\nwe propose a mechanism of presenting the same pattern repeatedly to the\nalgorithm which maintains the above properties. Finally, we give experimental\nevidence that algorithms constructed along these lines exhibit a considerably\nimproved performance.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2013 19:24:02 GMT"}, {"version": "v2", "created": "Sat, 25 Jan 2014 10:46:53 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Panagiotakopoulos", "Constantinos", ""], ["Tsampouka", "Petroula", ""]]}, {"id": "1304.6442", "submitter": "Marco Montali", "authors": "Diego Calvanese, Evgeny Kharlamov, Marco Montali, Ario Santoso,\n  Dmitriy Zheleznyakov", "title": "Verification of Inconsistency-Aware Knowledge and Action Bases (Extended\n  Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Description Logic Knowledge and Action Bases (KABs) have been recently\nintroduced as a mechanism that provides a semantically rich representation of\nthe information on the domain of interest in terms of a DL KB and a set of\nactions to change such information over time, possibly introducing new objects.\nIn this setting, decidability of verification of sophisticated temporal\nproperties over KABs, expressed in a variant of first-order mu-calculus, has\nbeen shown. However, the established framework treats inconsistency in a\nsimplistic way, by rejecting inconsistent states produced through action\nexecution. We address this problem by showing how inconsistency handling based\non the notion of repairs can be integrated into KABs, resorting to\ninconsistency-tolerant semantics. In this setting, we establish decidability\nand complexity of verification.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2013 23:24:31 GMT"}], "update_date": "2013-04-25", "authors_parsed": [["Calvanese", "Diego", ""], ["Kharlamov", "Evgeny", ""], ["Montali", "Marco", ""], ["Santoso", "Ario", ""], ["Zheleznyakov", "Dmitriy", ""]]}, {"id": "1304.6551", "submitter": "Vaclav Lin", "authors": "V\\'aclav L\\'in", "title": "Decision-Theoretic Troubleshooting: Hardness of Approximation", "comments": "The paper has been withdrawn since it has been published in IJAR\n  (http://dx.doi.org/10.1016/j.ijar.2013.07.003)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-theoretic troubleshooting is one of the areas to which Bayesian\nnetworks can be applied. Given a probabilistic model of a malfunctioning\nman-made device, the task is to construct a repair strategy with minimal\nexpected cost. The problem has received considerable attention over the past\ntwo decades. Efficient solution algorithms have been found for simple cases,\nwhereas other variants have been proven NP-complete. We study several variants\nof the problem found in literature, and prove that computing approximate\ntroubleshooting strategies is NP-hard. In the proofs, we exploit a close\nconnection to set-covering problems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2013 11:31:09 GMT"}, {"version": "v2", "created": "Wed, 29 May 2013 09:40:01 GMT"}, {"version": "v3", "created": "Thu, 6 Jun 2013 10:32:42 GMT"}, {"version": "v4", "created": "Thu, 1 Aug 2013 10:31:25 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["L\u00edn", "V\u00e1clav", ""]]}, {"id": "1304.6810", "submitter": "Guy Van den Broeck", "authors": "Daan Fierens, Guy Van den Broeck, Joris Renkens, Dimitar Shterionov,\n  Bernd Gutmann, Ingo Thon, Gerda Janssens, Luc De Raedt", "title": "Inference and learning in probabilistic logic programs using weighted\n  Boolean formulas", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 15 (2015) 358-401", "doi": "10.1017/S1471068414000076", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic logic programs are logic programs in which some of the facts\nare annotated with probabilities. This paper investigates how classical\ninference and learning tasks known from the graphical model community can be\ntackled for probabilistic logic programs. Several such tasks such as computing\nthe marginals given evidence and learning from (partial) interpretations have\nnot really been addressed for probabilistic logic programs before.\n  The first contribution of this paper is a suite of efficient algorithms for\nvarious inference tasks. It is based on a conversion of the program and the\nqueries and evidence to a weighted Boolean formula. This allows us to reduce\nthe inference tasks to well-studied tasks such as weighted model counting,\nwhich can be solved using state-of-the-art methods known from the graphical\nmodel and knowledge compilation literature. The second contribution is an\nalgorithm for parameter estimation in the learning from interpretations\nsetting. The algorithm employs Expectation Maximization, and is built on top of\nthe developed inference algorithms.\n  The proposed approach is experimentally evaluated. The results show that the\ninference algorithms improve upon the state-of-the-art in probabilistic logic\nprogramming and that it is indeed possible to learn the parameters of a\nprobabilistic logic program from interpretations.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2013 06:10:55 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Fierens", "Daan", ""], ["Broeck", "Guy Van den", ""], ["Renkens", "Joris", ""], ["Shterionov", "Dimitar", ""], ["Gutmann", "Bernd", ""], ["Thon", "Ingo", ""], ["Janssens", "Gerda", ""], ["De Raedt", "Luc", ""]]}, {"id": "1304.7045", "submitter": "Ohad Shamir", "authors": "Roi Livni, Shai Shalev-Shwartz, Ohad Shamir", "title": "An Algorithm for Training Polynomial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider deep neural networks, in which the output of each node is a\nquadratic function of its inputs. Similar to other deep architectures, these\nnetworks can compactly represent any function on a finite training set. The\nmain goal of this paper is the derivation of an efficient layer-by-layer\nalgorithm for training such networks, which we denote as the \\emph{Basis\nLearner}. The algorithm is a universal learner in the sense that the training\nerror is guaranteed to decrease at every iteration, and can eventually reach\nzero under mild conditions. We present practical implementations of this\nalgorithm, as well as preliminary experimental results. We also compare our\ndeep architecture to other shallow architectures for learning polynomials, in\nparticular kernel learning.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2013 00:35:37 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2014 13:14:59 GMT"}], "update_date": "2014-02-21", "authors_parsed": [["Livni", "Roi", ""], ["Shalev-Shwartz", "Shai", ""], ["Shamir", "Ohad", ""]]}, {"id": "1304.7168", "submitter": "Emad Saad", "authors": "Emad Saad", "title": "Non Deterministic Logic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Non deterministic applications arise in many domains, including, stochastic\noptimization, multi-objectives optimization, stochastic planning, contingent\nstochastic planning, reinforcement learning, reinforcement learning in\npartially observable Markov decision processes, and conditional planning. We\npresent a logic programming framework called non deterministic logic programs,\nalong with a declarative semantics and fixpoint semantics, to allow\nrepresenting and reasoning about inherently non deterministic real-world\napplications. The language of non deterministic logic programs framework is\nextended with non-monotonic negation, and two alternative semantics are\ndefined: the stable non deterministic model semantics and the well-founded non\ndeterministic model semantics as well as their relationship is studied. These\nsemantics subsume the deterministic stable model semantics and the\ndeterministic well-founded semantics of deterministic normal logic programs,\nand they reduce to the semantics of deterministic definite logic programs\nwithout negation. We show the application of the non deterministic logic\nprograms framework to a conditional planning problem.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2013 13:55:05 GMT"}], "update_date": "2013-04-29", "authors_parsed": [["Saad", "Emad", ""]]}, {"id": "1304.7238", "submitter": "Arindam Chaudhuri AC", "authors": "Arindam Chaudhuri, Kajal De, Dipak Chatterjee", "title": "Solution of the Decision Making Problems using Fuzzy Soft Relations", "comments": "29 Pages Journal Paper, International Journal of Information\n  Technology, Volume 15, Number 1, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fuzzy Modeling has been applied in a wide variety of fields such as\nEngineering and Management Sciences and Social Sciences to solve a number\nDecision Making Problems which involve impreciseness, uncertainty and vagueness\nin data. In particular, applications of this Modeling technique in Decision\nMaking Problems have remarkable significance. These problems have been tackled\nusing various theories such as Probability theory, Fuzzy Set Theory, Rough Set\nTheory, Vague Set Theory, Approximate Reasoning Theory etc. which lack in\nparameterization of the tools due to which they could not be applied\nsuccessfully to such problems. The concept of Soft Set has a promising\npotential for giving an optimal solution for these problems. With the\nmotivation of this new concept, in this paper we define the concepts of Soft\nRelation and Fuzzy Soft Relation and then apply them to solve a number of\nDecision Making Problems. The advantages of Fuzzy Soft Relation compared to\nother paradigms are discussed. To the best of our knowledge this is the first\nwork on the application of Fuzzy Soft Relation to the Decision Making Problems.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2013 17:36:14 GMT"}], "update_date": "2013-04-29", "authors_parsed": [["Chaudhuri", "Arindam", ""], ["De", "Kajal", ""], ["Chatterjee", "Dipak", ""]]}, {"id": "1304.7239", "submitter": "Arindam Chaudhuri AC", "authors": "Arindam Chaudhuri, Kajal De, Dipak Chatterjee", "title": "Solution of System of Linear Equations - A Neuro-Fuzzy Approach", "comments": "11 Pages, Journal Article, East West Journal of Mathematics, 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuro-Fuzzy Modeling has been applied in a wide variety of fields such as\nDecision Making, Engineering and Management Sciences etc. In particular,\napplications of this Modeling technique in Decision Making by involving complex\nSystems of Linear Algebraic Equations have remarkable significance. In this\nPaper, we present Polak-Ribiere Conjugate Gradient based Neural Network with\nFuzzy rules to solve System of Simultaneous Linear Algebraic Equations. This is\nachieved using Fuzzy Backpropagation Learning Rule. The implementation results\nshow that the proposed Neuro-Fuzzy Network yields effective solutions for\nexactly determined, underdetermined and over-determined Systems of Linear\nEquations. This fact is demonstrated by the Computational Complexity analysis\nof the Neuro-Fuzzy Algorithm. The proposed Algorithm is simulated effectively\nusing MATLAB software. To the best of our knowledge this is the first work of\nthe Systems of Linear Algebraic Equations using Neuro-Fuzzy Modeling.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2013 17:44:33 GMT"}], "update_date": "2013-04-29", "authors_parsed": [["Chaudhuri", "Arindam", ""], ["De", "Kajal", ""], ["Chatterjee", "Dipak", ""]]}, {"id": "1304.7244", "submitter": "Henning Schnoor", "authors": "Rudolf Berghammer and Henning Schnoor", "title": "Relation-algebraic and Tool-supported Control of Condorcet Voting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a relation-algebraic model of Condorcet voting and, based on it,\nrelation-algebraic solutions of the constructive control problem via the\nremoval of voters.\n  We consider two winning conditions, viz. to be a Condorcet winner and to be\nin the (Gilles resp. upward) uncovered set. For the first condition the control\nproblem is known to be NP-hard; for the second condition the NP-hardness of the\ncontrol problem is shown in the paper. All relation-algebraic specifications we\nwill develop in the paper immediately can be translated into the programming\nlanguage of the BDD-based computer system RelView. Our approach is very\nflexible and especially appropriate for prototyping and experimentation, and as\nsuch very instructive for educational purposes. It can easily be applied to\nother voting rules and control problems.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2013 11:17:46 GMT"}], "update_date": "2013-04-29", "authors_parsed": [["Berghammer", "Rudolf", ""], ["Schnoor", "Henning", ""]]}, {"id": "1304.7423", "submitter": "M.M.A. Hashem", "authors": "Nafisa Afrin Chowdhury, Murshida Khatun and M.M.A. Hashem", "title": "On Integrating Fuzzy Knowledge Using a Novel Evolutionary Algorithm", "comments": null, "journal-ref": "Procs. of the IEEE 10th International Conference on Computer &\n  Information Technology (ICCIT 2007), pp. 38-43, Dhaka, Bangladesh, December\n  27-29, (2007)", "doi": "10.1109/ICCITECHN.2007.4579352", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy systems may be considered as knowledge-based systems that incorporates\nhuman knowledge into their knowledge base through fuzzy rules and fuzzy\nmembership functions. The intent of this study is to present a fuzzy knowledge\nintegration framework using a Novel Evolutionary Strategy (NES), which can\nsimultaneously integrate multiple fuzzy rule sets and their membership function\nsets. The proposed approach consists of two phases: fuzzy knowledge encoding\nand fuzzy knowledge integration. Four application domains, the hepatitis\ndiagnosis, the sugarcane breeding prediction, Iris plants classification, and\nTic-tac-toe endgame were used to show the performance ofthe proposed knowledge\napproach. Results show that the fuzzy knowledge base derived using our approach\nperforms better than Genetic Algorithm based approach.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2013 03:02:47 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Chowdhury", "Nafisa Afrin", ""], ["Khatun", "Murshida", ""], ["Hashem", "M. M. A.", ""]]}, {"id": "1304.7507", "submitter": "Eugene Yuta Bann", "authors": "Eugene Yuta Bann, Joanna J. Bryson", "title": "Measuring Cultural Relativity of Emotional Valence and Arousal using\n  Semantic Clustering and Twitter", "comments": "To be presented at the 35th Annual Meeting of the Cognitive Science\n  Society (CogSci 2013), Berlin, Germany, Wednesday, July 31 - Saturday, August\n  3, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers since at least Darwin have debated whether and to what extent\nemotions are universal or culture-dependent. However, previous studies have\nprimarily focused on facial expressions and on a limited set of emotions. Given\nthat emotions have a substantial impact on human lives, evidence for cultural\nemotional relativity might be derived by applying distributional semantics\ntechniques to a text corpus of self-reported behaviour. Here, we explore this\nidea by measuring the valence and arousal of the twelve most popular emotion\nkeywords expressed on the micro-blogging site Twitter. We do this in three\ngeographical regions: Europe, Asia and North America. We demonstrate that in\nour sample, the valence and arousal levels of the same emotion keywords differ\nsignificantly with respect to these geographical regions --- Europeans are, or\nat least present themselves as more positive and aroused, North Americans are\nmore negative and Asians appear to be more positive but less aroused when\ncompared to global valence and arousal levels of the same emotion keywords. Our\nwork is the first in kind to programatically map large text corpora to a\ndimensional model of affect.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2013 19:30:11 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Bann", "Eugene Yuta", ""], ["Bryson", "Joanna J.", ""]]}, {"id": "1304.7607", "submitter": "Xiaojun Zhou", "authors": "Xiaolin Tang, Chunhua Yang, Xiaojun Zhou, Weihua Gui", "title": "A Discrete State Transition Algorithm for Generalized Traveling Salesman\n  Problem", "comments": "8 pages, 1 figure", "journal-ref": "Advances in Global Optimization, 2015, 95:137-145", "doi": "10.1007/978-3-319-08377-3__15", "report-no": null, "categories": "math.OC cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized traveling salesman problem (GTSP) is an extension of classical\ntraveling salesman problem (TSP), which is a combinatorial optimization problem\nand an NP-hard problem. In this paper, an efficient discrete state transition\nalgorithm (DSTA) for GTSP is proposed, where a new local search operator named\n\\textit{K-circle}, directed by neighborhood information in space, has been\nintroduced to DSTA to shrink search space and strengthen search ability. A\nnovel robust update mechanism, restore in probability and risk in probability\n(Double R-Probability), is used in our work to escape from local minima. The\nproposed algorithm is tested on a set of GTSP instances. Compared with other\nheuristics, experimental results have demonstrated the effectiveness and strong\nadaptability of DSTA and also show that DSTA has better search ability than its\ncompetitors.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2013 10:03:29 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Tang", "Xiaolin", ""], ["Yang", "Chunhua", ""], ["Zhou", "Xiaojun", ""], ["Gui", "Weihua", ""]]}, {"id": "1304.7820", "submitter": "Jianguo Ding", "authors": "Jianguo Ding, Pascal Bouvry", "title": "Challenges on Probabilistic Modeling for Evolving Networks", "comments": "18 pages. Book chapter. arXiv admin note: text overlap with\n  arXiv:1012.0009 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emerging of new networks, such as wireless sensor networks, vehicle\nnetworks, P2P networks, cloud computing, mobile Internet, or social networks,\nthe network dynamics and complexity expands from system design, hardware,\nsoftware, protocols, structures, integration, evolution, application, even to\nbusiness goals. Thus the dynamics and uncertainty are unavoidable\ncharacteristics, which come from the regular network evolution and unexpected\nhardware defects, unavoidable software errors, incomplete management\ninformation and dependency relationship between the entities among the emerging\ncomplex networks. Due to the complexity of emerging networks, it is not always\npossible to build precise models in modeling and optimization (local and\nglobal) for networks. This paper presents a survey on probabilistic modeling\nfor evolving networks and identifies the new challenges which emerge on the\nprobabilistic models and optimization strategies in the potential application\nareas of network performance, network management and network security for\nevolving networks.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2013 00:09:28 GMT"}, {"version": "v2", "created": "Sat, 4 May 2013 11:21:35 GMT"}], "update_date": "2013-05-07", "authors_parsed": [["Ding", "Jianguo", ""], ["Bouvry", "Pascal", ""]]}, {"id": "1304.7843", "submitter": "Gobithaasan Rudrusamy", "authors": "Azruddin Ahmad, Gobithasan Rudrusamy, Rahmat Budiarto, Azman Samsudin,\n  and Sureswaran Ramadass", "title": "A Hybrid Rule Based Fuzzy-Neural Expert System For Passive Network\n  Monitoring", "comments": null, "journal-ref": "2002 Proceedings of the Arab Conference on Information Technology\n  ACIT 2002, Dhaka, Pg.746-752", "doi": null, "report-no": null, "categories": "cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An enhanced approach for network monitoring is to create a network monitoring\ntool that has artificial intelligence characteristics. There are a number of\napproaches available. One such approach is by the use of a combination of rule\nbased, fuzzy logic and neural networks to create a hybrid ANFIS system. Such\nsystem will have a dual knowledge database approach. One containing membership\nfunction values to compare to and do deductive reasoning and another database\nwith rules deductively formulated by an expert (a network administrator). The\nknowledge database will be updated continuously with newly acquired patterns.\nIn short, the system will be composed of 2 parts, learning from data sets and\nfine-tuning the knowledge-base using neural network and the use of fuzzy logic\nin making decision based on the rules and membership functions inside the\nknowledge base. This paper will discuss the idea, steps and issues involved in\ncreating such a system.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2013 03:18:12 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Ahmad", "Azruddin", ""], ["Rudrusamy", "Gobithasan", ""], ["Budiarto", "Rahmat", ""], ["Samsudin", "Azman", ""], ["Ramadass", "Sureswaran", ""]]}, {"id": "1304.7855", "submitter": "EPTCS", "authors": "Matt Kaufmann (University of Texas at Austin), J Strother Moore\n  (University of Texas at Austin)", "title": "Enhancements to ACL2 in Versions 5.0, 6.0, and 6.1", "comments": "In Proceedings ACL2 2013, arXiv:1304.7123", "journal-ref": "EPTCS 114, 2013, pp. 5-12", "doi": "10.4204/EPTCS.114.1", "report-no": null, "categories": "cs.MS cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on highlights of the ACL2 enhancements introduced in ACL2 releases\nsince the 2011 ACL2 Workshop. Although many enhancements are critical for\nsoundness or robustness, we focus in this paper on those improvements that\ncould benefit users who are aware of them, but that might not be discovered in\neveryday practice.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2013 04:13:58 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Kaufmann", "Matt", "", "University of Texas at Austin"], ["Moore", "J Strother", "", "University of Texas at Austin"]]}, {"id": "1304.7920", "submitter": "Joris Mooij", "authors": "Joris M. Mooij, Dominik Janzing, Bernhard Sch\\\"olkopf", "title": "From Ordinary Differential Equations to Structural Causal Models: the\n  deterministic case", "comments": "Submitted to UAI 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how, and under which conditions, the equilibrium states of a\nfirst-order Ordinary Differential Equation (ODE) system can be described with a\ndeterministic Structural Causal Model (SCM). Our exposition sheds more light on\nthe concept of causality as expressed within the framework of Structural Causal\nModels, especially for cyclic models.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2013 08:58:51 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Mooij", "Joris M.", ""], ["Janzing", "Dominik", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}]