[{"id": "1211.0418", "submitter": "Normunds Gr\\=uz\\=itis", "authors": "Normunds Gr\\=uz\\=itis, Gunta Ne\\v{s}pore, Baiba Saul\\=ite", "title": "Verbalizing Ontologies in Controlled Baltic Languages", "comments": null, "journal-ref": "Human Language Technologies - The Baltic Perspective, Frontiers in\n  Artificial Intelligence and Applications, Vol. 219, IOS Press, 2010, pp.\n  187-194", "doi": "10.3233/978-1-60750-641-6-187", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controlled natural languages (mostly English-based) recently have emerged as\nseemingly informal supplementary means for OWL ontology authoring, if compared\nto the formal notations that are used by professional knowledge engineers. In\nthis paper we present by examples controlled Latvian language that has been\ndesigned to be compliant with the state of the art Attempto Controlled English.\nWe also discuss relation with controlled Lithuanian language that is being\ndesigned in parallel.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2012 11:09:44 GMT"}], "update_date": "2016-07-07", "authors_parsed": [["Gr\u016bz\u012btis", "Normunds", ""], ["Ne\u0161pore", "Gunta", ""], ["Saul\u012bte", "Baiba", ""]]}, {"id": "1211.0424", "submitter": "Zhaoxiang Zang", "authors": "Zhaoxiang Zang, Dehua Li, Junying Wang", "title": "Learning classifier systems with memory condition to solve non-Markov\n  problems", "comments": "34 pages, 15 figures, 1 table", "journal-ref": null, "doi": "10.1007/s00500-014-1357-y", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the family of Learning Classifier Systems, the classifier system XCS has\nbeen successfully used for many applications. However, the standard XCS has no\nmemory mechanism and can only learn optimal policy in Markov environments,\nwhere the optimal action is determined solely by the state of current sensory\ninput. In practice, most environments are partially observable environments on\nagent's sensation, which are also known as non-Markov environments. Within\nthese environments, XCS either fails, or only develops a suboptimal policy,\nsince it has no memory. In this work, we develop a new classifier system based\non XCS to tackle this problem. It adds an internal message list to XCS as the\nmemory list to record input sensation history, and extends a small number of\nclassifiers with memory conditions. The classifier's memory condition, as a\nfoothold to disambiguate non-Markov states, is used to sense a specified\nelement in the memory list. Besides, a detection method is employed to\nrecognize non-Markov states in environments, to avoid these states controlling\nover classifiers' memory conditions. Furthermore, four sets of different\ncomplex maze environments have been tested by the proposed method. Experimental\nresults show that our system is one of the best techniques to solve partially\nobservable environments, compared with some well-known classifier systems\nproposed for these environments.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2012 11:40:10 GMT"}], "update_date": "2014-11-06", "authors_parsed": [["Zang", "Zhaoxiang", ""], ["Li", "Dehua", ""], ["Wang", "Junying", ""]]}, {"id": "1211.0479", "submitter": "Stefan Szeider", "authors": "Christer B\\\"ackstr\\\"om, Peter Jonsson, Sebastian Ordyniak, Stefan\n  Szeider", "title": "Parameterized Complexity and Kernel Bounds for Hard Planning Problems", "comments": "This is the full version of a paper that will appear in the Proc. of\n  CIAC 2013", "journal-ref": "Proceedings of CIAC 2013, LNCS 7878, pp. 13-24, 2013", "doi": "10.1007/978-3-642-38233-8_2", "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The propositional planning problem is a notoriously difficult computational\nproblem. Downey et al. (1999) initiated the parameterized analysis of planning\n(with plan length as the parameter) and B\\\"ackstr\\\"om et al. (2012) picked up\nthis line of research and provided an extensive parameterized analysis under\nvarious restrictions, leaving open only one stubborn case. We continue this\nwork and provide a full classification. In particular, we show that the case\nwhen actions have no preconditions and at most $e$ postconditions is\nfixed-parameter tractable if $e\\leq 2$ and W[1]-complete otherwise. We show\nfixed-parameter tractability by a reduction to a variant of the Steiner Tree\nproblem; this problem has been shown fixed-parameter tractable by Guo et al.\n(2007). If a problem is fixed-parameter tractable, then it admits a\npolynomial-time self-reduction to instances whose input size is bounded by a\nfunction of the parameter, called the kernel. For some problems, this function\nis even polynomial which has desirable computational implications. Recent\nresearch in parameterized complexity has focused on classifying fixed-parameter\ntractable problems on whether they admit polynomial kernels or not. We revisit\nall the previously obtained restrictions of planning that are fixed-parameter\ntractable and show that none of them admits a polynomial kernel unless the\npolynomial hierarchy collapses to its third level.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2012 15:59:54 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2013 12:23:42 GMT"}], "update_date": "2013-07-16", "authors_parsed": [["B\u00e4ckstr\u00f6m", "Christer", ""], ["Jonsson", "Peter", ""], ["Ordyniak", "Sebastian", ""], ["Szeider", "Stefan", ""]]}, {"id": "1211.0501", "submitter": "Fintan Costello", "authors": "Fintan Costello and Paul Watts", "title": "Surprisingly Rational: Probability theory plus noise explains biases in\n  judgment", "comments": "64 pages. Final preprint version. In press, Psychological Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The systematic biases seen in people's probability judgments are typically\ntaken as evidence that people do not reason about probability using the rules\nof probability theory, but instead use heuristics which sometimes yield\nreasonable judgments and sometimes systematic biases. This view has had a major\nimpact in economics, law, medicine, and other fields; indeed, the idea that\npeople cannot reason with probabilities has become a widespread truism. We\npresent a simple alternative to this view, where people reason about\nprobability according to probability theory but are subject to random variation\nor noise in the reasoning process. In this account the effect of noise is\ncancelled for some probabilistic expressions: analysing data from two\nexperiments we find that, for these expressions, people's probability judgments\nare strikingly close to those required by probability theory. For other\nexpressions this account produces systematic deviations in probability\nestimates. These deviations explain four reliable biases in human probabilistic\nreasoning (conservatism, subadditivity, conjunction and disjunction fallacies).\nThese results suggest that people's probability judgments embody the rules of\nprobability theory, and that biases in those judgments are due to the effects\nof random noise.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2012 14:57:42 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2013 13:40:00 GMT"}, {"version": "v3", "created": "Wed, 30 Apr 2014 09:15:06 GMT"}], "update_date": "2014-05-01", "authors_parsed": [["Costello", "Fintan", ""], ["Watts", "Paul", ""]]}, {"id": "1211.0611", "submitter": "Aiping  Huang", "authors": "Aiping Huang, William Zhu", "title": "Matrix approach to rough sets through vector matroids over a field", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rough sets were proposed to deal with the vagueness and incompleteness of\nknowledge in information systems. There are may optimization issues in this\nfield such as attribute reduction. Matroids generalized from matrices are\nwidely used in optimization. Therefore, it is necessary to connect matroids\nwith rough sets. In this paper, we take field into consideration and introduce\nmatrix to study rough sets through vector matroids. First, a matrix\nrepresentation of an equivalence relation is proposed, and then a matroidal\nstructure of rough sets over a field is presented by the matrix. Second, the\nproperties of the matroidal structure including circuits, bases and so on are\nstudied through two special matrix solution spaces, especially null space.\nThird, over a binary field, we construct an equivalence relation from matrix\nnull space, and establish an algebra isomorphism from the collection of\nequivalence relations to the collection of sets, which any member is a family\nof the minimal non-empty sets that are supports of members of null space of a\nbinary dependence matrix. In a word, matrix provides a new viewpoint to study\nrough sets.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2012 13:19:34 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2013 02:16:40 GMT"}, {"version": "v3", "created": "Thu, 28 Mar 2013 02:03:21 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Huang", "Aiping", ""], ["Zhu", "William", ""]]}, {"id": "1211.0749", "submitter": "Indriana Hidayah", "authors": "Indriana Hidayah, Alvi Syahrina, Adhistya Erna Permanasari", "title": "Student Modeling using Case-Based Reasoning in Conventional Learning\n  System", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional face-to-face classrooms are still the main learning system\napplied in Indonesia. In assisting such conventional learning towards an\noptimal learning, formative evaluations are needed to monitor the progress of\nthe class. This task can be very hard when the size of the class is large.\nHence, this research attempted to create a classroom monitoring system based on\nstudent data of Department of Electrical Engineering and Information\nTechnology. In order to achieve the goal, a student modeling using Case-Based\nReasoning was proposed. A generic student model based on a framework was\ndeveloped. The model represented student knowledge of a subject. The result\nshowed that the system was able to store and retrieve student data for\nsuggestion of the current situation and formative evaluation for one of the\nsubject in the Department.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2012 03:09:33 GMT"}], "update_date": "2012-11-06", "authors_parsed": [["Hidayah", "Indriana", ""], ["Syahrina", "Alvi", ""], ["Permanasari", "Adhistya Erna", ""]]}, {"id": "1211.0906", "submitter": "Frank Hutter", "authors": "Frank Hutter, Lin Xu, Holger H. Hoos, Kevin Leyton-Brown", "title": "Algorithm Runtime Prediction: Methods & Evaluation", "comments": "51 pages, 13 figures, 8 tables. Added references, feature cost, and\n  experiments with subsets of features; reworded Sections 1&2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perhaps surprisingly, it is possible to predict how long an algorithm will\ntake to run on a previously unseen input, using machine learning techniques to\nbuild a model of the algorithm's runtime as a function of problem-specific\ninstance features. Such models have important applications to algorithm\nanalysis, portfolio-based algorithm selection, and the automatic configuration\nof parameterized algorithms. Over the past decade, a wide variety of techniques\nhave been studied for building such models. Here, we describe extensions and\nimprovements of existing models, new families of models, and -- perhaps most\nimportantly -- a much more thorough treatment of algorithm parameters as model\ninputs. We also comprehensively describe new and existing features for\npredicting algorithm runtime for propositional satisfiability (SAT), travelling\nsalesperson (TSP) and mixed integer programming (MIP) problems. We evaluate\nthese innovations through the largest empirical analysis of its kind, comparing\nto a wide range of runtime modelling techniques from the literature. Our\nexperiments consider 11 algorithms and 35 instance distributions; they also\nspan a very wide range of SAT, MIP, and TSP instances, with the least\nstructured having been generated uniformly at random and the most structured\nhaving emerged from real industrial applications. Overall, we demonstrate that\nour new models yield substantially better runtime predictions than previous\napproaches in terms of their generalization to new problem instances, to new\nalgorithms from a parameterized space, and to both simultaneously.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2012 16:15:16 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2013 09:00:50 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Hutter", "Frank", ""], ["Xu", "Lin", ""], ["Hoos", "Holger H.", ""], ["Leyton-Brown", "Kevin", ""]]}, {"id": "1211.0996", "submitter": "Varun Kanade", "authors": "Pranjal Awasthi, Vitaly Feldman, Varun Kanade", "title": "Learning using Local Membership Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new model of membership query (MQ) learning, where the\nlearning algorithm is restricted to query points that are \\emph{close} to\nrandom examples drawn from the underlying distribution. The learning model is\nintermediate between the PAC model (Valiant, 1984) and the PAC+MQ model (where\nthe queries are allowed to be arbitrary points).\n  Membership query algorithms are not popular among machine learning\npractitioners. Apart from the obvious difficulty of adaptively querying\nlabelers, it has also been observed that querying \\emph{unnatural} points leads\nto increased noise from human labelers (Lang and Baum, 1992). This motivates\nour study of learning algorithms that make queries that are close to examples\ngenerated from the data distribution.\n  We restrict our attention to functions defined on the $n$-dimensional Boolean\nhypercube and say that a membership query is local if its Hamming distance from\nsome example in the (random) training data is at most $O(\\log(n))$. We show the\nfollowing results in this model:\n  (i) The class of sparse polynomials (with coefficients in R) over $\\{0,1\\}^n$\nis polynomial time learnable under a large class of \\emph{locally smooth}\ndistributions using $O(\\log(n))$-local queries. This class also includes the\nclass of $O(\\log(n))$-depth decision trees.\n  (ii) The class of polynomial-sized decision trees is polynomial time\nlearnable under product distributions using $O(\\log(n))$-local queries.\n  (iii) The class of polynomial size DNF formulas is learnable under the\nuniform distribution using $O(\\log(n))$-local queries in time\n$n^{O(\\log(\\log(n)))}$.\n  (iv) In addition we prove a number of results relating the proposed model to\nthe traditional PAC model and the PAC+MQ model.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2012 20:42:16 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2013 21:04:47 GMT"}], "update_date": "2013-04-19", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Feldman", "Vitaly", ""], ["Kanade", "Varun", ""]]}, {"id": "1211.2041", "submitter": "Yuan Yao", "authors": "Yuan Yao, Hanghang Tong, Xifeng Yan, Feng Xu, Jian Lu", "title": "MaTrust: An Effective Multi-Aspect Trust Inference Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trust is a fundamental concept in many real-world applications such as\ne-commerce and peer-to-peer networks. In these applications, users can generate\nlocal opinions about the counterparts based on direct experiences, and these\nopinions can then be aggregated to build trust among unknown users. The\nmechanism to build new trust relationships based on existing ones is referred\nto as trust inference. State-of-the-art trust inference approaches employ the\ntransitivity property of trust by propagating trust along connected users. In\nthis paper, we propose a novel trust inference model (MaTrust) by exploring an\nequally important property of trust, i.e., the multi-aspect property. MaTrust\ndirectly characterizes multiple latent factors for each trustor and trustee\nfrom the locally-generated trust relationships. Furthermore, it can naturally\nincorporate prior knowledge as specified factors. These factors in turn serve\nas the basis to infer the unseen trustworthiness scores. Experimental\nevaluations on real data sets show that the proposed MaTrust significantly\noutperforms several benchmark trust inference models in both effectiveness and\nefficiency.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2012 04:46:47 GMT"}], "update_date": "2012-11-12", "authors_parsed": [["Yao", "Yuan", ""], ["Tong", "Hanghang", ""], ["Yan", "Xifeng", ""], ["Xu", "Feng", ""], ["Lu", "Jian", ""]]}, {"id": "1211.2087", "submitter": "Arindam Sarkar", "authors": "Arindam Sarkar and J. K. Mandal", "title": "Secured Wireless Communication using Fuzzy Logic based High Speed\n  Public-Key Cryptography (FLHSPKC)", "comments": "9 pages", "journal-ref": "(IJACSA) International Journal of Advanced Computer Science and\n  Applications, Vol. 3, No. 10, 2012, 137-145", "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper secured wireless communication using fuzzy logic based high\nspeed public key cryptography (FLHSPKC) has been proposed by satisfying the\nmajor issues likes computational safety, power management and restricted usage\nof memory in wireless communication. Wireless Sensor Network (WSN) has several\nmajor constraints likes inadequate source of energy, restricted computational\npotentiality and limited memory. Though conventional Elliptic Curve\nCryptography (ECC) which is a sort of public key cryptography used in wireless\ncommunication provides equivalent level of security like other existing public\nkey algorithm using smaller parameters than other but this traditional ECC does\nnot take care of all these major limitations in WSN. In conventional ECC\nconsider Elliptic curve point p, an arbitrary integer k and modulus m, ECC\ncarry out scalar multiplication kP mod m, which takes about 80% of key\ncomputation time on WSN. In this paper proposed FLHSPKC scheme provides some\nnovel strategy including novel soft computing based strategy to speed up scalar\nmultiplication in conventional ECC and which in turn takes shorter\ncomputational time and also satisfies power consumption restraint, limited\nusage of memory without hampering the security level. Performance analysis of\nthe different strategies under FLHSPKC scheme and comparison study with\nexisting conventional ECC methods has been done.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2012 09:57:16 GMT"}], "update_date": "2012-11-12", "authors_parsed": [["Sarkar", "Arindam", ""], ["Mandal", "J. K.", ""]]}, {"id": "1211.2126", "submitter": "Hela Ltifi Ms", "authors": "Hela Ltifi, Ghada Trabelsi, Mounir Ben Ayed, Adel M. Alimi", "title": "Dynamic Decision Support System Based on Bayesian Networks Application\n  to fight against the Nosocomial Infections", "comments": "8 pages, 6 figures, 43 references", "journal-ref": "International Journal of Advanced Research in Artificial\n  Intelligence (IJARAI), vol 1(1), pp. 22-29, 2012", "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The improvement of medical care quality is a significant interest for the\nfuture years. The fight against nosocomial infections (NI) in the intensive\ncare units (ICU) is a good example. We will focus on a set of observations\nwhich reflect the dynamic aspect of the decision, result of the application of\na Medical Decision Support System (MDSS). This system has to make dynamic\ndecision on temporal data. We use dynamic Bayesian network (DBN) to model this\ndynamic process. It is a temporal reasoning within a real-time environment; we\nare interested in the Dynamic Decision Support Systems in healthcare domain\n(MDDSS).\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2012 13:36:44 GMT"}], "update_date": "2012-11-12", "authors_parsed": [["Ltifi", "Hela", ""], ["Trabelsi", "Ghada", ""], ["Ayed", "Mounir Ben", ""], ["Alimi", "Adel M.", ""]]}, {"id": "1211.2245", "submitter": "Mark Levin", "authors": "Mark Sh. Levin", "title": "Composite Strategy for Multicriteria Ranking/Sorting (methodological\n  issues, examples)", "comments": "24 pages, 28 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper addresses the modular design of composite solving strategies for\nmulticriteria ranking (sorting). Here a 'scale of creativity' that is close to\ncreative levels proposed by Altshuller is used as the reference viewpoint: (i)\na basic object, (ii) a selected object, (iii) a modified object, and (iv) a\ndesigned object (e.g., composition of object components). These levels maybe\nused in various parts of decision support systems (DSS) (e.g., information,\noperations, user). The paper focuses on the more creative above-mentioned level\n(i.e., composition or combinatorial synthesis) for the operational part (i.e.,\ncomposite solving strategy). This is important for a search/exploration mode of\ndecision making process with usage of various procedures and techniques and\nanalysis/integration of obtained results. The paper describes methodological\nissues of decision technology and synthesis of composite strategy for\nmulticriteria ranking. The synthesis of composite strategies is based on\n'hierarchical morphological multicriteria design' (HMMD) which is based on\nselection and combination of design alternatives (DAs) (here: local procedures\nor techniques) while taking into account their quality and quality of their\ninterconnections (IC). A new version of HMMD with interval multiset estimates\nfor DAs is used. The operational environment of DSS COMBI for multicriteria\nranking, consisting of a morphology of local procedures or techniques (as\ndesign alternatives DAs), is examined as a basic one.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2012 21:11:13 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Levin", "Mark Sh.", ""]]}, {"id": "1211.2290", "submitter": "Abhimanu Kumar", "authors": "Abhimanu Kumar, Jason Baldridge, Matthew Lease, Joydeep Ghosh", "title": "Dating Texts without Explicit Temporal Cues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles temporal resolution of documents, such as determining when\na document is about or when it was written, based only on its text. We apply\ntechniques from information retrieval that predict dates via language models\nover a discretized timeline. Unlike most previous works, we rely {\\it solely}\non temporal cues implicit in the text. We consider both document-likelihood and\ndivergence based techniques and several smoothing methods for both of them. Our\nbest model predicts the mid-point of individuals' lives with a median of 22 and\nmean error of 36 years for Wikipedia biographies from 3800 B.C. to the present\nday. We also show that this approach works well when training on such\nbiographies and predicting dates both for non-biographical Wikipedia pages\nabout specific years (500 B.C. to 2010 A.D.) and for publication dates of short\nstories (1798 to 2008). Together, our work shows that, even in absence of\ntemporal extraction resources, it is possible to achieve remarkable temporal\nlocality across a diverse set of texts.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2012 05:12:31 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Kumar", "Abhimanu", ""], ["Baldridge", "Jason", ""], ["Lease", "Matthew", ""], ["Ghosh", "Joydeep", ""]]}, {"id": "1211.2399", "submitter": "Rustam Tagiew", "authors": "Rustam Tagiew", "title": "Mining Determinism in Human Strategic Behavior", "comments": "8 pages, no figures, EEML 2012", "journal-ref": "Experimental Economics and Machine Learning 2012, CEUR-WS Vol-870,\n  urn:nbn:de:0074-870-0", "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work lies in the fusion of experimental economics and data mining. It\ncontinues author's previous work on mining behaviour rules of human subjects\nfrom experimental data, where game-theoretic predictions partially fail to\nwork. Game-theoretic predictions aka equilibria only tend to success with\nexperienced subjects on specific games, what is rarely given. Apart from game\ntheory, contemporary experimental economics offers a number of alternative\nmodels. In relevant literature, these models are always biased by psychological\nand near-psychological theories and are claimed to be proven by the data. This\nwork introduces a data mining approach to the problem without using vast\npsychological background. Apart from determinism, no other biases are regarded.\nTwo datasets from different human subject experiments are taken for evaluation.\nThe first one is a repeated mixed strategy zero sum game and the second -\nrepeated ultimatum game. As result, the way of mining deterministic\nregularities in human strategic behaviour is described and evaluated. As future\nwork, the design of a new representation formalism is discussed.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2012 11:27:01 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Tagiew", "Rustam", ""]]}, {"id": "1211.2512", "submitter": "Hong Zhao", "authors": "Hong Zhao, Fan Min and William Zhu", "title": "Minimal cost feature selection of data with normal distribution\n  measurement errors", "comments": "This paper has been withdrawn by the author due to an error of the\n  title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimal cost feature selection is devoted to obtain a trade-off between test\ncosts and misclassification costs. This issue has been addressed recently on\nnominal data. In this paper, we consider numerical data with measurement errors\nand study minimal cost feature selection in this model. First, we build a data\nmodel with normal distribution measurement errors. Second, the neighborhood of\neach data item is constructed through the confidence interval. Comparing with\ndiscretized intervals, neighborhoods are more reasonable to maintain the\ninformation of data. Third, we define a new minimal total cost feature\nselection problem through considering the trade-off between test costs and\nmisclassification costs. Fourth, we proposed a backtracking algorithm with\nthree effective pruning techniques to deal with this problem. The algorithm is\ntested on four UCI data sets. Experimental results indicate that the pruning\ntechniques are effective, and the algorithm is efficient for data sets with\nnearly one thousand objects.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2012 05:26:20 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2013 02:43:45 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Zhao", "Hong", ""], ["Min", "Fan", ""], ["Zhu", "William", ""]]}, {"id": "1211.2719", "submitter": "Norbert B\\'atfai Ph.D.", "authors": "N. B\\'atfai", "title": "Quantum Consciousness Soccer Simulator", "comments": "9 pages, grammatically improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cognitive sciences it is not uncommon to use various games effectively.\nFor example, in artificial intelligence, the RoboCup initiative was to set up\nto catalyse research on the field of autonomous agent technology. In this\npaper, we introduce a similar soccer simulation initiative to try to\ninvestigate a model of human consciousness and a notion of reality in the form\nof a cognitive problem. In addition, for example, the home pitch advantage and\nthe objective role of the supporters could be naturally described and discussed\nin terms of this new soccer simulation model.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2012 18:10:05 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2012 20:40:04 GMT"}], "update_date": "2012-11-14", "authors_parsed": [["B\u00e1tfai", "N.", ""]]}, {"id": "1211.2736", "submitter": "Venkateshwara Prasad Tangirala", "authors": "Rajeswari P. V. N. and T. V. Prasad", "title": "Hybrid Systems for Knowledge Representation in Artificial Intelligence", "comments": "6 pages", "journal-ref": "International Journal of Advanced Research in Artificial\n  Intelligence, 1 (8), 2012, 31-36", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are few knowledge representation (KR) techniques available for\nefficiently representing knowledge. However, with the increase in complexity,\nbetter methods are needed. Some researchers came up with hybrid mechanisms by\ncombining two or more methods. In an effort to construct an intelligent\ncomputer system, a primary consideration is to represent large amounts of\nknowledge in a way that allows effective use and efficiently organizing\ninformation to facilitate making the recommended inferences. There are merits\nand demerits of combinations, and standardized method of KR is needed. In this\npaper, various hybrid schemes of KR were explored at length and details\npresented.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2012 19:09:08 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["N.", "Rajeswari P. V.", ""], ["Prasad", "T. V.", ""]]}, {"id": "1211.2972", "submitter": "Dan Stowell", "authors": "Dan Stowell and Mark D. Plumbley", "title": "Segregating event streams and noise with a Markov renewal process model", "comments": null, "journal-ref": "Journal of Machine Learning Research, 14(Aug):2213-2238, 2013", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We describe an inference task in which a set of timestamped event\nobservations must be clustered into an unknown number of temporal sequences\nwith independent and varying rates of observations. Various existing approaches\nto multi-object tracking assume a fixed number of sources and/or a fixed\nobservation rate; we develop an approach to inferring structure in timestamped\ndata produced by a mixture of an unknown and varying number of similar Markov\nrenewal processes, plus independent clutter noise. The inference simultaneously\ndistinguishes signal from noise as well as clustering signal observations into\nseparate source streams. We illustrate the technique via a synthetic experiment\nas well as an experiment to track a mixture of singing birds.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2012 12:43:45 GMT"}], "update_date": "2013-09-20", "authors_parsed": [["Stowell", "Dan", ""], ["Plumbley", "Mark D.", ""]]}, {"id": "1211.3089", "submitter": "Yuheng Hu", "authors": "Yuheng Hu, Ajita John, Fei Wang, Subbarao Kambhampati", "title": "ET-LDA: Joint Topic Modeling for Aligning Events and their Twitter\n  Feedback", "comments": "reference error, delete for now", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During broadcast events such as the Superbowl, the U.S. Presidential and\nPrimary debates, etc., Twitter has become the de facto platform for crowds to\nshare perspectives and commentaries about them. Given an event and an\nassociated large-scale collection of tweets, there are two fundamental research\nproblems that have been receiving increasing attention in recent years. One is\nto extract the topics covered by the event and the tweets; the other is to\nsegment the event. So far these problems have been viewed separately and\nstudied in isolation. In this work, we argue that these problems are in fact\ninter-dependent and should be addressed together. We develop a joint Bayesian\nmodel that performs topic modeling and event segmentation in one unified\nframework. We evaluate the proposed model both quantitatively and qualitatively\non two large-scale tweet datasets associated with two events from different\ndomains to show that it improves significantly over baseline models.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2012 19:46:51 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2012 05:50:15 GMT"}], "update_date": "2012-12-24", "authors_parsed": [["Hu", "Yuheng", ""], ["John", "Ajita", ""], ["Wang", "Fei", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1211.3212", "submitter": "Varun Kanade", "authors": "Varun Kanade, Zhenming Liu, Bozidar Radunovic", "title": "Distributed Non-Stochastic Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the online distributed non-stochastic experts problem, where the\ndistributed system consists of one coordinator node that is connected to $k$\nsites, and the sites are required to communicate with each other via the\ncoordinator. At each time-step $t$, one of the $k$ site nodes has to pick an\nexpert from the set ${1, ..., n}$, and the same site receives information about\npayoffs of all experts for that round. The goal of the distributed system is to\nminimize regret at time horizon $T$, while simultaneously keeping communication\nto a minimum.\n  The two extreme solutions to this problem are: (i) Full communication: This\nessentially simulates the non-distributed setting to obtain the optimal\n$O(\\sqrt{\\log(n)T})$ regret bound at the cost of $T$ communication. (ii) No\ncommunication: Each site runs an independent copy : the regret is\n$O(\\sqrt{log(n)kT})$ and the communication is 0. This paper shows the\ndifficulty of simultaneously achieving regret asymptotically better than\n$\\sqrt{kT}$ and communication better than $T$. We give a novel algorithm that\nfor an oblivious adversary achieves a non-trivial trade-off: regret\n$O(\\sqrt{k^{5(1+\\epsilon)/6} T})$ and communication $O(T/k^{\\epsilon})$, for\nany value of $\\epsilon \\in (0, 1/5)$. We also consider a variant of the model,\nwhere the coordinator picks the expert. In this model, we show that the\nlabel-efficient forecaster of Cesa-Bianchi et al. (2005) already gives us\nstrategy that is near optimal in regret vs communication trade-off.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2012 06:45:38 GMT"}], "update_date": "2012-11-15", "authors_parsed": [["Kanade", "Varun", ""], ["Liu", "Zhenming", ""], ["Radunovic", "Bozidar", ""]]}, {"id": "1211.3371", "submitter": "Christopher Simons", "authors": "C. L. Simons, J. E. Smith", "title": "A Comparison of Meta-heuristic Search for Interactive Software Design", "comments": "31 pages, 4 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in processing capacity, coupled with the desire to tackle problems\nwhere a human subjective judgment plays an important role in determining the\nvalue of a proposed solution, has led to a dramatic rise in the number of\napplications of Interactive Artificial Intelligence. Of particular note is the\ncoupling of meta-heuristic search engines with user-provided evaluation and\nrating of solutions, usually in the form of Interactive Evolutionary Algorithms\n(IEAs). These have a well-documented history of successes, but arguably the\npreponderance of IEAs stems from this history, rather than as a conscious\ndesign choice of meta-heuristic based on the characteristics of the problem at\nhand. This paper sets out to examine the basis for that assumption, taking as a\ncase study the domain of interactive software design. We consider a range of\nfactors that should affect the design choice including ease of use,\nscalability, and of course, performance, i.e. that ability to generate good\nsolutions within the limited number of evaluations available in interactive\nwork before humans lose focus. We then evaluate three methods, namely greedy\nlocal search, an evolutionary algorithm and ant colony optimization, with a\nvariety of representations for candidate solutions. Results show that after\nsuitable parameter tuning, ant colony optimization is highly effective within\ninteractive search and out-performs evolutionary algorithms with respect to\nincreasing numbers of attributes and methods in the software design problem.\nHowever, when larger numbers of classes are present in the software design, an\nevolutionary algorithm using a naive grouping integer-based representation\nappears more scalable.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2012 18:11:17 GMT"}], "update_date": "2012-11-15", "authors_parsed": [["Simons", "C. L.", ""], ["Smith", "J. E.", ""]]}, {"id": "1211.3497", "submitter": "Prabath Abeysiriwardana", "authors": "Prabath Chaminda Abeysiriwardana, Saluka R Kodituwakku", "title": "Ontology Based Information Extraction for Disease Intelligence", "comments": "Disease Intelligence, Disease Ontology, Information Extraction,\n  Semantic Web", "journal-ref": "International Journal of Research in Computer Science, 2 (6): pp.\n  7-19, November 2012. doi:10.7815/ijorcs.26.2012.051", "doi": "10.7815/ijorcs.26.2012.051", "report-no": null, "categories": "cs.AI cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disease Intelligence (DI) is based on the acquisition and aggregation of\nfragmented knowledge of diseases at multiple sources all over the world to\nprovide valuable information to doctors, researchers and information seeking\ncommunity. Some diseases have their own characteristics changed rapidly at\ndifferent places of the world and are reported on documents as unrelated and\nheterogeneous information which may be going unnoticed and may not be quickly\navailable. This research presents an Ontology based theoretical framework in\nthe context of medical intelligence and country/region. Ontology is designed\nfor storing information about rapidly spreading and changing diseases with\nincorporating existing disease taxonomies to genetic information of both humans\nand infectious organisms. It further maps disease symptoms to diseases and drug\neffects to disease symptoms. The machine understandable disease ontology\nrepresented as a website thus allows the drug effects to be evaluated on\ndisease symptoms and exposes genetic involvements in the human diseases.\nInfectious agents which have no known place in an existing classification but\nhave data on genetics would still be identified as organisms through the\nintelligence of this system. It will further facilitate researchers on the\nsubject to try out different solutions for curing diseases.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2012 05:33:28 GMT"}], "update_date": "2012-11-16", "authors_parsed": [["Abeysiriwardana", "Prabath Chaminda", ""], ["Kodituwakku", "Saluka R", ""]]}, {"id": "1211.3831", "submitter": "Youhei Akimoto", "authors": "Youhei Akimoto (INRIA Saclay - Ile de France), Yann Ollivier (LRI)", "title": "Objective Improvement in Information-Geometric Optimization", "comments": null, "journal-ref": "Foundations of Genetic Algorithms XII (2013)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information-Geometric Optimization (IGO) is a unified framework of stochastic\nalgorithms for optimization problems. Given a family of probability\ndistributions, IGO turns the original optimization problem into a new\nmaximization problem on the parameter space of the probability distributions.\nIGO updates the parameter of the probability distribution along the natural\ngradient, taken with respect to the Fisher metric on the parameter manifold,\naiming at maximizing an adaptive transform of the objective function. IGO\nrecovers several known algorithms as particular instances: for the family of\nBernoulli distributions IGO recovers PBIL, for the family of Gaussian\ndistributions the pure rank-mu CMA-ES update is recovered, and for exponential\nfamilies in expectation parametrization the cross-entropy/ML method is\nrecovered. This article provides a theoretical justification for the IGO\nframework, by proving that any step size not greater than 1 guarantees monotone\nimprovement over the course of optimization, in terms of q-quantile values of\nthe objective function f. The range of admissible step sizes is independent of\nf and its domain. We extend the result to cover the case of different step\nsizes for blocks of the parameters in the IGO algorithm. Moreover, we prove\nthat expected fitness improves over time when fitness-proportional selection is\napplied, in which case the RPP algorithm is recovered.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2012 08:54:08 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2012 12:57:45 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2013 13:36:08 GMT"}], "update_date": "2013-03-08", "authors_parsed": [["Akimoto", "Youhei", "", "INRIA Saclay - Ile de France"], ["Ollivier", "Yann", "", "LRI"]]}, {"id": "1211.3882", "submitter": "Oliver Obst", "authors": "Edward Moore, Oliver Obst, Mikhail Prokopenko, Peter Wang, Jason Held", "title": "Gliders2012: Development and Competition Results", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The RoboCup 2D Simulation League incorporates several challenging features,\nsetting a benchmark for Artificial Intelligence (AI). In this paper we describe\nsome of the ideas and tools around the development of our team, Gliders2012. In\nour description, we focus on the evaluation function as one of our central\nmechanisms for action selection. We also point to a new framework for watching\nlog files in a web browser that we release for use and further development by\nthe RoboCup community. Finally, we also summarize results of the group and\nfinal matches we played during RoboCup 2012, with Gliders2012 finishing 4th out\nof 19 teams.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2012 13:20:59 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2012 04:03:21 GMT"}], "update_date": "2012-11-22", "authors_parsed": [["Moore", "Edward", ""], ["Obst", "Oliver", ""], ["Prokopenko", "Mikhail", ""], ["Wang", "Peter", ""], ["Held", "Jason", ""]]}, {"id": "1211.4122", "submitter": "Zilong Xu", "authors": "Zilong Xu, Fan Min, William Zhu", "title": "Cost-sensitive C4.5 with post-pruning and competition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision tree is an effective classification approach in data mining and\nmachine learning. In applications, test costs and misclassification costs\nshould be considered while inducing decision trees. Recently, some\ncost-sensitive learning algorithms based on ID3 such as CS-ID3, IDX,\n\\lambda-ID3 have been proposed to deal with the issue. These algorithms deal\nwith only symbolic data. In this paper, we develop a decision tree algorithm\ninspired by C4.5 for numeric data. There are two major issues for our\nalgorithm. First, we develop the test cost weighted information gain ratio as\nthe heuristic information. According to this heuristic information, our\nalgorithm is to pick the attribute that provides more gain ratio and costs less\nfor each selection. Second, we design a post-pruning strategy through\nconsidering the tradeoff between test costs and misclassification costs of the\ngenerated decision tree. In this way, the total cost is reduced. Experimental\nresults indicate that (1) our algorithm is stable and effective; (2) the\npost-pruning technique reduces the total cost significantly; (3) the\ncompetition strategy is effective to obtain a cost-sensitive decision tree with\nlow cost.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2012 13:23:41 GMT"}], "update_date": "2012-11-20", "authors_parsed": [["Xu", "Zilong", ""], ["Min", "Fan", ""], ["Zhu", "William", ""]]}, {"id": "1211.4133", "submitter": "Ibrahim El Bitar", "authors": "Ibrahim El Bitar, Fatima-Zahra Belouadha, Ounsa Roudies", "title": "A Logic and Adaptive Approach for Efficient Diagnosis Systems using CBR", "comments": "5 pages,3 figures, 1 table", "journal-ref": "http://www.ijcaonline.org/archives/volume39/number15/4893-7393\n  year: 2012", "doi": "10.5120/4893-7393", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Case Based Reasoning (CBR) is an intelligent way of thinking based on\nexperience and capitalization of already solved cases (source cases) to find a\nsolution to a new problem (target case). Retrieval phase consists on\nidentifying source cases that are similar to the target case. This phase may\nlead to erroneous results if the existing knowledge imperfections are not taken\ninto account. This work presents a novel solution based on Fuzzy logic\ntechniques and adaptation measures which aggregate weighted similarities to\nimprove the retrieval results. To confirm the efficiency of our solution, we\nhave applied it to the industrial diagnosis domain. The obtained results are\nmore efficient results than those obtained by applying typical measures.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2012 15:52:55 GMT"}], "update_date": "2012-11-20", "authors_parsed": [["Bitar", "Ibrahim El", ""], ["Belouadha", "Fatima-Zahra", ""], ["Roudies", "Ounsa", ""]]}, {"id": "1211.4488", "submitter": "Jessica Ram\\'irez", "authors": "Jessica C. Ram\\'irez and Yuji Matsumoto", "title": "A Rule-Based Approach For Aligning Japanese-Spanish Sentences From A\n  Comparable Corpora", "comments": "International Journal on Natural Language Computing (IJNLC) Vol.1,\n  No.3, October 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The performance of a Statistical Machine Translation System (SMT) system is\nproportionally directed to the quality and length of the parallel corpus it\nuses. However for some pair of languages there is a considerable lack of them.\nThe long term goal is to construct a Japanese-Spanish parallel corpus to be\nused for SMT, whereas, there are a lack of useful Japanese-Spanish parallel\nCorpus. To address this problem, In this study we proposed a method for\nextracting Japanese-Spanish Parallel Sentences from Wikipedia using POS tagging\nand Rule-Based approach. The main focus of this approach is the syntactic\nfeatures of both languages. Human evaluation was performed over a sample and\nshows promising results, in comparison with the baseline.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 16:38:32 GMT"}], "update_date": "2012-11-20", "authors_parsed": [["Ram\u00edrez", "Jessica C.", ""], ["Matsumoto", "Yuji", ""]]}, {"id": "1211.4524", "submitter": "Saeid Pashazadeh", "authors": "Mohammad Javad Parseh and Saeid Pashazadeh", "title": "Applying Dynamic Model for Multiple Manoeuvring Target Tracking Using\n  Particle Filtering", "comments": "13 pages, 7 Figures, 1 Table", "journal-ref": "International Journal of Information Technology, Control and\n  Automation (IJITCA), Vol. 2, No. 4, pp. 37-49, 2012", "doi": "10.5121/ijitca.2012.2404", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we applied a dynamic model for manoeuvring targets in SIR\nparticle filter algorithm for improving tracking accuracy of multiple\nmanoeuvring targets. In our proposed approach, a color distribution model is\nused to detect changes of target's model . Our proposed approach controls\ndeformation of target's model. If deformation of target's model is larger than\na predetermined threshold, then the model will be updated. Global Nearest\nNeighbor (GNN) algorithm is used as data association algorithm. We named our\nproposed method as Deformation Detection Particle Filter (DDPF) . DDPF approach\nis compared with basic SIR-PF algorithm on real airshow videos. Comparisons\nresults show that, the basic SIR-PF algorithm is not able to track the\nmanoeuvring targets when the rotation or scaling is occurred in target' s\nmodel. However, DDPF approach updates target's model when the rotation or\nscaling is occurred. Thus, the proposed approach is able to track the\nmanoeuvring targets more efficiently and accurately.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 18:07:44 GMT"}], "update_date": "2014-04-14", "authors_parsed": [["Parseh", "Mohammad Javad", ""], ["Pashazadeh", "Saeid", ""]]}, {"id": "1211.4552", "submitter": "Gabriel Synnaeve", "authors": "Gabriel Synnaeve (LIG, LPPA), Pierre Bessiere (LPPA)", "title": "A Dataset for StarCraft AI \\& an Example of Armies Clustering", "comments": "Artificial Intelligence in Adversarial Real-Time Games 2012, Palo\n  Alto : United States (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper advocates the exploration of the full state of recorded real-time\nstrategy (RTS) games, by human or robotic players, to discover how to reason\nabout tactics and strategy. We present a dataset of StarCraft games\nencompassing the most of the games' state (not only player's orders). We\nexplain one of the possible usages of this dataset by clustering armies on\ntheir compositions. This reduction of armies compositions to mixtures of\nGaussian allow for strategic reasoning at the level of the components. We\nevaluated this clustering method by predicting the outcomes of battles based on\narmies compositions' mixtures components\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 20:18:43 GMT"}], "update_date": "2012-11-20", "authors_parsed": [["Synnaeve", "Gabriel", "", "LIG, LPPA"], ["Bessiere", "Pierre", "", "LPPA"]]}, {"id": "1211.4709", "submitter": "Manjula Shenoy K", "authors": "Manjula Shenoy.K, K.C.Shet, U.Dinesh Acharya", "title": "A New Similarity Measure for Taxonomy Based on Edge Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new similarity measure based on edge counting in a\ntaxonomy like WorldNet or Ontology. Measurement of similarity between text\nsegments or concepts is very useful for many applications like information\nretrieval, ontology matching, text mining, and question answering and so on.\nSeveral measures have been developed for measuring similarity between two\nconcepts: out of these we see that the measure given by Wu and Palmer [1] is\nsimple, and gives good performance. Our measure is based on their measure but\nstrengthens it. Wu and Palmer [1] measure has a disadvantage that it does not\nconsider how far the concepts are semantically. In our measure we include the\nshortest path between the concepts and the depth of whole taxonomy together\nwith the distances used in Wu and Palmer [1]. Also the measure has following\ndisadvantage i.e. in some situations, the similarity of two elements of an IS-A\nontology contained in the neighborhood exceeds the similarity value of two\nelements contained in the same hierarchy. Our measure introduces a penalization\nfactor for this case based upon shortest length between the concepts and depth\nof whole taxonomy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2012 10:53:22 GMT"}], "update_date": "2012-11-21", "authors_parsed": [["K", "Manjula Shenoy.", ""], ["Shet", "K. C.", ""], ["Acharya", "U. Dinesh", ""]]}, {"id": "1211.4957", "submitter": "Antonio Pisasale", "authors": "Antonio Pisasale, Domenico Cantone", "title": "An Experiment on the Connection between the DLs' Family DL<ForAllPiZero>\n  and the Real World", "comments": "15 pages, 2 sections, 2 appendices, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper describes the analysis of a selected testbed of Semantic Web\nontologies, by a SPARQL query, which determines those ontologies that can be\nrelated to the description logic DL<ForAllPiZero>, introduced in [4] and\nstudied in [9]. We will see that a reasonable number of them is expressible\nwithin such computationally efficient language. We expect that, in a long-term\nview, a temporalization of description logics, and consequently, of OWL(2), can\nopen new perspectives for the inclusion in this language of a greater number of\nontologies of the testbed and, hopefully, of the \"real world\".\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2012 08:18:54 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2012 09:59:40 GMT"}], "update_date": "2012-11-26", "authors_parsed": [["Pisasale", "Antonio", ""], ["Cantone", "Domenico", ""]]}, {"id": "1211.5189", "submitter": "Karthik Shankar", "authors": "Karthik H. Shankar and Marc W. Howard", "title": "Optimally fuzzy temporal memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any learner with the ability to predict the future of a structured\ntime-varying signal must maintain a memory of the recent past. If the signal\nhas a characteristic timescale relevant to future prediction, the memory can be\na simple shift register---a moving window extending into the past, requiring\nstorage resources that linearly grows with the timescale to be represented.\nHowever, an independent general purpose learner cannot a priori know the\ncharacteristic prediction-relevant timescale of the signal. Moreover, many\nnaturally occurring signals show scale-free long range correlations implying\nthat the natural prediction-relevant timescale is essentially unbounded. Hence\nthe learner should maintain information from the longest possible timescale\nallowed by resource availability. Here we construct a fuzzy memory system that\noptimally sacrifices the temporal accuracy of information in a scale-free\nfashion in order to represent prediction-relevant information from\nexponentially long timescales. Using several illustrative examples, we\ndemonstrate the advantage of the fuzzy memory system over a shift register in\ntime series forecasting of natural signals. When the available storage\nresources are limited, we suggest that a general purpose learner would be\nbetter off committing to such a fuzzy memory system.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2012 02:38:16 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2013 21:51:42 GMT"}], "update_date": "2013-10-24", "authors_parsed": [["Shankar", "Karthik H.", ""], ["Howard", "Marc W.", ""]]}, {"id": "1211.5371", "submitter": "Tai-Yu Ma", "authors": "Tai-Yu Ma (LET)", "title": "A hybrid cross entropy algorithm for solving dynamic transit network\n  design problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a hybrid multiagent learning algorithm for solving the\ndynamic simulation-based bilevel network design problem. The objective is to\ndetermine the op-timal frequency of a multimodal transit network, which\nminimizes total users' travel cost and operation cost of transit lines. The\nproblem is formulated as a bilevel programming problem with equilibrium\nconstraints describing non-cooperative Nash equilibrium in a dynamic\nsimulation-based transit assignment context. A hybrid algorithm combing the\ncross entropy multiagent learning algorithm and Hooke-Jeeves algorithm is\nproposed. Computational results are provided on the Sioux Falls network to\nillustrate the perform-ance of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2012 20:48:52 GMT"}], "update_date": "2012-11-26", "authors_parsed": [["Ma", "Tai-Yu", "", "LET"]]}, {"id": "1211.5643", "submitter": "Ladislau B\\\"ol\\\"oni", "authors": "Ladislau Boloni", "title": "Shadows and headless shadows: a worlds-based, autobiographical approach\n  to reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many cognitive systems deploy multiple, closed, individually consistent\nmodels which can represent interpretations of the present state of the world,\nmoments in the past, possible futures or alternate versions of reality. While\nthey appear under different names, these structures can be grouped under the\ngeneral term of worlds. The Xapagy architecture is a story-oriented cognitive\nsystem which relies exclusively on the autobiographical memory implemented as a\nraw collection of events organized into world-type structures called {\\em\nscenes}. The system performs reasoning by shadowing current events with events\nfrom the autobiography. The shadows are then extrapolated into headless shadows\ncorresponding to predictions, hidden events or inferred relations.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2012 04:11:37 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["Boloni", "Ladislau", ""]]}, {"id": "1211.5644", "submitter": "Ladislau B\\\"ol\\\"oni", "authors": "Ladislau Boloni", "title": "Modeling problems of identity in Little Red Riding Hood", "comments": "arXiv admin note: text overlap with arXiv:1105.3486", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper argues that the problem of identity is a critical challenge in\nagents which are able to reason about stories. The Xapagy architecture has been\nbuilt from scratch to perform narrative reasoning and relies on a somewhat\nunusual approach to represent instances and identity. We illustrate the\napproach by a representation of the story of Little Red Riding Hood in the\narchitecture, with a focus on the problem of identity raised by the narrative.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2012 04:21:42 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["Boloni", "Ladislau", ""]]}, {"id": "1211.5766", "submitter": "Abdelmalek Amine", "authors": "Reda Mohamed Hamou, Abdelmalek Amine, Ahmed Chaouki Lokbani, Michel\n  Simonet", "title": "Visualization and clustering by 3D cellular automata: Application to\n  unstructured data", "comments": "10 pages, 8 figures", "journal-ref": "International Journal Of Data Mining And Emerging Technologies.\n  2-1 (2012) 15-25", "doi": "10.5958/j.2249-3212.2.1.003", "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the limited performance of 2D cellular automata in terms of space when\nthe number of documents increases and in terms of visualization clusters, our\nmotivation was to experiment these cellular automata by increasing the size to\nview the impact of size on quality of results. The representation of textual\ndata was carried out by a vector model whose components are derived from the\noverall balancing of the used corpus, Term Frequency Inverse Document Frequency\n(TF-IDF). The WorldNet thesaurus has been used to address the problem of the\nlemmatization of the words because the representation used in this study is\nthat of the bags of words. Another independent method of the language was used\nto represent textual records is that of the n-grams. Several measures of\nsimilarity have been tested. To validate the classification we have used two\nmeasures of assessment based on the recall and precision (f-measure and\nentropy). The results are promising and confirm the idea to increase the\ndimension to the problem of the spatiality of the classes. The results obtained\nin terms of purity class (i.e. the minimum value of entropy) shows that the\nnumber of documents over longer believes the results are better for 3D cellular\nautomata, which was not obvious to the 2D dimension. In terms of spatial\nnavigation, cellular automata provide very good 3D performance visualization\nthan 2D cellular automata.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2012 14:24:01 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["Hamou", "Reda Mohamed", ""], ["Amine", "Abdelmalek", ""], ["Lokbani", "Ahmed Chaouki", ""], ["Simonet", "Michel", ""]]}, {"id": "1211.5829", "submitter": "Reza Oji", "authors": "Reza Oji", "title": "An Automatic Algorithm for Object Recognition and Detection Based on\n  ASIFT Keypoints", "comments": "11 pages - 8 figures. arXiv admin note: substantial text overlap with\n  arXiv:1210.7038", "journal-ref": "Signal & Image Processing : An International Journal (SIPIJ)\n  Vol.3, No.5, 2012, pp 29-39", "doi": "10.5121/sipij.2012.3503", "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object recognition is an important task in image processing and computer\nvision. This paper presents a perfect method for object recognition with full\nboundary detection by combining affine scale invariant feature transform\n(ASIFT) and a region merging algorithm. ASIFT is a fully affine invariant\nalgorithm that means features are invariant to six affine parameters namely\ntranslation (2 parameters), zoom, rotation and two camera axis orientations.\nThe features are very reliable and give us strong keypoints that can be used\nfor matching between different images of an object. We trained an object in\nseveral images with different aspects for finding best keypoints of it. Then, a\nrobust region merging algorithm is used to recognize and detect the object with\nfull boundary in the other images based on ASIFT keypoints and a similarity\nmeasure for merging regions in the image. Experimental results show that the\npresented method is very efficient and powerful to recognize the object and\ndetect it with high accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2012 01:10:15 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["Oji", "Reza", ""]]}, {"id": "1211.6097", "submitter": "Ladislau B\\\"ol\\\"oni", "authors": "Ladislau Boloni", "title": "Shadows and Headless Shadows: an Autobiographical Approach to Narrative\n  Reasoning", "comments": "arXiv admin note: substantial text overlap with arXiv:1211.5643", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Xapagy architecture is a story-oriented cognitive system which relies\nexclusively on the autobiographical memory implemented as a raw collection of\nevents. Reasoning is performed by shadowing current events with events from the\nautobiography. The shadows are then extrapolated into headless shadows (HLSs).\nIn a story following mood, HLSs can be used to track the level of surprise of\nthe agent, to infer hidden actions or relations between the participants, and\nto summarize ongoing events. In recall mood, the HLSs can be used to create new\nstories ranging from exact recall to free-form confabulation.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2012 04:35:45 GMT"}], "update_date": "2012-11-28", "authors_parsed": [["Boloni", "Ladislau", ""]]}, {"id": "1211.6205", "submitter": "Farnood Merrikh-Bayat", "authors": "Farnood Merrikh-Bayat, Farshad Merrikh-Bayat, and Saeed Bagheri\n  Shouraki", "title": "Neuro-Fuzzy Computing System with the Capacity of Implementation on\n  Memristor-Crossbar and Optimization-Free Hardware Training", "comments": "16 pages, 11 images, submitted to IEEE Trans. on Fuzzy systems", "journal-ref": null, "doi": "10.1109/TFUZZ.2013.2290140", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, first we present a new explanation for the relation between\nlogical circuits and artificial neural networks, logical circuits and fuzzy\nlogic, and artificial neural networks and fuzzy inference systems. Then, based\non these results, we propose a new neuro-fuzzy computing system which can\neffectively be implemented on the memristor-crossbar structure. One important\nfeature of the proposed system is that its hardware can directly be trained\nusing the Hebbian learning rule and without the need to any optimization. The\nsystem also has a very good capability to deal with huge number of input-out\ntraining data without facing problems like overtraining.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2012 03:51:44 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Merrikh-Bayat", "Farnood", ""], ["Merrikh-Bayat", "Farshad", ""], ["Shouraki", "Saeed Bagheri", ""]]}, {"id": "1211.6409", "submitter": "Mohammed El-Dosuky", "authors": "Mohammed El-Dosuky, Ahmed EL-Bassiouny, Taher Hamza and Magdy Rashad", "title": "Obesity Heuristic, New Way On Artificial Immune Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a need for new metaphors from immunology to flourish the application\nareas of Artificial Immune Systems. A metaheuristic called Obesity Heuristic\nderived from advances in obesity treatment is proposed. The main forces of the\nalgorithm are the generation omega-6 and omega-3 fatty acids. The algorithm\nworks with Just-In-Time philosophy; by starting only when desired. A case study\nof data cleaning is provided. With experiments conducted on standard tables,\nresults show that Obesity Heuristic outperforms other algorithms, with 100%\nrecall. This is a great improvement over other algorithms\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2012 01:34:45 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["El-Dosuky", "Mohammed", ""], ["EL-Bassiouny", "Ahmed", ""], ["Hamza", "Taher", ""], ["Rashad", "Magdy", ""]]}, {"id": "1211.6410", "submitter": "Mohammed El-Dosuky", "authors": "Mohammed El-Dosuky, Ahmed EL-Bassiouny, Taher Hamza and Magdy Rashad", "title": "New Hoopoe Heuristic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most optimization problems in real life applications are often highly\nnonlinear. Local optimization algorithms do not give the desired performance.\nSo, only global optimization algorithms should be used to obtain optimal\nsolutions. This paper introduces a new nature-inspired metaheuristic\noptimization algorithm, called Hoopoe Heuristic (HH). In this paper, we will\nstudy HH and validate it against some test functions. Investigations show that\nit is very promising and could be seen as an optimization of the powerful\nalgorithm of cuckoo search. Finally, we discuss the features of Hoopoe\nHeuristic and propose topics for further studies.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2012 01:30:36 GMT"}], "update_date": "2012-11-28", "authors_parsed": [["El-Dosuky", "Mohammed", ""], ["EL-Bassiouny", "Ahmed", ""], ["Hamza", "Taher", ""], ["Rashad", "Magdy", ""]]}, {"id": "1211.6411", "submitter": "Mohammed El-Dosuky", "authors": "Mohammed El-Dosuky, Ahmed EL-Bassiouny, Taher Hamza and Magdy Rashad", "title": "New Heuristics for Interfacing Human Motor System using Brain Waves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many new forms of interfacing human users to machines. We persevere\nhere electric mechanical form of interaction between human and machine. The\nemergence of brain-computer interface allows mind-to-movement systems. The\nstory of the Pied Piper inspired us to devise some new heuristics for\ninterfacing human motor system using brain waves by combining head helmet and\nLumbarMotionMonitor For the simulation we use java GridGain Brain responses of\nclassified subjects during training indicates that Probe can be the best\nstimulus to rely on in distinguishing between knowledgeable and not\nknowledgeable\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2012 01:21:25 GMT"}], "update_date": "2012-11-28", "authors_parsed": [["El-Dosuky", "Mohammed", ""], ["EL-Bassiouny", "Ahmed", ""], ["Hamza", "Taher", ""], ["Rashad", "Magdy", ""]]}, {"id": "1211.6496", "submitter": "Naushad UzZaman Naushad UzZaman", "authors": "Naushad UzZaman, Roi Blanco, Michael Matthews", "title": "TwitterPaul: Extracting and Aggregating Twitter Predictions", "comments": "Check out the blog post with a summary and Prediction Retrieval\n  information here: http://bitly.com/TwitterPaul", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces TwitterPaul, a system designed to make use of Social\nMedia data to help to predict game outcomes for the 2010 FIFA World Cup\ntournament. To this end, we extracted over 538K mentions to football games from\na large sample of tweets that occurred during the World Cup, and we classified\ninto different types with a precision of up to 88%. The different mentions were\naggregated in order to make predictions about the outcomes of the actual games.\nWe attempt to learn which Twitter users are accurate predictors and explore\nseveral techniques in order to exploit this information to make more accurate\npredictions. We compare our results to strong baselines and against the betting\nline (prediction market) and found that the quality of extractions is more\nimportant than the quantity, suggesting that high precision methods working on\na medium-sized dataset are preferable over low precision methods that use a\nlarger amount of data. Finally, by aggregating some classes of predictions, the\nsystem performance is close to the one of the betting line. Furthermore, we\nbelieve that this domain independent framework can help to predict other\nsports, elections, product release dates and other future events that people\ntalk about in social media.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2012 01:33:21 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2012 16:55:53 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["UzZaman", "Naushad", ""], ["Blanco", "Roi", ""], ["Matthews", "Michael", ""]]}, {"id": "1211.6610", "submitter": "Muhamed Halilovic", "authors": "Muhamed Halilovic, Abdulhamit Subasi", "title": "Intrusion Detection on Smartphones", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphone technology is more and more becoming the predominant communication\ntool for people across the world. People use their smartphones to keep their\ncontact data, to browse the internet, to exchange messages, to keep notes,\ncarry their personal files and documents, etc. Users while browsing are also\ncapable of shopping online, thus provoking a need to type their credit card\nnumbers and security codes. As the smartphones are becoming widespread so do\nthe security threats and vulnerabilities facing this technology. Recent news\nand articles indicate huge increase in malware and viruses for operating\nsystems employed on smartphones (primarily Android and iOS). Major limitations\nof smartphone technology are its processing power and its scarce energy source\nsince smartphones rely on battery usage. Since smartphones are devices which\nchange their network location as the user moves between different places,\nintrusion detection systems for smartphone technology are most often classified\nas IDSs designed for mobile ad-hoc networks. The aim of this research is to\ngive a brief overview of IDS technology, give an overview of major machine\nlearning and pattern recognition algorithms used in IDS technologies, give an\noverview of security models of iOS and Android and propose a new host-based IDS\nmodel for smartphones and create proof-of-concept application for Android\nplatform for the newly proposed model. Keywords: IDS, SVM, Android, iOS;\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2012 14:34:18 GMT"}], "update_date": "2012-11-29", "authors_parsed": [["Halilovic", "Muhamed", ""], ["Subasi", "Abdulhamit", ""]]}, {"id": "1211.6616", "submitter": "Rongpeng Li", "authors": "Rongpeng Li, Zhifeng Zhao, Xianfu Chen, Jacques Palicot, Honggang\n  Zhang", "title": "TACT: A Transfer Actor-Critic Learning Framework for Energy Saving in\n  Cellular Radio Access Networks", "comments": "11 figures, 30 pages, accepted in IEEE Transactions on Wireless\n  Communications 2014. IEEE Trans. Wireless Commun., Feb. 2014", "journal-ref": null, "doi": "10.1109/TWC.2014.022014.130840", "report-no": null, "categories": "cs.NI cs.AI cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Recent works have validated the possibility of improving energy efficiency in\nradio access networks (RANs), achieved by dynamically turning on/off some base\nstations (BSs). In this paper, we extend the research over BS switching\noperations, which should match up with traffic load variations. Instead of\ndepending on the dynamic traffic loads which are still quite challenging to\nprecisely forecast, we firstly formulate the traffic variations as a Markov\ndecision process. Afterwards, in order to foresightedly minimize the energy\nconsumption of RANs, we design a reinforcement learning framework based BS\nswitching operation scheme. Furthermore, to avoid the underlying curse of\ndimensionality in reinforcement learning, a transfer actor-critic algorithm\n(TACT), which utilizes the transferred learning expertise in historical periods\nor neighboring regions, is proposed and provably converges. In the end, we\nevaluate our proposed scheme by extensive simulations under various practical\nconfigurations and show that the proposed TACT algorithm contributes to a\nperformance jumpstart and demonstrates the feasibility of significant energy\nefficiency improvement at the expense of tolerable delay performance.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2012 14:48:36 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2013 00:37:28 GMT"}, {"version": "v3", "created": "Fri, 4 Apr 2014 07:37:14 GMT"}], "update_date": "2014-04-07", "authors_parsed": [["Li", "Rongpeng", ""], ["Zhao", "Zhifeng", ""], ["Chen", "Xianfu", ""], ["Palicot", "Jacques", ""], ["Zhang", "Honggang", ""]]}, {"id": "1211.6727", "submitter": "Qichao Que", "authors": "Mikhail Belkin and Qichao Que and Yusu Wang and Xueyuan Zhou", "title": "Graph Laplacians on Singular Manifolds: Toward understanding complex\n  spaces: graph Laplacians on manifolds with singularities and boundaries", "comments": null, "journal-ref": "JMLR W&CP 23: 36.1 - 36.26, 2012", "doi": null, "report-no": null, "categories": "cs.AI cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, much of the existing work in manifold learning has been done under\nthe assumption that the data is sampled from a manifold without boundaries and\nsingularities or that the functions of interest are evaluated away from such\npoints. At the same time, it can be argued that singularities and boundaries\nare an important aspect of the geometry of realistic data.\n  In this paper we consider the behavior of graph Laplacians at points at or\nnear boundaries and two main types of other singularities: intersections, where\ndifferent manifolds come together and sharp \"edges\", where a manifold sharply\nchanges direction. We show that the behavior of graph Laplacian near these\nsingularities is quite different from that in the interior of the manifolds. In\nfact, a phenomenon somewhat reminiscent of the Gibbs effect in the analysis of\nFourier series, can be observed in the behavior of graph Laplacian near such\npoints. Unlike in the interior of the domain, where graph Laplacian converges\nto the Laplace-Beltrami operator, near singularities graph Laplacian tends to a\nfirst-order differential operator, which exhibits different scaling behavior as\na function of the kernel width. One important implication is that while points\nnear the singularities occupy only a small part of the total volume, the\ndifference in scaling results in a disproportionately large contribution to the\ntotal behavior. Another significant finding is that while the scaling behavior\nof the operator is the same near different types of singularities, they are\nvery distinct at a more refined level of analysis.\n  We believe that a comprehensive understanding of these structures in addition\nto the standard case of a smooth manifold can take us a long way toward better\nmethods for analysis of complex non-linear data and can lead to significant\nprogress in algorithm design.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2012 20:10:42 GMT"}], "update_date": "2012-11-29", "authors_parsed": [["Belkin", "Mikhail", ""], ["Que", "Qichao", ""], ["Wang", "Yusu", ""], ["Zhou", "Xueyuan", ""]]}, {"id": "1211.6898", "submitter": "Bruno Scherrer", "authors": "Bruno Scherrer (INRIA Nancy - Grand Est / LORIA), Boris Lesner (INRIA\n  Nancy - Grand Est / LORIA)", "title": "On the Use of Non-Stationary Policies for Stationary Infinite-Horizon\n  Markov Decision Processes", "comments": null, "journal-ref": "NIPS 2012 (2012)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider infinite-horizon stationary $\\gamma$-discounted Markov Decision\nProcesses, for which it is known that there exists a stationary optimal policy.\nUsing Value and Policy Iteration with some error $\\epsilon$ at each iteration,\nit is well-known that one can compute stationary policies that are\n$\\frac{2\\gamma}{(1-\\gamma)^2}\\epsilon$-optimal. After arguing that this\nguarantee is tight, we develop variations of Value and Policy Iteration for\ncomputing non-stationary policies that can be up to\n$\\frac{2\\gamma}{1-\\gamma}\\epsilon$-optimal, which constitutes a significant\nimprovement in the usual situation when $\\gamma$ is close to 1. Surprisingly,\nthis shows that the problem of \"computing near-optimal non-stationary policies\"\nis much simpler than that of \"computing near-optimal stationary policies\".\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2012 12:54:58 GMT"}], "update_date": "2012-11-30", "authors_parsed": [["Scherrer", "Bruno", "", "INRIA Nancy - Grand Est / LORIA"], ["Lesner", "Boris", "", "INRIA\n  Nancy - Grand Est / LORIA"]]}, {"id": "1211.6971", "submitter": "Issam Qaffou", "authors": "Issam Qaffou, Mohamed Sadgal, Aziz Elfazziki", "title": "A New Automatic Method to Adjust Parameters for Object Recognition", "comments": null, "journal-ref": "IJACSA 2012", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To recognize an object in an image, the user must apply a combination of\noperators, where each operator has a set of parameters. These parameters must\nbe well adjusted in order to reach good results. Usually, this adjustment is\nmade manually by the user. In this paper we propose a new method to automate\nthe process of parameter adjustment for an object recognition task. Our method\nis based on reinforcement learning, we use two types of agents: User Agent that\ngives the necessary information and Parameter Agent that adjusts the parameters\nof each operator. Due to the nature of reinforcement learning the results do\nnot depend only on the system characteristics but also on the user favorite\nchoices.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2012 16:35:07 GMT"}], "update_date": "2012-11-30", "authors_parsed": [["Qaffou", "Issam", ""], ["Sadgal", "Mohamed", ""], ["Elfazziki", "Aziz", ""]]}, {"id": "1211.7012", "submitter": "Cezary Kaliszyk", "authors": "Cezary Kaliszyk and Josef Urban", "title": "Learning-Assisted Automated Reasoning with Flyspeck", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The considerable mathematical knowledge encoded by the Flyspeck project is\ncombined with external automated theorem provers (ATPs) and machine-learning\npremise selection methods trained on the proofs, producing an AI system capable\nof answering a wide range of mathematical queries automatically. The\nperformance of this architecture is evaluated in a bootstrapping scenario\nemulating the development of Flyspeck from axioms to the last theorem, each\ntime using only the previous theorems and proofs. It is shown that 39% of the\n14185 theorems could be proved in a push-button mode (without any high-level\nadvice and user interaction) in 30 seconds of real time on a fourteen-CPU\nworkstation. The necessary work involves: (i) an implementation of sound\ntranslations of the HOL Light logic to ATP formalisms: untyped first-order,\npolymorphic typed first-order, and typed higher-order, (ii) export of the\ndependency information from HOL Light and ATP proofs for the machine learners,\nand (iii) choice of suitable representations and methods for learning from\nprevious proofs, and their integration as advisors with HOL Light. This work is\ndescribed and discussed here, and an initial analysis of the body of proofs\nthat were found fully automatically is provided.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2012 18:15:10 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2013 09:20:30 GMT"}, {"version": "v3", "created": "Sun, 26 Oct 2014 15:02:54 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1211.7210", "submitter": "Tina Yu", "authors": "Tina Yu and Radel Ben-Av", "title": "Evolutionarily Stable Sets in Quantum Penny Flip Games", "comments": "25 pages, Quantum Information Processing Journal", "journal-ref": "Quantum Information Processing Journal, Volume 12, Issue 6, pp\n  2143-2165, June 2013", "doi": "10.1007/s11128-012-0515-3", "report-no": null, "categories": "quant-ph cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In game theory, an Evolutionarily Stable Set (ES set) is a set of Nash\nEquilibrium (NE) strategies that give the same payoffs. Similar to an\nEvolutionarily Stable Strategy (ES strategy), an ES set is also a strict NE.\nThis work investigates the evolutionary stability of classical and quantum\nstrategies in the quantum penny flip games. In particular, we developed an\nevolutionary game theory model to conduct a series of simulations where a\npopulation of mixed classical strategies from the ES set of the game were\ninvaded by quantum strategies. We found that when only one of the two players'\nmixed classical strategies were invaded, the results were different. In one\ncase, due to the interference phenomenon of superposition, quantum strategies\nprovided more payoff, hence successfully replaced the mixed classical\nstrategies in the ES set. In the other case, the mixed classical strategies\nwere able to sustain the invasion of quantum strategies and remained in the ES\nset. Moreover, when both players' mixed classical strategies were invaded by\nquantum strategies, a new quantum ES set emerged. The strategies in the quantum\nES set give both players payoff 0, which is the same as the payoff of the\nstrategies in the mixed classical ES set of this game.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2012 11:00:15 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Yu", "Tina", ""], ["Ben-Av", "Radel", ""]]}]