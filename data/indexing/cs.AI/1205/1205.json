[{"id": "1205.0243", "submitter": "Andino Maseleno", "authors": "Andino Maseleno, Md. Mahmud Hasan", "title": "Poultry Diseases Expert System using Dempster-Shafer Theory", "comments": "Brunei International Conference and Engineering Technology 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.AP", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Based on World Health Organization (WHO) fact sheet in the 2011, outbreaks of\npoultry diseases especially Avian Influenza in poultry may raise global public\nhealth concerns due to their effect on poultry populations, their potential to\ncause serious disease in people, and their pandemic potential. In this\nresearch, we built a Poultry Diseases Expert System using Dempster-Shafer\nTheory. In this Poultry Diseases Expert System We describe five symptoms which\ninclude depression, combs, wattle, bluish face region, swollen face region,\nnarrowness of eyes, and balance disorders. The result of the research is that\nPoultry Diseases Expert System has been successfully identifying poultry\ndiseases.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2012 00:19:47 GMT"}, {"version": "v2", "created": "Sun, 6 May 2012 04:11:42 GMT"}], "update_date": "2012-05-08", "authors_parsed": [["Maseleno", "Andino", ""], ["Hasan", "Md. Mahmud", ""]]}, {"id": "1205.0622", "submitter": "Marc Lanctot", "authors": "Marc Lanctot, Richard Gibson, Neil Burch, Martin Zinkevich, and\n  Michael Bowling", "title": "No-Regret Learning in Extensive-Form Games with Imperfect Recall", "comments": "21 pages, 4 figures, expanded version of article to appear in\n  Proceedings of the Twenty-Ninth International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual Regret Minimization (CFR) is an efficient no-regret learning\nalgorithm for decision problems modeled as extensive games. CFR's regret bounds\ndepend on the requirement of perfect recall: players always remember\ninformation that was revealed to them and the order in which it was revealed.\nIn games without perfect recall, however, CFR's guarantees do not apply. In\nthis paper, we present the first regret bound for CFR when applied to a general\nclass of games with imperfect recall. In addition, we show that CFR applied to\nany abstraction belonging to our general class results in a regret bound not\njust for the abstract game, but for the full game as well. We verify our theory\nand show how imperfect recall can be used to trade a small increase in regret\nfor a significant reduction in memory in three domains: die-roll poker, phantom\ntic-tac-toe, and Bluff.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2012 05:54:14 GMT"}], "update_date": "2012-05-04", "authors_parsed": [["Lanctot", "Marc", ""], ["Gibson", "Richard", ""], ["Burch", "Neil", ""], ["Zinkevich", "Martin", ""], ["Bowling", "Michael", ""]]}, {"id": "1205.0831", "submitter": "Andino Maseleno", "authors": "Andino Maseleno, Md. Mahmud Hasan", "title": "African Trypanosomiasis Detection using Dempster-Shafer Theory", "comments": null, "journal-ref": "International Journal of Emerging Trends in Computing and\n  Information Sciences, Vol. 3, No. 4, 2012, pp. 480 - 487", "doi": null, "report-no": null, "categories": "cs.AI stat.CO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  World Health Organization reports that African Trypanosomiasis affects mostly\npoor populations living in remote rural areas of Africa that can be fatal if\nproperly not treated. This paper presents Dempster-Shafer Theory for the\ndetection of African trypanosomiasis. Sustainable elimination of African\ntrypanosomiasis as a public-health problem is feasible and requires continuous\nefforts and innovative approaches. In this research, we implement\nDempster-Shafer theory for detecting African trypanosomiasis and displaying the\nresult of detection process. We describe eleven symptoms as major symptoms\nwhich include fever, red urine, skin rash, paralysis, headache, bleeding around\nthe bite, joint the paint, swollen lymph nodes, sleep disturbances, meningitis\nand arthritis. Dempster-Shafer theory to quantify the degree of belief, our\napproach uses Dempster-Shafer theory to combine beliefs under conditions of\nuncertainty and ignorance, and allows quantitative measurement of the belief\nand plausibility in our identification result.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2012 22:33:34 GMT"}], "update_date": "2012-05-07", "authors_parsed": [["Maseleno", "Andino", ""], ["Hasan", "Md. Mahmud", ""]]}, {"id": "1205.0917", "submitter": "Omri Mohamed Nazih", "authors": "Radhouane Boughamoura, Lobna Hlaoua and Mohamed Nazih Omri", "title": "VIQI: A New Approach for Visual Interpretation of Deep Web Query\n  Interfaces", "comments": "8th NCM: 2012 International Conference on Networked Computing and\n  Advanced Information Management", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Web databases contain more than 90% of pertinent information of the Web.\nDespite their importance, users don't profit of this treasury. Many deep web\nservices are offering competitive services in term of prices, quality of\nservice, and facilities. As the number of services is growing rapidly, users\nhave difficulty to ask many web services in the same time. In this paper, we\nimagine a system where users have the possibility to formulate one query using\none query interface and then the system translates query to the rest of query\ninterfaces. However, interfaces are created by designers in order to be\ninterpreted visually by users, machines can not interpret query from a given\ninterface. We propose a new approach which emulates capacity of interpretation\nof users and extracts query from deep web query interfaces. Our approach has\nproved good performances on two standard datasets.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2012 11:01:42 GMT"}], "update_date": "2012-05-07", "authors_parsed": [["Boughamoura", "Radhouane", ""], ["Hlaoua", "Lobna", ""], ["Omri", "Mohamed Nazih", ""]]}, {"id": "1205.0986", "submitter": "Wendelin B\\\"ohmer", "authors": "Wendelin B\\\"ohmer", "title": "Robot Navigation using Reinforcement Learning and Slow Feature Analysis", "comments": "Diploma Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of reinforcement learning algorithms onto real life problems\nalways bears the challenge of filtering the environmental state out of raw\nsensor readings. While most approaches use heuristics, biology suggests that\nthere must exist an unsupervised method to construct such filters\nautomatically. Besides the extraction of environmental states, the filters have\nto represent them in a fashion that support modern reinforcement algorithms.\nMany popular algorithms use a linear architecture, so one should aim at filters\nthat have good approximation properties in combination with linear functions.\nThis thesis wants to propose the unsupervised method slow feature analysis\n(SFA) for this task. Presented with a random sequence of sensor readings, SFA\nlearns a set of filters. With growing model complexity and training examples,\nthe filters converge against trigonometric polynomial functions. These are\nknown to possess excellent approximation capabilities and should therfore\nsupport the reinforcement algorithms well. We evaluate this claim on a robot.\nThe task is to learn a navigational control in a simple environment using the\nleast square policy iteration (LSPI) algorithm. The only accessible sensor is a\nhead mounted video camera, but without meaningful filtering, video images are\nnot suited as LSPI input. We will show that filters learned by SFA, based on a\nrandom walk video of the robot, allow the learned control to navigate\nsuccessfully in ca. 80% of the test trials.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2012 15:32:43 GMT"}], "update_date": "2012-05-07", "authors_parsed": [["B\u00f6hmer", "Wendelin", ""]]}, {"id": "1205.1638", "submitter": "Aji S", "authors": "Aji S, Ramachandra Kaimal", "title": "Document summarization using positive pointwise mutual information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The degree of success in document summarization processes depends on the\nperformance of the method used in identifying significant sentences in the\ndocuments. The collection of unique words characterizes the major signature of\nthe document, and forms the basis for Term-Sentence-Matrix (TSM). The Positive\nPointwise Mutual Information, which works well for measuring semantic\nsimilarity in the Term-Sentence-Matrix, is used in our method to assign weights\nfor each entry in the Term-Sentence-Matrix. The Sentence-Rank-Matrix generated\nfrom this weighted TSM, is then used to extract a summary from the document.\nOur experiments show that such a method would outperform most of the existing\nmethods in producing summaries from large documents.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 09:19:10 GMT"}], "update_date": "2012-05-09", "authors_parsed": [["S", "Aji", ""], ["Kaimal", "Ramachandra", ""]]}, {"id": "1205.1645", "submitter": "Fran\\c{c}ois Scharffe", "authors": "Julien Plu and Fran\\c{c}ois Scharffe", "title": "Publishing and linking transport data on the Web", "comments": "Presented at the First International Workshop On Open Data, WOD-2012\n  (http://arxiv.org/abs/1204.3726)", "journal-ref": null, "doi": null, "report-no": "WOD/2012/NANTES/13", "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Without Linked Data, transport data is limited to applications exclusively\naround transport. In this paper, we present a workflow for publishing and\nlinking transport data on the Web. So we will be able to develop transport\napplications and to add other features which will be created from other\ndatasets. This will be possible because transport data will be linked to these\ndatasets. We apply this workflow to two datasets: NEPTUNE, a French standard\ndescribing a transport line, and Passim, a directory containing relevant\ninformation on transport services, in every French city.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 09:50:35 GMT"}], "update_date": "2012-05-09", "authors_parsed": [["Plu", "Julien", ""], ["Scharffe", "Fran\u00e7ois", ""]]}, {"id": "1205.1794", "submitter": "Behrouz Abdolali", "authors": "Behrouz Abdolali and Hossein Sameti", "title": "A Novel Method For Speech Segmentation Based On Speakers'\n  Characteristics", "comments": "14 pages, 8 figures", "journal-ref": "B. Abdolali, H. Sameti \"A Novel Method for Speech Segmentation\n  based on Speakers' Specifications\", Signal & Image Processing: An\n  International Journal (SIPIJ) Vol.3, No.2, pp. 65-78, April 2012", "doi": "10.5121/sipij.2012.3205", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech Segmentation is the process change point detection for partitioning an\ninput audio stream into regions each of which corresponds to only one audio\nsource or one speaker. One application of this system is in Speaker Diarization\nsystems. There are several methods for speaker segmentation; however, most of\nthe Speaker Diarization Systems use BIC-based Segmentation methods. The main\ngoal of this paper is to propose a new method for speaker segmentation with\nhigher speed than the current methods - e.g. BIC - and acceptable accuracy. Our\nproposed method is based on the pitch frequency of the speech. The accuracy of\nthis method is similar to the accuracy of common speaker segmentation methods.\nHowever, its computation cost is much less than theirs. We show that our method\nis about 2.4 times faster than the BIC-based method, while the average accuracy\nof pitch-based method is slightly higher than that of the BIC-based method.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 19:54:13 GMT"}], "update_date": "2012-05-09", "authors_parsed": [["Abdolali", "Behrouz", ""], ["Sameti", "Hossein", ""]]}, {"id": "1205.1820", "submitter": "Paola Zizzi", "authors": "Paola Zizzi", "title": "The non-algorithmic side of the mind", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of a non-algorithmic side of the mind, conjectured by Penrose\non the basis of G\\\"odel's first incompleteness theorem, is investigated here in\nterms of a quantum metalanguage. We suggest that, besides human ordinary\nthought, which can be formalized in a computable, logical language, there is\nanother important kind of human thought, which is Turing-non-computable. This\nis methatought, the process of thinking about ordinary thought. Metathought can\nbe formalized as a metalanguage, which speaks about and controls the logical\nlanguage of ordinary thought. Ordinary thought has two computational modes, the\nquantum mode and the classical mode, the latter deriving from decoherence of\nthe former. In order to control the logical language of the quantum mode, one\nneeds to introduce a quantum metalanguage, which in turn requires a quantum\nversion of Tarski Convention T.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2012 17:24:03 GMT"}], "update_date": "2012-05-10", "authors_parsed": [["Zizzi", "Paola", ""]]}, {"id": "1205.2046", "submitter": "Mark Levin", "authors": "Mark Sh. Levin", "title": "Multiset Estimates and Combinatorial Synthesis", "comments": "30 pages, 24 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper addresses an approach to ordinal assessment of alternatives based\non assignment of elements into an ordinal scale. Basic versions of the\nassessment problems are formulated while taking into account the number of\nlevels at a basic ordinal scale [1,2,...,l] and the number of assigned elements\n(e.g., 1,2,3). The obtained estimates are multisets (or bags) (cardinality of\nthe multiset equals a constant). Scale-posets for the examined assessment\nproblems are presented. 'Interval multiset estimates' are suggested. Further,\noperations over multiset estimates are examined: (a) integration of multiset\nestimates, (b) proximity for multiset estimates, (c) comparison of multiset\nestimates, (d) aggregation of multiset estimates, and (e) alignment of multiset\nestimates. Combinatorial synthesis based on morphological approach is examined\nincluding the modified version of the approach with multiset estimates of\ndesign alternatives. Knapsack-like problems with multiset estimates are briefly\ndescribed as well. The assessment approach, multiset-estimates, and\ncorresponding combinatorial problems are illustrated by numerical examples.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 17:42:36 GMT"}], "update_date": "2012-05-10", "authors_parsed": [["Levin", "Mark Sh.", ""]]}, {"id": "1205.2382", "submitter": "Mete Ozay", "authors": "Mete Ozay, Ilke \\\"Oztekin, Uygar \\\"Oztekin, Fatos T. Yarman Vural", "title": "Mesh Learning for Classifying Cognitive Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A relatively recent advance in cognitive neuroscience has been multi-voxel\npattern analysis (MVPA), which enables researchers to decode brain states\nand/or the type of information represented in the brain during a cognitive\noperation. MVPA methods utilize machine learning algorithms to distinguish\namong types of information or cognitive states represented in the brain, based\non distributed patterns of neural activity. In the current investigation, we\npropose a new approach for representation of neural data for pattern analysis,\nnamely a Mesh Learning Model. In this approach, at each time instant, a star\nmesh is formed around each voxel, such that the voxel corresponding to the\ncenter node is surrounded by its p-nearest neighbors. The arc weights of each\nmesh are estimated from the voxel intensity values by least squares method. The\nestimated arc weights of all the meshes, called Mesh Arc Descriptors (MADs),\nare then used to train a classifier, such as Neural Networks, k-Nearest\nNeighbor, Na\\\"ive Bayes and Support Vector Machines. The proposed Mesh Model\nwas tested on neuroimaging data acquired via functional magnetic resonance\nimaging (fMRI) during a recognition memory experiment using categorized word\nlists, employing a previously established experimental paradigm (\\\"Oztekin &\nBadre, 2011). Results suggest that the proposed Mesh Learning approach can\nprovide an effective algorithm for pattern analysis of brain activity during\ncognitive processing.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2012 20:22:17 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2012 17:44:03 GMT"}, {"version": "v3", "created": "Thu, 5 Feb 2015 21:50:00 GMT"}], "update_date": "2015-02-09", "authors_parsed": [["Ozay", "Mete", ""], ["\u00d6ztekin", "Ilke", ""], ["\u00d6ztekin", "Uygar", ""], ["Vural", "Fatos T. Yarman", ""]]}, {"id": "1205.2541", "submitter": "Changzhong Wang", "authors": "Changzhong Wang, Baiqing Sun, Qinhua Hu", "title": "An improved approach to attribute reduction with covering rough sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribute reduction is viewed as an important preprocessing step for pattern\nrecognition and data mining. Most of researches are focused on attribute\nreduction by using rough sets. Recently, Tsang et al. discussed attribute\nreduction with covering rough sets in the paper [E. C.C. Tsang, D. Chen, Daniel\nS. Yeung, Approximations and reducts with covering generalized rough sets,\nComputers and Mathematics with Applications 56 (2008) 279-289], where an\napproach based on discernibility matrix was presented to compute all attribute\nreducts. In this paper, we provide an improved approach by constructing simpler\ndiscernibility matrix with covering rough sets, and then proceed to improve\nsome characterizations of attribute reduction provided by Tsang et al. It is\nproved that the improved discernible matrix is equivalent to the old one, but\nthe computational complexity of discernible matrix is greatly reduced.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2012 14:45:52 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Wang", "Changzhong", ""], ["Sun", "Baiqing", ""], ["Hu", "Qinhua", ""]]}, {"id": "1205.2596", "submitter": "Fabio Cozman", "authors": "Fabio Cozman and Avi Pfeffer", "title": "Proceedings of the Twenty-Seventh Conference on Uncertainty in\n  Artificial Intelligence (2011)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI2011", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Twenty-Seventh Conference on Uncertainty in\nArtificial Intelligence, which was held in Barcelona, Spain, July 14 - 17 2011.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2012 18:35:50 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 04:30:01 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Cozman", "Fabio", ""], ["Pfeffer", "Avi", ""]]}, {"id": "1205.2597", "submitter": "Peter Grunwald", "authors": "Peter Grunwald and Peter Spirtes", "title": "Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial\n  Intelligence (2010)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI2010", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Twenty-Sixth Conference on Uncertainty in\nArtificial Intelligence, which was held on Catalina Island, CA, July 8 - 11\n2010.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2012 18:40:29 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 04:29:00 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Grunwald", "Peter", ""], ["Spirtes", "Peter", ""]]}, {"id": "1205.2601", "submitter": "Changhe Yuan", "authors": "Changhe Yuan, Xiaolu Liu, Tsai-Ching Lu, Heejin Lim", "title": "Most Relevant Explanation: Properties, Algorithms, and Evaluations", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-631-638", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most Relevant Explanation (MRE) is a method for finding multivariate\nexplanations for given evidence in Bayesian networks [12]. This paper studies\nthe theoretical properties of MRE and develops an algorithm for finding\nmultiple top MRE solutions. Our study shows that MRE relies on an implicit soft\nrelevance measure in automatically identifying the most relevant target\nvariables and pruning less relevant variables from an explanation. The soft\nmeasure also enables MRE to capture the intuitive phenomenon of explaining away\nencoded in Bayesian networks. Furthermore, our study shows that the solution\nspace of MRE has a special lattice structure which yields interesting dominance\nrelations among the solutions. A K-MRE algorithm based on these dominance\nrelations is developed for generating a set of top solutions that are more\nrepresentative. Our empirical results show that MRE methods are promising\napproaches for explanation in Bayesian networks.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:47:26 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Yuan", "Changhe", ""], ["Liu", "Xiaolu", ""], ["Lu", "Tsai-Ching", ""], ["Lim", "Heejin", ""]]}, {"id": "1205.2603", "submitter": "Tianbao Yang", "authors": "Tianbao Yang, Rong Jin, Yun Chi, Shenghuo Zhu", "title": "A Bayesian Framework for Community Detection Integrating Content and\n  Link", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-615-622", "categories": "cs.SI cs.AI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of community detection in networked data\nthat combines link and content analysis. Most existing work combines link and\ncontent information by a generative model. There are two major shortcomings\nwith the existing approaches. First, they assume that the probability of\ncreating a link between two nodes is determined only by the community\nmemberships of the nodes; however other factors (e.g. popularity) could also\naffect the link pattern. Second, they use generative models to model the\ncontent of individual nodes, whereas these generative models are vulnerable to\nthe content attributes that are irrelevant to communities. We propose a\nBayesian framework for combining link and content information for community\ndetection that explicitly addresses these shortcomings. A new link model is\npresented that introduces a random variable to capture the node popularity when\ndeciding the link between two nodes; a discriminative model is used to\ndetermine the community membership of a node by its content. An approximate\ninference algorithm is presented for efficient Bayesian inference. Our\nempirical study shows that the proposed framework outperforms several\nstate-of-theart approaches in combining link and content information for\ncommunity detection.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:45:08 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Yang", "Tianbao", ""], ["Jin", "Rong", ""], ["Chi", "Yun", ""], ["Zhu", "Shenghuo", ""]]}, {"id": "1205.2606", "submitter": "Thomas J. Walsh", "authors": "Thomas J. Walsh, Istvan Szita, Carlos Diuk, Michael L. Littman", "title": "Exploring compact reinforcement-learning representations with linear\n  regression", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-591-598", "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new algorithm for online linear regression whose\nefficiency guarantees satisfy the requirements of the KWIK (Knows What It\nKnows) framework. The algorithm improves on the complexity bounds of the\ncurrent state-of-the-art procedure in this setting. We explore several\napplications of this algorithm for learning compact reinforcement-learning\nrepresentations. We show that KWIK linear regression can be used to learn the\nreward function of a factored MDP and the probabilities of action outcomes in\nStochastic STRIPS and Object Oriented MDPs, none of which have been proven to\nbe efficiently learnable in the RL setting before. We also combine KWIK linear\nregression with other KWIK learners to learn larger portions of these models,\nincluding experiments on learning factored MDP transition and reward functions\ntogether.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:40:40 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Walsh", "Thomas J.", ""], ["Szita", "Istvan", ""], ["Diuk", "Carlos", ""], ["Littman", "Michael L.", ""]]}, {"id": "1205.2613", "submitter": "Matthias Thimm", "authors": "Matthias Thimm", "title": "Measuring Inconsistency in Probabilistic Knowledge Bases", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-530-537", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops an inconsistency measure on conditional probabilistic\nknowledge bases. The measure is based on fundamental principles for\ninconsistency measures and thus provides a solid theoretical framework for the\ntreatment of inconsistencies in probabilistic expert systems. We illustrate its\nusefulness and immediate application on several examples and present some\nformal results. Building on this measure we use the Shapley value-a well-known\nsolution for coalition games-to define a sophisticated indicator that is not\nonly able to measure inconsistencies but to reveal the causes of\ninconsistencies in the knowledge base. Altogether these tools guide the\nknowledge engineer in his aim to restore consistency and therefore enable him\nto build a consistent and usable knowledge base that can be employed in\nprobabilistic expert systems.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:31:58 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Thimm", "Matthias", ""]]}, {"id": "1205.2615", "submitter": "Ilya Shpitser", "authors": "Ilya Shpitser, Judea Pearl", "title": "Effects of Treatment on the Treated: Identification and Generalization", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-514-521", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of causal analysis call for assessing, retrospectively, the\neffect of withholding an action that has in fact been implemented. This\ncounterfactual quantity, sometimes called \"effect of treatment on the treated,\"\n(ETT) have been used to to evaluate educational programs, critic public\npolicies, and justify individual decision making. In this paper we explore the\nconditions under which ETT can be estimated from (i.e., identified in)\nexperimental and/or observational studies. We show that, when the action\ninvokes a singleton variable, the conditions for ETT identification have simple\ncharacterizations in terms of causal diagrams. We further give a graphical\ncharacterization of the conditions under which the effects of multiple\ntreatments on the treated can be identified, as well as ways in which the ETT\nestimand can be constructed from both interventional and observational\ndistributions.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:29:08 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Shpitser", "Ilya", ""], ["Pearl", "Judea", ""]]}, {"id": "1205.2616", "submitter": "Prithviraj Sen", "authors": "Prithviraj Sen, Amol Deshpande, Lise Getoor", "title": "Bisimulation-based Approximate Lifted Inference", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-496-505", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a great deal of recent interest in methods for performing\nlifted inference; however, most of this work assumes that the first-order model\nis given as input to the system. Here, we describe lifted inference algorithms\nthat determine symmetries and automatically lift the probabilistic model to\nspeedup inference. In particular, we describe approximate lifted inference\ntechniques that allow the user to trade off inference accuracy for\ncomputational efficiency by using a handful of tunable parameters, while\nkeeping the error bounded. Our algorithms are closely related to the\ngraph-theoretic concept of bisimulation. We report experiments on both\nsynthetic and real data to show that in the presence of symmetries, run-times\nfor inference can be improved significantly, with approximate lifted inference\nproviding orders of magnitude speedup over ground inference.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:27:56 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Sen", "Prithviraj", ""], ["Deshpande", "Amol", ""], ["Getoor", "Lise", ""]]}, {"id": "1205.2619", "submitter": "Kevin Regan", "authors": "Kevin Regan, Craig Boutilier", "title": "Regret-based Reward Elicitation for Markov Decision Processes", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-444-451", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The specification of aMarkov decision process (MDP) can be difficult. Reward\nfunction specification is especially problematic; in practice, it is often\ncognitively complex and time-consuming for users to precisely specify rewards.\nThis work casts the problem of specifying rewards as one of preference\nelicitation and aims to minimize the degree of precision with which a reward\nfunction must be specified while still allowing optimal or near-optimal\npolicies to be produced. We first discuss how robust policies can be computed\nfor MDPs given only partial reward information using the minimax regret\ncriterion. We then demonstrate how regret can be reduced by efficiently\neliciting reward information using bound queries, using regret-reduction as a\nmeans for choosing suitable queries. Empirical results demonstrate that\nregret-based reward elicitation offers an effective way to produce near-optimal\npolicies without resorting to the precise specification of the entire reward\nfunction.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:23:30 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Regan", "Kevin", ""], ["Boutilier", "Craig", ""]]}, {"id": "1205.2620", "submitter": "Pekka Parviainen", "authors": "Pekka Parviainen, Mikko Koivisto", "title": "Exact Structure Discovery in Bayesian Networks with Less Space", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-436-443", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fastest known exact algorithms for scorebased structure discovery in\nBayesian networks on n nodes run in time and space 2nnO(1). The usage of these\nalgorithms is limited to networks on at most around 25 nodes mainly due to the\nspace requirement. Here, we study space-time tradeoffs for finding an optimal\nnetwork structure. When little space is available, we apply the Gurevich-Shelah\nrecurrence-originally proposed for the Hamiltonian path problem-and obtain time\n22n-snO(1) in space 2snO(1) for any s = n/2, n/4, n/8, . . .; we assume the\nindegree of each node is bounded by a constant. For the more practical setting\nwith moderate amounts of space, we present a novel scheme. It yields running\ntime 2n(3/2)pnO(1) in space 2n(3/4)pnO(1) for any p = 0, 1, . . ., n/2; these\nbounds hold as long as the indegrees are at most 0.238n. Furthermore, the\nlatter scheme allows easy and efficient parallelization beyond previous\nalgorithms. We also explore empirically the potential of the presented\ntechniques.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 17:30:15 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Parviainen", "Pekka", ""], ["Koivisto", "Mikko", ""]]}, {"id": "1205.2621", "submitter": "Mathias Niepert", "authors": "Mathias Niepert", "title": "Logical Inference Algorithms and Matrix Representations for\n  Probabilistic Conditional Independence", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-428-435", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logical inference algorithms for conditional independence (CI) statements\nhave important applications from testing consistency during knowledge\nelicitation to constraintbased structure learning of graphical models. We prove\nthat the implication problem for CI statements is decidable, given that the\nsize of the domains of the random variables is known and fixed. We will present\nan approximate logical inference algorithm which combines a falsification and a\nnovel validation algorithm. The validation algorithm represents each set of CI\nstatements as a sparse 0-1 matrix A and validates instances of the implication\nproblem by solving specific linear programs with constraint matrix A. We will\nshow experimentally that the algorithm is both effective and efficient in\nvalidating and falsifying instances of the probabilistic CI implication\nproblem.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 17:28:17 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Niepert", "Mathias", ""]]}, {"id": "1205.2624", "submitter": "Ofer Meshi", "authors": "Ofer Meshi, Ariel Jaimovich, Amir Globerson, Nir Friedman", "title": "Convexifying the Bethe Free Energy", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-402-410", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The introduction of loopy belief propagation (LBP) revitalized the\napplication of graphical models in many domains. Many recent works present\nimprovements on the basic LBP algorithm in an attempt to overcome convergence\nand local optima problems. Notable among these are convexified free energy\napproximations that lead to inference procedures with provable convergence and\nquality properties. However, empirically LBP still outperforms most of its\nconvex variants in a variety of settings, as we also demonstrate here.\nMotivated by this fact we seek convexified free energies that directly\napproximate the Bethe free energy. We show that the proposed approximations\ncompare favorably with state-of-the art convex free energy approximations.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 17:23:13 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Meshi", "Ofer", ""], ["Jaimovich", "Ariel", ""], ["Globerson", "Amir", ""], ["Friedman", "Nir", ""]]}, {"id": "1205.2625", "submitter": "Talya Meltzer", "authors": "Talya Meltzer, Amir Globerson, Yair Weiss", "title": "Convergent message passing algorithms - a unifying view", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-393-401", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message-passing algorithms have emerged as powerful techniques for\napproximate inference in graphical models. When these algorithms converge, they\ncan be shown to find local (or sometimes even global) optima of variational\nformulations to the inference problem. But many of the most popular algorithms\nare not guaranteed to converge. This has lead to recent interest in convergent\nmessage-passing algorithms. In this paper, we present a unified view of\nconvergent message-passing algorithms. We present a simple derivation of an\nabstract algorithm, tree-consistency bound optimization (TCBO) that is provably\nconvergent in both its sum and max product forms. We then show that many of the\nexisting convergent algorithms are instances of our TCBO algorithm, and obtain\nnovel convergent algorithms \"for free\" by exchanging maximizations and\nsummations in existing algorithms. In particular, we show that Wainwright's\nnon-convergent sum-product algorithm for tree based variational bounds, is\nactually convergent with the right update order for the case where trees are\nmonotonic chains.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 17:21:25 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Meltzer", "Talya", ""], ["Globerson", "Amir", ""], ["Weiss", "Yair", ""]]}, {"id": "1205.2633", "submitter": "M. Pawan Kumar", "authors": "M. Pawan Kumar, Daphne Koller", "title": "MAP Estimation of Semi-Metric MRFs via Hierarchical Graph Cuts", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-313-320", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of obtaining the maximum a posteriori estimate of\ndiscrete pairwise random fields with arbitrary unary potentials and semimetric\npairwise potentials. For this problem, we propose an accurate hierarchical move\nmaking strategy where each move is computed efficiently by solving an st-MINCUT\nproblem. Unlike previous move making approaches, e.g. the widely used\na-expansion algorithm, our method obtains the guarantees of the standard linear\nprogramming (LP) relaxation for the important special case of metric labeling.\nUnlike the existing LP relaxation solvers, e.g. interior-point algorithms or\ntree-reweighted message passing, our method is significantly faster as it uses\nonly the efficient st-MINCUT algorithm in its design. Using both synthetic and\nreal data experiments, we show that our technique outperforms several commonly\nused algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:47:50 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Kumar", "M. Pawan", ""], ["Koller", "Daphne", ""]]}, {"id": "1205.2634", "submitter": "Samantha Kleinberg", "authors": "Samantha Kleinberg, Bud Mishra", "title": "The Temporal Logic of Causal Structures", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-303-312", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational analysis of time-course data with an underlying causal\nstructure is needed in a variety of domains, including neural spike trains,\nstock price movements, and gene expression levels. However, it can be\nchallenging to determine from just the numerical time course data alone what is\ncoordinating the visible processes, to separate the underlying prima facie\ncauses into genuine and spurious causes and to do so with a feasible\ncomputational complexity. For this purpose, we have been developing a novel\nalgorithm based on a framework that combines notions of causality in philosophy\nwith algorithmic approaches built on model checking and statistical techniques\nfor multiple hypotheses testing. The causal relationships are described in\nterms of temporal logic formulae, reframing the inference problem in terms of\nmodel checking. The logic used, PCTL, allows description of both the time\nbetween cause and effect and the probability of this relationship being\nobserved. We show that equipped with these causal formulae with their\nassociated probabilities we may compute the average impact a cause makes to its\neffect and then discover statistically significant causes through the concepts\nof multiple hypothesis testing (treating each causal relationship as a\nhypothesis), and false discovery control. By exploring a well-chosen family of\npotentially all significant hypotheses with reasonably minimal description\nlength, it is possible to tame the algorithm's computational complexity while\nexploring the nearly complete search-space of all prima facie causes. We have\ntested these ideas in a number of domains and illustrate them here with two\nexamples.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:45:06 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Kleinberg", "Samantha", ""], ["Mishra", "Bud", ""]]}, {"id": "1205.2635", "submitter": "Jacek Kisynski", "authors": "Jacek Kisynski, David L Poole", "title": "Constraint Processing in Lifted Probabilistic Inference", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-293-302", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First-order probabilistic models combine representational power of\nfirst-order logic with graphical models. There is an ongoing effort to design\nlifted inference algorithms for first-order probabilistic models. We analyze\nlifted inference from the perspective of constraint processing and, through\nthis viewpoint, we analyze and compare existing approaches and expose their\nadvantages and limitations. Our theoretical results show that the wrong choice\nof constraint processing method can lead to exponential increase in\ncomputational complexity. Our empirical tests confirm the importance of\nconstraint processing in lifted inference. This is the first theoretical and\nempirical study of constraint processing in lifted inference.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:41:10 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Kisynski", "Jacek", ""], ["Poole", "David L", ""]]}, {"id": "1205.2636", "submitter": "Oleg Kiselyov", "authors": "Oleg Kiselyov, Chung-chieh Shan", "title": "Monolingual Probabilistic Programming Using Generalized Coroutines", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-285-292", "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programming languages and modeling toolkits are two modular\nways to build and reuse stochastic models and inference procedures. Combining\nstrengths of both, we express models and inference as generalized coroutines in\nthe same general-purpose language. We use existing facilities of the language,\nsuch as rich libraries, optimizing compilers, and types, to develop concise,\ndeclarative, and realistic models with competitive performance on exact and\napproximate inference. In particular, a wide range of models can be expressed\nusing memoization. Because deterministic parts of models run at full speed,\ncustom inference procedures are trivial to incorporate, and inference\nprocedures can reason about themselves without interpretive overhead. Within\nthis framework, we introduce a new, general algorithm for importance sampling\nwith look-ahead.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:39:37 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Kiselyov", "Oleg", ""], ["Shan", "Chung-chieh", ""]]}, {"id": "1205.2637", "submitter": "Kristian Kersting", "authors": "Kristian Kersting, Babak Ahmadi, Sriraam Natarajan", "title": "Counting Belief Propagation", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-277-284", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major benefit of graphical models is that most knowledge is captured in the\nmodel structure. Many models, however, produce inference problems with a lot of\nsymmetries not reflected in the graphical structure and hence not exploitable\nby efficient inference techniques such as belief propagation (BP). In this\npaper, we present a new and simple BP algorithm, called counting BP, that\nexploits such additional symmetries. Starting from a given factor graph,\ncounting BP first constructs a compressed factor graph of clusternodes and\nclusterfactors, corresponding to sets of nodes and factors that are\nindistinguishable given the evidence. Then it runs a modified BP algorithm on\nthe compressed graph that is equivalent to running BP on the original factor\ngraph. Our experiments show that counting BP is applicable to a variety of\nimportant AI tasks such as (dynamic) relational models and boolean model\ncounting, and that significant efficiency gains are obtainable, often by orders\nof magnitude.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:37:58 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Kersting", "Kristian", ""], ["Ahmadi", "Babak", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "1205.2638", "submitter": "Albert Xin Jiang", "authors": "Albert Xin Jiang, Kevin Leyton-Brown, Avi Pfeffer", "title": "Temporal Action-Graph Games: A New Representation for Dynamic Games", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-268-276", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce temporal action graph games (TAGGs), a novel\ngraphical representation of imperfect-information extensive form games. We show\nthat when a game involves anonymity or context-specific utility independencies,\nits encoding as a TAGG can be much more compact than its direct encoding as a\nmultiagent influence diagram (MAID).We also show that TAGGs can be understood\nas indirect MAID encodings in which many deterministic chance nodes are\nintroduced. We provide an algorithm for computing with TAGGs, and show both\ntheoretically and empirically that our approach improves significantly on the\nprevious state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:36:06 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Jiang", "Albert Xin", ""], ["Leyton-Brown", "Kevin", ""], ["Pfeffer", "Avi", ""]]}, {"id": "1205.2639", "submitter": "Tony S. Jebara", "authors": "Tony S. Jebara", "title": "MAP Estimation, Message Passing, and Perfect Graphs", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-258-267", "categories": "cs.AI cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiently finding the maximum a posteriori (MAP) configuration of a\ngraphical model is an important problem which is often implemented using\nmessage passing algorithms. The optimality of such algorithms is only well\nestablished for singly-connected graphs and other limited settings. This\narticle extends the set of graphs where MAP estimation is in P and where\nmessage passing recovers the exact solution to so-called perfect graphs. This\nresult leverages recent progress in defining perfect graphs (the strong perfect\ngraph theorem), linear programming relaxations of MAP estimation and recent\nconvergent message passing schemes. The article converts graphical models into\nnand Markov random fields which are straightforward to relax into linear\nprograms. Therein, integrality can be established in general by testing for\ngraph perfection. This perfection test is performed efficiently using a\npolynomial time algorithm. Alternatively, known decomposition tools from\nperfect graph theory may be used to prove perfection for certain families of\ngraphs. Thus, a general graph framework is provided for determining when MAP\nestimation in any graphical model is in P, has an integral linear programming\nrelaxation and is exactly recoverable by message passing.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:34:09 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Jebara", "Tony S.", ""]]}, {"id": "1205.2642", "submitter": "Peter Hooper", "authors": "Peter Hooper, Yasin Abbasi-Yadkori, Russell Greiner, Bret Hoehn", "title": "Improved Mean and Variance Approximations for Belief Net Responses via\n  Network Doubling", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-232-239", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Bayesian belief network models a joint distribution with an directed\nacyclic graph representing dependencies among variables and network parameters\ncharacterizing conditional distributions. The parameters are viewed as random\nvariables to quantify uncertainty about their values. Belief nets are used to\ncompute responses to queries; i.e., conditional probabilities of interest. A\nquery is a function of the parameters, hence a random variable. Van Allen et\nal. (2001, 2008) showed how to quantify uncertainty about a query via a delta\nmethod approximation of its variance. We develop more accurate approximations\nfor both query mean and variance. The key idea is to extend the query mean\napproximation to a \"doubled network\" involving two independent replicates. Our\nmethod assumes complete data and can be applied to discrete, continuous, and\nhybrid networks (provided discrete variables have only discrete parents). We\nanalyze several improvements, and provide empirical studies to demonstrate\ntheir effectiveness.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:28:28 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Hooper", "Peter", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Greiner", "Russell", ""], ["Hoehn", "Bret", ""]]}, {"id": "1205.2644", "submitter": "Geoffrey Gordon", "authors": "Geoffrey Gordon, Sue Ann Hong, Miroslav Dudik", "title": "First-Order Mixed Integer Linear Programming", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-213-222", "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed integer linear programming (MILP) is a powerful representation often\nused to formulate decision-making problems under uncertainty. However, it lacks\na natural mechanism to reason about objects, classes of objects, and relations.\nFirst-order logic (FOL), on the other hand, excels at reasoning about classes\nof objects, but lacks a rich representation of uncertainty. While representing\npropositional logic in MILP has been extensively explored, no theory exists yet\nfor fully combining FOL with MILP. We propose a new representation, called\nfirst-order programming or FOP, which subsumes both FOL and MILP. We establish\nformal methods for reasoning about first order programs, including a sound and\ncomplete lifted inference procedure for integer first order programs. Since FOP\ncan offer exponential savings in representation and proof size compared to FOL,\nand since representations and proofs are never significantly longer in FOP than\nin FOL, we anticipate that inference in FOP will be more tractable than\ninference in FOL for corresponding problems.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:25:08 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Gordon", "Geoffrey", ""], ["Hong", "Sue Ann", ""], ["Dudik", "Miroslav", ""]]}, {"id": "1205.2645", "submitter": "Joseph E. Gonzalez", "authors": "Joseph E. Gonzalez, Yucheng Low, Carlos E. Guestrin, David O'Hallaron", "title": "Distributed Parallel Inference on Large Factor Graphs", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-203-212", "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As computer clusters become more common and the size of the problems\nencountered in the field of AI grows, there is an increasing demand for\nefficient parallel inference algorithms. We consider the problem of parallel\ninference on large factor graphs in the distributed memory setting of computer\nclusters. We develop a new efficient parallel inference algorithm, DBRSplash,\nwhich incorporates over-segmented graph partitioning, belief residual\nscheduling, and uniform work Splash operations. We empirically evaluate the\nDBRSplash algorithm on a 120 processor cluster and demonstrate linear to\nsuper-linear performance gains on large factor graph models.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:23:28 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Gonzalez", "Joseph E.", ""], ["Low", "Yucheng", ""], ["Guestrin", "Carlos E.", ""], ["O'Hallaron", "David", ""]]}, {"id": "1205.2647", "submitter": "Christian Fritz", "authors": "Christian Fritz, Sheila McIlraith", "title": "Generating Optimal Plans in Highly-Dynamic Domains", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-177-184", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating optimal plans in highly dynamic environments is challenging. Plans\nare predicated on an assumed initial state, but this state can change\nunexpectedly during plan generation, potentially invalidating the planning\neffort. In this paper we make three contributions: (1) We propose a novel\nalgorithm for generating optimal plans in settings where frequent, unexpected\nevents interfere with planning. It is able to quickly distinguish relevant from\nirrelevant state changes, and to update the existing planning search tree if\nnecessary. (2) We argue for a new criterion for evaluating plan adaptation\ntechniques: the relative running time compared to the \"size\" of changes. This\nis significant since during recovery more changes may occur that need to be\nrecovered from subsequently, and in order for this process of repeated recovery\nto terminate, recovery time has to converge. (3) We show empirically that our\napproach can converge and find optimal plans in environments that would\nordinarily defy planning due to their high dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 13:51:50 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Fritz", "Christian", ""], ["McIlraith", "Sheila", ""]]}, {"id": "1205.2651", "submitter": "Mark Crowley", "authors": "Mark Crowley, John Nelson, David L Poole", "title": "Seeing the Forest Despite the Trees: Large Scale Spatial-Temporal\n  Decision Making", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-126-134", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a challenging real-world planning problem where actions must be\ntaken at each location in a spatial area at each point in time. We use forestry\nplanning as the motivating application. In Large Scale Spatial-Temporal (LSST)\nplanning problems, the state and action spaces are defined as the\ncross-products of many local state and action spaces spread over a large\nspatial area such as a city or forest. These problems possess state\nuncertainty, have complex utility functions involving spatial constraints and\nwe generally must rely on simulations rather than an explicit transition model.\nWe define LSST problems as reinforcement learning problems and present a\nsolution using policy gradients. We compare two different policy formulations:\nan explicit policy that identifies each location in space and the action to\ntake there; and an abstract policy that defines the proportion of actions to\ntake across all locations in space. We show that the abstract policy is more\nrobust and achieves higher rewards with far fewer parameters than the\nelementary policy. This abstract policy is also a better fit to the properties\nthat practitioners in LSST problem domains require for such methods to be\nwidely useful.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:08:18 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Crowley", "Mark", ""], ["Nelson", "John", ""], ["Poole", "David L", ""]]}, {"id": "1205.2652", "submitter": "Fabio Gagliardi Cozman", "authors": "Fabio Gagliardi Cozman, Rodrigo Bellizia Polastro", "title": "Complexity Analysis and Variational Inference for Interpretation-based\n  Probabilistic Description Logic", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-117-125", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents complexity analysis and variational methods for inference\nin probabilistic description logics featuring Boolean operators,\nquantification, qualified number restrictions, nominals, inverse roles and role\nhierarchies. Inference is shown to be PEXP-complete, and variational methods\nare designed so as to exploit logical inference whenever possible.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:05:48 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Cozman", "Fabio Gagliardi", ""], ["Polastro", "Rodrigo Bellizia", ""]]}, {"id": "1205.2655", "submitter": "Ido Cohn", "authors": "Ido Cohn, Tal El-Hay, Nir Friedman, Raz Kupferman", "title": "Mean Field Variational Approximation for Continuous-Time Bayesian\n  Networks", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-91-100", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous-time Bayesian networks is a natural structured representation\nlanguage for multicomponent stochastic processes that evolve continuously over\ntime. Despite the compact representation, inference in such models is\nintractable even in relatively simple structured networks. Here we introduce a\nmean field variational approximation in which we use a product of inhomogeneous\nMarkov processes to approximate a distribution over trajectories. This\nvariational approach leads to a globally consistent distribution, which can be\nefficiently queried. Additionally, it provides a lower bound on the probability\nof observations, thus making it attractive for learning tasks. We provide the\ntheoretical foundations for the approximation, an efficient implementation that\nexploits the wide range of highly optimized ordinary differential equations\n(ODE) solvers, experimentally explore characterizations of processes for which\nthis approximation is suitable, and show applications to a large-scale\nrealworld inference problem.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 14:57:02 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Cohn", "Ido", ""], ["El-Hay", "Tal", ""], ["Friedman", "Nir", ""], ["Kupferman", "Raz", ""]]}, {"id": "1205.2659", "submitter": "Blai Bonet", "authors": "Blai Bonet", "title": "Deterministic POMDPs Revisited", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-59-66", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a subclass of POMDPs, called Deterministic POMDPs, that is\ncharacterized by deterministic actions and observations. These models do not\nprovide the same generality of POMDPs yet they capture a number of interesting\nand challenging problems, and permit more efficient algorithms. Indeed, some of\nthe recent work in planning is built around such assumptions mainly by the\nquest of amenable models more expressive than the classical deterministic\nmodels. We provide results about the fundamental properties of Deterministic\nPOMDPs, their relation with AND/OR search problems and algorithms, and their\ncomputational complexity.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 14:50:18 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Bonet", "Blai", ""]]}, {"id": "1205.2665", "submitter": "Daniel Andrade", "authors": "Daniel Andrade, Bernhard Sick", "title": "Lower Bound Bayesian Networks - An Efficient Inference of Lower Bounds\n  on Probability Distributions in Bayesian Networks", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-10-18", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method to propagate lower bounds on conditional probability\ndistributions in conventional Bayesian networks. Our method guarantees to\nprovide outer approximations of the exact lower bounds. A key advantage is that\nwe can use any available algorithms and tools for Bayesian networks in order to\nrepresent and infer lower bounds. This new method yields results that are\nprovable exact for trees with binary variables, and results which are\ncompetitive to existing approximations in credal networks for all other network\nstructures. Our method is not limited to a specific kind of network structure.\nBasically, it is also not restricted to a specific kind of inference, but we\nrestrict our analysis to prognostic inference in this article. The\ncomputational complexity is superior to that of other existing approaches.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 14:40:39 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Andrade", "Daniel", ""], ["Sick", "Bernhard", ""]]}, {"id": "1205.2857", "submitter": "Ping Zhu", "authors": "Ping Zhu and Qiaoyan Wen", "title": "Operations on soft sets revisited", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Soft sets, as a mathematical tool for dealing with uncertainty, have recently\ngained considerable attention, including some successful applications in\ninformation processing, decision, demand analysis, and forecasting. To\nconstruct new soft sets from given soft sets, some operations on soft sets have\nbeen proposed. Unfortunately, such operations cannot keep all classical\nset-theoretic laws true for soft sets. In this paper, we redefine the\nintersection, complement, and difference of soft sets and investigate the\nalgebraic properties of these operations along with a known union operation. We\nfind that the new operation system on soft sets inherits all basic properties\nof operations on classical sets, which justifies our definitions.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2012 13:21:59 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Zhu", "Ping", ""], ["Wen", "Qiaoyan", ""]]}, {"id": "1205.3054", "submitter": "Bruno Scherrer", "authors": "Bruno Scherrer (INRIA Lorraine - LORIA), Victor Gabillon (INRIA Lille\n  - Nord Europe), Mohammad Ghavamzadeh (INRIA Lille - Nord Europe), Matthieu\n  Geist (UMI2958)", "title": "Approximate Modified Policy Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modified policy iteration (MPI) is a dynamic programming (DP) algorithm that\ncontains the two celebrated policy and value iteration methods. Despite its\ngenerality, MPI has not been thoroughly studied, especially its approximation\nform which is used when the state and/or action spaces are large or infinite.\nIn this paper, we propose three implementations of approximate MPI (AMPI) that\nare extensions of well-known approximate DP algorithms: fitted-value iteration,\nfitted-Q iteration, and classification-based policy iteration. We provide error\npropagation analyses that unify those for approximate policy and value\niteration. On the last classification-based implementation, we develop a\nfinite-sample analysis that shows that MPI's main parameter allows to control\nthe balance between the estimation error of the classifier and the overall\nvalue function approximation.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2012 15:01:31 GMT"}, {"version": "v2", "created": "Fri, 18 May 2012 06:56:47 GMT"}], "update_date": "2012-05-21", "authors_parsed": [["Scherrer", "Bruno", "", "INRIA Lorraine - LORIA"], ["Gabillon", "Victor", "", "INRIA Lille\n  - Nord Europe"], ["Ghavamzadeh", "Mohammad", "", "INRIA Lille - Nord Europe"], ["Geist", "Matthieu", "", "UMI2958"]]}, {"id": "1205.3109", "submitter": "Arthur Guez", "authors": "Arthur Guez and David Silver and Peter Dayan", "title": "Efficient Bayes-Adaptive Reinforcement Learning using Sample-Based\n  Search", "comments": "14 pages, 7 figures, includes supplementary material. Advances in\n  Neural Information Processing Systems (NIPS) 2012", "journal-ref": "(2012) Advances in Neural Information Processing Systems 25, pages\n  1034-1042", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian model-based reinforcement learning is a formally elegant approach to\nlearning optimal behaviour under model uncertainty, trading off exploration and\nexploitation in an ideal way. Unfortunately, finding the resulting\nBayes-optimal policies is notoriously taxing, since the search space becomes\nenormous. In this paper we introduce a tractable, sample-based method for\napproximate Bayes-optimal planning which exploits Monte-Carlo tree search. Our\napproach outperformed prior Bayesian model-based RL algorithms by a significant\nmargin on several well-known benchmark problems -- because it avoids expensive\napplications of Bayes rule within the search tree by lazily sampling models\nfrom the current beliefs. We illustrate the advantages of our approach by\nshowing it working in an infinite state space domain which is qualitatively out\nof reach of almost all previous work in Bayesian exploration.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2012 17:20:29 GMT"}, {"version": "v2", "created": "Sat, 13 Oct 2012 15:19:09 GMT"}, {"version": "v3", "created": "Thu, 3 Jan 2013 14:44:59 GMT"}, {"version": "v4", "created": "Wed, 18 Dec 2013 11:45:49 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Guez", "Arthur", ""], ["Silver", "David", ""], ["Dayan", "Peter", ""]]}, {"id": "1205.3137", "submitter": "Saurabh Singh", "authors": "Saurabh Singh, Abhinav Gupta, Alexei A. Efros", "title": "Unsupervised Discovery of Mid-Level Discriminative Patches", "comments": null, "journal-ref": "European Conference on Computer Vision, 2012", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to discover a set of discriminative patches which\ncan serve as a fully unsupervised mid-level visual representation. The desired\npatches need to satisfy two requirements: 1) to be representative, they need to\noccur frequently enough in the visual world; 2) to be discriminative, they need\nto be different enough from the rest of the visual world. The patches could\ncorrespond to parts, objects, \"visual phrases\", etc. but are not restricted to\nbe any one of them. We pose this as an unsupervised discriminative clustering\nproblem on a huge dataset of image patches. We use an iterative procedure which\nalternates between clustering and training discriminative classifiers, while\napplying careful cross-validation at each step to prevent overfitting. The\npaper experimentally demonstrates the effectiveness of discriminative patches\nas an unsupervised mid-level visual representation, suggesting that it could be\nused in place of visual words for many tasks. Furthermore, discriminative\npatches can also be used in a supervised regime, such as scene classification,\nwhere they demonstrate state-of-the-art performance on the MIT Indoor-67\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2012 18:52:57 GMT"}, {"version": "v2", "created": "Sat, 18 Aug 2012 04:16:13 GMT"}], "update_date": "2012-08-21", "authors_parsed": [["Singh", "Saurabh", ""], ["Gupta", "Abhinav", ""], ["Efros", "Alexei A.", ""]]}, {"id": "1205.3336", "submitter": "Antonio J. Tall\\'on-Ballesteros", "authors": "A.J. Tall\\'on-Ballesteros, P.A. Guti\\'errez-Pe\\~na, C.\n  Herv\\'as-Mart\\'inez", "title": "Distribution of the search of evolutionary product unit neural networks\n  for classification", "comments": "8 pages, 2 figures, in Proc. IADIS International Conference Applied\n  Computing 2007 (AC 2007), ISBN 978-972-8924-30-0, pp. 266-273, Spain. Note:\n  \"This is a reprint from a paper published in the Proceedings of the IADIS\n  International Conference Applied Comupting 2007, http://www.iadis.org\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the distributed processing in the search for an optimum\nclassification model using evolutionary product unit neural networks. For this\ndistributed search we used a cluster of computers. Our objective is to obtain a\nmore efficient design than those net architectures which do not use a\ndistributed process and which thus result in simpler designs. In order to get\nthe best classification models we use evolutionary algorithms to train and\ndesign neural networks, which require a very time consuming computation. The\nreasons behind the need for this distribution are various. It is complicated to\ntrain this type of nets because of the difficulty entailed in determining their\narchitecture due to the complex error surface. On the other hand, the use of\nevolutionary algorithms involves running a great number of tests with different\nseeds and parameters, thus resulting in a high computational cost\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2012 11:51:02 GMT"}], "update_date": "2012-05-16", "authors_parsed": [["Tall\u00f3n-Ballesteros", "A. J.", ""], ["Guti\u00e9rrez-Pe\u00f1a", "P. A.", ""], ["Herv\u00e1s-Mart\u00ednez", "C.", ""]]}, {"id": "1205.3380", "submitter": "Yefim Bakman", "authors": "Yefim Bakman", "title": "Unfair items detection in educational measurement", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI physics.ed-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measurement professionals cannot come to an agreement on the definition of\nthe term 'item fairness'. In this paper a continuous measure of item unfairness\nis proposed. The more the unfairness measure deviates from zero, the less fair\nthe item is. If the measure exceeds the cutoff value, the item is identified as\ndefinitely unfair. The new approach can identify unfair items that would not be\nidentified with conventional procedures. The results are in accord with\nexperts' judgments on the item qualities. Since no assumptions about scores\ndistributions and/or correlations are assumed, the method is applicable to any\neducational test. Its performance is illustrated through application to scores\nof a real test.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2012 16:12:05 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Bakman", "Yefim", ""]]}, {"id": "1205.3663", "submitter": "Johannes Klaus Fichte", "authors": "Johannes Klaus Fichte", "title": "The Good, the Bad, and the Odd: Cycles in Answer-Set Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backdoors of answer-set programs are sets of atoms that represent clever\nreasoning shortcuts through the search space. Assignments to backdoor atoms\nreduce the given program to several programs that belong to a tractable target\nclass. Previous research has considered target classes based on notions of\nacyclicity where various types of cycles (good and bad cycles) are excluded\nfrom graph representations of programs. We generalize the target classes by\ntaking the parity of the number of negative edges on bad cycles into account\nand consider backdoors for such classes. We establish new hardness results and\nnon-uniform polynomial-time tractability relative to directed or undirected\ncycles.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2012 20:19:57 GMT"}], "update_date": "2012-05-17", "authors_parsed": [["Fichte", "Johannes Klaus", ""]]}, {"id": "1205.3964", "submitter": "Yusuf Perwej", "authors": "Yusuf Perwej, Ashish Chaturvedi", "title": "Machine Recognition of Hand Written Characters using Neural Networks", "comments": "4 pages, 1 Figure, ISSN:0975 - 8887", "journal-ref": "International Journal of Computer Applications (IJCA) ,January\n  2011 Volume 14, Number 2, Pages 6-9", "doi": "10.5120/1819-2380", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even today in Twenty First Century Handwritten communication has its own\nstand and most of the times, in daily life it is globally using as means of\ncommunication and recording the information like to be shared with others.\nChallenges in handwritten characters recognition wholly lie in the variation\nand distortion of handwritten characters, since different people may use\ndifferent style of handwriting, and direction to draw the same shape of the\ncharacters of their known script. This paper demonstrates the nature of\nhandwritten characters, conversion of handwritten data into electronic data,\nand the neural network approach to make machine capable of recognizing hand\nwritten characters.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2012 15:50:08 GMT"}], "update_date": "2012-05-18", "authors_parsed": [["Perwej", "Yusuf", ""], ["Chaturvedi", "Ashish", ""]]}, {"id": "1205.3966", "submitter": "Yusuf Perwej", "authors": "Yusuf Perwej, Ashish Chaturvedi", "title": "Neural Networks for Handwritten English Alphabet Recognition", "comments": "5 pages, 3 Figure, ISSN:0975 - 8887", "journal-ref": "International Journal of Computer Applications(IJCA), April 2011,\n  Volume 20, Number 7, Pages 1-5", "doi": "10.5120/2449-2824", "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates the use of neural networks for developing a system\nthat can recognize hand-written English alphabets. In this system, each English\nalphabet is represented by binary values that are used as input to a simple\nfeature extraction system, whose output is fed to our neural network system.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2012 15:57:24 GMT"}], "update_date": "2012-05-18", "authors_parsed": [["Perwej", "Yusuf", ""], ["Chaturvedi", "Ashish", ""]]}, {"id": "1205.3981", "submitter": "Paolo Frasconi", "authors": "Paolo Frasconi, Fabrizio Costa, Luc De Raedt, Kurt De Grave", "title": "kLog: A Language for Logical and Relational Learning with Kernels", "comments": null, "journal-ref": null, "doi": "10.1016/j.artint.2014.08.003", "report-no": null, "categories": "cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce kLog, a novel approach to statistical relational learning.\nUnlike standard approaches, kLog does not represent a probability distribution\ndirectly. It is rather a language to perform kernel-based learning on\nexpressive logical and relational representations. kLog allows users to specify\nlearning problems declaratively. It builds on simple but powerful concepts:\nlearning from interpretations, entity/relationship data modeling, logic\nprogramming, and deductive databases. Access by the kernel to the rich\nrepresentation is mediated by a technique we call graphicalization: the\nrelational representation is first transformed into a graph --- in particular,\na grounded entity/relationship diagram. Subsequently, a choice of graph kernel\ndefines the feature space. kLog supports mixed numerical and symbolic data, as\nwell as background knowledge in the form of Prolog or Datalog programs as in\ninductive logic programming systems. The kLog framework can be applied to\ntackle the same range of tasks that has made statistical relational learning so\npopular, including classification, regression, multitask learning, and\ncollective classification. We also report about empirical comparisons, showing\nthat kLog can be either more accurate, or much faster at the same level of\naccuracy, than Tilde and Alchemy. kLog is GPLv3 licensed and is available at\nhttp://klog.dinfo.unifi.it along with tutorials.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2012 17:00:00 GMT"}, {"version": "v2", "created": "Fri, 18 May 2012 12:46:57 GMT"}, {"version": "v3", "created": "Fri, 22 Jun 2012 12:06:52 GMT"}, {"version": "v4", "created": "Mon, 17 Feb 2014 11:47:55 GMT"}, {"version": "v5", "created": "Mon, 28 Jul 2014 13:41:00 GMT"}], "update_date": "2014-10-17", "authors_parsed": [["Frasconi", "Paolo", ""], ["Costa", "Fabrizio", ""], ["De Raedt", "Luc", ""], ["De Grave", "Kurt", ""]]}, {"id": "1205.3997", "submitter": "Pedro Alejandro Ortega", "authors": "Pedro A. Ortega and Daniel A. Braun", "title": "Free Energy and the Generalized Optimality Equations for Sequential\n  Decision Making", "comments": "10 pages, 2 figures", "journal-ref": "European Workshop on Reinforcement Learning 2012", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.GT cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The free energy functional has recently been proposed as a variational\nprinciple for bounded rational decision-making, since it instantiates a natural\ntrade-off between utility gains and information processing costs that can be\naxiomatically derived. Here we apply the free energy principle to general\ndecision trees that include both adversarial and stochastic environments. We\nderive generalized sequential optimality equations that not only include the\nBellman optimality equations as a limit case, but also lead to well-known\ndecision-rules such as Expectimax, Minimax and Expectiminimax. We show how\nthese decision-rules can be derived from a single free energy principle that\nassigns a resource parameter to each node in the decision tree. These resource\nparameters express a concrete computational cost that can be measured as the\namount of samples that are needed from the distribution that belongs to each\nnode. The free energy principle therefore provides the normative basis for\ngeneralized optimality equations that account for both adversarial and\nstochastic environments.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2012 18:06:45 GMT"}], "update_date": "2012-05-18", "authors_parsed": [["Ortega", "Pedro A.", ""], ["Braun", "Daniel A.", ""]]}, {"id": "1205.4213", "submitter": "Pannagadatta Shivaswamy", "authors": "Pannaga Shivaswamy and Thorsten Joachims", "title": "Online Structured Prediction via Coactive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Coactive Learning as a model of interaction between a learning\nsystem and a human user, where both have the common goal of providing results\nof maximum utility to the user. At each step, the system (e.g. search engine)\nreceives a context (e.g. query) and predicts an object (e.g. ranking). The user\nresponds by correcting the system if necessary, providing a slightly improved\n-- but not necessarily optimal -- object as feedback. We argue that such\nfeedback can often be inferred from observable user behavior, for example, from\nclicks in web-search. Evaluating predictions by their cardinal utility to the\nuser, we propose efficient learning algorithms that have ${\\cal\nO}(\\frac{1}{\\sqrt{T}})$ average regret, even though the learning algorithm\nnever observes cardinal utility values as in conventional online learning. We\ndemonstrate the applicability of our model and learning algorithms on a movie\nrecommendation task, as well as ranking for web-search.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2012 18:19:13 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2012 16:25:02 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Shivaswamy", "Pannaga", ""], ["Joachims", "Thorsten", ""]]}, {"id": "1205.4295", "submitter": "Jascha Sohl-Dickstein", "authors": "Jascha Sohl-Dickstein", "title": "Efficient Methods for Unsupervised Learning of Probabilistic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT cs.NE math.IT physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis I develop a variety of techniques to train, evaluate, and\nsample from intractable and high dimensional probabilistic models. Abstract\nexceeds arXiv space limitations -- see PDF.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2012 04:25:04 GMT"}], "update_date": "2012-05-22", "authors_parsed": [["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1205.4378", "submitter": "Yu Zheng", "authors": "Yin Zhu, Yu Zheng, Liuhang Zhang, Darshan Santani, Xing Xie, Qiang\n  Yang", "title": "Inferring Taxi Status Using GPS Trajectories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we infer the statuses of a taxi, consisting of occupied,\nnon-occupied and parked, in terms of its GPS trajectory. The status information\ncan enable urban computing for improving a city's transportation systems and\nland use planning. In our solution, we first identify and extract a set of\neffective features incorporating the knowledge of a single trajectory,\nhistorical trajectories and geographic data like road network. Second, a\nparking status detection algorithm is devised to find parking places (from a\ngiven trajectory), dividing a trajectory into segments (i.e.,\nsub-trajectories). Third, we propose a two-phase inference model to learn the\nstatus (occupied or non-occupied) of each point from a taxi segment. This model\nfirst uses the identified features to train a local probabilistic classifier\nand then carries out a Hidden Semi-Markov Model (HSMM) for globally considering\nlong term travel patterns. We evaluated our method with a large-scale\nreal-world trajectory dataset generated by 600 taxis, showing the advantages of\nour method over baselines.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2012 03:24:25 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2012 08:15:27 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Zhu", "Yin", ""], ["Zheng", "Yu", ""], ["Zhang", "Liuhang", ""], ["Santani", "Darshan", ""], ["Xie", "Xing", ""], ["Yang", "Qiang", ""]]}, {"id": "1205.4655", "submitter": "Miroslaw Truszczynski", "authors": "Luciano Caroprese, Irina Trubitsyna, Miroslaw Truszczynski, Ester\n  Zumpano", "title": "The View-Update Problem for Indefinite Databases", "comments": "24 pages (includes proofs)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces and studies a declarative framework for updating views\nover indefinite databases. An indefinite database is a database with null\nvalues that are represented, following the standard database approach, by a\nsingle null constant. The paper formalizes views over such databases as\nindefinite deductive databases, and defines for them several classes of\ndatabase repairs that realize view-update requests. Most notable is the class\nof constrained repairs. Constrained repairs change the database \"minimally\" and\navoid making arbitrary commitments. They narrow down the space of alternative\nways to fulfill the view-update request to those that are grounded, in a\ncertain strong sense, in the database, the view and the view-update request.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2012 16:42:06 GMT"}], "update_date": "2012-05-22", "authors_parsed": [["Caroprese", "Luciano", ""], ["Trubitsyna", "Irina", ""], ["Truszczynski", "Miroslaw", ""], ["Zumpano", "Ester", ""]]}, {"id": "1205.5098", "submitter": "Balwinder Sodhi", "authors": "Balwinder Sodhi and Prabhakar T.V", "title": "A Simplified Description of Fuzzy TOPSIS", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simplified description of Fuzzy TOPSIS (Technique for Order Preference by\nSimilarity to Ideal Situation) is presented. We have adapted the TOPSIS\ndescription from existing Fuzzy theory literature and distilled the bare\nminimum concepts required for understanding and applying TOPSIS. An example has\nbeen worked out to illustrate the application of TOPSIS for a multi-criteria\ngroup decision making scenario.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2012 06:21:54 GMT"}, {"version": "v2", "created": "Sat, 3 Jun 2017 07:18:30 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Sodhi", "Balwinder", ""], ["T.", "Prabhakar", "V"]]}, {"id": "1205.5367", "submitter": "Nicola Di Mauro", "authors": "Claudio Taranto, Nicola Di Mauro, Floriana Esposito", "title": "Language-Constraint Reachability Learning in Probabilistic Graphs", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The probabilistic graphs framework models the uncertainty inherent in\nreal-world domains by means of probabilistic edges whose value quantifies the\nlikelihood of the edge existence or the strength of the link it represents. The\ngoal of this paper is to provide a learning method to compute the most likely\nrelationship between two nodes in a framework based on probabilistic graphs. In\nparticular, given a probabilistic graph we adopted the language-constraint\nreachability method to compute the probability of possible interconnections\nthat may exists between two nodes. Each of these connections may be viewed as\nfeature, or a factor, between the two nodes and the corresponding probability\nas its weight. Each observed link is considered as a positive instance for its\ncorresponding link label. Given the training set of observed links a\nL2-regularized Logistic Regression has been adopted to learn a model able to\npredict unobserved link labels. The experiments on a real world collaborative\nfiltering problem proved that the proposed approach achieves better results\nthan that obtained adopting classical methods.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2012 08:43:14 GMT"}], "update_date": "2012-05-25", "authors_parsed": [["Taranto", "Claudio", ""], ["Di Mauro", "Nicola", ""], ["Esposito", "Floriana", ""]]}, {"id": "1205.5823", "submitter": "Hector Zenil", "authors": "Roger Penrose", "title": "Foreword: A Computable Universe, Understanding Computation and Exploring\n  Nature As Computation", "comments": "26 pages, foreword to the book A Computable Universe: Understanding\n  Computation and Exploring Nature As Computation, World Scientific, 2012\n  http://www.mathrix.org/experimentalAIT/ComputationNature.htm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GL cs.AI cs.CC cs.IT math.IT physics.hist-ph physics.pop-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I am most honoured to have the privilege to present the Foreword to this\nfascinating and wonderfully varied collection of contributions, concerning the\nnature of computation and of its deep connection with the operation of those\nbasic laws, known or yet unknown, governing the universe in which we live.\nFundamentally deep questions are indeed being grappled with here, and the fact\nthat we find so many different viewpoints is something to be expected, since,\nin truth, we know little about the foundational nature and origins of these\nbasic laws, despite the immense precision that we so often find revealed in\nthem. Accordingly, it is not surprising that within the viewpoints expressed\nhere is some unabashed speculation, occasionally bordering on just partially\njustified guesswork, while elsewhere we find a good deal of precise reasoning,\nsome in the form of rigorous mathematical theorems. Both of these are as should\nbe, for without some inspired guesswork we cannot have new ideas as to where\nlook in order to make genuinely new progress, and without precise mathematical\nreasoning, no less than in precise observation, we cannot know when we are\nright -- or, more usually, when we are wrong.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2012 21:04:53 GMT"}], "update_date": "2012-05-29", "authors_parsed": [["Penrose", "Roger", ""]]}, {"id": "1205.5866", "submitter": "G K Panda", "authors": "B. K. Tripathy, G. K. Panda", "title": "Approximate Equalities on Rough Intuitionistic Fuzzy Sets and an\n  Analysis of Approximate Equalities", "comments": null, "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 9,\n  Issue 2, No 3, March 2012 ISSN (Online): 1694-0814 www.IJCSI.org", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to involve user knowledge in determining equality of sets, which may\nnot be equal in the mathematical sense, three types of approximate (rough)\nequalities were introduced by Novotny and Pawlak ([8, 9, 10]). These notions\nwere generalized by Tripathy, Mitra and Ojha ([13]), who introduced the\nconcepts of approximate (rough) equivalences of sets. Rough equivalences\ncapture equality of sets at a higher level than rough equalities. More\nproperties of these concepts were established in [14]. Combining the conditions\nfor the two types of approximate equalities, two more approximate equalities\nwere introduced by Tripathy [12] and a comparative analysis of their relative\nefficiency was provided. In [15], the four types of approximate equalities were\nextended by considering rough fuzzy sets instead of only rough sets. In fact\nthe concepts of leveled approximate equalities were introduced and properties\nwere studied. In this paper we proceed further by introducing and studying the\napproximate equalities based on rough intuitionistic fuzzy sets instead of\nrough fuzzy sets. That is we introduce the concepts of approximate\n(rough)equalities of intuitionistic fuzzy sets and study their properties. We\nprovide some real life examples to show the applications of rough equalities of\nfuzzy sets and rough equalities of intuitionistic fuzzy sets.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2012 09:49:38 GMT"}], "update_date": "2012-05-29", "authors_parsed": [["Tripathy", "B. K.", ""], ["Panda", "G. K.", ""]]}, {"id": "1205.6179", "submitter": "Maryam Mohammadi", "authors": "Maryam Mohammadi, Masine Md. Tap", "title": "A Mixed Integer Programming Model Formulation for Solving the Lot-Sizing\n  Problem", "comments": "9 pages, 1 figure, 13 tables; International Journal of Computer\n  Science Issues, Vol. 9, Issue 2, No 1, March 2012", "journal-ref": "International Journal of Computer Science Issues, Vol. 9, Issue 2,\n  No 1, Pages 28-36, March 2012", "doi": null, "report-no": "IJCSI-9-2-1-28-36", "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses a mixed integer programming (MIP) formulation for the\nmulti-item uncapacitated lot-sizing problem that is inspired from the trailer\nmanufacturer. The proposed MIP model has been utilized to find out the optimum\norder quantity, optimum order time, and the minimum total cost of purchasing,\nordering, and holding over the predefined planning horizon. This problem is\nknown as NP-hard problem. The model was presented in an optimal software form\nusing LINGO 13.0.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2012 18:31:20 GMT"}], "update_date": "2012-06-01", "authors_parsed": [["Mohammadi", "Maryam", ""], ["Tap", "Masine Md.", ""]]}]