[{"id": "0912.0071", "submitter": "Anand Sarwate", "authors": "Kamalika Chaudhuri, Claire Monteleoni, Anand D. Sarwate", "title": "Differentially Private Empirical Risk Minimization", "comments": "40 pages, 7 figures, accepted to the Journal of Machine Learning\n  Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy-preserving machine learning algorithms are crucial for the\nincreasingly common setting in which personal data, such as medical or\nfinancial records, are analyzed. We provide general techniques to produce\nprivacy-preserving approximations of classifiers learned via (regularized)\nempirical risk minimization (ERM). These algorithms are private under the\n$\\epsilon$-differential privacy definition due to Dwork et al. (2006). First we\napply the output perturbation ideas of Dwork et al. (2006), to ERM\nclassification. Then we propose a new method, objective perturbation, for\nprivacy-preserving machine learning algorithm design. This method entails\nperturbing the objective function before optimizing over classifiers. If the\nloss and regularizer satisfy certain convexity and differentiability criteria,\nwe prove theoretical results showing that our algorithms preserve privacy, and\nprovide generalization bounds for linear and nonlinear kernels. We further\npresent a privacy-preserving technique for tuning the parameters in general\nmachine learning algorithms, thereby providing end-to-end privacy guarantees\nfor the training process. We apply these results to produce privacy-preserving\nanalogues of regularized logistic regression and support vector machines. We\nobtain encouraging results from evaluating their performance on real\ndemographic and benchmark data sets. Our results show that both theoretically\nand empirically, objective perturbation is superior to the previous\nstate-of-the-art, output perturbation, in managing the inherent tradeoff\nbetween privacy and learning performance.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2009 04:35:44 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2010 19:33:44 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2010 05:26:22 GMT"}, {"version": "v4", "created": "Wed, 2 Jun 2010 23:16:36 GMT"}, {"version": "v5", "created": "Wed, 16 Feb 2011 22:35:55 GMT"}], "update_date": "2011-02-18", "authors_parsed": [["Chaudhuri", "Kamalika", ""], ["Monteleoni", "Claire", ""], ["Sarwate", "Anand D.", ""]]}, {"id": "0912.0132", "submitter": "Fadi Badra", "authors": "Fadi Badra (INRIA Lorraine - LORIA), Am\\'elie Cordier (LIRIS), Jean\n  Lieber (INRIA Lorraine - LORIA)", "title": "Opportunistic Adaptation Knowledge Discovery", "comments": null, "journal-ref": "8th International Conference on Case-Based Reasoning, ICCBR 2009,\n  Seattle : United States (2009)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptation has long been considered as the Achilles' heel of case-based\nreasoning since it requires some domain-specific knowledge that is difficult to\nacquire. In this paper, two strategies are combined in order to reduce the\nknowledge engineering cost induced by the adaptation knowledge (CA) acquisition\ntask: CA is learned from the case base by the means of knowledge discovery\ntechniques, and the CA acquisition sessions are opportunistically triggered,\ni.e., at problem-solving time.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2009 12:08:47 GMT"}], "update_date": "2009-12-02", "authors_parsed": [["Badra", "Fadi", "", "INRIA Lorraine - LORIA"], ["Cordier", "Am\u00e9lie", "", "LIRIS"], ["Lieber", "Jean", "", "INRIA Lorraine - LORIA"]]}, {"id": "0912.0224", "submitter": "Nicolas A. Barriga", "authors": "Nicolas A. Barriga, Mauricio Araya-L\\'opez", "title": "A Multi-stage Probabilistic Algorithm for Dynamic Path-Planning", "comments": "7 pages, 5 figures. Presented in Ingelectra 2009 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic sampling methods have become very popular to solve single-shot\npath planning problems. Rapidly-exploring Random Trees (RRTs) in particular\nhave been shown to be efficient in solving high dimensional problems. Even\nthough several RRT variants have been proposed for dynamic replanning, these\nmethods only perform well in environments with infrequent changes. This paper\naddresses the dynamic path planning problem by combining simple techniques in a\nmulti-stage probabilistic algorithm. This algorithm uses RRTs for initial\nplanning and informed local search for navigation. We show that this\ncombination of simple techniques provides better responses to highly dynamic\nenvironments than the RRT extensions.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2009 20:55:01 GMT"}], "update_date": "2009-12-02", "authors_parsed": [["Barriga", "Nicolas A.", ""], ["Araya-L\u00f3pez", "Mauricio", ""]]}, {"id": "0912.0266", "submitter": "Nicolas A. Barriga", "authors": "Nicolas A. Barriga, Mauricio Araya-L\\'opez, Mauricio Solar", "title": "Combining a Probabilistic Sampling Technique and Simple Heuristics to\n  solve the Dynamic Path Planning Problem", "comments": "8 pages, 7 figures. Presented at the XXVIII International Conference\n  of the Chilean Computer Society 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic sampling methods have become very popular to solve single-shot\npath planning problems. Rapidly-exploring Random Trees (RRTs) in particular\nhave been shown to be very efficient in solving high dimensional problems. Even\nthough several RRT variants have been proposed to tackle the dynamic replanning\nproblem, these methods only perform well in environments with infrequent\nchanges. This paper addresses the dynamic path planning problem by combining\nsimple techniques in a multi-stage probabilistic algorithm. This algorithm uses\nRRTs as an initial solution, informed local search to fix unfeasible paths and\na simple greedy optimizer. The algorithm is capable of recognizing when the\nlocal search is stuck, and subsequently restart the RRT. We show that this\ncombination of simple techniques provides better responses to a highly dynamic\nenvironment than the dynamic RRT variants.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2009 21:03:49 GMT"}], "update_date": "2009-12-03", "authors_parsed": [["Barriga", "Nicolas A.", ""], ["Araya-L\u00f3pez", "Mauricio", ""], ["Solar", "Mauricio", ""]]}, {"id": "0912.0270", "submitter": "Nicolas A. Barriga", "authors": "Nicolas A. Barriga", "title": "Single-Agent On-line Path Planning in Continuous, Unpredictable and\n  Highly Dynamic Environments", "comments": "54 pages, Master of Science in Informatics Engineering thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This document is a thesis on the subject of single-agent on-line path\nplanning in continuous,unpredictable and highly dynamic environments. The\nproblem is finding and traversing a collision-free path for a holonomic robot,\nwithout kinodynamic restrictions, moving in an environment with several\nunpredictably moving obstacles or adversaries. The availability of perfect\ninformation of the environment at all times is assumed.\n  Several static and dynamic variants of the Rapidly Exploring Random Trees\n(RRT) algorithm are explored, as well as an evolutionary algorithm for planning\nin dynamic environments called the Evolutionary Planner/Navigator. A\ncombination of both kinds of algorithms is proposed to overcome shortcomings in\nboth, and then a combination of a RRT variant for initial planning and informed\nlocal search for navigation, plus a simple greedy heuristic for optimization.\nWe show that this combination of simple techniques provides better responses to\nhighly dynamic environments than the RRT extensions.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2009 21:13:36 GMT"}], "update_date": "2009-12-03", "authors_parsed": [["Barriga", "Nicolas A.", ""]]}, {"id": "0912.2282", "submitter": "Kadirvelu SivaKumar", "authors": "Mrs. Neelu Nihalani, Dr. Sanjay Silakari and Dr. Mahesh Motwani", "title": "Design of Intelligent layer for flexible querying in databases", "comments": null, "journal-ref": "IJCSE Volume 1 Issue 2 2009 30-39", "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-based information technologies have been extensively used to help\nmany organizations, private companies, and academic and education institutions\nmanage their processes and information systems hereby become their nervous\ncentre. The explosion of massive data sets created by businesses, science and\ngovernments necessitates intelligent and more powerful computing paradigms so\nthat users can benefit from this data. Therefore most new-generation database\napplications demand intelligent information management to enhance efficient\ninteractions between database and the users. Database systems support only a\nBoolean query model. A selection query on SQL database returns all those tuples\nthat satisfy the conditions in the query.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2009 17:04:01 GMT"}], "update_date": "2009-12-14", "authors_parsed": [["Nihalani", "Mrs. Neelu", ""], ["Silakari", "Dr. Sanjay", ""], ["Motwani", "Dr. Mahesh", ""]]}, {"id": "0912.2385", "submitter": "Byron Boots", "authors": "Byron Boots, Sajid M. Siddiqi, Geoffrey J. Gordon", "title": "Closing the Learning-Planning Loop with Predictive State Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in artificial intelligence is that of planning to maximize\nfuture reward under uncertainty in a partially observable environment. In this\npaper we propose and demonstrate a novel algorithm which accurately learns a\nmodel of such an environment directly from sequences of action-observation\npairs. We then close the loop from observations to actions by planning in the\nlearned model and recovering a policy which is near-optimal in the original\nenvironment. Specifically, we present an efficient and statistically consistent\nspectral algorithm for learning the parameters of a Predictive State\nRepresentation (PSR). We demonstrate the algorithm by learning a model of a\nsimulated high-dimensional, vision-based mobile robot planning task, and then\nperform approximate point-based planning in the learned PSR. Analysis of our\nresults shows that the algorithm learns a state space which efficiently\ncaptures the essential features of the environment. This representation allows\naccurate prediction with a small number of parameters, and enables successful\nand efficient planning.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2009 00:59:26 GMT"}], "update_date": "2009-12-15", "authors_parsed": [["Boots", "Byron", ""], ["Siddiqi", "Sajid M.", ""], ["Gordon", "Geoffrey J.", ""]]}, {"id": "0912.2415", "submitter": "Juan Juli\\'an Merelo-Guerv\\'os Pr.", "authors": "Tomas Philip Runarsson, Juan J. Merelo-Guervos", "title": "Adapting Heuristic Mastermind Strategies to Evolutionary Algorithms", "comments": "Accepted at the NICSO'10 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The art of solving the Mastermind puzzle was initiated by Donald Knuth and is\nalready more than 30 years old; despite that, it still receives much attention\nin operational research and computer games journals, not to mention the\nnature-inspired stochastic algorithm literature. In this paper we try to\nsuggest a strategy that will allow nature-inspired algorithms to obtain results\nas good as those based on exhaustive search strategies; in order to do that, we\nfirst review, compare and improve current approaches to solving the puzzle;\nthen we test one of these strategies with an estimation of distribution\nalgorithm. Finally, we try to find a strategy that falls short of being\nexhaustive, and is then amenable for inclusion in nature inspired algorithms\n(such as evolutionary or particle swarm algorithms). This paper proves that by\nthe incorporation of local entropy into the fitness function of the\nevolutionary algorithm it becomes a better player than a random one, and gives\na rule of thumb on how to incorporate the best heuristic strategies to\nevolutionary algorithms without incurring in an excessive computational cost.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2009 12:17:48 GMT"}], "update_date": "2009-12-15", "authors_parsed": [["Runarsson", "Tomas Philip", ""], ["Merelo-Guervos", "Juan J.", ""]]}, {"id": "0912.2563", "submitter": "Karthik Narayanaswami", "authors": "Karthik Narayanaswami", "title": "A Model-Based Approach to Predicting Predator-Prey & Friend-Foe\n  Relationships in Ant Colonies", "comments": "Graduate work done in Fall 2005 at the BORG Lab, College of\n  Computing, Georgia Institute of Technology, under the advisement of Professor\n  Tucker Balch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding predator-prey relationships among insects is a challenging task\nin the domain of insect-colony research. This is due to several factors\ninvolved, such as determining whether a particular behavior is the result of a\npredator-prey interaction, a friend-foe interaction or another kind of\ninteraction. In this paper, we analyze a series of predator-prey and friend-foe\ninteractions in two colonies of carpenter ants to better understand and predict\nsuch behavior. Using the data gathered, we have also come up with a preliminary\nmodel for predicting such behavior under the specific conditions the experiment\nwas conducted in. In this paper, we present the results of our data analysis as\nwell as an overview of the processes involved.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2009 01:53:25 GMT"}], "update_date": "2009-12-15", "authors_parsed": [["Narayanaswami", "Karthik", ""]]}, {"id": "0912.2846", "submitter": "Agostino Dovier", "authors": "Agostino Dovier, Andrea Formisano, and Enrico Pontelli", "title": "Multi-valued Action Languages in CLP(FD)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Action description languages, such as A and B, are expressive instruments\nintroduced for formalizing planning domains and planning problem instances. The\npaper starts by proposing a methodology to encode an action language (with\nconditional effects and static causal laws), a slight variation of B, using\nConstraint Logic Programming over Finite Domains. The approach is then\ngeneralized to raise the use of constraints to the level of the action language\nitself. A prototype implementation has been developed, and the preliminary\nresults are presented and discussed.\n  To appear in Theory and Practice of Logic Programming (TPLP)\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2009 11:10:13 GMT"}], "update_date": "2009-12-16", "authors_parsed": [["Dovier", "Agostino", ""], ["Formisano", "Andrea", ""], ["Pontelli", "Enrico", ""]]}, {"id": "0912.3134", "submitter": "Michael Thomas", "authors": "Nadia Creignou, Johannes Schmidt, Michael Thomas", "title": "Complexity of Propositional Abduction for Restricted Sets of Boolean\n  Functions", "comments": "Proceedings version, the journal version is available at\n  http://arxiv.org/abs/1006.4923", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abduction is a fundamental and important form of non-monotonic reasoning.\nGiven a knowledge base explaining how the world behaves it aims at finding an\nexplanation for some observed manifestation. In this paper we focus on\npropositional abduction, where the knowledge base and the manifestation are\nrepresented by propositional formulae. The problem of deciding whether there\nexists an explanation has been shown to be SigmaP2-complete in general. We\nconsider variants obtained by restricting the allowed connectives in the\nformulae to certain sets of Boolean functions. We give a complete\nclassification of the complexity for all considerable sets of Boolean\nfunctions. In this way, we identify easier cases, namely NP-complete and\npolynomial cases; and we highlight sources of intractability. Further, we\naddress the problem of counting the explanations and draw a complete picture\nfor the counting complexity.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2009 13:28:23 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2010 20:58:09 GMT"}, {"version": "v3", "created": "Wed, 23 Jun 2010 14:24:20 GMT"}, {"version": "v4", "created": "Mon, 28 Jun 2010 13:32:20 GMT"}], "update_date": "2010-06-29", "authors_parsed": [["Creignou", "Nadia", ""], ["Schmidt", "Johannes", ""], ["Thomas", "Michael", ""]]}, {"id": "0912.3228", "submitter": "Vadim Bulitko", "authors": "Valeriy K. Bulitko and Vadim Bulitko", "title": "On Backtracking in Real-time Heuristic Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time heuristic search algorithms are suitable for situated agents that\nneed to make their decisions in constant time. Since the original work by Korf\nnearly two decades ago, numerous extensions have been suggested. One of the\nmost intriguing extensions is the idea of backtracking wherein the agent\ndecides to return to a previously visited state as opposed to moving forward\ngreedily. This idea has been empirically shown to have a significant impact on\nvarious performance measures. The studies have been carried out in particular\nempirical testbeds with specific real-time search algorithms that use\nbacktracking. Consequently, the extent to which the trends observed are\ncharacteristic of backtracking in general is unclear. In this paper, we present\nthe first entirely theoretical study of backtracking in real-time heuristic\nsearch. In particular, we present upper bounds on the solution cost exponential\nand linear in a parameter regulating the amount of backtracking. The results\nhold for a wide class of real-time heuristic search algorithms that includes\nmany existing algorithms as a small subclass.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2009 18:59:29 GMT"}], "update_date": "2009-12-17", "authors_parsed": [["Bulitko", "Valeriy K.", ""], ["Bulitko", "Vadim", ""]]}, {"id": "0912.3309", "submitter": "Afshin Rostamizadeh", "authors": "Corinna Cortes, Mehryar Mohri and Afshin Rostamizadeh", "title": "New Generalization Bounds for Learning Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents several novel generalization bounds for the problem of\nlearning kernels based on the analysis of the Rademacher complexity of the\ncorresponding hypothesis sets. Our bound for learning kernels with a convex\ncombination of p base kernels has only a log(p) dependency on the number of\nkernels, p, which is considerably more favorable than the previous best bound\ngiven for the same problem. We also give a novel bound for learning with a\nlinear combination of p base kernels with an L_2 regularization whose\ndependency on p is only in p^{1/4}.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2009 02:29:41 GMT"}], "update_date": "2009-12-18", "authors_parsed": [["Cortes", "Corinna", ""], ["Mohri", "Mehryar", ""], ["Rostamizadeh", "Afshin", ""]]}, {"id": "0912.3747", "submitter": "Prodromos Malakasiotis", "authors": "Ion Androutsopoulos and Prodromos Malakasiotis", "title": "A Survey of Paraphrasing and Textual Entailment Methods", "comments": "Technical Report, Natural Language Processing Group, Department of\n  Informatics, Athens University of Economics and Business, Greece, 2010", "journal-ref": "I. Androutsopoulos and P. Malakasiotis, \"A Survey of Paraphrasing\n  and Textual Entailment Methods\". Journal of Artificial Intelligence Research,\n  38:135-187, 2010", "doi": "10.1613/jair.2985", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paraphrasing methods recognize, generate, or extract phrases, sentences, or\nlonger natural language expressions that convey almost the same information.\nTextual entailment methods, on the other hand, recognize, generate, or extract\npairs of natural language expressions, such that a human who reads (and trusts)\nthe first element of a pair would most likely infer that the other element is\nalso true. Paraphrasing can be seen as bidirectional textual entailment and\nmethods from the two areas are often similar. Both kinds of methods are useful,\nat least in principle, in a wide range of natural language processing\napplications, including question answering, summarization, text generation, and\nmachine translation. We summarize key ideas from the two areas by considering\nin turn recognition, generation, and extraction methods, also pointing to\nprominent articles and resources.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2009 17:34:45 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2009 12:42:16 GMT"}, {"version": "v3", "created": "Sun, 30 May 2010 11:00:19 GMT"}], "update_date": "2010-06-01", "authors_parsed": [["Androutsopoulos", "Ion", ""], ["Malakasiotis", "Prodromos", ""]]}, {"id": "0912.4473", "submitter": "Shankar Vembu", "authors": "Shankar Vembu", "title": "Learning to Predict Combinatorial Structures", "comments": "PhD thesis, Department of Computer Science, University of Bonn\n  (submitted, December 2009)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The major challenge in designing a discriminative learning algorithm for\npredicting structured data is to address the computational issues arising from\nthe exponential size of the output space. Existing algorithms make different\nassumptions to ensure efficient, polynomial time estimation of model\nparameters. For several combinatorial structures, including cycles, partially\nordered sets, permutations and other graph classes, these assumptions do not\nhold. In this thesis, we address the problem of designing learning algorithms\nfor predicting combinatorial structures by introducing two new assumptions: (i)\nThe first assumption is that a particular counting problem can be solved\nefficiently. The consequence is a generalisation of the classical ridge\nregression for structured prediction. (ii) The second assumption is that a\nparticular sampling problem can be solved efficiently. The consequence is a new\ntechnique for designing and analysing probabilistic structured prediction\nmodels. These results can be applied to solve several complex learning problems\nincluding but not limited to multi-label classification, multi-category\nhierarchical classification, and label ranking.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2009 18:03:55 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2010 22:47:44 GMT"}], "update_date": "2010-06-29", "authors_parsed": [["Vembu", "Shankar", ""]]}, {"id": "0912.4553", "submitter": "Matthias Brust R.", "authors": "Reginaldo J. da Silva Filho, Matthias R. Brust and Carlos H.C. Ribeiro", "title": "Consensus Dynamics in a non-deterministic Naming Game with Shared Memory", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the naming game, individuals or agents exchange pairwise local information\nin order to communicate about objects in their common environment. The goal of\nthe game is to reach a consensus about naming these objects. Originally used to\ninvestigate language formation and self-organizing vocabularies, we extend the\nclassical naming game with a globally shared memory accessible by all agents.\nThis shared memory can be interpreted as an external source of knowledge like a\nbook or an Internet site. The extended naming game models an environment\nsimilar to one that can be found in the context of social bookmarking and\ncollaborative tagging sites where users tag sites using appropriate labels, but\nalso mimics an important aspect in the field of human-based image labeling.\nAlthough the extended naming game is non-deterministic in its word selection,\nwe show that consensus towards a common vocabulary is reached. More\nimportantly, we show the qualitative and quantitative influence of the external\nsource of information, i.e. the shared memory, on the consensus dynamics\nbetween the agents.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2009 02:42:33 GMT"}], "update_date": "2009-12-24", "authors_parsed": [["Filho", "Reginaldo J. da Silva", ""], ["Brust", "Matthias R.", ""], ["Ribeiro", "Carlos H. C.", ""]]}, {"id": "0912.4584", "submitter": "Brijnesh Jain", "authors": "Brijnesh Jain and Klaus Obermayer", "title": "A Necessary and Sufficient Condition for Graph Matching Being Equivalent\n  to the Maximum Weight Clique Problem", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper formulates a necessary and sufficient condition for a generic\ngraph matching problem to be equivalent to the maximum vertex and edge weight\nclique problem in a derived association graph. The consequences of this results\nare threefold: first, the condition is general enough to cover a broad range of\npractical graph matching problems; second, a proof to establish equivalence\nbetween graph matching and clique search reduces to showing that a given graph\nmatching problem satisfies the proposed condition; and third, the result sets\nthe scene for generic continuous solutions for a broad range of graph matching\nproblems. To illustrate the mathematical framework, we apply it to a number of\ngraph matching problems, including the problem of determining the graph edit\ndistance.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2009 08:40:51 GMT"}], "update_date": "2009-12-24", "authors_parsed": [["Jain", "Brijnesh", ""], ["Obermayer", "Klaus", ""]]}, {"id": "0912.4598", "submitter": "Brijnesh Jain", "authors": "Brijnesh J. Jain and Klaus Obermayer", "title": "Elkan's k-Means for Graphs", "comments": "21 pages; submitted to MLJ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends k-means algorithms from the Euclidean domain to the domain\nof graphs. To recompute the centroids, we apply subgradient methods for solving\nthe optimization-based formulation of the sample mean of graphs. To accelerate\nthe k-means algorithm for graphs without trading computational time against\nsolution quality, we avoid unnecessary graph distance calculations by\nexploiting the triangle inequality of the underlying distance metric following\nElkan's k-means algorithm proposed in \\cite{Elkan03}. In experiments we show\nthat the accelerated k-means algorithm are faster than the standard k-means\nalgorithm for graphs provided there is a cluster structure in the data.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2009 10:30:11 GMT"}], "update_date": "2009-12-24", "authors_parsed": [["Jain", "Brijnesh J.", ""], ["Obermayer", "Klaus", ""]]}, {"id": "0912.4649", "submitter": "Boris Ryabko", "authors": "Boris Ryabko, Zhanna Reznikova", "title": "The use of ideas of Information Theory for studying \"language\" and\n  intelligence in ants", "comments": null, "journal-ref": "Entropy 2009, 11(4), 836-853", "doi": "10.3390/e11040836", "report-no": null, "categories": "cs.IT cs.AI math.IT nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this review we integrate results of long term experimental study on ant\n\"language\" and intelligence which were fully based on fundamental ideas of\nInformation Theory, such as the Shannon entropy, the Kolmogorov complexity, and\nthe Shannon's equation connecting the length of a message ($l$) and its\nfrequency $(p)$, i.e. $l = - \\log p$ for rational communication systems. This\napproach, new for studying biological communication systems, enabled us to\nobtain the following important results on ants' communication and intelligence:\ni) to reveal \"distant homing\" in ants, that is, their ability to transfer\ninformation about remote events; ii) to estimate the rate of information\ntransmission; iii) to reveal that ants are able to grasp regularities and to\nuse them for \"compression\" of information; iv) to reveal that ants are able to\ntransfer to each other the information about the number of objects; v) to\ndiscover that ants can add and subtract small numbers. The obtained results\nshow that Information Theory is not only wonderful mathematical theory, but\nmany its results may be considered as Nature laws.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2009 14:12:47 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Ryabko", "Boris", ""], ["Reznikova", "Zhanna", ""]]}, {"id": "0912.4879", "submitter": "Alain Bonardi", "authors": "Alain Bonardi (STMS), Francis Rousseaux (STMS, CRESTIC)", "title": "Similarit\\'e en intension vs en extension : \\`a la crois\\'ee de\n  l'informatique et du th\\'e\\^atre", "comments": null, "journal-ref": "Revue d'Intelligence Artificielle (2005) 281-288", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional staging is based on a formal approach of similarity leaning on\ndramaturgical ontologies and instanciation variations. Inspired by interactive\ndata mining, that suggests different approaches, we give an overview of\ncomputer science and theater researches using computers as partners of the\nactor to escape the a priori specification of roles.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2009 15:28:15 GMT"}], "update_date": "2009-12-25", "authors_parsed": [["Bonardi", "Alain", "", "STMS"], ["Rousseaux", "Francis", "", "STMS, CRESTIC"]]}, {"id": "0912.4883", "submitter": "Daniil Ryabko", "authors": "Daniil Ryabko (INRIA Futurs, Lifl)", "title": "On Finding Predictors for Arbitrary Families of Processes", "comments": null, "journal-ref": "Journal of Machine Learning Research 11 (2010) 581-602", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem is sequence prediction in the following setting. A sequence\n$x_1,...,x_n,...$ of discrete-valued observations is generated according to\nsome unknown probabilistic law (measure) $\\mu$. After observing each outcome,\nit is required to give the conditional probabilities of the next observation.\nThe measure $\\mu$ belongs to an arbitrary but known class $C$ of stochastic\nprocess measures. We are interested in predictors $\\rho$ whose conditional\nprobabilities converge (in some sense) to the \"true\" $\\mu$-conditional\nprobabilities if any $\\mu\\in C$ is chosen to generate the sequence. The\ncontribution of this work is in characterizing the families $C$ for which such\npredictors exist, and in providing a specific and simple form in which to look\nfor a solution. We show that if any predictor works, then there exists a\nBayesian predictor, whose prior is discrete, and which works too. We also find\nseveral sufficient and necessary conditions for the existence of a predictor,\nin terms of topological characterizations of the family $C$, as well as in\nterms of local behaviour of the measures in $C$, which in some cases lead to\nprocedures for constructing such predictors. It should be emphasized that the\nframework is completely general: the stochastic processes considered are not\nrequired to be i.i.d., stationary, or to belong to any parametric or countable\nfamily.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2009 15:29:32 GMT"}], "update_date": "2012-03-13", "authors_parsed": [["Ryabko", "Daniil", "", "INRIA Futurs, Lifl"]]}, {"id": "0912.5029", "submitter": "Christos Dimitrakakis", "authors": "Christos Dimitrakakis", "title": "Complexity of stochastic branch and bound methods for belief tree search\n  in Bayesian reinforcement learning", "comments": "13 pages, 1 figure, ICAART 2010", "journal-ref": null, "doi": null, "report-no": "TR-UVA-09-01", "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a lot of recent work on Bayesian methods for reinforcement\nlearning exhibiting near-optimal online performance. The main obstacle facing\nsuch methods is that in most problems of interest, the optimal solution\ninvolves planning in an infinitely large tree. However, it is possible to\nobtain stochastic lower and upper bounds on the value of each tree node. This\nenables us to use stochastic branch and bound algorithms to search the tree\nefficiently. This paper proposes two such algorithms and examines their\ncomplexity in this setting.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2009 16:32:46 GMT"}], "update_date": "2009-12-31", "authors_parsed": [["Dimitrakakis", "Christos", ""]]}, {"id": "0912.5073", "submitter": "Ji Han", "authors": "Ji Han", "title": "A Rational Decision Maker with Ordinal Utility under Uncertainty:\n  Optimism and Pessimism", "comments": "This paper has been withdrawn by the author", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In game theory and artificial intelligence, decision making models often\ninvolve maximizing expected utility, which does not respect ordinal invariance.\nIn this paper, the author discusses the possibility of preserving ordinal\ninvariance and still making a rational decision under uncertainty.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2009 14:09:43 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2010 12:25:13 GMT"}], "update_date": "2010-06-14", "authors_parsed": [["Han", "Ji", ""]]}, {"id": "0912.5241", "submitter": "Wolfgang Gatterbauer", "authors": "Wolfgang Gatterbauer, Magdalena Balazinska, Nodira Khoussainova, Dan\n  Suciu", "title": "Believe It or Not: Adding Belief Annotations to Databases", "comments": "17 pages, 10 figures", "journal-ref": "Full version of: VLDB 2009 conference version; PVLDB 2(1):1-12\n  (2009)", "doi": null, "report-no": "University of Washington CSE Technical Report 08-12-01", "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a database model that allows users to annotate data with belief\nstatements. Our motivation comes from scientific database applications where a\ncommunity of users is working together to assemble, revise, and curate a shared\ndata repository. As the community accumulates knowledge and the database\ncontent evolves over time, it may contain conflicting information and members\ncan disagree on the information it should store. For example, Alice may believe\nthat a tuple should be in the database, whereas Bob disagrees. He may also\ninsert the reason why he thinks Alice believes the tuple should be in the\ndatabase, and explain what he thinks the correct tuple should be instead.\n  We propose a formal model for Belief Databases that interprets users'\nannotations as belief statements. These annotations can refer both to the base\ndata and to other annotations. We give a formal semantics based on a fragment\nof multi-agent epistemic logic and define a query language over belief\ndatabases. We then prove a key technical result, stating that every belief\ndatabase can be encoded as a canonical Kripke structure. We use this structure\nto describe a relational representation of belief databases, and give an\nalgorithm for translating queries over the belief database into standard\nrelational queries. Finally, we report early experimental results with our\nprototype implementation on synthetic data.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2009 18:36:21 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Gatterbauer", "Wolfgang", ""], ["Balazinska", "Magdalena", ""], ["Khoussainova", "Nodira", ""], ["Suciu", "Dan", ""]]}, {"id": "0912.5340", "submitter": "Wolfgang Gatterbauer", "authors": "Alexandra Meliou, Wolfgang Gatterbauer, Katherine F. Moore, Dan Suciu", "title": "Why so? or Why no? Functional Causality for Explaining Query Answers", "comments": "18 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": "University of Washington CSE Technical Report 09-12-01", "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose causality as a unified framework to explain query\nanswers and non-answers, thus generalizing and extending several previously\nproposed approaches of provenance and missing query result explanations.\n  We develop our framework starting from the well-studied definition of actual\ncauses by Halpern and Pearl. After identifying some undesirable characteristics\nof the original definition, we propose functional causes as a refined\ndefinition of causality with several desirable properties. These properties\nallow us to apply our notion of causality in a database context and apply it\nuniformly to define the causes of query results and their individual\ncontributions in several ways: (i) we can model both provenance as well as\nnon-answers, (ii) we can define explanations as either data in the input\nrelations or relational operations in a query plan, and (iii) we can give\ngraded degrees of responsibility to individual causes, thus allowing us to rank\ncauses. In particular, our approach allows us to explain contributions to\nrelational aggregate functions and to rank causes according to their respective\nresponsibilities. We give complexity results and describe polynomial algorithms\nfor evaluating causality in tractable cases. Throughout the paper, we\nillustrate the applicability of our framework with several examples.\n  Overall, we develop in this paper the theoretical foundations of causality\ntheory in a database context.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2009 05:56:22 GMT"}], "update_date": "2009-12-31", "authors_parsed": [["Meliou", "Alexandra", ""], ["Gatterbauer", "Wolfgang", ""], ["Moore", "Katherine F.", ""], ["Suciu", "Dan", ""]]}, {"id": "0912.5511", "submitter": "Hans Tompits", "authors": "James Delgrande, Torsten Schaub, Hans Tompits and Stefan Woltran", "title": "A general approach to belief change in answer set programming", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of belief change in (nonmonotonic) logic programming\nunder answer set semantics. Unlike previous approaches to belief change in\nlogic programming, our formal techniques are analogous to those of\ndistance-based belief revision in propositional logic. In developing our\nresults, we build upon the model theory of logic programs furnished by SE\nmodels. Since SE models provide a formal, monotonic characterisation of logic\nprograms, we can adapt techniques from the area of belief revision to belief\nchange in logic programs. We introduce methods for revising and merging logic\nprograms, respectively. For the former, we study both subset-based revision as\nwell as cardinality-based revision, and we show that they satisfy the majority\nof the AGM postulates for revision. For merging, we consider operators\nfollowing arbitration merging and IC merging, respectively. We also present\nencodings for computing the revision as well as the merging of logic programs\nwithin the same logic programming framework, giving rise to a direct\nimplementation of our approach in terms of off-the-shelf answer set solvers.\nThese encodings reflect in turn the fact that our change operators do not\nincrease the complexity of the base formalism.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2009 18:33:43 GMT"}], "update_date": "2009-12-31", "authors_parsed": [["Delgrande", "James", ""], ["Schaub", "Torsten", ""], ["Tompits", "Hans", ""], ["Woltran", "Stefan", ""]]}, {"id": "0912.5533", "submitter": "Reinhard Moratz", "authors": "Reinhard Moratz, Dominik L\\\"ucke, Till Mossakowski", "title": "Oriented Straight Line Segment Algebra: Qualitative Spatial Reasoning\n  about Oriented Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Nearly 15 years ago, a set of qualitative spatial relations between oriented\nstraight line segments (dipoles) was suggested by Schlieder. This work received\nsubstantial interest amongst the qualitative spatial reasoning community.\nHowever, it turned out to be difficult to establish a sound constraint calculus\nbased on these relations. In this paper, we present the results of a new\ninvestigation into dipole constraint calculi which uses algebraic methods to\nderive sound results on the composition of relations and other properties of\ndipole calculi. Our results are based on a condensed semantics of the dipole\nrelations.\n  In contrast to the points that are normally used, dipoles are extended and\nhave an intrinsic direction. Both features are important properties of natural\nobjects. This allows for a straightforward representation of prototypical\nreasoning tasks for spatial agents. As an example, we show how to generate\nsurvey knowledge from local observations in a street network. The example\nillustrates the fast constraint-based reasoning capabilities of the dipole\ncalculus. We integrate our results into two reasoning tools which are publicly\navailable.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2009 20:38:12 GMT"}], "update_date": "2009-12-31", "authors_parsed": [["Moratz", "Reinhard", ""], ["L\u00fccke", "Dominik", ""], ["Mossakowski", "Till", ""]]}]