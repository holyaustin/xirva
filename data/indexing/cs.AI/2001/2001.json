[{"id": "2001.00006", "submitter": "Travis LaCroix", "authors": "Travis LaCroix and Yoshua Bengio", "title": "Learning from Learning Machines: Optimisation, Rules, and Social Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an analogy between machine learning systems and economic entities in\nthat they are both adaptive, and their behaviour is specified in a more-or-less\nexplicit way. It appears that the area of AI that is most analogous to the\nbehaviour of economic entities is that of morally good decision-making, but it\nis an open question as to how precisely moral behaviour can be achieved in an\nAI system. This paper explores the analogy between these two complex systems,\nand we suggest that a clearer understanding of this apparent analogy may help\nus forward in both the socio-economic domain and the AI domain: known results\nin economics may help inform feasible solutions in AI safety, but also known\nresults in AI may inform economic policy. If this claim is correct, then the\nrecent successes of deep learning for AI suggest that more implicit\nspecifications work better than explicit ones for solving such problems.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 17:42:06 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["LaCroix", "Travis", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2001.00081", "submitter": "Patrick Kelley", "authors": "Patrick Gage Kelley, Yongwei Yang, Courtney Heldreth, Christopher\n  Moessner, Aaron Sedley, Andreas Kramm, David T. Newman, and Allison Woodruff", "title": "Exciting, Useful, Worrying, Futuristic: Public Perception of Artificial\n  Intelligence in 8 Countries", "comments": "12 pages, 2 figures, 3 tables. AIES 2021: Proceedings of the AAAI/ACM\n  Conference on AI, Ethics, and Society", "journal-ref": null, "doi": "10.1145/3461702.3462605", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the influence and use of artificial intelligence (AI) have grown and its\ntransformative potential has become more apparent, many questions have been\nraised regarding the economic, political, social, and ethical implications of\nits use. Public opinion plays an important role in these discussions,\ninfluencing product adoption, commercial development, research funding, and\nregulation. In this paper we present results of an in-depth survey of public\nopinion of artificial intelligence conducted with 10,005 respondents spanning\neight countries and six continents. We report widespread perception that AI\nwill have significant impact on society, accompanied by strong support for the\nresponsible development and use of AI, and also characterize the public's\nsentiment towards AI with four key themes (exciting, useful, worrying, and\nfuturistic) whose prevalence distinguishes response to AI in different\ncountries.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 10:27:05 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 17:20:34 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Kelley", "Patrick Gage", ""], ["Yang", "Yongwei", ""], ["Heldreth", "Courtney", ""], ["Moessner", "Christopher", ""], ["Sedley", "Aaron", ""], ["Kramm", "Andreas", ""], ["Newman", "David T.", ""], ["Woodruff", "Allison", ""]]}, {"id": "2001.00089", "submitter": "Candice Schumann", "authors": "Debjani Saha, Candice Schumann, Duncan C. McElfresh, John P.\n  Dickerson, Michelle L. Mazurek, Michael Carl Tschantz", "title": "Measuring Non-Expert Comprehension of Machine Learning Fairness Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bias in machine learning has manifested injustice in several areas, such as\nmedicine, hiring, and criminal justice. In response, computer scientists have\ndeveloped myriad definitions of fairness to correct this bias in fielded\nalgorithms. While some definitions are based on established legal and ethical\nnorms, others are largely mathematical. It is unclear whether the general\npublic agrees with these fairness definitions, and perhaps more importantly,\nwhether they understand these definitions. We take initial steps toward\nbridging this gap between ML researchers and the public, by addressing the\nquestion: does a lay audience understand a basic definition of ML fairness? We\ndevelop a metric to measure comprehension of three such\ndefinitions--demographic parity, equal opportunity, and equalized odds. We\nevaluate this metric using an online survey, and investigate the relationship\nbetween comprehension and sentiment, demographics, and the definition itself.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 00:58:54 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 16:23:08 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 21:13:01 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Saha", "Debjani", ""], ["Schumann", "Candice", ""], ["McElfresh", "Duncan C.", ""], ["Dickerson", "John P.", ""], ["Mazurek", "Michelle L.", ""], ["Tschantz", "Michael Carl", ""]]}, {"id": "2001.00102", "submitter": "Baoxiang Wang", "authors": "Baoxiang Wang, Shuai Li, Jiajin Li, Siu On Chan", "title": "The Gambler's Problem and Beyond", "comments": "International Conference on Learning Representations (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the Gambler's problem, a simple reinforcement learning problem\nwhere the gambler has the chance to double or lose the bets until the target is\nreached. This is an early example introduced in the reinforcement learning\ntextbook by Sutton and Barto (2018), where they mention an interesting pattern\nof the optimal value function with high-frequency components and repeating\nnon-smooth points. It is however without further investigation. We provide the\nexact formula for the optimal value function for both the discrete and the\ncontinuous cases. Though simple as it might seem, the value function is\npathological: fractal, self-similar, derivative taking either zero or infinity,\nand not written as elementary functions. It is in fact one of the generalized\nCantor functions, where it holds a complexity that has been uncharted thus far.\nOur analyses could provide insights into improving value function\napproximation, gradient-based algorithms, and Q-learning, in real applications\nand implementations.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 22:48:15 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 11:44:17 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 12:43:52 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Wang", "Baoxiang", ""], ["Li", "Shuai", ""], ["Li", "Jiajin", ""], ["Chan", "Siu On", ""]]}, {"id": "2001.00127", "submitter": "Kai Jiang", "authors": "Kai Jiang, XiaoLong Qin", "title": "Reinforcement Learning with Goal-Distance Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning usually uses the feedback rewards of environmental to\ntrain agents. But the rewards in the actual environment are sparse, and even\nsome environments will not rewards. Most of the current methods are difficult\nto get good performance in sparse reward or non-reward environments. Although\nusing shaped rewards is effective when solving sparse reward tasks, it is\nlimited to specific problems and learning is also susceptible to local optima.\nWe propose a model-free method that does not rely on environmental rewards to\nsolve the problem of sparse rewards in the general environment. Our method use\nthe minimum number of transitions between states as the distance to replace the\nrewards of environmental, and proposes a goal-distance gradient to achieve\npolicy improvement. We also introduce a bridge point planning method based on\nthe characteristics of our method to improve exploration efficiency, thereby\nsolving more complex tasks. Experiments show that our method performs better on\nsparse reward and local optimal problems in complex environments than previous\nwork.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 02:37:34 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 12:26:33 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Jiang", "Kai", ""], ["Qin", "XiaoLong", ""]]}, {"id": "2001.00234", "submitter": "Ramin Ayanzadeh", "authors": "Ramin Ayanzadeh, Milton Halem and Tim Finin", "title": "Reinforcement Quantum Annealing: A Quantum-Assisted Learning Automata\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the reinforcement quantum annealing (RQA) scheme in which an\nintelligent agent interacts with a quantum annealer that plays the stochastic\nenvironment role of learning automata and tries to iteratively find better\nIsing Hamiltonians for the given problem of interest. As a proof-of-concept, we\npropose a novel approach for reducing the NP-complete problem of Boolean\nsatisfiability (SAT) to minimizing Ising Hamiltonians and show how to apply the\nRQA for increasing the probability of finding the global optimum. Our\nexperimental results on two different benchmark SAT problems (namely factoring\npseudo-prime numbers and random SAT with phase transitions), using a D-Wave\n2000Q quantum processor, demonstrated that RQA finds notably better solutions\nwith fewer samples, compared to state-of-the-art techniques in the realm of\nquantum annealing.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 16:41:58 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Ayanzadeh", "Ramin", ""], ["Halem", "Milton", ""], ["Finin", "Tim", ""]]}, {"id": "2001.00248", "submitter": "Sungryull Sohn", "authors": "Sungryull Sohn, Hyunjae Woo, Jongwook Choi, Honglak Lee", "title": "Meta Reinforcement Learning with Autonomous Inference of Subtask\n  Dependencies", "comments": "Published in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and address a novel few-shot RL problem, where a task is\ncharacterized by a subtask graph which describes a set of subtasks and their\ndependencies that are unknown to the agent. The agent needs to quickly adapt to\nthe task over few episodes during adaptation phase to maximize the return in\nthe test phase. Instead of directly learning a meta-policy, we develop a\nMeta-learner with Subtask Graph Inference(MSGI), which infers the latent\nparameter of the task by interacting with the environment and maximizes the\nreturn given the latent parameter. To facilitate learning, we adopt an\nintrinsic reward inspired by upper confidence bound (UCB) that encourages\nefficient exploration. Our experiment results on two grid-world domains and\nStarCraft II environments show that the proposed method is able to accurately\ninfer the latent task parameter, and to adapt more efficiently than existing\nmeta RL and hierarchical RL methods.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 17:34:00 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 01:44:03 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Sohn", "Sungryull", ""], ["Woo", "Hyunjae", ""], ["Choi", "Jongwook", ""], ["Lee", "Honglak", ""]]}, {"id": "2001.00271", "submitter": "Khimya Khetarpal", "authors": "Khimya Khetarpal, Martin Klissarov, Maxime Chevalier-Boisvert,\n  Pierre-Luc Bacon, Doina Precup", "title": "Options of Interest: Temporal Abstraction with Interest Functions", "comments": "To appear in Proceedings of the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal abstraction refers to the ability of an agent to use behaviours of\ncontrollers which act for a limited, variable amount of time. The options\nframework describes such behaviours as consisting of a subset of states in\nwhich they can initiate, an internal policy and a stochastic termination\ncondition. However, much of the subsequent work on option discovery has ignored\nthe initiation set, because of difficulty in learning it from data. We provide\na generalization of initiation sets suitable for general function\napproximation, by defining an interest function associated with an option. We\nderive a gradient-based learning algorithm for interest functions, leading to a\nnew interest-option-critic architecture. We investigate how interest functions\ncan be leveraged to learn interpretable and reusable temporal abstractions. We\ndemonstrate the efficacy of the proposed approach through quantitative and\nqualitative results, in both discrete and continuous environments.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 21:24:39 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Khetarpal", "Khimya", ""], ["Klissarov", "Martin", ""], ["Chevalier-Boisvert", "Maxime", ""], ["Bacon", "Pierre-Luc", ""], ["Precup", "Doina", ""]]}, {"id": "2001.00329", "submitter": "Dallas Card", "authors": "Dallas Card and Noah A. Smith", "title": "On Consequentialism and Fairness", "comments": "Updating to published version", "journal-ref": "Front. Artif. Intell., 08 May 2020", "doi": "10.3389/frai.2020.00034", "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on fairness in machine learning has primarily emphasized how to\ndefine, quantify, and encourage \"fair\" outcomes. Less attention has been paid,\nhowever, to the ethical foundations which underlie such efforts. Among the\nethical perspectives that should be taken into consideration is\nconsequentialism, the position that, roughly speaking, outcomes are all that\nmatter. Although consequentialism is not free from difficulties, and although\nit does not necessarily provide a tractable way of choosing actions (because of\nthe combined problems of uncertainty, subjectivity, and aggregation), it\nnevertheless provides a powerful foundation from which to critique the existing\nliterature on machine learning fairness. Moreover, it brings to the fore some\nof the tradeoffs involved, including the problem of who counts, the pros and\ncons of using a policy, and the relative value of the distant future. In this\npaper we provide a consequentialist critique of common definitions of fairness\nwithin machine learning, as well as a machine learning perspective on\nconsequentialism. We conclude with a broader discussion of the issues of\nlearning and randomization, which have important implications for the ethics of\nautomated decision making systems.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 05:39:48 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 04:36:44 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Card", "Dallas", ""], ["Smith", "Noah A.", ""]]}, {"id": "2001.00338", "submitter": "Ryan Wisnesky", "authors": "Eric Daimler, Ryan Wisnesky", "title": "Informal Data Transformation Considered Harmful", "comments": "Proceedings paper for AAAI FSS-19: HAI19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we take the common position that AI systems are limited more by\nthe integrity of the data they are learning from than the sophistication of\ntheir algorithms, and we take the uncommon position that the solution to\nachieving better data integrity in the enterprise is not to clean and validate\ndata ex-post-facto whenever needed (the so-called data lake approach to data\nmanagement, which can lead to data scientists spending 80% of their time\ncleaning data), but rather to formally and automatically guarantee that data\nintegrity is preserved as it transformed (migrated, integrated, composed,\nqueried, viewed, etc) throughout the enterprise, so that data and programs that\ndepend on that data need not constantly be re-validated for every particular\nuse.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 06:26:36 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Daimler", "Eric", ""], ["Wisnesky", "Ryan", ""]]}, {"id": "2001.00463", "submitter": "Toby Shevlane", "authors": "Toby Shevlane, Allan Dafoe", "title": "The Offense-Defense Balance of Scientific Knowledge: Does Publishing AI\n  Research Reduce Misuse?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing concern over the potential misuse of artificial intelligence\n(AI) research. Publishing scientific research can facilitate misuse of the\ntechnology, but the research can also contribute to protections against misuse.\nThis paper addresses the balance between these two effects. Our theoretical\nframework elucidates the factors governing whether the published research will\nbe more useful for attackers or defenders, such as the possibility for adequate\ndefensive measures, or the independent discovery of the knowledge outside of\nthe scientific community. The balance will vary across scientific fields.\nHowever, we show that the existing conversation within AI has imported concepts\nand conclusions from prior debates within computer security over the disclosure\nof software vulnerabilities. While disclosure of software vulnerabilities often\nfavours defence, this cannot be assumed for AI research. The AI research\ncommunity should consider concepts and policies from a broad set of adjacent\nfields, and ultimately needs to craft policy well-suited to its particular\nchallenges.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 10:20:44 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 23:24:21 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Shevlane", "Toby", ""], ["Dafoe", "Allan", ""]]}, {"id": "2001.00471", "submitter": "Haruna Isah", "authors": "Kennedy Ralston, Yuhao Chen, Haruna Isah, Farhana Zulkernine", "title": "A Voice Interactive Multilingual Student Support System using IBM Watson", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems powered by artificial intelligence are being developed to be more\nuser-friendly by communicating with users in a progressively human-like\nconversational way. Chatbots, also known as dialogue systems, interactive\nconversational agents, or virtual agents are an example of such systems used in\na wide variety of applications ranging from customer support in the business\ndomain to companionship in the healthcare sector. It is becoming increasingly\nimportant to develop chatbots that can best respond to the personalized needs\nof their users so that they can be as helpful to the user as possible in a real\nhuman way. This paper investigates and compares three popular existing chatbots\nAPI offerings and then propose and develop a voice interactive and multilingual\nchatbot that can effectively respond to users mood, tone, and language using\nIBM Watson Assistant, Tone Analyzer, and Language Translator. The chatbot was\nevaluated using a use case that was targeted at responding to users needs\nregarding exam stress based on university students survey data generated using\nGoogle Forms. The results of measuring the chatbot effectiveness at analyzing\nresponses regarding exam stress indicate that the chatbot responding\nappropriately to the user queries regarding how they are feeling about exams\n76.5%. The chatbot could also be adapted for use in other application areas\nsuch as student info-centers, government kiosks, and mental health support\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 18:58:25 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Ralston", "Kennedy", ""], ["Chen", "Yuhao", ""], ["Isah", "Haruna", ""], ["Zulkernine", "Farhana", ""]]}, {"id": "2001.00496", "submitter": "Andreas Sedlmeier", "authors": "Andreas Sedlmeier, Thomas Gabor, Thomy Phan, Lenz Belzner, Claudia\n  Linnhoff-Popien", "title": "Uncertainty-Based Out-of-Distribution Classification in Deep\n  Reinforcement Learning", "comments": "arXiv admin note: text overlap with arXiv:1901.02219", "journal-ref": "Proceedings of the 12th International Conference on Agents and\n  Artificial Intelligence - Volume 2: ICAART, 2020, ISBN 978-989-758-395-7,\n  pages 522-529", "doi": "10.5220/0008949905220529", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness to out-of-distribution (OOD) data is an important goal in building\nreliable machine learning systems. Especially in autonomous systems, wrong\npredictions for OOD inputs can cause safety critical situations. As a first\nstep towards a solution, we consider the problem of detecting such data in a\nvalue-based deep reinforcement learning (RL) setting. Modelling this problem as\na one-class classification problem, we propose a framework for\nuncertainty-based OOD classification: UBOOD. It is based on the effect that an\nagent's epistemic uncertainty is reduced for situations encountered during\ntraining (in-distribution), and thus lower than for unencountered (OOD)\nsituations. Being agnostic towards the approach used for estimating epistemic\nuncertainty, combinations with different uncertainty estimation methods, e.g.\napproximate Bayesian inference methods or ensembling techniques are possible.\nWe further present a first viable solution for calculating a dynamic\nclassification threshold, based on the uncertainty distribution of the training\ndata. Evaluation shows that the framework produces reliable classification\nresults when combined with ensemble-based estimators, while the combination\nwith concrete dropout-based estimators fails to reliably detect OOD situations.\nIn summary, UBOOD presents a viable approach for OOD classification in deep RL\nsettings by leveraging the epistemic uncertainty of the agent's value function.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 09:52:49 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Sedlmeier", "Andreas", ""], ["Gabor", "Thomas", ""], ["Phan", "Thomy", ""], ["Belzner", "Lenz", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "2001.00503", "submitter": "Letian Chen", "authors": "Letian Chen, Rohan Paleja, Muyleng Ghuy, Matthew Gombolay", "title": "Joint Goal and Strategy Inference across Heterogeneous Demonstrators via\n  Reward Network Distillation", "comments": "In Proceedings of the 2020 ACM/IEEE In-ternational Conference on\n  Human-Robot Interaction (HRI '20), March 23 to 26, 2020, Cambridge, United\n  Kingdom.ACM, New York, NY, USA, 10 pages", "journal-ref": null, "doi": "10.1145/3319502.3374791", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has achieved tremendous success as a general\nframework for learning how to make decisions. However, this success relies on\nthe interactive hand-tuning of a reward function by RL experts. On the other\nhand, inverse reinforcement learning (IRL) seeks to learn a reward function\nfrom readily-obtained human demonstrations. Yet, IRL suffers from two major\nlimitations: 1) reward ambiguity - there are an infinite number of possible\nreward functions that could explain an expert's demonstration and 2)\nheterogeneity - human experts adopt varying strategies and preferences, which\nmakes learning from multiple demonstrators difficult due to the common\nassumption that demonstrators seeks to maximize the same reward. In this work,\nwe propose a method to jointly infer a task goal and humans' strategic\npreferences via network distillation. This approach enables us to distill a\nrobust task reward (addressing reward ambiguity) and to model each strategy's\nobjective (handling heterogeneity). We demonstrate our algorithm can better\nrecover task reward and strategy rewards and imitate the strategies in two\nsimulated tasks and a real-world table tennis task.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 16:04:21 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 18:45:39 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 16:04:47 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Chen", "Letian", ""], ["Paleja", "Rohan", ""], ["Ghuy", "Muyleng", ""], ["Gombolay", "Matthew", ""]]}, {"id": "2001.00569", "submitter": "Massimiliano Dal Mas", "authors": "Massimiliano Dal Mas", "title": "Emergent Behaviors from Folksonomy Driven Interactions", "comments": "6 pages, 5 figures; for details see: http://www.maxdalmas.com arXiv\n  admin note: text overlap with arXiv:1612.09574", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reflect the evolving knowledge on the Web this paper considers ontologies\nbased on folksonomies according to a new concept structure called\n\"Folksodriven\" to represent folksonomies. This paper describes a research\nprogram for studying Folksodriven tags interactions leading to Folksodriven\ncluster behavior. The goal of the research is to understand the type of simple\nlocal interactions which produce complex and purposive group behaviors on\nFolksodriven tags. We describe a synthetic, bottom-up approach to studying\ngroup behavior, consisting of designing and testing a variety of social\ninteractions and cultural scenarios with Folksodriven tags. We propose a set of\nbasic interactions which can be used to structure and simplify the process of\nboth designing and analyzing emergent group behaviors. The presented behavior\nrepertories was developed and tested on a folksonomy environment.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 18:33:03 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Mas", "Massimiliano Dal", ""]]}, {"id": "2001.00570", "submitter": "Yaoshiang Ho", "authors": "Yaoshiang Ho, Samuel Wookey", "title": "The Real-World-Weight Cross-Entropy Loss Function: Modeling the Costs of\n  Mislabeling", "comments": "Submitted to IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2019.2962617", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new metric to measure goodness-of-fit for\nclassifiers, the Real World Cost function. This metric factors in information\nabout a real world problem, such as financial impact, that other measures like\naccuracy or F1 do not. This metric is also more directly interpretable for\nusers. To optimize for this metric, we introduce the Real-World- Weight\nCrossentropy loss function, in both binary and single-label classification\nvariants. Both variants allow direct input of real world costs as weights. For\nsingle-label, multicategory classification, our loss function also allows\ndirect penalization of probabilistic false positives, weighted by label, during\nthe training of a machine learning model. We compare the design of our loss\nfunction to the binary crossentropy and categorical crossentropy functions, as\nwell as their weighted variants, to discuss the potential for improvement in\nhandling a variety of known shortcomings of machine learning, ranging from\nimbalanced classes to medical diagnostic error to reinforcement of social bias.\nWe create scenarios that emulate those issues using the MNIST data set and\ndemonstrate empirical results of our new loss function. Finally, we sketch a\nproof of this function based on Maximum Likelihood Estimation and discuss\nfuture directions.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 08:54:42 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Ho", "Yaoshiang", ""], ["Wookey", "Samuel", ""]]}, {"id": "2001.00571", "submitter": "Tamirlan Seidakhmetov", "authors": "Tamirlan Seidakhmetov", "title": "Question Type Classification Methods Comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a comparative study of state-of-the-art approaches for\nquestion classification task: Logistic Regression, Convolutional Neural\nNetworks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent\nNeural Networks (QRNN). All models use pre-trained GLoVe word embeddings and\ntrained on human-labeled data. The best accuracy is achieved using CNN model\nwith five convolutional layers and various kernel sizes stacked in parallel,\nfollowed by one fully connected layer. The model reached 90.7% accuracy on TREC\n10 test set. All the model architectures in this paper were developed from\nscratch on PyTorch, in few cases based on reliable open-source implementation.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 00:16:46 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Seidakhmetov", "Tamirlan", ""]]}, {"id": "2001.00572", "submitter": "Guoxiu He", "authors": "Guoxiu He, Zhe Gao, Zhuoren Jiang, Yangyang Kang, Changlong Sun,\n  Xiaozhong Liu, Wei Lu", "title": "Read Beyond the Lines: Understanding the Implied Textual Meaning via a\n  Skim and Intensive Reading Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nonliteral interpretation of a text is hard to be understood by machine\nmodels due to its high context-sensitivity and heavy usage of figurative\nlanguage. In this study, inspired by human reading comprehension, we propose a\nnovel, simple, and effective deep neural framework, called Skim and Intensive\nReading Model (SIRM), for figuring out implied textual meaning. The proposed\nSIRM consists of two main components, namely the skim reading component and\nintensive reading component. N-gram features are quickly extracted from the\nskim reading component, which is a combination of several convolutional neural\nnetworks, as skim (entire) information. An intensive reading component enables\na hierarchical investigation for both local (sentence) and global (paragraph)\nrepresentation, which encapsulates the current embedding and the contextual\ninformation with a dense connection. More specifically, the contextual\ninformation includes the near-neighbor information and the skim information\nmentioned above. Finally, besides the normal training loss function, we employ\nan adversarial loss function as a penalty over the skim reading component to\neliminate noisy information arisen from special figurative words in the\ntraining data. To verify the effectiveness, robustness, and efficiency of the\nproposed architecture, we conduct extensive comparative experiments on several\nsarcasm benchmarks and an industrial spam dataset with metaphors. Experimental\nresults indicate that (1) the proposed model, which benefits from context\nmodeling and consideration of figurative language, outperforms existing\nstate-of-the-art solutions, with comparable parameter scale and training speed;\n(2) the SIRM yields superior robustness in terms of parameter size sensitivity;\n(3) compared with ablation and addition variants of the SIRM, the final\nframework is efficient enough.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 03:43:35 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 14:27:21 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["He", "Guoxiu", ""], ["Gao", "Zhe", ""], ["Jiang", "Zhuoren", ""], ["Kang", "Yangyang", ""], ["Sun", "Changlong", ""], ["Liu", "Xiaozhong", ""], ["Lu", "Wei", ""]]}, {"id": "2001.00593", "submitter": "Hendrik Poulsen Nautrup", "authors": "Hendrik Poulsen Nautrup, Tony Metger, Raban Iten, Sofiene Jerbi, Lea\n  M. Trenkwalder, Henrik Wilming, Hans J. Briegel, Renato Renner", "title": "Operationally meaningful representations of physical systems in neural\n  networks", "comments": "24 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To make progress in science, we often build abstract representations of\nphysical systems that meaningfully encode information about the systems. The\nrepresentations learnt by most current machine learning techniques reflect\nstatistical structure present in the training data; however, these methods do\nnot allow us to specify explicit and operationally meaningful requirements on\nthe representation. Here, we present a neural network architecture based on the\nnotion that agents dealing with different aspects of a physical system should\nbe able to communicate relevant information as efficiently as possible to one\nanother. This produces representations that separate different parameters which\nare useful for making statements about the physical system in different\nexperimental settings. We present examples involving both classical and quantum\nphysics. For instance, our architecture finds a compact representation of an\narbitrary two-qubit system that separates local parameters from parameters\ndescribing quantum correlations. We further show that this method can be\ncombined with reinforcement learning to enable representation learning within\ninteractive scenarios where agents need to explore experimental settings to\nidentify relevant variables.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 19:01:31 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Nautrup", "Hendrik Poulsen", ""], ["Metger", "Tony", ""], ["Iten", "Raban", ""], ["Jerbi", "Sofiene", ""], ["Trenkwalder", "Lea M.", ""], ["Wilming", "Henrik", ""], ["Briegel", "Hans J.", ""], ["Renner", "Renato", ""]]}, {"id": "2001.00626", "submitter": "Arun Verma Mr.", "authors": "Arun Verma, Manjesh K. Hanawal, and Nandyala Hemachandra", "title": "Unsupervised Online Feature Selection for Cost-Sensitive Medical\n  Diagnosis", "comments": "Accepted to NetHealth Workshop at COMSNETS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In medical diagnosis, physicians predict the state of a patient by checking\nmeasurements (features) obtained from a sequence of tests, e.g., blood test,\nurine test, followed by invasive tests. As tests are often costly, one would\nlike to obtain only those features (tests) that can establish the presence or\nabsence of the state conclusively. Another aspect of medical diagnosis is that\nwe are often faced with unsupervised prediction tasks as the true state of the\npatients may not be known. Motivated by such medical diagnosis problems, we\nconsider a {\\it Cost-Sensitive Medical Diagnosis} (CSMD) problem, where the\ntrue state of patients is unknown. We formulate the CSMD problem as a feature\nselection problem where each test gives a feature that can be used in a\nprediction model. Our objective is to learn strategies for selecting the\nfeatures that give the best trade-off between accuracy and costs. We exploit\nthe `Weak Dominance' property of problem to develop online algorithms that\nidentify a set of features which provides an `optimal' trade-off between cost\nand accuracy of prediction without requiring to know the true state of the\nmedical condition. Our empirical results validate the performance of our\nalgorithms on problem instances generated from real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 14:15:29 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Verma", "Arun", ""], ["Hanawal", "Manjesh K.", ""], ["Hemachandra", "Nandyala", ""]]}, {"id": "2001.00627", "submitter": "Xiao-Yun Zhou", "authors": "Xiao-Yun Zhou, Yao Guo, Mali Shen, Guang-Zhong Yang", "title": "Artificial Intelligence in Surgery", "comments": "Frontiers of Medicine 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) is gradually changing the practice of surgery\nwith the advanced technological development of imaging, navigation and robotic\nintervention. In this article, the recent successful and influential\napplications of AI in surgery are reviewed from pre-operative planning and\nintra-operative guidance to the integration of surgical robots. We end with\nsummarizing the current state, emerging trends and major challenges in the\nfuture development of AI in surgery.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 12:39:04 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Zhou", "Xiao-Yun", ""], ["Guo", "Yao", ""], ["Shen", "Mali", ""], ["Yang", "Guang-Zhong", ""]]}, {"id": "2001.00632", "submitter": "Qian Hu", "authors": "Qian Hu, Huzefa Rangwala", "title": "Academic Performance Estimation with Attention-based Graph Convolutional\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Student's academic performance prediction empowers educational technologies\nincluding academic trajectory and degree planning, course recommender systems,\nearly warning and advising systems. Given a student's past data (such as grades\nin prior courses), the task of student's performance prediction is to predict a\nstudent's grades in future courses. Academic programs are structured in a way\nthat prior courses lay the foundation for future courses. The knowledge\nrequired by courses is obtained by taking multiple prior courses, which\nexhibits complex relationships modeled by graph structures. Traditional methods\nfor student's performance prediction usually neglect the underlying\nrelationships between multiple courses; and how students acquire knowledge\nacross them. In addition, traditional methods do not provide interpretation for\npredictions needed for decision making. In this work, we propose a novel\nattention-based graph convolutional networks model for student's performance\nprediction. We conduct extensive experiments on a real-world dataset obtained\nfrom a large public university. The experimental results show that our proposed\nmodel outperforms state-of-the-art approaches in terms of grade prediction. The\nproposed model also shows strong accuracy in identifying students who are\nat-risk of failing or dropping out so that timely intervention and feedback can\nbe provided to the student.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 23:11:27 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Hu", "Qian", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "2001.00682", "submitter": "Roozbeh Yousefzadeh", "authors": "Roozbeh Yousefzadeh and Dianne P. O'Leary", "title": "Auditing and Debugging Deep Learning Models via Decision Boundaries:\n  Individual-level and Group-level Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have been criticized for their lack of easy\ninterpretation, which undermines confidence in their use for important\napplications. Nevertheless, they are consistently utilized in many\napplications, consequential to humans' lives, mostly because of their better\nperformance. Therefore, there is a great need for computational methods that\ncan explain, audit, and debug such models. Here, we use flip points to\naccomplish these goals for deep learning models with continuous output scores\n(e.g., computed by softmax), used in social applications. A flip point is any\npoint that lies on the boundary between two output classes: e.g. for a model\nwith a binary yes/no output, a flip point is any input that generates equal\nscores for \"yes\" and \"no\". The flip point closest to a given input is of\nparticular importance because it reveals the least changes in the input that\nwould change a model's classification, and we show that it is the solution to a\nwell-posed optimization problem. Flip points also enable us to systematically\nstudy the decision boundaries of a deep learning classifier. The resulting\ninsight into the decision boundaries of a deep model can clearly explain the\nmodel's output on the individual-level, via an explanation report that is\nunderstandable by non-experts. We also develop a procedure to understand and\naudit model behavior towards groups of people. Flip points can also be used to\nalter the decision boundaries in order to improve undesirable behaviors. We\ndemonstrate our methods by investigating several models trained on standard\ndatasets used in social applications of machine learning. We also identify the\nfeatures that are most responsible for particular classifications and\nmisclassifications.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 01:45:36 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Yousefzadeh", "Roozbeh", ""], ["O'Leary", "Dianne P.", ""]]}, {"id": "2001.00733", "submitter": "Hao Fu", "authors": "Danning Zheng, Ruihua Song, Tianran Hu, Hao Fu, Jin Zhou", "title": "\"Love is as Complex as Math\": Metaphor Generation System for Social\n  Chatbot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the wide adoption of intelligent chatbot in human daily life, user demands\nfor such systems evolve from basic task-solving conversations to more casual\nand friend-like communication. To meet the user needs and build emotional bond\nwith users, it is essential for social chatbots to incorporate more human-like\nand advanced linguistic features. In this paper, we investigate the usage of a\ncommonly used rhetorical device by human -- metaphor for social chatbot. Our\nwork first designs a metaphor generation framework, which generates topic-aware\nand novel figurative sentences. By embedding the framework into a chatbot\nsystem, we then enables the chatbot to communicate with users using figurative\nlanguage. Human annotators validate the novelty and properness of the generated\nmetaphors. More importantly, we evaluate the effects of employing metaphors in\nhuman-chatbot conversations. Experiments indicate that our system effectively\narouses user interests in communicating with our chatbot, resulting in\nsignificantly longer human-chatbot conversations.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 05:56:13 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Zheng", "Danning", ""], ["Song", "Ruihua", ""], ["Hu", "Tianran", ""], ["Fu", "Hao", ""], ["Zhou", "Jin", ""]]}, {"id": "2001.00742", "submitter": "George Monta\\~nez", "authors": "Tyler Sam, Jake Williams, Abel Tadesse, Huey Sun, George Montanez", "title": "Decomposable Probability-of-Success Metrics in Algorithmic Search", "comments": "Accepted to 12th International Conference on Agents and Artificial\n  Intelligence (ICAART 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies have used a specific success metric within an algorithmic\nsearch framework to prove machine learning impossibility results. However, this\nspecific success metric prevents us from applying these results on other forms\nof machine learning, e.g. transfer learning. We define decomposable metrics as\na category of success metrics for search problems which can be expressed as a\nlinear operation on a probability distribution to solve this issue. Using an\narbitrary decomposable metric to measure the success of a search, we\ndemonstrate theorems which bound success in various ways, generalizing several\nexisting results in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 06:26:57 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Sam", "Tyler", ""], ["Williams", "Jake", ""], ["Tadesse", "Abel", ""], ["Sun", "Huey", ""], ["Montanez", "George", ""]]}, {"id": "2001.00786", "submitter": "Alessandro Paolo Capasso", "authors": "Alessandro Paolo Capasso, Giulio Bacchiani, Daniele Molinari", "title": "Intelligent Roundabout Insertion using Deep Reinforcement Learning", "comments": null, "journal-ref": "Proceedings of ICAART 2020, ISBN: 978-989-758-395-7", "doi": "10.5220/0008915003780385", "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important topic in the autonomous driving research is the development of\nmaneuver planning systems. Vehicles have to interact and negotiate with each\nother so that optimal choices, in terms of time and safety, are taken. For this\npurpose, we present a maneuver planning module able to negotiate the entering\nin busy roundabouts. The proposed module is based on a neural network trained\nto predict when and how entering the roundabout throughout the whole duration\nof the maneuver. Our model is trained with a novel implementation of A3C, which\nwe will call Delayed A3C (D-A3C), in a synthetic environment where vehicles\nmove in a realistic manner with interaction capabilities. In addition, the\nsystem is trained such that agents feature a unique tunable behavior, emulating\nreal world scenarios where drivers have their own driving styles. Similarly,\nthe maneuver can be performed using different aggressiveness levels, which is\nparticularly useful to manage busy scenarios where conservative rule-based\npolicies would result in undefined waits.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 11:16:41 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 11:24:33 GMT"}, {"version": "v3", "created": "Wed, 28 Apr 2021 09:22:53 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Capasso", "Alessandro Paolo", ""], ["Bacchiani", "Giulio", ""], ["Molinari", "Daniele", ""]]}, {"id": "2001.00804", "submitter": "Simone Agostinelli", "authors": "Simone Agostinelli, Andrea Marrella and Massimo Mecella", "title": "Towards Intelligent Robotic Process Automation for BPMers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic Process Automation (RPA) is a fast-emerging automation technology\nthat sits between the fields of Business Process Management (BPM) and\nArtificial Intelligence (AI), and allows organizations to automate high volume\nroutines. RPA tools are able to capture the execution of such routines\npreviously performed by a human users on the interface of a computer system,\nand then emulate their enactment in place of the user by means of a software\nrobot. Nowadays, in the BPM domain, only simple, predictable business processes\ninvolving routine work can be automated by RPA tools in situations where there\nis no room for interpretation, while more sophisticated work is still left to\nhuman experts. In this paper, starting from an in-depth experimentation of the\nRPA tools available on the market, we provide a classification framework to\ncategorize them on the basis of some key dimensions. Then, based on this\nanalysis, we derive four research challenges and discuss prospective approaches\nnecessary to inject intelligence into current RPA technology, in order to\nachieve more widespread adoption of RPA in the BPM domain.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 12:37:52 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Agostinelli", "Simone", ""], ["Marrella", "Andrea", ""], ["Mecella", "Massimo", ""]]}, {"id": "2001.00805", "submitter": "Brendan O'Donoghue", "authors": "Brendan O'Donoghue, Ian Osband, Catalin Ionescu", "title": "Making Sense of Reinforcement Learning and Probabilistic Inference", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) combines a control problem with statistical\nestimation: The system dynamics are not known to the agent, but can be learned\nthrough experience. A recent line of research casts `RL as inference' and\nsuggests a particular framework to generalize the RL problem as probabilistic\ninference. Our paper surfaces a key shortcoming in that approach, and clarifies\nthe sense in which RL can be coherently cast as an inference problem. In\nparticular, an RL agent must consider the effects of its actions upon future\nrewards and observations: The exploration-exploitation tradeoff. In all but the\nmost simple settings, the resulting inference is computationally intractable so\nthat practical RL algorithms must resort to approximation. We demonstrate that\nthe popular `RL as inference' approximation can perform poorly in even very\nbasic problems. However, we show that with a small modification the framework\ndoes yield algorithms that can provably perform well, and we show that the\nresulting algorithm is equivalent to the recently proposed K-learning, which we\nfurther connect with Thompson sampling.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 12:50:42 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 12:32:36 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 18:12:05 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["O'Donoghue", "Brendan", ""], ["Osband", "Ian", ""], ["Ionescu", "Catalin", ""]]}, {"id": "2001.00818", "submitter": "Soma Dhavala", "authors": "Shakkeel Ahmed, Ravi S. Mula, Soma S. Dhavala", "title": "A Framework for Democratizing AI", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning and Artificial Intelligence are considered an integral part\nof the Fourth Industrial Revolution. Their impact, and far-reaching\nconsequences, while acknowledged, are yet to be comprehended. These\ntechnologies are very specialized, and few organizations and select highly\ntrained professionals have the wherewithal, in terms of money, manpower, and\nmight, to chart the future. However, concentration of power can lead to\nmarginalization, causing severe inequalities. Regulatory agencies and\ngovernments across the globe are creating national policies, and laws around\nthese technologies to protect the rights of the digital citizens, as well as to\nempower them. Even private, not-for-profit organizations are also contributing\nto democratizing the technologies by making them \\emph{accessible} and\n\\emph{affordable}. However, accessibility and affordability are all but a few\nof the facets of democratizing the field. Others include, but not limited to,\n\\emph{portability}, \\emph{explainability}, \\emph{credibility}, \\emph{fairness},\namong others. As one can imagine, democratizing AI is a multi-faceted problem,\nand it requires advancements in science, technology and policy. At\n\\texttt{mlsquare}, we are developing scientific tools in this space.\nSpecifically, we introduce an opinionated, extensible, \\texttt{Python}\nframework that provides a single point of interface to a variety of solutions\nin each of the categories mentioned above. We present the design details, APIs\nof the framework, reference implementations, road map for development, and\nguidelines for contributions.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 17:30:14 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Ahmed", "Shakkeel", ""], ["Mula", "Ravi S.", ""], ["Dhavala", "Soma S.", ""]]}, {"id": "2001.00819", "submitter": "Petr Savick\\'y", "authors": "Petr Ku\\v{c}era, Petr Savick\\'y", "title": "Bounds on the size of PC and URC formulas", "comments": "24 pages, minor corrections and improvements of the text", "journal-ref": "Journal of Artificial Intelligence Research 69 (2020) 1395-1420", "doi": "10.1613/jair.1.12006", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate CNF formulas, for which the unit propagation is\nstrong enough to derive a contradiction if the formula together with a partial\nassignment of the variables is unsatisfiable (unit refutation complete or URC\nformulas) or additionally to derive all implied literals if the formula is\nsatisfiable (propagation complete or PC formulas). If a formula represents a\nfunction using existentially quantified auxiliary variables, it is called an\nencoding of the function. We prove several results on the sizes of PC and URC\nformulas and encodings. One of them are separations between the sizes of\nformulas of different types. Namely, we prove an exponential separation between\nthe size of URC formulas and PC formulas and between the size of PC encodings\nusing auxiliary variables and URC formulas. Besides of this, we prove that the\nsizes of any two irredundant PC formulas for the same function differ at most\nby a factor polynomial in the number of the variables and present an example of\na function demonstrating that a similar statement is not true for URC formulas.\nOne of the separations above implies that a q-Horn formula may require an\nexponential number of additional clauses to become a URC formula. On the other\nhand, for every q-Horn formula, we present a polynomial size URC encoding of\nthe same function using auxiliary variables. This encoding is not q-Horn in\ngeneral.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 13:15:32 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 09:52:20 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 13:40:47 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Ku\u010dera", "Petr", ""], ["Savick\u00fd", "Petr", ""]]}, {"id": "2001.00846", "submitter": "Diego Antognini", "authors": "Nikola Milojkovic, Diego Antognini, Giancarlo Bergamin, Boi Faltings\n  and Claudiu Musat", "title": "Multi-Gradient Descent for Multi-Objective Recommender Systems", "comments": "9 pages, 4 figures, Accepted at AAAI 2020 - Workshop on Interactive\n  and Conversational Recommendation Systems (WICRS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems need to mirror the complexity of the environment they are\napplied in. The more we know about what might benefit the user, the more\nobjectives the recommender system has. In addition there may be multiple\nstakeholders - sellers, buyers, shareholders - in addition to legal and ethical\nconstraints. Simultaneously optimizing for a multitude of objectives,\ncorrelated and not correlated, having the same scale or not, has proven\ndifficult so far.\n  We introduce a stochastic multi-gradient descent approach to recommender\nsystems (MGDRec) to solve this problem. We show that this exceeds\nstate-of-the-art methods in traditional objective mixtures, like revenue and\nrecall. Not only that, but through gradient normalization we can combine\nfundamentally different objectives, having diverse scales, into a single\ncoherent framework. We show that uncorrelated objectives, like the proportion\nof quality products, can be improved alongside accuracy. Through the use of\nstochasticity, we avoid the pitfalls of calculating full gradients and provide\na clear setting for its applicability.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 19:56:08 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 08:04:23 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 07:35:21 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Milojkovic", "Nikola", ""], ["Antognini", "Diego", ""], ["Bergamin", "Giancarlo", ""], ["Faltings", "Boi", ""], ["Musat", "Claudiu", ""]]}, {"id": "2001.00991", "submitter": "Marc Killpack", "authors": "Erich Mielke, Eric Townsend, David Wingate, and Marc D. Killpack", "title": "Human-robot co-manipulation of extended objects: Data-driven models and\n  control from analysis of human-human dyads", "comments": "Paper has been in submission to IJRR since November 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human teams are able to easily perform collaborative manipulation tasks.\nHowever, for a robot and human to simultaneously manipulate an extended object\nis a difficult task using existing methods from the literature. Our approach in\nthis paper is to use data from human-human dyad experiments to determine motion\nintent which we use for a physical human-robot co-manipulation task. We first\npresent and analyze data from human-human dyads performing co-manipulation\ntasks. We show that our human-human dyad data has interesting trends including\nthat interaction forces are non-negligible compared to the force required to\naccelerate an object and that the beginning of a lateral movement is\ncharacterized by distinct torque triggers from the leader of the dyad. We also\nexamine different metrics to quantify performance of different dyads. We also\ndevelop a deep neural network based on motion data from human-human trials to\npredict human intent based on past motion. We then show how force and motion\ndata can be used as a basis for robot control in a human-robot dyad. Finally,\nwe compare the performance of two controllers for human-robot co-manipulation\nto human-human dyad performance.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 21:23:12 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Mielke", "Erich", ""], ["Townsend", "Eric", ""], ["Wingate", "David", ""], ["Killpack", "Marc D.", ""]]}, {"id": "2001.01004", "submitter": "Ali Ayub", "authors": "Ali Ayub and Alan R. Wagner", "title": "Teach Me What You Want to Play: Learning Variants of Connect Four\n  through Human-Robot Interaction", "comments": "The final authenticated publication is available online at\n  https://doi.org/10.1007/978-3-030-62056-1_42", "journal-ref": "International Conference on Social Robotics (ICSR), 2020", "doi": "10.1007/978-3-030-62056-1_42", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper investigates the use of game theoretic representations to\nrepresent and learn how to play interactive games such as Connect Four. We\ncombine aspects of learning by demonstration, active learning, and game theory\nallowing a robot to leverage its developing representation of the game to\nconduct question/answer sessions with a person, thus filling in gaps in its\nknowledge. The paper demonstrates a method for teaching a robot the win\nconditions of the game Connect Four and its variants using a single\ndemonstration and a few trial examples with a question and answer session led\nby the robot. Our results show that the robot can learn arbitrary win\nconditions for the game with little prior knowledge of the win conditions and\nthen play the game with a human utilizing the learned win conditions. Our\nexperiments also show that some questions are more important for learning the\ngame's win conditions. We believe that this method could be broadly applied to\na variety of interactive learning scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 22:28:24 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 05:43:32 GMT"}, {"version": "v3", "created": "Sun, 23 Aug 2020 02:20:53 GMT"}, {"version": "v4", "created": "Wed, 13 Jan 2021 06:51:10 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Ayub", "Ali", ""], ["Wagner", "Alan R.", ""]]}, {"id": "2001.01007", "submitter": "Volodymyr Leno", "authors": "Volodymyr Leno, Marlon Dumas, Marcello La Rosa, Fabrizio Maria Maggi,\n  Artem Polyvyanyy", "title": "Automated Discovery of Data Transformations for Robotic Process\n  Automation", "comments": "8 pages, 5 figures. To be published in proceedings of AAAI-20\n  workshop on Intelligent Process Automation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic Process Automation (RPA) is a technology for automating repetitive\nroutines consisting of sequences of user interactions with one or more\napplications. In order to fully exploit the opportunities opened by RPA,\ncompanies need to discover which specific routines may be automated, and how.\nIn this setting, this paper addresses the problem of analyzing User Interaction\n(UI) logs in order to discover routines where a user transfers data from one\nspreadsheet or (Web) form to another. The paper maps this problem to that of\ndiscovering data transformations by example - a problem for which several\ntechniques are available. The paper shows that a naive application of a\nstate-of-the-art technique for data transformation discovery is computationally\ninefficient. Accordingly, the paper proposes two optimizations that take\nadvantage of the information in the UI log and the fact that data transfers\nacross applications typically involve copying alphabetic and numeric tokens\nseparately. The proposed approach and its optimizations are evaluated using UI\nlogs that replicate a real-life repetitive data transfer routine.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 23:15:45 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Leno", "Volodymyr", ""], ["Dumas", "Marlon", ""], ["La Rosa", "Marcello", ""], ["Maggi", "Fabrizio Maria", ""], ["Polyvyanyy", "Artem", ""]]}, {"id": "2001.01089", "submitter": "Michael Morak", "authors": "Manuel Bichler, Michael Morak, and Stefan Woltran", "title": "selp: A Single-Shot Epistemic Logic Program Solver", "comments": "19 pages, 2 figures, under consideration in Theory and Practice of\n  Logic Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Epistemic Logic Programs (ELPs) are an extension of Answer Set Programming\n(ASP) with epistemic operators that allow for a form of meta-reasoning, that\nis, reasoning over multiple possible worlds. Existing ELP solving approaches\ngenerally rely on making multiple calls to an ASP solver in order to evaluate\nthe ELP. However, in this paper, we show that there also exists a direct\ntranslation from ELPs into non-ground ASP with bounded arity. The resulting ASP\nprogram can thus be solved in a single shot. We then implement this encoding\nmethod, using recently proposed techniques to handle large, non-ground ASP\nrules, into the prototype ELP solving system \"selp\", which we present in this\npaper. This solver exhibits competitive performance on a set of ELP benchmark\ninstances. Under consideration in Theory and Practice of Logic Programming\n(TPLP).\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 15:36:31 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Bichler", "Manuel", ""], ["Morak", "Michael", ""], ["Woltran", "Stefan", ""]]}, {"id": "2001.01115", "submitter": "Prasanna Raj Noel Dabre", "authors": "Raj Dabre, Chenhui Chu, Anoop Kunchukuttan", "title": "A Comprehensive Survey of Multilingual Neural Machine Translation", "comments": "This is an extended version of our survey paper on multilingual NMT.\n  The previous version [arXiv:1905.05395] is rather condensed and is useful for\n  speed-reading whereas this version is more beginner friendly. Under review at\n  the computing surveys journal. We have intentionally decided to maintain both\n  short and long versions of our survey paper for different reader groups", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a survey on multilingual neural machine translation (MNMT), which\nhas gained a lot of traction in the recent years. MNMT has been useful in\nimproving translation quality as a result of translation knowledge transfer\n(transfer learning). MNMT is more promising and interesting than its\nstatistical machine translation counterpart because end-to-end modeling and\ndistributed representations open new avenues for research on machine\ntranslation. Many approaches have been proposed in order to exploit\nmultilingual parallel corpora for improving translation quality. However, the\nlack of a comprehensive survey makes it difficult to determine which approaches\nare promising and hence deserve further exploration. In this paper, we present\nan in-depth survey of existing literature on MNMT. We first categorize various\napproaches based on their central use-case and then further categorize them\nbased on resource scenarios, underlying modeling principles, core-issues and\nchallenges. Wherever possible we address the strengths and weaknesses of\nseveral techniques by comparing them with each other. We also discuss the\nfuture directions that MNMT research might take. This paper is aimed towards\nboth, beginners and experts in NMT. We hope this paper will serve as a starting\npoint as well as a source of new ideas for researchers and engineers interested\nin MNMT.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 19:38:00 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 16:54:33 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Dabre", "Raj", ""], ["Chu", "Chenhui", ""], ["Kunchukuttan", "Anoop", ""]]}, {"id": "2001.01126", "submitter": "Alexander Ruch", "authors": "Alexander Ruch", "title": "Can x2vec Save Lives? Integrating Graph and Language Embeddings for\n  Automatic Mental Health Classification", "comments": "25 pages (23 body, 2 supplemental material), 12 figures (10 body, 2\n  supplemental material), 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph and language embedding models are becoming commonplace in large scale\nanalyses given their ability to represent complex sparse data densely in\nlow-dimensional space. Integrating these models' complementary relational and\ncommunicative data may be especially helpful if predicting rare events or\nclassifying members of hidden populations - tasks requiring huge and sparse\ndatasets for generalizable analyses. For example, due to social stigma and\ncomorbidities, mental health support groups often form in amorphous online\ngroups. Predicting suicidality among individuals in these settings using\nstandard network analyses is prohibitive due to resource limits (e.g., memory),\nand adding auxiliary data like text to such models exacerbates complexity- and\nsparsity-related issues. Here, I show how merging graph and language embedding\nmodels (metapath2vec and doc2vec) avoids these limits and extracts unsupervised\nclustering data without domain expertise or feature engineering. Graph and\nlanguage distances to a suicide support group have little correlation (\\r{ho} <\n0.23), implying the two models are not embedding redundant information. When\nused separately to predict suicidality among individuals, graph and language\ndata generate relatively accurate results (69% and 76%, respectively); however,\nwhen integrated, both data produce highly accurate predictions (90%, with 10%\nfalse-positives and 12% false-negatives). Visualizing graph embeddings\nannotated with predictions of potentially suicidal individuals shows the\nintegrated model could classify such individuals even if they are positioned\nfar from the support group. These results extend research on the importance of\nsimultaneously analyzing behavior and language in massive networks and efforts\nto integrate embedding models for different kinds of data when predicting and\nclassifying, particularly when they involve rare events.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 20:56:21 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Ruch", "Alexander", ""]]}, {"id": "2001.01230", "submitter": "Juho Lauri", "authors": "Juho Lauri, Sourav Dutta, Marco Grassia, Deepak Ajwani", "title": "Learning fine-grained search space pruning and heuristics for\n  combinatorial optimization", "comments": "Integrates three works which appeared at AAAI'19 [arXiv:1902.08455],\n  the DSO workshop at IJCAI'19 [arXiv:1910.00517] and CIKM'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial optimization problems arise in a wide range of applications\nfrom diverse domains. Many of these problems are NP-hard and designing\nefficient heuristics for them requires considerable time and experimentation.\nOn the other hand, the number of optimization problems in the industry\ncontinues to grow. In recent years, machine learning techniques have been\nexplored to address this gap. We propose a framework for leveraging machine\nlearning techniques to scale-up exact combinatorial optimization algorithms. In\ncontrast to the existing approaches based on deep-learning, reinforcement\nlearning and restricted Boltzmann machines that attempt to directly learn the\noutput of the optimization problem from its input (with limited success), our\nframework learns the relatively simpler task of pruning the elements in order\nto reduce the size of the problem instances. In addition, our framework uses\nonly interpretable learning models based on intuitive features and thus the\nlearning process provides deeper insights into the optimization problem and the\ninstance class, that can be used for designing better heuristics. For the\nclassical maximum clique enumeration problem, we show that our framework can\nprune a large fraction of the input graph (around 99 % of nodes in case of\nsparse graphs) and still detect almost all of the maximum cliques. This results\nin several fold speedups of state-of-the-art algorithms. Furthermore, the model\nused in our framework highlights that the chi-squared value of neighborhood\ndegree has a statistically significant correlation with the presence of a node\nin a maximum clique, particularly in dense graphs which constitute a\nsignificant challenge for modern solvers. We leverage this insight to design a\nnovel heuristic for this problem outperforming the state-of-the-art. Our\nheuristic is also of independent interest for maximum clique detection and\nenumeration.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 13:10:39 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Lauri", "Juho", ""], ["Dutta", "Sourav", ""], ["Grassia", "Marco", ""], ["Ajwani", "Deepak", ""]]}, {"id": "2001.01296", "submitter": "Pedro Ramaciotti Morales", "authors": "Pedro Ramaciotti Morales, Robin Lamarche-Perrin, Raphael\n  Fournier-S'niehotta, Remy Poulain, Lionel Tabourier, and Fabien Tarissan", "title": "Measuring Diversity in Heterogeneous Information Networks", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.IR cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Diversity is a concept relevant to numerous domains of research varying from\necology, to information theory, and to economics, to cite a few. It is a notion\nthat is steadily gaining attention in the information retrieval, network\nanalysis, and artificial neural networks communities. While the use of\ndiversity measures in network-structured data counts a growing number of\napplications, no clear and comprehensive description is available for the\ndifferent ways in which diversities can be measured. In this article, we\ndevelop a formal framework for the application of a large family of diversity\nmeasures to heterogeneous information networks (HINs), a flexible, widely-used\nnetwork data formalism. This extends the application of diversity measures,\nfrom systems of classifications and apportionments, to more complex relations\nthat can be better modeled by networks. In doing so, we not only provide an\neffective organization of multiple practices from different domains, but also\nunearth new observables in systems modeled by heterogeneous information\nnetworks. We illustrate the pertinence of our approach by developing different\napplications related to various domains concerned by both diversity and\nnetworks. In particular, we illustrate the usefulness of these new proposed\nobservables in the domains of recommender systems and social media studies,\namong other fields.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 19:21:50 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 18:21:04 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 12:23:01 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Morales", "Pedro Ramaciotti", ""], ["Lamarche-Perrin", "Robin", ""], ["Fournier-S'niehotta", "Raphael", ""], ["Poulain", "Remy", ""], ["Tabourier", "Lionel", ""], ["Tarissan", "Fabien", ""]]}, {"id": "2001.01326", "submitter": "Jakub Kowalski", "authors": "Jakub Kowalski, Rados{\\l}aw Miernik", "title": "Evolutionary Approach to Collectible Card Game Arena Deckbuilding using\n  Active Genes", "comments": "Accepted to IEEE Congress on Evolutionary Computation 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we evolve a card-choice strategy for the arena mode of Legends\nof Code and Magic, a programming game inspired by popular collectible card\ngames like Hearthstone or TES: Legends. In the arena game mode, before each\nmatch, a player has to construct his deck choosing cards one by one from the\npreviously unknown options. Such a scenario is difficult from the optimization\npoint of view, as not only the fitness function is non-deterministic, but its\nvalue, even for a given problem instance, is impossible to be calculated\ndirectly and can only be estimated with simulation-based approaches. We propose\na variant of the evolutionary algorithm that uses a concept of an active gene\nto reduce the range of the operators only to generation-specific subsequences\nof the genotype. Thus, we batched learning process and constrained evolutionary\nupdates only to the cards relevant for the particular draft, without forgetting\nthe knowledge from the previous tests. We developed and tested various\nimplementations of this idea, investigating their performance by taking into\naccount the computational cost of each variant. Performed experiments show that\nsome of the introduced active-genes algorithms tend to learn faster and produce\nstatistically better draft policies than the compared methods.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 22:46:08 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 12:27:51 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Kowalski", "Jakub", ""], ["Miernik", "Rados\u0142aw", ""]]}, {"id": "2001.01391", "submitter": "Said Varlioglu", "authors": "Murat Ozer, Nelly Elsayed, Said Varlioglu, Chengcheng Li", "title": "A Rule-Based Model for Victim Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed a novel automated model, called Vulnerability\nIndex for Population at Risk (VIPAR) scores, to identify rare populations for\ntheir future shooting victimizations. Likewise, the focused deterrence approach\nidentifies vulnerable individuals and offers certain types of treatments (e.g.,\noutreach services) to prevent violence in communities. The proposed rule-based\nengine model is the first AI-based model for victim prediction. This paper aims\nto compare the list of focused deterrence strategy with the VIPAR score list\nregarding their predictive power for the future shooting victimizations.\nDrawing on the criminological studies, the model uses age, past criminal\nhistory, and peer influence as the main predictors of future violence. Social\nnetwork analysis is employed to measure the influence of peers on the outcome\nvariable. The model also uses logistic regression analysis to verify the\nvariable selections. Our empirical results show that VIPAR scores predict 25.8%\nof future shooting victims and 32.2% of future shooting suspects, whereas\nfocused deterrence list predicts 13% of future shooting victims and 9.4% of\nfuture shooting suspects. The model outperforms the intelligence list of\nfocused deterrence policies in predicting the future fatal and non-fatal\nshootings. Furthermore, we discuss the concerns about the presumption of\ninnocence right.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 04:29:59 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 20:10:21 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Ozer", "Murat", ""], ["Elsayed", "Nelly", ""], ["Varlioglu", "Said", ""], ["Li", "Chengcheng", ""]]}, {"id": "2001.01416", "submitter": "Thomas Weise", "authors": "Thomas Weise and Zhize Wu and Xinlu Li and Yan Chen", "title": "Frequency Fitness Assignment: Making Optimization Algorithms Invariant\n  under Bijective Transformations of the Objective Function Value", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under Frequency Fitness Assignment (FFA), the fitness corresponding to an\nobjective value is its encounter frequency in fitness assignment steps and is\nsubject to minimization. FFA renders optimization processes invariant under\nbijective transformations of the objective function value. On TwoMax, Jump, and\nTrap functions of dimension s, the classical (1+1)-EA with standard mutation at\nrate 1/s can have expected runtimes exponential in s. In our experiments, a\n(1+1)-FEA, the same algorithm but using FFA, exhibits mean runtimes that seem\nto scale as $s^2\\ln{s}$. Since Jump and Trap are bijective transformations of\nOneMax, it behaves identical on all three. On OneMax, LeadingOnes, and Plateau\nproblems, it seems to be slower than the (1+1)-EA by a factor linear in s. The\n(1+1)-FEA performs much better than the (1+1)-EA on W-Model and MaxSat\ninstances. We further verify the bijection invariance by applying the Md5\nchecksum computation as transformation to some of the above problems and yield\nthe same behaviors. Finally, we show that FFA can improve the performance of a\nmemetic algorithm for job shop scheduling.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 06:16:18 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 06:05:17 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 23:45:23 GMT"}, {"version": "v4", "created": "Thu, 1 Oct 2020 10:05:30 GMT"}, {"version": "v5", "created": "Thu, 15 Oct 2020 22:45:11 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Weise", "Thomas", ""], ["Wu", "Zhize", ""], ["Li", "Xinlu", ""], ["Chen", "Yan", ""]]}, {"id": "2001.01577", "submitter": "Francisco Garcia", "authors": "Francisco M. Garcia, Chris Nota, Philip S. Thomas", "title": "Learning Reusable Options for Multi-Task Reinforcement Learning", "comments": "15 pages, 7 figures, pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has become an increasingly active area of\nresearch in recent years. Although there are many algorithms that allow an\nagent to solve tasks efficiently, they often ignore the possibility that prior\nexperience related to the task at hand might be available. For many practical\napplications, it might be unfeasible for an agent to learn how to solve a task\nfrom scratch, given that it is generally a computationally expensive process;\nhowever, prior experience could be leveraged to make these problems tractable\nin practice. In this paper, we propose a framework for exploiting existing\nexperience by learning reusable options. We show that after an agent learns\npolicies for solving a small number of problems, we are able to use the\ntrajectories generated from those policies to learn reusable options that allow\nan agent to quickly learn how to solve novel and related problems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 13:49:31 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Garcia", "Francisco M.", ""], ["Nota", "Chris", ""], ["Thomas", "Philip S.", ""]]}, {"id": "2001.01588", "submitter": "Chantana Chantrapornchai", "authors": "Chantana Chantrapornchai, Aphisit Tunsakul", "title": "Information Extraction based on Named Entity for Tourism Corpus", "comments": "6 pages, 9 figures", "journal-ref": "16th International Joint Conference on Computer Science and\n  Software Engineering (JCSSE), 2019, pp. 187-192", "doi": "10.1109/JCSSE.2019.8864166", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Tourism information is scattered around nowadays. To search for the\ninformation, it is usually time consuming to browse through the results from\nsearch engine, select and view the details of each accommodation. In this\npaper, we present a methodology to extract particular information from full\ntext returned from the search engine to facilitate the users. Then, the users\ncan specifically look to the desired relevant information. The approach can be\nused for the same task in other domains. The main steps are 1) building\ntraining data and 2) building recognition model. First, the tourism data is\ngathered and the vocabularies are built. The raw corpus is used to train for\ncreating vocabulary embedding. Also, it is used for creating annotated data.\nThe process of creating named entity annotation is presented. Then, the\nrecognition model of a given entity type can be built. From the experiments,\ngiven hotel description, the model can extract the desired entity,i.e, name,\nlocation, facility. The extracted data can further be stored as a structured\ninformation, e.g., in the ontology format, for future querying and inference.\nThe model for automatic named entity identification, based on machine learning,\nyields the error ranging 8%-25%.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 17:16:28 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Chantrapornchai", "Chantana", ""], ["Tunsakul", "Aphisit", ""]]}, {"id": "2001.01592", "submitter": "Enmei Tu", "authors": "Enmei Tu, Guanghao Zhang, Shangbo Mao, Lily Rachmawati and Guang-Bin\n  Huang", "title": "Modeling Historical AIS Data For Vessel Path Prediction: A Comprehensive\n  Treatment", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prosperity of artificial intelligence has aroused intensive interests in\nintelligent/autonomous navigation, in which path prediction is a key\nfunctionality for decision supports, e.g. route planning, collision warning,\nand traffic regulation. For maritime intelligence, Automatic Identification\nSystem (AIS) plays an important role because it recently has been made\ncompulsory for large international commercial vessels and is able to provide\nnearly real-time information of the vessel. Therefore AIS data based vessel\npath prediction is a promising way in future maritime intelligence. However,\nreal-world AIS data collected online are just highly irregular trajectory\nsegments (AIS message sequences) from different types of vessels and\ngeographical regions, with possibly very low data quality. So even there are\nsome works studying how to build a path prediction model using historical AIS\ndata, but still, it is a very challenging problem. In this paper, we propose a\ncomprehensive framework to model massive historical AIS trajectory segments for\naccurate vessel path prediction. Experimental comparisons with existing popular\nmethods are made to validate the proposed approach and results show that our\napproach could outperform the baseline methods by a wide margin.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 09:16:40 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 02:20:32 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Tu", "Enmei", ""], ["Zhang", "Guanghao", ""], ["Mao", "Shangbo", ""], ["Rachmawati", "Lily", ""], ["Huang", "Guang-Bin", ""]]}, {"id": "2001.01620", "submitter": "Manuel Del Verme", "authors": "Manuel Del Verme, Bruno Castro da Silva, Gianluca Baldassarre", "title": "Optimal Options for Multi-Task Reinforcement Learning Under Time\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning can greatly benefit from the use of options as a way\nof encoding recurring behaviours and to foster exploration. An important open\nproblem is how can an agent autonomously learn useful options when solving\nparticular distributions of related tasks. We investigate some of the\nconditions that influence optimality of options, in settings where agents have\na limited time budget for learning each task and the task distribution might\ninvolve problems with different levels of similarity. We directly search for\noptimal option sets and show that the discovered options significantly differ\ndepending on factors such as the available learning time budget and that the\nfound options outperform popular option-generation heuristics.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 15:08:46 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Del Verme", "Manuel", ""], ["da Silva", "Bruno Castro", ""], ["Baldassarre", "Gianluca", ""]]}, {"id": "2001.01772", "submitter": "Thomas Unger", "authors": "Thomas A. Unger, Elia Bruni", "title": "Generalizing Emergent Communication", "comments": "Summary of a master thesis by Thomas A. Unger, supervised by Elia\n  Bruni at the University of Amsterdam from January to August 2019. 9 pages, 6\n  figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We converted the recently developed BabyAI grid world platform to a\nsender/receiver setup in order to test the hypothesis that established deep\nreinforcement learning techniques are sufficient to incentivize the emergence\nof a grounded discrete communication protocol between generalized agents. This\nis in contrast to previous experiments that employed straight-through\nestimation or specialized inductive biases. Our results show that these can\nindeed be avoided, by instead providing proper environmental incentives.\nMoreover, they show that a longer interval between communications incentivized\nmore abstract semantics. In some cases, the communicating agents adapted to new\nenvironments more quickly than a monolithic agent, showcasing the potential of\nemergent communication for transfer learning and generalization in general.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 20:48:42 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 18:49:57 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 23:40:39 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Unger", "Thomas A.", ""], ["Bruni", "Elia", ""]]}, {"id": "2001.01781", "submitter": "Kumar Sankar Ray", "authors": "Sandip Paul, Kumar Sankar Ray and Diganta Saha", "title": "Modeling Uncertainty and Imprecision in Nonmonotonic Reasoning using\n  Fuzzy Numbers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To deal with uncertainty in reasoning, interval-valued logic has been\ndeveloped. But uniform intervals cannot capture the difference in degrees of\nbelief for different values in the interval. To salvage the problem triangular\nand trapezoidal fuzzy numbers are used as the set of truth values along with\ntraditional intervals. Preorder-based truth and knowledge ordering are defined\nover the set of fuzzy numbers defined over $[0,1]$. Based on this enhanced set\nof epistemic states, an answer set framework is developed, with properly\ndefined logical connectives. This type of framework is efficient in knowledge\nrepresentation and reasoning with vague and uncertain information under\nnonmonotonic environment where rules may posses exceptions.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 07:58:33 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Paul", "Sandip", ""], ["Ray", "Kumar Sankar", ""], ["Saha", "Diganta", ""]]}, {"id": "2001.01818", "submitter": "Zheyuan Ryan Shi", "authors": "Zheyuan Ryan Shi, Claire Wang, Fei Fang", "title": "Artificial Intelligence for Social Good: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence for social good (AI4SG) is a research theme that aims\nto use and advance artificial intelligence to address societal issues and\nimprove the well-being of the world. AI4SG has received lots of attention from\nthe research community in the past decade with several successful applications.\nBuilding on the most comprehensive collection of the AI4SG literature to date\nwith over 1000 contributed papers, we provide a detailed account and analysis\nof the work under the theme in the following ways. (1) We quantitatively\nanalyze the distribution and trend of the AI4SG literature in terms of\napplication domains and AI techniques used. (2) We propose three conceptual\nmethods to systematically group the existing literature and analyze the eight\nAI4SG application domains in a unified framework. (3) We distill five research\ntopics that represent the common challenges in AI4SG across various application\ndomains. (4) We discuss five issues that, we hope, can shed light on the future\ndevelopment of the AI4SG research.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 00:16:28 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Shi", "Zheyuan Ryan", ""], ["Wang", "Claire", ""], ["Fang", "Fei", ""]]}, {"id": "2001.01835", "submitter": "Patrick Rodler", "authors": "Patrick Rodler", "title": "Understanding the QuickXPlain Algorithm: Simple Explanation and Formal\n  Proof", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In his seminal paper of 2004, Ulrich Junker proposed the QuickXPlain\nalgorithm, which provides a divide-and-conquer computation strategy to find\nwithin a given set an irreducible subset with a particular (monotone) property.\nBeside its original application in the domain of constraint satisfaction\nproblems, the algorithm has since then found widespread adoption in areas as\ndifferent as model-based diagnosis, recommender systems, verification, or the\nSemantic Web. This popularity is due to the frequent occurrence of the problem\nof finding irreducible subsets on the one hand, and to QuickXPlain's general\napplicability and favorable computational complexity on the other hand.\n  However, although (we regularly experience) people are having a hard time\nunderstanding QuickXPlain and seeing why it works correctly, a proof of\ncorrectness of the algorithm has never been published. This is what we account\nfor in this work, by explaining QuickXPlain in a novel tried and tested way and\nby presenting an intelligible formal proof of it. Apart from showing the\ncorrectness of the algorithm and excluding the later detection of errors (proof\nand trust effect), the added value of the availability of a formal proof is,\ne.g., (i) that the workings of the algorithm often become completely clear only\nafter studying, verifying and comprehending the proof (didactic effect), (ii)\nthe shown proof methodology can be used as a guidance for proving other\nrecursive algorithms (transfer effect), and (iii) the possibility of providing\n\"gapless\" correctness proofs of systems that rely on (results computed by)\nQuickXPlain, such as numerous model-based debuggers (completeness effect).\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 01:37:41 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 07:59:09 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Rodler", "Patrick", ""]]}, {"id": "2001.01891", "submitter": "Bishwamittra Ghosh", "authors": "Bishwamittra Ghosh and Kuldeep S. Meel", "title": "IMLI: An Incremental Framework for MaxSAT-Based Learning of\n  Interpretable Classification Rules", "comments": "10 pages, published in the proceedings of AAAI/ACM Conference on AI,\n  Ethics, and Society (AIES 2019)", "journal-ref": "AIES-19: AAAI/ACM conference on Artificial Intelligence, Ethics,\n  and SocietyAt: Honolulu, HI, United States, January 27-28, 2019", "doi": "10.1145/3306618.3314283", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide adoption of machine learning in the critical domains such as medical\ndiagnosis, law, education had propelled the need for interpretable techniques\ndue to the need for end users to understand the reasoning behind decisions due\nto learning systems. The computational intractability of interpretable learning\nled practitioners to design heuristic techniques, which fail to provide sound\nhandles to tradeoff accuracy and interpretability.\n  Motivated by the success of MaxSAT solvers over the past decade, recently\nMaxSAT-based approach, called MLIC, was proposed that seeks to reduce the\nproblem of learning interpretable rules expressed in Conjunctive Normal Form\n(CNF) to a MaxSAT query. While MLIC was shown to achieve accuracy similar to\nthat of other state of the art black-box classifiers while generating small\ninterpretable CNF formulas, the runtime performance of MLIC is significantly\nlagging and renders approach unusable in practice. In this context, authors\nraised the question: Is it possible to achieve the best of both worlds, i.e., a\nsound framework for interpretable learning that can take advantage of MaxSAT\nsolvers while scaling to real-world instances?\n  In this paper, we take a step towards answering the above question in\naffirmation. We propose IMLI: an incremental approach to MaxSAT based framework\nthat achieves scalable runtime performance via partition-based training\nmethodology. Extensive experiments on benchmarks arising from UCI repository\ndemonstrate that IMLI achieves up to three orders of magnitude runtime\nimprovement without loss of accuracy and interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 05:03:53 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Ghosh", "Bishwamittra", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "2001.01902", "submitter": "Yiru Chen", "authors": "Yiru Chen, Eugene Wu", "title": "Monte Carlo Tree Search for Generating Interactive Data Analysis\n  Interfaces", "comments": "4 pages, 6 figures, The AAAI-20 Workshop on Intelligent Process\n  Automation (IPA-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive tools like user interfaces help democratize data access for\nend-users by hiding underlying programming details and exposing the necessary\nwidget interface to users. Since customized interfaces are costly to build,\nautomated interface generation is desirable. SQL is the dominant way to analyze\ndata and there already exists logs to analyze data. Previous work proposed a\nsyntactic approach to analyze structural changes in SQL query logs and\nautomatically generates a set of widgets to express the changes. However, they\ndo not consider layout usability and the sequential order of queries in the\nlog. We propose to adopt Monte Carlo Tree Search(MCTS) to search for the\noptimal interface that accounts for hierarchical layout as well as the\nusability in terms of how easy to express the query log.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 06:01:30 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 03:18:57 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Chen", "Yiru", ""], ["Wu", "Eugene", ""]]}, {"id": "2001.01918", "submitter": "Qun Liu", "authors": "Supratik Mukhopadhyay, Qun Liu, Edward Collier, Yimin Zhu, Ravindra\n  Gudishala, Chanachok Chokwitthaya, Robert DiBiano, Alimire Nabijiang, Sanaz\n  Saeidi, Subhajit Sidhanta, Arnab Ganguly", "title": "Context-Aware Design of Cyber-Physical Human Systems (CPHS)", "comments": "Paper was accepted at the 12th International Conference on\n  Communication Systems and Networks (COMSNETS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, it has been widely accepted by the research community that\ninteractions between humans and cyber-physical infrastructures have played a\nsignificant role in determining the performance of the latter. The existing\nparadigm for designing cyber-physical systems for optimal performance focuses\non developing models based on historical data. The impacts of context factors\ndriving human system interaction are challenging and are difficult to capture\nand replicate in existing design models. As a result, many existing models do\nnot or only partially address those context factors of a new design owing to\nthe lack of capabilities to capture the context factors. This limitation in\nmany existing models often causes performance gaps between predicted and\nmeasured results. We envision a new design environment, a cyber-physical human\nsystem (CPHS) where decision-making processes for physical infrastructures\nunder design are intelligently connected to distributed resources over\ncyberinfrastructure such as experiments on design features and empirical\nevidence from operations of existing instances. The framework combines existing\ndesign models with context-aware design-specific data involving\nhuman-infrastructure interactions in new designs, using a machine learning\napproach to create augmented design models with improved predictive powers.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 07:31:36 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Mukhopadhyay", "Supratik", ""], ["Liu", "Qun", ""], ["Collier", "Edward", ""], ["Zhu", "Yimin", ""], ["Gudishala", "Ravindra", ""], ["Chokwitthaya", "Chanachok", ""], ["DiBiano", "Robert", ""], ["Nabijiang", "Alimire", ""], ["Saeidi", "Sanaz", ""], ["Sidhanta", "Subhajit", ""], ["Ganguly", "Arnab", ""]]}, {"id": "2001.01982", "submitter": "Guido Schillaci", "authors": "Guido Schillaci, Antonio Pico Villalpando, Verena Vanessa Hafner,\n  Peter Hanappe, David Colliaux, Timoth\\'ee Wintz", "title": "Intrinsic Motivation and Episodic Memories for Robot Exploration of\n  High-Dimensional Sensory Spaces", "comments": "This manuscript has been submitted for consideration for publication\n  in the Adaptive Behaviour Sage Journal, edited by Tom Froese", "journal-ref": "Adaptive behaviour 2020", "doi": "10.1177/1059712320922916", "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work presents an architecture that generates curiosity-driven\ngoal-directed exploration behaviours for an image sensor of a microfarming\nrobot. A combination of deep neural networks for offline unsupervised learning\nof low-dimensional features from images, and of online learning of shallow\nneural networks representing the inverse and forward kinematics of the system\nhave been used. The artificial curiosity system assigns interest values to a\nset of pre-defined goals, and drives the exploration towards those that are\nexpected to maximise the learning progress. We propose the integration of an\nepisodic memory in intrinsic motivation systems to face catastrophic forgetting\nissues, typically experienced when performing online updates of artificial\nneural networks. Our results show that adopting an episodic memory system not\nonly prevents the computational models from quickly forgetting knowledge that\nhas been previously acquired, but also provides new avenues for modulating the\nbalance between plasticity and stability of the models.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 11:39:20 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Schillaci", "Guido", ""], ["Villalpando", "Antonio Pico", ""], ["Hafner", "Verena Vanessa", ""], ["Hanappe", "Peter", ""], ["Colliaux", "David", ""], ["Wintz", "Timoth\u00e9e", ""]]}, {"id": "2001.02004", "submitter": "Zijie Wang", "authors": "Zijie J. Wang, Robert Turko, Omar Shaikh, Haekyu Park, Nilaksh Das,\n  Fred Hohman, Minsuk Kahng, Duen Horng Chau", "title": "CNN 101: Interactive Visual Learning for Convolutional Neural Networks", "comments": "CHI'20 Late-Breaking Work (April 25-30, 2020), 7 pages, 3 figures", "journal-ref": null, "doi": "10.1145/3334480.3382899", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning solving previously-thought hard problems has\ninspired many non-experts to learn and understand this exciting technology.\nHowever, it is often challenging for learners to take the first steps due to\nthe complexity of deep learning models. We present our ongoing work, CNN 101,\nan interactive visualization system for explaining and teaching convolutional\nneural networks. Through tightly integrated interactive views, CNN 101 offers\nboth overview and detailed descriptions of how a model works. Built using\nmodern web technologies, CNN 101 runs locally in users' web browsers without\nrequiring specialized hardware, broadening the public's education access to\nmodern deep learning techniques.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 12:46:41 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 15:16:57 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 16:38:32 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Wang", "Zijie J.", ""], ["Turko", "Robert", ""], ["Shaikh", "Omar", ""], ["Park", "Haekyu", ""], ["Das", "Nilaksh", ""], ["Hohman", "Fred", ""], ["Kahng", "Minsuk", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2001.02021", "submitter": "Tanya Braun", "authors": "Tanya Braun, Ralf M\\\"oller", "title": "Exploring Unknown Universes in Probabilistic Relational Models", "comments": "Also accepted at the 9th StarAI Workshop at AAAI-20", "journal-ref": "Proceedings of AI 2019: Advances in Artificial Intelligence, 2019,\n  91-103", "doi": "10.1007/978-3-030-35288-2_8", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large probabilistic models are often shaped by a pool of known individuals (a\nuniverse) and relations between them. Lifted inference algorithms handle sets\nof known individuals for tractable inference. Universes may not always be\nknown, though, or may only described by assumptions such as \"small universes\nare more likely\". Without a universe, inference is no longer possible for\nlifted algorithms, losing their advantage of tractable inference. The aim of\nthis paper is to define a semantics for models with unknown universes decoupled\nfrom a specific constraint language to enable lifted and thereby, tractable\ninference.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 13:26:55 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Braun", "Tanya", ""], ["M\u00f6ller", "Ralf", ""]]}, {"id": "2001.02037", "submitter": "Patrik Christen", "authors": "Patrik Christen and Olivier Del Fabbro", "title": "Cybernetical Concepts for Cellular Automaton and Artificial Neural\n  Network Modelling and Implementation", "comments": "12 pages, 1 figure", "journal-ref": "2019 IEEE International Conference on Systems, Man and Cybernetics\n  (SMC), 4124-4130, 2019", "doi": "10.1109/SMC.2019.8913839", "report-no": null, "categories": "cs.OH cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As a discipline cybernetics has a long and rich history. In its first\ngeneration it not only had a worldwide span, in the area of computer modelling,\nfor example, its proponents such as John von Neumann, Stanislaw Ulam, Warren\nMcCulloch and Walter Pitts, also came up with models and methods such as\ncellular automata and artificial neural networks, which are still the\nfoundation of most modern modelling approaches. At the same time, cybernetics\nalso got the attention of philosophers, such as the Frenchman Gilbert Simondon,\nwho made use of cybernetical concepts in order to establish a metaphysics and a\nnatural philosophy of individuation, giving cybernetics thereby a philosophical\ninterpretation, which he baptised allagmatic. In this paper, we emphasise this\nallagmatic theory by showing how Simondon's philosophical concepts can be used\nto formulate a generic computer model or metamodel for complex systems\nmodelling and its implementation in program code, according to generic\nprogramming. We also present how the developed allagmatic metamodel is capable\nof building simple cellular automata and artificial neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 21:02:34 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 20:59:31 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 21:41:04 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Christen", "Patrik", ""], ["Del Fabbro", "Olivier", ""]]}, {"id": "2001.02094", "submitter": "Emir Zunic Dr.", "authors": "Emir Zunic, Dzenana Donko, Emir Buza", "title": "An adaptive data-driven approach to solve real-world vehicle routing\n  problems in logistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation occupies one-third of the amount in the logistics costs, and\naccordingly transportation systems largely influence the performance of the\nlogistics system. This work presents an adaptive data-driven innovative modular\napproach for solving the real-world Vehicle Routing Problems (VRP) in the field\nof logistics. The work consists of two basic units: (i) an innovative\nmulti-step algorithm for successful and entirely feasible solving of the VRP\nproblems in logistics, (ii) an adaptive approach for adjusting and setting up\nparameters and constants of the proposed algorithm. The proposed algorithm\ncombines several data transformation approaches, heuristics and Tabu search.\nMoreover, as the performance of the algorithm depends on the set of control\nparameters and constants, a predictive model that adaptively adjusts these\nparameters and constants according to historical data is proposed. A comparison\nof the acquired results has been made using the Decision Support System with\npredictive models: Generalized Linear Models (GLM) and Support Vector Machine\n(SVM). The algorithm, along with the control parameters, which using the\nprediction method were acquired, was incorporated into a web-based enterprise\nsystem, which is in use in several big distribution companies in Bosnia and\nHerzegovina. The results of the proposed algorithm were compared with a set of\nbenchmark instances and validated over real benchmark instances as well. The\nsuccessful feasibility of the given routes, in a real environment, is also\npresented.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 17:47:41 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Zunic", "Emir", ""], ["Donko", "Dzenana", ""], ["Buza", "Emir", ""]]}, {"id": "2001.02095", "submitter": "Konstantinos Xylogiannopoulos", "authors": "Konstantinos F. Xylogiannopoulos", "title": "Data Curves Clustering Using Common Patterns Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the past decades we have experienced an enormous expansion of the\naccumulated data that humanity produces. Daily a numerous number of smart\ndevices, usually interconnected over internet, produce vast, real-values\ndatasets. Time series representing datasets from completely irrelevant domains\nsuch as finance, weather, medical applications, traffic control etc. become\nmore and more crucial in human day life. Analyzing and clustering these time\nseries, or in general any kind of curves, could be critical for several human\nactivities. In the current paper, the new Curves Clustering Using Common\nPatterns (3CP) methodology is introduced, which applies a repeated pattern\ndetection algorithm in order to cluster sequences according to their shape and\nthe similarities of common patterns between time series, data curves and\neventually any kind of discrete sequences. For this purpose, the Longest\nExpected Repeated Pattern Reduced Suffix Array (LERP-RSA) data structure has\nbeen used in combination with the All Repeated Patterns Detection (ARPaD)\nalgorithm in order to perform highly accurate and efficient detection of\nsimilarities among data curves that can be used for clustering purposes and\nwhich also provides additional flexibility and features.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 18:36:38 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Xylogiannopoulos", "Konstantinos F.", ""]]}, {"id": "2001.02114", "submitter": "Yunfeng Zhang", "authors": "Yunfeng Zhang, Q. Vera Liao, Rachel K. E. Bellamy", "title": "Effect of Confidence and Explanation on Accuracy and Trust Calibration\n  in AI-Assisted Decision Making", "comments": null, "journal-ref": null, "doi": "10.1145/3351095.3372852", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, AI is being increasingly used to help human experts make decisions in\nhigh-stakes scenarios. In these scenarios, full automation is often\nundesirable, not only due to the significance of the outcome, but also because\nhuman experts can draw on their domain knowledge complementary to the model's\nto ensure task success. We refer to these scenarios as AI-assisted decision\nmaking, where the individual strengths of the human and the AI come together to\noptimize the joint decision outcome. A key to their success is to appropriately\n\\textit{calibrate} human trust in the AI on a case-by-case basis; knowing when\nto trust or distrust the AI allows the human expert to appropriately apply\ntheir knowledge, improving decision outcomes in cases where the model is likely\nto perform poorly. This research conducts a case study of AI-assisted decision\nmaking in which humans and AI have comparable performance alone, and explores\nwhether features that reveal case-specific model information can calibrate\ntrust and improve the joint performance of the human and AI. Specifically, we\nstudy the effect of showing confidence score and local explanation for a\nparticular prediction. Through two human experiments, we show that confidence\nscore can help calibrate people's trust in an AI model, but trust calibration\nalone is not sufficient to improve AI-assisted decision making, which may also\ndepend on whether the human can bring in enough unique knowledge to complement\nthe AI's errors. We also highlight the problems in using local explanation for\nAI-assisted decision making scenarios and invite the research community to\nexplore new approaches to explainability for calibrating human trust in AI.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 15:33:48 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Zhang", "Yunfeng", ""], ["Liao", "Q. Vera", ""], ["Bellamy", "Rachel K. E.", ""]]}, {"id": "2001.02122", "submitter": "Christoph Gebhardt", "authors": "Christoph Gebhardt, Antti Oulasvirta, Otmar Hilliges", "title": "Hierarchical Reinforcement Learning as a Model of Human Task\n  Interleaving", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do people decide how long to continue in a task, when to switch, and to\nwhich other task? Understanding the mechanisms that underpin task interleaving\nis a long-standing goal in the cognitive sciences. Prior work suggests greedy\nheuristics and a policy maximizing the marginal rate of return. However, it is\nunclear how such a strategy would allow for adaptation to everyday environments\nthat offer multiple tasks with complex switch costs and delayed rewards. Here\nwe develop a hierarchical model of supervisory control driven by reinforcement\nlearning (RL). The supervisory level learns to switch using task-specific\napproximate utility estimates, which are computed on the lower level. A\nhierarchically optimal value function decomposition can be learned from\nexperience, even in conditions with multiple tasks and arbitrary and uncertain\nreward and cost structures. The model reproduces known empirical effects of\ntask interleaving. It yields better predictions of individual-level data than a\nmyopic baseline in a six-task problem (N=211). The results support hierarchical\nRL as a plausible model of task interleaving.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 17:53:28 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Gebhardt", "Christoph", ""], ["Oulasvirta", "Antti", ""], ["Hilliges", "Otmar", ""]]}, {"id": "2001.02192", "submitter": "Santhosh Kumar Ramakrishnan", "authors": "Santhosh K. Ramakrishnan, Dinesh Jayaraman, Kristen Grauman", "title": "An Exploration of Embodied Visual Exploration", "comments": "30 main + 21 appendix pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embodied computer vision considers perception for robots in novel,\nunstructured environments. Of particular importance is the embodied visual\nexploration problem: how might a robot equipped with a camera scope out a new\nenvironment? Despite the progress thus far, many basic questions pertinent to\nthis problem remain unanswered: (i) What does it mean for an agent to explore\nits environment well? (ii) Which methods work well, and under which assumptions\nand environmental settings? (iii) Where do current approaches fall short, and\nwhere might future work seek to improve? Seeking answers to these questions, we\nfirst present a taxonomy for existing visual exploration algorithms and create\na standard framework for benchmarking them. We then perform a thorough\nempirical study of the four state-of-the-art paradigms using the proposed\nframework with two photorealistic simulated 3D environments, a state-of-the-art\nexploration architecture, and diverse evaluation metrics. Our experimental\nresults offer insights and suggest new performance metrics and baselines for\nfuture work in visual exploration. Code, models and data are publicly\navailable: https://github.com/facebookresearch/exploring_exploration\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 17:40:32 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 02:58:53 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Ramakrishnan", "Santhosh K.", ""], ["Jayaraman", "Dinesh", ""], ["Grauman", "Kristen", ""]]}, {"id": "2001.02271", "submitter": "Jichen Zhu", "authors": "Chelsea M. Myers, Evan Freed, Luis Fernando Laris Pardo, Anushay\n  Furqan, Sebastian Risi, Jichen Zhu", "title": "Revealing Neural Network Bias to Non-Experts Through Interactive\n  Counterfactual Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI algorithms are not immune to biases. Traditionally, non-experts have\nlittle control in uncovering potential social bias (e.g., gender bias) in the\nalgorithms that may impact their lives. We present a preliminary design for an\ninteractive visualization tool CEB to reveal biases in a commonly used AI\nmethod, Neural Networks (NN). CEB combines counterfactual examples and\nabstraction of an NN decision process to empower non-experts to detect bias.\nThis paper presents the design of CEB and initial findings of an expert panel\n(n=6) with AI, HCI, and Social science experts.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 20:24:10 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 19:09:37 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Myers", "Chelsea M.", ""], ["Freed", "Evan", ""], ["Pardo", "Luis Fernando Laris", ""], ["Furqan", "Anushay", ""], ["Risi", "Sebastian", ""], ["Zhu", "Jichen", ""]]}, {"id": "2001.02284", "submitter": "Alena Moiseeva", "authors": "Alena Moiseeva, Dietrich Trautmann, Michael Heimann, Hinrich Sch\\\"utze", "title": "Multipurpose Intelligent Process Automation via Conversational Assistant", "comments": "Presented at the AAAI-20 Workshop on Intelligent Process Automation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent Process Automation (IPA) is an emerging technology with a primary\ngoal to assist the knowledge worker by taking care of repetitive, routine and\nlow-cognitive tasks. Conversational agents that can interact with users in a\nnatural language are potential application for IPA systems. Such intelligent\nagents can assist the user by answering specific questions and executing\nroutine tasks that are ordinarily performed in a natural language (i.e.,\ncustomer support). In this work, we tackle a challenge of implementing an IPA\nconversational assistant in a real-world industrial setting with a lack of\nstructured training data. Our proposed system brings two significant benefits:\nFirst, it reduces repetitive and time-consuming activities and, therefore,\nallows workers to focus on more intelligent processes. Second, by interacting\nwith users, it augments the resources with structured and to some extent\nlabeled training data. We showcase the usage of the latter by re-implementing\nseveral components of our system with Transfer Learning (TL) methods.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 21:47:37 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 12:10:49 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Moiseeva", "Alena", ""], ["Trautmann", "Dietrich", ""], ["Heimann", "Michael", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2001.02296", "submitter": "Dan Shiebler", "authors": "Dan Shiebler, Alexis Toumi, Mehrnoosh Sadrzadeh", "title": "Incremental Monoidal Grammars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we define formal grammars in terms of free monoidal categories,\nalong with a functor from the category of formal grammars to the category of\nautomata. Generalising from the Booleans to arbitrary semirings, we extend our\nconstruction to weighted formal grammars and weighted automata. This allows us\nto link the categorical viewpoint on natural language to the standard machine\nlearning notion of probabilistic language model.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 22:37:12 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 12:37:53 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Shiebler", "Dan", ""], ["Toumi", "Alexis", ""], ["Sadrzadeh", "Mehrnoosh", ""]]}, {"id": "2001.02328", "submitter": "Nishanth Kumar", "authors": "Nishanth Kumar", "title": "The Past and Present of Imitation Learning: A Citation Chain Study", "comments": "This report was originally submitted as a Final Project for 'CSCI\n  1951M: The Great Ideas in Computer Science', offered at Brown University in\n  Fall 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation Learning is a promising area of active research. Over the last 30\nyears, Imitation Learning has advanced significantly and been used to solve\ndifficult tasks ranging from Autonomous Driving to playing Atari games. In the\ncourse of this development, different methods for performing Imitation Learning\nhave fallen into and out of favor. In this paper, I explore the development of\nthese different methods and attempt to examine how the field has progressed. I\nfocus my analysis on surveying 4 landmark papers that sequentially build upon\neach other to develop increasingly impressive Imitation Learning methods.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 00:58:31 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Kumar", "Nishanth", ""]]}, {"id": "2001.02329", "submitter": "Anup Anand Deshmukh", "authors": "Anup Anand Deshmukh, Catherine Soladie, Renaud Seguier", "title": "Emo-CNN for Perceiving Stress from Audio Signals: A Brain Chemistry\n  Approach", "comments": "2 pages, 2 tables and 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion plays a key role in many applications like healthcare, to gather\npatients emotional behavior. There are certain emotions which are given more\nimportance due to their effectiveness in understanding human feelings. In this\npaper, we propose an approach that models human stress from audio signals. The\nresearch challenge in speech emotion detection is defining the very meaning of\nstress and being able to categorize it in a precise manner. Supervised Machine\nLearning models, including state of the art Deep Learning classification\nmethods, rely on the availability of clean and labelled data. One of the\nproblems in affective computation and emotion detection is the limited amount\nof annotated data of stress. The existing labelled stress emotion datasets are\nhighly subjective to the perception of the annotator.\n  We address the first issue of feature selection by exploiting the use of\ntraditional MFCC features in Convolutional Neural Network. Our experiments show\nthat Emo-CNN consistently and significantly outperforms the popular existing\nmethods over multiple datasets. It achieves 90.2% categorical accuracy on the\nEmo-DB dataset. To tackle the second and the more significant problem of\nsubjectivity in stress labels, we use Lovheim's cube, which is a 3-dimensional\nprojection of emotions. The cube aims at explaining the relationship between\nthese neurotransmitters and the positions of emotions in 3D space. The learnt\nemotion representations from the Emo-CNN are mapped to the cube using three\ncomponent PCA (Principal Component Analysis) which is then used to model human\nstress. This proposed approach not only circumvents the need for labelled\nstress data but also complies with the psychological theory of emotions given\nby Lovheim's cube. We believe that this work is the first step towards creating\na connection between Artificial Intelligence and the chemistry of human\nemotions.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 01:01:48 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Deshmukh", "Anup Anand", ""], ["Soladie", "Catherine", ""], ["Seguier", "Renaud", ""]]}, {"id": "2001.02330", "submitter": "Krittaphat Pugdeethosapol", "authors": "Amar Shrestha, Krittaphat Pugdeethosapol, Haowen Fang, Qinru Qiu", "title": "High-Level Plan for Behavioral Robot Navigation with Natural Language\n  Directions and R-NET", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the navigational environment is known, it can be represented as a graph\nwhere landmarks are nodes, the robot behaviors that move from node to node are\nedges, and the route is a set of behavioral instructions. The route path from\nsource to destination can be viewed as a class of combinatorial optimization\nproblems where the path is a sequential subset from a set of discrete items.\nThe pointer network is an attention-based recurrent network that is suitable\nfor such a task. In this paper, we utilize a modified R-NET with gated\nattention and self-matching attention translating natural language instructions\nto a high-level plan for behavioral robot navigation by developing an\nunderstanding of the behavioral navigational graph to enable the pointer\nnetwork to produce a sequence of behaviors representing the path. Tests on the\nnavigation graph dataset show that our model outperforms the state-of-the-art\napproach for both known and unknown environments.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 01:14:11 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Shrestha", "Amar", ""], ["Pugdeethosapol", "Krittaphat", ""], ["Fang", "Haowen", ""], ["Qiu", "Qinru", ""]]}, {"id": "2001.02372", "submitter": "Bernhard Bermeitinger", "authors": "Simon Donig, Maria Christoforaki, Bernhard Bermeitinger, Siegfried\n  Handschuh", "title": "Multimodal Semantic Transfer from Text to Image. Fine-Grained Image\n  Classification by Distributional Semantics", "comments": "19 pages, second half in German as published in DHd2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last years, image classification processes like neural networks in the\narea of art-history and Heritage Informatics have experienced a broad\ndistribution (Lang and Ommer 2018). These methods face several challenges,\nincluding the handling of comparatively small amounts of data as well as\nhigh-dimensional data in the Digital Humanities. Here, a Convolutional Neural\nNetwork (CNN) is used that output is not, as usual, a series of flat text\nlabels but a series of semantically loaded vectors. These vectors result from a\nDistributional Semantic Model (DSM) which is generated from an in-domain text\ncorpus.\n  -----\n  In den letzten Jahren hat die Verwendung von Bildklassifizierungsverfahren\nwie neuronalen Netzwerken auch im Bereich der historischen Bildwissenschaften\nund der Heritage Informatics weite Verbreitung gefunden (Lang und Ommer 2018).\nDiese Verfahren stehen dabei vor einer Reihe von Herausforderungen, darunter\ndem Umgangmit den vergleichsweise kleinen Datenmengen sowie zugleich\nhochdimensionalen Da-tenr\\\"aumen in den digitalen Geisteswissenschaften. Meist\nbilden diese Methoden dieKlassifizierung auf einen vergleichsweise flachen Raum\nab. Dieser flache Zugang verliert im Bem\\\"uhen um ontologische Eindeutigkeit\neine Reihe von relevanten Dimensionen, darunter taxonomische, mereologische und\nassoziative Beziehungen zwischenden Klassen beziehungsweise dem nicht\nformalisierten Kontext. Dabei wird ein Convolutional Neural Network (CNN)\ngenutzt, dessen Ausgabe im Trainingsprozess, anders als herk\\\"ommlich, nicht\nauf einer Serie flacher Textlabel beruht, sondern auf einer Serie von Vektoren.\nDiese Vektoren resultieren aus einem Distributional Semantic Model (DSM),\nwelches aus einem Dom\\\"ane-Textkorpus generiert wird.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 14:26:06 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Donig", "Simon", ""], ["Christoforaki", "Maria", ""], ["Bermeitinger", "Bernhard", ""], ["Handschuh", "Siegfried", ""]]}, {"id": "2001.02462", "submitter": "Nobuhiro Ito", "authors": "Nobuhiro Ito, Yuya Suzuki and Akiko Aizawa", "title": "From Natural Language Instructions to Complex Processes: Issues in\n  Chaining Trigger Action Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automation services for complex business processes usually require a high\nlevel of information technology literacy. There is a strong demand for a\nsmartly assisted process automation (IPA: intelligent process automation)\nservice that enables even general users to easily use advanced automation. A\nnatural language interface for such automation is expected as an elemental\ntechnology for the IPA realization. The workflow targeted by IPA is generally\ncomposed of a combination of multiple tasks. However, semantic parsing, one of\nthe natural language processing methods, for such complex workflows has not yet\nbeen fully studied. The reasons are that (1) the formal expression and grammar\nof the workflow required for semantic analysis have not been sufficiently\nexamined and (2) the dataset of the workflow formal expression with its\ncorresponding natural language description required for learning workflow\nsemantics did not exist. This paper defines a new grammar for complex workflows\nwith chaining machine-executable meaning representations for semantic parsing.\nThe representations are at a high abstraction level. Additionally, an approach\nto creating datasets is proposed based on this grammar.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 11:44:47 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Ito", "Nobuhiro", ""], ["Suzuki", "Yuya", ""], ["Aizawa", "Akiko", ""]]}, {"id": "2001.02478", "submitter": "Q.Vera Liao", "authors": "Q. Vera Liao, Daniel Gruen, Sarah Miller", "title": "Questioning the AI: Informing Design Practices for Explainable AI User\n  Experiences", "comments": "Working draft. To appear in the ACM CHI Conference on Human Factors\n  in Computing Systems (CHI 2020)", "journal-ref": null, "doi": "10.1145/3313831.3376590", "report-no": null, "categories": "cs.HC cs.AI cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A surge of interest in explainable AI (XAI) has led to a vast collection of\nalgorithmic work on the topic. While many recognize the necessity to\nincorporate explainability features in AI systems, how to address real-world\nuser needs for understanding AI remains an open question. By interviewing 20 UX\nand design practitioners working on various AI products, we seek to identify\ngaps between the current XAI algorithmic work and practices to create\nexplainable AI products. To do so, we develop an algorithm-informed XAI\nquestion bank in which user needs for explainability are represented as\nprototypical questions users might ask about the AI, and use it as a study\nprobe. Our work contributes insights into the design space of XAI, informs\nefforts to support design practices in this space, and identifies opportunities\nfor future XAI work. We also provide an extended XAI question bank and discuss\nhow it can be used for creating user-centered XAI.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 12:34:51 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 21:44:57 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Liao", "Q. Vera", ""], ["Gruen", "Daniel", ""], ["Miller", "Sarah", ""]]}, {"id": "2001.02522", "submitter": "Fenglei Fan", "authors": "Fenglei Fan, Jinjun Xiong, Mengzhou Li, and Ge Wang", "title": "On Interpretability of Artificial Neural Networks: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning as represented by the artificial deep neural networks (DNNs)\nhas achieved great success in many important areas that deal with text, images,\nvideos, graphs, and so on. However, the black-box nature of DNNs has become one\nof the primary obstacles for their wide acceptance in mission-critical\napplications such as medical diagnosis and therapy. Due to the huge potential\nof deep learning, interpreting neural networks has recently attracted much\nresearch attention. In this paper, based on our comprehensive taxonomy, we\nsystematically review recent studies in understanding the mechanism of neural\nnetworks, describe applications of interpretability especially in medicine, and\ndiscuss future directions of interpretability research, such as in relation to\nfuzzy logic and brain science.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 13:40:42 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 22:55:52 GMT"}, {"version": "v3", "created": "Sat, 23 Jan 2021 15:59:45 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Fan", "Fenglei", ""], ["Xiong", "Jinjun", ""], ["Li", "Mengzhou", ""], ["Wang", "Ge", ""]]}, {"id": "2001.02553", "submitter": "Marvin Wyrich", "authors": "Marvin Wyrich, Regina Hebig, Stefan Wagner, Riccardo Scandariato", "title": "Perception and Acceptance of an Autonomous Refactoring Bot", "comments": "8 pages, 2 figures. To be published at 12th International Conference\n  on Agents and Artificial Intelligence (ICAART 2020)", "journal-ref": null, "doi": "10.5220/0009168803030310", "report-no": null, "categories": "cs.SE cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of autonomous bots for automatic support in software development\ntasks is increasing. In the past, however, they were not always perceived\npositively and sometimes experienced a negative bias compared to their human\ncounterparts. We conducted a qualitative study in which we deployed an\nautonomous refactoring bot for 41 days in a student software development\nproject. In between and at the end, we conducted semi-structured interviews to\nfind out how developers perceive the bot and whether they are more or less\ncritical when reviewing the contributions of a bot compared to human\ncontributions. Our findings show that the bot was perceived as a useful and\nunobtrusive contributor, and developers were no more critical of it than they\nwere about their human colleagues, but only a few team members felt responsible\nfor the bot.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 14:47:54 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Wyrich", "Marvin", ""], ["Hebig", "Regina", ""], ["Wagner", "Stefan", ""], ["Scandariato", "Riccardo", ""]]}, {"id": "2001.02619", "submitter": "Tathagata Chakraborti", "authors": "Tathagata Chakraborti and Yasaman Khazaeni", "title": "D3BA: A Tool for Optimizing Business Processes Using Non-Deterministic\n  Planning", "comments": "Appears in the Proceedings of the AAAI 2020 Workshop on Intelligent\n  Process Automation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper builds upon recent work in the declarative design of dialogue\nagents and proposes an exciting new tool -- D3BA -- Declarative Design for\nDigital Business Automation, built to optimize business processes using the\npower of AI planning. The tool provides a powerful framework to build,\noptimize, and maintain complex business processes and optimize them by\ncomposing with services that automate one or more subtasks. We illustrate\nsalient features of this composition technique, compare with other philosophies\nof composition, and highlight exciting opportunities for research in this\nemerging field of business process automation.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 16:58:14 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 22:13:37 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Chakraborti", "Tathagata", ""], ["Khazaeni", "Yasaman", ""]]}, {"id": "2001.02811", "submitter": "Jingliang Duan", "authors": "Jingliang Duan, Yang Guan, Shengbo Eben Li, Yangang Ren, Bo Cheng", "title": "Distributional Soft Actor-Critic: Off-Policy Reinforcement Learning for\n  Addressing Value Estimation Errors", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2021", "doi": "10.1109/TNNLS.2021.3082568", "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning (RL), function approximation errors are known to\neasily lead to the Q-value overestimations, thus greatly reducing policy\nperformance. This paper presents a distributional soft actor-critic (DSAC)\nalgorithm, which is an off-policy RL method for continuous control setting, to\nimprove the policy performance by mitigating Q-value overestimations. We first\ndiscover in theory that learning a distribution function of state-action\nreturns can effectively mitigate Q-value overestimations because it is capable\nof adaptively adjusting the update stepsize of the Q-value function. Then, a\ndistributional soft policy iteration (DSPI) framework is developed by embedding\nthe return distribution function into maximum entropy RL. Finally, we present a\ndeep off-policy actor-critic variant of DSPI, called DSAC, which directly\nlearns a continuous return distribution by keeping the variance of the\nstate-action returns within a reasonable range to address exploding and\nvanishing gradient problems. We evaluate DSAC on the suite of MuJoCo continuous\ncontrol tasks, achieving the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 02:27:18 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 08:39:55 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 15:21:17 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Duan", "Jingliang", ""], ["Guan", "Yang", ""], ["Li", "Shengbo Eben", ""], ["Ren", "Yangang", ""], ["Cheng", "Bo", ""]]}, {"id": "2001.02872", "submitter": "Mark Wallace G", "authors": "Mark Wallace and Aldeida Aleti", "title": "The Neighbours' Similar Fitness Property for Local Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For most practical optimisation problems local search outperforms random\nsampling - despite the \"No Free Lunch Theorem\". This paper introduces a\nproperty of search landscapes termed Neighbours' Similar Fitness (NSF) that\nunderlies the good performance of neighbourhood search in terms of local\nimprovement. Though necessary, NSF is not sufficient to ensure that searching\nfor improvement among the neighbours of a good solution is better than random\nsearch. The paper introduces an additional (natural) property which supports a\ngeneral proof that, for NSF landscapes, neighbourhood search beats random\nsearch.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 07:53:56 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Wallace", "Mark", ""], ["Aleti", "Aldeida", ""]]}, {"id": "2001.02889", "submitter": "Duligur Ibeling", "authors": "Duligur Ibeling, Thomas Icard", "title": "Probabilistic Reasoning across the Causal Hierarchy", "comments": "AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a formalization of the three-tier causal hierarchy of association,\nintervention, and counterfactuals as a series of probabilistic logical\nlanguages. Our languages are of strictly increasing expressivity, the first\ncapable of expressing quantitative probabilistic reasoning -- including\nconditional independence and Bayesian inference -- the second encoding\ndo-calculus reasoning for causal effects, and the third capturing a fully\nexpressive do-calculus for arbitrary counterfactual queries. We give a\ncorresponding series of finitary axiomatizations complete over both structural\ncausal models and probabilistic programs, and show that satisfiability and\nvalidity for each language are decidable in polynomial space.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 08:52:14 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 16:03:38 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 17:40:29 GMT"}, {"version": "v4", "created": "Wed, 29 Jul 2020 23:55:30 GMT"}, {"version": "v5", "created": "Wed, 2 Jun 2021 08:14:53 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Ibeling", "Duligur", ""], ["Icard", "Thomas", ""]]}, {"id": "2001.02907", "submitter": "Whiyoung Jung", "authors": "Whiyoung Jung, Giseung Park, Youngchul Sung", "title": "Population-Guided Parallel Policy Search for Reinforcement Learning", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new population-guided parallel learning scheme is proposed\nto enhance the performance of off-policy reinforcement learning (RL). In the\nproposed scheme, multiple identical learners with their own value-functions and\npolicies share a common experience replay buffer, and search a good policy in\ncollaboration with the guidance of the best policy information. The key point\nis that the information of the best policy is fused in a soft manner by\nconstructing an augmented loss function for policy update to enlarge the\noverall search region by the multiple learners. The guidance by the previous\nbest policy and the enlarged range enable faster and better policy search.\nMonotone improvement of the expected cumulative return by the proposed scheme\nis proved theoretically. Working algorithms are constructed by applying the\nproposed scheme to the twin delayed deep deterministic (TD3) policy gradient\nalgorithm. Numerical results show that the constructed algorithm outperforms\nmost of the current state-of-the-art RL algorithms, and the gain is significant\nin the case of sparse reward environment.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 10:13:57 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Jung", "Whiyoung", ""], ["Park", "Giseung", ""], ["Sung", "Youngchul", ""]]}, {"id": "2001.02912", "submitter": "Laure Soulier", "authors": "Sharon Oviatt and Laure Soulier", "title": "Conversational Search for Learning Technologies", "comments": "Dagstuhl Report on Conversational Search (ID 19461) - This document\n  is a report of the breaking group \"Conversational Search for Learning\n  Technologies\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational search is based on a user-system cooperation with the\nobjective to solve an information-seeking task. In this report, we discuss the\nimplication of such cooperation with the learning perspective from both user\nand system side. We also focus on the stimulation of learning through a key\ncomponent of conversational search, namely the multimodality of communication\nway, and discuss the implication in terms of information retrieval. We end with\na research road map describing promising research directions and perspectives.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 10:35:27 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Oviatt", "Sharon", ""], ["Soulier", "Laure", ""]]}, {"id": "2001.02921", "submitter": "Kashyap Todi", "authors": "Niraj Dayama, Kashyap Todi, Taru Saarelainen, Antti Oulasvirta", "title": "GRIDS: Interactive Layout Design with Integer Programming", "comments": "13 pages, 10 figures, ACM CHI 2020 Full Paper", "journal-ref": null, "doi": "10.1145/3313831.3376553", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grid layouts are used by designers to spatially organise user interfaces when\nsketching and wireframing. However, their design is largely time consuming\nmanual work. This is challenging due to combinatorial explosion and complex\nobjectives, such as alignment, balance, and expectations regarding positions.\nThis paper proposes a novel optimisation approach for the generation of diverse\ngrid-based layouts. Our mixed integer linear programming (MILP) model offers a\nrigorous yet efficient method for grid generation that ensures packing,\nalignment, grouping, and preferential positioning of elements. Further, we\npresent techniques for interactive diversification, enhancement, and completion\nof grid layouts (Figure 1). These capabilities are demonstrated using GRIDS1, a\nwireframing tool that provides designers with real-time layout suggestions. We\nreport findings from a ratings study (N = 13) and a design study (N = 16),\nlending evidence for the benefit of computational grid generation during early\nstages of design.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 11:08:15 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Dayama", "Niraj", ""], ["Todi", "Kashyap", ""], ["Saarelainen", "Taru", ""], ["Oulasvirta", "Antti", ""]]}, {"id": "2001.02970", "submitter": "Sama Daryanavard Miss", "authors": "Sama Daryanavard, Bernd Porr", "title": "Closed-loop deep learning: generating forward models with\n  back-propagation", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A reflex is a simple closed loop control approach which tries to minimise an\nerror but fails to do so because it will always react too late. An adaptive\nalgorithm can use this error to learn a forward model with the help of\npredictive cues. For example a driver learns to improve their steering by\nlooking ahead to avoid steering in the last minute. In order to process complex\ncues such as the road ahead deep learning is a natural choice. However, this is\nusually only achieved indirectly by employing deep reinforcement learning\nhaving a discrete state space. Here, we show how this can be directly achieved\nby embedding deep learning into a closed loop system and preserving its\ncontinuous processing. We show specifically how error back-propagation can be\nachieved in z-space and in general how gradient based approaches can be\nanalysed in such closed loop scenarios. The performance of this learning\nparadigm is demonstrated using a line-follower both in simulation and on a real\nrobot that show very fast and continuous learning.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 13:36:57 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 11:14:24 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Daryanavard", "Sama", ""], ["Porr", "Bernd", ""]]}, {"id": "2001.03041", "submitter": "Tomasz Zi\\k{e}tkiewicz", "authors": "Marek Kubis, Zygmunt Vetulani, Miko{\\l}aj Wypych, Tomasz\n  Zi\\k{e}tkiewicz", "title": "Open Challenge for Correcting Errors of Speech Recognition Systems", "comments": null, "journal-ref": "Vetulani, Zygmunt, Paroubek, Patrick (eds.): Proceedings of the\n  9th Language and Technology Conference, pp. 219-223, Wydawnictwo Nauka i\n  Innowacje, Pozna\\'n, Poland, 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper announces the new long-term challenge for improving the performance\nof automatic speech recognition systems. The goal of the challenge is to\ninvestigate methods of correcting the recognition results on the basis of\npreviously made errors by the speech processing system. The dataset prepared\nfor the task is described and evaluation criteria are presented.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 15:07:32 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Kubis", "Marek", ""], ["Vetulani", "Zygmunt", ""], ["Wypych", "Miko\u0142aj", ""], ["Zi\u0119tkiewicz", "Tomasz", ""]]}, {"id": "2001.03210", "submitter": "Porter Jenkins", "authors": "Porter Jenkins, Hua Wei, J. Stockton Jenkins, Zhenhui Li", "title": "A Probabilistic Simulator of Spatial Demand for Product Allocation", "comments": "8 pages, The AAAI-20 Workshop on Intelligent Process Automation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connecting consumers with relevant products is a very important problem in\nboth online and offline commerce. In physical retail, product placement is an\neffective way to connect consumers with products. However, selecting product\nlocations within a store can be a tedious process. Moreover, learning important\nspatial patterns in offline retail is challenging due to the scarcity of data\nand the high cost of exploration and experimentation in the physical world. To\naddress these challenges, we propose a stochastic model of spatial demand in\nphysical retail. We show that the proposed model is more predictive of demand\nthan existing baselines. We also perform a preliminary study into different\nautomation techniques and show that an optimal product allocation policy can be\nlearned through Deep Q-Learning.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 20:18:37 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Jenkins", "Porter", ""], ["Wei", "Hua", ""], ["Jenkins", "J. Stockton", ""], ["Li", "Zhenhui", ""]]}, {"id": "2001.03359", "submitter": "Guangliang Li", "authors": "Qilei Zhang, Jinying Lin, Qixin Sha, Bo He and Guangliang Li", "title": "Deep Interactive Reinforcement Learning for Path Following of Autonomous\n  Underwater Vehicle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous underwater vehicle (AUV) plays an increasingly important role in\nocean exploration. Existing AUVs are usually not fully autonomous and generally\nlimited to pre-planning or pre-programming tasks. Reinforcement learning (RL)\nand deep reinforcement learning have been introduced into the AUV design and\nresearch to improve its autonomy. However, these methods are still difficult to\napply directly to the actual AUV system because of the sparse rewards and low\nlearning efficiency. In this paper, we proposed a deep interactive\nreinforcement learning method for path following of AUV by combining the\nadvantages of deep reinforcement learning and interactive RL. In addition,\nsince the human trainer cannot provide human rewards for AUV when it is running\nin the ocean and AUV needs to adapt to a changing environment, we further\npropose a deep reinforcement learning method that learns from both human\nrewards and environmental rewards at the same time. We test our methods in two\npath following tasks---straight line and sinusoids curve following of AUV by\nsimulating in the Gazebo platform. Our experimental results show that with our\nproposed deep interactive RL method, AUV can converge faster than a DQN learner\nfrom only environmental reward. Moreover, AUV learning with our deep RL from\nboth human and environmental rewards can also achieve a similar or even better\nperformance than that with the deep interactive RL method and can adapt to the\nactual environment by further learning from environmental rewards.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 09:22:39 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Zhang", "Qilei", ""], ["Lin", "Jinying", ""], ["Sha", "Qixin", ""], ["He", "Bo", ""], ["Li", "Guangliang", ""]]}, {"id": "2001.03384", "submitter": "Evangelos Pournaras", "authors": "Brionna Davis, Grace Jennings, Taylor Pothast, Ilias Gerostathopoulos,\n  Evangelos Pournaras, Raphael E. Stern", "title": "Decentralized Optimization of Vehicle Route Planning -- A Cross-City\n  Comparative Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.DC cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New mobility concepts are at the forefront of research and innovation in\nsmart cities. The introduction of connected and autonomous vehicles enables new\npossibilities in vehicle routing. Specifically, knowing the origin and\ndestination of each agent in the network can allow for real-time routing of the\nvehicles to optimize network performance. However, this relies on individual\nvehicles being \"altruistic\" i.e., being willing to accept an alternative\nnon-preferred route in order to achieve a network-level performance goal. In\nthis work, we conduct a study to compare different levels of agent altruism and\nthe resulting effect on the network-level traffic performance. Specifically,\nthis study compares the effects of different underlying urban structures on the\noverall network performance, and investigates which characteristics of the\nnetwork make it possible to realize routing improvements using a decentralized\noptimization router. The main finding is that, with increased vehicle altruism,\nit is possible to balance traffic flow among the links of the network. We show\nevidence that the decentralized optimization router is more effective with\nnetworks of high load while we study the influence of cities characteristics,\nin particular: networks with a higher number of nodes (intersections) or edges\n(roads) per unit area allow for more possible alternate routes, and thus higher\npotential to improve network performance.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 11:02:51 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Davis", "Brionna", ""], ["Jennings", "Grace", ""], ["Pothast", "Taylor", ""], ["Gerostathopoulos", "Ilias", ""], ["Pournaras", "Evangelos", ""], ["Stern", "Raphael E.", ""]]}, {"id": "2001.03386", "submitter": "Sahil Manchanda", "authors": "Sahil Manchanda, Arun Rajkumar, Simarjot Kaur, Narayanan Unny", "title": "SUPAID: A Rule mining based method for automatic rollout decision aid\n  for supervisors in fleet management systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decision to rollout a vehicle is critical to fleet management companies\nas wrong decisions can lead to additional cost of maintenance and failures\nduring journey. With the availability of large amount of data and advancement\nof machine learning techniques, the rollout decisions of a supervisor can be\neffectively automated and the mistakes in decisions made by the supervisor\nlearnt. In this paper, we propose a novel learning algorithm SUPAID which under\na natural 'one-way efficiency' assumption on the supervisor, uses a rule mining\napproach to rank the vehicles based on their roll-out feasibility thus helping\nprevent the supervisor from makingerroneous decisions. Our experimental results\non real data from a public transit agency from a city in U.S show that the\nproposed method SUPAID can result in significant cost savings.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 11:06:04 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 05:34:11 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Manchanda", "Sahil", ""], ["Rajkumar", "Arun", ""], ["Kaur", "Simarjot", ""], ["Unny", "Narayanan", ""]]}, {"id": "2001.03436", "submitter": "Marcel Hildebrandt", "authors": "Marcel Hildebrandt, Jorge Andres Quintero Serna, Yunpu Ma, Martin\n  Ringsquandl, Mitchell Joblin, Volker Tresp", "title": "Debate Dynamics for Human-comprehensible Fact-checking on Knowledge\n  Graphs", "comments": "AAAI 2019 Fall Symposium Series. arXiv admin note: substantial text\n  overlap with arXiv:2001.00461", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for fact-checking on knowledge graphs based on\ndebate dynamics. The underlying idea is to frame the task of triple\nclassification as a debate game between two reinforcement learning agents which\nextract arguments -- paths in the knowledge graph -- with the goal to justify\nthe fact being true (thesis) or the fact being false (antithesis),\nrespectively. Based on these arguments, a binary classifier, referred to as the\njudge, decides whether the fact is true or false. The two agents can be\nconsidered as sparse feature extractors that present interpretable evidence for\neither the thesis or the antithesis. In contrast to black-box methods, the\narguments enable the user to gain an understanding for the decision of the\njudge. Moreover, our method allows for interactive reasoning on knowledge\ngraphs where the users can raise additional arguments or evaluate the debate\ntaking common sense reasoning and external information into account. Such\ninteractive systems can increase the acceptance of various AI applications\nbased on knowledge graphs and can further lead to higher efficiency,\nrobustness, and fairness.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 15:19:45 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Hildebrandt", "Marcel", ""], ["Serna", "Jorge Andres Quintero", ""], ["Ma", "Yunpu", ""], ["Ringsquandl", "Martin", ""], ["Joblin", "Mitchell", ""], ["Tresp", "Volker", ""]]}, {"id": "2001.03521", "submitter": "Yiyuan Li", "authors": "Yiyuan Li, Antonios Anastasopoulos and Alan W Black", "title": "Towards Minimal Supervision BERT-based Grammar Error Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current grammatical error correction (GEC) models typically consider the task\nas sequence generation, which requires large amounts of annotated data and\nlimit the applications in data-limited settings. We try to incorporate\ncontextual information from pre-trained language model to leverage annotation\nand benefit multilingual scenarios. Results show strong potential of\nBidirectional Encoder Representations from Transformers (BERT) in grammatical\nerror correction task.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 15:45:59 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Li", "Yiyuan", ""], ["Anastasopoulos", "Antonios", ""], ["Black", "Alan W", ""]]}, {"id": "2001.03543", "submitter": "Yara Rizk", "authors": "Yara Rizk, Abhishek Bhandwalder, Scott Boag, Tathagata Chakraborti,\n  Vatche Isahagian, Yasaman Khazaeni, Falk Pollock, Merve Unuvar", "title": "A Unified Conversational Assistant Framework for Business Process\n  Automation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Business process automation is a booming multi-billion-dollar industry that\npromises to remove menial tasks from workers' plates -- through the\nintroduction of autonomous agents -- and free up their time and brain power for\nmore creative and engaging tasks. However, an essential component to the\nsuccessful deployment of such autonomous agents is the ability of business\nusers to monitor their performance and customize their execution. A simple and\nuser-friendly interface with a low learning curve is necessary to increase the\nadoption of such agents in banking, insurance, retail and other domains. As a\nresult, proactive chatbots will play a crucial role in the business automation\nspace. Not only can they respond to users' queries and perform actions on their\nbehalf but also initiate communication with the users to inform them of the\nsystem's behavior. This will provide business users a natural language\ninterface to interact with, monitor and control autonomous agents. In this\nwork, we present a multi-agent orchestration framework to develop such\nproactive chatbots by discussing the types of skills that can be composed into\nagents and how to orchestrate these agents. Two use cases on a travel\npreapproval business process and a loan application business process are\nadopted to qualitatively analyze the proposed framework based on four criteria:\nperformance, coding overhead, scalability, and agent overlap.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 22:30:05 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Rizk", "Yara", ""], ["Bhandwalder", "Abhishek", ""], ["Boag", "Scott", ""], ["Chakraborti", "Tathagata", ""], ["Isahagian", "Vatche", ""], ["Khazaeni", "Yasaman", ""], ["Pollock", "Falk", ""], ["Unuvar", "Merve", ""]]}, {"id": "2001.03573", "submitter": "Matthijs Maas", "authors": "Peter Cihon, Matthijs M. Maas, Luke Kemp", "title": "Should Artificial Intelligence Governance be Centralised? Design Lessons\n  from History", "comments": "A shorter version of the paper is to be published in the proceedings\n  of AAAI/ACM AIES 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can effective international governance for artificial intelligence remain\nfragmented, or is there a need for a centralised international organisation for\nAI? We draw on the history of other international regimes to identify\nadvantages and disadvantages in centralising AI governance. Some\nconsiderations, such as efficiency and political power, speak in favour of\ncentralisation. Conversely, the risk of creating a slow and brittle institution\nspeaks against it, as does the difficulty in securing participation while\ncreating stringent rules. Other considerations depend on the specific design of\na centralised institution. A well-designed body may be able to deter forum\nshopping and ensure policy coordination. However, forum shopping can be\nbeneficial and a fragmented landscape of institutions can be self-organising.\nCentralisation entails trade-offs and the details matter. We conclude with two\ncore recommendations. First, the outcome will depend on the exact design of a\ncentral institution. A well-designed centralised regime covering a set of\ncoherent issues could be beneficial. But locking-in an inadequate structure may\npose a fate worse than fragmentation. Second, for now fragmentation will likely\npersist. This should be closely monitored to see if it is self-organising or\nsimply inadequate.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 17:34:31 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Cihon", "Peter", ""], ["Maas", "Matthijs M.", ""], ["Kemp", "Luke", ""]]}, {"id": "2001.03671", "submitter": "Harsh Mehta", "authors": "Harsh Mehta, Yoav Artzi, Jason Baldridge, Eugene Ie, Piotr Mirowski", "title": "Retouchdown: Adding Touchdown to StreetLearn as a Shareable Resource for\n  Language Grounding Tasks in Street View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Touchdown dataset (Chen et al., 2019) provides instructions by human\nannotators for navigation through New York City streets and for resolving\nspatial descriptions at a given location. To enable the wider research\ncommunity to work effectively with the Touchdown tasks, we are publicly\nreleasing the 29k raw Street View panoramas needed for Touchdown. We follow the\nprocess used for the StreetLearn data release (Mirowski et al., 2019) to check\npanoramas for personally identifiable information and blur them as necessary.\nThese have been added to the StreetLearn dataset and can be obtained via the\nsame process as used previously for StreetLearn. We also provide a reference\nimplementation for both of the Touchdown tasks: vision and language navigation\n(VLN) and spatial description resolution (SDR). We compare our model results to\nthose given in Chen et al. (2019) and show that the panoramas we have added to\nStreetLearn fully support both Touchdown tasks and can be used effectively for\nfurther research and comparison.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 21:35:28 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Mehta", "Harsh", ""], ["Artzi", "Yoav", ""], ["Baldridge", "Jason", ""], ["Ie", "Eugene", ""], ["Mirowski", "Piotr", ""]]}, {"id": "2001.03792", "submitter": "Raghav Nagpal", "authors": "Raghav Nagpal, Achyuthan Unni Krishnan and Hanshen Yu", "title": "Reward Engineering for Object Pick and Place Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic grasping is a crucial area of research as it can result in the\nacceleration of the automation of several Industries utilizing robots ranging\nfrom manufacturing to healthcare. Reinforcement learning is the field of study\nwhere an agent learns a policy to execute an action by exploring and exploiting\nrewards from an environment. Reinforcement learning can thus be used by the\nagent to learn how to execute a certain task, in our case grasping an object.\nWe have used the Pick and Place environment provided by OpenAI's Gym to\nengineer rewards. Hindsight Experience Replay (HER) has shown promising results\nwith problems having a sparse reward. In the default configuration of the\nOpenAI baseline and environment the reward function is calculated using the\ndistance between the target location and the robot end-effector. By weighting\nthe cost based on the distance of the end-effector from the goal in the x,y and\nz-axes we were able to almost halve the learning time compared to the baselines\nprovided by OpenAI, an intuitive strategy that further reduced learning time.\nIn this project, we were also able to introduce certain user desired\ntrajectories in the learnt policies (city-block / Manhattan trajectories). This\nhelps us understand that by engineering the rewards we can tune the agent to\nlearn policies in a certain way even if it might not be the most optimal but is\nthe desired manner.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 20:13:28 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Nagpal", "Raghav", ""], ["Krishnan", "Achyuthan Unni", ""], ["Yu", "Hanshen", ""]]}, {"id": "2001.03809", "submitter": "Maxime Bouton", "authors": "Maxime Bouton, Jana Tumova, and Mykel J. Kochenderfer", "title": "Point-Based Methods for Model Checking in Partially Observable Markov\n  Decision Processes", "comments": "8 pages, 3 figures, AAAI 2020", "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous systems are often required to operate in partially observable\nenvironments. They must reliably execute a specified objective even with\nincomplete information about the state of the environment. We propose a\nmethodology to synthesize policies that satisfy a linear temporal logic formula\nin a partially observable Markov decision process (POMDP). By formulating a\nplanning problem, we show how to use point-based value iteration methods to\nefficiently approximate the maximum probability of satisfying a desired logical\nformula and compute the associated belief state policy. We demonstrate that our\nmethod scales to large POMDP domains and provides strong bounds on the\nperformance of the resulting policy.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 23:09:25 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Bouton", "Maxime", ""], ["Tumova", "Jana", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2001.04025", "submitter": "Chen Ma", "authors": "Chen Ma, Dylan R. Ashley, Junfeng Wen, Yoshua Bengio", "title": "Universal Successor Features for Transfer Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer in Reinforcement Learning (RL) refers to the idea of applying\nknowledge gained from previous tasks to solving related tasks. Learning a\nuniversal value function (Schaul et al., 2015), which generalizes over goals\nand states, has previously been shown to be useful for transfer. However,\nsuccessor features are believed to be more suitable than values for transfer\n(Dayan, 1993; Barreto et al.,2017), even though they cannot directly generalize\nto new goals. In this paper, we propose (1) Universal Successor Features (USFs)\nto capture the underlying dynamics of the environment while allowing\ngeneralization to unseen goals and (2) a flexible end-to-end model of USFs that\ncan be trained by interacting with the environment. We show that learning USFs\nis compatible with any RL algorithm that learns state values using a temporal\ndifference method. Our experiments in a simple gridworld and with two MuJoCo\nenvironments show that USFs can greatly accelerate training when learning\nmultiple tasks and can effectively transfer knowledge to new tasks.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 03:41:06 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Ma", "Chen", ""], ["Ashley", "Dylan R.", ""], ["Wen", "Junfeng", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2001.04170", "submitter": "Simon Razniewski", "authors": "Yohan Chalier, Simon Razniewski, and Gerhard Weikum", "title": "Joint Reasoning for Multi-Faceted Commonsense Knowledge", "comments": "11 pages", "journal-ref": "AKBC 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense knowledge (CSK) supports a variety of AI applications, from\nvisual understanding to chatbots. Prior works on acquiring CSK, such as\nConceptNet, have compiled statements that associate concepts, like everyday\nobjects or activities, with properties that hold for most or some instances of\nthe concept. Each concept is treated in isolation from other concepts, and the\nonly quantitative measure (or ranking) of properties is a confidence score that\nthe statement is valid. This paper aims to overcome these limitations by\nintroducing a multi-faceted model of CSK statements and methods for joint\nreasoning over sets of inter-related statements. Our model captures four\ndifferent dimensions of CSK statements: plausibility, typicality, remarkability\nand salience, with scoring and ranking along each dimension. For example,\nhyenas drinking water is typical but not salient, whereas hyenas eating\ncarcasses is salient. For reasoning and ranking, we develop a method with soft\nconstraints, to couple the inference over concepts that are related in in a\ntaxonomic hierarchy. The reasoning is cast into an integer linear programming\n(ILP), and we leverage the theory of reduction costs of a relaxed LP to compute\ninformative rankings. This methodology is applied to several large CSK\ncollections. Our evaluation shows that we can consolidate these inputs into\nmuch cleaner and more expressive knowledge. Results are available at\nhttps://dice.mpi-inf.mpg.de.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 11:34:25 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 20:58:16 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Chalier", "Yohan", ""], ["Razniewski", "Simon", ""], ["Weikum", "Gerhard", ""]]}, {"id": "2001.04171", "submitter": "Maarten Bieshaar", "authors": "Silvia Beddar-Wiesing, Maarten Bieshaar", "title": "Multi-Sensor Data and Knowledge Fusion -- A Proposal for a Terminology\n  Definition", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fusion is a common tool for the analysis and utilization of available\ndatasets and so an essential part of data mining and machine learning\nprocesses. However, a clear definition of the type of fusion is not always\nprovided due to inconsistent literature. In the following, the process of\nfusion is defined depending on the fusion components and the abstraction level\non which the fusion occurs. The focus in the first part of the paper at hand is\non the clear definition of the terminology and the development of an\nappropriate ontology of the fusion components and the fusion level. In the\nsecond part, common fusion techniques are presented.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 11:42:36 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Beddar-Wiesing", "Silvia", ""], ["Bieshaar", "Maarten", ""]]}, {"id": "2001.04186", "submitter": "Kristina Yordanova", "authors": "Debajyoti Paul Chowdhury and Arghya Biswas and Tomasz Sosnowski and\n  Kristina Yordanova", "title": "Towards Evaluating Plan Generation Approaches with Instructional Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in behaviour understanding through language grounding has\nshown it is possible to automatically generate behaviour models from textual\ninstructions. These models usually have goal-oriented structure and are\nmodelled with different formalisms from the planning domain such as the\nPlanning Domain Definition Language. One major problem that still remains is\nthat there are no benchmark datasets for comparing the different model\ngeneration approaches, as each approach is usually evaluated on domain-specific\napplication. To allow the objective comparison of different methods for model\ngeneration from textual instructions, in this report we introduce a dataset\nconsisting of 83 textual instructions in English language, their refinement in\na more structured form as well as manually developed plans for each of the\ninstructions. The dataset is publicly available to the community.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 12:35:16 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Chowdhury", "Debajyoti Paul", ""], ["Biswas", "Arghya", ""], ["Sosnowski", "Tomasz", ""], ["Yordanova", "Kristina", ""]]}, {"id": "2001.04191", "submitter": "Johannes Klaus Fichte", "authors": "Johannes K. Fichte, Markus Hecher, Patrick Thier, Stefan Woltran", "title": "Exploiting Database Management Systems and Treewidth for Counting", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": "10.1017/S147106842100003X", "report-no": null, "categories": "cs.AI cs.DS math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bounded treewidth is one of the most cited combinatorial invariants, which\nwas applied in the literature for solving several counting problems\nefficiently. A canonical counting problem is #SAT, which asks to count the\nsatisfying assignments of a Boolean formula. Recent work shows that\nbenchmarking instances for #SAT often have reasonably small treewidth. This\npaper deals with counting problems for instances of small treewidth. We\nintroduce a general framework to solve counting questions based on\nstate-of-the-art database management systems (DBMS). Our framework takes\nexplicitly advantage of small treewidth by solving instances using dynamic\nprogramming (DP) on tree decompositions (TD). Therefore, we implement the\nconcept of DP into a DBMS (PostgreSQL), since DP algorithms are already often\ngiven in terms of table manipulations in theory. This allows for elegant\nspecifications of DP algorithms and the use of SQL to manipulate records and\ntables, which gives us a natural approach to bring DP algorithms into practice.\nTo the best of our knowledge, we present the first approach to employ a DBMS\nfor algorithms on TDs. A key advantage of our approach is that DBMS naturally\nallow to deal with huge tables with a limited amount of main memory (RAM),\nparallelization, as well as suspending computation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 12:45:22 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 16:54:41 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Fichte", "Johannes K.", ""], ["Hecher", "Markus", ""], ["Thier", "Patrick", ""], ["Woltran", "Stefan", ""]]}, {"id": "2001.04192", "submitter": "Bernard Espinasse", "authors": "Rinaldo Lima, Bernard Espinasse (LIS, R2I), Fred Freitas", "title": "A logic-based relational learning approach to relation extraction: The\n  OntoILPER system", "comments": null, "journal-ref": "Engineering Applications of Artificial Intelligence, Elsevier,\n  2019, 78, pp.142-157", "doi": "10.1016/j.engappai.2018.11.001", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation Extraction (RE), the task of detecting and characterizing semantic\nrelations between entities in text, has gained much importance in the last two\ndecades, mainly in the biomedical domain. Many papers have been published on\nRelation Extraction using supervised machine learning techniques. Most of these\ntechniques rely on statistical methods, such as feature-based and\ntree-kernels-based methods. Such statistical learning techniques are usually\nbased on a propositional hypothesis space for representing examples, i.e., they\nemploy an attribute-value representation of features. This kind of\nrepresentation has some drawbacks, particularly in the extraction of complex\nrelations which demand more contextual information about the involving\ninstances, i.e., it is not able to effectively capture structural information\nfrom parse trees without loss of information. In this work, we present\nOntoILPER, a logic-based relational learning approach to Relation Extraction\nthat uses Inductive Logic Programming for generating extraction models in the\nform of symbolic extraction rules. OntoILPER takes profit of a rich relational\nrepresentation of examples, which can alleviate the aforementioned drawbacks.\nThe proposed relational approach seems to be more suitable for Relation\nExtraction than statistical ones for several reasons that we argue. Moreover,\nOntoILPER uses a domain ontology that guides the background knowledge\ngeneration process and is used for storing the extracted relation instances.\nThe induced extraction rules were evaluated on three protein-protein\ninteraction datasets from the biomedical domain. The performance of OntoILPER\nextraction models was compared with other state-of-the-art RE systems. The\nencouraging results seem to demonstrate the effectiveness of the proposed\nsolution.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 12:47:49 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Lima", "Rinaldo", "", "LIS, R2I"], ["Espinasse", "Bernard", "", "LIS, R2I"], ["Freitas", "Fred", ""]]}, {"id": "2001.04219", "submitter": "Markus Hecher", "authors": "Markus Hecher, Michael Morak, Stefan Woltran", "title": "Structural Decompositions of Epistemic Logic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.CL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epistemic logic programs (ELPs) are a popular generalization of standard\nAnswer Set Programming (ASP) providing means for reasoning over answer sets\nwithin the language. This richer formalism comes at the price of higher\ncomputational complexity reaching up to the fourth level of the polynomial\nhierarchy. However, in contrast to standard ASP, dedicated investigations\ntowards tractability have not been undertaken yet. In this paper, we give first\nresults in this direction and show that central ELP problems can be solved in\nlinear time for ELPs exhibiting structural properties in terms of bounded\ntreewidth. We also provide a full dynamic programming algorithm that adheres to\nthese bounds. Finally, we show that applying treewidth to a novel dependency\nstructure---given in terms of epistemic literals---allows to bound the number\nof ASP solver calls in typical ELP solving procedures.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 13:16:13 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Hecher", "Markus", ""], ["Morak", "Michael", ""], ["Woltran", "Stefan", ""]]}, {"id": "2001.04233", "submitter": "Mikael Zayenz Lagerkvist", "authors": "Mikael Zayenz Lagerkvist", "title": "State Representation and Polyomino Placement for the Game Patchwork", "comments": "In ModRef 2019, The 18th workshop on Constraint Modelling and\n  Reformulation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Modern board games are a rich source of entertainment for many people, but\nalso contain interesting and challenging structures for game playing research\nand implementing game playing agents. This paper studies the game Patchwork, a\ntwo player strategy game using polyomino tile drafting and placement. The core\npolyomino placement mechanic is implemented in a constraint model using regular\nconstraints, extending and improving the model in (Lagerkvist, Pesant, 2008)\nwith: explicit rotation handling; optional placements; and new constraints for\nresource usage. Crucial for implementing good game playing agents is to have\ngreat heuristics for guiding the search when faced with large branching\nfactors. This paper divides placing tiles into two parts: a policy used for\nplacing parts and an evaluation used to select among different placements.\nPolicies are designed based on classical packing literature as well as common\nstandard constraint programming heuristics. For evaluation, global propagation\nguided regret is introduced, choosing placements based on not ruling out later\nplacements. Extensive evaluations are performed, showing the importance of\nusing a good evaluation and that the proposed global propagation guided regret\nis a very effective guide.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 13:29:38 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Lagerkvist", "Mikael Zayenz", ""]]}, {"id": "2001.04238", "submitter": "Mikael Zayenz Lagerkvist", "authors": "Mikael Zayenz Lagerkvist", "title": "Nmbr9 as a Constraint Programming Challenge", "comments": "Abstract at the 25th International Conference on Principles and\n  Practice of Constraint Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Modern board games are a rich source of interesting and new challenges for\ncombinatorial problems. The game Nmbr9 is a solitaire style puzzle game using\npolyominoes. The rules of the game are simple to explain, but modelling the\ngame effectively using constraint programming is hard. This abstract presents\nthe game, contributes new generalized variants of the game suitable for\nbenchmarking and testing, and describes a model for the presented variants. The\nquestion of the top possible score in the standard game is an open challenge.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 13:40:49 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Lagerkvist", "Mikael Zayenz", ""]]}, {"id": "2001.04242", "submitter": "James Smith", "authors": "James E. Smith", "title": "(Newtonian) Space-Time Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The space-time (s-t) algebra provides a mathematical model for communication\nand computation using values encoded as events in discretized linear\n(Newtonian) time. Consequently, the input-output behavior of s-t algebra and\nimplemented functions are consistent with the flow of time. The s-t algebra and\nfunctions are formally defined. A network design framework for s-t functions is\ndescribed, and the design of temporal neural networks, a form of spiking neural\nnetworks, is discussed as an extended case study. Finally, the relationship\nwith Allen's interval algebra is briefly discussed.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 20:40:56 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 00:54:33 GMT"}, {"version": "v3", "created": "Mon, 20 Jan 2020 17:58:12 GMT"}, {"version": "v4", "created": "Sat, 25 Apr 2020 13:30:14 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Smith", "James E.", ""]]}, {"id": "2001.04270", "submitter": "Joel Colloc", "authors": "Jo\\\"el Colloc (IDEES)", "title": "Perspectives and Ethics of the Autonomous Artificial Thinking Systems", "comments": "The 28th International Conference on Systems Research, Informatics\n  and Cybernetics, Symposium on Spotlight Research in Modelling & Simulation of\n  Physical & Biological Systems Depending on Space, Time, Retardation,\n  Anticipation, Aug 2016, Baden-Baden, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The feasibility of autonomous artificial thinking systems needs to compare\nthe way the human beings acquire their information and develops the thought\nwith the current capacities of the autonomous information systems. Our model\nuses four hierarchies: the hierarchy of information systems, the cognitive\nhierarchy, the linguistic hierarchy and the digital informative hierarchy that\ncombines artificial intelligence, the power of computers models, methods and\ntools to develop autonomous information systems. The question of the capability\nof autonomous system to provide a form of artificial thought arises with the\nethical consequences on the social life and the perspective of transhumanism.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:23:21 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Colloc", "Jo\u00ebl", "", "IDEES"]]}, {"id": "2001.04326", "submitter": "Olegs Verhodubs", "authors": "Olegs Verhodubs", "title": "Merging of Ontologies Through Merging of Their Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology merging is important, but not always effective. The main reason, why\nontology merging is not effective, is that ontology merging is performed\nwithout considering goals. Goals define the way, in which ontologies to be\nmerged more effectively. The paper illustrates ontology merging by means of\nrules, which are generated from these ontologies. This is necessary for further\nuse in expert systems.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 15:08:10 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Verhodubs", "Olegs", ""]]}, {"id": "2001.04335", "submitter": "Jessica Whittlestone", "authors": "Carina Prunkl and Jess Whittlestone", "title": "Beyond Near- and Long-Term: Towards a Clearer Account of Research\n  Priorities in AI Ethics and Society", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One way of carving up the broad \"AI ethics and society\" research space that\nhas emerged in recent years is to distinguish between \"near-term\" and\n\"long-term\" research. While such ways of breaking down the research space can\nbe useful, we put forward several concerns about the near/long-term distinction\ngaining too much prominence in how research questions and priorities are\nframed. We highlight some ambiguities and inconsistencies in how the\ndistinction is used, and argue that while there are differing priorities within\nthis broad research community, these differences are not well-captured by the\nnear/long-term distinction. We unpack the near/long-term distinction into four\ndifferent dimensions, and propose some ways that researchers can communicate\nmore clearly about their work and priorities using these dimensions. We suggest\nthat moving towards a more nuanced conversation about research priorities can\nhelp establish new opportunities for collaboration, aid the development of more\nconsistent and coherent research agendas, and enable identification of\npreviously neglected research areas.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 15:22:42 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 12:18:20 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Prunkl", "Carina", ""], ["Whittlestone", "Jess", ""]]}, {"id": "2001.04344", "submitter": "Olfa Nasraoui", "authors": "Pegah Sagheb Haghighi, Olurotimi Seton, Olfa Nasraoui", "title": "An Explainable Autoencoder For Collaborative Filtering Recommendation", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders are a common building block of Deep Learning architectures,\nwhere they are mainly used for representation learning. They have also been\nsuccessfully used in Collaborative Filtering (CF) recommender systems to\npredict missing ratings. Unfortunately, like all black box machine learning\nmodels, they are unable to explain their outputs. Hence, while predictions from\nan Autoencoder-based recommender system might be accurate, it might not be\nclear to the user why a recommendation was generated. In this work, we design\nan explainable recommendation system using an Autoencoder model whose\npredictions can be explained using the neighborhood based explanation style.\nOur preliminary work can be considered to be the first step towards an\nexplainable deep learning architecture based on Autoencoders.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 23:55:30 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Haghighi", "Pegah Sagheb", ""], ["Seton", "Olurotimi", ""], ["Nasraoui", "Olfa", ""]]}, {"id": "2001.04377", "submitter": "Minae Kwon", "authors": "Minae Kwon, Erdem Biyik, Aditi Talati, Karan Bhasin, Dylan P. Losey,\n  Dorsa Sadigh", "title": "When Humans Aren't Optimal: Robots that Collaborate with Risk-Aware\n  Humans", "comments": "ACM/IEEE International Conference on Human-Robot Interaction", "journal-ref": null, "doi": "10.1145/3319502.3374832", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to collaborate safely and efficiently, robots need to anticipate how\ntheir human partners will behave. Some of today's robots model humans as if\nthey were also robots, and assume users are always optimal. Other robots\naccount for human limitations, and relax this assumption so that the human is\nnoisily rational. Both of these models make sense when the human receives\ndeterministic rewards: i.e., gaining either $100 or $130 with certainty. But in\nreal world scenarios, rewards are rarely deterministic. Instead, we must make\nchoices subject to risk and uncertainty--and in these settings, humans exhibit\na cognitive bias towards suboptimal behavior. For example, when deciding\nbetween gaining $100 with certainty or $130 only 80% of the time, people tend\nto make the risk-averse choice--even though it leads to a lower expected gain!\nIn this paper, we adopt a well-known Risk-Aware human model from behavioral\neconomics called Cumulative Prospect Theory and enable robots to leverage this\nmodel during human-robot interaction (HRI). In our user studies, we offer\nsupporting evidence that the Risk-Aware model more accurately predicts\nsuboptimal human behavior. We find that this increased modeling accuracy\nresults in safer and more efficient human-robot collaboration. Overall, we\nextend existing rational human models so that collaborative robots can\nanticipate and plan around suboptimal human behavior during HRI.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 16:27:46 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Kwon", "Minae", ""], ["Biyik", "Erdem", ""], ["Talati", "Aditi", ""], ["Bhasin", "Karan", ""], ["Losey", "Dylan P.", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "2001.04417", "submitter": "Florian Seiffarth", "authors": "Florian Seiffarth, Tamas Horvath and Stefan Wrobel", "title": "Maximal Closed Set and Half-Space Separations in Finite Closure Systems", "comments": "An early version of this paper was presented at ECML/PKDD 2019 and\n  has appeared in the Lecture Notes in Computer Science, Machine Learning and\n  Knowledge Discovery in Databases - European Conference, ECML PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several problems of artificial intelligence, such as predictive learning,\nformal concept analysis or inductive logic programming, can be viewed as a\nspecial case of half-space separation in abstract closure systems over finite\nground sets. For the typical scenario that the closure system is given via a\nclosure operator, we show that the half-space separation problem is\nNP-complete. As a first approach to overcome this negative result, we relax the\nproblem to maximal closed set separation, give a greedy algorithm solving this\nproblem with a linear number of closure operator calls, and show that this\nbound is sharp. For a second direction, we consider Kakutani closure systems\nand prove that they are algorithmically characterized by the greedy algorithm.\nAs a first special case of the general problem setting, we consider Kakutani\nclosure systems over graphs, generalize a fundamental characterization result\nbased on the Pasch axiom to graph structured partitioning of finite sets, and\ngive a sufficient condition for this kind of closures systems in terms of graph\nminors. For a second case, we then focus on closure systems over finite\nlattices, give an improved adaptation of the greedy algorithm for this special\ncase, and present two applications concerning formal concept and subsumption\nlattices. We also report some experimental results to demonstrate the practical\nusefulness of our algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 17:34:47 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 10:06:19 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Seiffarth", "Florian", ""], ["Horvath", "Tamas", ""], ["Wrobel", "Stefan", ""]]}, {"id": "2001.04418", "submitter": "Michiel Van Der Meer", "authors": "Michiel van der Meer, Matteo Pirotta, Elia Bruni", "title": "Exploiting Language Instructions for Interpretable and Compositional\n  Reinforcement Learning", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an alternative approach to making an agent\ncompositional through the use of a diagnostic classifier. Because of the need\nfor explainable agents in automated decision processes, we attempt to interpret\nthe latent space from an RL agent to identify its current objective in a\ncomplex language instruction. Results show that the classification process\ncauses changes in the hidden states which makes them more easily interpretable,\nbut also causes a shift in zero-shot performance to novel instructions. Lastly,\nwe limit the supervisory signal on the classification, and observe a similar\nbut less notable effect.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 17:35:56 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["van der Meer", "Michiel", ""], ["Pirotta", "Matteo", ""], ["Bruni", "Elia", ""]]}, {"id": "2001.04425", "submitter": "Hiba Arnaout", "authors": "Hiba Arnaout, Simon Razniewski, Gerhard Weikum, and Jeff Z. Pan", "title": "Negative Statements Considered Useful", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases (KBs) about notable entities and their properties are an\nimportant asset in applications such as search, question answering and\ndialogue. All popular KBs capture virtually only positive statements, and\nabstain from taking any stance on statements not stored in the KB. This paper\nmakes the case for explicitly stating salient statements that do not hold.\nNegative statements are useful to overcome limitations of question answering,\nand can often contribute to informative summaries of entities. Due to the\nabundance of such invalid statements, any effort to compile them needs to\naddress ranking by saliency. We present a statistical inference method for\ncompiling and ranking negative statements,based on expectations from positive\nstatements of related entities in peer groups. Experimental results, with a\nvariety of datasets, show that the method can effectively discover notable\nnegative statements, and extrinsic studies underline their usefulness for\nentity summarization. Datasets and code are released as resources for further\nresearch.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 17:49:37 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 14:42:40 GMT"}, {"version": "v3", "created": "Mon, 20 Jan 2020 14:45:01 GMT"}, {"version": "v4", "created": "Tue, 8 Sep 2020 09:00:13 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Arnaout", "Hiba", ""], ["Razniewski", "Simon", ""], ["Weikum", "Gerhard", ""], ["Pan", "Jeff Z.", ""]]}, {"id": "2001.04432", "submitter": "Michael Skinner", "authors": "Michael A. Skinner, Lakshmi Raman, Neel Shah, Abdelaziz Farhat,\n  Sriraam Natarajan", "title": "A Preliminary Approach for Learning Relational Policies for the\n  Management of Critically Ill Children", "comments": "6 pages, 1 figure, presented at the 2020 AAAI StarAI workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased use of electronic health records has made possible the\nautomated extraction of medical policies from patient records to aid in the\ndevelopment of clinical decision support systems. We adapted a boosted\nStatistical Relational Learning (SRL) framework to learn probabilistic rules\nfrom clinical hospital records for the management of physiologic parameters of\nchildren with severe cardiac or respiratory failure who were managed with\nextracorporeal membrane oxygenation. In this preliminary study, the results\nwere promising. In particular, the algorithm returned logic rules for medical\nactions that are consistent with medical reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:02:34 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Skinner", "Michael A.", ""], ["Raman", "Lakshmi", ""], ["Shah", "Neel", ""], ["Farhat", "Abdelaziz", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "2001.04465", "submitter": "Andreea Bobu", "authors": "Andreea Bobu, Dexter R.R. Scobee, Jaime F. Fisac, S. Shankar Sastry,\n  Anca D. Dragan", "title": "LESS is More: Rethinking Probabilistic Models of Human Behavior", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": "10.1145/3319502.3374811", "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots need models of human behavior for both inferring human goals and\npreferences, and predicting what people will do. A common model is the\nBoltzmann noisily-rational decision model, which assumes people approximately\noptimize a reward function and choose trajectories in proportion to their\nexponentiated reward. While this model has been successful in a variety of\nrobotics domains, its roots lie in econometrics, and in modeling decisions\namong different discrete options, each with its own utility or reward. In\ncontrast, human trajectories lie in a continuous space, with continuous-valued\nfeatures that influence the reward function. We propose that it is time to\nrethink the Boltzmann model, and design it from the ground up to operate over\nsuch trajectory spaces. We introduce a model that explicitly accounts for\ndistances between trajectories, rather than only their rewards. Rather than\neach trajectory affecting the decision independently, similar trajectories now\naffect the decision together. We start by showing that our model better\nexplains human behavior in a user study. We then analyze the implications this\nhas for robot inference, first in toy environments where we have ground truth\nand find more accurate inference, and finally for a 7DOF robot arm learning\nfrom user demonstrations.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:59:01 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Bobu", "Andreea", ""], ["Scobee", "Dexter R. R.", ""], ["Fisac", "Jaime F.", ""], ["Sastry", "S. Shankar", ""], ["Dragan", "Anca D.", ""]]}, {"id": "2001.04509", "submitter": "Lionel Robert", "authors": "Na Du, Feng Zhou, Elizabeth Pulver, Dawn M. Tilbury, Lionel P. Robert,\n  Anuj K. Pradhan, X. Jessie Yang", "title": "Examining the Effects of Emotional Valence and Arousal on Takeover\n  Performance in Conditionally Automated Driving", "comments": "28 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In conditionally automated driving, drivers have difficulty in takeover\ntransitions as they become increasingly decoupled from the operational level of\ndriving. Factors influencing takeover performance, such as takeover lead time\nand the engagement of non-driving related tasks, have been studied in the past.\nHowever, despite the important role emotions play in human-machine interaction\nand in manual driving, little is known about how emotions influence drivers\ntakeover performance. This study, therefore, examined the effects of emotional\nvalence and arousal on drivers takeover timeliness and quality in conditionally\nautomated driving. We conducted a driving simulation experiment with 32\nparticipants. Movie clips were played for emotion induction. Participants with\ndifferent levels of emotional valence and arousal were required to take over\ncontrol from automated driving, and their takeover time and quality were\nanalyzed. Results indicate that positive valence led to better takeover quality\nin the form of a smaller maximum resulting acceleration and a smaller maximum\nresulting jerk. However, high arousal did not yield an advantage in takeover\ntime. This study contributes to the literature by demonstrating how emotional\nvalence and arousal affect takeover performance. The benefits of positive\nemotions carry over from manual driving to conditionally automated driving\nwhile the benefits of arousal do not.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 19:28:15 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Du", "Na", ""], ["Zhou", "Feng", ""], ["Pulver", "Elizabeth", ""], ["Tilbury", "Dawn M.", ""], ["Robert", "Lionel P.", ""], ["Pradhan", "Anuj K.", ""], ["Yang", "X. Jessie", ""]]}, {"id": "2001.04529", "submitter": "Madan Ravi Ganesh", "authors": "Madan Ravi Ganesh and Jason J. Corso", "title": "Rethinking Curriculum Learning with Incremental Labels and Adaptive\n  Compensation", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like humans, deep networks have been shown to learn better when samples are\norganized and introduced in a meaningful order or curriculum. Conventional\ncurriculum learning schemes introduce samples in their order of difficulty.\nThis forces models to begin learning from a subset of the available data while\nadding the external overhead of evaluating the difficulty of samples. In this\nwork, we propose Learning with Incremental Labels and Adaptive Compensation\n(LILAC), a two-phase method that incrementally increases the number of unique\noutput labels rather than the difficulty of samples while consistently using\nthe entire dataset throughout training. In the first phase, Incremental Label\nIntroduction, we partition data into mutually exclusive subsets, one that\ncontains a subset of the ground-truth labels and another that contains the\nremaining data attached to a pseudo-label. Throughout the training process, we\nrecursively reveal unseen ground-truth labels in fixed increments until all the\nlabels are known to the model. In the second phase, Adaptive Compensation, we\noptimize the loss function using altered target vectors of previously\nmisclassified samples. The target vectors of such samples are modified to a\nsmoother distribution to help models learn better. On evaluating across three\nstandard image benchmarks, CIFAR-10, CIFAR-100, and STL-10, we show that LILAC\noutperforms all comparable baselines. Further, we detail the importance of\npacing the introduction of new labels to a model as well as the impact of using\na smooth target vector.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 21:00:46 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 14:24:06 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 16:00:02 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Ganesh", "Madan Ravi", ""], ["Corso", "Jason J.", ""]]}, {"id": "2001.04533", "submitter": "Arun Sathanur", "authors": "Kelsey Maass, Arun V Sathanur, Arif Khan, Robert Rallo", "title": "Street-level Travel-time Estimation via Aggregated Uber Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating temporal patterns in travel times along road segments in urban\nsettings is of central importance to traffic engineers and city planners. In\nthis work, we propose a methodology to leverage coarse-grained and aggregated\ntravel time data to estimate the street-level travel times of a given\nmetropolitan area. Our main focus is to estimate travel times along the\narterial road segments where relevant data are often unavailable. The central\nidea of our approach is to leverage easy-to-obtain, aggregated data sets with\nbroad spatial coverage, such as the data published by Uber Movement, as the\nfabric over which other expensive, fine-grained datasets, such as loop counter\nand probe data, can be overlaid. Our proposed methodology uses a graph\nrepresentation of the road network and combines several techniques such as\ngraph-based routing, trip sampling, graph sparsification, and least-squares\noptimization to estimate the street-level travel times. Using sampled trips and\nweighted shortest-path routing, we iteratively solve constrained least-squares\nproblems to obtain the travel time estimates. We demonstrate our method on the\nLos Angeles metropolitan-area street network, where aggregated travel time data\nis available for trips between traffic analysis zones. Additionally, we present\ntechniques to scale our approach via a novel graph pseudo-sparsification\ntechnique.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 21:14:38 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Maass", "Kelsey", ""], ["Sathanur", "Arun V", ""], ["Khan", "Arif", ""], ["Rallo", "Robert", ""]]}, {"id": "2001.04566", "submitter": "Pedro Zuidberg Dos Martires", "authors": "Pedro Zuidberg Dos Martires, Samuel Kolb", "title": "Monte Carlo Anti-Differentiation for Approximate Weighted Model\n  Integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic inference in the hybrid domain, i.e. inference over\ndiscrete-continuous domains, requires tackling two well known #P-hard problems\n1)~weighted model counting (WMC) over discrete variables and 2)~integration\nover continuous variables. For both of these problems inference techniques have\nbeen developed separately in order to manage their #P-hardness, such as\nknowledge compilation for WMC and Monte Carlo (MC) methods for (approximate)\nintegration in the continuous domain. Weighted model integration (WMI), the\nextension of WMC to the hybrid domain, has been proposed as a formalism to\nstudy probabilistic inference over discrete and continuous variables alike.\nRecently developed WMI solvers have focused on exploiting structure in WMI\nproblems, for which they rely on symbolic integration to find the primitive of\nan integrand, i.e. to perform anti-differentiation. To combine these advances\nwith state-of-the-art Monte Carlo integration techniques, we introduce\n\\textit{Monte Carlo anti-differentiation} (MCAD), which computes MC\napproximations of anti-derivatives. In our empirical evaluation we substitute\nthe exact symbolic integration backend in an existing WMI solver with an MCAD\nbackend. Our experiments show that that equipping existing WMI solvers with\nMCAD yields a fast yet reliable approximate inference scheme.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 23:45:10 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Martires", "Pedro Zuidberg Dos", ""], ["Kolb", "Samuel", ""]]}, {"id": "2001.04669", "submitter": "Ami Sakakibara", "authors": "Ryohei Oura, Ami Sakakibara, Toshimitsu Ushio", "title": "Reinforcement Learning of Control Policy for Linear Temporal Logic\n  Specifications Using Limit-Deterministic Generalized B\\\"uchi Automata", "comments": "7 pages, 6 figures; an extended version of a manuscript accepted to\n  IEEE L-CSS", "journal-ref": null, "doi": "10.1109/LCSYS.2020.2980552", "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter proposes a novel reinforcement learning method for the synthesis\nof a control policy satisfying a control specification described by a linear\ntemporal logic formula. We assume that the controlled system is modeled by a\nMarkov decision process (MDP). We convert the specification to a\nlimit-deterministic generalized B\\\"uchi automaton (LDGBA) with several\naccepting sets that accepts all infinite sequences satisfying the formula. The\nLDGBA is augmented so that it explicitly records the previous visits to\naccepting sets. We take a product of the augmented LDGBA and the MDP, based on\nwhich we define a reward function. The agent gets rewards whenever state\ntransitions are in an accepting set that has not been visited for a certain\nnumber of steps. Consequently, sparsity of rewards is relaxed and optimal\ncirculations among the accepting sets are learned. We show that the proposed\nmethod can learn an optimal policy when the discount factor is sufficiently\nclose to one.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 08:55:56 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 07:25:09 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 07:39:51 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Oura", "Ryohei", ""], ["Sakakibara", "Ami", ""], ["Ushio", "Toshimitsu", ""]]}, {"id": "2001.04678", "submitter": "David Balduzzi", "authors": "David Balduzzi, Wojciech M Czarnecki, Thomas W Anthony, Ian M Gemp,\n  Edward Hughes, Joel Z Leibo, Georgios Piliouras, Thore Graepel", "title": "Smooth markets: A basic mechanism for organizing gradient-based learners", "comments": "18 pages, 3 figures", "journal-ref": "ICLR 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the success of modern machine learning, it is becoming increasingly\nimportant to understand and control how learning algorithms interact.\nUnfortunately, negative results from game theory show there is little hope of\nunderstanding or controlling general n-player games. We therefore introduce\nsmooth markets (SM-games), a class of n-player games with pairwise zero sum\ninteractions. SM-games codify a common design pattern in machine learning that\nincludes (some) GANs, adversarial training, and other recent algorithms. We\nshow that SM-games are amenable to analysis and optimization using first-order\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 09:19:39 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 09:09:22 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Balduzzi", "David", ""], ["Czarnecki", "Wojciech M", ""], ["Anthony", "Thomas W", ""], ["Gemp", "Ian M", ""], ["Hughes", "Edward", ""], ["Leibo", "Joel Z", ""], ["Piliouras", "Georgios", ""], ["Graepel", "Thore", ""]]}, {"id": "2001.04701", "submitter": "Christoph Benzm\\\"uller", "authors": "Christoph Benzm\\\"uller", "title": "A (Simplified) Supreme Being Necessarily Exists, says the Computer:\n  Computationally Explored Variants of G\\\"odel's Ontological Argument", "comments": "11 pages, 11 figures", "journal-ref": "KR 2020 -- The 17th International Conference on Principles of\n  Knowledge Representation and Reasoning, Rhodes, Greece, September 12-18, 2020", "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CL math.GN math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach to universal (meta-)logical reasoning in classical higher-order\nlogic is employed to explore and study simplifications of Kurt G\\\"odel's modal\nontological argument. Some argument premises are modified, others are dropped,\nmodal collapse is avoided and validity is shown already in weak modal logics K\nand T. Key to the gained simplifications of G\\\"odel's original theory is the\nexploitation of a link to the notions of filter and ultrafilter from topology.\nThe paper illustrates how modern knowledge representation and reasoning\ntechnology for quantified non-classical logics can contribute new knowledge to\nother disciplines. The contributed material is also well suited to support\nteaching of non-trivial logic formalisms in classroom.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 10:26:51 GMT"}, {"version": "v10", "created": "Sun, 14 Jun 2020 06:25:33 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 12:16:56 GMT"}, {"version": "v3", "created": "Mon, 27 Jan 2020 09:27:58 GMT"}, {"version": "v4", "created": "Sun, 9 Feb 2020 08:32:22 GMT"}, {"version": "v5", "created": "Tue, 11 Feb 2020 10:13:53 GMT"}, {"version": "v6", "created": "Sat, 15 Feb 2020 17:06:34 GMT"}, {"version": "v7", "created": "Thu, 12 Mar 2020 08:52:54 GMT"}, {"version": "v8", "created": "Wed, 25 Mar 2020 14:43:57 GMT"}, {"version": "v9", "created": "Mon, 4 May 2020 15:17:25 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Benzm\u00fcller", "Christoph", ""]]}, {"id": "2001.04721", "submitter": "Byoung Chul Ko Prof.", "authors": "Sangwon Kim, Mira Jeong, Byoung Chul Ko", "title": "Interpretation and Simplification of Deep Forest", "comments": "Major issues on the experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new method for interpreting and simplifying a black box\nmodel of a deep random forest (RF) using a proposed rule elimination. In deep\nRF, a large number of decision trees are connected to multiple layers, thereby\nmaking an analysis difficult. It has a high performance similar to that of a\ndeep neural network (DNN), but achieves a better generalizability. Therefore,\nin this study, we consider quantifying the feature contributions and frequency\nof the fully trained deep RF in the form of a decision rule set. The feature\ncontributions provide a basis for determining how features affect the decision\nprocess in a rule set. Model simplification is achieved by eliminating\nunnecessary rules by measuring the feature contributions. Consequently, the\nsimplified model has fewer parameters and rules than before. Experiment results\nhave shown that a feature contribution analysis allows a black box model to be\ndecomposed for quantitatively interpreting a rule set. The proposed method was\nsuccessfully applied to various deep RF models and benchmark datasets while\nmaintaining a robust performance despite the elimination of a large number of\nrules.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 11:30:26 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 04:09:22 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 06:25:48 GMT"}, {"version": "v4", "created": "Sat, 12 Dec 2020 04:35:05 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Kim", "Sangwon", ""], ["Jeong", "Mira", ""], ["Ko", "Byoung Chul", ""]]}, {"id": "2001.04757", "submitter": "Evgeny Kharlamov", "authors": "Henrik Forssell and Evgeny Kharlamov and Evgenij Thorstensen", "title": "On Equivalence and Cores for Incomplete Databases in Open and Closed\n  Worlds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data exchange heavily relies on the notion of incomplete database instances.\nSeveral semantics for such instances have been proposed and include open (OWA),\nclosed (CWA), and open-closed (OCWA) world. For all these semantics important\nquestions are: whether one incomplete instance semantically implies another;\nwhen two are semantically equivalent; and whether a smaller or smallest\nsemantically equivalent instance exists. For OWA and CWA these questions are\nfully answered. For several variants of OCWA, however, they remain open. In\nthis work we adress these questions for Closed Powerset semantics and the OCWA\nsemantics of Libkin and Sirangelo, 2011. We define a new OCWA semantics, called\nOCWA*, in terms of homomorphic covers that subsumes both semantics, and\ncharacterize semantic implication and equivalence in terms of such covers. This\ncharacterization yields a guess-and-check algorithm to decide equivalence, and\nshows that the problem is NP-complete. For the minimization problem we show\nthat for several common notions of minimality there is in general no unique\nminimal equivalent instance for Closed Powerset semantics, and consequently not\nfor the more expressive OCWA* either. However, for Closed Powerset semantics we\nshow that one can find, for any incomplete database, a unique finite set of its\nsubinstances which are subinstances (up to renaming of nulls) of all instances\nsemantically equivalent to the original incomplete one. We study properties of\nthis set, and extend the analysis to OCWA*.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 13:10:01 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Forssell", "Henrik", ""], ["Kharlamov", "Evgeny", ""], ["Thorstensen", "Evgenij", ""]]}, {"id": "2001.04809", "submitter": "Joshua Kim", "authors": "Joshua Y. Kim, Greyson Y. Kim and Kalina Yacef", "title": "Detecting depression in dyadic conversations with multimodal narratives\n  and visualizations", "comments": "12 pages", "journal-ref": "AI 2019: Advances in Artificial Intelligence. AI 2019 vol 11919", "doi": "10.1007/978-3-030-35288-2_25", "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversations contain a wide spectrum of multimodal information that gives us\nhints about the emotions and moods of the speaker. In this paper, we developed\na system that supports humans to analyze conversations. Our main contribution\nis the identification of appropriate multimodal features and the integration of\nsuch features into verbatim conversation transcripts. We demonstrate the\nability of our system to take in a wide range of multimodal information and\nautomatically generated a prediction score for the depression state of the\nindividual. Our experiments showed that this approach yielded better\nperformance than the baseline model. Furthermore, the multimodal narrative\napproach makes it easy to integrate learnings from other disciplines, such as\nconversational analysis and psychology. Lastly, this interdisciplinary and\nautomated approach is a step towards emulating how practitioners record the\ncourse of treatment as well as emulating how conversational analysts have been\nanalyzing conversations by hand.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 10:47:13 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 23:16:48 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kim", "Joshua Y.", ""], ["Kim", "Greyson Y.", ""], ["Yacef", "Kalina", ""]]}, {"id": "2001.04835", "submitter": "Maarten Bieshaar", "authors": "Kristina Scharei, Florian Heidecker, Maarten Bieshaar", "title": "Knowledge Representations in Technical Systems -- A Taxonomy", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recent usage of technical systems in human-centric environments leads to\nthe question, how to teach technical systems, e.g., robots, to understand,\nlearn, and perform tasks desired by the human. Therefore, an accurate\nrepresentation of knowledge is essential for the system to work as expected.\nThis article mainly gives insight into different knowledge representation\ntechniques and their categorization into various problem domains in artificial\nintelligence. Additionally, applications of presented knowledge representations\nare introduced in everyday robotics tasks. By means of the provided taxonomy,\nthe search for a proper knowledge representation technique regarding a specific\nproblem should be facilitated.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 15:00:09 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 07:07:10 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Scharei", "Kristina", ""], ["Heidecker", "Florian", ""], ["Bieshaar", "Maarten", ""]]}, {"id": "2001.04841", "submitter": "Song Cheng", "authors": "Song Cheng, Qi Liu, Enhong Chen", "title": "Domain Adaption for Knowledge Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of online education system, knowledge tracing\nwhich aims at predicting students' knowledge state is becoming a critical and\nfundamental task in personalized education. Traditionally, existing methods are\ndomain-specified. However, there are a larger number of domains (e.g.,\nsubjects, schools) in the real world and the lacking of data in some domains,\nhow to utilize the knowledge and information in other domains to help train a\nknowledge tracing model for target domains is increasingly important. We refer\nto this problem as domain adaptation for knowledge tracing (DAKT) which\ncontains two aspects: (1) how to achieve great knowledge tracing performance in\neach domain. (2) how to transfer good performed knowledge tracing model between\ndomains. To this end, in this paper, we propose a novel adaptable framework,\nnamely adaptable knowledge tracing (AKT) to address the DAKT problem.\nSpecifically, for the first aspect, we incorporate the educational\ncharacteristics (e.g., slip, guess, question texts) based on the deep knowledge\ntracing (DKT) to obtain a good performed knowledge tracing model. For the\nsecond aspect, we propose and adopt three domain adaptation processes. First,\nwe pre-train an auto-encoder to select useful source instances for target model\ntraining. Second, we minimize the domain-specific knowledge state distribution\ndiscrepancy under maximum mean discrepancy (MMD) measurement to achieve domain\nadaptation. Third, we adopt fine-tuning to deal with the problem that the\noutput dimension of source and target domain are different to make the model\nsuitable for target domains. Extensive experimental results on two private\ndatasets and seven public datasets clearly prove the effectiveness of AKT for\ngreat knowledge tracing performance and its superior transferable ability.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 15:04:48 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Cheng", "Song", ""], ["Liu", "Qi", ""], ["Chen", "Enhong", ""]]}, {"id": "2001.04861", "submitter": "Xueru Zhang", "authors": "Xueru Zhang, Mingyan Liu", "title": "Fairness in Learning-Based Sequential Decision Algorithms: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic fairness in decision-making has been studied extensively in\nstatic settings where one-shot decisions are made on tasks such as\nclassification. However, in practice most decision-making processes are of a\nsequential nature, where decisions made in the past may have an impact on\nfuture data. This is particularly the case when decisions affect the\nindividuals or users generating the data used for future decisions. In this\nsurvey, we review existing literature on the fairness of data-driven sequential\ndecision-making. We will focus on two types of sequential decisions: (1) past\ndecisions have no impact on the underlying user population and thus no impact\non future data; (2) past decisions have an impact on the underlying user\npopulation and therefore the future data, which can then impact future\ndecisions. In each case the impact of various fairness interventions on the\nunderlying population is examined.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 15:49:57 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Zhang", "Xueru", ""], ["Liu", "Mingyan", ""]]}, {"id": "2001.04959", "submitter": "Alexander Gorban", "authors": "Alexander N. Gorban, Valery A. Makarov, Ivan Y. Tyukin", "title": "High--Dimensional Brain in a High-Dimensional World: Blessing of\n  Dimensionality", "comments": "18 pages, 5 figures", "journal-ref": "Entropy 2020, 22(1), 82", "doi": "10.3390/e22010082", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High-dimensional data and high-dimensional representations of reality are\ninherent features of modern Artificial Intelligence systems and applications of\nmachine learning. The well-known phenomenon of the \"curse of dimensionality\"\nstates: many problems become exponentially difficult in high dimensions.\nRecently, the other side of the coin, the \"blessing of dimensionality\", has\nattracted much attention. It turns out that generic high-dimensional datasets\nexhibit fairly simple geometric properties. Thus, there is a fundamental\ntradeoff between complexity and simplicity in high dimensional spaces. Here we\npresent a brief explanatory review of recent ideas, results and hypotheses\nabout the blessing of dimensionality and related simplifying effects relevant\nto machine learning and neuroscience.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 18:40:51 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Gorban", "Alexander N.", ""], ["Makarov", "Valery A.", ""], ["Tyukin", "Ivan Y.", ""]]}, {"id": "2001.04974", "submitter": "Chuteng Zhou", "authors": "Chuteng Zhou, Prad Kadambi, Matthew Mattina, Paul N. Whatmough", "title": "Noisy Machines: Understanding Noisy Neural Networks and Enhancing\n  Robustness to Analog Hardware Errors Using Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning has brought forth a wave of interest in computer\nhardware design to better meet the high demands of neural network inference. In\nparticular, analog computing hardware has been heavily motivated specifically\nfor accelerating neural networks, based on either electronic, optical or\nphotonic devices, which may well achieve lower power consumption than\nconventional digital electronics. However, these proposed analog accelerators\nsuffer from the intrinsic noise generated by their physical components, which\nmakes it challenging to achieve high accuracy on deep neural networks. Hence,\nfor successful deployment on analog accelerators, it is essential to be able to\ntrain deep neural networks to be robust to random continuous noise in the\nnetwork weights, which is a somewhat new challenge in machine learning. In this\npaper, we advance the understanding of noisy neural networks. We outline how a\nnoisy neural network has reduced learning capacity as a result of loss of\nmutual information between its input and output. To combat this, we propose\nusing knowledge distillation combined with noise injection during training to\nachieve more noise robust networks, which is demonstrated experimentally across\ndifferent networks and datasets, including ImageNet. Our method achieves models\nwith as much as two times greater noise tolerance compared with the previous\nbest attempts, which is a significant step towards making analog hardware\npractical for deep learning.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 18:59:48 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Zhou", "Chuteng", ""], ["Kadambi", "Prad", ""], ["Mattina", "Matthew", ""], ["Whatmough", "Paul N.", ""]]}, {"id": "2001.05012", "submitter": "Kobi Cohen", "authors": "Dor Livne and Kobi Cohen", "title": "PoPS: Policy Pruning and Shrinking for Deep Reinforcement Learning", "comments": "This paper has been accepted for publication in the IEEE Journal of\n  Selected Topics in Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of deep neural networks (DNNs) for function approximation\nin reinforcement learning has triggered the development of Deep Reinforcement\nLearning (DRL) algorithms in various fields, such as robotics, computer games,\nnatural language processing, computer vision, sensing systems, and wireless\nnetworking. Unfortunately, DNNs suffer from high computational cost and memory\nconsumption, which limits the use of DRL algorithms in systems with limited\nhardware resources. In recent years, pruning algorithms have demonstrated\nconsiderable success in reducing the redundancy of DNNs in classification\ntasks. However, existing algorithms suffer from a significant performance\nreduction in the DRL domain. In this paper, we develop the first effective\nsolution to the performance reduction problem of pruning in the DRL domain, and\nestablish a working algorithm, named Policy Pruning and Shrinking (PoPS), to\ntrain DRL models with strong performance while achieving a compact\nrepresentation of the DNN. The framework is based on a novel iterative policy\npruning and shrinking method that leverages the power of transfer learning when\ntraining the DRL model. We present an extensive experimental study that\ndemonstrates the strong performance of PoPS using the popular Cartpole, Lunar\nLander, Pong, and Pacman environments. Finally, we develop an open source\nsoftware for the benefit of researchers and developers in related fields.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 19:28:06 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Livne", "Dor", ""], ["Cohen", "Kobi", ""]]}, {"id": "2001.05065", "submitter": "Jacob Schrum", "authors": "Jake Gutierrez and Jacob Schrum", "title": "Generative Adversarial Network Rooms in Generative Graph Grammar\n  Dungeons for The Legend of Zelda", "comments": "Congress on Evolutionary Computation 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have demonstrated their ability to\nlearn patterns in data and produce new exemplars similar to, but different\nfrom, their training set in several domains, including video games. However,\nGANs have a fixed output size, so creating levels of arbitrary size for a\ndungeon crawling game is difficult. GANs also have trouble encoding semantic\nrequirements that make levels interesting and playable. This paper combines a\nGAN approach to generating individual rooms with a graph grammar approach to\ncombining rooms into a dungeon. The GAN captures design principles of\nindividual rooms, but the graph grammar organizes rooms into a global layout\nwith a sequence of obstacles determined by a designer. Room data from The\nLegend of Zelda is used to train the GAN. This approach is validated by a user\nstudy, showing that GAN dungeons are as enjoyable to play as a level from the\noriginal game, and levels generated with a graph grammar alone. However, GAN\ndungeons have rooms considered more complex, and plain graph grammar's dungeons\nare considered least complex and challenging. Only the GAN approach creates an\nextensive supply of both layouts and rooms, where rooms span across the\nspectrum of those seen in the training set to new creations merging design\nprinciples from multiple rooms.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 22:22:11 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 19:07:28 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Gutierrez", "Jake", ""], ["Schrum", "Jacob", ""]]}, {"id": "2001.05068", "submitter": "Aaron Tucker", "authors": "Aaron D. Tucker, Markus Anderljung, and Allan Dafoe", "title": "Social and Governance Implications of Improved Data Efficiency", "comments": "7 pages, 2 figures, accepted to Artificial Intelligence Ethics and\n  Society 2020", "journal-ref": null, "doi": "10.1145/3375627.3375863", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many researchers work on improving the data efficiency of machine learning.\nWhat would happen if they succeed? This paper explores the social-economic\nimpact of increased data efficiency. Specifically, we examine the intuition\nthat data efficiency will erode the barriers to entry protecting incumbent\ndata-rich AI firms, exposing them to more competition from data-poor firms. We\nfind that this intuition is only partially correct: data efficiency makes it\neasier to create ML applications, but large AI firms may have more to gain from\nhigher performing AI systems. Further, we find that the effect on privacy, data\nmarkets, robustness, and misuse are complex. For example, while it seems\nintuitive that misuse risk would increase along with data efficiency -- as more\nactors gain access to any level of capability -- the net effect crucially\ndepends on how much defensive measures are improved. More investigation into\ndata efficiency, as well as research into the \"AI production function\", will be\nkey to understanding the development of the AI industry and its societal\nimpacts.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 22:26:12 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Tucker", "Aaron D.", ""], ["Anderljung", "Markus", ""], ["Dafoe", "Allan", ""]]}, {"id": "2001.05087", "submitter": "Tristan Cazenave", "authors": "Tristan Cazenave", "title": "Monte Carlo Game Solver", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general algorithm to order moves so as to speedup exact game\nsolvers. It uses online learning of playout policies and Monte Carlo Tree\nSearch. The learned policy and the information in the Monte Carlo tree are used\nto order moves in game solvers. They improve greatly the solving time for\nmultiple games.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 00:20:13 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Cazenave", "Tristan", ""]]}, {"id": "2001.05198", "submitter": "Ondrej Kuzelka", "authors": "Ondrej Kuzelka, Yuyi Wang", "title": "Domain-Liftability of Relational Marginal Polytopes", "comments": "A preliminary version of a paper accepted to AISTATS 2020, presented\n  at the StarAI 2020 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study computational aspects of relational marginal polytopes which are\nstatistical relational learning counterparts of marginal polytopes, well-known\nfrom probabilistic graphical models. Here, given some first-order logic\nformula, we can define its relational marginal statistic to be the fraction of\ngroundings that make this formula true in a given possible world. For a list of\nfirst-order logic formulas, the relational marginal polytope is the set of all\npoints that correspond to the expected values of the relational marginal\nstatistics that are realizable. In this paper, we study the following two\nproblems: (i) Do domain-liftability results for the partition functions of\nMarkov logic networks (MLNs) carry over to the problem of relational marginal\npolytope construction? (ii) Is the relational marginal polytope containment\nproblem hard under some plausible complexity-theoretic assumptions? Our\npositive results have consequences for lifted weight learning of MLNs. In\nparticular, we show that weight learning of MLNs is domain-liftable whenever\nthe computation of the partition function of the respective MLNs is\ndomain-liftable (this result has not been rigorously proven before).\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 09:45:48 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Kuzelka", "Ondrej", ""], ["Wang", "Yuyi", ""]]}, {"id": "2001.05208", "submitter": "Vaishak Belle", "authors": "Vaishak Belle", "title": "SMT + ILP", "comments": "In AAAI Workshop: Statistical Relational Artificial Intelligence\n  (StarAI), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inductive logic programming (ILP) has been a deeply influential paradigm in\nAI, enjoying decades of research on its theory and implementations. As a\nnatural descendent of the fields of logic programming and machine learning, it\nadmits the incorporation of background knowledge, which can be very useful in\ndomains where prior knowledge from experts is available and can lead to a more\ndata-efficient learning regime. Be that as it may, the limitation to Horn\nclauses composed over Boolean variables is a very serious one. Many phenomena\noccurring in the real-world are best characterized using continuous entities,\nand more generally, mixtures of discrete and continuous entities. In this\nposition paper, we motivate a reconsideration of inductive declarative\nprogramming by leveraging satisfiability modulo theory technology.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 10:09:21 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Belle", "Vaishak", ""]]}, {"id": "2001.05214", "submitter": "Dell Zhang", "authors": "Dell Zhang, Andre Freitas, Dacheng Tao, Dawn Song", "title": "Proceedings of the AAAI-20 Workshop on Intelligent Process Automation\n  (IPA-20)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the AAAI-20 Workshop on Intelligent Process\nAutomation (IPA-20) which took place in New York, NY, USA on February 7th 2020.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 10:22:12 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 16:00:26 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 14:00:46 GMT"}, {"version": "v4", "created": "Mon, 19 Apr 2021 16:31:34 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Zhang", "Dell", ""], ["Freitas", "Andre", ""], ["Tao", "Dacheng", ""], ["Song", "Dawn", ""]]}, {"id": "2001.05263", "submitter": "Ondrej Kuzelka", "authors": "Timothy van Bremen, Ondrej Kuzelka", "title": "Approximate Weighted First-Order Model Counting: Exploiting Fast\n  Approximate Model Counters and Symmetry", "comments": "Presented at StarAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the symmetric weighted first-order model counting task and present\nApproxWFOMC, a novel anytime method for efficiently bounding the weighted\nfirst-order model count in the presence of an unweighted first-order model\ncounting oracle. The algorithm has applications to inference in a variety of\nfirst-order probabilistic representations, such as Markov logic networks and\nprobabilistic logic programs. Crucially for many applications, we make no\nassumptions on the form of the input sentence. Instead, our algorithm makes use\nof the symmetry inherent in the problem by imposing cardinality constraints on\nthe number of possible true groundings of a sentence's literals. Realising the\nfirst-order model counting oracle in practice using the approximate\nhashing-based model counter ApproxMC3, we show how our algorithm outperforms\nexisting approximate and exact techniques for inference in first-order\nprobabilistic models. We additionally provide PAC guarantees on the generated\nbounds.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 12:21:06 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["van Bremen", "Timothy", ""], ["Kuzelka", "Ondrej", ""]]}, {"id": "2001.05270", "submitter": "Mario Holubar", "authors": "Mario S. Holubar, Marco A. Wiering", "title": "Continuous-action Reinforcement Learning for Playing Racing Games:\n  Comparing SPG to PPO", "comments": "12 pages, 9 figures. Code is available at\n  https://github.com/mario-holubar/RacingRL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, a novel racing environment for OpenAI Gym is introduced. This\nenvironment operates with continuous action- and state-spaces and requires\nagents to learn to control the acceleration and steering of a car while\nnavigating a randomly generated racetrack. Different versions of two\nactor-critic learning algorithms are tested on this environment: Sampled Policy\nGradient (SPG) and Proximal Policy Optimization (PPO). An extension of SPG is\nintroduced that aims to improve learning performance by weighting action\nsamples during the policy update step. The effect of using experience replay\n(ER) is also investigated. To this end, a modification to PPO is introduced\nthat allows for training using old action samples by optimizing the actor in\nlog space. Finally, a new technique for performing ER is tested that aims to\nimprove learning speed without sacrificing performance by splitting the\ntraining into two parts, whereby networks are first trained using state\ntransitions from the replay buffer, and then using only recent experiences. The\nresults indicate that experience replay is not beneficial to PPO in continuous\naction spaces. The training of SPG seems to be more stable when actions are\nweighted. All versions of SPG outperform PPO when ER is used. The ER trick is\neffective at improving training speed on a computationally less intensive\nversion of SPG.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 12:30:57 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Holubar", "Mario S.", ""], ["Wiering", "Marco A.", ""]]}, {"id": "2001.05288", "submitter": "Joseph Tassone", "authors": "Joseph Tassone, Salimur Choudhury", "title": "A Comprehensive Survey on the Ambulance Routing and Location Problems", "comments": "30 pages,7 figures,16 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research, an extensive literature review was performed on the recent\ndevelopments of the ambulance routing problem (ARP) and ambulance location\nproblem (ALP). Both are respective modifications of the vehicle routing problem\n(VRP) and maximum covering problem (MCP), with modifications to objective\nfunctions and constraints. Although alike, a key distinction is emergency\nservice systems (EMS) are considered critical and the optimization of these has\nbecome all the more important as a result. Similar to their parent problems,\nthese are NP-hard and must resort to approximations if the space size is too\nlarge. Much of the current work has simply been on modifying existing systems\nthrough simulation to achieve a more acceptable result. There has been attempts\ntowards using meta-heuristics, though practical experimentation is lacking when\ncompared to VRP or MCP. The contributions of this work are a comprehensive\nsurvey of current methodologies, summarized models, and suggested future\nimprovements.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 05:33:11 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Tassone", "Joseph", ""], ["Choudhury", "Salimur", ""]]}, {"id": "2001.05291", "submitter": "Joseph Tassone", "authors": "Joseph Tassone, Geoffrey Pond, Salimur Choudhury", "title": "Algorithms for Optimizing Fleet Staging of Air Ambulances", "comments": "15 pages,6 figures,2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a disaster situation, air ambulance rapid response will often be the\ndetermining factor in patient survival. Obstacles intensify this circumstance,\nwith geographical remoteness and limitations in vehicle placement making it an\narduous task. Considering these elements, the arrangement of responders is a\ncritical decision of the utmost importance. Utilizing real mission data, this\nresearch structured an optimal coverage problem with integer linear\nprogramming. For accurate comparison, the Gurobi optimizer was programmed with\nthe developed model and timed for performance. A solution implementing base\nranking followed by both local and Tabu search-based algorithms was created.\nThe local search algorithm proved insufficient for maximizing coverage, while\nthe Tabu search achieved near-optimal results. In the latter case, the total\nvehicle travel distance was minimized and the runtime significantly\noutperformed the one generated by Gurobi. Furthermore, variations utilizing\nparallel CUDA processing further decreased the algorithmic runtime. These\nproved superior as the number of test missions increased, while also\nmaintaining the same minimized distance.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 04:32:28 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 19:54:05 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Tassone", "Joseph", ""], ["Pond", "Geoffrey", ""], ["Choudhury", "Salimur", ""]]}, {"id": "2001.05316", "submitter": "Md Saiful Islam", "authors": "Aisha Khatun, Anisur Rahman, Md. Saiful Islam, Marium-E-Jannat", "title": "Authorship Attribution in Bangla literature using Character-level CNN", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Characters are the smallest unit of text that can extract stylometric signals\nto determine the author of a text. In this paper, we investigate the\neffectiveness of character-level signals in Authorship Attribution of Bangla\nLiterature and show that the results are promising but improvable. The time and\nmemory efficiency of the proposed model is much higher than the word level\ncounterparts but accuracy is 2-5% less than the best performing word-level\nmodels. Comparison of various word-based models is performed and shown that the\nproposed model performs increasingly better with larger datasets. We also\nanalyze the effect of pre-training character embedding of diverse Bangla\ncharacter set in authorship attribution. It is seen that the performance is\nimproved by up to 10% on pre-training. We used 2 datasets from 6 to 14 authors,\nbalancing them before training and compare the results.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 14:54:04 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Khatun", "Aisha", ""], ["Rahman", "Anisur", ""], ["Islam", "Md. Saiful", ""], ["Marium-E-Jannat", "", ""]]}, {"id": "2001.05371", "submitter": "Patrick Schramowski", "authors": "Patrick Schramowski, Wolfgang Stammer, Stefano Teso, Anna Brugger,\n  Xiaoting Shao, Hans-Georg Luigs, Anne-Katrin Mahlein, Kristian Kersting", "title": "Making deep neural networks right for the right scientific reasons by\n  interacting with their explanations", "comments": "arXiv admin note: text overlap with arXiv:1805.08578", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have shown excellent performances in many real-world\napplications. Unfortunately, they may show \"Clever Hans\"-like behavior---making\nuse of confounding factors within datasets---to achieve high performance. In\nthis work, we introduce the novel learning setting of \"explanatory interactive\nlearning\" (XIL) and illustrate its benefits on a plant phenotyping research\ntask. XIL adds the scientist into the training loop such that she interactively\nrevises the original model via providing feedback on its explanations. Our\nexperimental results demonstrate that XIL can help avoiding Clever Hans moments\nin machine learning and encourages (or discourages, if appropriate) trust into\nthe underlying model.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 15:20:55 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 11:59:54 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 13:38:58 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Schramowski", "Patrick", ""], ["Stammer", "Wolfgang", ""], ["Teso", "Stefano", ""], ["Brugger", "Anna", ""], ["Shao", "Xiaoting", ""], ["Luigs", "Hans-Georg", ""], ["Mahlein", "Anne-Katrin", ""], ["Kersting", "Kristian", ""]]}, {"id": "2001.05375", "submitter": "Florian Buettner", "authors": "Florian Buettner, John Piorkowski, Ian McCulloh, Ulli Waltinger", "title": "AAAI FSS-19: Human-Centered AI: Trustworthiness of AI Models and Data\n  Proceedings", "comments": "Proceedings for AAAI 2019 Fall Symposium Series - Human-centered AI:\n  Trustworthiness of AI Models & Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To facilitate the widespread acceptance of AI systems guiding decision-making\nin real-world applications, it is key that solutions comprise trustworthy,\nintegrated human-AI systems. Not only in safety-critical applications such as\nautonomous driving or medicine, but also in dynamic open world systems in\nindustry and government it is crucial for predictive models to be\nuncertainty-aware and yield trustworthy predictions. Another key requirement\nfor deployment of AI at enterprise scale is to realize the importance of\nintegrating human-centered design into AI systems such that humans are able to\nuse systems effectively, understand results and output, and explain findings to\noversight committees.\n  While the focus of this symposium was on AI systems to improve data quality\nand technical robustness and safety, we welcomed submissions from broadly\ndefined areas also discussing approaches addressing requirements such as\nexplainable models, human trust and ethical aspects of AI.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 15:30:29 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Buettner", "Florian", ""], ["Piorkowski", "John", ""], ["McCulloh", "Ian", ""], ["Waltinger", "Ulli", ""]]}, {"id": "2001.05390", "submitter": "Piero Bonatti", "authors": "P.A. Bonatti, L. Ioffredo, I. Petrova, L. Sauro, I. R. Siahaan", "title": "Real Time Reasoning in OWL2 for GDPR Compliance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper shows how knowledge representation and reasoning techniques can be\nused to support organizations in complying with the GDPR, that is, the new\nEuropean data protection regulation. This work is carried out in a European\nH2020 project called SPECIAL. Data usage policies, the consent of data\nsubjects, and selected fragments of the GDPR are encoded in a fragment of OWL2\ncalled PL (policy language); compliance checking and policy validation are\nreduced to subsumption checking and concept consistency checking. This work\nproposes a satisfactory tradeoff between the expressiveness requirements on PL\nposed by the GDPR, and the scalability requirements that arise from the use\ncases provided by SPECIAL's industrial partners. Real-time compliance checking\nis achieved by means of a specialized reasoner, called PLR, that leverages\nknowledge compilation and structural subsumption techniques. The performance of\na prototype implementation of PLR is analyzed through systematic experiments,\nand compared with the performance of other important reasoners. Moreover, we\nshow how PL and PLR can be extended to support richer ontologies, by means of\nimport-by-query techniques. PL and its integration with OWL2's profiles\nconstitute new tractable fragments of OWL2. We prove also some negative\nresults, concerning the intractability of unrestricted reasoning in PL, and the\nlimitations posed on ontology import.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 15:50:27 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Bonatti", "P. A.", ""], ["Ioffredo", "L.", ""], ["Petrova", "I.", ""], ["Sauro", "L.", ""], ["Siahaan", "I. R.", ""]]}, {"id": "2001.05411", "submitter": "Erwan Lecarpentier", "authors": "Erwan Lecarpentier, David Abel, Kavosh Asadi, Yuu Jinnai, Emmanuel\n  Rachelson, Michael L. Littman", "title": "Lipschitz Lifelong Reinforcement Learning", "comments": "In proceedings of the 35th AAAI Conference on Artificial Intelligence\n  (AAAI 2021), 21 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of knowledge transfer when an agent is facing a\nseries of Reinforcement Learning (RL) tasks. We introduce a novel metric\nbetween Markov Decision Processes (MDPs) and establish that close MDPs have\nclose optimal value functions. Formally, the optimal value functions are\nLipschitz continuous with respect to the tasks space. These theoretical results\nlead us to a value-transfer method for Lifelong RL, which we use to build a\nPAC-MDP algorithm with improved convergence rate. Further, we show the method\nto experience no negative transfer with high probability. We illustrate the\nbenefits of the method in Lifelong RL experiments.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 16:29:30 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 16:25:07 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 14:35:30 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Lecarpentier", "Erwan", ""], ["Abel", "David", ""], ["Asadi", "Kavosh", ""], ["Jinnai", "Yuu", ""], ["Rachelson", "Emmanuel", ""], ["Littman", "Michael L.", ""]]}, {"id": "2001.05424", "submitter": "Amanda Swearngin", "authors": "Amanda Swearngin, Chenglong Wang, Alannah Oleson, James Fogarty, Amy\n  J. Ko", "title": "Scout: Rapid Exploration of Interface Layout Alternatives through\n  High-Level Design Constraints", "comments": "13 pages, 8 figures, ACM CHI Full Paper (2020)", "journal-ref": "Proceedings of the 2019 CHI Conference on Human Factors in\n  Computing Systems", "doi": "10.1145/3313831.3376593", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although exploring alternatives is fundamental to creating better interface\ndesigns, current processes for creating alternatives are generally manual,\nlimiting the alternatives a designer can explore. We present Scout, a system\nthat helps designers rapidly explore alternatives through mixed-initiative\ninteraction with high-level constraints and design feedback. Prior\nconstraint-based layout systems use low-level spatial constraints and generally\nproduce a single design. Tosupport designer exploration of alternatives, Scout\nintroduces high-level constraints based on design concepts (e.g.,~semantic\nstructure, emphasis, order) and formalizes them into low-level spatial\nconstraints that a solver uses to generate potential layouts. In an evaluation\nwith 18 interface designers, we found that Scout: (1) helps designers create\nmore spatially diverse layouts with similar quality to those created with a\nbaseline tool and (2) can help designers avoid a linear design process and\nquickly ideate layouts they do not believe they would have thought of on their\nown.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 16:49:26 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Swearngin", "Amanda", ""], ["Wang", "Chenglong", ""], ["Oleson", "Alannah", ""], ["Fogarty", "James", ""], ["Ko", "Amy J.", ""]]}, {"id": "2001.05458", "submitter": "Pinkesh Badjatiya", "authors": "Pinkesh Badjatiya, Mausoom Sarkar, Abhishek Sinha, Siddharth Singh,\n  Nikaash Puri, Jayakumar Subramanian, Balaji Krishnamurthy", "title": "Inducing Cooperative behaviour in Sequential-Social dilemmas through\n  Multi-Agent Reinforcement Learning using Status-Quo Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In social dilemma situations, individual rationality leads to sub-optimal\ngroup outcomes. Several human engagements can be modeled as a sequential\n(multi-step) social dilemmas. However, in contrast to humans, Deep\nReinforcement Learning agents trained to optimize individual rewards in\nsequential social dilemmas converge to selfish, mutually harmful behavior. We\nintroduce a status-quo loss (SQLoss) that encourages an agent to stick to the\nstatus quo, rather than repeatedly changing its policy. We show how agents\ntrained with SQLoss evolve cooperative behavior in several social dilemma\nmatrix games. To work with social dilemma games that have visual input, we\npropose GameDistill. GameDistill uses self-supervision and clustering to\nautomatically extract cooperative and selfish policies from a social dilemma\ngame. We combine GameDistill and SQLoss to show how agents evolve socially\ndesirable cooperative behavior in the Coin Game.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 18:10:46 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 09:55:17 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Badjatiya", "Pinkesh", ""], ["Sarkar", "Mausoom", ""], ["Sinha", "Abhishek", ""], ["Singh", "Siddharth", ""], ["Puri", "Nikaash", ""], ["Subramanian", "Jayakumar", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "2001.05462", "submitter": "Wael Al Enezi", "authors": "Wael Al Enezi, Clark Verbrugge", "title": "Offline Grid-Based Coverage path planning for guards in games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic approaches to exhaustive coverage have application in video\ngames, enabling automatic game level exploration. Current designs use simple\nheuristics that frequently result in poor performance or exhibit unnatural\nbehaviour. In this paper, we introduce a novel algorithm for covering a 2D\npolygonal (with holes) area. We assume prior knowledge of the map layout and\nuse a grid-based world representation. Experimental analysis over several\nscenarios ranging from simple layouts to more complex maps used in actual games\nshow good performance. This work serves as an initial step towards building a\nmore efficient coverage path planning algorithm for non-player characters.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 18:28:27 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Enezi", "Wael Al", ""], ["Verbrugge", "Clark", ""]]}, {"id": "2001.05490", "submitter": "Miriam Enzi", "authors": "Miriam Enzi, Sophie N. Parragh, David Pisinger and Matthias\n  Prandtstetter", "title": "Modeling and solving the multimodal car- and ride-sharing problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the multimodal car- and ride-sharing problem (MMCRP), in which a\npool of cars is used to cover a set of ride requests, while uncovered requests\nare assigned to other modes of transport (MOT). A car's route consists of one\nor more trips. Each trip must have a specific but non-predetermined driver,\nstart in a depot and finish in a (possibly different) depot. Ride-sharing\nbetween users is allowed, even when two rides do not have the same origin\nand/or destination. A user has always the option of using other modes of\ntransport according to an individual list of preferences.\n  The problem can be formulated as a vehicle scheduling problem. In order to\nsolve the problem, an auxiliary graph is constructed in which each trip\nstarting and ending in a depot, and covering possible ride-shares, is modeled\nas an edge in a time-space graph. We propose a two-layer decomposition\nalgorithm based on column generation, where the master problem ensures that\neach request can only be covered at most once, and the pricing problem\ngenerates new promising routes by solving a kind of shortest path problem in a\ntime-space network. Computational experiments based on realistic instances are\nreported. The benchmark instances are based on demographic, spatial, and\neconomic data of Vienna, Austria. We solve large instances with the column\ngeneration based approach to near optimality in reasonable time, and we further\ninvestigate various exact and heuristic pricing schemes.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 09:43:55 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Enzi", "Miriam", ""], ["Parragh", "Sophie N.", ""], ["Pisinger", "David", ""], ["Prandtstetter", "Matthias", ""]]}, {"id": "2001.05495", "submitter": "Pinkesh Badjatiya", "authors": "Pinkesh Badjatiya, Manish Gupta, Vasudeva Varma", "title": "Stereotypical Bias Removal for Hate Speech Detection Task using\n  Knowledge-based Generalizations", "comments": null, "journal-ref": "In The World Wide Web Conference (WWW '19). Association for\n  Computing Machinery, New York, NY, USA, 49-59. 2019", "doi": "10.1145/3308558.3313504", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-increasing cases of hate spread on social media platforms, it\nis critical to design abuse detection mechanisms to proactively avoid and\ncontrol such incidents. While there exist methods for hate speech detection,\nthey stereotype words and hence suffer from inherently biased training. Bias\nremoval has been traditionally studied for structured datasets, but we aim at\nbias mitigation from unstructured text data. In this paper, we make two\nimportant contributions. First, we systematically design methods to quantify\nthe bias for any model and propose algorithms for identifying the set of words\nwhich the model stereotypes. Second, we propose novel methods leveraging\nknowledge-based generalizations for bias-free learning. Knowledge-based\ngeneralization provides an effective way to encode knowledge because the\nabstraction they provide not only generalizes content but also facilitates\nretraction of information from the hate speech detection classifier, thereby\nreducing the imbalance. We experiment with multiple knowledge generalization\npolicies and analyze their effect on general performance and in mitigating\nbias. Our experiments with two real-world datasets, a Wikipedia Talk Pages\ndataset (WikiDetox) of size ~96k and a Twitter dataset of size ~24k, show that\nthe use of knowledge-based generalizations results in better performance by\nforcing the classifier to learn from generalized content. Our methods utilize\nexisting knowledge-bases and can easily be extended to other tasks\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 18:17:36 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Badjatiya", "Pinkesh", ""], ["Gupta", "Manish", ""], ["Varma", "Vasudeva", ""]]}, {"id": "2001.05573", "submitter": "Michael Hind", "authors": "Michael Hind, Dennis Wei, Yunfeng Zhang", "title": "Consumer-Driven Explanations for Machine Learning Decisions: An\n  Empirical Study of Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many proposed methods for explaining machine learning predictions are in fact\nchallenging to understand for nontechnical consumers. This paper builds upon an\nalternative consumer-driven approach called TED that asks for explanations to\nbe provided in training data, along with target labels. Using semi-synthetic\ndata from credit approval and employee retention applications, experiments are\nconducted to investigate some practical considerations with TED, including its\nperformance with different classification algorithms, varying numbers of\nexplanations, and variability in explanations. A new algorithm is proposed to\nhandle the case where some training examples do not have explanations. Our\nresults show that TED is robust to increasing numbers of explanations, noisy\nexplanations, and large fractions of missing explanations, thus making advances\ntoward its practical deployment.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:45:48 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Hind", "Michael", ""], ["Wei", "Dennis", ""], ["Zhang", "Yunfeng", ""]]}, {"id": "2001.05724", "submitter": "Shunwang Gong", "authors": "Guadalupe Gonzalez, Shunwang Gong, Ivan Laponogov, Kirill Veselkov,\n  Michael Bronstein", "title": "Graph Attentional Autoencoder for Anticancer Hyperfood Prediction", "comments": "33rd Conference on Neural Information Processing Systems Workshops\n  (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research efforts have shown the possibility to discover anticancer\ndrug-like molecules in food from their effect on protein-protein interaction\nnetworks, opening a potential pathway to disease-beating diet design. We\nformulate this task as a graph classification problem on which graph neural\nnetworks (GNNs) have achieved state-of-the-art results. However, GNNs are\ndifficult to train on sparse low-dimensional features according to our\nempirical evidence. Here, we present graph augmented features, integrating\ngraph structural information and raw node attributes with varying ratios, to\nease the training of networks. We further introduce a novel neural network\narchitecture on graphs, the Graph Attentional Autoencoder (GAA) to predict food\ncompounds with anticancer properties based on perturbed protein networks. We\ndemonstrate that the method outperforms the baseline approach and\nstate-of-the-art graph classification models in this task.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 10:08:51 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Gonzalez", "Guadalupe", ""], ["Gong", "Shunwang", ""], ["Laponogov", "Ivan", ""], ["Veselkov", "Kirill", ""], ["Bronstein", "Michael", ""]]}, {"id": "2001.05730", "submitter": "Ryuta Arisaka", "authors": "Ryuta Arisaka and Takayuki Ito", "title": "Broadening Label-based Argumentation Semantics with May-Must Scales\n  (May-Must Argumentation)", "comments": "Changes made to the previous version. 1. Definitions of satisfaction\n  of may/must conditions have been simplified. 2. Corrected the definition of a\n  maximally designating labelling which is now called a maximally proper\n  labelling instead", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The semantics as to which set of arguments in a given argumentation graph may\nbe acceptable (acceptability semantics) can be characterised in a few different\nways. Among them, labelling-based approach allows for concise and flexible\ndetermination of acceptability statuses of arguments through assignment of a\nlabel indicating acceptance, rejection, or undecided to each argument. In this\nwork, we contemplate a way of broadening it by accommodating may- and must-\nconditions for an argument to be accepted or rejected, as determined by the\nnumber(s) of rejected and accepted attacking arguments. We show that the\nbroadened label-based semantics can be used to express more mild indeterminacy\nthan inconsistency for acceptability judgement when, for example, it may be the\ncase that an argument is accepted and when it may also be the case that it is\nrejected. We identify that finding which conditions a labelling satisfies for\nevery argument can be an undecidable problem, which has an unfavourable\nimplication to existence of a semantics. We propose to address this problem by\nenforcing a labelling to maximally respect the conditions, while keeping the\nrest that would necessarily cause non-termination labelled undecided. Several\nsemantics will be presented and the relation among them will be noted. Towards\nthe end, we will touch upon possible research directions that can be pursued\nfurther.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 10:24:13 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 05:51:29 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 03:26:44 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Arisaka", "Ryuta", ""], ["Ito", "Takayuki", ""]]}, {"id": "2001.05847", "submitter": "Pablo Lanillos", "authors": "Cansu Sancaktar, Marcel van Gerven, Pablo Lanillos", "title": "End-to-End Pixel-Based Deep Active Inference for Body Perception and\n  Action", "comments": null, "journal-ref": null, "doi": "10.1109/ICDL-EpiRob48136.2020.9278105", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a pixel-based deep active inference algorithm (PixelAI) inspired\nby human body perception and action. Our algorithm combines the free-energy\nprinciple from neuroscience, rooted in variational inference, with deep\nconvolutional decoders to scale the algorithm to directly deal with raw visual\ninput and provide online adaptive inference. Our approach is validated by\nstudying body perception and action in a simulated and a real Nao robot.\nResults show that our approach allows the robot to perform 1) dynamical body\nestimation of its arm using only monocular camera images and 2) autonomous\nreaching to \"imagined\" arm poses in the visual space. This suggests that robot\nand human body perception and action can be efficiently solved by viewing both\nas an active inference problem guided by ongoing sensory input.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 12:19:09 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 14:15:16 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 21:30:12 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Sancaktar", "Cansu", ""], ["van Gerven", "Marcel", ""], ["Lanillos", "Pablo", ""]]}, {"id": "2001.05871", "submitter": "Vivian Lai", "authors": "Vivian Lai, Han Liu, Chenhao Tan", "title": "\"Why is 'Chicago' deceptive?\" Towards Building Model-Driven Tutorials\n  for Humans", "comments": "26 pages, 48 figures, CHI 2020", "journal-ref": null, "doi": "10.1145/10.1145/3313831.3376873", "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To support human decision making with machine learning models, we often need\nto elucidate patterns embedded in the models that are unsalient, unknown, or\ncounterintuitive to humans. While existing approaches focus on explaining\nmachine predictions with real-time assistance, we explore model-driven\ntutorials to help humans understand these patterns in a training phase. We\nconsider both tutorials with guidelines from scientific papers, analogous to\ncurrent practices of science communication, and automatically selected examples\nfrom training data with explanations. We use deceptive review detection as a\ntestbed and conduct large-scale, randomized human-subject experiments to\nexamine the effectiveness of such tutorials. We find that tutorials indeed\nimprove human performance, with and without real-time assistance. In\nparticular, although deep learning provides superior predictive performance\nthan simple models, tutorials and explanations from simple models are more\nuseful to humans. Our work suggests future directions for human-centered\ntutorials and explanations towards a synergy between humans and AI.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 19:00:00 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Lai", "Vivian", ""], ["Liu", "Han", ""], ["Tan", "Chenhao", ""]]}, {"id": "2001.05952", "submitter": "Patrick Rodler", "authors": "Patrick Rodler", "title": "On Expert Behaviors and Question Types for Efficient Query-Based\n  Ontology Fault Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LO cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We challenge existing query-based ontology fault localization methods wrt.\nassumptions they make, criteria they optimize, and interaction means they use.\nWe find that their efficiency depends largely on the behavior of the\ninteracting expert, that performed calculations can be inefficient or\nimprecise, and that used optimization criteria are often not fully realistic.\nAs a remedy, we suggest a novel (and simpler) interaction approach which\novercomes all identified problems and, in comprehensive experiments on faulty\nreal-world ontologies, enables a successful fault localization while requiring\nfewer expert interactions in 66 % of the cases, and always at least 80 % less\nexpert waiting time, compared to existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 17:23:07 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Rodler", "Patrick", ""]]}, {"id": "2001.05970", "submitter": "Viet Duong", "authors": "Viet Duong, Phu Pham, Ritwik Bose, Jiebo Luo", "title": "#MeToo on Campus: Studying College Sexual Assault at Scale Using Data\n  Reported on Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the emergence of the #MeToo trend on social media has empowered\nthousands of people to share their own sexual harassment experiences. This\nviral trend, in conjunction with the massive personal information and content\navailable on Twitter, presents a promising opportunity to extract data driven\ninsights to complement the ongoing survey based studies about sexual harassment\nin college. In this paper, we analyze the influence of the #MeToo trend on a\npool of college followers. The results show that the majority of topics\nembedded in those #MeToo tweets detail sexual harassment stories, and there\nexists a significant correlation between the prevalence of this trend and\nofficial reports on several major geographical regions. Furthermore, we\ndiscover the outstanding sentiments of the #MeToo tweets using deep semantic\nmeaning representations and their implications on the affected users\nexperiencing different types of sexual harassment. We hope this study can raise\nfurther awareness regarding sexual misconduct in academia.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:05:46 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Duong", "Viet", ""], ["Pham", "Phu", ""], ["Bose", "Ritwik", ""], ["Luo", "Jiebo", ""]]}, {"id": "2001.05994", "submitter": "Mycal Tucker", "authors": "Mycal Tucker, Yilun Zhou, Julie Shah", "title": "Adversarially Guided Self-Play for Adopting Social Conventions", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic agents must adopt existing social conventions in order to be\neffective teammates. These social conventions, such as driving on the right or\nleft side of the road, are arbitrary choices among optimal policies, but all\nagents on a successful team must use the same convention. Prior work has\nidentified a method of combining self-play with paired input-output data\ngathered from existing agents in order to learn their social convention without\ninteracting with them. We build upon this work by introducing a technique\ncalled Adversarial Self-Play (ASP) that uses adversarial training to shape the\nspace of possible learned policies and substantially improves learning\nefficiency. ASP only requires the addition of unpaired data: a dataset of\noutputs produced by the social convention without associated inputs.\nTheoretical analysis reveals how ASP shapes the policy space and the\ncircumstances (when behaviors are clustered or exhibit some other structure)\nunder which it offers the greatest benefits. Empirical results across three\ndomains confirm ASP's advantages: it produces models that more closely match\nthe desired social convention when given as few as two paired datapoints.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:51:42 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 20:41:11 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Tucker", "Mycal", ""], ["Zhou", "Yilun", ""], ["Shah", "Julie", ""]]}, {"id": "2001.06007", "submitter": "Nicolas Lair", "authors": "Nicolas Lair, Cl\\'ement Delgrange, David Mugisha, Jean-Michel Dussoux,\n  Pierre-Yves Oudeyer, and Peter Ford Dominey", "title": "User-in-the-loop Adaptive Intent Detection for Instructable Digital\n  Assistant", "comments": "To be published as a conference paper in the proceedings of IUI'20", "journal-ref": "25th International Conference on Intelligent User Interfaces (IUI\n  '20), March 17--20, 2020, Cagliari, Italy", "doi": "10.1145/3377325.3377490", "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People are becoming increasingly comfortable using Digital Assistants (DAs)\nto interact with services or connected objects. However, for non-programming\nusers, the available possibilities for customizing their DA are limited and do\nnot include the possibility of teaching the assistant new tasks. To make the\nmost of the potential of DAs, users should be able to customize assistants by\ninstructing them through Natural Language (NL). To provide such\nfunctionalities, NL interpretation in traditional assistants should be\nimproved: (1) The intent identification system should be able to recognize new\nforms of known intents, and to acquire new intents as they are expressed by the\nuser. (2) In order to be adaptive to novel intents, the Natural Language\nUnderstanding module should be sample efficient, and should not rely on a\npretrained model. Rather, the system should continuously collect the training\ndata as it learns new intents from the user. In this work, we propose AidMe\n(Adaptive Intent Detection in Multi-Domain Environments), a user-in-the-loop\nadaptive intent detection framework that allows the assistant to adapt to its\nuser by learning his intents as their interaction progresses. AidMe builds its\nrepertoire of intents and collects data to train a model of semantic similarity\nevaluation that can discriminate between the learned intents and autonomously\ndiscover new forms of known intents. AidMe addresses two major issues - intent\nlearning and user adaptation - for instructable digital assistants. We\ndemonstrate the capabilities of AidMe as a standalone system by comparing it\nwith a one-shot learning system and a pretrained NLU module through simulations\nof interactions with a user. We also show how AidMe can smoothly integrate to\nan existing instructable digital assistant.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:06:43 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Lair", "Nicolas", ""], ["Delgrange", "Cl\u00e9ment", ""], ["Mugisha", "David", ""], ["Dussoux", "Jean-Michel", ""], ["Oudeyer", "Pierre-Yves", ""], ["Dominey", "Peter Ford", ""]]}, {"id": "2001.06047", "submitter": "Assaf Marron", "authors": "Assaf Marron, Lior Limonad, Sarah Pollack, and David Harel", "title": "Expecting the Unexpected: Developing Autonomous-System Design Principles\n  for Reacting to Unpredicted Events and Conditions", "comments": "6 pages; 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.HC cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When developing autonomous systems, engineers and other stakeholders make\ngreat effort to prepare the system for all foreseeable events and conditions.\nHowever, these systems are still bound to encounter events and conditions that\nwere not considered at design time. For reasons like safety, cost, or ethics,\nit is often highly desired that these new situations be handled correctly upon\nfirst encounter. In this paper we first justify our position that there will\nalways exist unpredicted events and conditions, driven among others by: new\ninventions in the real world; the diversity of world-wide system deployments\nand uses; and, the non-negligible probability that multiple seemingly unlikely\nevents, which may be neglected at design time, will not only occur, but occur\ntogether. We then argue that despite this unpredictability property, handling\nthese events and conditions is indeed possible. Hence, we offer and exemplify\ndesign principles that when applied in advance, can enable systems to deal, in\nthe future, with unpredicted circumstances. We conclude with a discussion of\nhow this work and a broader theoretical study of the unexpected can contribute\ntoward a foundation of engineering principles for developing trustworthy\nnext-generation autonomous systems.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 19:39:01 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 12:30:23 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 13:39:32 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Marron", "Assaf", ""], ["Limonad", "Lior", ""], ["Pollack", "Sarah", ""], ["Harel", "David", ""]]}, {"id": "2001.06086", "submitter": "Johan Pauwels", "authors": "Johan Pauwels, Gy\\\"orgy Fazekas, Mark B. Sandler", "title": "A Critical Look at the Applicability of Markov Logic Networks for Music\n  Signal Analysis", "comments": "Accepted for presentation at the Ninth International Workshop on\n  Statistical Relational AI (StarAI 2020) at the 34th AAAI Conference on\n  Artificial Intelligence (AAAI) in New York, on February 7th 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Markov logic networks (MLNs) have been proposed as a\npotentially useful paradigm for music signal analysis. Because all hidden\nMarkov models can be reformulated as MLNs, the latter can provide an\nall-encompassing framework that reuses and extends previous work in the field.\nHowever, just because it is theoretically possible to reformulate previous work\nas MLNs, does not mean that it is advantageous. In this paper, we analyse some\nproposed examples of MLNs for musical analysis and consider their practical\ndisadvantages when compared to formulating the same musical dependence\nrelationships as (dynamic) Bayesian networks. We argue that a number of\npractical hurdles such as the lack of support for sequences and for arbitrary\ncontinuous probability distributions make MLNs less than ideal for the proposed\nmusical applications, both in terms of easy of formulation and computational\nrequirements due to their required inference algorithms. These conclusions are\nnot specific to music, but apply to other fields as well, especially when\nsequential data with continuous observations is involved. Finally, we show that\nthe ideas underlying the proposed examples can be expressed perfectly well in\nthe more commonly used framework of (dynamic) Bayesian networks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 21:46:13 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Pauwels", "Johan", ""], ["Fazekas", "Gy\u00f6rgy", ""], ["Sandler", "Mark B.", ""]]}, {"id": "2001.06190", "submitter": "Juan-Manuel Torres-Moreno", "authors": "Ana Lilia Laureano-Cruces, Laura Hern\\'andez-Dom\\'inguez, Martha\n  Mora-Torres, Juan-Manuel Torres-Moreno, Jaime Enrique Cabrera-L\\'opez", "title": "Visual Simplified Characters' Emotion Emulator Implementing OCC Model", "comments": "7 pages, 14 figures, 2 tables", "journal-ref": "CGST Conference on Computer Science and Engineering, Istanbul,\n  Turkey, 19-21 December 2011", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a visual emulator of the emotions seen in\ncharacters in stories. This system is based on a simplified view of the\ncognitive structure of emotions proposed by Ortony, Clore and Collins (OCC\nModel). The goal of this paper is to provide a visual platform that allows us\nto observe changes in the characters' different emotions, and the intricate\ninterrelationships between: 1) each character's emotions, 2) their affective\nrelationships and actions, 3) The events that take place in the development of\na plot, and 4) the objects of desire that make up the emotional map of any\nstory. This tool was tested on stories with a contrasting variety of emotional\nand affective environments: Othello, Twilight, and Harry Potter, behaving\nsensibly and in keeping with the atmosphere in which the characters were\nimmersed.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 08:41:46 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Laureano-Cruces", "Ana Lilia", ""], ["Hern\u00e1ndez-Dom\u00ednguez", "Laura", ""], ["Mora-Torres", "Martha", ""], ["Torres-Moreno", "Juan-Manuel", ""], ["Cabrera-L\u00f3pez", "Jaime Enrique", ""]]}, {"id": "2001.06322", "submitter": "Piero Bonatti", "authors": "P. A. Bonatti, L. Ioffredo, I. M. Petrova, L. Sauro", "title": "Fast Compliance Checking with General Vocabularies", "comments": "arXiv admin note: substantial text overlap with arXiv:2001.05390", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of complying with the GDPR while processing and\ntransferring personal data on the web. For this purpose we introduce an\nextensible profile of OWL2 for representing data protection policies. With this\nlanguage, a company's data usage policy can be checked for compliance with data\nsubjects' consent and with a formalized fragment of the GDPR by means of\nsubsumption queries. The outer structure of the policies is restricted in order\nto make compliance checking highly scalable, as required when processing\nhigh-frequency data streams or large data volumes. However, the vocabularies\nfor specifying policy properties can be chosen rather freely from expressive\nHorn fragments of OWL2. We exploit IBQ reasoning to integrate specialized\nreasoners for the policy language and the vocabulary's language. Our\nexperiments show that this approach significantly improves performance.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 09:08:00 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Bonatti", "P. A.", ""], ["Ioffredo", "L.", ""], ["Petrova", "I. M.", ""], ["Sauro", "L.", ""]]}, {"id": "2001.06354", "submitter": "Hyounghun Kim", "authors": "Hyounghun Kim, Hao Tan, Mohit Bansal", "title": "Modality-Balanced Models for Visual Dialogue", "comments": "AAAI 2020 (11 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Visual Dialog task requires a model to exploit both image and\nconversational context information to generate the next response to the\ndialogue. However, via manual analysis, we find that a large number of\nconversational questions can be answered by only looking at the image without\nany access to the context history, while others still need the conversation\ncontext to predict the correct answers. We demonstrate that due to this reason,\nprevious joint-modality (history and image) models over-rely on and are more\nprone to memorizing the dialogue history (e.g., by extracting certain keywords\nor patterns in the context information), whereas image-only models are more\ngeneralizable (because they cannot memorize or extract keywords from history)\nand perform substantially better at the primary normalized discounted\ncumulative gain (NDCG) task metric which allows multiple correct answers.\nHence, this observation encourages us to explicitly maintain two models, i.e.,\nan image-only model and an image-history joint model, and combine their\ncomplementary abilities for a more balanced multimodal model. We present\nmultiple methods for this integration of the two models, via ensemble and\nconsensus dropout fusion with shared parameters. Empirically, our models\nachieve strong results on the Visual Dialog challenge 2019 (rank 3 on NDCG and\nhigh balance across metrics), and substantially outperform the winner of the\nVisual Dialog challenge 2018 on most metrics.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 14:57:12 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Kim", "Hyounghun", ""], ["Tan", "Hao", ""], ["Bansal", "Mohit", ""]]}, {"id": "2001.06463", "submitter": "Alexandros Papangelis", "authors": "Alexandros Papangelis, Mahdi Namazifar, Chandra Khatri, Yi-Chia Wang,\n  Piero Molino, Gokhan Tur", "title": "Plato Dialogue System: A Flexible Conversational AI Research Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the field of Spoken Dialogue Systems and Conversational AI grows, so does\nthe need for tools and environments that abstract away implementation details\nin order to expedite the development process, lower the barrier of entry to the\nfield, and offer a common test-bed for new ideas. In this paper, we present\nPlato, a flexible Conversational AI platform written in Python that supports\nany kind of conversational agent architecture, from standard architectures to\narchitectures with jointly-trained components, single- or multi-party\ninteractions, and offline or online training of any conversational agent\ncomponent. Plato has been designed to be easy to understand and debug and is\nagnostic to the underlying learning frameworks that train each component.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 18:27:29 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Papangelis", "Alexandros", ""], ["Namazifar", "Mahdi", ""], ["Khatri", "Chandra", ""], ["Wang", "Yi-Chia", ""], ["Molino", "Piero", ""], ["Tur", "Gokhan", ""]]}, {"id": "2001.06487", "submitter": "Kai Yan", "authors": "Yunlong Lu and Kai Yan", "title": "Algorithms in Multi-Agent Systems: A Holistic Perspective from\n  Reinforcement Learning and Game Theory", "comments": "14 pages, review. Reorganizing the expressions in part of\n  introduction and background", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep reinforcement learning (RL) has achieved outstanding results in recent\nyears, which has led a dramatic increase in the number of methods and\napplications. Recent works are exploring learning beyond single-agent scenarios\nand considering multi-agent scenarios. However, they are faced with lots of\nchallenges and are seeking for help from traditional game-theoretic algorithms,\nwhich, in turn, show bright application promise combined with modern algorithms\nand boosting computing power. In this survey, we first introduce basic concepts\nand algorithms in single agent RL and multi-agent systems; then, we summarize\nthe related algorithms from three aspects. Solution concepts from game theory\ngive inspiration to algorithms which try to evaluate the agents or find better\nsolutions in multi-agent systems. Fictitious self-play becomes popular and has\na great impact on the algorithm of multi-agent reinforcement learning.\nCounterfactual regret minimization is an important tool to solve games with\nincomplete information, and has shown great strength when combined with deep\nlearning.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 15:08:04 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 13:28:37 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 02:16:05 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Lu", "Yunlong", ""], ["Yan", "Kai", ""]]}, {"id": "2001.06528", "submitter": "Haydn Belfield", "authors": "Haydn Belfield", "title": "Activism by the AI Community: Analysing Recent Achievements and Future\n  Prospects", "comments": "Forthcoming in Proceedings of the 2020 AAAI/ACM Conference on\n  Artificial Intelligence, Ethics and Society. 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The artificial intelligence community (AI) has recently engaged in activism\nin relation to their employers, other members of the community, and their\ngovernments in order to shape the societal and ethical implications of AI. It\nhas achieved some notable successes, but prospects for further political\norganising and activism are uncertain. We survey activism by the AI community\nover the last six years; apply two analytical frameworks drawing upon the\nliterature on epistemic communities, and worker organising and bargaining; and\nexplore what they imply for the future prospects of the AI community. Success\nthus far has hinged on a coherent shared culture, and high bargaining power due\nto the high demand for a limited supply of AI talent. Both are crucial to the\nfuture of AI activism and worthy of sustained attention.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 20:53:10 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Belfield", "Haydn", ""]]}, {"id": "2001.06615", "submitter": "Mitchell Burger", "authors": "Mitchell Burger", "title": "The Risk to Population Health Equity Posed by Automated Decision\n  Systems: A Narrative Review", "comments": "22 pages (12 pages excluding references), 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence is already ubiquitous, and is increasingly being used\nto autonomously make ever more consequential decisions. However, there has been\nrelatively little research into the consequences for equity of the use of\nnarrow AI and automated decision systems in medicine and public health. A\nnarrative review using a hermeneutic approach was undertaken to explore current\nand future uses of AI in medicine and public health, issues that have emerged,\nand longer-term implications for population health. Accounts in the literature\nreveal a tremendous expectation on AI to transform medical and public health\npractices, especially regarding precision medicine and precision public health.\nAutomated decisions being made about disease detection, diagnosis, treatment,\nand health funding allocation have significant consequences for individual and\npopulation health and wellbeing. Meanwhile, it is evident that issues of bias,\nincontestability, and erosion of privacy have emerged in sensitive domains\nwhere narrow AI and automated decision systems are in common use. As the use of\nautomated decision systems expands, it is probable that these same issues will\nmanifest widely in medicine and public health applications. Bias,\nincontestability, and erosion of privacy are mechanisms by which existing\nsocial, economic and health disparities are perpetuated and amplified. The\nimplication is that there is a significant risk that use of automated decision\nsystems in health will exacerbate existing population health inequities. The\nindustrial scale and rapidity with which automated decision systems can be\napplied to whole populations heightens the risk to population health equity.\nThere is a need therefore to design and implement automated decision systems\nwith care, monitor their impact over time, and develop capacities to respond to\nissues as they emerge.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 06:52:47 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Burger", "Mitchell", ""]]}, {"id": "2001.06627", "submitter": "Samaneh Hoseini Semnani", "authors": "Samaneh Hosseini Semnani, Hugh Liu, Michael Everett, Anton de Ruiter,\n  Jonathan P. How", "title": "Multi-agent Motion Planning for Dense and Dynamic Environments via Deep\n  Reinforcement Learning", "comments": "IEEE Robotics and Automation Letters (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a hybrid algorithm of deep reinforcement learning (RL)\nand Force-based motion planning (FMP) to solve distributed motion planning\nproblem in dense and dynamic environments. Individually, RL and FMP algorithms\neach have their own limitations. FMP is not able to produce time-optimal paths\nand existing RL solutions are not able to produce collision-free paths in dense\nenvironments. Therefore, we first tried improving the performance of recent RL\napproaches by introducing a new reward function that not only eliminates the\nrequirement of a pre supervised learning (SL) step but also decreases the\nchance of collision in crowded environments. That improved things, but there\nwere still a lot of failure cases. So, we developed a hybrid approach to\nleverage the simpler FMP approach in stuck, simple and high-risk cases, and\ncontinue using RL for normal cases in which FMP can't produce optimal path.\nAlso, we extend GA3C-CADRL algorithm to 3D environment. Simulation results show\nthat the proposed algorithm outperforms both deep RL and FMP algorithms and\nproduces up to 50% more successful scenarios than deep RL and up to 75% less\nextra time to reach goal than FMP.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 08:24:40 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Semnani", "Samaneh Hosseini", ""], ["Liu", "Hugh", ""], ["Everett", "Michael", ""], ["de Ruiter", "Anton", ""], ["How", "Jonathan P.", ""]]}, {"id": "2001.06631", "submitter": "Kangfei Zhao", "authors": "Kangfei Zhao, Yu Rong, Jeffrey Xu Yu, Junzhou Huang, Hao Zhang", "title": "Graph Ordering: Towards the Optimal by Learning", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning has achieved a remarkable success in many\ngraph-based applications, such as node classification, link prediction, and\ncommunity detection. These models are usually designed to preserve the vertex\ninformation at different granularity and reduce the problems in discrete space\nto some machine learning tasks in continuous space. However, regardless of the\nfruitful progress, for some kind of graph applications, such as graph\ncompression and edge partition, it is very hard to reduce them to some graph\nrepresentation learning tasks. Moreover, these problems are closely related to\nreformulating a global layout for a specific graph, which is an important\nNP-hard combinatorial optimization problem: graph ordering. In this paper, we\npropose to attack the graph ordering problem behind such applications by a\nnovel learning approach. Distinguished from greedy algorithms based on\npredefined heuristics, we propose a neural network model: Deep Order Network\n(DON) to capture the hidden locality structure from partial vertex order sets.\nSupervised by sampled partial order, DON has the ability to infer unseen\ncombinations. Furthermore, to alleviate the combinatorial explosion in the\ntraining space of DON and make the efficient partial vertex order sampling , we\nemploy a reinforcement learning model: the Policy Network, to adjust the\npartial order sampling probabilities during the training phase of DON\nautomatically. To this end, the Policy Network can improve the training\nefficiency and guide DON to evolve towards a more effective model\nautomatically. Comprehensive experiments on both synthetic and real data\nvalidate that DON-RL outperforms the current state-of-the-art heuristic\nalgorithm consistently. Two case studies on graph compression and edge\npartitioning demonstrate the potential power of DON-RL in real applications.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 09:14:16 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Zhao", "Kangfei", ""], ["Rong", "Yu", ""], ["Yu", "Jeffrey Xu", ""], ["Huang", "Junzhou", ""], ["Zhang", "Hao", ""]]}, {"id": "2001.06668", "submitter": "Douglas Blank", "authors": "Douglas S. Blank", "title": "Learning to See Analogies: A Connectionist Exploration", "comments": "191 pages, PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This dissertation explores the integration of learning and analogy-making\nthrough the development of a computer program, called Analogator, that learns\nto make analogies by example. By \"seeing\" many different analogy problems,\nalong with possible solutions, Analogator gradually develops an ability to make\nnew analogies. That is, it learns to make analogies by analogy. This approach\nstands in contrast to most existing research on analogy-making, in which\ntypically the a priori existence of analogical mechanisms within a model is\nassumed. The present research extends standard connectionist methodologies by\ndeveloping a specialized associative training procedure for a recurrent network\narchitecture. The network is trained to divide input scenes (or situations)\ninto appropriate figure and ground components. Seeing one scene in terms of a\nparticular figure and ground provides the context for seeing another in an\nanalogous fashion. After training, the model is able to make new analogies\nbetween novel situations. Analogator has much in common with lower-level\nperceptual models of categorization and recognition; it thus serves as a\nunifying framework encompassing both high-level analogical learning and\nlow-level perception. This approach is compared and contrasted with other\ncomputational models of analogy-making. The model's training and generalization\nperformance is examined, and limitations are discussed.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 14:06:16 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Blank", "Douglas S.", ""]]}, {"id": "2001.06684", "submitter": "Dakuo Wang", "authors": "Amy X. Zhang, Michael Muller, Dakuo Wang", "title": "How do Data Science Workers Collaborate? Roles, Workflows, and Tools", "comments": "CSCW'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, the prominence of data science within organizations has given rise to\nteams of data science workers collaborating on extracting insights from data,\nas opposed to individual data scientists working alone. However, we still lack\na deep understanding of how data science workers collaborate in practice. In\nthis work, we conducted an online survey with 183 participants who work in\nvarious aspects of data science. We focused on their reported interactions with\neach other (e.g., managers with engineers) and with different tools (e.g.,\nJupyter Notebook). We found that data science teams are extremely collaborative\nand work with a variety of stakeholders and tools during the six common steps\nof a data science workflow (e.g., clean data and train model). We also found\nthat the collaborative practices workers employ, such as documentation, vary\naccording to the kinds of tools they use. Based on these findings, we discuss\ndesign implications for supporting data science team collaborations and future\nresearch directions.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 15:11:56 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 08:38:00 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 16:38:43 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Zhang", "Amy X.", ""], ["Muller", "Michael", ""], ["Wang", "Dakuo", ""]]}, {"id": "2001.06691", "submitter": "Christian K\\\"astner", "authors": "Christian K\\\"astner, Eunsuk Kang", "title": "Teaching Software Engineering for AI-Enabled Systems", "comments": "to be published in ICSE-SEET 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software engineers have significant expertise to offer when building\nintelligent systems, drawing on decades of experience and methods for building\nsystems that are scalable, responsive and robust, even when built on unreliable\ncomponents. Systems with artificial-intelligence or machine-learning (ML)\ncomponents raise new challenges and require careful engineering. We designed a\nnew course to teach software-engineering skills to students with a background\nin ML. We specifically go beyond traditional ML courses that teach modeling\ntechniques under artificial conditions and focus, in lecture and assignments,\non realism with large and changing datasets, robust and evolvable\ninfrastructure, and purposeful requirements engineering that considers ethics\nand fairness as well. We describe the course and our infrastructure and share\nexperience and all material from teaching the course for the first time.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 15:24:17 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["K\u00e4stner", "Christian", ""], ["Kang", "Eunsuk", ""]]}, {"id": "2001.06693", "submitter": "Vijay Arya", "authors": "Karan Dabas, Nishtha Madan, Vijay Arya, Sameep Mehta, Gautam Singh,\n  Tanmoy Chakraborty", "title": "Fair Transfer of Multiple Style Attributes in Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To preserve anonymity and obfuscate their identity on online platforms users\nmay morph their text and portray themselves as a different gender or\ndemographic. Similarly, a chatbot may need to customize its communication style\nto improve engagement with its audience. This manner of changing the style of\nwritten text has gained significant attention in recent years. Yet these past\nresearch works largely cater to the transfer of single style attributes. The\ndisadvantage of focusing on a single style alone is that this often results in\ntarget text where other existing style attributes behave unpredictably or are\nunfairly dominated by the new style. To counteract this behavior, it would be\nnice to have a style transfer mechanism that can transfer or control multiple\nstyles simultaneously and fairly. Through such an approach, one could obtain\nobfuscated or written text incorporated with a desired degree of multiple soft\nstyles such as female-quality, politeness, or formalness.\n  In this work, we demonstrate that the transfer of multiple styles cannot be\nachieved by sequentially performing multiple single-style transfers. This is\nbecause each single style-transfer step often reverses or dominates over the\nstyle incorporated by a previous transfer step. We then propose a neural\nnetwork architecture for fairly transferring multiple style attributes in a\ngiven text. We test our architecture on the Yelp data set to demonstrate our\nsuperior performance as compared to existing one-style transfer steps performed\nin a sequence.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 15:38:04 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Dabas", "Karan", ""], ["Madan", "Nishtha", ""], ["Arya", "Vijay", ""], ["Mehta", "Sameep", ""], ["Singh", "Gautam", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "2001.06781", "submitter": "Bhaskar Ramasubramanian", "authors": "Baicen Xiao, Qifan Lu, Bhaskar Ramasubramanian, Andrew Clark, Linda\n  Bushnell, Radha Poovendran", "title": "FRESH: Interactive Reward Shaping in High-Dimensional State Spaces using\n  Human Feedback", "comments": "Accepted as Full Paper to International Conference on Autonomous\n  Agents and Multi-Agent Systems (AAMAS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has been successful in training autonomous agents to\naccomplish goals in complex environments. Although this has been adapted to\nmultiple settings, including robotics and computer games, human players often\nfind it easier to obtain higher rewards in some environments than reinforcement\nlearning algorithms. This is especially true of high-dimensional state spaces\nwhere the reward obtained by the agent is sparse or extremely delayed. In this\npaper, we seek to effectively integrate feedback signals supplied by a human\noperator with deep reinforcement learning algorithms in high-dimensional state\nspaces. We call this FRESH (Feedback-based REward SHaping). During training, a\nhuman operator is presented with trajectories from a replay buffer and then\nprovides feedback on states and actions in the trajectory. In order to\ngeneralize feedback signals provided by the human operator to previously unseen\nstates and actions at test-time, we use a feedback neural network. We use an\nensemble of neural networks with a shared network architecture to represent\nmodel uncertainty and the confidence of the neural network in its output. The\noutput of the feedback neural network is converted to a shaping reward that is\naugmented to the reward provided by the environment. We evaluate our approach\non the Bowling and Skiing Atari games in the arcade learning environment.\nAlthough human experts have been able to achieve high scores in these\nenvironments, state-of-the-art deep learning algorithms perform poorly. We\nobserve that FRESH is able to achieve much higher scores than state-of-the-art\ndeep learning algorithms in both environments. FRESH also achieves a 21.4%\nhigher score than a human expert in Bowling and does as well as a human expert\nin Skiing.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 06:07:20 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Xiao", "Baicen", ""], ["Lu", "Qifan", ""], ["Ramasubramanian", "Bhaskar", ""], ["Clark", "Andrew", ""], ["Bushnell", "Linda", ""], ["Poovendran", "Radha", ""]]}, {"id": "2001.06917", "submitter": "Jiaoyan Chen", "authors": "Jiaoyan Chen, Xi Chen, Ian Horrocks, Ernesto Jimenez-Ruiz, and Erik B.\n  Myklebus", "title": "Correcting Knowledge Base Assertions", "comments": "Accepted by The Web Conference (WWW) 2020", "journal-ref": null, "doi": "10.1145/3366423.3380226", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The usefulness and usability of knowledge bases (KBs) is often limited by\nquality issues. One common issue is the presence of erroneous assertions, often\ncaused by lexical or semantic confusion. We study the problem of correcting\nsuch assertions, and present a general correction framework which combines\nlexical matching, semantic embedding, soft constraint mining and semantic\nconsistency checking. The framework is evaluated using DBpedia and an\nenterprise medical KB.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 23:03:47 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Chen", "Jiaoyan", ""], ["Chen", "Xi", ""], ["Horrocks", "Ian", ""], ["Jimenez-Ruiz", "Ernesto", ""], ["Myklebus", "Erik B.", ""]]}, {"id": "2001.06921", "submitter": "arXiv Admin", "authors": "Amit Kumar Mondal", "title": "A Survey of Reinforcement Learning Techniques: Strategies, Recent\n  Development, and Future Directions", "comments": "This submission has been withdrawn by arXiv administrators as the\n  second author was added without their knowledge or consent", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is one of the core components in designing an\nartificial intelligent system emphasizing real-time response. Reinforcement\nlearning influences the system to take actions within an arbitrary environment\neither having previous knowledge about the environment model or not. In this\npaper, we present a comprehensive study on Reinforcement Learning focusing on\nvarious dimensions including challenges, the recent development of different\nstate-of-the-art techniques, and future directions. The fundamental objective\nof this paper is to provide a framework for the presentation of available\nmethods of reinforcement learning that is informative enough and simple to\nfollow for the new researchers and academics in this domain considering the\nlatest concerns. First, we illustrated the core techniques of reinforcement\nlearning in an easily understandable and comparable way. Finally, we analyzed\nand depicted the recent developments in reinforcement learning approaches. My\nanalysis pointed out that most of the models focused on tuning policy values\nrather than tuning other things in a particular state of reasoning.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 23:51:14 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 14:54:38 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Mondal", "Amit Kumar", ""]]}, {"id": "2001.06927", "submitter": "Ramprasaath R. Selvaraju", "authors": "Ramprasaath R. Selvaraju, Purva Tendulkar, Devi Parikh, Eric Horvitz,\n  Marco Ribeiro, Besmira Nushi, Ece Kamar", "title": "SQuINTing at VQA Models: Introspecting VQA Models with Sub-Questions", "comments": "Accepted to CVPR'20 as an Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing VQA datasets contain questions with varying levels of complexity.\nWhile the majority of questions in these datasets require perception for\nrecognizing existence, properties, and spatial relationships of entities, a\nsignificant portion of questions pose challenges that correspond to reasoning\ntasks - tasks that can only be answered through a synthesis of perception and\nknowledge about the world, logic and / or reasoning. Analyzing performance\nacross this distinction allows us to notice when existing VQA models have\nconsistency issues; they answer the reasoning questions correctly but fail on\nassociated low-level perception questions. For example, in Figure 1, models\nanswer the complex reasoning question \"Is the banana ripe enough to eat?\"\ncorrectly, but fail on the associated perception question \"Are the bananas\nmostly green or yellow?\" indicating that the model likely answered the\nreasoning question correctly but for the wrong reason. We quantify the extent\nto which this phenomenon occurs by creating a new Reasoning split of the VQA\ndataset and collecting VQA-introspect, a new dataset1 which consists of 238K\nnew perception questions which serve as sub questions corresponding to the set\nof perceptual tasks needed to effectively answer the complex reasoning\nquestions in the Reasoning split. Our evaluation shows that state-of-the-art\nVQA models have comparable performance in answering perception and reasoning\nquestions, but suffer from consistency problems. To address this shortcoming,\nwe propose an approach called Sub-Question Importance-aware Network Tuning\n(SQuINT), which encourages the model to attend to the same parts of the image\nwhen answering the reasoning question and the perception sub question. We show\nthat SQuINT improves model consistency by ~5%, also marginally improving\nperformance on the Reasoning questions in VQA, while also displaying better\nattention maps.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 01:02:36 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 17:54:16 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Selvaraju", "Ramprasaath R.", ""], ["Tendulkar", "Purva", ""], ["Parikh", "Devi", ""], ["Horvitz", "Eric", ""], ["Ribeiro", "Marco", ""], ["Nushi", "Besmira", ""], ["Kamar", "Ece", ""]]}, {"id": "2001.06980", "submitter": "Yuri Lavinas Mr", "authors": "Yuri Lavinas, Claus Aranha, Marcelo Ladeira and Felipe Campelo", "title": "MOEA/D with Random Partial Update Strategy", "comments": null, "journal-ref": null, "doi": "10.1109/CEC48606.2020.9185527", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent studies on resource allocation suggest that some subproblems are more\nimportant than others in the context of the MOEA/D, and that focusing on the\nmost relevant ones can consistently improve the performance of that algorithm.\nThese studies share the common characteristic of updating only a fraction of\nthe population at any given iteration of the algorithm. In this work we\ninvestigate a new, simpler partial update strategy, in which a random subset of\nsolutions is selected at every iteration. The performance of the MOEA/D using\nthis new resource allocation approach is compared experimentally against that\nof the standard MOEA/D-DE and the MOEA/D with relative improvement-based\nresource allocation. The results indicate that using the MOEA/D with this new\npartial update strategy results in improved HV and IGD values, and a much\nhigher proportion of non-dominated solutions, particularly as the number of\nupdated solutions at every iteration is reduced.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 05:13:52 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Lavinas", "Yuri", ""], ["Aranha", "Claus", ""], ["Ladeira", "Marcelo", ""], ["Campelo", "Felipe", ""]]}, {"id": "2001.06988", "submitter": "Yasuho Yamashita", "authors": "Yasuho Yamashita, Takuma Shibahara and Junichi Kuwata", "title": "A point-wise linear model reveals reasons for 30-day readmission of\n  heart failure patients", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heart failures in the United States cost an estimated 30.7 billion dollars\nannually and predictive analysis can decrease costs due to readmission of heart\nfailure patients. Deep learning can predict readmissions but does not give\nreasons for its predictions. Ours is the first study on a deep-learning\napproach to explaining decisions behind readmission predictions. Additionally,\nit provides an automatic patient stratification to explain cohorts of\nreadmitted patients. The new deep-learning model called a point-wise linear\nmodel is a meta-learning machine of linear models. It generates a logistic\nregression model to predict early readmission for each patient. The custom-made\nprediction models allow us to analyze feature importance. We evaluated the\napproach using a dataset that had 30-days readmission patients with heart\nfailures. This study has been submitted in PLOS ONE. In advance, we would like\nto share the theoretical aspect of the point-wise linear model as a part of our\nstudy.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 05:56:32 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Yamashita", "Yasuho", ""], ["Shibahara", "Takuma", ""], ["Kuwata", "Junichi", ""]]}, {"id": "2001.07038", "submitter": "Ana Freire", "authors": "Ana Freire, Lorenzo Porcaro and Emilia G\\'omez", "title": "Measuring Diversity of Artificial Intelligence Conferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of diversity of the Artificial Intelligence (AI) field is nowadays a\nconcern, and several initiatives such as funding schemes and mentoring programs\nhave been designed to overcome it. However, there is no indication on how these\ninitiatives actually impact AI diversity in the short and long term. This work\nstudies the concept of diversity in this particular context and proposes a\nsmall set of diversity indicators (i.e. indexes) of AI scientific events. These\nindicators are designed to quantify the diversity of the AI field and monitor\nits evolution. We consider diversity in terms of gender, geographical location\nand business (understood as the presence of academia versus industry). We\ncompute these indicators for the different communities of a conference:\nauthors, keynote speakers and organizing committee. From these components we\ncompute a summarized diversity indicator for each AI event. We evaluate the\nproposed indexes for a set of recent major AI conferences and we discuss their\nvalues and limitations.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 10:09:50 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 10:34:58 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 15:45:35 GMT"}, {"version": "v4", "created": "Mon, 22 Mar 2021 17:08:41 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Freire", "Ana", ""], ["Porcaro", "Lorenzo", ""], ["G\u00f3mez", "Emilia", ""]]}, {"id": "2001.07076", "submitter": "Tao Chen", "authors": "Tao Chen, Rami Bahsoon, and Xin Yao", "title": "Synergizing Domain Expertise with Self-Awareness in Software Systems: A\n  Patternized Architecture Guideline", "comments": "Accepted manuscript to the Proceedings of the IEEE. Please use the\n  following citation: Tao Chen, Rami Bahsoon, and Xin Yao. 2020. Synergizing\n  Domain Expertise with Self-Awareness in Software Systems: A Patternized\n  Architecture Guideline. Proc. IEEE, in press", "journal-ref": null, "doi": "10.1109/JPROC.2020.2985293", "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To promote engineering self-aware and self-adaptive software systems in a\nreusable manner, architectural patterns and the related methodology provide an\nunified solution to handle the recurring problems in the engineering process.\nHowever, in existing patterns and methods, domain knowledge and engineers'\nexpertise that is built over time are not explicitly linked to the self-aware\nprocesses. This linkage is important, as the knowledge is a valuable asset for\nthe related problems and its absence would cause unnecessary overhead, possibly\nmisleading results and unwise waste of the tremendous benefit that could have\nbeen brought by the domain expertise. This paper highlights the importance of\nsynergizing domain expertise and the self-awareness to enable better\nself-adaptation in software systems, relying on well-defined expertise\nrepresentation, algorithms and techniques. In particular, we present a holistic\nframework of notions, enriched patterns and methodology, dubbed DBASES, that\noffers a principled guideline for the engineers to perform difficulty and\nbenefit analysis on possible synergies, in an attempt to keep\n\"engineers-in-the-loop\". Through three tutorial case studies, we demonstrate\nhow DBASES can be applied in different domains, within which a carefully\nselected set of candidates with different synergies can be used for\nquantitative investigation, providing more informed decisions of the design\nchoices.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 12:17:22 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 20:34:51 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Chen", "Tao", ""], ["Bahsoon", "Rami", ""], ["Yao", "Xin", ""]]}, {"id": "2001.07118", "submitter": "Ryan Carey", "authors": "Ryan Carey, Eric Langlois, Tom Everitt and Shane Legg", "title": "The Incentives that Shape Behaviour", "comments": "In SafeAI workshop at AAAI. Superseded by arXiv:2102.01685", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Which variables does an agent have an incentive to control with its decision,\nand which variables does it have an incentive to respond to? We formalise these\nincentives, and demonstrate unique graphical criteria for detecting them in any\nsingle decision causal influence diagram. To this end, we introduce structural\ncausal influence models, a hybrid of the influence diagram and structural\ncausal model frameworks. Finally, we illustrate how these incentives predict\nagent incentives in both fairness and AI safety applications.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 14:32:07 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 20:02:54 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Carey", "Ryan", ""], ["Langlois", "Eric", ""], ["Everitt", "Tom", ""], ["Legg", "Shane", ""]]}, {"id": "2001.07119", "submitter": "Mengzhuo Guo", "authors": "Mengzhuo Guo, Qingpeng Zhang, Xiuwu Liao, Daniel Dajun Zeng", "title": "An interpretable neural network model through piecewise linear\n  approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing interpretable methods explain a black-box model in a post-hoc\nmanner, which uses simpler models or data analysis techniques to interpret the\npredictions after the model is learned. However, they (a) may derive\ncontradictory explanations on the same predictions given different methods and\ndata samples, and (b) focus on using simpler models to provide higher\ndescriptive accuracy at the sacrifice of prediction accuracy. To address these\nissues, we propose a hybrid interpretable model that combines a piecewise\nlinear component and a nonlinear component. The first component describes the\nexplicit feature contributions by piecewise linear approximation to increase\nthe expressiveness of the model. The other component uses a multi-layer\nperceptron to capture feature interactions and implicit nonlinearity, and\nincrease the prediction performance. Different from the post-hoc approaches,\nthe interpretability is obtained once the model is learned in the form of\nfeature shapes. We also provide a variant to explore higher-order interactions\namong features to demonstrate that the proposed model is flexible for\nadaptation. Experiments demonstrate that the proposed model can achieve good\ninterpretability by describing feature shapes while maintaining\nstate-of-the-art accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 14:32:11 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Guo", "Mengzhuo", ""], ["Zhang", "Qingpeng", ""], ["Liao", "Xiuwu", ""], ["Zeng", "Daniel Dajun", ""]]}, {"id": "2001.07141", "submitter": "Bastien Maubert", "authors": "Bastien Maubert, Aniello Murano, Sophie Pinchinat, Fran\\c{c}ois\n  Schwarzentruber and Silvia Stranieri", "title": "Dynamic Epistemic Logic Games with Epistemic Temporal Goals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Epistemic Logic (DEL) is a logical framework in which one can\ndescribe in great detail how actions are perceived by the agents, and how they\naffect the world. DEL games were recently introduced as a way to define classes\nof games with imperfect information where the actions available to the players\nare described very precisely. This framework makes it possible to define\neasily, for instance, classes of games where players can only use public\nactions or public announcements. These games have been studied for reachability\nobjectives, where the aim is to reach a situation satisfying some epistemic\nproperty expressed in epistemic logic; several (un)decidability results have\nbeen established. In this work we show that the decidability results obtained\nfor reachability objectives extend to a much more general class of winning\nconditions, namely those expressible in the epistemic temporal logic LTLK. To\ndo so we establish that the infinite game structures generated by DEL public\nactions are regular, and we describe how to obtain finite representations on\nwhich we rely to solve them.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 15:27:23 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Maubert", "Bastien", ""], ["Murano", "Aniello", ""], ["Pinchinat", "Sophie", ""], ["Schwarzentruber", "Fran\u00e7ois", ""], ["Stranieri", "Silvia", ""]]}, {"id": "2001.07142", "submitter": "Diogo Rato", "authors": "Diogo Rato, Samuel Mascarenhas, and Rui Prada", "title": "Towards Social Identity in Socio-Cognitive Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current architectures for social agents are designed around some specific\nunits of social behaviour that address particular challenges. Although their\nperformance might be adequate for controlled environments, deploying these\nagents in the wild is difficult. Moreover, the increasing demand for autonomous\nagents capable of living alongside humans calls for the design of more robust\nsocial agents that can cope with diverse social situations. We believe that to\ndesign such agents, their sociality and cognition should be conceived as one.\nThis includes creating mechanisms for constructing social reality as an\ninterpretation of the physical world with social meanings and selective\ndeployment of cognitive resources adequate to the situation. We identify\nseveral design principles that should be considered while designing agent\narchitectures for socio-cognitive systems. Taking these remarks into account,\nwe propose a socio-cognitive agent model based on the concept of Cognitive\nSocial Frames that allow the adaptation of an agent's cognition based on its\ninterpretation of its surroundings, its Social Context. Our approach supports\nan agent's reasoning about other social actors and its relationship with them.\nCognitive Social Frames can be built around social groups, and form the basis\nfor social group dynamics mechanisms and construct of Social Identity.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 15:27:26 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Rato", "Diogo", ""], ["Mascarenhas", "Samuel", ""], ["Prada", "Rui", ""]]}, {"id": "2001.07295", "submitter": "Clayton Morrison", "authors": "Adarsh Pyarelal and Marco A. Valenzuela-Escarcega and Rebecca Sharp\n  and Paul D. Hein, Jon Stephens, Pratik Bhandari, HeuiChan Lim, Saumya Debray,\n  Clayton T. Morrison", "title": "AutoMATES: Automated Model Assembly from Text, Equations, and Software", "comments": "8 pages, 6 figures, accepted to Modeling the World's Systems 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MM cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models of complicated systems can be represented in different ways - in\nscientific papers, they are represented using natural language text as well as\nequations. But to be of real use, they must also be implemented as software,\nthus making code a third form of representing models. We introduce the\nAutoMATES project, which aims to build semantically-rich unified\nrepresentations of models from scientific code and publications to facilitate\nthe integration of computational models from different domains and allow for\nmodeling large, complicated systems that span multiple domains and levels of\nabstraction.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 00:33:40 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Pyarelal", "Adarsh", ""], ["Valenzuela-Escarcega", "Marco A.", ""], ["Sharp", "Rebecca", ""], ["Hein", "Paul D.", ""], ["Stephens", "Jon", ""], ["Bhandari", "Pratik", ""], ["Lim", "HeuiChan", ""], ["Debray", "Saumya", ""], ["Morrison", "Clayton T.", ""]]}, {"id": "2001.07317", "submitter": "Chuyu Xiong", "authors": "Chuyu Xiong", "title": "Sampling and Learning for Boolean Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we continue our study on universal learning machine by\nintroducing new tools. We first discuss boolean function and boolean circuit,\nand we establish one set of tools, namely, fitting extremum and proper sampling\nset. We proved the fundamental relationship between proper sampling set and\ncomplexity of boolean circuit. Armed with this set of tools, we then introduce\nmuch more effective learning strategies. We show that with such learning\nstrategies and learning dynamics, universal learning can be achieved, and\nrequires much less data.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 03:01:14 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Xiong", "Chuyu", ""]]}, {"id": "2001.07343", "submitter": "Colin Summers", "authors": "Colin Summers, Kendall Lowrey, Aravind Rajeswaran, Siddhartha\n  Srinivasa, Emanuel Todorov", "title": "Lyceum: An efficient and scalable ecosystem for robot learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Lyceum, a high-performance computational ecosystem for robot\nlearning. Lyceum is built on top of the Julia programming language and the\nMuJoCo physics simulator, combining the ease-of-use of a high-level programming\nlanguage with the performance of native C. In addition, Lyceum has a\nstraightforward API to support parallel computation across multiple cores and\nmachines. Overall, depending on the complexity of the environment, Lyceum is\n5-30x faster compared to other popular abstractions like OpenAI's Gym and\nDeepMind's dm-control. This substantially reduces training time for various\nreinforcement learning algorithms; and is also fast enough to support real-time\nmodel predictive control through MuJoCo. The code, tutorials, and demonstration\nvideos can be found at: www.lyceum.ml.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 05:03:04 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Summers", "Colin", ""], ["Lowrey", "Kendall", ""], ["Rajeswaran", "Aravind", ""], ["Srinivasa", "Siddhartha", ""], ["Todorov", "Emanuel", ""]]}, {"id": "2001.07362", "submitter": "Abhishek Dubey", "authors": "Geoffrey Pettet, Ayan Mukhopadhyay, Mykel Kochenderfer, Yevgeniy\n  Vorobeychik, Abhishek Dubey", "title": "On Algorithmic Decision Procedures in Emergency Response Systems in\n  Smart and Connected Communities", "comments": "Accepted at AAMAS 2020 (International Conference on Autonomous Agents\n  and Multiagent Systems)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergency Response Management (ERM) is a critical problem faced by\ncommunities across the globe. Despite this, it is common for ERM systems to\nfollow myopic decision policies in the real world. Principled approaches to aid\nERM decision-making under uncertainty have been explored but have failed to be\naccepted into real systems. We identify a key issue impeding their adoption ---\nalgorithmic approaches to emergency response focus on reactive, post-incident\ndispatching actions, i.e. optimally dispatching a responder \\textit{after}\nincidents occur. However, the critical nature of emergency response dictates\nthat when an incident occurs, first responders always dispatch the closest\navailable responder to the incident. We argue that the crucial period of\nplanning for ERM systems is not post-incident, but between incidents. This is\nnot a trivial planning problem --- a major challenge with dynamically balancing\nthe spatial distribution of responders is the complexity of the problem. An\northogonal problem in ERM systems is planning under limited communication,\nwhich is particularly important in disaster scenarios that affect communication\nnetworks. We address both problems by proposing two partially decentralized\nmulti-agent planning algorithms that utilize heuristics and exploit the\nstructure of the dispatch problem. We evaluate our proposed approach using\nreal-world data, and find that in several contexts, dynamic re-balancing the\nspatial distribution of emergency responders reduces both the average response\ntime as well as its variance.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 07:04:38 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 01:03:37 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 00:12:20 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Pettet", "Geoffrey", ""], ["Mukhopadhyay", "Ayan", ""], ["Kochenderfer", "Mykel", ""], ["Vorobeychik", "Yevgeniy", ""], ["Dubey", "Abhishek", ""]]}, {"id": "2001.07374", "submitter": "Joel Colloc", "authors": "Ying Shen (UPN), Jacquet-Andrieu Armelle, Jo\\\"el Colloc (IDEES)", "title": "A multi-agent ontologies-based clinical decision support system", "comments": "in French", "journal-ref": "AMINA'2012, Jan 2012, Mahdia, Tunisie", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical decision support systems combine knowledge and data from a variety\nof sources, represented by quantitative models based on stochastic methods, or\nqualitative based rather on expert heuristics and deductive reasoning. At the\nsame time, case-based reasoning (CBR) memorizes and returns the experience of\nsolving similar problems. The cooperation of heterogeneous clinical knowledge\nbases (knowledge objects, semantic distances, evaluation functions, logical\nrules, databases...) is based on medical ontologies. A multi-agent decision\nsupport system (MADSS) enables the integration and cooperation of agents\nspecialized in different fields of knowledge (semiology, pharmacology, clinical\ncases, etc.). Each specialist agent operates a knowledge base defining the\nconduct to be maintained in conformity with the state of the art associated\nwith an ontological basis that expresses the semantic relationships between the\nterms of the domain in question. Our approach is based on the specialization of\nagents adapted to the knowledge models used during the clinical steps and\nontologies. This modular approach is suitable for the realization of MADSS in\nmany areas.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 08:04:13 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Shen", "Ying", "", "UPN"], ["Armelle", "Jacquet-Andrieu", "", "IDEES"], ["Colloc", "Jo\u00ebl", "", "IDEES"]]}, {"id": "2001.07417", "submitter": "Carlos Fern\\'andez-Lor\\'ia", "authors": "Carlos Fern\\'andez-Lor\\'ia, Foster Provost, Xintian Han", "title": "Explaining Data-Driven Decisions made by AI Systems: The Counterfactual\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine counterfactual explanations for explaining the decisions made by\nmodel-based AI systems. The counterfactual approach we consider defines an\nexplanation as a set of the system's data inputs that causally drives the\ndecision (i.e., changing the inputs in the set changes the decision) and is\nirreducible (i.e., changing any subset of the inputs does not change the\ndecision). We (1) demonstrate how this framework may be used to provide\nexplanations for decisions made by general, data-driven AI systems that may\nincorporate features with arbitrary data types and multiple predictive models,\nand (2) propose a heuristic procedure to find the most useful explanations\ndepending on the context. We then contrast counterfactual explanations with\nmethods that explain model predictions by weighting features according to their\nimportance (e.g., SHAP, LIME) and present two fundamental reasons why we should\ncarefully consider whether importance-weight explanations are well-suited to\nexplain system decisions. Specifically, we show that (i) features that have a\nlarge importance weight for a model prediction may not affect the corresponding\ndecision, and (ii) importance weights are insufficient to communicate whether\nand how features influence decisions. We demonstrate this with several concise\nexamples and three detailed case studies that compare the counterfactual\napproach with SHAP to illustrate various conditions under which counterfactual\nexplanations explain data-driven decisions better than importance weights.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 09:58:58 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 13:28:14 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 03:30:11 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2021 21:52:22 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Fern\u00e1ndez-Lor\u00eda", "Carlos", ""], ["Provost", "Foster", ""], ["Han", "Xintian", ""]]}, {"id": "2001.07455", "submitter": "Martin Lindvall", "authors": "Martin Lindvall and Jesper Molin", "title": "Designing for the Long Tail of Machine Learning", "comments": "Accepted for presentation in poster format for the ACM CHI'19\n  Workshop <Emerging Perspectives in Human-Centered Machine Learning>", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent technical advances has made machine learning (ML) a promising\ncomponent to include in end user facing systems. However, user experience (UX)\npractitioners face challenges in relating ML to existing user-centered design\nprocesses and how to navigate the possibilities and constraints of this design\nspace. Drawing on our own experience, we characterize designing within this\nspace as navigating trade-offs between data gathering, model development and\ndesigning valuable interactions for a given model performance. We suggest that\nthe theoretical description of how machine learning performance scales with\ntraining data can guide designers in these trade-offs as well as having\nimplications for prototyping. We exemplify the learning curve's usage by\narguing that a useful pattern is to design an initial system in a bootstrap\nphase that aims to exploit the training effect of data collected at increasing\norders of magnitude.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 11:53:28 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Lindvall", "Martin", ""], ["Molin", "Jesper", ""]]}, {"id": "2001.07495", "submitter": "Daniel Nissani", "authors": "Daniel N. Nissani (Nissensohn)", "title": "Unsupervisedly Learned Representations: Should the Quest be Over?", "comments": "To be published at The 6th International Conference on Machine\n  Learning, Optimization and Data Science - LOD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exists a Classification accuracy gap of about 20% between our best\nmethods of generating Unsupervisedly Learned Representations and the accuracy\nrates achieved by (naturally Unsupervisedly Learning) humans. We are at our\nfourth decade at least in search of this class of paradigms. It thus may well\nbe that we are looking in the wrong direction. We present in this paper a\npossible solution to this puzzle. We demonstrate that Reinforcement Learning\nschemes can learn representations, which may be used for Pattern Recognition\ntasks such as Classification, achieving practically the same accuracy as that\nof humans. Our main modest contribution lies in the observations that: a. when\napplied to a real world environment (e.g. nature itself) Reinforcement Learning\ndoes not require labels, and thus may be considered a natural candidate for the\nlong sought, accuracy competitive Unsupervised Learning method, and b. in\ncontrast, when Reinforcement Learning is applied in a simulated or symbolic\nprocessing environment (e.g. a computer program) it does inherently require\nlabels and should thus be generally classified, with some exceptions, as\nSupervised Learning. The corollary of these observations is that further search\nfor Unsupervised Learning competitive paradigms which may be trained in\nsimulated environments like many of those found in research and applications\nmay be futile.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 13:05:31 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 07:52:59 GMT"}, {"version": "v3", "created": "Sun, 26 Jul 2020 08:14:00 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Nissani", "Daniel N.", "", "Nissensohn"]]}, {"id": "2001.07504", "submitter": "Sophie Chabridon", "authors": "Nicolas Aussel (INF, ACMES-SAMOVAR, IP Paris), Sophie Chabridon (IP\n  Paris, INF, ACMES-SAMOVAR), Yohan Petetin (TIPIC-SAMOVAR, CITI, IP Paris)", "title": "Combining Federated and Active Learning for Communication-efficient\n  Distributed Failure Prediction in Aeronautics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning has proven useful in the recent years as a way to achieve\nfailure prediction for industrial systems. However, the high computational\nresources necessary to run learning algorithms are an obstacle to its\nwidespread application. The sub-field of Distributed Learning offers a solution\nto this problem by enabling the use of remote resources but at the expense of\nintroducing communication costs in the application that are not always\nacceptable. In this paper, we propose a distributed learning approach able to\noptimize the use of computational and communication resources to achieve\nexcellent learning model performances through a centralized architecture. To\nachieve this, we present a new centralized distributed learning algorithm that\nrelies on the learning paradigms of Active Learning and Federated Learning to\noffer a communication-efficient method that offers guarantees of model\nprecision on both the clients and the central server. We evaluate this method\non a public benchmark and show that its performances in terms of precision are\nvery close to state-of-the-art performance level of non-distributed learning\ndespite additional constraints.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 13:17:00 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Aussel", "Nicolas", "", "INF, ACMES-SAMOVAR, IP Paris"], ["Chabridon", "Sophie", "", "IP\n  Paris, INF, ACMES-SAMOVAR"], ["Petetin", "Yohan", "", "TIPIC-SAMOVAR, CITI, IP Paris"]]}, {"id": "2001.07522", "submitter": "Jan Bosch", "authors": "Jan Bosch, Ivica Crnkovic, Helena Holmstr\\\"om Olsson", "title": "Engineering AI Systems: A Research Agenda", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) and machine learning (ML) are increasingly\nbroadly adopted in industry, However, based on well over a dozen case studies,\nwe have learned that deploying industry-strength, production quality ML models\nin systems proves to be challenging. Companies experience challenges related to\ndata quality, design methods and processes, performance of models as well as\ndeployment and compliance. We learned that a new, structured engineering\napproach is required to construct and evolve systems that contain ML/DL\ncomponents. In this paper, we provide a conceptualization of the typical\nevolution patterns that companies experience when employing ML as well as an\noverview of the key problems experienced by the companies that we have studied.\nThe main contribution of the paper is a research agenda for AI engineering that\nprovides an overview of the key engineering challenges surrounding ML solutions\nand an overview of open items that need to be addressed by the research\ncommunity at large.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 20:29:48 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 12:59:36 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Bosch", "Jan", ""], ["Crnkovic", "Ivica", ""], ["Olsson", "Helena Holmstr\u00f6m", ""]]}, {"id": "2001.07524", "submitter": "Pushkar Mishra", "authors": "Pushkar Mishra, Aleksandra Piktus, Gerard Goossen, Fabrizio Silvestri", "title": "Node Masking: Making Graph Neural Networks Generalize and Scale Better", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have received a lot of interest in the recent\ntimes. From the early spectral architectures that could only operate on\nundirected graphs per a transductive learning paradigm to the current state of\nthe art spatial ones that can apply inductively to arbitrary graphs, GNNs have\nseen significant contributions from the research community. In this paper, we\nutilize some theoretical tools to better visualize the operations performed by\nstate of the art spatial GNNs. We analyze the inner workings of these\narchitectures and introduce a simple concept, Node Masking, that allows them to\ngeneralize and scale better. To empirically validate the concept, we perform\nseveral experiments on some widely-used datasets for node classification in\nboth the transductive and inductive settings, hence laying down strong\nbenchmarks for future research.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 06:26:40 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 10:14:08 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 12:40:50 GMT"}, {"version": "v4", "created": "Sun, 16 May 2021 19:40:24 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Mishra", "Pushkar", ""], ["Piktus", "Aleksandra", ""], ["Goossen", "Gerard", ""], ["Silvestri", "Fabrizio", ""]]}, {"id": "2001.07526", "submitter": "Vevake Balaraman", "authors": "Vevake Balaraman and Bernardo Magnini", "title": "Domain-Aware Dialogue State Tracker for Multi-Domain Dialogue Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In task-oriented dialogue systems the dialogue state tracker (DST) component\nis responsible for predicting the state of the dialogue based on the dialogue\nhistory. Current DST approaches rely on a predefined domain ontology, a fact\nthat limits their effective usage for large scale conversational agents, where\nthe DST constantly needs to be interfaced with ever-increasing services and\nAPIs. Focused towards overcoming this drawback, we propose a domain-aware\ndialogue state tracker, that is completely data-driven and it is modeled to\npredict for dynamic service schemas. The proposed model utilizes domain and\nslot information to extract both domain and slot specific representations for a\ngiven dialogue, and then uses such representations to predict the values of the\ncorresponding slot. Integrating this mechanism with a pretrained language model\n(i.e. BERT), our approach can effectively learn semantic relations.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 13:41:09 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Balaraman", "Vevake", ""], ["Magnini", "Bernardo", ""]]}, {"id": "2001.07527", "submitter": "Eugenio Bargiacchi", "authors": "Eugenio Bargiacchi, Timothy Verstraeten, Diederik M. Roijers, Ann\n  Now\\'e", "title": "Model-based Multi-Agent Reinforcement Learning with Cooperative\n  Prioritized Sweeping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new model-based reinforcement learning algorithm, Cooperative\nPrioritized Sweeping, for efficient learning in multi-agent Markov decision\nprocesses. The algorithm allows for sample-efficient learning on large problems\nby exploiting a factorization to approximate the value function. Our approach\nonly requires knowledge about the structure of the problem in the form of a\ndynamic decision network. Using this information, our method learns a model of\nthe environment and performs temporal difference updates which affect multiple\njoint states and actions at once. Batch updates are additionally performed\nwhich efficiently back-propagate knowledge throughout the factored Q-function.\nOur method outperforms the state-of-the-art algorithm sparse cooperative\nQ-learning algorithm, both on the well-known SysAdmin benchmark and randomized\nenvironments.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 19:13:44 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Bargiacchi", "Eugenio", ""], ["Verstraeten", "Timothy", ""], ["Roijers", "Diederik M.", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "2001.07537", "submitter": "Vinod Muthusamy", "authors": "Steve T.K. Jan, Vatche Ishakian, Vinod Muthusamy", "title": "AI Trust in business processes: The need for process-aware explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Business processes underpin a large number of enterprise operations including\nprocessing loan applications, managing invoices, and insurance claims. There is\na large opportunity for infusing AI to reduce cost or provide better customer\nexperience, and the business process management (BPM) literature is rich in\nmachine learning solutions including unsupervised learning to gain insights on\nclusters of process traces, classification models to predict the outcomes,\nduration, or paths of partial process traces, extracting business process from\ndocuments, and models to recommend how to optimize a business process or\nnavigate decision points. More recently, deep learning models including those\nfrom the NLP domain have been applied to process predictions.\n  Unfortunately, very little of these innovations have been applied and adopted\nby enterprise companies. We assert that a large reason for the lack of adoption\nof AI models in BPM is that business users are risk-averse and do not\nimplicitly trust AI models. There has, unfortunately, been little attention\npaid to explaining model predictions to business users with process context. We\nchallenge the BPM community to build on the AI interpretability literature, and\nthe AI Trust community to understand\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 13:51:36 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Jan", "Steve T. K.", ""], ["Ishakian", "Vatche", ""], ["Muthusamy", "Vinod", ""]]}, {"id": "2001.07541", "submitter": "Ana Ozaki", "authors": "Camille Bourgaux, Ana Ozaki, Rafael Pe\\~naloza and Livia Predoiu", "title": "Provenance for the Description Logic ELHr", "comments": "This is the long version of IJCAI 2020 paper 2243 (24 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of handling provenance information in ELHr ontologies.\nWe consider a setting recently introduced for ontology-based data access, based\non semirings and extending classical data provenance, in which ontology axioms\nare annotated with provenance tokens. A consequence inherits the provenance of\nthe axioms involved in deriving it, yielding a provenance polynomial as an\nannotation. We analyse the semantics for the ELHr case and show that the\npresence of conjunctions poses various difficulties for handling provenance,\nsome of which are mitigated by assuming multiplicative idempotency of the\nsemiring. Under this assumption, we study three problems: ontology completion\nwith provenance, computing the set of relevant axioms for a consequence, and\nquery answering.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 13:56:48 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 22:16:35 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Bourgaux", "Camille", ""], ["Ozaki", "Ana", ""], ["Pe\u00f1aloza", "Rafael", ""], ["Predoiu", "Livia", ""]]}, {"id": "2001.07566", "submitter": "Chenguang Lu", "authors": "Chenguang Lu", "title": "Channels' Confirmation and Predictions' Confirmation: from the Medical\n  Test to the Raven Paradox", "comments": "12 tables, 7 figures", "journal-ref": null, "doi": "10.3390/e22040384", "report-no": null, "categories": "cs.AI cs.IT math.IT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After long arguments between positivism and falsificationism, the\nverification of universal hypotheses was replaced with the confirmation of\nuncertain major premises. Unfortunately, Hemple discovered the Raven Paradox\n(RP). Then, Carnap used the logical probability increment as the confirmation\nmeasure. So far, many confirmation measures have been proposed. Measure F among\nthem proposed by Kemeny and Oppenheim possesses symmetries and asymmetries\nproposed by Elles and Fitelson, monotonicity proposed by Greco et al., and\nnormalizing property suggested by many researchers. Based on the semantic\ninformation theory, a measure b* similar to F is derived from the medical test.\nLike the likelihood ratio, b* and F can only indicate the quality of channels\nor the testing means instead of the quality of probability predictions. And, it\nis still not easy to use b*, F, or another measure to clarify the RP. For this\nreason, measure c* similar to the correct rate is derived. The c* has the\nsimple form: (a-c)/max(a, c); it supports the Nicod Criterion and undermines\nthe Equivalence Condition, and hence, can be used to eliminate the RP. Some\nexamples are provided to show why it is difficult to use one of popular\nconfirmation measures to eliminate the RP. Measure F, b*, and c* indicate that\nfewer counterexamples' existence is more essential than more positive examples'\nexistence, and hence, are compatible with Popper's falsification thought.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 11:22:18 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Lu", "Chenguang", ""]]}, {"id": "2001.07573", "submitter": "Suzanne Tolmeijer", "authors": "Suzanne Tolmeijer, Markus Kneer, Cristina Sarasua, Markus Christen,\n  Abraham Bernstein", "title": "Implementations in Machine Ethics: A Survey", "comments": "published version, journal paper, ACM Computing Surveys, 38 pages, 7\n  tables, 4 figures", "journal-ref": "ACM Comput. Surv. 53, 6, Article 132 (December 2020), 38 pages", "doi": "10.1145/3419633", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Increasingly complex and autonomous systems require machine ethics to\nmaximize the benefits and minimize the risks to society arising from the new\ntechnology. It is challenging to decide which type of ethical theory to employ\nand how to implement it effectively. This survey provides a threefold\ncontribution. First, it introduces a trimorphic taxonomy to analyze machine\nethics implementations with respect to their object (ethical theories), as well\nas their nontechnical and technical aspects. Second, an exhaustive selection\nand description of relevant works is presented. Third, applying the new\ntaxonomy to the selected works, dominant research patterns, and lessons for the\nfield are identified, and future directions for research are suggested.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 14:32:23 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 16:27:08 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Tolmeijer", "Suzanne", ""], ["Kneer", "Markus", ""], ["Sarasua", "Cristina", ""], ["Christen", "Markus", ""], ["Bernstein", "Abraham", ""]]}, {"id": "2001.07578", "submitter": "Nicholas Asher", "authors": "Nicholas Asher, Soumya Paul, Chris Russell", "title": "Adequate and fair explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining sophisticated machine-learning based systems is an important issue\nat the foundations of AI. Recent efforts have shown various methods for\nproviding explanations. These approaches can be broadly divided into two\nschools: those that provide a local and human interpreatable approximation of a\nmachine learning algorithm, and logical approaches that exactly characterise\none aspect of the decision. In this paper we focus upon the second school of\nexact explanations with a rigorous logical foundation. There is an\nepistemological problem with these exact methods. While they can furnish\ncomplete explanations, such explanations may be too complex for humans to\nunderstand or even to write down in human readable form. Interpretability\nrequires epistemically accessible explanations, explanations humans can grasp.\nYet what is a sufficiently complete epistemically accessible explanation still\nneeds clarification. We do this here in terms of counterfactuals, following\n[Wachter et al., 2017]. With counterfactual explanations, many of the\nassumptions needed to provide a complete explanation are left implicit. To do\nso, counterfactual explanations exploit the properties of a particular data\npoint or sample, and as such are also local as well as partial explanations. We\nexplore how to move from local partial explanations to what we call complete\nlocal explanations and then to global ones. But to preserve accessibility we\nargue for the need for partiality. This partiality makes it possible to hide\nexplicit biases present in the algorithm that may be injurious or unfair.We\ninvestigate how easy it is to uncover these biases in providing complete and\nfair explanations by exploiting the structure of the set of counterfactuals\nproviding a complete local explanation.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 14:42:51 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Asher", "Nicholas", ""], ["Paul", "Soumya", ""], ["Russell", "Chris", ""]]}, {"id": "2001.07592", "submitter": "Yakov Savelyev", "authors": "Yasha Savelyev", "title": "Incompleteness for stably consistent formal systems", "comments": "17 pages, rewritten with stronger results generalizing the original\n  Godel incompleteness theorems to stable consistency. Added background\n  concerning recent related works. Simplified the language, particularly the\n  notion of an abstract Turing machine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO physics.hist-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first partly develop a mathematical notion of stable consistency intended\nto reflect the actual consistency property of human beings. Then we give a\ngeneralization of the first and second G\\\"odel incompleteness theorem to stably\n$1,2$-consistent formal systems. Our argument in particular re-proves the\noriginal incompleteness theorems from first principles, using Turing machine\nlanguage to (computably) construct our \"G\\\"odel sentence\" directly, in\nparticular we do not use the diagonal lemma, nor any meta-logic, with the proof\nnaturally formalizable in set theory. In practice such a stably consistent\nformal system could be meant to represent the mathematical output of humanity\nevolving in time, so that the above gives a formalization of a famous\ndisjunction of G\\\"odel, obstructing computability of intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 15:04:15 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 00:55:26 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 16:47:08 GMT"}, {"version": "v4", "created": "Tue, 4 Aug 2020 23:10:14 GMT"}, {"version": "v5", "created": "Thu, 5 Nov 2020 18:22:25 GMT"}, {"version": "v6", "created": "Wed, 19 May 2021 17:40:44 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Savelyev", "Yasha", ""]]}, {"id": "2001.07615", "submitter": "Stefan Ultes", "authors": "Stefan Ultes", "title": "Improving Interaction Quality Estimation with BiLSTMs and the Impact on\n  Dialogue Policy Learning", "comments": "Published at SIGDIAL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning suitable and well-performing dialogue behaviour in statistical\nspoken dialogue systems has been in the focus of research for many years. While\nmost work which is based on reinforcement learning employs an objective measure\nlike task success for modelling the reward signal, we use a reward based on\nuser satisfaction estimation. We propose a novel estimator and show that it\noutperforms all previous estimators while learning temporal dependencies\nimplicitly. Furthermore, we apply this novel user satisfaction estimation model\nlive in simulated experiments where the satisfaction estimation model is\ntrained on one domain and applied in many other domains which cover a similar\ntask. We show that applying this model results in higher estimated\nsatisfaction, similar task success rates and a higher robustness to noise.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 15:39:12 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Ultes", "Stefan", ""]]}, {"id": "2001.07641", "submitter": "Johannes Schneider", "authors": "Johannes Schneider, Joshua Handali, Michalis Vlachos and Christian\n  Meske", "title": "Deceptive AI Explanations: Creation and Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) comes with great opportunities but also great\nrisks. Automatically generated explanations for decisions are deemed helpful to\nbetter understand AI, increasing transparency and fostering trust. However,\ngiven e.g. economic incentives to create dishonest AI, can we trust its\nexplanations? To address this issue, our paper investigates to what extent\nmodels of AI, i.e. deep learning, and existing instruments to increase\ntransparency regarding AI decisions can be used to create and detect deceptive\nexplanations. For empirical evaluation, we focus on text classification and\nalter explanations originating from GradCAM, a well-established technique for\ncreating explanations in neural networks. We then evaluate the effect of\ndeceptive explanations on users in an experiment with 200 participants. Our\nfindings confirm that deceptive explanations can indeed fool humans while\nmachine learning methods can detect seemingly minor attempts of deception with\naccuracy that exceeds 80\\% given sufficient domain knowledge in the form of\ntraining data. Without domain knowledge, one can still infer inconsistencies in\nthe explanations in an unsupervised manner given basic knowledge on the\nallegedly deceptive model.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 16:41:22 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 21:02:51 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Schneider", "Johannes", ""], ["Handali", "Joshua", ""], ["Vlachos", "Michalis", ""], ["Meske", "Christian", ""]]}, {"id": "2001.07679", "submitter": "Mohamadreza Ahmadi", "authors": "Mohamadreza Ahmadi, Rangoli Sharan, and Joel W. Burdick", "title": "Stochastic Finite State Control of POMDPs with LTL Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL cs.RO cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partially observable Markov decision processes (POMDPs) provide a modeling\nframework for autonomous decision making under uncertainty and imperfect\nsensing, e.g. robot manipulation and self-driving cars. However, optimal\ncontrol of POMDPs is notoriously intractable. This paper considers the\nquantitative problem of synthesizing sub-optimal stochastic finite state\ncontrollers (sFSCs) for POMDPs such that the probability of satisfying a set of\nhigh-level specifications in terms of linear temporal logic (LTL) formulae is\nmaximized. We begin by casting the latter problem into an optimization and use\nrelaxations based on the Poisson equation and McCormick envelopes. Then, we\npropose an stochastic bounded policy iteration algorithm, leading to a\ncontrolled growth in sFSC size and an any time algorithm, where the performance\nof the controller improves with successive iterations, but can be stopped by\nthe user based on time or memory considerations. We illustrate the proposed\nmethod by a robot navigation case study.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 18:10:47 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Ahmadi", "Mohamadreza", ""], ["Sharan", "Rangoli", ""], ["Burdick", "Joel W.", ""]]}, {"id": "2001.07709", "submitter": "Kun He Prof.", "authors": "Kun He, Kevin Tole, Fei Ni, Yong Yuan, Linyun Liao", "title": "Adaptive Large Neighborhood Search for Circle Bin Packing Problem", "comments": "13 pages, 6 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address a new variant of packing problem called the circle bin packing\nproblem (CBPP), which is to find a dense packing of circle items to multiple\nsquare bins so as to minimize the number of used bins. To this end, we propose\nan adaptive large neighborhood search (ALNS) algorithm, which uses our Greedy\nAlgorithm with Corner Occupying Action (GACOA) to construct an initial layout.\nThe greedy solution is usually in a local optimum trap, and ALNS enables\nmultiple neighborhood search that depends on the stochastic annealing schedule\nto avoid getting stuck in local minimum traps. Specifically, ALNS perturbs the\ncurrent layout to jump out of a local optimum by iteratively reassigns some\ncircles and accepts the new layout with some probability during the search. The\nacceptance probability is adjusted adaptively using simulated annealing that\nfine-tunes the search direction in order to reach the global optimum. We\nbenchmark computational results against GACOA in heterogeneous instances. ALNS\nalways outperforms GACOA in improving the objective function, and in several\ncases, there is a significant reduction on the number of bins used in the\npacking.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 10:14:15 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["He", "Kun", ""], ["Tole", "Kevin", ""], ["Ni", "Fei", ""], ["Yuan", "Yong", ""], ["Liao", "Linyun", ""]]}, {"id": "2001.07752", "submitter": "Luyao Yuan", "authors": "Luyao Yuan, Zipeng Fu, Jingyue Shen, Lu Xu, Junhong Shen, Song-Chun\n  Zhu", "title": "Emergence of Pragmatics from Referential Game between Theory of Mind\n  Agents", "comments": null, "journal-ref": "Emergent Communication Workshop, 33rd Conference on Neural\n  Information Processing Systems (NeurIPS 2019)", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pragmatics studies how context can contribute to language meanings [1]. In\nhuman communication, language is never interpreted out of context, and\nsentences can usually convey more information than their literal meanings [2].\nHowever, this mechanism is missing in most multi-agent systems [3, 4, 5, 6],\nrestricting the communication efficiency and the capability of human-agent\ninteraction. In this paper, we propose an algorithm, using which agents can\nspontaneously learn the ability to \"read between lines\" without any explicit\nhand-designed rules. We integrate the theory of mind (ToM) [7, 8] in a\ncooperative multi-agent pedagogical situation and propose an adaptive\nreinforcement learning (RL) algorithm to develop a communication protocol. ToM\nis a profound cognitive science concept, claiming that people regularly reason\nabout other's mental states, including beliefs, goals, and intentions, to\nobtain performance advantage in competition, cooperation or coalition. With\nthis ability, agents consider language as not only messages but also rational\nacts reflecting others' hidden states. Our experiments demonstrate the\nadvantage of pragmatic protocols over non-pragmatic protocols. We also show the\nteaching complexity following the pragmatic protocol empirically approximates\nto recursive teaching dimension (RTD).\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 19:37:33 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Yuan", "Luyao", ""], ["Fu", "Zipeng", ""], ["Shen", "Jingyue", ""], ["Xu", "Lu", ""], ["Shen", "Junhong", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2001.07754", "submitter": "Anneke Haga", "authors": "Anneke Haga, Carsten Lutz, Johannes Marti, Frank Wolter", "title": "A Journey into Ontology Approximation: From Non-Horn to Horn", "comments": "21 pages, 4 figures, paragraph with examples added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study complete approximations of an ontology formulated in a non-Horn\ndescription logic (DL) such as $\\mathcal{ALC}$ in a Horn DL such\nas~$\\mathcal{EL}$. We provide concrete approximation schemes that are\nnecessarily infinite and observe that in the $\\mathcal{ELU}$-to-$\\mathcal{EL}$\ncase finite approximations tend to exist in practice and are guaranteed to\nexist when the original ontology is acyclic. In contrast, neither of this is\nthe case for $\\mathcal{ELU}_\\bot$-to-$\\mathcal{EL}_\\bot$ and for\n$\\mathcal{ALC}$-to-$\\mathcal{EL}_\\bot$ approximations. We also define a notion\nof approximation tailored towards ontology-mediated querying, connect it to\nsubsumption-based approximations, and identify a case where finite\napproximations are guaranteed to exist.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 19:47:21 GMT"}, {"version": "v2", "created": "Sat, 25 Jan 2020 09:18:11 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 09:45:13 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 20:01:03 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Haga", "Anneke", ""], ["Lutz", "Carsten", ""], ["Marti", "Johannes", ""], ["Wolter", "Frank", ""]]}, {"id": "2001.07804", "submitter": "Gongjin Lan", "authors": "Gongjin Lan, Matteo De Carlo, Fuda van Diggelen, Jakub M. Tomczak,\n  Diederik M. Roijers, and A.E. Eiben", "title": "Learning Directed Locomotion in Modular Robots with Evolvable\n  Morphologies", "comments": "30 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the well-studied problem of gait learning in modular robots in\ntwo dimensions. Firstly, we address locomotion in a given target direction that\ngoes beyond learning a typical undirected gait. Secondly, rather than studying\none fixed robot morphology we consider a test suite of different modular\nrobots. This study is based on our interest in evolutionary robot systems where\nboth morphologies and controllers evolve. In such a system, newborn robots have\nto learn to control their own body that is a random combination of the bodies\nof the parents. We apply and compare two learning algorithms, Bayesian\noptimization and HyperNEAT. The results of the experiments in simulation show\nthat both methods successfully learn good controllers, but Bayesian\noptimization is more effective and efficient. We validate the best learned\ncontrollers by constructing three robots from the test suite in the real world\nand observe their fitness and actual trajectories. The obtained results\nindicate a reality gap that depends on the controllers and the shape of the\nrobots, but overall the trajectories are adequate and follow the target\ndirections successfully.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 23:01:00 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Lan", "Gongjin", ""], ["De Carlo", "Matteo", ""], ["van Diggelen", "Fuda", ""], ["Tomczak", "Jakub M.", ""], ["Roijers", "Diederik M.", ""], ["Eiben", "A. E.", ""]]}, {"id": "2001.07838", "submitter": "Bilal Abu-Salih", "authors": "Bilal Abu-Salih, Kit Yan Chan, Omar Al-Kadi, Marwan Al-Tawil, Pornpit\n  Wongthongtham, Tomayess Issa, Heba Saadeh, Malak Al-Hassan, Bushra Bremie,\n  Abdulaziz Albahlal", "title": "An Approach for Time-aware Domain-based Social Influence Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Social Networks(OSNs) have established virtual platforms enabling\npeople to express their opinions, interests and thoughts in a variety of\ncontexts and domains, allowing legitimate users as well as spammers and other\nuntrustworthy users to publish and spread their content. Hence, the concept of\nsocial trust has attracted the attention of information processors/data\nscientists and information consumers/business firms. One of the main reasons\nfor acquiring the value of Social Big Data (SBD) is to provide frameworks and\nmethodologies using which the credibility of OSNs users can be evaluated. These\napproaches should be scalable to accommodate large-scale social data. Hence,\nthere is a need for well comprehending of social trust to improve and expand\nthe analysis process and inferring the credibility of SBD. Given the exposed\nenvironment's settings and fewer limitations related to OSNs, the medium allows\nlegitimate and genuine users as well as spammers and other low trustworthy\nusers to publish and spread their content. Hence, this paper presents an\napproach incorporates semantic analysis and machine learning modules to measure\nand predict users' trustworthiness in numerous domains in different time\nperiods. The evaluation of the conducted experiment validates the applicability\nof the incorporated machine learning techniques to predict highly trustworthy\ndomain-based users.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 10:39:37 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Abu-Salih", "Bilal", ""], ["Chan", "Kit Yan", ""], ["Al-Kadi", "Omar", ""], ["Al-Tawil", "Marwan", ""], ["Wongthongtham", "Pornpit", ""], ["Issa", "Tomayess", ""], ["Saadeh", "Heba", ""], ["Al-Hassan", "Malak", ""], ["Bremie", "Bushra", ""], ["Albahlal", "Abdulaziz", ""]]}, {"id": "2001.07914", "submitter": "Sahil Verma", "authors": "Sahil Verma, Roland H.C. Yap", "title": "Benchmarking Symbolic Execution Using Constraint Problems -- Initial\n  Results", "comments": null, "journal-ref": "ICTAI 2019", "doi": "10.1109/ICTAI.2019.00010", "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic execution is a powerful technique for bug finding and program\ntesting. It is successful in finding bugs in real-world code. The core\nreasoning techniques use constraint solving, path exploration, and search,\nwhich are also the same techniques used in solving combinatorial problems,\ne.g., finite-domain constraint satisfaction problems (CSPs). We propose CSP\ninstances as more challenging benchmarks to evaluate the effectiveness of the\ncore techniques in symbolic execution. We transform CSP benchmarks into C\nprograms suitable for testing the reasoning capabilities of symbolic execution\ntools. From a single CSP P, we transform P depending on transformation choice\ninto different C programs. Preliminary testing with the KLEE, Tracer-X, and\nLLBMC tools show substantial runtime differences from transformation and solver\nchoice. Our C benchmarks are effective in showing the limitations of existing\nsymbolic execution tools. The motivation for this work is we believe that\nbenchmarks of this form can spur the development and engineering of improved\ncore reasoning in symbolic execution engines.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 08:48:55 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Verma", "Sahil", ""], ["Yap", "Roland H. C.", ""]]}, {"id": "2001.07993", "submitter": "Rajiv Ranjan Kumar", "authors": "Rajiv Ranjan Kumar, Pradeep Varakantham", "title": "On Solving Cooperative MARL Problems with a Few Good Experiences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative Multi-agent Reinforcement Learning (MARL) is crucial for\ncooperative decentralized decision learning in many domains such as search and\nrescue, drone surveillance, package delivery and fire fighting problems. In\nthese domains, a key challenge is learning with a few good experiences, i.e.,\npositive reinforcements are obtained only in a few situations (e.g., on\nextinguishing a fire or tracking a crime or delivering a package) and in most\nother situations there is zero or negative reinforcement. Learning decisions\nwith a few good experiences is extremely challenging in cooperative MARL\nproblems due to three reasons. First, compared to the single agent case,\nexploration is harder as multiple agents have to be coordinated to receive a\ngood experience. Second, environment is not stationary as all the agents are\nlearning at the same time (and hence change policies). Third, scale of problem\nincreases significantly with every additional agent.\n  Relevant existing work is extensive and has focussed on dealing with a few\ngood experiences in single-agent RL problems or on scalable approaches for\nhandling non-stationarity in MARL problems. Unfortunately, neither of these\napproaches (or their extensions) are able to address the problem of sparse good\nexperiences effectively. Therefore, we provide a novel fictitious self\nimitation approach that is able to simultaneously handle non-stationarity and\nsparse good experiences in a scalable manner. Finally, we provide a thorough\ncomparison (experimental or descriptive) against relevant cooperative MARL\nalgorithms to demonstrate the utility of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 12:53:53 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Kumar", "Rajiv Ranjan", ""], ["Varakantham", "Pradeep", ""]]}, {"id": "2001.08013", "submitter": "Balaji Ganesan", "authors": "Balaji Ganesan, Riddhiman Dasgupta, Akshay Parekh, Hima Patel, and\n  Berthold Reinwald", "title": "A Neural Architecture for Person Ontology population", "comments": "6 pages, 10 figures. arXiv admin note: substantial text overlap with\n  arXiv:1811.09368", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A person ontology comprising concepts, attributes and relationships of people\nhas a number of applications in data protection, didentification, population of\nknowledge graphs for business intelligence and fraud prevention. While\nartificial neural networks have led to improvements in Entity Recognition,\nEntity Classification, and Relation Extraction, creating an ontology largely\nremains a manual process, because it requires a fixed set of semantic relations\nbetween concepts. In this work, we present a system for automatically\npopulating a person ontology graph from unstructured data using neural models\nfor Entity Classification and Relation Extraction. We introduce a new dataset\nfor these tasks and discuss our results.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 13:49:14 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Ganesan", "Balaji", ""], ["Dasgupta", "Riddhiman", ""], ["Parekh", "Akshay", ""], ["Patel", "Hima", ""], ["Reinwald", "Berthold", ""]]}, {"id": "2001.08016", "submitter": "Shikha Singh", "authors": "Shikha Singh, Deepak Khemani", "title": "Subjective Knowledge and Reasoning about Agents in Multi-Agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though a lot of work in multi-agent systems is focused on reasoning about\nknowledge and beliefs of artificial agents, an explicit representation and\nreasoning about the presence/absence of agents, especially in the scenarios\nwhere agents may be unaware of other agents joining in or going offline in a\nmulti-agent system, leading to partial knowledge/asymmetric knowledge of the\nagents is mostly overlooked by the MAS community. Such scenarios lay the\nfoundations of cases where an agent can influence other agents' mental states\nby (mis)informing them about the presence/absence of collaborators or\nadversaries. In this paper, we investigate how Kripke structure-based epistemic\nmodels can be extended to express the above notion based on an agent's\nsubjective knowledge and we discuss the challenges that come along.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 13:50:26 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Singh", "Shikha", ""], ["Khemani", "Deepak", ""]]}, {"id": "2001.08034", "submitter": "Darryl Hannan", "authors": "Darryl Hannan, Akshay Jain, and Mohit Bansal", "title": "ManyModalQA: Modality Disambiguation and QA over Diverse Inputs", "comments": "AAAI 2020 (10 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new multimodal question answering challenge, ManyModalQA, in\nwhich an agent must answer a question by considering three distinct modalities:\ntext, images, and tables. We collect our data by scraping Wikipedia and then\nutilize crowdsourcing to collect question-answer pairs. Our questions are\nambiguous, in that the modality that contains the answer is not easily\ndetermined based solely upon the question. To demonstrate this ambiguity, we\nconstruct a modality selector (or disambiguator) network, and this model gets\nsubstantially lower accuracy on our challenge set, compared to existing\ndatasets, indicating that our questions are more ambiguous. By analyzing this\nmodel, we investigate which words in the question are indicative of the\nmodality. Next, we construct a simple baseline ManyModalQA model, which, based\non the prediction from the modality selector, fires a corresponding pre-trained\nstate-of-the-art unimodal QA model. We focus on providing the community with a\nnew manymodal evaluation set and only provide a fine-tuning set, with the\nexpectation that existing datasets and approaches will be transferred for most\nof the training, to encourage low-resource generalization without large,\nmonolithic training sets for each new task. There is a significant gap between\nour baseline models and human performance; therefore, we hope that this\nchallenge encourages research in end-to-end modality disambiguation and\nmultimodal QA models, as well as transfer learning. Code and data available at:\nhttps://github.com/hannandarryl/ManyModalQA\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 14:39:28 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Hannan", "Darryl", ""], ["Jain", "Akshay", ""], ["Bansal", "Mohit", ""]]}, {"id": "2001.08116", "submitter": "David Warde-Farley", "authors": "Tom Van de Wiele, David Warde-Farley, Andriy Mnih and Volodymyr Mnih", "title": "Q-Learning in enormous action spaces via amortized approximate\n  maximization", "comments": "A previous version of this work appeared at the Deep Reinforcement\n  Learning Workshop, NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying Q-learning to high-dimensional or continuous action spaces can be\ndifficult due to the required maximization over the set of possible actions.\nMotivated by techniques from amortized inference, we replace the expensive\nmaximization over all actions with a maximization over a small subset of\npossible actions sampled from a learned proposal distribution. The resulting\napproach, which we dub Amortized Q-learning (AQL), is able to handle discrete,\ncontinuous, or hybrid action spaces while maintaining the benefits of\nQ-learning. Our experiments on continuous control tasks with up to 21\ndimensional actions show that AQL outperforms D3PG (Barth-Maron et al, 2018)\nand QT-Opt (Kalashnikov et al, 2018). Experiments on structured discrete action\nspaces demonstrate that AQL can efficiently learn good policies in spaces with\nthousands of discrete actions.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:14:38 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Van de Wiele", "Tom", ""], ["Warde-Farley", "David", ""], ["Mnih", "Andriy", ""], ["Mnih", "Volodymyr", ""]]}, {"id": "2001.08173", "submitter": "Peyman Hosseinzadeh Kassani", "authors": "Peyman Hosseinzadeh Kassani, Li Xiao, Gemeng Zhang, Julia M. Stephen,\n  Tony W. Wilson, Vince D. Calhoun, Yu Ping Wang", "title": "Causality based Feature Fusion for Brain Neuro-Developmental Analysis", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human brain development is a complex and dynamic process that is affected by\nseveral factors such as genetics, sex hormones, and environmental changes. A\nnumber of recent studies on brain development have examined functional\nconnectivity (FC) defined by the temporal correlation between time series of\ndifferent brain regions. We propose to add the directional flow of information\nduring brain maturation. To do so, we extract effective connectivity (EC)\nthrough Granger causality (GC) for two different groups of subjects, i.e.,\nchildren and young adults. The motivation is that the inclusion of causal\ninteraction may further discriminate brain connections between two age groups\nand help to discover new connections between brain regions. The contributions\nof this study are threefold. First, there has been a lack of attention to\nEC-based feature extraction in the context of brain development. To this end,\nwe propose a new kernel-based GC (KGC) method to learn nonlinearity of complex\nbrain network, where a reduced Sine hyperbolic polynomial (RSP) neural network\nwas used as our proposed learner. Second, we used causality values as the\nweight for the directional connectivity between brain regions. Our findings\nindicated that the strength of connections was significantly higher in young\nadults relative to children. In addition, our new EC-based feature outperformed\nFC-based analysis from Philadelphia neurocohort (PNC) study with better\ndiscrimination of the different age groups. Moreover, the fusion of these two\nsets of features (FC + EC) improved brain age prediction accuracy by more than\n4%, indicating that they should be used together for brain development studies.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 17:38:42 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kassani", "Peyman Hosseinzadeh", ""], ["Xiao", "Li", ""], ["Zhang", "Gemeng", ""], ["Stephen", "Julia M.", ""], ["Wilson", "Tony W.", ""], ["Calhoun", "Vince D.", ""], ["Wang", "Yu Ping", ""]]}, {"id": "2001.08177", "submitter": "Roxana R\\u{a}dulescu", "authors": "Roxana R\\u{a}dulescu, Patrick Mannion, Yijie Zhang, Diederik M.\n  Roijers, and Ann Now\\'e", "title": "A utility-based analysis of equilibria in multi-objective normal form\n  games", "comments": "Under review since 16 January 2020", "journal-ref": null, "doi": "10.1017/S0269888920000351", "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-objective multi-agent systems (MOMAS), agents explicitly consider\nthe possible tradeoffs between conflicting objective functions. We argue that\ncompromises between competing objectives in MOMAS should be analysed on the\nbasis of the utility that these compromises have for the users of a system,\nwhere an agent's utility function maps their payoff vectors to scalar utility\nvalues. This utility-based approach naturally leads to two different\noptimisation criteria for agents in a MOMAS: expected scalarised returns (ESR)\nand scalarised expected returns (SER). In this article, we explore the\ndifferences between these two criteria using the framework of multi-objective\nnormal form games (MONFGs). We demonstrate that the choice of optimisation\ncriterion (ESR or SER) can radically alter the set of equilibria in a MONFG\nwhen non-linear utility functions are used.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 22:27:38 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["R\u0103dulescu", "Roxana", ""], ["Mannion", "Patrick", ""], ["Zhang", "Yijie", ""], ["Roijers", "Diederik M.", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "2001.08179", "submitter": "Xingyao Zhang", "authors": "Xingyao Zhang, Cao Xiao, Lucas M. Glass, Jimeng Sun", "title": "DeepEnroll: Patient-Trial Matching with Deep Embedding and Entailment\n  Prediction", "comments": "accepted by The World Wide Web Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical trials are essential for drug development but often suffer from\nexpensive, inaccurate and insufficient patient recruitment. The core problem of\npatient-trial matching is to find qualified patients for a trial, where patient\ninformation is stored in electronic health records (EHR) while trial\neligibility criteria (EC) are described in text documents available on the web.\nHow to represent longitudinal patient EHR? How to extract complex logical rules\nfrom EC? Most existing works rely on manual rule-based extraction, which is\ntime consuming and inflexible for complex inference. To address these\nchallenges, we proposed DeepEnroll, a cross-modal inference learning model to\njointly encode enrollment criteria (text) and patients records (tabular data)\ninto a shared latent space for matching inference. DeepEnroll applies a\npre-trained Bidirectional Encoder Representations from Transformers(BERT) model\nto encode clinical trial information into sentence embedding. And uses a\nhierarchical embedding model to represent patient longitudinal EHR. In\naddition, DeepEnroll is augmented by a numerical information embedding and\nentailment module to reason over numerical information in both EC and EHR.\nThese encoders are trained jointly to optimize patient-trial matching score. We\nevaluated DeepEnroll on the trial-patient matching task with demonstrated on\nreal world datasets. DeepEnroll outperformed the best baseline by up to 12.4%\nin average F1.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 17:51:25 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 02:39:47 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zhang", "Xingyao", ""], ["Xiao", "Cao", ""], ["Glass", "Lucas M.", ""], ["Sun", "Jimeng", ""]]}, {"id": "2001.08192", "submitter": "Michael Nwogugu", "authors": "Michael C. Nwogugu", "title": "Complexity, Stability Properties of Mixed Games and Dynamic Algorithms,\n  and Learning in the Sharing Economy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI econ.TH math.DS nlin.AO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Sharing Economy (which includes Airbnb, Apple, Alibaba, Uber, WeWork,\nEbay, Didi Chuxing, Amazon) blossomed across the world, triggered structural\nchanges in industries and significantly affected international capital flows\nprimarily by disobeying a wide variety of statutes and laws in many countries.\nThey also illegally reduced and changing the nature of competition in many\nindustries often to the detriment of social welfare. This article develops new\ndynamic pricing models for the SEOs and derives some stability properties of\nmixed games and dynamic algorithms which eliminate antitrust liability and also\nreduce deadweight losses, greed, Regret and GPS manipulation. The new dynamic\npricing models contravene the Myerson Satterthwaite Impossibility Theorem.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 01:09:36 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Nwogugu", "Michael C.", ""]]}, {"id": "2001.08193", "submitter": "Veronique Ventos", "authors": "J Li, S Thepaut, V Ventos", "title": "StarAI: Reducing incompleteness in the game of Bridge using PLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bridge is a trick-taking card game requiring the ability to evaluate\nprobabilities since it is a game of incomplete information where each player\nonly sees its cards. In order to choose a strategy, a player needs to gather\ninformation about the hidden cards in the other players' hand. We present a\nmethodology allowing us to model a part of card playing in Bridge using\nProbabilistic Logic Programming.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 18:27:51 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Li", "J", ""], ["Thepaut", "S", ""], ["Ventos", "V", ""]]}, {"id": "2001.08236", "submitter": "Tao Chen", "authors": "Tao Chen, Miqing Li, Ke Li, and Kalyanmoy Deb", "title": "Search-Based Software Engineering for Self-Adaptive Systems: Survey,\n  Disappointments, Suggestions and Opportunities", "comments": "submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search-Based Software Engineering (SBSE) is a promising paradigm that\nexploits the computational search to optimize different processes when\nengineering complex software systems. Self-adaptive system (SAS) is one\ncategory of such complex systems that permits to optimize different functional\nand non-functional objectives/criteria under changing environments (e.g.,\nrequirements and workload), which involves problems that are subject to search.\nIn this regard, over years, there has been a considerable amount of work that\ninvestigates SBSE for SASs. In this paper, we provide the first systematic and\ncomprehensive survey exclusively on SBSE for SASs, covering papers in 27 venues\nfrom 7 repositories, which eventually leads to several key statistics from the\nmost notable 74 primary studies in this particular field of research. Our\nresults, surprisingly, have revealed five disappointments that are of utmost\nimportance and can result in serve consequences but have been overwhelmingly\nignored in existing studies. We provide theoretical and/or experimental\nevidence to justify our arguments against the disappointments, present\nsuggestions, and highlight the promising research opportunities towards their\nmitigation. We also elaborate on three other emergent, but currently\nunder-explored opportunities for future work on SBSE for SASs. By mitigating\nthe disappointments revealed in this work, together with the highlighted\nopportunities, we hope to be able to excite a much more significant growth in\nthis particular research direction.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 19:10:41 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 21:58:40 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Chen", "Tao", ""], ["Li", "Miqing", ""], ["Li", "Ke", ""], ["Deb", "Kalyanmoy", ""]]}, {"id": "2001.08279", "submitter": "Rahul Radhakrishnan Iyer", "authors": "Rahul Radhakrishnan Iyer, Miguel Ballesteros, Chris Dyer, Robert\n  Frederking", "title": "Transition-Based Dependency Parsing using Perceptron Learner", "comments": "This was part of an assignment at my graduate course at LTI. This\n  does not offer any major novelties", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntactic parsing using dependency structures has become a standard technique\nin natural language processing with many different parsing models, in\nparticular data-driven models that can be trained on syntactically annotated\ncorpora. In this paper, we tackle transition-based dependency parsing using a\nPerceptron Learner. Our proposed model, which adds more relevant features to\nthe Perceptron Learner, outperforms a baseline arc-standard parser. We beat the\nUAS of the MALT and LSTM parsers. We also give possible ways to address parsing\nof non-projective trees.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 20:58:22 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 22:09:19 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Iyer", "Rahul Radhakrishnan", ""], ["Ballesteros", "Miguel", ""], ["Dyer", "Chris", ""], ["Frederking", "Robert", ""]]}, {"id": "2001.08298", "submitter": "Zana Bu\\c{c}inca", "authors": "Zana Bu\\c{c}inca, Phoebe Lin, Krzysztof Z. Gajos, Elena L. Glassman", "title": "Proxy Tasks and Subjective Measures Can Be Misleading in Evaluating\n  Explainable AI Systems", "comments": null, "journal-ref": null, "doi": "10.1145/3377325.3377498", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable artificially intelligent (XAI) systems form part of\nsociotechnical systems, e.g., human+AI teams tasked with making decisions. Yet,\ncurrent XAI systems are rarely evaluated by measuring the performance of\nhuman+AI teams on actual decision-making tasks. We conducted two online\nexperiments and one in-person think-aloud study to evaluate two currently\ncommon techniques for evaluating XAI systems: (1) using proxy, artificial tasks\nsuch as how well humans predict the AI's decision from the given explanations,\nand (2) using subjective measures of trust and preference as predictors of\nactual performance. The results of our experiments demonstrate that evaluations\nwith proxy tasks did not predict the results of the evaluations with the actual\ndecision-making tasks. Further, the subjective measures on evaluations with\nactual decision-making tasks did not predict the objective performance on those\nsame tasks. Our results suggest that by employing misleading evaluation\nmethods, our field may be inadvertently slowing its progress toward developing\nhuman+AI teams that can reliably perform better than humans or AIs alone.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 22:14:28 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Bu\u00e7inca", "Zana", ""], ["Lin", "Phoebe", ""], ["Gajos", "Krzysztof Z.", ""], ["Glassman", "Elena L.", ""]]}, {"id": "2001.08299", "submitter": "Rohan Chitnis", "authors": "Rohan Chitnis, Tom Silver, Joshua Tenenbaum, Leslie Pack Kaelbling,\n  Tomas Lozano-Perez", "title": "GLIB: Efficient Exploration for Relational Model-Based Reinforcement\n  Learning via Goal-Literal Babbling", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of efficient exploration for transition model learning\nin the relational model-based reinforcement learning setting without extrinsic\ngoals or rewards. Inspired by human curiosity, we propose goal-literal babbling\n(GLIB), a simple and general method for exploration in such problems. GLIB\nsamples relational conjunctive goals that can be understood as specific,\ntargeted effects that the agent would like to achieve in the world, and plans\nto achieve these goals using the transition model being learned. We provide\ntheoretical guarantees showing that exploration with GLIB will converge almost\nsurely to the ground truth model. Experimentally, we find GLIB to strongly\noutperform existing methods in both prediction and planning on a range of\ntasks, encompassing standard PDDL and PPDDL planning benchmarks and a robotic\nmanipulation task implemented in the PyBullet physics simulator. Video:\nhttps://youtu.be/F6lmrPT6TOY Code: https://git.io/JIsTB\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 22:24:06 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 14:54:54 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 19:53:36 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Chitnis", "Rohan", ""], ["Silver", "Tom", ""], ["Tenenbaum", "Joshua", ""], ["Kaelbling", "Leslie Pack", ""], ["Lozano-Perez", "Tomas", ""]]}, {"id": "2001.08335", "submitter": "Ryuta Arisaka", "authors": "Ryuta Arisaka and Takayuki Ito", "title": "Numerical Abstract Persuasion Argumentation for Expressing Concurrent\n  Multi-Agent Negotiations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A negotiation process by 2 agents e1 and e2 can be interleaved by another\nnegotiation process between, say, e1 and e3. The interleaving may alter the\nresource allocation assumed at the inception of the first negotiation process.\nExisting proposals for argumentation-based negotiations have focused primarily\non two-agent bilateral negotiations, but scarcely on the concurrency of\nmulti-agent negotiations. To fill the gap, we present a novel argumentation\ntheory, basing its development on abstract persuasion argumentation (which is\nan abstract argumentation formalism with a dynamic relation). Incorporating\ninto it numerical information and a mechanism of handshakes among members of\nthe dynamic relation, we show that the extended theory adapts well to\nconcurrent multi-agent negotiations over scarce resources.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 01:46:58 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Arisaka", "Ryuta", ""], ["Ito", "Takayuki", ""]]}, {"id": "2001.08357", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Zhengang Li, Yifan Gong, Tianyun Zhang, Wei Niu, Zheng\n  Zhan, Pu Zhao, Jian Tang, Xue Lin, Bin Ren, Yanzhi Wang", "title": "BLK-REW: A Unified Block-based DNN Pruning Framework using Reweighted\n  Regularization Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accelerating DNN execution on various resource-limited computing platforms\nhas been a long-standing problem. Prior works utilize l1-based group lasso or\ndynamic regularization such as ADMM to perform structured pruning on DNN models\nto leverage the parallel computing architectures. However, both of the pruning\ndimensions and pruning methods lack universality, which leads to degraded\nperformance and limited applicability. To solve the problem, we propose a new\nblock-based pruning framework that comprises a general and flexible structured\npruning dimension as well as a powerful and efficient reweighted regularization\nmethod. Our framework is universal, which can be applied to both CNNs and RNNs,\nimplying complete support for the two major kinds of computation-intensive\nlayers (i.e., CONV and FC layers). To complete all aspects of the\npruning-for-acceleration task, we also integrate compiler-based code\noptimization into our framework that can perform DNN inference in a real-time\nmanner. To the best of our knowledge, it is the first time that the weight\npruning framework achieves universal coverage for both CNNs and RNNs with\nreal-time mobile acceleration and no accuracy compromise.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 03:30:56 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 03:00:10 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ma", "Xiaolong", ""], ["Li", "Zhengang", ""], ["Gong", "Yifan", ""], ["Zhang", "Tianyun", ""], ["Niu", "Wei", ""], ["Zhan", "Zheng", ""], ["Zhao", "Pu", ""], ["Tang", "Jian", ""], ["Lin", "Xue", ""], ["Ren", "Bin", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2001.08372", "submitter": "Andreas Hinterreiter", "authors": "Andreas Hinterreiter and Christian Steinparz and Moritz Sch\\\"ofl and\n  Holger Stitz and Marc Streit", "title": "ProjectionPathExplorer: Exploring Visual Patterns in Projected\n  Decision-Making Paths", "comments": "Final version; accepted for publication in the ACM TiiS Special Issue\n  on \"Interactive Visual Analytics for Making Explainable and Accountable\n  Decisions\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In problem-solving, a path towards solutions can be viewed as a sequence of\ndecisions. The decisions, made by humans or computers, describe a trajectory\nthrough a high-dimensional representation space of the problem. By means of\ndimensionality reduction, these trajectories can be visualized in\nlower-dimensional space. Such embedded trajectories have previously been\napplied to a wide variety of data, but analysis has focused almost exclusively\non the self-similarity of single trajectories. In contrast, we describe\npatterns emerging from drawing many trajectories---for different initial\nconditions, end states, and solution strategies---in the same embedding space.\nWe argue that general statements about the problem-solving tasks and solving\nstrategies can be made by interpreting these patterns. We explore and\ncharacterize such patterns in trajectories resulting from human and\nmachine-made decisions in a variety of application domains: logic puzzles\n(Rubik's cube), strategy games (chess), and optimization problems (neural\nnetwork training). We also discuss the importance of suitably chosen\nrepresentation spaces and similarity metrics for the embedding.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 13:29:11 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 15:39:05 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Hinterreiter", "Andreas", ""], ["Steinparz", "Christian", ""], ["Sch\u00f6fl", "Moritz", ""], ["Stitz", "Holger", ""], ["Streit", "Marc", ""]]}, {"id": "2001.08398", "submitter": "Andrea Frank", "authors": "Andrea Frank, Laurel Riek", "title": "Socially intelligent task and motion planning for human-robot\n  interaction", "comments": "2 pages plus references, no figures. Presented at RSS 2019 Workshop\n  on Robust Task and Motion Planning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As social beings, much human behavior is predicated on social context - the\nambient social state that includes cultural norms, social signals, individual\npreferences, etc. In this paper, we propose a socially-aware task and motion\nplanning algorithm that considers social context to generate appropriate and\neffective plans in human social environments (HSEs). The key strength of our\nproposed approach is that it explicitly models how potential actions not only\naffect objective cost, but also transform the social context in which it plans\nand acts. We investigate strategies to limit the complexity of our algorithm,\nso that our planner will remain tractable for mobile platforms in complex HSEs\nlike hospitals and factories. The planner will also consider the relative\nimportance and urgency of its tasks, which it uses to determine when it is and\nis not appropriate to violate social expectations to achieve its objective.\nThis social awareness will allow robots to understand a fundamental rule of\nsociety: just because something makes your job easier, does not make it the\nright thing to do!\n  To our knowledge, the proposed work is the first task and motion planning\napproach that supports socially intelligent robot policy for HSEs. Through this\nongoing work, robots will be able to understand, respect, and leverage social\ncontext accomplish tasks both acceptably and effectively in HSEs.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 07:48:22 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Frank", "Andrea", ""], ["Riek", "Laurel", ""]]}, {"id": "2001.08481", "submitter": "Oier Mees", "authors": "Oier Mees, Alp Emek, Johan Vertens, Wolfram Burgard", "title": "Learning Object Placements For Relational Instructions by Hallucinating\n  Scene Representations", "comments": "Accepted at the 2020 IEEE International Conference on Robotics and\n  Automation (ICRA). Video at https://www.youtube.com/watch?v=zaZkHTWFMKM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots coexisting with humans in their environment and performing services\nfor them need the ability to interact with them. One particular requirement for\nsuch robots is that they are able to understand spatial relations and can place\nobjects in accordance with the spatial relations expressed by their user. In\nthis work, we present a convolutional neural network for estimating pixelwise\nobject placement probabilities for a set of spatial relations from a single\ninput image. During training, our network receives the learning signal by\nclassifying hallucinated high-level scene representations as an auxiliary task.\nUnlike previous approaches, our method does not require ground truth data for\nthe pixelwise relational probabilities or 3D models of the objects, which\nsignificantly expands the applicability in practical applications. Our results\nobtained using real-world data and human-robot experiments demonstrate the\neffectiveness of our method in reasoning about the best way to place objects to\nreproduce a spatial relation. Videos of our experiments can be found at\nhttps://youtu.be/zaZkHTWFMKM\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 12:58:50 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 18:14:11 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Mees", "Oier", ""], ["Emek", "Alp", ""], ["Vertens", "Johan", ""], ["Burgard", "Wolfram", ""]]}, {"id": "2001.08525", "submitter": "Yehia Elrakaiby", "authors": "Yehia Elrakaiby and Paola Spoletini and Bashar Nuseibeh", "title": "Optimal by Design: Model-Driven Synthesis of Adaptation Strategies for\n  Autonomous Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many software systems have become too large and complex to be managed\nefficiently by human administrators, particularly when they operate in\nuncertain and dynamic environments and require frequent changes.\nRequirements-driven adaptation techniques have been proposed to endow systems\nwith the necessary means to autonomously decide ways to satisfy their\nrequirements. However, many current approaches rely on general-purpose\nlanguages, models and/or frameworks to design, develop and analyze autonomous\nsystems. Unfortunately, these tools are not tailored towards the\ncharacteristics of adaptation problems in autonomous systems. In this paper, we\npresent Optimal by Design (ObD ), a framework for model-based\nrequirements-driven synthesis of optimal adaptation strategies for autonomous\nsystems. ObD proposes a model (and a language) for the high-level description\nof the basic elements of self-adaptive systems, namely the system,\ncapabilities, requirements and environment. Based on those elements, a Markov\nDecision Process (MDP) is constructed to compute the optimal strategy or the\nmost rewarding system behaviour. Furthermore, this defines a reflex controller\nthat can ensure timely responses to changes. One novel feature of the framework\nis that it benefits both from goal-oriented techniques, developed for\nrequirement elicitation, refinement and analysis, and synthesis capabilities\nand extensive research around MDPs, their extensions and tools. Our preliminary\nevaluation results demonstrate the practicality and advantages of the\nframework.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 12:49:55 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Elrakaiby", "Yehia", ""], ["Spoletini", "Paola", ""], ["Nuseibeh", "Bashar", ""]]}, {"id": "2001.08546", "submitter": "Preslav Nakov", "authors": "Alberto Barron-Cedeno, Tamer Elsayed, Preslav Nakov, Giovanni Da San\n  Martino, Maram Hasanain, Reem Suwaileh, and Fatima Haouari", "title": "CheckThat! at CLEF 2020: Enabling the Automatic Identification and\n  Verification of Claims in Social Media", "comments": "Computational journalism, Check-worthiness, Fact-checking, Veracity,\n  CLEF-2020 CheckThat! Lab", "journal-ref": "CLEF-2018 ECIR-2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the third edition of the CheckThat! Lab, which is part of the\n2020 Cross-Language Evaluation Forum (CLEF). CheckThat! proposes four\ncomplementary tasks and a related task from previous lab editions, offered in\nEnglish, Arabic, and Spanish. Task 1 asks to predict which tweets in a Twitter\nstream are worth fact-checking. Task 2 asks to determine whether a claim posted\nin a tweet can be verified using a set of previously fact-checked claims. Task\n3 asks to retrieve text snippets from a given set of Web pages that would be\nuseful for verifying a target tweet's claim. Task 4 asks to predict the\nveracity of a target tweet's claim using a set of Web pages and potentially\nuseful snippets in them. Finally, the lab offers a fifth task that asks to\npredict the check-worthiness of the claims made in English political debates\nand speeches. CheckThat! features a full evaluation framework. The evaluation\nis carried out using mean average precision or precision at rank k for ranking\ntasks, and F1 for classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 06:47:11 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Barron-Cedeno", "Alberto", ""], ["Elsayed", "Tamer", ""], ["Nakov", "Preslav", ""], ["Martino", "Giovanni Da San", ""], ["Hasanain", "Maram", ""], ["Suwaileh", "Reem", ""], ["Haouari", "Fatima", ""]]}, {"id": "2001.08603", "submitter": "Nitesh Kumar", "authors": "Kumar Nitesh, Kuzelka Ondrej and De Raedt Luc", "title": "Learning Distributional Programs for Relational Autocompletion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Relational autocompletion is the problem of automatically filling out some\nmissing values in multi-relational data. We tackle this problem within the\nprobabilistic logic programming framework of Distributional Clauses (DC), which\nsupports both discrete and continuous probability distributions. Within this\nframework, we introduce DiceML { an approach to learn both the structure and\nthe parameters of DC programs from relational data (with possibly missing\ndata). To realize this, DiceML integrates statistical modeling and\ndistributional clauses with rule learning. The distinguishing features of\nDiceML are that it 1) tackles autocompletion in relational data, 2) learns\ndistributional clauses extended with statistical models, 3) deals with both\ndiscrete and continuous distributions, 4) can exploit background knowledge, and\n5) uses an expectation-maximization based algorithm to cope with missing data.\nThe empirical results show the promise of the approach, even when there is\nmissing data.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 15:34:42 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 11:51:31 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 17:22:42 GMT"}, {"version": "v4", "created": "Thu, 18 Mar 2021 14:08:55 GMT"}, {"version": "v5", "created": "Mon, 5 Jul 2021 14:35:00 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Nitesh", "Kumar", ""], ["Ondrej", "Kuzelka", ""], ["Luc", "De Raedt", ""]]}, {"id": "2001.08615", "submitter": "Alberto Tejero", "authors": "Alberto Tejero, Victor Rodriguez-Doncel and Ivan Pau", "title": "Knowledge Graphs for Innovation Ecosystems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Innovation ecosystems can be naturally described as a collection of networked\nentities, such as experts, institutions, projects, technologies and products.\nRepresenting in a machine-readable form these entities and their relations is\nnot entirely attainable, due to the existence of abstract concepts such as\nknowledge and due to the confidential, non-public nature of this information,\nbut even its partial depiction is of strong interest. The representation of\ninnovation ecosystems incarnated as knowledge graphs would enable the\ngeneration of reports with new insights, the execution of advanced data\nanalysis tasks. An ontology to capture the essential entities and relations is\npresented, as well as the description of data sources, which can be used to\npopulate innovation knowledge graphs. Finally, the application case of the\nUniversidad Politecnica de Madrid is presented, as well as an insight of future\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 08:02:32 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Tejero", "Alberto", ""], ["Rodriguez-Doncel", "Victor", ""], ["Pau", "Ivan", ""]]}, {"id": "2001.08618", "submitter": "Bence Keresztury", "authors": "Bence Keresztury and Elia Bruni", "title": "Compositional properties of emergent languages in deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent findings in multi-agent deep learning systems point towards the\nemergence of compositional languages. These claims are often made without exact\nanalysis or testing of the language. In this work, we analyze the emergent\nlanguage resulting from two different cooperative multi-agent game with more\nexact measures for compositionality. Our findings suggest that solutions found\nby deep learning models are often lacking the ability to reason on an abstract\nlevel therefore failing to generalize the learned knowledge to out of the\ntraining distribution examples. Strategies for testing compositional capacities\nand emergence of human-level concepts are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 15:55:36 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Keresztury", "Bence", ""], ["Bruni", "Elia", ""]]}, {"id": "2001.08656", "submitter": "David Melhart", "authors": "David Melhart, Georgios N. Yannakakis, Antonios Liapis", "title": "I Feel I Feel You: A Theory of Mind Experiment in Games", "comments": "Accepted manuscript for the KI-Kunstliche Intelligenz special issue\n  on Artificial Intelligence in Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study into the player's emotional theory of mind of gameplaying\nagents, we investigate how an agent's behaviour and the player's own\nperformance and emotions shape the recognition of a frustrated behaviour. We\nfocus on the perception of frustration as it is a prevalent affective\nexperience in human-computer interaction. We present a testbed game tailored\ntowards this end, in which a player competes against an agent with a\nfrustration model based on theory. We collect gameplay data, an annotated\nground truth about the player's appraisal of the agent's frustration, and apply\nface recognition to estimate the player's emotional state. We examine the\ncollected data through correlation analysis and predictive machine learning\nmodels, and find that the player's observable emotions are not correlated\nhighly with the perceived frustration of the agent. This suggests that our\nsubject's theory of mind is a cognitive process based on the gameplay context.\nOur predictive models---using ranking support vector machines---corroborate\nthese results, yielding moderately accurate predictors of players' theory of\nmind.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 16:49:39 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Melhart", "David", ""], ["Yannakakis", "Georgios N.", ""], ["Liapis", "Antonios", ""]]}, {"id": "2001.08688", "submitter": "Heng Zhang", "authors": "Heng Zhang, Yan Zhang, Guifei Jiang", "title": "Model-theoretic Characterizations of Existential Rule Languages", "comments": "17 pages, 2 figures, the full version of a paper submitted to IJCAI\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existential rules, a.k.a. dependencies in databases, and Datalog+/- in\nknowledge representation and reasoning recently, are a family of important\nlogical languages widely used in computer science and artificial intelligence.\nTowards a deep understanding of these languages in model theory, we establish\nmodel-theoretic characterizations for a number of existential rule languages\nsuch as (disjunctive) embedded dependencies, tuple-generating dependencies\n(TGDs), (frontier-)guarded TGDs and linear TGDs. All these characterizations\nhold for arbitrary structures, and most of them also work on the class of\nfinite structures. As a natural application of these characterizations,\ncomplexity bounds for the rewritability of above languages are also identified.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 17:29:18 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Zhang", "Heng", ""], ["Zhang", "Yan", ""], ["Jiang", "Guifei", ""]]}, {"id": "2001.08730", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Shivansh Pate, and Vinay P. Namboodiri", "title": "Robust Explanations for Visual Question Answering", "comments": "WACV-2020 (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a method to obtain robust explanations for visual\nquestion answering(VQA) that correlate well with the answers. Our model\nexplains the answers obtained through a VQA model by providing visual and\ntextual explanations. The main challenges that we address are i) Answers and\ntextual explanations obtained by current methods are not well correlated and\nii) Current methods for visual explanation do not focus on the right location\nfor explaining the answer. We address both these challenges by using a\ncollaborative correlated module which ensures that even if we do not train for\nnoise based attacks, the enhanced correlation ensures that the right\nexplanation and answer can be generated. We further show that this also aids in\nimproving the generated visual and textual explanations. The use of the\ncorrelated module can be thought of as a robust method to verify if the answer\nand explanations are coherent. We evaluate this model using VQA-X dataset. We\nobserve that the proposed method yields better textual and visual justification\nthat supports the decision. We showcase the robustness of the model against a\nnoise-based perturbation attack using corresponding visual and textual\nexplanations. A detailed empirical analysis is shown. Here we provide source\ncode link for our model \\url{https://github.com/DelTA-Lab-IITK/CCM-WACV}.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 18:43:34 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Patro", "Badri N.", ""], ["Pate", "Shivansh", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "2001.08767", "submitter": "Anay Mehrotra", "authors": "L. Elisa Celis and Anay Mehrotra and Nisheeth K. Vishnoi", "title": "Interventions for Ranking in the Presence of Implicit Bias", "comments": "This paper will appear at the ACM FAT* 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.DS cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit bias is the unconscious attribution of particular qualities (or lack\nthereof) to a member from a particular social group (e.g., defined by gender or\nrace). Studies on implicit bias have shown that these unconscious stereotypes\ncan have adverse outcomes in various social contexts, such as job screening,\nteaching, or policing. Recently, (Kleinberg and Raghavan, 2018) considered a\nmathematical model for implicit bias and showed the effectiveness of the Rooney\nRule as a constraint to improve the utility of the outcome for certain cases of\nthe subset selection problem. Here we study the problem of designing\ninterventions for the generalization of subset selection -- ranking -- that\nrequires to output an ordered set and is a central primitive in various social\nand computational contexts. We present a family of simple and interpretable\nconstraints and show that they can optimally mitigate implicit bias for a\ngeneralization of the model studied in (Kleinberg and Raghavan, 2018).\nSubsequently, we prove that under natural distributional assumptions on the\nutilities of items, simple, Rooney Rule-like, constraints can also surprisingly\nrecover almost all the utility lost due to implicit biases. Finally, we augment\nour theoretical results with empirical findings on real-world distributions\nfrom the IIT-JEE (2009) dataset and the Semantic Scholar Research corpus.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 19:11:31 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Celis", "L. Elisa", ""], ["Mehrotra", "Anay", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "2001.08779", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Vinod K. Kurmi, Sandeep Kumar, and Vinay P. Namboodiri", "title": "Deep Bayesian Network for Visual Question Generation", "comments": "WACV-2020 (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Generating natural questions from an image is a semantic task that requires\nusing vision and language modalities to learn multimodal representations.\nImages can have multiple visual and language cues such as places, captions, and\ntags. In this paper, we propose a principled deep Bayesian learning framework\nthat combines these cues to produce natural questions. We observe that with the\naddition of more cues and by minimizing uncertainty in the among cues, the\nBayesian network becomes more confident. We propose a Minimizing Uncertainty of\nMixture of Cues (MUMC), that minimizes uncertainty present in a mixture of cues\nexperts for generating probabilistic questions. This is a Bayesian framework\nand the results show a remarkable similarity to natural questions as validated\nby a human study. We observe that with the addition of more cues and by\nminimizing uncertainty among the cues, the Bayesian framework becomes more\nconfident. Ablation studies of our model indicate that a subset of cues is\ninferior at this task and hence the principled fusion of cues is preferred.\nFurther, we observe that the proposed approach substantially improves over\nstate-of-the-art benchmarks on the quantitative metrics (BLEU-n, METEOR, ROUGE,\nand CIDEr). Here we provide project link for Deep Bayesian VQG\n\\url{https://delta-lab-iitk.github.io/BVQG/}\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 19:37:20 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Patro", "Badri N.", ""], ["Kurmi", "Vinod K.", ""], ["Kumar", "Sandeep", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "2001.08791", "submitter": "Brian Quanz", "authors": "Brian Quanz, Wei Sun, Ajay Deshpande, Dhruv Shah, Jae-eun Park", "title": "Machine learning based co-creative design framework", "comments": "Thirty-third Conference on Neural Information Processing Systems\n  (NeurIPS) 2019 Workshop on Machine Learning for Creativity and Design,\n  December 14th, 2019, Vancouver, Canada\n  (https://neurips2019creativity.github.io/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a flexible, co-creative framework bringing together multiple\nmachine learning techniques to assist human users to efficiently produce\neffective creative designs. We demonstrate its potential with a perfume bottle\ndesign case study, including human evaluation and quantitative and qualitative\nanalyses.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 20:18:44 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Quanz", "Brian", ""], ["Sun", "Wei", ""], ["Deshpande", "Ajay", ""], ["Shah", "Dhruv", ""], ["Park", "Jae-eun", ""]]}, {"id": "2001.08823", "submitter": "Alex Kearney", "authors": "Alex Kearney, Anna Koop, Patrick M. Pilarski", "title": "What's a Good Prediction? Challenges in evaluating an agent's knowledge", "comments": "In preparation for submission to Adaptive Behaviour", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing general knowledge by learning task-independent models of the\nworld can help agents solve challenging problems. However, both constructing\nand evaluating such models remains an open challenge. The most common\napproaches to evaluating models is to assess their accuracy with respect to\nobservable values. However, the prevailing reliance on estimator accuracy as a\nproxy for the usefulness of the knowledge has the potential to lead us astray.\nWe demonstrate the conflict between accuracy and usefulness through a series of\nillustrative examples including both a thought experiment and empirical example\nin MineCraft, using the General Value Function framework (GVF). Having\nidentified challenges in assessing an agent's knowledge, we propose an\nalternate evaluation approach that arises continually in the online continual\nlearning setting we recommend evaluation by examining internal learning\nprocesses, specifically the relevance of a GVF's features to the prediction\ntask at hand. This paper contributes a first look into evaluation of\npredictions through their use, an integral component of predictive knowledge\nwhich is as of yet unexplored.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 21:44:43 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 23:44:37 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Kearney", "Alex", ""], ["Koop", "Anna", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "2001.08837", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, Matthew Hausknecht", "title": "Graph Constrained Reinforcement Learning for Natural Language Action\n  Spaces", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive Fiction games are text-based simulations in which an agent\ninteracts with the world purely through natural language. They are ideal\nenvironments for studying how to extend reinforcement learning agents to meet\nthe challenges of natural language understanding, partial observability, and\naction generation in combinatorially-large text-based action spaces. We present\nKG-A2C, an agent that builds a dynamic knowledge graph while exploring and\ngenerates actions using a template-based action space. We contend that the dual\nuses of the knowledge graph to reason about game state and to constrain natural\nlanguage generation are the keys to scalable exploration of combinatorially\nlarge natural language actions. Results across a wide variety of IF games show\nthat KG-A2C outperforms current IF agents despite the exponential increase in\naction space size.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 22:33:18 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Hausknecht", "Matthew", ""]]}, {"id": "2001.08868", "submitter": "Andrea Madotto Mr", "authors": "Andrea Madotto, Mahdi Namazifar, Joost Huizinga, Piero Molino, Adrien\n  Ecoffet, Huaixiu Zheng, Alexandros Papangelis, Dian Yu, Chandra Khatri,\n  Gokhan Tur", "title": "Exploration Based Language Learning for Text-Based Games", "comments": "Accepted at IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents an exploration and imitation-learning-based agent capable\nof state-of-the-art performance in playing text-based computer games.\nText-based computer games describe their world to the player through natural\nlanguage and expect the player to interact with the game using text. These\ngames are of interest as they can be seen as a testbed for language\nunderstanding, problem-solving, and language generation by artificial agents.\nMoreover, they provide a learning environment in which these skills can be\nacquired through interactions with an environment rather than using fixed\ncorpora. One aspect that makes these games particularly challenging for\nlearning agents is the combinatorially large action space. Existing methods for\nsolving text-based games are limited to games that are either very simple or\nhave an action space restricted to a predetermined set of admissible actions.\nIn this work, we propose to use the exploration approach of Go-Explore for\nsolving text-based games. More specifically, in an initial exploration phase,\nwe first extract trajectories with high rewards, after which we train a policy\nto solve the game by imitating these trajectories. Our experiments show that\nthis approach outperforms existing solutions in solving text-based games, and\nit is more sample efficient in terms of the number of interactions with the\nenvironment. Moreover, we show that the learned policy can generalize better\nthan existing solutions to unseen games without using any restriction on the\naction space.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 03:03:51 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 02:27:49 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Madotto", "Andrea", ""], ["Namazifar", "Mahdi", ""], ["Huizinga", "Joost", ""], ["Molino", "Piero", ""], ["Ecoffet", "Adrien", ""], ["Zheng", "Huaixiu", ""], ["Papangelis", "Alexandros", ""], ["Yu", "Dian", ""], ["Khatri", "Chandra", ""], ["Tur", "Gokhan", ""]]}, {"id": "2001.08928", "submitter": "Hamid Reza Boveiri", "authors": "Hamid Reza Boveiri and Raouf Khayami", "title": "On the Performance of Metaheuristics: A Different Perspective", "comments": "Version 0.1: 16 Pages, 5 Figures, and 7 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, we are immersed in tens of newly-proposed evolutionary and\nswam-intelligence metaheuristics, which makes it very difficult to choose a\nproper one to be applied on a specific optimization problem at hand. On the\nother hand, most of these metaheuristics are nothing but slightly modified\nvariants of the basic metaheuristics. For example, Differential Evolution (DE)\nor Shuffled Frog Leaping (SFL) are just Genetic Algorithms (GA) with a\nspecialized operator or an extra local search, respectively. Therefore, what\ncomes to the mind is whether the behavior of such newly-proposed metaheuristics\ncan be investigated on the basis of studying the specifications and\ncharacteristics of their ancestors. In this paper, a comprehensive evaluation\nstudy on some basic metaheuristics i.e. Genetic Algorithm (GA), Particle Swarm\nOptimization (PSO), Artificial Bee Colony (ABC), Teaching-Learning-Based\nOptimization (TLBO), and Cuckoo Optimization algorithm (COA) is conducted,\nwhich give us a deeper insight into the performance of them so that we will be\nable to better estimate the performance and applicability of all other\nvariations originated from them. A large number of experiments have been\nconducted on 20 different combinatorial optimization benchmark functions with\ndifferent characteristics, and the results reveal to us some fundamental\nconclusions besides the following ranking order among these metaheuristics,\n{ABC, PSO, TLBO, GA, COA} i.e. ABC and COA are the best and the worst methods\nfrom the performance point of view, respectively. In addition, from the\nconvergence perspective, PSO and ABC have significant better convergence for\nunimodal and multimodal functions, respectively, while GA and COA have\npremature convergence to local optima in many cases needing alternative\nmutation mechanisms to enhance diversification and global search.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 09:34:10 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Boveiri", "Hamid Reza", ""], ["Khayami", "Raouf", ""]]}, {"id": "2001.08930", "submitter": "Piero Bonatti", "authors": "Piero A. Bonatti, Sabrina Kirrane, Iliana M. Petrova, Luigi Sauro", "title": "Machine Understandable Policies and GDPR Compliance Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The European General Data Protection Regulation (GDPR) calls for technical\nand organizational measures to support its implementation. Towards this end,\nthe SPECIAL H2020 project aims to provide a set of tools that can be used by\ndata controllers and processors to automatically check if personal data\nprocessing and sharing complies with the obligations set forth in the GDPR. The\nprimary contributions of the project include: (i) a policy language that can be\nused to express consent, business policies, and regulatory obligations; and\n(ii) two different approaches to automated compliance checking that can be used\nto demonstrate that data processing performed by data controllers / processors\ncomplies with consent provided by data subjects, and business processes comply\nwith regulatory obligations set forth in the GDPR.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 09:41:47 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Bonatti", "Piero A.", ""], ["Kirrane", "Sabrina", ""], ["Petrova", "Iliana M.", ""], ["Sauro", "Luigi", ""]]}, {"id": "2001.09005", "submitter": "Federico Errica", "authors": "Federico Errica, Davide Bacciu, Alessio Micheli", "title": "Theoretically Expressive and Edge-aware Graph Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new Graph Neural Network that combines recent advancements in\nthe field. We give theoretical contributions by proving that the model is\nstrictly more general than the Graph Isomorphism Network and the Gated Graph\nNeural Network, as it can approximate the same functions and deal with\narbitrary edge values. Then, we show how a single node information can flow\nthrough the graph unchanged.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 13:43:39 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Errica", "Federico", ""], ["Bacciu", "Davide", ""], ["Micheli", "Alessio", ""]]}, {"id": "2001.09063", "submitter": "Abhinav Gupta", "authors": "Agnieszka S{\\l}owik, Abhinav Gupta, William L. Hamilton, Mateja\n  Jamnik, Sean B. Holden", "title": "Towards Graph Representation Learning in Emergent Communication", "comments": "The first two authors contributed equally. Accepted at the\n  Reinforcement Learning in Games workshop at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent findings in neuroscience suggest that the human brain represents\ninformation in a geometric structure (for instance, through conceptual spaces).\nIn order to communicate, we flatten the complex representation of entities and\ntheir attributes into a single word or a sentence. In this paper we use graph\nconvolutional networks to support the evolution of language and cooperation in\nmulti-agent systems. Motivated by an image-based referential game, we propose a\ngraph referential game with varying degrees of complexity, and we provide\nstrong baseline models that exhibit desirable properties in terms of language\nemergence and cooperation. We show that the emerged communication protocol is\nrobust, that the agents uncover the true factors of variation in the game, and\nthat they learn to generalize beyond the samples encountered during training.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 15:55:59 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 14:18:31 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["S\u0142owik", "Agnieszka", ""], ["Gupta", "Abhinav", ""], ["Hamilton", "William L.", ""], ["Jamnik", "Mateja", ""], ["Holden", "Sean B.", ""]]}, {"id": "2001.09113", "submitter": "Daniel Graves PhD", "authors": "Daniel Graves, Kasra Rezaee, Sean Scheideman", "title": "Perception as prediction using general value functions in autonomous\n  driving applications", "comments": "8 pages, 6 figures, IROS 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and demonstrate a framework called perception as prediction for\nautonomous driving that uses general value functions (GVFs) to learn\npredictions. Perception as prediction learns data-driven predictions relating\nto the impact of actions on the agent's perception of the world. It also\nprovides a data-driven approach to predict the impact of the anticipated\nbehavior of other agents on the world without explicitly learning their policy\nor intentions. We demonstrate perception as prediction by learning to predict\nan agent's front safety and rear safety with GVFs, which encapsulate\nanticipation of the behavior of the vehicle in front and in the rear,\nrespectively. The safety predictions are learned through random interactions in\na simulated environment containing other agents. We show that these predictions\ncan be used to produce similar control behavior to an LQR-based controller in\nan adaptive cruise control problem as well as provide advanced warning when the\nvehicle behind is approaching dangerously. The predictions are compact\npolicy-based predictions that support prediction of the long term impact on\nsafety when following a given policy. We analyze two controllers that use the\nlearned predictions in a racing simulator to understand the value of the\npredictions and demonstrate their use in the real-world on a Clearpath Jackal\nrobot and an autonomous vehicle platform.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 17:33:06 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Graves", "Daniel", ""], ["Rezaee", "Kasra", ""], ["Scheideman", "Sean", ""]]}, {"id": "2001.09124", "submitter": "Michael Fisher", "authors": "Michael Fisher, Viviana Mascardi, Kristin Yvonne Rozier, Bernd-Holger\n  Schlingloff, Michael Winikoff and Neil Yorke-Smith", "title": "Towards a Framework for Certification of Reliable Autonomous Systems", "comments": "66 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A computational system is called autonomous if it is able to make its own\ndecisions, or take its own actions, without human supervision or control. The\ncapability and spread of such systems have reached the point where they are\nbeginning to touch much of everyday life. However, regulators grapple with how\nto deal with autonomous systems, for example how could we certify an Unmanned\nAerial System for autonomous use in civilian airspace? We here analyse what is\nneeded in order to provide verified reliable behaviour of an autonomous system,\nanalyse what can be done as the state-of-the-art in automated verification, and\npropose a roadmap towards developing regulatory guidelines, including\narticulating challenges to researchers, to engineers, and to regulators. Case\nstudies in seven distinct domains illustrate the article.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 18:18:35 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Fisher", "Michael", ""], ["Mascardi", "Viviana", ""], ["Rozier", "Kristin Yvonne", ""], ["Schlingloff", "Bernd-Holger", ""], ["Winikoff", "Michael", ""], ["Yorke-Smith", "Neil", ""]]}, {"id": "2001.09212", "submitter": "Ahmed Khalifa", "authors": "Ahmed Khalifa, Philip Bontrager, Sam Earle and Julian Togelius", "title": "PCGRL: Procedural Content Generation via Reinforcement Learning", "comments": "7 pages, 7 figures, 1 table, published at AIIDE2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how reinforcement learning can be used to train\nlevel-designing agents. This represents a new approach to procedural content\ngeneration in games, where level design is framed as a game, and the content\ngenerator itself is learned. By seeing the design problem as a sequential task,\nwe can use reinforcement learning to learn how to take the next action so that\nthe expected final level quality is maximized. This approach can be used when\nfew or no examples exist to train from, and the trained generator is very fast.\nWe investigate three different ways of transforming two-dimensional level\ndesign problems into Markov decision processes and apply these to three game\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 22:09:08 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 06:33:01 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 02:31:50 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Khalifa", "Ahmed", ""], ["Bontrager", "Philip", ""], ["Earle", "Sam", ""], ["Togelius", "Julian", ""]]}, {"id": "2001.09219", "submitter": "Q.Vera Liao", "authors": "Bhavya Ghai, Q. Vera Liao, Yunfeng Zhang, Rachel Bellamy, Klaus\n  Mueller", "title": "Explainable Active Learning (XAL): An Empirical Study of How Local\n  Explanations Impact Annotator Experience", "comments": "replacing with a draft accepted to CSCW2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide adoption of Machine Learning technologies has created a rapidly\ngrowing demand for people who can train ML models. Some advocated the term\n\"machine teacher\" to refer to the role of people who inject domain knowledge\ninto ML models. One promising learning paradigm is Active Learning (AL), by\nwhich the model intelligently selects instances to query the machine teacher\nfor labels. However, in current AL settings, the human-AI interface remains\nminimal and opaque. We begin considering AI explanations as a core element of\nthe human-AI interface for teaching machines. When a human student learns, it\nis a common pattern to present one's own reasoning and solicit feedback from\nthe teacher. When a ML model learns and still makes mistakes, the human teacher\nshould be able to understand the reasoning underlying the mistakes. When the\nmodel matures, the machine teacher should be able to recognize its progress in\norder to trust and feel confident about their teaching outcome. Toward this\nvision, we propose a novel paradigm of explainable active learning (XAL), by\nintroducing techniques from the recently surging field of explainable AI (XAI)\ninto an AL setting. We conducted an empirical study comparing the model\nlearning outcomes, feedback content and experience with XAL, to that of\ntraditional AL and coactive learning (providing the model's prediction without\nthe explanation). Our study shows benefits of AI explanation as interfaces for\nmachine teaching--supporting trust calibration and enabling rich forms of\nteaching feedback, and potential drawbacks--anchoring effect with the model\njudgment and cognitive workload. Our study also reveals important individual\nfactors that mediate a machine teacher's reception to AI explanations,\nincluding task knowledge, AI experience and need for cognition. By reflecting\non the results, we suggest future directions and design implications for XAL.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 22:52:18 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 00:18:11 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 16:47:14 GMT"}, {"version": "v4", "created": "Wed, 30 Sep 2020 12:43:28 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Ghai", "Bhavya", ""], ["Liao", "Q. Vera", ""], ["Zhang", "Yunfeng", ""], ["Bellamy", "Rachel", ""], ["Mueller", "Klaus", ""]]}, {"id": "2001.09293", "submitter": "Gavin Rens", "authors": "Gavin Rens, Jean-Fran\\c{c}ois Raskin", "title": "Learning Non-Markovian Reward Models in MDPs", "comments": "18 pages, single column, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are situations in which an agent should receive rewards only after\nhaving accomplished a series of previous tasks. In other words, the reward that\nthe agent receives is non-Markovian. One natural and quite general way to\nrepresent history-dependent rewards is via a Mealy machine; a finite state\nautomaton that produces output sequences (rewards in our case) from input\nsequences (state/action observations in our case). In our formal setting, we\nconsider a Markov decision process (MDP) that models the dynamic of the\nenvironment in which the agent evolves and a Mealy machine synchronised with\nthis MDP to formalise the non-Markovian reward function. While the MDP is known\nby the agent, the reward function is unknown from the agent and must be learnt.\n  Learning non-Markov reward functions is a challenge. Our approach to overcome\nthis challenging problem is a careful combination of the Angluin's L* active\nlearning algorithm to learn finite automata, testing techniques for\nestablishing conformance of finite model hypothesis and optimisation techniques\nfor computing optimal strategies in Markovian (immediate) reward MDPs. We also\nshow how our framework can be combined with classical heuristics such as Monte\nCarlo Tree Search. We illustrate our algorithms and a preliminary\nimplementation on two typical examples for AI.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 10:51:42 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Rens", "Gavin", ""], ["Raskin", "Jean-Fran\u00e7ois", ""]]}, {"id": "2001.09318", "submitter": "Raphael Koster", "authors": "Raphael K\\\"oster, Dylan Hadfield-Menell, Gillian K. Hadfield, Joel Z.\n  Leibo", "title": "Silly rules improve the capacity of agents to learn stable enforcement\n  and compliance behaviors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can societies learn to enforce and comply with social norms? Here we\ninvestigate the learning dynamics and emergence of compliance and enforcement\nof social norms in a foraging game, implemented in a multi-agent reinforcement\nlearning setting. In this spatiotemporally extended game, individuals are\nincentivized to implement complex berry-foraging policies and punish\ntransgressions against social taboos covering specific berry types. We show\nthat agents benefit when eating poisonous berries is taboo, meaning the\nbehavior is punished by other agents, as this helps overcome a\ncredit-assignment problem in discovering delayed health effects. Critically,\nhowever, we also show that introducing an additional taboo, which results in\npunishment for eating a harmless berry, improves the rate and stability with\nwhich agents learn to punish taboo violations and comply with taboos.\nCounterintuitively, our results show that an arbitrary taboo (a \"silly rule\")\ncan enhance social learning dynamics and achieve better outcomes in the middle\nstages of learning. We discuss the results in the context of studying\nnormativity as a group-level emergent phenomenon.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 14:00:33 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["K\u00f6ster", "Raphael", ""], ["Hadfield-Menell", "Dylan", ""], ["Hadfield", "Gillian K.", ""], ["Leibo", "Joel Z.", ""]]}, {"id": "2001.09365", "submitter": "Evgeny Kharlamov", "authors": "Dmitriy Zheleznyakov, Evgeny Kharlamov, Werner Nutt, Diego Calvanese", "title": "On Expansion and Contraction of DL-Lite Knowledge Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases (KBs) are not static entities: new information constantly\nappears and some of the previous knowledge becomes obsolete. In order to\nreflect this evolution of knowledge, KBs should be expanded with the new\nknowledge and contracted from the obsolete one. This problem is well-studied\nfor propositional but much less for first-order KBs. In this work we\ninvestigate knowledge expansion and contraction for KBs expressed in DL-Lite, a\nfamily of description logics (DLs) that underlie the tractable fragment OWL 2\nQL of the Web Ontology Language OWL 2. We start with a novel knowledge\nevolution framework and natural postulates that evolution should respect, and\ncompare our postulates to the well-established AGM postulates. We then review\nwell-known model and formula-based approaches for expansion and contraction for\npropositional theories and show how they can be adapted to the case of DL-Lite.\nIn particular, we show intrinsic limitations of model-based approaches: besides\nthe fact that some of them do not respect the postulates we have established,\nthey ignore the structural properties of KBs. This leads to undesired\nproperties of evolution results: evolution of DL-Lite KBs cannot be captured in\nDL-Lite. Moreover, we show that well-known formula-based approaches are also\nnot appropriate for DL-Lite expansion and contraction: they either have a high\ncomplexity of computation, or they produce logical theories that cannot be\nexpressed in DL-Lite. Thus, we propose a novel formula-based approach that\nrespects our principles and for which evolution is expressible in DL-Lite. For\nthis approach we also propose\n  polynomial time deterministic algorithms to compute evolution of DL-Lite KBs\nwhen evolution affects only factual data.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 21:58:32 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Zheleznyakov", "Dmitriy", ""], ["Kharlamov", "Evgeny", ""], ["Nutt", "Werner", ""], ["Calvanese", "Diego", ""]]}, {"id": "2001.09373", "submitter": "John Kanu", "authors": "John Kanu, Eadom Dessalene, Xiaomin Lin, Cornelia Fermuller, Yiannis\n  Aloimonos", "title": "Following Instructions by Imagining and Reaching Visual Goals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While traditional methods for instruction-following typically assume prior\nlinguistic and perceptual knowledge, many recent works in reinforcement\nlearning (RL) have proposed learning policies end-to-end, typically by training\nneural networks to map joint representations of observations and instructions\ndirectly to actions. In this work, we present a novel framework for learning to\nperform temporally extended tasks using spatial reasoning in the RL framework,\nby sequentially imagining visual goals and choosing appropriate actions to\nfulfill imagined goals. Our framework operates on raw pixel images, assumes no\nprior linguistic or perceptual knowledge, and learns via intrinsic motivation\nand a single extrinsic reward signal measuring task completion. We validate our\nmethod in two environments with a robot arm in a simulated interactive 3D\nenvironment. Our method outperforms two flat architectures with raw-pixel and\nground-truth states, and a hierarchical architecture with ground-truth states\non object arrangement tasks.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 23:26:56 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Kanu", "John", ""], ["Dessalene", "Eadom", ""], ["Lin", "Xiaomin", ""], ["Fermuller", "Cornelia", ""], ["Aloimonos", "Yiannis", ""]]}, {"id": "2001.09386", "submitter": "Xiaotao Gu", "authors": "Xiaotao Gu, Yuning Mao, Jiawei Han, Jialu Liu, Hongkun Yu, You Wu,\n  Cong Yu, Daniel Finnie, Jiaqi Zhai, Nicholas Zukoski", "title": "Generating Representative Headlines for News Stories", "comments": "WebConf 2020 (WWW 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Millions of news articles are published online every day, which can be\noverwhelming for readers to follow. Grouping articles that are reporting the\nsame event into news stories is a common way of assisting readers in their news\nconsumption. However, it remains a challenging research problem to efficiently\nand effectively generate a representative headline for each story. Automatic\nsummarization of a document set has been studied for decades, while few studies\nhave focused on generating representative headlines for a set of articles.\nUnlike summaries, which aim to capture most information with least redundancy,\nheadlines aim to capture information jointly shared by the story articles in\nshort length, and exclude information that is too specific to each individual\narticle. In this work, we study the problem of generating representative\nheadlines for news stories. We develop a distant supervision approach to train\nlarge-scale generation models without any human annotation. This approach\ncenters on two technical components. First, we propose a multi-level\npre-training framework that incorporates massive unlabeled corpus with\ndifferent quality-vs.-quantity balance at different levels. We show that models\ntrained within this framework outperform those trained with pure human curated\ncorpus. Second, we propose a novel self-voting-based article attention layer to\nextract salient information shared by multiple articles. We show that models\nthat incorporate this layer are robust to potential noises in news stories and\noutperform existing baselines with or without noises. We can further enhance\nour model by incorporating human labels, and we show our distant supervision\napproach significantly reduces the demand on labeled data.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 02:08:22 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 02:13:59 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 21:39:47 GMT"}, {"version": "v4", "created": "Mon, 13 Apr 2020 21:47:52 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Gu", "Xiaotao", ""], ["Mao", "Yuning", ""], ["Han", "Jiawei", ""], ["Liu", "Jialu", ""], ["Yu", "Hongkun", ""], ["Wu", "You", ""], ["Yu", "Cong", ""], ["Finnie", "Daniel", ""], ["Zhai", "Jiaqi", ""], ["Zukoski", "Nicholas", ""]]}, {"id": "2001.09388", "submitter": "Ning Yu", "authors": "Ning Yu, Zachary Tuttle, Carl Jake Thurnau, Emmanuel Mireku", "title": "AI-Powered GUI Attack and Its Defensive Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the first Graphical User Interface (GUI) prototype was invented in the\n1970s, GUI systems have been deployed into various personal computer systems\nand server platforms. Recently, with the development of artificial intelligence\n(AI) technology, malicious malware powered by AI is emerging as a potential\nthreat to GUI systems. This type of AI-based cybersecurity attack, targeting at\nGUI systems, is explored in this paper. It is twofold: (1) A malware is\ndesigned to attack the existing GUI system by using AI-based object recognition\ntechniques. (2) Its defensive methods are discovered by generating adversarial\nexamples and other methods to alleviate the threats from the intelligent GUI\nattack. The results have shown that a generic GUI attack can be implemented and\nperformed in a simple way based on current AI techniques and its\ncountermeasures are temporary but effective to mitigate the threats of GUI\nattack so far.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 02:33:52 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Yu", "Ning", ""], ["Tuttle", "Zachary", ""], ["Thurnau", "Carl Jake", ""], ["Mireku", "Emmanuel", ""]]}, {"id": "2001.09398", "submitter": "Wenjie Zhang", "authors": "Wenjie Zhang, Zeyu Sun, Qihao Zhu, Ge Li, Shaowei Cai, Yingfei Xiong,\n  and Lu Zhang", "title": "NLocalSAT: Boosting Local Search with Solution Prediction", "comments": "Accepted by IJCAI 2020", "journal-ref": null, "doi": "10.24963/ijcai.2020/164", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Boolean satisfiability problem (SAT) is a famous NP-complete problem in\ncomputer science. An effective way for solving a satisfiable SAT problem is the\nstochastic local search (SLS). However, in this method, the initialization is\nassigned in a random manner, which impacts the effectiveness of SLS solvers. To\naddress this problem, we propose NLocalSAT. NLocalSAT combines SLS with a\nsolution prediction model, which boosts SLS by changing initialization\nassignments with a neural network. We evaluated NLocalSAT on five SLS solvers\n(CCAnr, Sparrow, CPSparrow, YalSAT, and probSAT) with instances in the random\ntrack of SAT Competition 2018. The experimental results show that solvers with\nNLocalSAT achieve 27% ~ 62% improvement over the original SLS solvers.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 04:22:53 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 09:38:01 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 04:05:35 GMT"}, {"version": "v4", "created": "Wed, 9 Dec 2020 07:01:26 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Zhang", "Wenjie", ""], ["Sun", "Zeyu", ""], ["Zhu", "Qihao", ""], ["Li", "Ge", ""], ["Cai", "Shaowei", ""], ["Xiong", "Yingfei", ""], ["Zhang", "Lu", ""]]}, {"id": "2001.09403", "submitter": "Abhishek Nan", "authors": "Abhishek Nan, Anandh Perumal, Osmar R. Zaiane", "title": "Sentiment and Knowledge Based Algorithmic Trading with Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic trading, due to its inherent nature, is a difficult problem to\ntackle; there are too many variables involved in the real world which make it\nalmost impossible to have reliable algorithms for automated stock trading. The\nlack of reliable labelled data that considers physical and physiological\nfactors that dictate the ups and downs of the market, has hindered the\nsupervised learning attempts for dependable predictions. To learn a good policy\nfor trading, we formulate an approach using reinforcement learning which uses\ntraditional time series stock price data and combines it with news headline\nsentiments, while leveraging knowledge graphs for exploiting news about\nimplicit relationships.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 05:27:53 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Nan", "Abhishek", ""], ["Perumal", "Anandh", ""], ["Zaiane", "Osmar R.", ""]]}, {"id": "2001.09442", "submitter": "Ulrich Furbach", "authors": "Ulrike Barthelme{\\ss} and Ulrich Furbach and Claudia Schon", "title": "Consciousness and Automated Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims at demonstrating how a first-order logic reasoning system in\ncombination with a large knowledge base can be understood as an artificial\nconsciousness system. For this we review some aspects from the area of\nphilosophy of mind and in particular Tononi's Information Integration Theory\n(IIT) and Baars' Global Workspace Theory. These will be applied to the\nreasoning system Hyper with ConceptNet as a knowledge base within a scenario of\ncommonsense and cognitive reasoning. Finally we demonstrate that such a system\nis very well able to do conscious mind wandering.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 11:43:48 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 14:13:18 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 10:08:33 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Barthelme\u00df", "Ulrike", ""], ["Furbach", "Ulrich", ""], ["Schon", "Claudia", ""]]}, {"id": "2001.09461", "submitter": "Sabrina Kirrane", "authors": "Sabrina Kirrane, Javier D. Fern\\'andez, Piero Bonatti, Uros Milosevic,\n  Axel Polleres, Rigo Wenning", "title": "The SPECIAL-K Personal Data Processing Transparency and Compliance\n  Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The European General Data Protection Regulation (GDPR) brings new challenges\nfor companies who must ensure they have an appropriate legal basis for\nprocessing personal data and must provide transparency with respect to personal\ndata processing and sharing within and between organisations. Additionally,\nwhen it comes to consent as a legal basis, companies need to ensure that they\ncomply with usage constraints specified by data subjects. This paper presents\nthe policy language and supporting ontologies and vocabularies, developed\nwithin the SPECIAL EU H2020 project, which can be used to represent data usage\npolicies and data processing and sharing events. We introduce a concrete\ntransparency and compliance architecture, referred to as SPECIAL-K, that can be\nused to automatically verify that data processing and sharing complies with the\ndata subjects consent. Our evaluation, based on a new compliance benchmark,\nshows the efficiency and scalability of the system with increasing number of\nevents and users.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 14:30:09 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 16:34:22 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 12:12:07 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Kirrane", "Sabrina", ""], ["Fern\u00e1ndez", "Javier D.", ""], ["Bonatti", "Piero", ""], ["Milosevic", "Uros", ""], ["Polleres", "Axel", ""], ["Wenning", "Rigo", ""]]}, {"id": "2001.09464", "submitter": "Frank Emmert-Streib", "authors": "Frank Emmert-Streib, Olli Yli-Harja, and Matthias Dehmer", "title": "Explainable Artificial Intelligence and Machine Learning: A reality\n  rooted perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are used to the availability of big data generated in nearly all fields of\nscience as a consequence of technological progress. However, the analysis of\nsuch data possess vast challenges. One of these relates to the explainability\nof artificial intelligence (AI) or machine learning methods. Currently, many of\nsuch methods are non-transparent with respect to their working mechanism and\nfor this reason are called black box models, most notably deep learning\nmethods. However, it has been realized that this constitutes severe problems\nfor a number of fields including the health sciences and criminal justice and\narguments have been brought forward in favor of an explainable AI. In this\npaper, we do not assume the usual perspective presenting explainable AI as it\nshould be, but rather we provide a discussion what explainable AI can be. The\ndifference is that we do not present wishful thinking but reality grounded\nproperties in relation to a scientific theory beyond physics.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 15:09:45 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Emmert-Streib", "Frank", ""], ["Yli-Harja", "Olli", ""], ["Dehmer", "Matthias", ""]]}, {"id": "2001.09467", "submitter": "Harish Kumaar Venkataraman", "authors": "Harish Venkataraman, Derya Aksaray, Peter Seiler", "title": "Tractable Reinforcement Learning of Signal Temporal Logic Objectives", "comments": "Github code repository:\n  https://github.com/kumaa001/Tractable_RL_for_STL_Objectives. arXiv admin\n  note: text overlap with arXiv:1609.07409", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal temporal logic (STL) is an expressive language to specify time-bound\nreal-world robotic tasks and safety specifications. Recently, there has been an\ninterest in learning optimal policies to satisfy STL specifications via\nreinforcement learning (RL). Learning to satisfy STL specifications often needs\na sufficient length of state history to compute reward and the next action. The\nneed for history results in exponential state-space growth for the learning\nproblem. Thus the learning problem becomes computationally intractable for most\nreal-world applications. In this paper, we propose a compact means to capture\nstate history in a new augmented state-space representation. An approximation\nto the objective (maximizing probability of satisfaction) is proposed and\nsolved for in the new augmented state-space. We show the performance bound of\nthe approximate solution and compare it with the solution of an existing\ntechnique via simulations.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 15:23:54 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 15:17:50 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Venkataraman", "Harish", ""], ["Aksaray", "Derya", ""], ["Seiler", "Peter", ""]]}, {"id": "2001.09508", "submitter": "Terrence W.K. Mak", "authors": "Terrence W.K. Mak, Ferdinando Fioretto, Pascal Van Hentenryck", "title": "Bilevel Optimization for Differentially Private Optimization in Energy\n  Systems", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies how to apply differential privacy to constrained\noptimization problems whose inputs are sensitive. This task raises significant\nchallenges since random perturbations of the input data often render the\nconstrained optimization problem infeasible or change significantly the nature\nof its optimal solutions. To address this difficulty, this paper proposes a\nbilevel optimization model that can be used as a post-processing step: It\nredistributes the noise introduced by a differentially private mechanism\noptimally while restoring feasibility and near-optimality. The paper shows\nthat, under a natural assumption, this bilevel model can be solved efficiently\nfor real-life large-scale nonlinear nonconvex optimization problems with\nsensitive customer data. The experimental results demonstrate the accuracy of\nthe privacy-preserving mechanism and showcases significant benefits compared to\nstandard approaches.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 20:15:28 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 22:06:28 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Mak", "Terrence W. K.", ""], ["Fioretto", "Ferdinando", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "2001.09522", "submitter": "Jiaming Shen", "authors": "Jiaming Shen, Zhihong Shen, Chenyan Xiong, Chi Wang, Kuansan Wang,\n  Jiawei Han", "title": "TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced\n  Graph Neural Network", "comments": "WWW 2020", "journal-ref": null, "doi": "10.1145/3366423.3380132", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taxonomies consist of machine-interpretable semantics and provide valuable\nknowledge for many web applications. For example, online retailers (e.g.,\nAmazon and eBay) use taxonomies for product recommendation, and web search\nengines (e.g., Google and Bing) leverage taxonomies to enhance query\nunderstanding. Enormous efforts have been made on constructing taxonomies\neither manually or semi-automatically. However, with the fast-growing volume of\nweb content, existing taxonomies will become outdated and fail to capture\nemerging knowledge. Therefore, in many applications, dynamic expansions of an\nexisting taxonomy are in great demand. In this paper, we study how to expand an\nexisting taxonomy by adding a set of new concepts. We propose a novel\nself-supervised framework, named TaxoExpan, which automatically generates a set\nof <query concept, anchor concept> pairs from the existing taxonomy as training\ndata. Using such self-supervision data, TaxoExpan learns a model to predict\nwhether a query concept is the direct hyponym of an anchor concept. We develop\ntwo innovative techniques in TaxoExpan: (1) a position-enhanced graph neural\nnetwork that encodes the local structure of an anchor concept in the existing\ntaxonomy, and (2) a noise-robust training objective that enables the learned\nmodel to be insensitive to the label noise in the self-supervision data.\nExtensive experiments on three large-scale datasets from different domains\ndemonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy\nexpansion.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 21:30:21 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Shen", "Jiaming", ""], ["Shen", "Zhihong", ""], ["Xiong", "Chenyan", ""], ["Wang", "Chi", ""], ["Wang", "Kuansan", ""], ["Han", "Jiawei", ""]]}, {"id": "2001.09637", "submitter": "Angsheng Li", "authors": "Angsheng Li", "title": "Structural Information Learning Machinery: Learning from Observing,\n  Associating, Optimizing, Decoding, and Abstracting", "comments": "48 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper, we propose the model of {\\it structural information\nlearning machines} (SiLeM for short), leading to a mathematical definition of\nlearning by merging the theories of computation and information. Our model\nshows that the essence of learning is {\\it to gain information}, that to gain\ninformation is {\\it to eliminate uncertainty} embedded in a data space, and\nthat to eliminate uncertainty of a data space can be reduced to an optimization\nproblem, that is, an {\\it information optimization problem}, which can be\nrealized by a general {\\it encoding tree method}. The principle and criterion\nof the structural information learning machines are maximization of {\\it\ndecoding information} from the data points observed together with the\nrelationships among the data points, and semantical {\\it interpretation} of\nsyntactical {\\it essential structure}, respectively. A SiLeM machine learns the\nlaws or rules of nature. It observes the data points of real world, builds the\n{\\it connections} among the observed data and constructs a {\\it data space},\nfor which the principle is to choose the way of connections of data points so\nthat the {\\it decoding information} of the data space is maximized, finds the\n{\\it encoding tree} of the data space that minimizes the dynamical uncertainty\nof the data space, in which the encoding tree is hence referred to as a {\\it\ndecoder}, due to the fact that it has already eliminated the maximum amount of\nuncertainty embedded in the data space, interprets the {\\it semantics} of the\ndecoder, an encoding tree, to form a {\\it knowledge tree}, extracts the {\\it\nremarkable common features} for both semantical and syntactical features of the\nmodules decoded by a decoder to construct {\\it trees of abstractions},\nproviding the foundations for {\\it intuitive reasoning} in the learning when\nnew data are observed.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 09:14:46 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Li", "Angsheng", ""]]}, {"id": "2001.09684", "submitter": "Muhammad Usama", "authors": "Inaam Ilahi, Muhammad Usama, Junaid Qadir, Muhammad Umar Janjua, Ala\n  Al-Fuqaha, Dinh Thai Hoang, and Dusit Niyato", "title": "Challenges and Countermeasures for Adversarial Attacks on Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has numerous applications in the real world\nthanks to its outstanding ability in quickly adapting to the surrounding\nenvironments. Despite its great advantages, DRL is susceptible to adversarial\nattacks, which precludes its use in real-life critical systems and applications\n(e.g., smart grids, traffic controls, and autonomous vehicles) unless its\nvulnerabilities are addressed and mitigated. Thus, this paper provides a\ncomprehensive survey that discusses emerging attacks in DRL-based systems and\nthe potential countermeasures to defend against these attacks. We first cover\nsome fundamental backgrounds about DRL and present emerging adversarial attacks\non machine learning techniques. We then investigate more details of the\nvulnerabilities that the adversary can exploit to attack DRL along with the\nstate-of-the-art countermeasures to prevent such attacks. Finally, we highlight\nopen issues and research challenges for developing solutions to deal with\nattacks for DRL-based intelligent systems.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 10:53:11 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Ilahi", "Inaam", ""], ["Usama", "Muhammad", ""], ["Qadir", "Junaid", ""], ["Janjua", "Muhammad Umar", ""], ["Al-Fuqaha", "Ala", ""], ["Hoang", "Dinh Thai", ""], ["Niyato", "Dusit", ""]]}, {"id": "2001.09694", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Junjie Yang, Hai Zhao", "title": "Retrospective Reader for Machine Reading Comprehension", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading comprehension (MRC) is an AI challenge that requires machine\nto determine the correct answers to questions based on a given passage. MRC\nsystems must not only answer question when necessary but also distinguish when\nno answer is available according to the given passage and then tactfully\nabstain from answering. When unanswerable questions are involved in the MRC\ntask, an essential verification module called verifier is especially required\nin addition to the encoder, though the latest practice on MRC modeling still\nmost benefits from adopting well pre-trained language models as the encoder\nblock by only focusing on the \"reading\". This paper devotes itself to exploring\nbetter verifier design for the MRC task with unanswerable questions. Inspired\nby how humans solve reading comprehension questions, we proposed a\nretrospective reader (Retro-Reader) that integrates two stages of reading and\nverification strategies: 1) sketchy reading that briefly investigates the\noverall interactions of passage and question, and yield an initial judgment; 2)\nintensive reading that verifies the answer and gives the final prediction. The\nproposed reader is evaluated on two benchmark MRC challenge datasets SQuAD2.0\nand NewsQA, achieving new state-of-the-art results. Significance tests show\nthat our model is significantly better than the strong ELECTRA and ALBERT\nbaselines. A series of analysis is also conducted to interpret the\neffectiveness of the proposed reader.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 11:14:34 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 17:42:50 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 02:52:35 GMT"}, {"version": "v4", "created": "Fri, 11 Dec 2020 09:28:12 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Yang", "Junjie", ""], ["Zhao", "Hai", ""]]}, {"id": "2001.09734", "submitter": "Kacper Sokol", "authors": "Kacper Sokol and Peter Flach", "title": "One Explanation Does Not Fit All: The Promise of Interactive\n  Explanations for Machine Learning Transparency", "comments": "Published in the Kunstliche Intelligenz journal, special issue on\n  Challenges in Interactive Machine Learning", "journal-ref": null, "doi": "10.1007/s13218-020-00637-y", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for transparency of predictive systems based on Machine Learning\nalgorithms arises as a consequence of their ever-increasing proliferation in\nthe industry. Whenever black-box algorithmic predictions influence human\naffairs, the inner workings of these algorithms should be scrutinised and their\ndecisions explained to the relevant stakeholders, including the system\nengineers, the system's operators and the individuals whose case is being\ndecided. While a variety of interpretability and explainability methods is\navailable, none of them is a panacea that can satisfy all diverse expectations\nand competing objectives that might be required by the parties involved. We\naddress this challenge in this paper by discussing the promises of Interactive\nMachine Learning for improved transparency of black-box systems using the\nexample of contrastive explanations -- a state-of-the-art approach to\nInterpretable Machine Learning.\n  Specifically, we show how to personalise counterfactual explanations by\ninteractively adjusting their conditional statements and extract additional\nexplanations by asking follow-up \"What if?\" questions. Our experience in\nbuilding, deploying and presenting this type of system allowed us to list\ndesired properties as well as potential limitations, which can be used to guide\nthe development of interactive explainers. While customising the medium of\ninteraction, i.e., the user interface comprising of various communication\nchannels, may give an impression of personalisation, we argue that adjusting\nthe explanation itself and its content is more important. To this end,\nproperties such as breadth, scope, context, purpose and target of the\nexplanation have to be considered, in addition to explicitly informing the\nexplainee about its limitations and caveats...\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 13:10:12 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Sokol", "Kacper", ""], ["Flach", "Peter", ""]]}, {"id": "2001.09773", "submitter": "Zachary Lipton", "authors": "Sina Fazelpour, Zachary C. Lipton", "title": "Algorithmic Fairness from a Non-ideal Perspective", "comments": "Accepted for publication at the AAAI/ACM Conference on Artificial\n  Intelligence, Ethics, and Society (AIES) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent breakthroughs in predictive modeling, practitioners in\nboth industry and government have turned to machine learning with hopes of\noperationalizing predictions to drive automated decisions. Unfortunately, many\nsocial desiderata concerning consequential decisions, such as justice or\nfairness, have no natural formulation within a purely predictive framework. In\nefforts to mitigate these problems, researchers have proposed a variety of\nmetrics for quantifying deviations from various statistical parities that we\nmight expect to observe in a fair world and offered a variety of algorithms in\nattempts to satisfy subsets of these parities or to trade off the degree to\nwhich they are satisfied against utility. In this paper, we connect this\napproach to \\emph{fair machine learning} to the literature on ideal and\nnon-ideal methodological approaches in political philosophy. The ideal approach\nrequires positing the principles according to which a just world would operate.\nIn the most straightforward application of ideal theory, one supports a\nproposed policy by arguing that it closes a discrepancy between the real and\nthe perfectly just world. However, by failing to account for the mechanisms by\nwhich our non-ideal world arose, the responsibilities of various\ndecision-makers, and the impacts of proposed policies, naive applications of\nideal thinking can lead to misguided interventions. In this paper, we\ndemonstrate a connection between the fair machine learning literature and the\nideal approach in political philosophy, and argue that the increasingly\napparent shortcomings of proposed fair machine learning algorithms reflect\nbroader troubles faced by the ideal approach. We conclude with a critical\ndiscussion of the harms of misguided solutions, a reinterpretation of\nimpossibility results, and directions for future research.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 18:44:41 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Fazelpour", "Sina", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2001.09778", "submitter": "Emilia Gomez", "authors": "Emilio G\\'omez-Gonz\\'alez, Emilia Gomez, Javier M\\'arquez-Rivas,\n  Manuel Guerrero-Claro, Isabel Fern\\'andez-Lizaranzu, Mar\\'ia Isabel\n  Relimpio-L\\'opez, Manuel E. Dorado, Mar\\'ia Jos\\'e Mayorga-Buiza, Guillermo\n  Izquierdo-Ayuso, Luis Capit\\'an-Morales", "title": "Artificial intelligence in medicine and healthcare: a review and\n  classification of current and near-future applications and their ethical and\n  social Impact", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper provides an overview of the current and near-future applications\nof Artificial Intelligence (AI) in Medicine and Health Care and presents a\nclassification according to their ethical and societal aspects, potential\nbenefits and pitfalls, and issues that can be considered controversial and are\nnot deeply discussed in the literature.\n  This work is based on an analysis of the state of the art of research and\ntechnology, including existing software, personal monitoring devices, genetic\ntests and editing tools, personalized digital models, online platforms,\naugmented reality devices, and surgical and companion robotics. Motivated by\nour review, we present and describe the notion of 'extended personalized\nmedicine', we then review existing applications of AI in medicine and\nhealthcare and explore the public perception of medical AI systems, and how\nthey show, simultaneously, extraordinary opportunities and drawbacks that even\nquestion fundamental medical concepts. Many of these topics coincide with\nurgent priorities recently defined by the World Health Organization for the\ncoming decade. In addition, we study the transformations of the roles of\ndoctors and patients in an age of ubiquitous information, identify the risk of\na division of Medicine into 'fake-based', 'patient-generated', and\n'scientifically tailored', and draw the attention of some aspects that need\nfurther thorough analysis and public debate.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 15:39:42 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 14:46:51 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["G\u00f3mez-Gonz\u00e1lez", "Emilio", ""], ["Gomez", "Emilia", ""], ["M\u00e1rquez-Rivas", "Javier", ""], ["Guerrero-Claro", "Manuel", ""], ["Fern\u00e1ndez-Lizaranzu", "Isabel", ""], ["Relimpio-L\u00f3pez", "Mar\u00eda Isabel", ""], ["Dorado", "Manuel E.", ""], ["Mayorga-Buiza", "Mar\u00eda Jos\u00e9", ""], ["Izquierdo-Ayuso", "Guillermo", ""], ["Capit\u00e1n-Morales", "Luis", ""]]}, {"id": "2001.09784", "submitter": "Dana Pessach", "authors": "Dana Pessach and Erez Shmueli", "title": "Algorithmic Fairness", "comments": "31 pages, 1 figure, This is a survey article that reviews the field\n  of algorithmic fairness", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of decisions regarding the daily lives of human beings\nare being controlled by artificial intelligence (AI) algorithms in spheres\nranging from healthcare, transportation, and education to college admissions,\nrecruitment, provision of loans and many more realms. Since they now touch on\nmany aspects of our lives, it is crucial to develop AI algorithms that are not\nonly accurate but also objective and fair. Recent studies have shown that\nalgorithmic decision-making may be inherently prone to unfairness, even when\nthere is no intention for it. This paper presents an overview of the main\nconcepts of identifying, measuring and improving algorithmic fairness when\nusing AI algorithms. The paper begins by discussing the causes of algorithmic\nbias and unfairness and the common definitions and measures for fairness.\nFairness-enhancing mechanisms are then reviewed and divided into pre-process,\nin-process and post-process mechanisms. A comprehensive comparison of the\nmechanisms is then conducted, towards a better understanding of which\nmechanisms should be used in different scenarios. The paper then describes the\nmost commonly used fairness-related datasets in this field. Finally, the paper\nends by reviewing several emerging research sub-fields of algorithmic fairness.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 19:01:38 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Pessach", "Dana", ""], ["Shmueli", "Erez", ""]]}, {"id": "2001.09786", "submitter": "Somali Chaterji", "authors": "Somali Chaterji, Nathan DeLay, John Evans, Nathan Mosier, Bernard\n  Engel, Dennis Buckmaster and Ranveer Chandra", "title": "Artificial Intelligence for Digital Agriculture at Scale: Techniques,\n  Policies, and Challenges", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital agriculture has the promise to transform agricultural throughput. It\ncan do this by applying data science and engineering for mapping input factors\nto crop throughput, while bounding the available resources. In addition, as the\ndata volumes and varieties increase with the increase in sensor deployment in\nagricultural fields, data engineering techniques will also be instrumental in\ncollection of distributed data as well as distributed processing of the data.\nThese have to be done such that the latency requirements of the end users and\napplications are satisfied. Understanding how farm technology and big data can\nimprove farm productivity can significantly increase the world's food\nproduction by 2050 in the face of constrained arable land and with the water\nlevels receding. While much has been written about digital agriculture's\npotential, little is known about the economic costs and benefits of these\nemergent systems. In particular, the on-farm decision making processes, both in\nterms of adoption and optimal implementation, have not been adequately\naddressed. For example, if some algorithm needs data from multiple data owners\nto be pooled together, that raises the question of data ownership. This paper\nis the first one to bring together the important questions that will guide the\nend-to-end pipeline for the evolution of a new generation of digital\nagricultural solutions, driving the next revolution in agriculture and\nsustainability under one umbrella.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 06:02:38 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Chaterji", "Somali", ""], ["DeLay", "Nathan", ""], ["Evans", "John", ""], ["Mosier", "Nathan", ""], ["Engel", "Bernard", ""], ["Buckmaster", "Dennis", ""], ["Chandra", "Ranveer", ""]]}, {"id": "2001.09795", "submitter": "Mahdi Bohlouli", "authors": "Mahdi Bohlouli, Patrick Uhr, Fabian Merges, Sanaz Mohammad Hassani,\n  Madjid Fathi", "title": "Practical Approach of Knowledge Management in Medical Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge organization, infrastructure, and knowledge-based activities are\nall subjects that help in the creation of business strategies for the new\nenterprise. In this paper, the first basics of knowledge-based systems are\nstudied. Practical issues and challenges of Knowledge Management (KM)\nimplementations are then illustrated. Finally, a comparison of different\nknowledge-based projects is presented along with abstracted information on\ntheir implementation, techniques, and results. Most of these projects are in\nthe field of medical science. Based on our study and evaluation of different KM\nprojects, we conclude that KM is being used in every science, industry, and\nbusiness. But its importance in medical science and assisted living projects\nare highlighted nowadays with the most of research institutes. Most medical\ncenters are interested in using knowledge-based services like portals and\nlearning techniques of knowledge for their future innovations and supports.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:39:46 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Bohlouli", "Mahdi", ""], ["Uhr", "Patrick", ""], ["Merges", "Fabian", ""], ["Hassani", "Sanaz Mohammad", ""], ["Fathi", "Madjid", ""]]}, {"id": "2001.09796", "submitter": "Mahdi Bohlouli", "authors": "Mahdi Bohlouli, Alexander Holland, Madjid Fathi", "title": "Knowledge Integration of Collaborative Product Design Using Cloud\n  Computing Infrastructure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pivotal key to the success of manufacturing enterprises is a sustainable\nand innovative product design and development. In collaborative design,\nstakeholders are heterogeneously distributed chain-like. Due to the growing\nvolume of data and knowledge, effective management of the knowledge acquired in\nthe product design and development is one of the key challenges facing most\nmanufacturing enterprises. Opportunities for improving efficiency and\nperformance of IT-based product design applications through centralization of\nresources such as knowledge and computation have increased in the last few\nyears with the maturation of technologies such as SOA, virtualization, grid\ncomputing, and/or cloud computing. The main focus of this paper is the concept\nof ongoing research in providing the knowledge integration service for\ncollaborative product design and development using cloud computing\ninfrastructure. Potentials of the cloud computing to support the Knowledge\nintegration functionalities as a Service by providing functionalities such as\nknowledge mapping, merging, searching, and transferring in product design\nprocedure are described in this paper. Proposed knowledge integration services\nsupport users by giving real-time access to knowledge resources. The framework\nhas the advantage of availability, efficiency, cost reduction, less time to\nresult, and scalability.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:44:27 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Bohlouli", "Mahdi", ""], ["Holland", "Alexander", ""], ["Fathi", "Madjid", ""]]}, {"id": "2001.09797", "submitter": "Mahdi Bohlouli", "authors": "Mahdi Bohlouli, Nikolaos Mittas, George Kakarontzas, Theodosios\n  Theodosiou, Lefteris Angelis, Madjid Fathi", "title": "Competence Assessment as an Expert System for Human Resource Management:\n  A Mathematical Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.SE cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient human resource management needs accurate assessment and\nrepresentation of available competences as well as effective mapping of\nrequired competences for specific jobs and positions. In this regard,\nappropriate definition and identification of competence gaps express\ndifferences between acquired and required competences. Using a detailed\nquantification scheme together with a mathematical approach is a way to support\naccurate competence analytics, which can be applied in a wide variety of\nsectors and fields. This article describes the combined use of software\ntechnologies and mathematical and statistical methods for assessing and\nanalyzing competences in human resource information systems. Based on a\nstandard competence model, which is called a Professional, Innovative and\nSocial competence tree, the proposed framework offers flexible tools to experts\nin real enterprise environments, either for evaluation of employees towards an\noptimal job assignment and vocational training or for recruitment processes.\nThe system has been tested with real human resource data sets in the frame of\nthe European project called ComProFITS.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 21:37:15 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Bohlouli", "Mahdi", ""], ["Mittas", "Nikolaos", ""], ["Kakarontzas", "George", ""], ["Theodosiou", "Theodosios", ""], ["Angelis", "Lefteris", ""], ["Fathi", "Madjid", ""]]}, {"id": "2001.09830", "submitter": "Manikandan Ravikiran", "authors": "Manikandan Ravikiran", "title": "What's happened in MOOC Posts Analysis, Knowledge Tracing and Peer\n  Feedbacks? A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning Management Systems (LMS) and Educational Data Mining (EDM) are two\nimportant parts of online educational environment with the former being a\ncentralised web-based information systems where the learning content is managed\nand learning activities are organised (Stone and Zheng,2014) and latter\nfocusing on using data mining techniques for the analysis of data so generated.\nAs part of this work, we present a literature review of three major tasks of\nEDM (See section 2), by identifying shortcomings and existing open problems,\nand a Blumenfield chart (See section 3). The consolidated set of papers and\nresources so used are released in\nhttps://github.com/manikandan-ravikiran/cs6460-Survey. The coverage statistics\nand review matrix of the survey are as shown in Figure 1 & Table 1\nrespectively. Acronym expansions are added in the Appendix Section 4.1.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 14:45:55 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Ravikiran", "Manikandan", ""]]}, {"id": "2001.09856", "submitter": "Nicolas Dupin", "authors": "Franco Peschiera, Olga Batta\\\"ia, Alain Ha\\\"it, Nicolas Dupin", "title": "Long term planning of military aircraft flight and maintenance\n  operations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Flight and Maintenance Planning (FMP) problem in its military\nvariant and applied to long term planning. The problem has been previously\nstudied for short- and medium-term horizons only. We compare its similarities\nand differences with previous work and prove its complexity. We generate\nscenarios inspired by the French Air Force fleet. We formulate an exact Mixed\nInteger Programming (MIP) model to solve the problem in these scenarios and we\nanalyse the performance of the solving method under these circumstances. A\nheuristic was built to generate fast feasible solutions, that in some cases\nwere shown to help warm-start the model.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 15:23:29 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Peschiera", "Franco", ""], ["Batta\u00efa", "Olga", ""], ["Ha\u00eft", "Alain", ""], ["Dupin", "Nicolas", ""]]}, {"id": "2001.09898", "submitter": "Bernard Yannou", "authors": "Tianjun Hou (LGI), Bernard Yannou (LGI), Yann Leroy, Emilie Poirson\n  (IRCCyN)", "title": "Mining Changes in User Expectation Over Time From Online Reviews", "comments": null, "journal-ref": "Journal of Mechanical Design, American Society of Mechanical\n  Engineers, 2019, 141 (9)", "doi": "10.1115/1.4042793", "report-no": null, "categories": "cs.IR cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Customers post online reviews at any time. With the timestamp of online\nreviews, they can be regarded as a flow of information. With this\ncharacteristic, designers can capture the changes in customer feedback to help\nset up product improvement strategies. Here we propose an approach for\ncapturing changes of user expectation on product affordances based on the\nonline reviews for two generations of products. First, the approach uses a\nrule-based natural language processing method to automatically identify and\nstructure product affordances from review text. Then, inspired by the Kano\nmodel which classifies preferences of product attributes in five categories,\nconjoint analysis is used to quantitatively categorize the structured\naffordances. Finally, changes of user expectation can be found by applying the\nconjoint analysis on the online reviews posted for two successive generations\nof products. A case study based on the online reviews of Kindle e-readers\ndownloaded from amazon.com shows that designers can use our proposed approach\nto evaluate their product improvement strategies for previous products and\ndevelop new product improvement strategies for future products.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 12:57:06 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Hou", "Tianjun", "", "LGI"], ["Yannou", "Bernard", "", "LGI"], ["Leroy", "Yann", "", "IRCCyN"], ["Poirson", "Emilie", "", "IRCCyN"]]}, {"id": "2001.09923", "submitter": "Najla AL-Saati Dr.", "authors": "Najla Akram Al-Saati", "title": "Applying Gene Expression Programming for Solving One-Dimensional\n  Bin-Packing Problems", "comments": "20 page", "journal-ref": "Rafidain Journal of Computer sciences and Mathematics , Vol. 10,\n  No. 4, 2013", "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims to study and explore the use of Gene Expression Programming\n(GEP) in solving the on-line Bin-Packing problem. The main idea is to show how\nGEP can automatically find acceptable heuristic rules to solve the problem\nefficiently and economically. One dimensional Bin-Packing problem is considered\nin the course of this work with the constraint of minimizing the number of bins\nfilled with the given pieces. Experimental Data includes instances of benchmark\ntest data taken from Falkenauer (1996) for One-dimensional Bin-Packing\nProblems. Results show that GEP can be used as a very powerful and flexible\ntool for finding interesting compact rules suited for the problem. The impact\nof functions is also investigated to show how they can affect and influence the\nsuccess of rates when they appear in rules. High success rates are gained with\nsmaller population size and fewer generations compared to previous work\nperformed using Genetic Programming.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 15:07:45 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Al-Saati", "Najla Akram", ""]]}, {"id": "2001.09956", "submitter": "Zhe Xu", "authors": "Zhe Xu, Yuxin Chen and Ufuk Topcu", "title": "Adaptive Teaching of Temporal Logic Formulas to Learners with\n  Preferences", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine teaching is an algorithmic framework for teaching a target hypothesis\nvia a sequence of examples or demonstrations. We investigate machine teaching\nfor temporal logic formulas -- a novel and expressive hypothesis class amenable\nto time-related task specifications. In the context of teaching temporal logic\nformulas, an exhaustive search even for a myopic solution takes exponential\ntime (with respect to the time span of the task). We propose an efficient\napproach for teaching parametric linear temporal logic formulas. Concretely, we\nderive a necessary condition for the minimal time length of a demonstration to\neliminate a set of hypotheses. Utilizing this condition, we propose a myopic\nteaching algorithm by solving a sequence of integer programming problems. We\nfurther show that, under two notions of teaching complexity, the proposed\nalgorithm has near-optimal performance. The results strictly generalize the\nprevious results on teaching preference-based version space learners. We\nevaluate our algorithm extensively under a variety of learner types (i.e.,\nlearners with different preference models) and interactive protocols (e.g.,\nbatched and adaptive). The results show that the proposed algorithms can\nefficiently teach a given target temporal logic formula under various settings,\nand that there are significant gains of teaching efficacy when the teacher\nadapts to the learner's current hypotheses or uses oracles.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 18:22:53 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Xu", "Zhe", ""], ["Chen", "Yuxin", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2001.09993", "submitter": "Jean-Christophe Burnel", "authors": "Jean-Christophe Burnel (OBELIX), Kilian Fatras (OBELIX), Nicolas\n  Courty (OBELIX)", "title": "Generating Natural Adversarial Hyperspectral examples with a modified\n  Wasserstein GAN", "comments": "C&ESAR, Nov 2019, Rennes, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are a hot topic due to their abilities to fool a\nclassifier's prediction. There are two strategies to create such examples, one\nuses the attacked classifier's gradients, while the other only requires access\nto the clas-sifier's prediction. This is particularly appealing when the\nclassifier is not full known (black box model). In this paper, we present a new\nmethod which is able to generate natural adversarial examples from the true\ndata following the second paradigm. Based on Generative Adversarial Networks\n(GANs) [5], it reweights the true data empirical distribution to encourage the\nclassifier to generate ad-versarial examples. We provide a proof of concept of\nour method by generating adversarial hyperspectral signatures on a remote\nsensing dataset.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 07:32:46 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Burnel", "Jean-Christophe", "", "OBELIX"], ["Fatras", "Kilian", "", "OBELIX"], ["Courty", "Nicolas", "", "OBELIX"]]}, {"id": "2001.10048", "submitter": "Shabnam Ghaffarzadegan", "authors": "Yiwei Sun and Shabnam Ghaffarzadegan", "title": "An Ontology-Aware Framework for Audio Event Classification", "comments": "Accepted in IEEE International Conference on Acoustics, Speech, and\n  Signal Processing 2020 (ICASSP 2020). Have signed an e-copyright agreement\n  with the IEEE during ICASSP 2020 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in audio event classification often ignore the structure\nand relation between the label classes available as prior information. This\nstructure can be defined by ontology and augmented in the classifier as a form\nof domain knowledge. To capture such dependencies between the labels, we\npropose an ontology-aware neural network containing two components:\nfeed-forward ontology layers and graph convolutional networks (GCN). The\nfeed-forward ontology layers capture the intra-dependencies of labels between\ndifferent levels of ontology. On the other hand, GCN mainly models\ninter-dependency structure of labels within an ontology level. The framework is\nevaluated on two benchmark datasets for single-label and multi-label audio\nevent classification tasks. The results demonstrate the proposed solutions\nefficacy to capture and explore the ontology relations and improve the\nclassification performance.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 20:07:39 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Sun", "Yiwei", ""], ["Ghaffarzadegan", "Shabnam", ""]]}, {"id": "2001.10054", "submitter": "Junyi Gao", "authors": "Junyi Gao, Cao Xiao, Yasha Wang, Wen Tang, Lucas M. Glass, Jimeng Sun", "title": "StageNet: Stage-Aware Neural Networks for Health Risk Prediction", "comments": null, "journal-ref": null, "doi": "10.1145/3366423.3380136", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has demonstrated success in health risk prediction especially\nfor patients with chronic and progressing conditions. Most existing works focus\non learning disease Network (StageNet) model to extract disease stage\ninformation from patient data and integrate it into risk prediction. StageNet\nis enabled by (1) a stage-aware long short-term memory (LSTM) module that\nextracts health stage variations unsupervisedly; (2) a stage-adaptive\nconvolutional module that incorporates stage-related progression patterns into\nrisk prediction. We evaluate StageNet on two real-world datasets and show that\nStageNet outperforms state-of-the-art models in risk prediction task and\npatient subtyping task. Compared to the best baseline model, StageNet achieves\nup to 12% higher AUPRC for risk prediction task on two real-world patient\ndatasets. StageNet also achieves over 58% higher Calinski-Harabasz score (a\ncluster quality metric) for a patient subtyping task.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 17:50:36 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Gao", "Junyi", ""], ["Xiao", "Cao", ""], ["Wang", "Yasha", ""], ["Tang", "Wen", ""], ["Glass", "Lucas M.", ""], ["Sun", "Jimeng", ""]]}, {"id": "2001.10055", "submitter": "Ganesh Ghalme", "authors": "Ganesh Ghalme, Swapnil Dhamal, Shweta Jain, Sujit Gujar, Y. Narahari", "title": "Ballooning Multi-Armed Bandits", "comments": "A full version of this paper is accepted in the Journal of Artificial\n  Intelligence (AIJ) of Elsevier. A preliminary version is published as an\n  extended abstract in AAMAS 2020. Proceedings of the 19th International\n  Conference on Autonomous Agents and MultiAgent Systems. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Ballooning Multi-Armed Bandits (BL-MAB), a novel\nextension of the classical stochastic MAB model. In the BL-MAB model, the set\nof available arms grows (or balloons) over time. In contrast to the classical\nMAB setting where the regret is computed with respect to the best arm overall,\nthe regret in a BL-MAB setting is computed with respect to the best available\narm at each time. We first observe that the existing stochastic MAB algorithms\nresult in linear regret for the BL-MAB model. We prove that, if the best arm is\nequally likely to arrive at any time instant, a sub-linear regret cannot be\nachieved. Next, we show that if the best arm is more likely to arrive in the\nearly rounds, one can achieve sub-linear regret. Our proposed algorithm\ndetermines (1) the fraction of the time horizon for which the newly arriving\narms should be explored and (2) the sequence of arm pulls in the exploitation\nphase from among the explored arms. Making reasonable assumptions on the\narrival distribution of the best arm in terms of the thinness of the\ndistribution's tail, we prove that the proposed algorithm achieves sub-linear\ninstance-independent regret. We further quantify explicit dependence of regret\non the arrival distribution parameters. We reinforce our theoretical findings\nwith extensive simulation results. We conclude by showing that our algorithm\nwould achieve sub-linear regret even if (a) the distributional parameters are\nnot exactly known, but are obtained using a reasonable learning mechanism or\n(b) the best arm is not more likely to arrive early, but a large fraction of\narms is likely to arrive relatively early.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 04:35:05 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 10:41:13 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 12:33:14 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ghalme", "Ganesh", ""], ["Dhamal", "Swapnil", ""], ["Jain", "Shweta", ""], ["Gujar", "Sujit", ""], ["Narahari", "Y.", ""]]}, {"id": "2001.10056", "submitter": "Markus Abel", "authors": "Markus Quade and Thomas Isele and Markus Abel", "title": "Explainable Machine Learning Control -- robust control and stability\n  analysis", "comments": "submitted to Physica D. arXiv admin note: text overlap with\n  arXiv:1612.05276", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI nlin.AO physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the term explainable AI became known as an approach to produce\nmodels from artificial intelligence which allow interpretation. Since a long\ntime, there are models of symbolic regression in use that are perfectly\nexplainable and mathematically tractable: in this contribution we demonstrate\nhow to use symbolic regression methods to infer the optimal control of a\ndynamical system given one or several optimization criteria, or cost functions.\nIn previous publications, network control was achieved by automatized machine\nlearning control using genetic programming. Here, we focus on the subsequent\nanalysis of the analytical expressions which result from the machine learning.\nIn particular, we use AUTO to analyze the stability properties of the\ncontrolled oscillator system which served as our model. As a result, we show\nthat there is a considerable advantage of explainable models over less\naccessible neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 08:09:58 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Quade", "Markus", ""], ["Isele", "Thomas", ""], ["Abel", "Markus", ""]]}, {"id": "2001.10070", "submitter": "Navdeep Kaur", "authors": "Navdeep Kaur and Gautam Kunapuli and Sriraam Natarajan", "title": "Non-Parametric Learning of Lifted Restricted Boltzmann Machines", "comments": "33 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of discriminatively learning restricted Boltzmann\nmachines in the presence of relational data. Unlike previous approaches that\nemploy a rule learner (for structure learning) and a weight learner (for\nparameter learning) sequentially, we develop a gradient-boosted approach that\nperforms both simultaneously. Our approach learns a set of weak relational\nregression trees, whose paths from root to leaf are conjunctive clauses and\nrepresent the structure, and whose leaf values represent the parameters. When\nthe learned relational regression trees are transformed into a lifted RBM, its\nhidden nodes are precisely the conjunctive clauses derived from the relational\nregression trees. This leads to a more interpretable and explainable model. Our\nempirical evaluations clearly demonstrate this aspect, while displaying no loss\nin effectiveness of the learned models.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 05:23:26 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kaur", "Navdeep", ""], ["Kunapuli", "Gautam", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "2001.10130", "submitter": "Alex Cummaudo Mr", "authors": "Alex Cummaudo, Rajesh Vasa, Scott Barnett, John Grundy, Mohamed\n  Abdelrazek", "title": "Interpreting Cloud Computer Vision Pain-Points: A Mining Study of Stack\n  Overflow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent services are becoming increasingly more pervasive; application\ndevelopers want to leverage the latest advances in areas such as computer\nvision to provide new services and products to users, and large technology\nfirms enable this via RESTful APIs. While such APIs promise an\neasy-to-integrate on-demand machine intelligence, their current design,\ndocumentation and developer interface hides much of the underlying machine\nlearning techniques that power them. Such APIs look and feel like conventional\nAPIs but abstract away data-driven probabilistic behaviour - the implications\nof a developer treating these APIs in the same way as other, traditional cloud\nservices, such as cloud storage, is of concern. The objective of this study is\nto determine the various pain-points developers face when implementing systems\nthat rely on the most mature of these intelligent services, specifically those\nthat provide computer vision. We use Stack Overflow to mine indications of the\nfrustrations that developers appear to face when using computer vision\nservices, classifying their questions against two recent classification\ntaxonomies (documentation-related and general questions). We find that, unlike\nmature fields like mobile development, there is a contrast in the types of\nquestions asked by developers. These indicate a shallow understanding of the\nunderlying technology that empower such systems. We discuss several\nimplications of these findings via the lens of learning taxonomies to suggest\nhow the software engineering community can improve these services and comment\non the nature by which developers use them.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 00:56:51 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Cummaudo", "Alex", ""], ["Vasa", "Rajesh", ""], ["Barnett", "Scott", ""], ["Grundy", "John", ""], ["Abdelrazek", "Mohamed", ""]]}, {"id": "2001.10161", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, Wesley Cheung, Dan Tu, William Broniec, Mark\n  O. Riedl", "title": "Bringing Stories Alive: Generating Interactive Fiction Worlds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  World building forms the foundation of any task that requires narrative\nintelligence. In this work, we focus on procedurally generating interactive\nfiction worlds---text-based worlds that players \"see\" and \"talk to\" using\nnatural language. Generating these worlds requires referencing everyday and\nthematic commonsense priors in addition to being semantically consistent,\ninteresting, and coherent throughout. Using existing story plots as\ninspiration, we present a method that first extracts a partial knowledge graph\nencoding basic information regarding world structure such as locations and\nobjects. This knowledge graph is then automatically completed utilizing\nthematic knowledge and used to guide a neural language generation model that\nfleshes out the rest of the world. We perform human participant-based\nevaluations, testing our neural model's ability to extract and fill-in a\nknowledge graph and to generate language conditioned on it against rule-based\nand human-made baselines. Our code is available at\nhttps://github.com/rajammanabrolu/WorldGeneration.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 04:13:05 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Cheung", "Wesley", ""], ["Tu", "Dan", ""], ["Broniec", "William", ""], ["Riedl", "Mark O.", ""]]}, {"id": "2001.10178", "submitter": "Benjamin Evans", "authors": "Benjamin Patrick Evans, Bing Xue, Mengjie Zhang", "title": "An Adaptive and Near Parameter-free Evolutionary Computation Approach\n  Towards True Automation in AutoML", "comments": "18 pages (single column), 2 figures", "journal-ref": null, "doi": "10.1109/CEC48606.2020.9185770", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common claim of evolutionary computation methods is that they can achieve\ngood results without the need for human intervention. However, one criticism of\nthis is that there are still hyperparameters which must be tuned in order to\nachieve good performance. In this work, we propose a near \"parameter-free\"\ngenetic programming approach, which adapts the hyperparameter values throughout\nevolution without ever needing to be specified manually. We apply this to the\narea of automated machine learning (by extending TPOT), to produce pipelines\nwhich can effectively be claimed to be free from human input, and show that the\nresults are competitive with existing state-of-the-art which use hand-selected\nhyperparameter values. Pipelines begin with a randomly chosen estimator and\nevolve to competitive pipelines automatically. This work moves towards a truly\nautomatic approach to AutoML.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 05:44:53 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Evans", "Benjamin Patrick", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""]]}, {"id": "2001.10208", "submitter": "Yichuan Charlie Tang", "authors": "Yichuan Charlie Tang", "title": "Towards Learning Multi-agent Negotiations via Self-Play", "comments": "Autonomous Driving Workshop, IEEE International Conference on\n  Computer Vision (ICCV 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making sophisticated, robust, and safe sequential decisions is at the heart\nof intelligent systems. This is especially critical for planning in complex\nmulti-agent environments, where agents need to anticipate other agents'\nintentions and possible future actions. Traditional methods formulate the\nproblem as a Markov Decision Process, but the solutions often rely on various\nassumptions and become brittle when presented with corner cases. In contrast,\ndeep reinforcement learning (Deep RL) has been very effective at finding\npolicies by simultaneously exploring, interacting, and learning from\nenvironments. Leveraging the powerful Deep RL paradigm, we demonstrate that an\niterative procedure of self-play can create progressively more diverse\nenvironments, leading to the learning of sophisticated and robust multi-agent\npolicies. We demonstrate this in a challenging multi-agent simulation of\nmerging traffic, where agents must interact and negotiate with others in order\nto successfully merge on or off the road. While the environment starts off\nsimple, we increase its complexity by iteratively adding an increasingly\ndiverse set of agents to the agent \"zoo\" as training progresses. Qualitatively,\nwe find that through self-play, our policies automatically learn interesting\nbehaviors such as defensive driving, overtaking, yielding, and the use of\nsignal lights to communicate intentions to other agents. In addition,\nquantitatively, we show a dramatic improvement of the success rate of merging\nmaneuvers from 63% to over 98%.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 08:37:33 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Tang", "Yichuan Charlie", ""]]}, {"id": "2001.10269", "submitter": "Debo Cheng", "authors": "Debo Cheng (1), Jiuyong Li (1), Lin Liu (1), Jixue Liu (1), Kui Yu\n  (2), and Thuc Duy Le (1) ((1) School of Information Technology and\n  Mathematical Sciences, University of South Australia (2) School of Computer\n  Science and Information Engineering, Hefei University of Technology)", "title": "Causal query in observational data with hidden variables", "comments": "8 pages and 7 figures. The paper has been accepted by ECAI2020. We\n  have updated the proof of the Theorem 1 and removed Theorem 2 from the\n  conference version", "journal-ref": null, "doi": "10.3233/FAIA200390", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the problem of causal query in observational data with\nhidden variables, with the aim of seeking the change of an outcome when\n\"manipulating\" a variable while given a set of plausible confounding variables\nwhich affect the manipulated variable and the outcome. Such an \"experiment on\ndata\" to estimate the causal effect of the manipulated variable is useful for\nvalidating an experiment design using historical data or for exploring\nconfounders when studying a new relationship. However, existing data-driven\nmethods for causal effect estimation face some major challenges, including poor\nscalability with high dimensional data, low estimation accuracy due to\nheuristics used by the global causal structure learning algorithms, and the\nassumption of causal sufficiency when hidden variables are inevitable in data.\nIn this paper, we develop a theorem for using local search to find a superset\nof the adjustment (or confounding) variables for causal effect estimation from\nobservational data under a realistic pretreatment assumption. The theorem\nensures that the unbiased estimate of causal effect is included in the set of\ncausal effects estimated by the superset of adjustment variables. Based on the\ndeveloped theorem, we propose a data-driven algorithm for causal query.\nExperiments show that the proposed algorithm is faster and produces better\ncausal effect estimation than an existing data-driven causal effect estimation\nmethod with hidden variables. The causal effects estimated by the proposed\nalgorithm are as accurate as those by the state-of-the-art methods using domain\nknowledge.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 11:23:26 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 05:14:20 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 06:52:09 GMT"}, {"version": "v4", "created": "Tue, 24 Nov 2020 05:11:56 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Cheng", "Debo", ""], ["Li", "Jiuyong", ""], ["Liu", "Lin", ""], ["Liu", "Jixue", ""], ["Yu", "Kui", ""], ["Le", "Thuc Duy", ""]]}, {"id": "2001.10284", "submitter": "Prashan Madumal", "authors": "Prashan Madumal, Tim Miller, Liz Sonenberg, Frank Vetere", "title": "Distal Explanations for Model-free Explainable Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce and evaluate a distal explanation model for\nmodel-free reinforcement learning agents that can generate explanations for\n`why' and `why not' questions. Our starting point is the observation that\ncausal models can generate opportunity chains that take the form of `A enables\nB and B causes C'. Using insights from an analysis of 240 explanations\ngenerated in a human-agent experiment, we define a distal explanation model\nthat can analyse counterfactuals and opportunity chains using decision trees\nand causal models. A recurrent neural network is employed to learn opportunity\nchains, and decision trees are used to improve the accuracy of task prediction\nand the generated counterfactuals. We computationally evaluate the model in 6\nreinforcement learning benchmarks using different reinforcement learning\nalgorithms. From a study with 90 human participants, we show that our distal\nexplanation model results in improved outcomes over three scenarios compared\nwith two baseline explanation models.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 11:57:38 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 09:46:38 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Madumal", "Prashan", ""], ["Miller", "Tim", ""], ["Sonenberg", "Liz", ""], ["Vetere", "Frank", ""]]}, {"id": "2001.10341", "submitter": "Ning Yang", "authors": "Huanrui Luo, Ning Yang, Philip S. Yu", "title": "Hybrid Deep Embedding for Recommendations with Dynamic Aspect-Level\n  Explanations", "comments": "2019 IEEE International Conference on Big Data (Big Data) Best Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable recommendation is far from being well solved partly due to three\nchallenges. The first is the personalization of preference learning, which\nrequires that different items/users have different contributions to the\nlearning of user preference or item quality. The second one is dynamic\nexplanation, which is crucial for the timeliness of recommendation\nexplanations. The last one is the granularity of explanations. In practice,\naspect-level explanations are more persuasive than item-level or user-level\nones. In this paper, to address these challenges simultaneously, we propose a\nnovel model called Hybrid Deep Embedding (HDE) for aspect-based explainable\nrecommendations, which can make recommendations with dynamic aspect-level\nexplanations. The main idea of HDE is to learn the dynamic embeddings of users\nand items for rating prediction and the dynamic latent aspect\npreference/quality vectors for the generation of aspect-level explanations,\nthrough fusion of the dynamic implicit feedbacks extracted from reviews and the\nattentive user-item interactions. Particularly, as the aspect\npreference/quality of users/items is learned automatically, HDE is able to\ncapture the impact of aspects that are not mentioned in reviews of a user or an\nitem. The extensive experiments conducted on real datasets verify the\nrecommending performance and explainability of HDE. The source code of our work\nis available at \\url{https://github.com/lola63/HDE-Python}\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 13:16:32 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Luo", "Huanrui", ""], ["Yang", "Ning", ""], ["Yu", "Philip S.", ""]]}, {"id": "2001.10343", "submitter": "Pratikkumar Prajapati", "authors": "Pratikkumar Prajapati", "title": "Predictive analysis of Bitcoin price considering social sentiments", "comments": "12 pages, 4 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on the use of sentiment analysis on news and social media to\nanalyze and predict the price of Bitcoin. Bitcoin is the leading cryptocurrency\nand has the highest market capitalization among digital currencies. Predicting\nBitcoin values may help understand and predict potential market movement and\nfuture growth of the technology. Unlike (mostly) repeating phenomena like\nweather, cryptocurrency values do not follow a repeating pattern and mere past\nvalue of Bitcoin does not reveal any secret of future Bitcoin value. Humans\nfollow general sentiments and technical analysis to invest in the market. Hence\nconsidering people's sentiment can give a good degree of prediction. We focus\non using social sentiment as a feature to predict future Bitcoin value, and in\nparticular, consider Google News and Reddit posts. We find that social\nsentiment gives a good estimate of how future Bitcoin values may move. We\nachieve the lowest test RMSE of 434.87 using an LSTM that takes as inputs the\nhistorical price of various cryptocurrencies, the sentiment of news articles\nand the sentiment of Reddit posts.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:08:05 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Prajapati", "Pratikkumar", ""]]}, {"id": "2001.10362", "submitter": "Vivek Kothari", "authors": "Vivek Kothari, Edgar Liberis, Nicholas D. Lane", "title": "The Final Frontier: Deep Learning in Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning, particularly deep learning, is being increasing utilised in\nspace applications, mirroring the groundbreaking success in many earthbound\nproblems. Deploying a space device, e.g. a satellite, is becoming more\naccessible to small actors due to the development of modular satellites and\ncommercial space launches, which fuels further growth of this area. Deep\nlearning's ability to deliver sophisticated computational intelligence makes it\nan attractive option to facilitate various tasks on space devices and reduce\noperational costs. In this work, we identify deep learning in space as one of\ndevelopment directions for mobile and embedded machine learning. We collate\nvarious applications of machine learning to space data, such as satellite\nimaging, and describe how on-device deep learning can meaningfully improve the\noperation of a spacecraft, such as by reducing communication costs or\nfacilitating navigation. We detail and contextualise compute platform of\nsatellites and draw parallels with embedded systems and current research in\ndeep learning for resource-constrained environments.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 12:38:27 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 10:45:35 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Kothari", "Vivek", ""], ["Liberis", "Edgar", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2001.10376", "submitter": "Amit Kumar", "authors": "Amit Kumar, Manohar Madanu, Hari Prakash, Lalitha Jonnavithula,\n  Srinivasa Rao Aravilli", "title": "Advaita: Bug Duplicity Detection System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bugs are prevalent in software development. To improve software quality, bugs\nare filed using a bug tracking system. Properties of a reported bug would\nconsist of a headline, description, project, product, component that is\naffected by the bug and the severity of the bug. Duplicate bugs rate (% of\nduplicate bugs) are in the range from single digit (1 to 9%) to double digits\n(40%) based on the product maturity , size of the code and number of engineers\nworking on the project. Duplicate bugs range are between 9% to 39% in some of\nthe open source projects like Eclipse, Firefox etc. Detection of duplicity\ndeals with identifying whether any two bugs convey the same meaning. This\ndetection of duplicates helps in de-duplication. Detecting duplicate bugs help\nreduce triaging efforts and saves time for developers in fixing the issues.\nTraditional natural language processing techniques are less accurate in\nidentifying similarity between sentences. Using the bug data present in a bug\ntracking system, various approaches were explored including several machine\nlearning algorithms, to obtain a viable approach that can identify duplicate\nbugs, given a pair of sentences(i.e. the respective bug descriptions). This\napproach considers multiple sets of features viz. basic text statistical\nfeatures, semantic features and contextual features. These features are\nextracted from the headline, description and component and are subsequently\nused to train a classification algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 04:48:39 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kumar", "Amit", ""], ["Madanu", "Manohar", ""], ["Prakash", "Hari", ""], ["Jonnavithula", "Lalitha", ""], ["Aravilli", "Srinivasa Rao", ""]]}, {"id": "2001.10380", "submitter": "Aladdin Ayesh", "authors": "Qadri Mishael and Aladdin Ayesh", "title": "Investigating Classification Techniques with Feature Selection For\n  Intention Mining From Twitter Feed", "comments": "24 pages, 7 figures, 6 tables, DRAFT journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the last decade, social networks became most popular medium for\ncommunication and interaction. As an example, micro-blogging service Twitter\nhas more than 200 million registered users who exchange more than 65 million\nposts per day. Users express their thoughts, ideas, and even their intentions\nthrough these tweets. Most of the tweets are written informally and often in\nslang language, that contains misspelt and abbreviated words. This paper\ninvestigates the problem of selecting features that affect extracting user's\nintention from Twitter feeds based on text mining techniques. It starts by\npresenting the method we used to construct our own dataset from extracted\nTwitter feeds. Following that, we present two techniques of feature selection\nfollowed by classification. In the first technique, we use Information Gain as\na one-phase feature selection, followed by supervised classification\nalgorithms. In the second technique, we use a hybrid approach based on forward\nfeature selection algorithm in which two feature selection techniques employed\nfollowed by classification algorithms. We examine these two techniques with\nfour classification algorithms. We evaluate them using our own dataset, and we\ncritically review the results.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 11:55:33 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Mishael", "Qadri", ""], ["Ayesh", "Aladdin", ""]]}, {"id": "2001.10474", "submitter": "Modjtaba Shokrian Zini", "authors": "Modjtaba Shokrian Zini, Mohammad Pedramfar, Matthew Riemer, Miao Liu", "title": "Coagent Networks Revisited", "comments": "Added multiple experiments and new results to the previous version\n  \"Parameter Sharing in Coagent Networks\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is aiming to discuss and close some of the gaps in the literature\non models using options (and more generally coagents). Briefly surveying the\ntheory behind these models, it also aims to provide a unifying point of view on\nthe many diverse examples that fall under a same category called coagent\nnetwork. Motivated by the result of [10] on parameter sharing of options, we\nrevisit the theory of (a)synchronous Coagent Network [8] by generalizing the\nresult to the context where parameters are shared among the function\napproximators of coagents. The proof is more intuitive and uses the concept of\nexecution paths in a coagent network. Theoretically, this informs us of some\nnecessary modifications to the algorithms found in the literature which make\nthem more mathematically accurate. It also allows us to introduce a new simple\noption framework, Feedforward Option Network, which outperforms the previous\noption models in time to convergence and stability in the famous nonstationary\nFour Rooms task. In addition, a stabilization effect is observed in\nhierarchical models which justify the unnecessity of the target network in\ntraining such models. Finally, we publish our code which allows us to be\nflexible in our experiments settings.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 17:31:23 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 11:09:46 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Zini", "Modjtaba Shokrian", ""], ["Pedramfar", "Mohammad", ""], ["Riemer", "Matthew", ""], ["Liu", "Miao", ""]]}, {"id": "2001.10560", "submitter": "Mehdi Ali", "authors": "Mehdi Ali, Hajira Jabeen, Charles Tapley Hoyt, and Jens Lehman", "title": "The KEEN Universe: An Ecosystem for Knowledge Graph Embeddings with a\n  Focus on Reproducibility and Transferability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an emerging trend of embedding knowledge graphs (KGs) in continuous\nvector spaces in order to use those for machine learning tasks. Recently, many\nknowledge graph embedding (KGE) models have been proposed that learn low\ndimensional representations while trying to maintain the structural properties\nof the KGs such as the similarity of nodes depending on their edges to other\nnodes. KGEs can be used to address tasks within KGs such as the prediction of\nnovel links and the disambiguation of entities. They can also be used for\ndownstream tasks like question answering and fact-checking. Overall, these\ntasks are relevant for the semantic web community. Despite their popularity,\nthe reproducibility of KGE experiments and the transferability of proposed KGE\nmodels to research fields outside the machine learning community can be a major\nchallenge. Therefore, we present the KEEN Universe, an ecosystem for knowledge\ngraph embeddings that we have developed with a strong focus on reproducibility\nand transferability. The KEEN Universe currently consists of the Python\npackages PyKEEN (Python KnowlEdge EmbeddiNgs), BioKEEN (Biological KnowlEdge\nEmbeddiNgs), and the KEEN Model Zoo for sharing trained KGE models with the\ncommunity.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 19:12:37 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Ali", "Mehdi", ""], ["Jabeen", "Hajira", ""], ["Hoyt", "Charles Tapley", ""], ["Lehman", "Jens", ""]]}, {"id": "2001.10581", "submitter": "M\\'arcio Silva", "authors": "M\\'arcio Silva, Lucas Santos de Oliveira, Athanasios Andreou, Pedro\n  Olmo Vaz de Melo, Oana Goga and Fabr\\'icio Benevenuto", "title": "Facebook Ads Monitor: An Independent Auditing System for Political Ads\n  on Facebook", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 2016 United States presidential election was marked by the abuse of\ntargeted advertising on Facebook. Concerned with the risk of the same kind of\nabuse to happen in the 2018 Brazilian elections, we designed and deployed an\nindependent auditing system to monitor political ads on Facebook in Brazil. To\ndo that we first adapted a browser plugin to gather ads from the timeline of\nvolunteers using Facebook. We managed to convince more than 2000 volunteers to\nhelp our project and install our tool. Then, we use a Convolution Neural\nNetwork (CNN) to detect political Facebook ads using word embeddings. To\nevaluate our approach, we manually label a data collection of 10k ads as\npolitical or non-political and then we provide an in-depth evaluation of\nproposed approach for identifying political ads by comparing it with classic\nsupervised machine learning methods. Finally, we deployed a real system that\nshows the ads identified as related to politics. We noticed that not all\npolitical ads we detected were present in the Facebook Ad Library for political\nads. Our results emphasize the importance of enforcement mechanisms for\ndeclaring political ads and the need for independent auditing platforms.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 20:34:06 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 13:26:33 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Silva", "M\u00e1rcio", ""], ["de Oliveira", "Lucas Santos", ""], ["Andreou", "Athanasios", ""], ["de Melo", "Pedro Olmo Vaz", ""], ["Goga", "Oana", ""], ["Benevenuto", "Fabr\u00edcio", ""]]}, {"id": "2001.10585", "submitter": "Duygu Sap", "authors": "Duygu Sap and Daniel P. Szabo", "title": "An Automated Approach for the Discovery of Interoperability", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we present an automated approach that would test for and\ndiscover the interoperability of CAD systems based on the\napproximately-invariant shape properties of their models. We further show that\nexchanging models in standard format does not guarantee the preservation of\nshape properties. Our analysis is based on utilizing queries in deriving the\nshape properties and constructing the proxy models of the given CAD models [1].\nWe generate template files to accommodate the information necessary for the\nproperty computations and proxy model constructions, and implement an\ninteroperability discovery program called DTest to execute the interoperability\ntesting. We posit that our method could be extended to interoperability testing\non CAD-to-CAE and/or CAD-to-CAM interactions by modifying the set of property\nchecks and providing the additional requirements that may emerge in CAE or CAM\napplications.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 06:07:43 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Sap", "Duygu", ""], ["Szabo", "Daniel P.", ""]]}, {"id": "2001.10615", "submitter": "Karla Saldana Ochoa", "authors": "Diana Alvarez-Marin and Karla Saldana Ochoa", "title": "Indexical Cities: Articulating Personal Models of Urban Preference with\n  Geotagged Data", "comments": "29 pages 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to assess the potential of liking a city or a neighborhood before ever\nhaving been there. The concept of urban quality has until now pertained to\nglobal city ranking, where cities are evaluated under a grid of given\nparameters, or either to empirical and sociological approaches, often\nconstrained by the amount of available information. Using state of the art\nmachine learning techniques and thousands of geotagged satellite and\nperspective images from diverse urban cultures, this research characterizes\npersonal preference in urban spaces and predicts a spectrum of unknown likeable\nplaces for a specific observer. Unlike most urban perception studies, our\nintention is not by any means to provide an objective measure of urban quality,\nbut rather to portray personal views of the city or Cities of Indexes.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 11:00:19 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Alvarez-Marin", "Diana", ""], ["Ochoa", "Karla Saldana", ""]]}, {"id": "2001.10617", "submitter": "Manikandan Ravikiran", "authors": "Manikandan Ravikiran", "title": "Systematic Review of Approaches to Improve Peer Assessment at Scale", "comments": "This is a review assignment, work on progress. Expected to be updated\n  regularly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Peer Assessment is a task of analysis and commenting on student's writing by\npeers, is core of all educational components both in campus and in MOOC's.\nHowever, with the sheer scale of MOOC's & its inherent personalised open ended\nlearning, automatic grading and tools assisting grading at scale is highly\nimportant. Previously we presented survey on tasks of post classification,\nknowledge tracing and ended with brief review on Peer Assessment (PA), with\nsome initial problems. In this review we shall continue review on PA from\nperspective of improving the review process itself. As such rest of this review\nfocus on three facets of PA namely Auto grading and Peer Assessment Tools (we\nshall look only on how peer reviews/auto-grading is carried), strategies to\nhandle Rogue Reviews, Peer Review Improvement using Natural Language\nProcessing. The consolidated set of papers and resources so used are released\nin https://github.com/manikandan-ravikiran/cs6460-Survey-2.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 15:59:24 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Ravikiran", "Manikandan", ""]]}, {"id": "2001.10640", "submitter": "Jie Zhang", "authors": "Zihe Wang and Zhide Wei and Jie Zhang", "title": "Bounded Incentives in Manipulating the Probabilistic Serial Rule", "comments": "To appear in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Probabilistic Serial mechanism is well-known for its desirable fairness\nand efficiency properties. It is one of the most prominent protocols for the\nrandom assignment problem. However, Probabilistic Serial is not\nincentive-compatible, thereby these desirable properties only hold for the\nagents' declared preferences, rather than their genuine preferences. A\nsubstantial utility gain through strategic behaviors would trigger\nself-interested agents to manipulate the mechanism and would subvert the very\nfoundation of adopting the mechanism in practice. In this paper, we\ncharacterize the extent to which an individual agent can increase its utility\nby strategic manipulation. We show that the incentive ratio of the mechanism is\n$\\frac{3}{2}$. That is, no agent can misreport its preferences such that its\nutility becomes more than 1.5 times of what it is when reports truthfully. This\nratio is a worst-case guarantee by allowing an agent to have complete\ninformation about other agents' reports and to figure out the best response\nstrategy even if it is computationally intractable in general. To complement\nthis worst-case study, we further evaluate an agent's utility gain on average\nby experiments. The experiments show that an agent' incentive in manipulating\nthe rule is very limited. These results shed some light on the robustness of\nProbabilistic Serial against strategic manipulation, which is one step further\nthan knowing that it is not incentive-compatible.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 23:53:37 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Wang", "Zihe", ""], ["Wei", "Zhide", ""], ["Zhang", "Jie", ""]]}, {"id": "2001.10726", "submitter": "Andr\\'es Camero", "authors": "Andr\\'es Camero, Hao Wang, Enrique Alba, Thomas B\\\"ack", "title": "Bayesian Neural Architecture Search using A Training-Free Performance\n  Metric", "comments": null, "journal-ref": "Applied Soft Computing, p.107356 (2021)", "doi": "10.1016/j.asoc.2021.107356", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are a powerful approach for time series\nprediction. However, their performance is strongly affected by their\narchitecture and hyperparameter settings. The architecture optimization of RNNs\nis a time-consuming task, where the search space is typically a mixture of\nreal, integer and categorical values. To allow for shrinking and expanding the\nsize of the network, the representation of architectures often has a variable\nlength. In this paper, we propose to tackle the architecture optimization\nproblem with a variant of the Bayesian Optimization (BO) algorithm. To reduce\nthe evaluation time of candidate architectures the Mean Absolute Error Random\nSampling (MRS), a training-free method to estimate the network performance, is\nadopted as the objective function for BO. Also, we propose three fixed-length\nencoding schemes to cope with the variable-length architecture representation.\nThe result is a new perspective on accurate and efficient design of RNNs, that\nwe validate on three problems. Our findings show that 1) the BO algorithm can\nexplore different network architectures using the proposed encoding schemes and\nsuccessfully designs well-performing architectures, and 2) the optimization\ntime is significantly reduced by using MRS, without compromising the\nperformance as compared to the architectures obtained from the actual training\nprocedure.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 08:42:58 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 07:48:42 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Camero", "Andr\u00e9s", ""], ["Wang", "Hao", ""], ["Alba", "Enrique", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2001.10730", "submitter": "Sicui Zhang", "authors": "Sicui Zhang (1 and 2), Laura Genga (2), Hui Yan (1 and 2), Xudong Lu\n  (1 and 2), Huilong Duan (1), Uzay Kaymak (2 and 1) ((1) School of Biomedical\n  Engineering and Instrumental Science, Zhejiang University, Hangzhou, P.R.\n  China, (2) School of Industrial Engineering, Eindhoven University of\n  Technology, Eindhoven, The Netherlands)", "title": "Towards Multi-perspective conformance checking with fuzzy sets", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conformance checking techniques are widely adopted to pinpoint possible\ndiscrepancies between process models and the execution of the process in\nreality. However, state of the art approaches adopt a crisp evaluation of\ndeviations, with the result that small violations are considered at the same\nlevel of significant ones. This affects the quality of the provided\ndiagnostics, especially when there exists some tolerance with respect to\nreasonably small violations, and hampers the flexibility of the process. In\nthis work, we propose a novel approach which allows to represent actors'\ntolerance with respect to violations and to account for severity of deviations\nwhen assessing executions compliance. We argue that besides improving the\nquality of the provided diagnostics, allowing some tolerance in deviations\nassessment also enhances the flexibility of conformance checking techniques\nand, indirectly, paves the way for improving the resilience of the overall\nprocess management system.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 09:02:23 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Zhang", "Sicui", "", "1 and 2"], ["Genga", "Laura", "", "1 and 2"], ["Yan", "Hui", "", "1 and 2"], ["Lu", "Xudong", "", "1 and 2"], ["Duan", "Huilong", "", "2 and 1"], ["Kaymak", "Uzay", "", "2 and 1"]]}, {"id": "2001.10742", "submitter": "Ming Yin", "authors": "Ming Yin and Yu-Xiang Wang (University of California Santa Barbara)", "title": "Asymptotically Efficient Off-Policy Evaluation for Tabular Reinforcement\n  Learning", "comments": "Includes appendix. Accepted for AISTATS 2020", "journal-ref": "International Conference on Artificial Intelligence and\n  Statistics, 108 (2020) 3948-3958", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of off-policy evaluation for reinforcement learning,\nwhere the goal is to estimate the expected reward of a target policy $\\pi$\nusing offline data collected by running a logging policy $\\mu$. Standard\nimportance-sampling based approaches for this problem suffer from a variance\nthat scales exponentially with time horizon $H$, which motivates a splurge of\nrecent interest in alternatives that break the \"Curse of Horizon\" (Liu et al.\n2018, Xie et al. 2019). In particular, it was shown that a marginalized\nimportance sampling (MIS) approach can be used to achieve an estimation error\nof order $O(H^3/ n)$ in mean square error (MSE) under an episodic Markov\nDecision Process model with finite states and potentially infinite actions. The\nMSE bound however is still a factor of $H$ away from a Cramer-Rao lower bound\nof order $\\Omega(H^2/n)$. In this paper, we prove that with a simple\nmodification to the MIS estimator, we can asymptotically attain the Cramer-Rao\nlower bound, provided that the action space is finite. We also provide a\ngeneral method for constructing MIS estimators with high-probability error\nbounds.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 09:56:26 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Yin", "Ming", "", "University of California Santa Barbara"], ["Wang", "Yu-Xiang", "", "University of California Santa Barbara"]]}, {"id": "2001.10799", "submitter": "Rustam Tagiew", "authors": "Rustam Tagiew", "title": "Business Negotiation Definition Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The target of this paper is to present an industry-ready prototype software\nfor general game playing. This software can also be used as the central element\nfor experimental economics research, interfacing of game-theoretic libraries,\nAI-driven software testing, algorithmic trade, human behavior mining and\nsimulation of (strategic) interactions. The software is based on a\ndomain-specific language for electronic business to business negotiations --\nSIDL3.0. The paper also contains many examples to prove the power of this\nlanguage.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 11:07:00 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Tagiew", "Rustam", ""]]}, {"id": "2001.10828", "submitter": "Ji\\v{r}\\'i Fink", "authors": "Ji\\v{r}\\'i Fink, Martin Loebl, Petra Pelik\\'anov\\'a", "title": "A New Arc-Routing Algorithm Applied to Winter Road Maintenance", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies large scale instances of a fairly general arc-routing\nproblem as well as incorporate practical constraints in particular coming from\nthe scheduling problem of the winter road maintenance (e.g. different\npriorities for and methods of road maintenance). We develop a new algorithm\nbased on a bin-packing heuristic which is well-scalable and able to solve road\nnetworks on thousands of crossroads and road segments in few minutes. Since it\nis impossible to find an optimal solution for such a large instances to compare\nit with a result of our algorithm, we also develop techniques to compute lower\nbounds which are based on Integer Linear Programming and Lazy Constraints.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 08:44:42 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Fink", "Ji\u0159\u00ed", ""], ["Loebl", "Martin", ""], ["Pelik\u00e1nov\u00e1", "Petra", ""]]}, {"id": "2001.10834", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima", "title": "Smart Induction for Isabelle/HOL (System Description)", "comments": "Under submission at IJCAR2020 as a System Description", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.PL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof assistants offer tactics to facilitate inductive proofs. However, it\nstill requires human ingenuity to decide what arguments to pass to those\ninduction tactics. To automate this process, we present smart_induct for\nIsabelle/HOL. Given an inductive problem in any problem domain, smart_induct\nlists promising arguments for the induct tactic without relying on a search.\nOur evaluation demonstrated smart_induct produces valuable recommendations\nacross problem domains.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 15:29:34 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Nagashima", "Yutaka", ""]]}, {"id": "2001.10905", "submitter": "Ioannis Papantonis", "authors": "Ioannis Papantonis, Vaishak Belle", "title": "Interventions and Counterfactuals in Tractable Probabilistic Models:\n  Limitations of Contemporary Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been an increasing interest in studying\ncausality-related properties in machine learning models generally, and in\ngenerative models in particular. While that is well motivated, it inherits the\nfundamental computational hardness of probabilistic inference, making exact\nreasoning intractable. Probabilistic tractable models have also recently\nemerged, which guarantee that conditional marginals can be computed in time\nlinear in the size of the model, where the model is usually learned from data.\nAlthough initially limited to low tree-width models, recent tractable models\nsuch as sum product networks (SPNs) and probabilistic sentential decision\ndiagrams (PSDDs) exploit efficient function representations and also capture\nhigh tree-width models.\n  In this paper, we ask the following technical question: can we use the\ndistributions represented or learned by these models to perform causal queries,\nsuch as reasoning about interventions and counterfactuals? By appealing to some\nexisting ideas on transforming such models to Bayesian networks, we answer\nmostly in the negative. We show that when transforming SPNs to a causal graph\ninterventional reasoning reduces to computing marginal distributions; in other\nwords, only trivial causal reasoning is possible. For PSDDs the situation is\nonly slightly better. We first provide an algorithm for constructing a causal\ngraph from a PSDD, which introduces augmented variables. Intervening on the\noriginal variables, once again, reduces to marginal distributions, but when\nintervening on the augmented variables, a deterministic but nonetheless\ncausal-semantics can be provided for PSDDs.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 15:45:47 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Papantonis", "Ioannis", ""], ["Belle", "Vaishak", ""]]}, {"id": "2001.10913", "submitter": "Andrea Banino", "authors": "Andrea Banino, Adri\\`a Puigdom\\`enech Badia, Raphael K\\\"oster, Martin\n  J. Chadwick, Vinicius Zambaldi, Demis Hassabis, Caswell Barry, Matthew\n  Botvinick, Dharshan Kumaran, Charles Blundell", "title": "MEMO: A Deep Network for Flexible Combination of Episodic Memories", "comments": "9 pages, 2 figures, 3 tables, to be published as a conference paper\n  at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research developing neural network architectures with external memory\nhave often used the benchmark bAbI question and answering dataset which\nprovides a challenging number of tasks requiring reasoning. Here we employed a\nclassic associative inference task from the memory-based reasoning neuroscience\nliterature in order to more carefully probe the reasoning capacity of existing\nmemory-augmented architectures. This task is thought to capture the essence of\nreasoning -- the appreciation of distant relationships among elements\ndistributed across multiple facts or memories. Surprisingly, we found that\ncurrent architectures struggle to reason over long distance associations.\nSimilar results were obtained on a more complex task involving finding the\nshortest path between nodes in a path. We therefore developed MEMO, an\narchitecture endowed with the capacity to reason over longer distances. This\nwas accomplished with the addition of two novel components. First, it\nintroduces a separation between memories (facts) stored in external memory and\nthe items that comprise these facts in external memory. Second, it makes use of\nan adaptive retrieval mechanism, allowing a variable number of \"memory hops\"\nbefore the answer is produced. MEMO is capable of solving our novel reasoning\ntasks, as well as match state of the art results in bAbI.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 15:56:16 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Banino", "Andrea", ""], ["Badia", "Adri\u00e0 Puigdom\u00e8nech", ""], ["K\u00f6ster", "Raphael", ""], ["Chadwick", "Martin J.", ""], ["Zambaldi", "Vinicius", ""], ["Hassabis", "Demis", ""], ["Barry", "Caswell", ""], ["Botvinick", "Matthew", ""], ["Kumaran", "Dharshan", ""], ["Blundell", "Charles", ""]]}, {"id": "2001.10916", "submitter": "Sherif Saad", "authors": "William Briguglio and Sherif Saad", "title": "Interpreting Machine Learning Malware Detectors Which Leverage N-gram\n  Analysis", "comments": "18 pages, The 12th International Symposium on Foundations & Practice\n  of Security, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cyberattack detection and prevention systems, cybersecurity analysts\nalways prefer solutions that are as interpretable and understandable as\nrule-based or signature-based detection. This is because of the need to tune\nand optimize these solutions to mitigate and control the effect of false\npositives and false negatives. Interpreting machine learning models is a new\nand open challenge. However, it is expected that an interpretable machine\nlearning solution will be domain-specific. For instance, interpretable\nsolutions for machine learning models in healthcare are different than\nsolutions in malware detection. This is because the models are complex, and\nmost of them work as a black-box. Recently, the increased ability for malware\nauthors to bypass antimalware systems has forced security specialists to look\nto machine learning for creating robust detection systems. If these systems are\nto be relied on in the industry, then, among other challenges, they must also\nexplain their predictions. The objective of this paper is to evaluate the\ncurrent state-of-the-art ML models interpretability techniques when applied to\nML-based malware detectors. We demonstrate interpretability techniques in\npractice and evaluate the effectiveness of existing interpretability techniques\nin the malware analysis domain.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 19:10:50 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Briguglio", "William", ""], ["Saad", "Sherif", ""]]}, {"id": "2001.10922", "submitter": "Jason Bernard", "authors": "Jason Bernard, Ian McQuillan", "title": "Stochastic L-system Inference from Multiple String Sequence Inputs", "comments": "24 pages, 5 figures, submitted to Applied Soft Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lindenmayer systems (L-systems) are a grammar system that consist of string\nrewriting rules. The rules replace every symbol in a string in parallel with a\nsuccessor to produce the next string, and this procedure iterates. In a\nstochastic context-free L-system (S0L-system), every symbol may have one or\nmore rewriting rule, each with an associated probability of selection. Properly\nconstructed rewriting rules have been found to be useful for modeling and\nsimulating some natural and human engineered processes where each derived\nstring describes a step in the simulation. Typically, processes are modeled by\nexperts who meticulously construct the rules based on measurements or domain\nknowledge of the process. This paper presents an automated approach to finding\nstochastic L-systems, given a set of string sequences as input. The implemented\ntool is called the Plant Model Inference Tool for S0L-systems (PMIT-S0L).\nPMIT-S0L is evaluated using 960 procedurally generated S0L-systems in a test\nsuite, which are each used to generate input strings, and PMIT-S0L is then used\nto infer the system from only the sequences. The evaluation shows that PMIT-S0L\ninfers S0L-systems with up to 9 rewriting rules each in under 12 hours.\nAdditionally, it is found that 3 sequences of strings is sufficient to find the\ncorrect original rewriting rules in 100% of the cases in the test suite, and 6\nsequences of strings reduces the difference in the associated probabilities to\napproximately 1% or less.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 16:11:02 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Bernard", "Jason", ""], ["McQuillan", "Ian", ""]]}, {"id": "2001.10929", "submitter": "Juri Opitz", "authors": "Juri Opitz and Letitia Parcalabescu and Anette Frank", "title": "AMR Similarity Metrics from Principles", "comments": "TACL 2020 https://doi.org/10.1162/tacl_a_00329", "journal-ref": null, "doi": "10.1162/tacl_a_00329", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different metrics have been proposed to compare Abstract Meaning\nRepresentation (AMR) graphs. The canonical Smatch metric (Cai and Knight, 2013)\naligns the variables of two graphs and assesses triple matches. The recent\nSemBleu metric (Song and Gildea, 2019) is based on the machine-translation\nmetric Bleu (Papineni et al., 2002) and increases computational efficiency by\nablating the variable-alignment.\n  In this paper, i) we establish criteria that enable researchers to perform a\nprincipled assessment of metrics comparing meaning representations like AMR;\nii) we undertake a thorough analysis of Smatch and SemBleu where we show that\nthe latter exhibits some undesirable properties. For example, it does not\nconform to the identity of indiscernibles rule and introduces biases that are\nhard to control; iii) we propose a novel metric S$^2$match that is more\nbenevolent to only very slight meaning deviations and targets the fulfilment of\nall established criteria. We assess its suitability and show its advantages\nover Smatch and SemBleu.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 16:19:44 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 09:34:56 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Opitz", "Juri", ""], ["Parcalabescu", "Letitia", ""], ["Frank", "Anette", ""]]}, {"id": "2001.10953", "submitter": "Nihar Shrikant Bendre", "authors": "Nihar Bendre, Nima Ebadi, John J Prevost and Paul Rad", "title": "Human Action Performance using Deep Neuro-Fuzzy Recurrent Attention\n  Model", "comments": "1 pages, 6 figures, 2 algorithms. Published at IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2020.2982364", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A great number of computer vision publications have focused on distinguishing\nbetween human action recognition and classification rather than the intensity\nof actions performed. Indexing the intensity which determines the performance\nof human actions is a challenging task due to the uncertainty and information\ndeficiency that exists in the video inputs. To remedy this uncertainty, in this\npaper we coupled fuzzy logic rules with the neural-based action recognition\nmodel to rate the intensity of a human action as intense or mild. In our\napproach, we used a Spatio-Temporal LSTM to generate the weights of the\nfuzzy-logic model, and then demonstrate through experiments that indexing of\nthe action intensity is possible. We analyzed the integrated model by applying\nit to videos of human actions with different action intensities and were able\nto achieve an accuracy of 89.16% on our intensity indexing generated dataset.\nThe integrated model demonstrates the ability of a neuro-fuzzy inference module\nto effectively estimate the intensity index of human actions.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 16:56:39 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 17:40:08 GMT"}, {"version": "v3", "created": "Wed, 25 Mar 2020 20:40:07 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Bendre", "Nihar", ""], ["Ebadi", "Nima", ""], ["Prevost", "John J", ""], ["Rad", "Paul", ""]]}, {"id": "2001.11017", "submitter": "Konstantin D Pandl", "authors": "Konstantin D. Pandl, Scott Thiebes, Manuel Schmidt-Kraepelin, Ali\n  Sunyaev", "title": "On the Convergence of Artificial Intelligence and Distributed Ledger\n  Technology: A Scoping Review and Future Research Agenda", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developments in Artificial Intelligence (AI) and Distributed Ledger\nTechnology (DLT) currently lead to lively debates in academia and practice. AI\nprocesses data to perform tasks that were previously thought possible only for\nhumans. DLT has the potential to create consensus over data among a group of\nparticipants in uncertain environments. In recent research, both technologies\nare used in similar and even the same systems. Examples include the design of\nsecure distributed ledgers or the creation of allied learning systems\ndistributed across multiple nodes. This can lead to technological convergence,\nwhich in the past, has paved the way for major innovations in information\ntechnology. Previous work highlights several potential benefits of the\nconvergence of AI and DLT but only provides a limited theoretical framework to\ndescribe upcoming real-world integration cases of both technologies. We aim to\ncontribute by conducting a systematic literature review on previous work and\nproviding rigorously derived future research opportunities. This work helps\nresearchers active in AI or DLT to overcome current limitations in their field,\nand practitioners to develop systems along with the convergence of both\ntechnologies.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 18:57:27 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 13:36:25 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Pandl", "Konstantin D.", ""], ["Thiebes", "Scott", ""], ["Schmidt-Kraepelin", "Manuel", ""], ["Sunyaev", "Ali", ""]]}, {"id": "2001.11027", "submitter": "Volker Tresp", "authors": "Volker Tresp and Sahand Sharifzadeh and Dario Konopatzki and Yunpu Ma", "title": "The Tensor Brain: Semantic Decoding for Perception and Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse perception and memory, using mathematical models for knowledge\ngraphs and tensors, to gain insights into the corresponding functionalities of\nthe human mind. Our discussion is based on the concept of propositional\nsentences consisting of \\textit{subject-predicate-object} (SPO) triples for\nexpressing elementary facts. SPO sentences are the basis for most natural\nlanguages but might also be important for explicit perception and declarative\nmemories, as well as intra-brain communication and the ability to argue and\nreason. A set of SPO sentences can be described as a knowledge graph, which can\nbe transformed into an adjacency tensor. We introduce tensor models, where\nconcepts have dual representations as indices and associated embeddings, two\nconstructs we believe are essential for the understanding of implicit and\nexplicit perception and memory in the brain. We argue that a biological\nrealization of perception and memory imposes constraints on information\nprocessing. In particular, we propose that explicit perception and declarative\nmemories require a semantic decoder, which, in a simple realization, is based\non four layers: First, a sensory memory layer, as a buffer for sensory input,\nsecond, an index layer representing concepts, third, a memoryless\nrepresentation layer for the broadcasting of information ---the \"blackboard\",\nor the \"canvas\" of the brain--- and fourth, a working memory layer as a\nprocessing center and data buffer. We discuss the operations of the four layers\nand relate them to the global workspace theory. In a Bayesian brain\ninterpretation, semantic memory defines the prior for observable triple\nstatements. We propose that ---in evolution and during development--- semantic\nmemory, episodic memory, and natural language evolved as emergent properties in\nagents' process to gain a deeper understanding of sensory information.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 07:48:01 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 16:21:01 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 08:41:03 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Tresp", "Volker", ""], ["Sharifzadeh", "Sahand", ""], ["Konopatzki", "Dario", ""], ["Ma", "Yunpu", ""]]}, {"id": "2001.11031", "submitter": "Jakob Knollm\\\"uller", "authors": "Jakob Knollm\\\"uller and Torsten En{\\ss}lin", "title": "Bayesian Reasoning with Trained Neural Networks", "comments": null, "journal-ref": "Entropy 2021, 23(6), 693", "doi": "10.3390/e23060693", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We showed how to use trained neural networks to perform Bayesian reasoning in\norder to solve tasks outside their initial scope. Deep generative models\nprovide prior knowledge, and classification/regression networks impose\nconstraints. The tasks at hand were formulated as Bayesian inference problems,\nwhich we approximately solved through variational or sampling techniques. The\napproach built on top of already trained networks, and the addressable\nquestions grew super-exponentially with the number of available networks. In\nits simplest form, the approach yielded conditional generative models. However,\nmultiple simultaneous constraints constitute elaborate questions. We compared\nthe approach to specifically trained generators, showed how to solve riddles,\nand demonstrated its compatibility with state-of-the-art architectures.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 19:00:00 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 18:00:05 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 09:55:29 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Knollm\u00fcller", "Jakob", ""], ["En\u00dflin", "Torsten", ""]]}, {"id": "2001.11165", "submitter": "Sam Ganzfried", "authors": "Sam Ganzfried", "title": "Fictitious Play Outperforms Counterfactual Regret Minimization", "comments": "Fixed a bug in the 5-player CFR implementation from prior version and\n  reran the 5-player experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare the performance of two popular algorithms, fictitious play and\ncounterfactual regret minimization, in approximating Nash equilibrium in\nmultiplayer games. Despite recent success of counterfactual regret minimization\nin multiplayer poker and conjectures of its superiority, we show that\nfictitious play leads to improved Nash equilibrium approximation over a variety\nof game classes and sizes.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 03:47:09 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 18:55:50 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 00:06:01 GMT"}, {"version": "v4", "created": "Mon, 18 May 2020 22:01:27 GMT"}, {"version": "v5", "created": "Thu, 23 Jul 2020 19:02:20 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Ganzfried", "Sam", ""]]}, {"id": "2001.11224", "submitter": "Tuomo Hiippala", "authors": "Tuomo Hiippala and John A. Bateman", "title": "Introducing the diagrammatic mode", "comments": "16 pages; submitted to Diagrams 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we propose a multimodal perspective to diagrammatic\nrepresentations by sketching a description of what may be tentatively termed\nthe diagrammatic mode. We consider diagrammatic representations in the light of\ncontemporary multimodality theory and explicate what enables diagrammatic\nrepresentations to integrate natural language, various forms of graphics,\ndiagrammatic elements such as arrows, lines and other expressive resources into\ncoherent organisations. We illustrate the proposed approach using two recent\ndiagram corpora and show how a multimodal approach supports the empirical\nanalysis of diagrammatic representations, especially in identifying\ndiagrammatic constituents and describing their interrelations.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 09:17:32 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Hiippala", "Tuomo", ""], ["Bateman", "John A.", ""]]}, {"id": "2001.11261", "submitter": "Mischa Schmidt", "authors": "Mischa Schmidt, Julia Gastinger, S\\'ebastien Nicolas, Anett Sch\\\"ulke\n  (NEC Laboratories Europe GmbH)", "title": "HAMLET -- A Learning Curve-Enabled Multi-Armed Bandit for Algorithm\n  Selection", "comments": "8 pages, 8 figures; IJCNN 2020: International Joint Conference on\n  Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated algorithm selection and hyperparameter tuning facilitates the\napplication of machine learning. Traditional multi-armed bandit strategies look\nto the history of observed rewards to identify the most promising arms for\noptimizing expected total reward in the long run. When considering limited time\nbudgets and computational resources, this backward view of rewards is\ninappropriate as the bandit should look into the future for anticipating the\nhighest final reward at the end of a specified time budget. This work addresses\nthat insight by introducing HAMLET, which extends the bandit approach with\nlearning curve extrapolation and computation time-awareness for selecting among\na set of machine learning algorithms. Results show that the HAMLET Variants 1-3\nexhibit equal or better performance than other bandit-based algorithm selection\nstrategies in experiments with recorded hyperparameter tuning traces for the\nmajority of considered time budgets. The best performing HAMLET Variant 3\ncombines learning curve extrapolation with the well-known upper confidence\nbound exploration bonus. That variant performs better than all non-HAMLET\npolicies with statistical significance at the 95% level for 1,485 runs.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:28:39 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 08:37:16 GMT"}, {"version": "v3", "created": "Thu, 28 May 2020 06:56:35 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Schmidt", "Mischa", "", "NEC Laboratories Europe GmbH"], ["Gastinger", "Julia", "", "NEC Laboratories Europe GmbH"], ["Nicolas", "S\u00e9bastien", "", "NEC Laboratories Europe GmbH"], ["Sch\u00fclke", "Anett", "", "NEC Laboratories Europe GmbH"]]}, {"id": "2001.11274", "submitter": "Alfonso White", "authors": "Alfonso White, Daniela M. Romano", "title": "Scalable Psychological Momentum Forecasting in Esports", "comments": "8 pages, 8 figures", "journal-ref": "Proceedings of Workshop SUM '20: State-based User Modelling, The\n  13th ACM International Conference on Web Search and Data Mining (WSDM '20),\n  2020", "doi": "10.13140/RG.2.2.21224.21769", "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world of competitive Esports and video gaming has seen and continues to\nexperience steady growth in popularity and complexity. Correspondingly, more\nresearch on the topic is being published, ranging from social network analyses\nto the benchmarking of advanced artificial intelligence systems in playing\nagainst humans. In this paper, we present ongoing work on an intelligent agent\nrecommendation engine that suggests actions to players in order to maximise\nsuccess and enjoyment, both in the space of in-game choices, as well as\ndecisions made around play session timing in the broader context. By leveraging\ntemporal data and appropriate models, we show that a learned representation of\nplayer psychological momentum, and of tilt, can be used, in combination with\nplayer expertise, to achieve state-of-the-art performance in pre- and\npost-draft win prediction. Our progress toward fulfilling the potential for\nderiving optimal recommendations is documented.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:57:40 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 01:16:19 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["White", "Alfonso", ""], ["Romano", "Daniela M.", ""]]}, {"id": "2001.11279", "submitter": "Victor-Alexandru Darvariu", "authors": "Victor-Alexandru Darvariu, Stephen Hailes, Mirco Musolesi", "title": "Improving the Robustness of Graphs through Reinforcement Learning and\n  Graph Neural Networks", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs can be used to represent and reason about real world systems and a\nvariety of metrics have been devised to quantify their global characteristics.\nAn important property is robustness to failures and attacks, which is relevant\nfor the infrastructure and communication networks that power modern society.\nPrior work on making topological modifications to a graph, e.g., adding edges,\nin order to increase robustness is typically based on local and spectral\nproperties or a shallow search since robustness is expensive to compute\ndirectly. However, such strategies are necessarily suboptimal.\n  In this work, we present RNet-DQN, an approach for constructing networks that\nuses Reinforcement Learning to address improving the robustness of graphs to\nrandom and targeted removals of nodes. In particular, the approach relies on\nchanges in the estimated robustness as a reward signal and Graph Neural\nNetworks for representing states. Experiments on synthetic and real-world\ngraphs show that this approach can deliver performance superior to existing\nmethods while being much cheaper to evaluate and generalizing to out-of-sample\ngraphs, as well as to larger out-of-distribution graphs in some cases. The\napproach is readily applicable to optimizing other global structural properties\nof graphs.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 12:11:45 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 20:38:53 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 10:24:09 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Darvariu", "Victor-Alexandru", ""], ["Hailes", "Stephen", ""], ["Musolesi", "Mirco", ""]]}, {"id": "2001.11324", "submitter": "Basit Qureshi", "authors": "Basit Qureshi and Yasir Javed", "title": "Proceedings of Symposium on Data Mining Applications 2014", "comments": "Proceedings of Symposium on Data Mining Applications 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Symposium on Data Mining and Applications (SDMA 2014) is aimed to gather\nresearchers and application developers from a wide range of data mining related\nareas such as statistics, computational intelligence, pattern recognition,\ndatabases, Big Data Mining and visualization. SDMA is organized by MEGDAM to\nadvance the state of the art in data mining research field and its various real\nworld applications. The symposium will provide opportunities for technical\ncollaboration among data mining and machine learning researchers around the\nSaudi Arabia, GCC countries and Middle-East region. Acceptance will be based\nprimarily on originality, significance and quality of contribution.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 07:30:00 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Qureshi", "Basit", ""], ["Javed", "Yasir", ""]]}, {"id": "2001.11337", "submitter": "Zehong Cao Prof.", "authors": "Xiaotong Gu, Zehong Cao, Alireza Jolfaei, Peng Xu, Dongrui Wu,\n  Tzyy-Ping Jung, Chin-Teng Lin", "title": "EEG-based Brain-Computer Interfaces (BCIs): A Survey of Recent Studies\n  on Signal Sensing Technologies and Computational Intelligence Approaches and\n  their Applications", "comments": "Submitting to IEEE/ACM Transactions on Computational Biology and\n  Bioinformatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-Computer Interface (BCI) is a powerful communication tool between users\nand systems, which enhances the capability of the human brain in communicating\nand interacting with the environment directly. Advances in neuroscience and\ncomputer science in the past decades have led to exciting developments in BCI,\nthereby making BCI a top interdisciplinary research area in computational\nneuroscience and intelligence. Recent technological advances such as wearable\nsensing devices, real-time data streaming, machine learning, and deep learning\napproaches have increased interest in electroencephalographic (EEG) based BCI\nfor translational and healthcare applications. Many people benefit from\nEEG-based BCIs, which facilitate continuous monitoring of fluctuations in\ncognitive states under monotonous tasks in the workplace or at home. In this\nstudy, we survey the recent literature of EEG signal sensing technologies and\ncomputational intelligence approaches in BCI applications, compensated for the\ngaps in the systematic summary of the past five years (2015-2019). In specific,\nwe first review the current status of BCI and its significant obstacles. Then,\nwe present advanced signal sensing and enhancement technologies to collect and\nclean EEG signals, respectively. Furthermore, we demonstrate state-of-art\ncomputational intelligence techniques, including interpretable fuzzy models,\ntransfer learning, deep learning, and combinations, to monitor, maintain, or\ntrack human cognitive states and operating performance in prevalent\napplications. Finally, we deliver a couple of innovative BCI-inspired\nhealthcare applications and discuss some future research directions in\nEEG-based BCIs.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 10:36:26 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Gu", "Xiaotong", ""], ["Cao", "Zehong", ""], ["Jolfaei", "Alireza", ""], ["Xu", "Peng", ""], ["Wu", "Dongrui", ""], ["Jung", "Tzyy-Ping", ""], ["Lin", "Chin-Teng", ""]]}, {"id": "2001.11349", "submitter": "Ioannis Papantonis", "authors": "Ioannis Papantonis, Vaishak Belle", "title": "On Constraint Definability in Tractable Probabilistic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating constraints is a major concern in probabilistic machine\nlearning. A wide variety of problems require predictions to be integrated with\nreasoning about constraints, from modelling routes on maps to approving loan\npredictions. In the former, we may require the prediction model to respect the\npresence of physical paths between the nodes on the map, and in the latter, we\nmay require that the prediction model respect fairness constraints that ensure\nthat outcomes are not subject to bias. Broadly speaking, constraints may be\nprobabilistic, logical or causal, but the overarching challenge is to determine\nif and how a model can be learnt that handles all the declared constraints. To\nthe best of our knowledge, this is largely an open problem. In this paper, we\nconsider a mathematical inquiry on how the learning of tractable probabilistic\nmodels, such as sum-product networks, is possible while incorporating\nconstraints.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 16:05:56 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Papantonis", "Ioannis", ""], ["Belle", "Vaishak", ""]]}, {"id": "2001.11366", "submitter": "Anna Bosman", "authors": "Mamuku Mokuwe, Michael Burke, Anna Sergeevna Bosman", "title": "Black-Box Saliency Map Generation Using Bayesian Optimisation", "comments": "Submitted to IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saliency maps are often used in computer vision to provide intuitive\ninterpretations of what input regions a model has used to produce a specific\nprediction. A number of approaches to saliency map generation are available,\nbut most require access to model parameters. This work proposes an approach for\nsaliency map generation for black-box models, where no access to model\nparameters is available, using a Bayesian optimisation sampling method. The\napproach aims to find the global salient image region responsible for a\nparticular (black-box) model's prediction. This is achieved by a sampling-based\napproach to model perturbations that seeks to localise salient regions of an\nimage to the black-box model. Results show that the proposed approach to\nsaliency map generation outperforms grid-based perturbation approaches, and\nperforms similarly to gradient-based approaches which require access to model\nparameters.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 14:39:12 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Mokuwe", "Mamuku", ""], ["Burke", "Michael", ""], ["Bosman", "Anna Sergeevna", ""]]}, {"id": "2001.11384", "submitter": "Siddharth Yadav", "authors": "Siddharth Yadav, Tanmoy Chakraborty", "title": "Unsupervised Sentiment Analysis for Code-mixed Data", "comments": null, "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence 2021\n  vol. 35, no. 18, pp. 15941-15942,", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code-mixing is the practice of alternating between two or more languages.\nMostly observed in multilingual societies, its occurrence is increasing and\ntherefore its importance. A major part of sentiment analysis research has been\nmonolingual, and most of them perform poorly on code-mixed text. In this work,\nwe introduce methods that use different kinds of multilingual and cross-lingual\nembeddings to efficiently transfer knowledge from monolingual text to\ncode-mixed text for sentiment analysis of code-mixed text. Our methods can\nhandle code-mixed text through a zero-shot learning. Our methods beat\nstate-of-the-art on English-Spanish code-mixed sentiment analysis by absolute\n3\\% F1-score. We are able to achieve 0.58 F1-score (without parallel corpus)\nand 0.62 F1-score (with parallel corpus) on the same benchmark in a zero-shot\nway as compared to 0.68 F1-score in supervised settings. Our code is publicly\navailable.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 06:12:12 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Yadav", "Siddharth", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "2001.11390", "submitter": "Thomas Chaboud", "authors": "Thomas Chaboud, C\\'edric Pralet, Nicolas Schmidt", "title": "Tackling Air Traffic Conflicts as a Weighted CSP : Experiments with the\n  Lumberjack Method", "comments": "Keywords: Constraints Programming, ATC, graph algorithms, clique\n  searching. 15 pages, 6 figures, 2 tables. Creative Commons\n  Attribution-Noncommercial-ShareAlike license (CC BY-NC-SA 4.0)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present an extension to an air traffic conflicts resolution\nmethod consisting in generating a large number of trajectories for a set of\naircraft, and efficiently selecting the best compatible ones. We propose a\nmultimanoeuvre version which encapsulates different conflict-solving\nalgorithms, in particular an original \"smart brute-force\" method and the\nwell-known ToulBar2 CSP toolset. Experiments on several benchmarks show that\nthe first one is very efficient on cases involving few aircraft (representative\nof what actually happens in operations), allowing us to search through a large\npool of manoeuvres and trajectories; however, this method is overtaken by its\ncomplexity when the number of aircraft increases to 7 and more. Conversely,\nwithin acceptable times, the ToulBar2 toolset can handle conflicts involving\nmore aircraft, but with fewer possible trajectories for each.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 15:22:45 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Chaboud", "Thomas", ""], ["Pralet", "C\u00e9dric", ""], ["Schmidt", "Nicolas", ""]]}, {"id": "2001.11457", "submitter": "Alejandro Su\\'arez Hern\\'andez", "authors": "Alejandro Su\\'arez-Hern\\'andez and Javier Segovia-Aguas and Carme\n  Torras and Guillem Aleny\\`a", "title": "STRIPS Action Discovery", "comments": "Presented to Genplan 2020 workshop, held in the AAAI 2020 conference\n  (https://sites.google.com/view/genplan20) (2021/03/05: included missing\n  acknowledgments)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of specifying high-level knowledge bases for planning becomes a\nhard task in realistic environments. This knowledge is usually handcrafted and\nis hard to keep updated, even for system experts. Recent approaches have shown\nthe success of classical planning at synthesizing action models even when all\nintermediate states are missing. These approaches can synthesize action schemas\nin Planning Domain Definition Language (PDDL) from a set of execution traces\neach consisting, at least, of an initial and final state. In this paper, we\npropose a new algorithm to unsupervisedly synthesize STRIPS action models with\na classical planner when action signatures are unknown. In addition, we\ncontribute with a compilation to classical planning that mitigates the problem\nof learning static predicates in the action model preconditions, exploits the\ncapabilities of SAT planners with parallel encodings to compute action schemas\nand validate all instances. Our system is flexible in that it supports the\ninclusion of partial input information that may speed up the search. We show\nthrough several experiments how learned action models generalize over unseen\nplanning instances.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 17:08:39 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 10:57:37 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 10:37:52 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Su\u00e1rez-Hern\u00e1ndez", "Alejandro", ""], ["Segovia-Aguas", "Javier", ""], ["Torras", "Carme", ""], ["Aleny\u00e0", "Guillem", ""]]}, {"id": "2001.11466", "submitter": "Laura Maria Palomino Marino", "authors": "Agust\\'in Alejandro Ortiz-D\\'iaz, Fabiano Baldo, Laura Mar\\'ia\n  Palomino Mari\\~no and Alberto Verdecia Cabrera", "title": "Fase-AL -- Adaptation of Fast Adaptive Stacking of Ensembles for\n  Supporting Active Learning", "comments": "10 pages, 6 figures", "journal-ref": "AIRCC, Volume 10, Number 01, January 2020. 7th International\n  Conference on Computer Science and Information Technology (CoSIT 2020). ISBN\n  : 978-1-925953-15-2", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification algorithms to mine data stream have been extensively studied\nin recent years. However, a lot of these algorithms are designed for supervised\nlearning which requires labeled instances. Nevertheless, the labeling of the\ndata is costly and time-consuming. Because of this, alternative learning\nparadigms have been proposed to reduce the cost of the labeling process without\nsignificant loss of model performance. Active learning is one of these\nparadigms, whose main objective is to build classification models that request\nthe lowest possible number of labeled examples achieving adequate levels of\naccuracy. Therefore, this work presents the FASE-AL algorithm which induces\nclassification models with non-labeled instances using Active Learning. FASE-AL\nis based on the algorithm Fast Adaptive Stacking of Ensembles (FASE). FASE is\nan ensemble algorithm that detects and adapts the model when the input data\nstream has concept drift. FASE-AL was compared with four different strategies\nof active learning found in the literature. Real and synthetic databases were\nused in the experiments. The algorithm achieves promising results in terms of\nthe percentage of correctly classified instances.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 17:25:47 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Ortiz-D\u00edaz", "Agust\u00edn Alejandro", ""], ["Baldo", "Fabiano", ""], ["Mari\u00f1o", "Laura Mar\u00eda Palomino", ""], ["Cabrera", "Alberto Verdecia", ""]]}, {"id": "2001.11507", "submitter": "Erwin de Gelder", "authors": "E. de Gelder, J.-P. Paardekooper, A. Khabbaz Saberi, H. Elrofai, O. Op\n  den Camp., J. Ploeg, L. Friedmann, B. De Schutter", "title": "Ontology for Scenarios for the Assessment of Automated Vehicles", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of assessment methods for the performance of Automated\nVehicles (AVs) is essential to enable and speed up the deployment of automated\ndriving technologies, due to the complex operational domain of AVs. As\ntraditional methods for assessing vehicles are not applicable for AVs, other\napproaches have been proposed. Among these, real-world scenario-based\nassessment is widely supported by many players in the automotive field. In this\napproach, test cases are derived from real-world scenarios that are obtained\nfrom driving data.\n  To minimize any ambiguity regarding these test cases and scenarios, a clear\ndefinition of the notion of scenario is required. In this paper, we propose a\nmore concrete definition of scenario, compared to what is known to the authors\nfrom the literature. This is achieved by proposing an ontology in which the\nquantitative building blocks of a scenario are defined. An example illustrates\nthat the presented ontology is applicable for scenario-based assessment of AVs.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 08:14:26 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 07:30:29 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 12:40:49 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["de Gelder", "E.", ""], ["Paardekooper", "J. -P.", ""], ["Saberi", "A. Khabbaz", ""], ["Elrofai", "H.", ""], ["Camp.", "O. Op den", ""], ["Ploeg", "J.", ""], ["Friedmann", "L.", ""], ["De Schutter", "B.", ""]]}, {"id": "2001.11590", "submitter": "Thanh Pham Dinh", "authors": "Pham Dinh Thanh, Huynh Thi Thanh Binh, Bui Thu Lam", "title": "New mechanism of combination crossover operators in genetic algorithm\n  for solving the traveling salesman problem", "comments": "The final publication is available at link.springer.com", "journal-ref": null, "doi": "10.1007/978-3-319-11680-8_29", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traveling salesman problem (TSP) is a well-known in computing field. There\nare many researches to improve the genetic algorithm for solving TSP. In this\npaper, we propose two new crossover operators and new mechanism of combination\ncrossover operators in genetic algorithm for solving TSP. We experimented on\nTSP instances from TSP-Lib and compared the results of proposed algorithm with\ngenetic algorithm (GA), which used MSCX. Experimental results show that, our\nproposed algorithm is better than the GA using MSCX on the min, mean cost\nvalues.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 13:20:44 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Thanh", "Pham Dinh", ""], ["Binh", "Huynh Thi Thanh", ""], ["Lam", "Bui Thu", ""]]}, {"id": "2001.11591", "submitter": "Ivan Reinaldo Meneghini", "authors": "Ivan Reinaldo Meneghini, Marcos Antonio Alves, Ant\\'onio Gaspar-Cunha,\n  Frederico Gadelha Guimar\\~aes", "title": "Scalable and Customizable Benchmark Problems for Many-Objective\n  Optimization", "comments": "24 pages, 23 figures, to be published in Applied Soft computing", "journal-ref": "Applied Soft Computing, Volume 90, 2020, 106139", "doi": "10.1016/j.asoc.2020.106139", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Solving many-objective problems (MaOPs) is still a significant challenge in\nthe multi-objective optimization (MOO) field. One way to measure algorithm\nperformance is through the use of benchmark functions (also called test\nfunctions or test suites), which are artificial problems with a well-defined\nmathematical formulation, known solutions and a variety of features and\ndifficulties. In this paper we propose a parameterized generator of scalable\nand customizable benchmark problems for MaOPs. It is able to generate problems\nthat reproduce features present in other benchmarks and also problems with some\nnew features. We propose here the concept of generative benchmarking, in which\none can generate an infinite number of MOO problems, by varying parameters that\ncontrol specific features that the problem should have: scalability in the\nnumber of variables and objectives, bias, deceptiveness, multimodality, robust\nand non-robust solutions, shape of the Pareto front, and constraints. The\nproposed Generalized Position-Distance (GPD) tunable benchmark generator uses\nthe position-distance paradigm, a basic approach to building test functions,\nused in other benchmarks such as Deb, Thiele, Laumanns and Zitzler (DTLZ),\nWalking Fish Group (WFG) and others. It includes scalable problems in any\nnumber of variables and objectives and it presents Pareto fronts with different\ncharacteristics. The resulting functions are easy to understand and visualize,\neasy to implement, fast to compute and their Pareto optimal solutions are\nknown.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 12:39:51 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 12:49:59 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Meneghini", "Ivan Reinaldo", ""], ["Alves", "Marcos Antonio", ""], ["Gaspar-Cunha", "Ant\u00f3nio", ""], ["Guimar\u00e3es", "Frederico Gadelha", ""]]}, {"id": "2001.11628", "submitter": "Ryo Okumura", "authors": "Ryo Okumura, Masashi Okada and Tadahiro Taniguchi", "title": "Domain-Adversarial and Conditional State Space Model for Imitation\n  Learning", "comments": "Published at IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State representation learning (SRL) in partially observable Markov decision\nprocesses has been studied to learn abstract features of data useful for robot\ncontrol tasks. For SRL, acquiring domain-agnostic states is essential for\nachieving efficient imitation learning. Without these states, imitation\nlearning is hampered by domain-dependent information useless for control.\nHowever, existing methods fail to remove such disturbances from the states when\nthe data from experts and agents show large domain shifts. To overcome this\nissue, we propose a domain-adversarial and conditional state space model\n(DAC-SSM) that enables control systems to obtain domain-agnostic and task- and\ndynamics-aware states. DAC-SSM jointly optimizes the state inference,\nobservation reconstruction, forward dynamics, and reward models. To remove\ndomain-dependent information from the states, the model is trained with domain\ndiscriminators in an adversarial manner, and the reconstruction is conditioned\non domain labels. We experimentally evaluated the model predictive control\nperformance via imitation learning for continuous control of sparse reward\ntasks in simulators and compared it with the performance of the existing SRL\nmethod. The agents from DAC-SSM achieved performance comparable to experts and\nmore than twice the baselines. We conclude domain-agnostic states are essential\nfor imitation learning that has large domain shifts and can be obtained using\nDAC-SSM.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 01:39:19 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 06:51:25 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Okumura", "Ryo", ""], ["Okada", "Masashi", ""], ["Taniguchi", "Tadahiro", ""]]}, {"id": "2001.11673", "submitter": "Mehrdad Alizadeh", "authors": "Mehrdad Alizadeh, Barbara Di Eugenio", "title": "Augmenting Visual Question Answering with Semantic Frame Information in\n  a Multitask Learning Approach", "comments": "14th IEEE International Conference on SEMANTIC COMPUTING, 8 Pages,\n  February 2020, San Diego CA USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Visual Question Answering (VQA) concerns providing answers to Natural\nLanguage questions about images. Several deep neural network approaches have\nbeen proposed to model the task in an end-to-end fashion. Whereas the task is\ngrounded in visual processing, if the question focuses on events described by\nverbs, the language understanding component becomes crucial. Our hypothesis is\nthat models should be aware of verb semantics, as expressed via semantic role\nlabels, argument types, and/or frame elements. Unfortunately, no VQA dataset\nexists that includes verb semantic information. Our first contribution is a new\nVQA dataset (imSituVQA) that we built by taking advantage of the imSitu\nannotations. The imSitu dataset consists of images manually labeled with\nsemantic frame elements, mostly taken from FrameNet. Second, we propose a\nmultitask CNN-LSTM VQA model that learns to classify the answers as well as the\nsemantic frame elements. Our experiments show that semantic frame element\nclassification helps the VQA system avoid inconsistent responses and improves\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 06:31:39 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Alizadeh", "Mehrdad", ""], ["Di Eugenio", "Barbara", ""]]}, {"id": "2001.11695", "submitter": "Andrea Piazzoni", "authors": "Andrea Piazzoni, Jim Cherian, Martin Slavik, Justin Dauwels", "title": "Modeling Sensing and Perception Errors towards Robust Decision Making in\n  Autonomous Vehicles", "comments": "11 pages, 8 figures. Preprint of an article submitted to IJCAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensing and Perception (S&P) is a crucial component of an autonomous system\n(such as a robot), especially when deployed in highly dynamic environments\nwhere it is required to react to unexpected situations. This is particularly\ntrue in case of Autonomous Vehicles (AVs) driving on public roads. However, the\ncurrent evaluation metrics for perception algorithms are typically designed to\nmeasure their accuracy per se and do not account for their impact on the\ndecision making subsystem(s). This limitation does not help developers and\nthird party evaluators to answer a critical question: is the performance of a\nperception subsystem sufficient for the decision making subsystem to make\nrobust, safe decisions? In this paper, we propose a simulation-based\nmethodology towards answering this question. At the same time, we show how to\nanalyze the impact of different kinds of sensing and perception errors on the\nbehavior of the autonomous system.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 08:02:14 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Piazzoni", "Andrea", ""], ["Cherian", "Jim", ""], ["Slavik", "Martin", ""], ["Dauwels", "Justin", ""]]}, {"id": "2001.11757", "submitter": "Giorgio Visani Mr", "authors": "Giorgio Visani, Enrico Bagli, Federico Chesani, Alessandro Poluzzi and\n  Davide Capuzzo", "title": "Statistical stability indices for LIME: obtaining reliable explanations\n  for Machine Learning models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays we are witnessing a transformation of the business processes towards\na more computation driven approach. The ever increasing usage of Machine\nLearning techniques is the clearest example of such trend.\n  This sort of revolution is often providing advantages, such as an increase in\nprediction accuracy and a reduced time to obtain the results. However, these\nmethods present a major drawback: it is very difficult to understand on what\ngrounds the algorithm took the decision.\n  To address this issue we consider the LIME method. We give a general\nbackground on LIME then, we focus on the stability issue: employing the method\nrepeated times, under the same conditions, may yield to different explanations.\n  Two complementary indices are proposed, to measure LIME stability. It is\nimportant for the practitioner to be aware of the issue, as well as to have a\ntool for spotting it. Stability guarantees LIME explanations to be reliable,\ntherefore a stability assessment, made through the proposed indices, is\ncrucial.\n  As a case study, we apply both Machine Learning and classical statistical\ntechniques to Credit Risk data. We test LIME on the Machine Learning algorithm\nand check its stability. Eventually, we examine the goodness of the\nexplanations returned.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 10:39:46 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 09:30:09 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Visani", "Giorgio", ""], ["Bagli", "Enrico", ""], ["Chesani", "Federico", ""], ["Poluzzi", "Alessandro", ""], ["Capuzzo", "Davide", ""]]}, {"id": "2001.11777", "submitter": "Lionel Robert", "authors": "Lionel P. Robert, Rasha Alahmad, Connor Esterwood, Sangmi Kim,\n  Sangseok You, Qiaoning Zhang", "title": "A Review of Personality in Human Robot Interactions", "comments": "70 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personality has been identified as a vital factor in understanding the\nquality of human robot interactions. Despite this the research in this area\nremains fragmented and lacks a coherent framework. This makes it difficult to\nunderstand what we know and identify what we do not. As a result our knowledge\nof personality in human robot interactions has not kept pace with the\ndeployment of robots in organizations or in our broader society. To address\nthis shortcoming, this paper reviews 83 articles and 84 separate studies to\nassess the current state of human robot personality research. This review: (1)\nhighlights major thematic research areas, (2) identifies gaps in the\nliterature, (3) derives and presents major conclusions from the literature and\n(4) offers guidance for future research.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 11:28:37 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 21:57:37 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Robert", "Lionel P.", ""], ["Alahmad", "Rasha", ""], ["Esterwood", "Connor", ""], ["Kim", "Sangmi", ""], ["You", "Sangseok", ""], ["Zhang", "Qiaoning", ""]]}, {"id": "2001.11785", "submitter": "Pallavi Bagga", "authors": "Pallavi Bagga, Nicola Paoletti, Bedour Alrayes, Kostas Stathis", "title": "A Deep Reinforcement Learning Approach to Concurrent Bilateral\n  Negotiation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel negotiation model that allows an agent to learn how to\nnegotiate during concurrent bilateral negotiations in unknown and dynamic\ne-markets. The agent uses an actor-critic architecture with model-free\nreinforcement learning to learn a strategy expressed as a deep neural network.\nWe pre-train the strategy by supervision from synthetic market data, thereby\ndecreasing the exploration time required for learning during negotiation. As a\nresult, we can build automated agents for concurrent negotiations that can\nadapt to different e-market settings without the need to be pre-programmed. Our\nexperimental evaluation shows that our deep reinforcement learning-based agents\noutperform two existing well-known negotiation strategies in one-to-many\nconcurrent bilateral negotiations for a range of e-market settings.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 12:05:46 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 13:42:44 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Bagga", "Pallavi", ""], ["Paoletti", "Nicola", ""], ["Alrayes", "Bedour", ""], ["Stathis", "Kostas", ""]]}, {"id": "2001.11797", "submitter": "Kenny Schlegel", "authors": "Kenny Schlegel, Peer Neubert, Peter Protzel", "title": "A comparison of Vector Symbolic Architectures", "comments": "14 pages, 10 figures, preprint - manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector Symbolic Architectures combine a high-dimensional vector space with a\nset of carefully designed operators in order to perform symbolic computations\nwith large numerical vectors. Major goals are the exploitation of their\nrepresentational power and ability to deal with fuzziness and ambiguity. Over\nthe past years, several VSA implementations have been proposed. The available\nimplementations differ in the underlying vector space and the particular\nimplementations of the required VSA operators - with important ramifications\nfor the properties of these architectures. For example, not every VSA is\nequally well suited to address each task, including complete incompatibility.\nThis paper provides an overview of eleven available VSA implementations and\ndiscusses their commonalities and differences in the underlying vector space,\nbundling, and binding/unbinding operations. We create a taxonomy of available\nbinding/unbinding operations and show an important ramification for non\nself-inverse binding operations using an example from analogical reasoning. A\nmain contribution is the experimental comparison of the available\nimplementations in order to evaluate (1) the capacity of bundles, (2) the\napproximation quality of non-exact unbinding operations, (3) the influence of\ncombining binding and bundling operations on the query answering performance,\nand (4) the performance on two example applications: visual place and language\nrecognition. An overall good performance is shown by the HRR VSA in the\nfrequency domain. However, its non-self-inverse binding mechanism can\nnegatively influence its applicability, e.g. to analogical reasoning. We expect\nthis systematization and comparison to be relevant for development and\nevaluation of new VSAs, but most importantly, to support the selection of an\nappropriate VSA for a particular task. The implementations are available in\nform of a MATLAB toolbox.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 12:42:38 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 07:49:13 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 18:05:22 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Schlegel", "Kenny", ""], ["Neubert", "Peer", ""], ["Protzel", "Peter", ""]]}, {"id": "2001.11821", "submitter": "Jean-Philippe Fauvelle", "authors": "Alexandre Dey, Marc Velay, Jean-Philippe Fauvelle, Sylvain Navers", "title": "Adversarial vs behavioural-based defensive AI with joint, continual and\n  active learning: automated evaluation of robustness to deception, poisoning\n  and concept drift", "comments": "in French. European Cyber Week - CESAR/IAD Conference - Artificial\n  Intelligence and Defence, French Ministry of Defence, Nov 2019, Rennes,\n  France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in Artificial Intelligence (AI) have brought new\ncapabilities to behavioural analysis (UEBA) for cyber-security consisting in\nthe detection of hostile action based on the unusual nature of events observed\non the Information System.In our previous work (presented at C\\&ESAR 2018 and\nFIC 2019), we have associated deep neural networks auto-encoders for anomaly\ndetection and graph-based events correlation to address major limitations in\nUEBA systems. This resulted in reduced false positive and false negative rates,\nimproved alert explainability, while maintaining real-time performances and\nscalability. However, we did not address the natural evolution of behaviours\nthrough time, also known as concept drift. To maintain effective detection\ncapabilities, an anomaly-based detection system must be continually trained,\nwhich opens a door to an adversary that can conduct the so-called\n\"frog-boiling\" attack by progressively distilling unnoticed attack traces\ninside the behavioural models until the complete attack is considered normal.\nIn this paper, we present a solution to effectively mitigate this attack by\nimproving the detection process and efficiently leveraging human expertise. We\nalso present preliminary work on adversarial AI conducting deception attack,\nwhich, in term, will be used to help assess and improve the defense system.\nThese defensive and offensive AI implement joint, continual and active\nlearning, in a step that is necessary in assessing, validating and certifying\nAI-based defensive solutions.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 13:54:36 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Dey", "Alexandre", ""], ["Velay", "Marc", ""], ["Fauvelle", "Jean-Philippe", ""], ["Navers", "Sylvain", ""]]}, {"id": "2001.11841", "submitter": "Ozan \\c{C}atal", "authors": "Ozan \\c{C}atal, Tim Verbelen, Johannes Nauta, Cedric De Boom and Bart\n  Dhoedt", "title": "Learning Perception and Planning with Deep Active Inference", "comments": "Accepted on ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Active inference is a process theory of the brain that states that all living\norganisms infer actions in order to minimize their (expected) free energy.\nHowever, current experiments are limited to predefined, often discrete, state\nspaces. In this paper we use recent advances in deep learning to learn the\nstate space and approximate the necessary probability distributions to engage\nin active inference.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 12:27:05 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 12:50:13 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["\u00c7atal", "Ozan", ""], ["Verbelen", "Tim", ""], ["Nauta", "Johannes", ""], ["De Boom", "Cedric", ""], ["Dhoedt", "Bart", ""]]}, {"id": "2001.11850", "submitter": "Yuyu Zhang", "authors": "Yuyu Zhang, Xinshi Chen, Yuan Yang, Arun Ramamurthy, Bo Li, Yuan Qi,\n  Le Song", "title": "Efficient Probabilistic Logic Reasoning with Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Logic Networks (MLNs), which elegantly combine logic rules and\nprobabilistic graphical models, can be used to address many knowledge graph\nproblems. However, inference in MLN is computationally intensive, making the\nindustrial-scale application of MLN very difficult. In recent years, graph\nneural networks (GNNs) have emerged as efficient and effective tools for\nlarge-scale graph problems. Nevertheless, GNNs do not explicitly incorporate\nprior logic rules into the models, and may require many labeled examples for a\ntarget task. In this paper, we explore the combination of MLNs and GNNs, and\nuse graph neural networks for variational inference in MLN. We propose a GNN\nvariant, named ExpressGNN, which strikes a nice balance between the\nrepresentation power and the simplicity of the model. Our extensive experiments\non several benchmark datasets demonstrate that ExpressGNN leads to effective\nand efficient probabilistic logic reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 23:34:36 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 01:10:16 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Zhang", "Yuyu", ""], ["Chen", "Xinshi", ""], ["Yang", "Yuan", ""], ["Ramamurthy", "Arun", ""], ["Li", "Bo", ""], ["Qi", "Yuan", ""], ["Song", "Le", ""]]}, {"id": "2001.11905", "submitter": "Laurens Devos", "authors": "Laurens Devos, Wannes Meert, Jesse Davis", "title": "Verifying Tree Ensembles by Reasoning about Potential Instances", "comments": "Devos, Laurens, Wannes Meert, and Jesse Davis. \"Verifying tree\n  ensembles by reasoning about potential instances.\" Proceedings of the 2021\n  SIAM International Conference on Data Mining (SDM). Society for Industrial\n  and Applied Mathematics, 2021", "journal-ref": null, "doi": "10.1137/1.9781611976700.51", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imagine being able to ask questions to a black box model such as \"Which\nadversarial examples exist?\", \"Does a specific attribute have a\ndisproportionate effect on the model's prediction?\" or \"What kind of\npredictions could possibly be made for a partially described example?\" This\nlast question is particularly important if your partial description does not\ncorrespond to any observed example in your data, as it provides insight into\nhow the model will extrapolate to unseen data. These capabilities would be\nextremely helpful as they would allow a user to better understand the model's\nbehavior, particularly as it relates to issues such as robustness, fairness,\nand bias. In this paper, we propose such an approach for an ensemble of trees.\nSince, in general, this task is intractable we present a strategy that (1) can\nprune part of the input space given the question asked to simplify the problem;\nand (2) follows a divide and conquer approach that is incremental and can\nalways return some answers and indicates which parts of the input domains are\nstill uncertain. The usefulness of our approach is shown on a diverse set of\nuse cases.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 15:31:23 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 13:45:19 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 12:54:32 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Devos", "Laurens", ""], ["Meert", "Wannes", ""], ["Davis", "Jesse", ""]]}, {"id": "2001.11958", "submitter": "Xiao Liu", "authors": "Xiao Liu, Mingzhe Chen, Yuanwei Liu, Yue Chen, Shuguang Cui, and Lajos\n  Hanzo", "title": "Artificial Intelligence Aided Next-Generation Networks Relying on UAVs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) assisted unmanned aerial vehicle (UAV) aided\nnext-generation networking is proposed for dynamic environments. In the\nAI-enabled UAV-aided wireless networks (UAWN), multiple UAVs are employed as\naerial base stations, which are capable of rapidly adapting to the dynamic\nenvironment by collecting information about the users' position and\ntele-traffic demands, learning from the environment and acting upon the\nfeedback received from the users. Moreover, AI enables the interaction amongst\na swarm of UAVs for cooperative optimization of the system. As a benefit of the\nAI framework, several challenges of conventional UAWN may be circumvented,\nleading to enhanced network performance, improved reliability and agile\nadaptivity. As a further benefit, dynamic trajectory design and resource\nallocation are demonstrated. Finally, potential research challenges and\nopportunities are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 15:10:22 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Liu", "Xiao", ""], ["Chen", "Mingzhe", ""], ["Liu", "Yuanwei", ""], ["Chen", "Yue", ""], ["Cui", "Shuguang", ""], ["Hanzo", "Lajos", ""]]}, {"id": "2001.11985", "submitter": "Denis Lukovnikov", "authors": "D. Lukovnikov, A. Fischer, J. Lehmann", "title": "Pretrained Transformers for Simple Question Answering over Knowledge\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering simple questions over knowledge graphs is a well-studied problem in\nquestion answering. Previous approaches for this task built on recurrent and\nconvolutional neural network based architectures that use pretrained word\nembeddings. It was recently shown that finetuning pretrained transformer\nnetworks (e.g. BERT) can outperform previous approaches on various natural\nlanguage processing tasks. In this work, we investigate how well BERT performs\non SimpleQuestions and provide an evaluation of both BERT and BiLSTM-based\nmodels in datasparse scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:14:17 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Lukovnikov", "D.", ""], ["Fischer", "A.", ""], ["Lehmann", "J.", ""]]}, {"id": "2001.11990", "submitter": "Serena Wang", "authors": "Serena Wang and Maya Gupta", "title": "Deontological Ethics By Monotonicity Shape Constraints", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate how easy it is for modern machine-learned systems to violate\ncommon deontological ethical principles and social norms such as \"favor the\nless fortunate,\" and \"do not penalize good attributes.\" We propose that in some\ncases such ethical principles can be incorporated into a machine-learned model\nby adding shape constraints that constrain the model to respond only positively\nto relevant inputs. We analyze the relationship between these deontological\nconstraints that act on individuals and the consequentialist group-based\nfairness goals of one-sided statistical parity and equal opportunity. This\nstrategy works with sensitive attributes that are Boolean or real-valued such\nas income and age, and can help produce more responsible and trustworthy AI.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:27:27 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 00:20:00 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Wang", "Serena", ""], ["Gupta", "Maya", ""]]}, {"id": "2001.12004", "submitter": "Joseph Suarez", "authors": "Joseph Suarez, Yilun Du, Igor Mordatch, Phillip Isola", "title": "Neural MMO v1.3: A Massively Multiagent Game Environment for Training\n  and Evaluating Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in multiagent intelligence research is fundamentally limited by the\nnumber and quality of environments available for study. In recent years,\nsimulated games have become a dominant research platform within reinforcement\nlearning, in part due to their accessibility and interpretability. Previous\nworks have targeted and demonstrated success on arcade, first person shooter\n(FPS), real-time strategy (RTS), and massive online battle arena (MOBA) games.\nOur work considers massively multiplayer online role-playing games (MMORPGs or\nMMOs), which capture several complexities of real-world learning that are not\nwell modeled by any other game genre. We present Neural MMO, a massively\nmultiagent game environment inspired by MMOs and discuss our progress on two\nmore general challenges in multiagent systems engineering for AI research:\ndistributed infrastructure and game IO. We further demonstrate that standard\npolicy gradient methods and simple baseline models can learn interesting\nemergent exploration and specialization behaviors in this setting.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:50:02 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 01:58:32 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Suarez", "Joseph", ""], ["Du", "Yilun", ""], ["Mordatch", "Igor", ""], ["Isola", "Phillip", ""]]}]