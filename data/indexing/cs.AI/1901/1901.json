[{"id": "1901.00032", "submitter": "Edward Kim", "authors": "Edward Kim, Zach Jensen, Alexander van Grootel, Kevin Huang, Matthew\n  Staib, Sheshera Mysore, Haw-Shiuan Chang, Emma Strubell, Andrew McCallum,\n  Stefanie Jegelka, Elsa Olivetti", "title": "Inorganic Materials Synthesis Planning with Literature-Trained Neural\n  Networks", "comments": "Added new funding support to the acknowledgments section in this\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging new data sources is a key step in accelerating the pace of\nmaterials design and discovery. To complement the strides in synthesis planning\ndriven by historical, experimental, and computed data, we present an automated\nmethod for connecting scientific literature to synthesis insights. Starting\nfrom natural language text, we apply word embeddings from language models,\nwhich are fed into a named entity recognition model, upon which a conditional\nvariational autoencoder is trained to generate syntheses for arbitrary\nmaterials. We show the potential of this technique by predicting precursors for\ntwo perovskite materials, using only training data published over a decade\nprior to their first reported syntheses. We demonstrate that the model learns\nrepresentations of materials corresponding to synthesis-related properties, and\nthat the model's behavior complements existing thermodynamic knowledge.\nFinally, we apply the model to perform synthesizability screening for proposed\nnovel perovskite compounds.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 20:03:01 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 16:35:34 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Kim", "Edward", ""], ["Jensen", "Zach", ""], ["van Grootel", "Alexander", ""], ["Huang", "Kevin", ""], ["Staib", "Matthew", ""], ["Mysore", "Sheshera", ""], ["Chang", "Haw-Shiuan", ""], ["Strubell", "Emma", ""], ["McCallum", "Andrew", ""], ["Jegelka", "Stefanie", ""], ["Olivetti", "Elsa", ""]]}, {"id": "1901.00056", "submitter": "Chenwei Zhang", "authors": "Chenwei Zhang, Yaliang Li, Nan Du, Wei Fan, Philip S. Yu", "title": "Entity Synonym Discovery via Multipiece Bilateral Context Matching", "comments": "In IJCAI 2020 as a long paper. Code and data are available at\n  https://github.com/czhang99/SynonymNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to automatically discover synonymous entities in an open-world\nsetting benefits various tasks such as entity disambiguation or knowledge graph\ncanonicalization. Existing works either only utilize entity features, or rely\non structured annotations from a single piece of context where the entity is\nmentioned. To leverage diverse contexts where entities are mentioned, in this\npaper, we generalize the distributional hypothesis to a multi-context setting\nand propose a synonym discovery framework that detects entity synonyms from\nfree-text corpora with considerations on effectiveness and robustness. As one\nof the key components in synonym discovery, we introduce a neural network model\nSYNONYMNET to determine whether or not two given entities are synonym with each\nother. Instead of using entities features, SYNONYMNET makes use of multiple\npieces of contexts in which the entity is mentioned, and compares the\ncontext-level similarity via a bilateral matching schema. Experimental results\ndemonstrate that the proposed model is able to detect synonym sets that are not\nobserved during training on both generic and domain-specific datasets:\nWiki+Freebase, PubMed+UMLS, and MedBook+MKG, with up to 4.16% improvement in\nterms of Area Under the Curve and 3.19% in terms of Mean Average Precision\ncompared to the best baseline method.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 22:05:05 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 01:01:12 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Zhang", "Chenwei", ""], ["Li", "Yaliang", ""], ["Du", "Nan", ""], ["Fan", "Wei", ""], ["Yu", "Philip S.", ""]]}, {"id": "1901.00064", "submitter": "Peter Eckersley", "authors": "Peter Eckersley", "title": "Impossibility and Uncertainty Theorems in AI Value Alignment (or why\n  your AGI should not have a utility function)", "comments": "Published in SafeAI 2019: Proceedings of the AAAI Workshop on\n  Artificial Intelligence Safety 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Utility functions or their equivalents (value functions, objective functions,\nloss functions, reward functions, preference orderings) are a central tool in\nmost current machine learning systems. These mechanisms for defining goals and\nguiding optimization run into practical and conceptual difficulty when there\nare independent, multi-dimensional objectives that need to be pursued\nsimultaneously and cannot be reduced to each other. Ethicists have proved\nseveral impossibility theorems that stem from this origin; those results appear\nto show that there is no way of formally specifying what it means for an\noutcome to be good for a population without violating strong human ethical\nintuitions (in such cases, the objective function is a social welfare\nfunction). We argue that this is a practical problem for any machine learning\nsystem (such as medical decision support systems or autonomous weapons) or\nrigidly rule-based bureaucracy that will make high stakes decisions about human\nlives: such systems should not use objective functions in the strict\nmathematical sense.\n  We explore the alternative of using uncertain objectives, represented for\ninstance as partially ordered preferences, or as probability distributions over\ntotal orders. We show that previously known impossibility theorems can be\ntransformed into uncertainty theorems in both of those settings, and prove\nlower bounds on how much uncertainty is implied by the impossibility results.\nWe close by proposing two conjectures about the relationship between\nuncertainty in objectives and severe unintended consequences from AI systems.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 23:51:27 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 02:57:13 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 03:12:49 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Eckersley", "Peter", ""]]}, {"id": "1901.00073", "submitter": "EPTCS", "authors": "Bernd Finkbeiner (Saarland University), Samantha Kleinberg (Stevens\n  Institute of Technology)", "title": "Proceedings 3rd Workshop on formal reasoning about Causation,\n  Responsibility, and Explanations in Science and Technology", "comments": null, "journal-ref": "EPTCS 286, 2019", "doi": "10.4204/EPTCS.286", "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CREST 2018 workshop is the third in a series of workshops addressing\nformal approaches to reasoning about causation in systems engineering. The\ntopic of formally identifying the cause(s) of specific events - usually some\nform of failures -, and explaining why they occurred, are increasingly in the\nfocus of several, disjoint communities. The main objective of CREST is to bring\ntogether researchers and practitioners from industry and academia in order to\nenable discussions how explicit and implicit reasoning about causation is\nperformed. A further objective is to link to the foundations of causal\nreasoning in the philosophy of sciences and to causal reasoning performed in\nother areas of computer science, engineering, and beyond.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 01:22:19 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Finkbeiner", "Bernd", "", "Saarland University"], ["Kleinberg", "Samantha", "", "Stevens\n  Institute of Technology"]]}, {"id": "1901.00117", "submitter": "Sai Kiran Narayanaswami", "authors": "Sai Kiran Narayanaswami, Nandan Sudarsanam, Balaraman Ravindran", "title": "An Active Learning Framework for Efficient Robust Policy Search", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust Policy Search is the problem of learning policies that do not degrade\nin performance when subject to unseen environment model parameters. It is\nparticularly relevant for transferring policies learned in a simulation\nenvironment to the real world. Several existing approaches involve sampling\nlarge batches of trajectories which reflect the differences in various possible\nenvironments, and then selecting some subset of these to learn robust policies,\nsuch as the ones that result in the worst performance. We propose an active\nlearning based framework, EffAcTS, to selectively choose model parameters for\nthis purpose so as to collect only as much data as necessary to select such a\nsubset. We apply this framework to an existing method, namely EPOpt, and\nexperimentally validate the gains in sample efficiency and the performance of\nour approach on standard continuous control tasks. We also present a Multi-Task\nLearning perspective to the problem of Robust Policy Search, and draw\nconnections from our proposed framework to existing work on Multi-Task\nLearning.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 08:50:47 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Narayanaswami", "Sai Kiran", ""], ["Sudarsanam", "Nandan", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1901.00158", "submitter": "Wanrong Zhu", "authors": "Wanrong Zhu, Zhiting Hu, Eric Xing", "title": "Text Infilling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen remarkable progress of text generation in different\ncontexts, such as the most common setting of generating text from scratch, and\nthe emerging paradigm of retrieval-and-rewriting. Text infilling, which fills\nmissing text portions of a sentence or paragraph, is also of numerous use in\nreal life, yet is under-explored. Previous work has focused on restricted\nsettings by either assuming single word per missing portion or limiting to a\nsingle missing portion to the end of the text. This paper studies the general\ntask of text infilling, where the input text can have an arbitrary number of\nportions to be filled, each of which may require an arbitrary unknown number of\ntokens. We study various approaches for the task, including a self-attention\nmodel with segment-aware position encoding and bidirectional context modeling.\nWe create extensive supervised data by masking out text with varying\nstrategies. Experiments show the self-attention model greatly outperforms\nothers, creating a strong baseline for future research.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 14:41:17 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 17:55:36 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Zhu", "Wanrong", ""], ["Hu", "Zhiting", ""], ["Xing", "Eric", ""]]}, {"id": "1901.00204", "submitter": "Ramin Hasibi", "authors": "Ramin Hasibi, Matin Shokri, Mehdi Dehghan", "title": "Augmentation Scheme for Dealing with Imbalanced Network Traffic\n  Classification Using Deep Learning", "comments": "Submitted to IFIP Networking 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important tasks in network management is identifying\ndifferent types of traffic flows. As a result, a type of management service,\ncalled Network Traffic Classifier (NTC), has been introduced. One type of NTCs\nthat has gained huge attention in recent years applies deep learning on packets\nin order to classify flows. Internet is an imbalanced environment i.e., some\nclasses of applications are a lot more populated than others e.g., HTTP.\nAdditionally, one of the challenges in deep learning methods is that they do\nnot perform well in imbalanced environments in terms of evaluation metrics such\nas precision, recall, and $\\mathrm{F_1}$ measure. In order to solve this\nproblem, we recommend the use of augmentation methods to balance the dataset.\nIn this paper, we propose a novel data augmentation approach based on the use\nof Long Short Term Memory (LSTM) networks for generating traffic flow patterns\nand Kernel Density Estimation (KDE) for replicating the numerical features of\neach class. First, we use the LSTM network in order to learn and generate the\nsequence of packets in a flow for classes with less population. Then, we\ncomplete the features of the sequence with generating random values based on\nthe distribution of a certain feature, which will be estimated using KDE.\nFinally, we compare the training of a Convolutional Recurrent Neural Network\n(CRNN) in large-scale imbalanced, sampled, and augmented datasets. The\ncontribution of our augmentation scheme is then evaluated on all of the\ndatasets through measurements of precision, recall, and F1 measure for every\nclass of application. The results demonstrate that our scheme is well suited\nfor network traffic flow datasets and improves the performance of deep learning\nalgorithms when it comes to above-mentioned metrics.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 20:02:38 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Hasibi", "Ramin", ""], ["Shokri", "Matin", ""], ["Dehghan", "Mehdi", ""]]}, {"id": "1901.00210", "submitter": "Andrea Zanette", "authors": "Andrea Zanette, Emma Brunskill", "title": "Tighter Problem-Dependent Regret Bounds in Reinforcement Learning\n  without Domain Knowledge using Value Function Bounds", "comments": "Bug fixes", "journal-ref": "International Conference on Machine Learning 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strong worst-case performance bounds for episodic reinforcement learning\nexist but fortunately in practice RL algorithms perform much better than such\nbounds would predict. Algorithms and theory that provide strong\nproblem-dependent bounds could help illuminate the key features of what makes a\nRL problem hard and reduce the barrier to using RL algorithms in practice. As a\nstep towards this we derive an algorithm for finite horizon discrete MDPs and\nassociated analysis that both yields state-of-the art worst-case regret bounds\nin the dominant terms and yields substantially tighter bounds if the RL\nenvironment has small environmental norm, which is a function of the variance\nof the next-state value functions. An important benefit of our algorithmic is\nthat it does not require apriori knowledge of a bound on the environmental\nnorm. As a result of our analysis, we also help address an open learning theory\nquestion~\\cite{jiang2018open} about episodic MDPs with a constant upper-bound\non the sum of rewards, providing a regret bound with no $H$-dependence in the\nleading term that scales a polynomial function of the number of episodes.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 21:17:21 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 06:43:16 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 17:27:39 GMT"}, {"version": "v4", "created": "Fri, 1 Nov 2019 20:35:28 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zanette", "Andrea", ""], ["Brunskill", "Emma", ""]]}, {"id": "1901.00243", "submitter": "Mohammad Kachuee Mr.", "authors": "Mohammad Kachuee, Orpaz Goldstein, Kimmo Karkkainen, Sajad Darabi,\n  Majid Sarrafzadeh", "title": "Opportunistic Learning: Budgeted Cost-Sensitive Learning from Data\n  Streams", "comments": "https://openreview.net/forum?id=S1eOHo09KX", "journal-ref": "International Conference on Learning Representations (ICLR), 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world learning scenarios, features are only acquirable at a cost\nconstrained under a budget. In this paper, we propose a novel approach for\ncost-sensitive feature acquisition at the prediction-time. The suggested method\nacquires features incrementally based on a context-aware feature-value\nfunction. We formulate the problem in the reinforcement learning paradigm, and\nintroduce a reward function based on the utility of each feature. Specifically,\nMC dropout sampling is used to measure expected variations of the model\nuncertainty which is used as a feature-value function. Furthermore, we suggest\nsharing representations between the class predictor and value function\nestimator networks. The suggested approach is completely online and is readily\napplicable to stream learning setups. The solution is evaluated on three\ndifferent datasets including the well-known MNIST dataset as a benchmark as\nwell as two cost-sensitive datasets: Yahoo Learning to Rank and a dataset in\nthe medical domain for diabetes classification. According to the results, the\nproposed method is able to efficiently acquire features and make accurate\npredictions.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 02:33:54 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 02:42:39 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Kachuee", "Mohammad", ""], ["Goldstein", "Orpaz", ""], ["Karkkainen", "Kimmo", ""], ["Darabi", "Sajad", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1901.00246", "submitter": "Christopher Hazard", "authors": "Christopher J. Hazard, Christopher Fusting, Michael Resnick, Michael\n  Auerbach, Michael Meehan, Valeri Korobov", "title": "Natively Interpretable Machine Learning and Artificial Intelligence:\n  Preliminary Results and Future Directions", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have become more and more complex in order to better\napproximate complex functions. Although fruitful in many domains, the added\ncomplexity has come at the cost of model interpretability. The once popular\nk-nearest neighbors (kNN) approach, which finds and uses the most similar data\nfor reasoning, has received much less attention in recent decades due to\nnumerous problems when compared to other techniques. We show that many of these\nhistorical problems with kNN can be overcome, and our contribution has\napplications not only in machine learning but also in online learning, data\nsynthesis, anomaly detection, model compression, and reinforcement learning,\nwithout sacrificing interpretability. We introduce a synthesis between kNN and\ninformation theory that we hope will provide a clear path towards models that\nare innately interpretable and auditable. Through this work we hope to gather\ninterest in combining kNN with information theory as a promising path to fully\nauditable machine learning and artificial intelligence.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 03:00:21 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 16:35:42 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Hazard", "Christopher J.", ""], ["Fusting", "Christopher", ""], ["Resnick", "Michael", ""], ["Auerbach", "Michael", ""], ["Meehan", "Michael", ""], ["Korobov", "Valeri", ""]]}, {"id": "1901.00270", "submitter": "Luckeciano Melo", "authors": "Luckeciano Carvalho Melo, Marcos Ricardo Omena Albuquerque Maximo, and\n  Adilson Marques da Cunha", "title": "Learning Humanoid Robot Motions Through Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controlling a high degrees of freedom humanoid robot is acknowledged as one\nof the hardest problems in Robotics. Due to the lack of mathematical models, an\napproach frequently employed is to rely on human intuition to design keyframe\nmovements by hand, usually aided by graphical tools. In this paper, we propose\na learning framework based on neural networks in order to mimic humanoid robot\nmovements. The developed technique does not make any assumption about the\nunderlying implementation of the movement, therefore both keyframe and\nmodel-based motions may be learned. The framework was applied in the RoboCup 3D\nSoccer Simulation domain and promising results were obtained using the same\nnetwork architecture for several motions, even when copying motions from\nanother teams.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 05:46:52 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Melo", "Luckeciano Carvalho", ""], ["Maximo", "Marcos Ricardo Omena Albuquerque", ""], ["da Cunha", "Adilson Marques", ""]]}, {"id": "1901.00295", "submitter": "Xingjian Du", "authors": "Xingjian Du, Mengyao Zhu, Xuan Shi, Xinpeng Zhang, Wen Zhang, Jingdong\n  Chen", "title": "End-to-End Model for Speech Enhancement by Consistent Spectrogram\n  Masking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, phase processing is attracting increasinginterest in speech\nenhancement community. Some researchersintegrate phase estimations module into\nspeech enhancementmodels by using complex-valued short-time Fourier\ntransform(STFT) spectrogram based training targets, e.g. Complex RatioMask\n(cRM) [1]. However, masking on spectrogram would violentits consistency\nconstraints. In this work, we prove that theinconsistent problem enlarges the\nsolution space of the speechenhancement model and causes unintended artifacts.\nConsistencySpectrogram Masking (CSM) is proposed to estimate the\ncomplexspectrogram of a signal with the consistency constraint in asimple but\nnot trivial way. The experiments comparing ourCSM based end-to-end model with\nother methods are conductedto confirm that the CSM accelerate the model\ntraining andhave significant improvements in speech quality. From\nourexperimental results, we assured that our method could enha\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 08:39:05 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Du", "Xingjian", ""], ["Zhu", "Mengyao", ""], ["Shi", "Xuan", ""], ["Zhang", "Xinpeng", ""], ["Zhang", "Wen", ""], ["Chen", "Jingdong", ""]]}, {"id": "1901.00298", "submitter": "Han Yu", "authors": "Han Yu, Chunyan Miao, Yongqing Zheng, Lizhen Cui, Simon Fauvel and\n  Cyril Leung", "title": "Ethically Aligned Opportunistic Scheduling for Productive Laziness", "comments": null, "journal-ref": "Proceedings of the 2nd AAAI/ACM Conference on Artificial\n  Intelligence, Ethics, and Society (AIES-19), 2019", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In artificial intelligence (AI) mediated workforce management systems (e.g.,\ncrowdsourcing), long-term success depends on workers accomplishing tasks\nproductively and resting well. This dual objective can be summarized by the\nconcept of productive laziness. Existing scheduling approaches mostly focus on\nefficiency but overlook worker wellbeing through proper rest. In order to\nenable workforce management systems to follow the IEEE Ethically Aligned Design\nguidelines to prioritize worker wellbeing, we propose a distributed\nComputational Productive Laziness (CPL) approach in this paper. It\nintelligently recommends personalized work-rest schedules based on local data\nconcerning a worker's capabilities and situational factors to incorporate\nopportunistic resting and achieve superlinear collective productivity without\nthe need for explicit coordination messages. Extensive experiments based on a\nreal-world dataset of over 5,000 workers demonstrate that CPL enables workers\nto spend 70% of the effort to complete 90% of the tasks on average, providing\nmore ethically aligned scheduling than existing approaches.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 09:01:07 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Yu", "Han", ""], ["Miao", "Chunyan", ""], ["Zheng", "Yongqing", ""], ["Cui", "Lizhen", ""], ["Fauvel", "Simon", ""], ["Leung", "Cyril", ""]]}, {"id": "1901.00365", "submitter": "Karl Schlechta", "authors": "Karl Schlechta", "title": "KI, Philosophie, Logik", "comments": "in German", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a short (and personal) introduction in German to the connections\nbetween artificial intelligence, philosophy, and logic, and to the author's\nwork.\n  Dies ist eine kurze (und persoenliche) Einfuehrung in die Zusammenhaenge\nzwischen Kuenstlicher Intelligenz, Philosophie, und Logik, und in die Arbeiten\ndes Autors.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 10:29:47 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Schlechta", "Karl", ""]]}, {"id": "1901.00433", "submitter": "Patrick Forr\\'e", "authors": "Patrick Forr\\'e, Joris M. Mooij", "title": "Causal Calculus in the Presence of Cycles, Latent Confounders and\n  Selection Bias", "comments": "Accepted for publication in Conference on Uncertainty in Artificial\n  Intelligence 2019 (UAI-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the main rules of causal calculus (also called do-calculus) for i/o\nstructural causal models (ioSCMs), a generalization of a recently proposed\ngeneral class of non-/linear structural causal models that allow for cycles,\nlatent confounders and arbitrary probability distributions. We also generalize\nadjustment criteria and formulas from the acyclic setting to the general one\n(i.e. ioSCMs). Such criteria then allow to estimate (conditional) causal\neffects from observational data that was (partially) gathered under selection\nbias and cycles. This generalizes the backdoor criterion, the\nselection-backdoor criterion and extensions of these to arbitrary ioSCMs.\nTogether, our results thus enable causal reasoning in the presence of cycles,\nlatent confounders and selection bias. Finally, we extend the ID algorithm for\nthe identification of causal effects to ioSCMs.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 15:58:49 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 16:38:18 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Forr\u00e9", "Patrick", ""], ["Mooij", "Joris M.", ""]]}, {"id": "1901.00444", "submitter": "Prasad Bhavana Mr", "authors": "Prasad G Bhavana, Vineet C Nair", "title": "BMF: Block matrix approach to factorization of large scale data", "comments": "Disagreement on success criteria of the method with my guide", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix Factorization (MF) on large scale matrices is computationally as well\nas memory intensive task. Alternative convergence techniques are needed when\nthe size of the input matrix is higher than the available memory on a Central\nProcessing Unit (CPU) and Graphical Processing Unit (GPU). While alternating\nleast squares (ALS) convergence on CPU could take forever, loading all the\nrequired matrices on to GPU memory may not be possible when the dimensions are\nsignificantly higher. Hence we introduce a novel technique that is based on\nconsidering the entire data into a block matrix and relies on factorization at\na block level.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 16:25:54 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 16:46:17 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Bhavana", "Prasad G", ""], ["Nair", "Vineet C", ""]]}, {"id": "1901.00525", "submitter": "Fathi Salem", "authors": "Daniel Kent and Fathi M.Salem", "title": "Performance of Three Slim Variants of The Long Short-Term Memory (LSTM)\n  Layer", "comments": "4 pages, 2 Tables, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Long Short-Term Memory (LSTM) layer is an important advancement in the\nfield of neural networks and machine learning, allowing for effective training\nand impressive inference performance. LSTM-based neural networks have been\nsuccessfully employed in various applications such as speech processing and\nlanguage translation. The LSTM layer can be simplified by removing certain\ncomponents, potentially speeding up training and runtime with limited change in\nperformance. In particular, the recently introduced variants, called SLIM\nLSTMs, have shown success in initial experiments to support this view. Here, we\nperform computational analysis of the validation accuracy of a convolutional\nplus recurrent neural network architecture using comparatively the standard\nLSTM and three SLIM LSTM layers. We have found that some realizations of the\nSLIM LSTM layers can potentially perform as well as the standard LSTM layer for\nour considered architecture.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 20:28:23 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Kent", "Daniel", ""], ["Salem", "Fathi M.", ""]]}, {"id": "1901.00544", "submitter": "Yen-Chang Hsu", "authors": "Yen-Chang Hsu, Zhaoyang Lv, Joel Schlosser, Phillip Odom, Zsolt Kira", "title": "Multi-class Classification without Multi-class Labels", "comments": "International Conference on Learning Representations (ICLR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a new strategy for multi-class classification that\nrequires no class-specific labels, but instead leverages pairwise similarity\nbetween examples, which is a weaker form of annotation. The proposed method,\nmeta classification learning, optimizes a binary classifier for pairwise\nsimilarity prediction and through this process learns a multi-class classifier\nas a submodule. We formulate this approach, present a probabilistic graphical\nmodel for it, and derive a surprisingly simple loss function that can be used\nto learn neural network-based models. We then demonstrate that this same\nframework generalizes to the supervised, unsupervised cross-task, and\nsemi-supervised settings. Our method is evaluated against state of the art in\nall three learning paradigms and shows a superior or comparable accuracy,\nproviding evidence that learning multi-class classification without multi-class\nlabels is a viable learning option.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 22:09:12 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Hsu", "Yen-Chang", ""], ["Lv", "Zhaoyang", ""], ["Schlosser", "Joel", ""], ["Odom", "Phillip", ""], ["Kira", "Zsolt", ""]]}, {"id": "1901.00553", "submitter": "Antonio Luca Alfeo", "authors": "A.L. Alfeo, F.P. Appio, M.G.C.A. Cimino, A. Lazzeri, A. Martini, G.\n  Vaglini", "title": "An adaptive stigmergy-based system for evaluating technological\n  indicator dynamics in the context of smart specialization", "comments": "mail: luca.alfeo@ing.unipi.it", "journal-ref": "INSTICC The 5th International Conference on Pattern Recognition\n  Applications and Methods (ICPRAM 2016), pp. 497-502, Rome, Italy, 2016", "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Regional innovation is more and more considered an important enabler of\nwelfare. It is no coincidence that the European Commission has started looking\nat regional peculiarities and dynamics, in order to focus Research and\nInnovation Strategies for Smart Specialization towards effective investment\npolicies. In this context, this work aims to support policy makers in the\nanalysis of innovation-relevant trends. We exploit a European database of the\nregional patent application to determine the dynamics of a set of technological\ninnovation indicators. For this purpose, we design and develop a software\nsystem for assessing unfolding trends in such indicators. In contrast with\nconventional knowledge-based design, our approach is biologically-inspired and\nbased on self-organization of information. This means that a functional\nstructure, called track, appears and stays spontaneous at runtime when local\ndynamism in data occurs. A further prototyping of tracks allows a better\ndistinction of the critical phenomena during unfolding events, with a better\nassessment of the progressing levels. The proposed mechanism works if\nstructural parameters are correctly tuned for the given historical context.\nDetermining such correct parameters is not a simple task since different\nindicators may have different dynamics. For this purpose, we adopt an\nadaptation mechanism based on differential evolution. The study includes the\nproblem statement and its characterization in the literature, as well as the\nproposed solving approach, experimental setting and results.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 23:13:52 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Alfeo", "A. L.", ""], ["Appio", "F. P.", ""], ["Cimino", "M. G. C. A.", ""], ["Lazzeri", "A.", ""], ["Martini", "A.", ""], ["Vaglini", "G.", ""]]}, {"id": "1901.00563", "submitter": "Zheng Zhang", "authors": "Jie Wen, Zuofeng Zhong, Zheng Zhang, Lunke Fei, Zhihui Lai, Runze Chen", "title": "Adaptive Locality Preserving Regression", "comments": "The paper has been accepted by IEEE Transactions on Circuits and\n  Systems for Video Technology (TCSVT), and the code can be available at\n  https://drive.google.com/file/d/1iNzONkRByIaUhXwdEhOkkh_0d2AAXNE8/view", "journal-ref": "IEEE Transactions on Circuits and Systems for Video Technology,\n  2018", "doi": "10.1109/TCSVT.2018.2889727", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel discriminative regression method, called adaptive\nlocality preserving regression (ALPR) for classification. In particular, ALPR\naims to learn a more flexible and discriminative projection that not only\npreserves the intrinsic structure of data, but also possesses the properties of\nfeature selection and interpretability. To this end, we introduce a target\nlearning technique to adaptively learn a more discriminative and flexible\ntarget matrix rather than the pre-defined strict zero-one label matrix for\nregression. Then a locality preserving constraint regularized by the adaptive\nlearned weights is further introduced to guide the projection learning, which\nis beneficial to learn a more discriminative projection and avoid overfitting.\nMoreover, we replace the conventional `Frobenius norm' with the special l21\nnorm to constrain the projection, which enables the method to adaptively select\nthe most important features from the original high-dimensional data for feature\nextraction. In this way, the negative influence of the redundant features and\nnoises residing in the original data can be greatly eliminated. Besides, the\nproposed method has good interpretability for features owing to the\nrow-sparsity property of the l21 norm. Extensive experiments conducted on the\nsynthetic database with manifold structure and many real-world databases prove\nthe effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 00:36:23 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Wen", "Jie", ""], ["Zhong", "Zuofeng", ""], ["Zhang", "Zheng", ""], ["Fei", "Lunke", ""], ["Lai", "Zhihui", ""], ["Chen", "Runze", ""]]}, {"id": "1901.00569", "submitter": "Meixin Zhu", "authors": "Meixin Zhu, Xuesong Wang, Yinhai Wang", "title": "Human-Like Autonomous Car-Following Model with Deep Reinforcement\n  Learning", "comments": null, "journal-ref": "Transportation Research Part C: Emerging Technologies 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a framework for human-like autonomous car-following\nplanning based on deep reinforcement learning (deep RL). Historical driving\ndata are fed into a simulation environment where an RL agent learns from trial\nand error interactions based on a reward function that signals how much the\nagent deviates from the empirical data. Through these interactions, an optimal\npolicy, or car-following model that maps in a human-like way from speed,\nrelative speed between a lead and following vehicle, and inter-vehicle spacing\nto acceleration of a following vehicle is finally obtained. The model can be\ncontinuously updated when more data are fed in. Two thousand car-following\nperiods extracted from the 2015 Shanghai Naturalistic Driving Study were used\nto train the model and compare its performance with that of traditional and\nrecent data-driven car-following models. As shown by this study results, a deep\ndeterministic policy gradient car-following model that uses disparity between\nsimulated and observed speed as the reward function and considers a reaction\ndelay of 1s, denoted as DDPGvRT, can reproduce human-like car-following\nbehavior with higher accuracy than traditional and recent data-driven\ncar-following models. Specifically, the DDPGvRT model has a spacing validation\nerror of 18% and speed validation error of 5%, which are less than those of\nother models, including the intelligent driver model, models based on locally\nweighted regression, and conventional neural network-based models. Moreover,\nthe DDPGvRT demonstrates good capability of generalization to various driving\nsituations and can adapt to different drivers by continuously learning. This\nstudy demonstrates that reinforcement learning methodology can offer insight\ninto driver behavior and can contribute to the development of human-like\nautonomous driving algorithms and traffic-flow models.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 01:05:29 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Zhu", "Meixin", ""], ["Wang", "Xuesong", ""], ["Wang", "Yinhai", ""]]}, {"id": "1901.00577", "submitter": "Guizeng You", "authors": "Xinwu Yang, Guizeng You, Chong Zhao, Mengfei Dou and Xinian Guo", "title": "An Improved multi-objective genetic algorithm based on orthogonal design\n  and adaptive clustering pruning strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two important characteristics of multi-objective evolutionary algorithms are\ndistribution and convergency. As a classic multi-objective genetic algorithm,\nNSGA-II is widely used in multi-objective optimization fields. However, in\nNSGA-II, the random population initialization and the strategy of population\nmaintenance based on distance cannot maintain the distribution or convergency\nof the population well. To dispose these two deficiencies, this paper proposes\nan improved algorithm, OTNSGA-II II, which has a better performance on\ndistribution and convergency. The new algorithm adopts orthogonal experiment,\nwhich selects individuals in manner of a new discontinuing non-dominated\nsorting and crowding distance, to produce the initial population. And a new\npruning strategy based on clustering is proposed to self-adaptively prunes\nindividuals with similar features and poor performance in non-dominated sorting\nand crowding distance, or to individuals are far away from the Pareto Front\naccording to the degree of intra-class aggregation of clustering results. The\nnew pruning strategy makes population to converge to the Pareto Front more\neasily and maintain the distribution of population. OTNSGA-II and NSGA-II are\ncompared on various types of test functions to verify the improvement of\nOTNSGA-II in terms of distribution and convergency.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 02:12:07 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Yang", "Xinwu", ""], ["You", "Guizeng", ""], ["Zhao", "Chong", ""], ["Dou", "Mengfei", ""], ["Guo", "Xinian", ""]]}, {"id": "1901.00586", "submitter": "Zheyuan Ryan Shi", "authors": "Zheyuan Ryan Shi, Aaron Schlenker, Brian Hay, Daniel Bittleston, Siyu\n  Gao, Emily Peterson, John Trezza, Fei Fang", "title": "Draining the Water Hole: Mitigating Social Engineering Attacks with\n  CyberTWEAK", "comments": "IAAI-20, AICS-2020 Workshop", "journal-ref": null, "doi": null, "report-no": "AICS/2019/02", "categories": "cs.CR cs.AI cs.GT cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber adversaries have increasingly leveraged social engineering attacks to\nbreach large organizations and threaten the well-being of today's online users.\nOne clever technique, the \"watering hole\" attack, compromises a legitimate\nwebsite to execute drive-by download attacks by redirecting users to another\nmalicious domain. We introduce a game-theoretic model that captures the salient\naspects for an organization protecting itself from a watering hole attack by\naltering the environment information in web traffic so as to deceive the\nattackers. Our main contributions are (1) a novel Social Engineering Deception\n(SED) game model that features a continuous action set for the attacker, (2) an\nin-depth analysis of the SED model to identify computationally feasible\nreal-world cases, and (3) the CyberTWEAK algorithm which solves for the optimal\nprotection policy. To illustrate the potential use of our framework, we built a\nbrowser extension based on our algorithms which is now publicly available\nonline. The CyberTWEAK extension will be vital to the continued development and\ndeployment of countermeasures for social engineering.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 02:42:34 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 01:53:37 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 05:00:58 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Shi", "Zheyuan Ryan", ""], ["Schlenker", "Aaron", ""], ["Hay", "Brian", ""], ["Bittleston", "Daniel", ""], ["Gao", "Siyu", ""], ["Peterson", "Emily", ""], ["Trezza", "John", ""], ["Fang", "Fei", ""]]}, {"id": "1901.00590", "submitter": "EPTCS", "authors": "Kevin Baum (Saarland University, Germany), Holger Hermanns (Saarland\n  University, Germany), Timo Speith (Saarland University, Germany)", "title": "Towards a Framework Combining Machine Ethics and Machine Explainability", "comments": "In Proceedings CREST 2018, arXiv:1901.00073", "journal-ref": "EPTCS 286, 2019, pp. 34-49", "doi": "10.4204/EPTCS.286.4", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We find ourselves surrounded by a rapidly increasing number of autonomous and\nsemi-autonomous systems. Two grand challenges arise from this development:\nMachine Ethics and Machine Explainability. Machine Ethics, on the one hand, is\nconcerned with behavioral constraints for systems, so that morally acceptable,\nrestricted behavior results; Machine Explainability, on the other hand, enables\nsystems to explain their actions and argue for their decisions, so that human\nusers can understand and justifiably trust them.\n  In this paper, we try to motivate and work towards a framework combining\nMachine Ethics and Machine Explainability. Starting from a toy example, we\ndetect various desiderata of such a framework and argue why they should and how\nthey could be incorporated in autonomous systems. Our main idea is to apply a\nframework of formal argumentation theory both, for decision-making under\nethical constraints and for the task of generating useful explanations given\nonly limited knowledge of the world. The result of our deliberations can be\ndescribed as a first version of an ethically motivated, principle-governed\nframework combining Machine Ethics and Machine Explainability\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 02:52:38 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Baum", "Kevin", "", "Saarland University, Germany"], ["Hermanns", "Holger", "", "Saarland\n  University, Germany"], ["Speith", "Timo", "", "Saarland University, Germany"]]}, {"id": "1901.00603", "submitter": "Victor Zhong", "authors": "Victor Zhong, Caiming Xiong, Nitish Shirish Keskar, Richard Socher", "title": "Coarse-grain Fine-grain Coattention Network for Multi-evidence Question\n  Answering", "comments": "ICLR 2019; 9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end neural models have made significant progress in question\nanswering, however recent studies show that these models implicitly assume that\nthe answer and evidence appear close together in a single document. In this\nwork, we propose the Coarse-grain Fine-grain Coattention Network (CFC), a new\nquestion answering model that combines information from evidence across\nmultiple documents. The CFC consists of a coarse-grain module that interprets\ndocuments with respect to the query then finds a relevant answer, and a\nfine-grain module which scores each candidate answer by comparing its\noccurrences across all of the documents with the query. We design these modules\nusing hierarchies of coattention and self-attention, which learn to emphasize\ndifferent parts of the input. On the Qangaroo WikiHop multi-evidence question\nanswering task, the CFC obtains a new state-of-the-art result of 70.6% on the\nblind test set, outperforming the previous best by 3% accuracy despite not\nusing pretrained contextual encoders.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 03:55:49 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 17:33:02 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zhong", "Victor", ""], ["Xiong", "Caiming", ""], ["Keskar", "Nitish Shirish", ""], ["Socher", "Richard", ""]]}, {"id": "1901.00612", "submitter": "Chunyuan Li", "authors": "Chunyuan Li, Ke Bai, Jianqiao Li, Guoyin Wang, Changyou Chen, Lawrence\n  Carin", "title": "Adversarial Learning of a Sampler Based on an Unnormalized Distribution", "comments": "Published in AISTATS 2019; Code: https://github.com/ChunyuanLI/RAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate adversarial learning in the case when only an unnormalized\nform of the density can be accessed, rather than samples. With insights so\ngarnered, adversarial learning is extended to the case for which one has access\nto an unnormalized form u(x) of the target density function, but no samples.\nFurther, new concepts in GAN regularization are developed, based on learning\nfrom samples or from u(x). The proposed method is compared to alternative\napproaches, with encouraging results demonstrated across a range of\napplications, including deep soft Q-learning.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 05:23:28 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Li", "Chunyuan", ""], ["Bai", "Ke", ""], ["Li", "Jianqiao", ""], ["Wang", "Guoyin", ""], ["Chen", "Changyou", ""], ["Carin", "Lawrence", ""]]}, {"id": "1901.00723", "submitter": "Simon Lucas", "authors": "Simon M. Lucas, Jialin Liu, Ivan Bravi, Raluca D. Gaina, John\n  Woodward, Vanessa Volz and Diego Perez-Liebana", "title": "Efficient Evolutionary Methods for Game Agent Optimisation: Model-Based\n  is Best", "comments": "8 pages, to appear in 2019 AAAI workshop on Games and Simulations for\n  Artificial Intelligence ( https://www.gamesim.ai/ )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces a simple and fast variant of Planet Wars as a test-bed\nfor statistical planning based Game AI agents, and for noisy hyper-parameter\noptimisation. Planet Wars is a real-time strategy game with simple rules but\ncomplex game-play. The variant introduced in this paper is designed for speed\nto enable efficient experimentation, and also for a fixed action space to\nenable practical inter-operability with General Video Game AI agents. If we\ntreat the game as a win-loss game (which is standard), then this leads to\nchallenging noisy optimisation problems both in tuning agents to play the game,\nand in tuning game parameters. Here we focus on the problem of tuning an agent,\nand report results using the recently developed N-Tuple Bandit Evolutionary\nAlgorithm and a number of other optimisers, including Sequential Model-based\nAlgorithm Configuration (SMAC). Results indicate that the N-Tuple Bandit\nEvolutionary offers competitive performance as well as insight into the effects\nof combinations of parameter choices.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 14:03:23 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Lucas", "Simon M.", ""], ["Liu", "Jialin", ""], ["Bravi", "Ivan", ""], ["Gaina", "Raluca D.", ""], ["Woodward", "John", ""], ["Volz", "Vanessa", ""], ["Perez-Liebana", "Diego", ""]]}, {"id": "1901.00811", "submitter": "Alexandre Coninx", "authors": "Seungsu Kim, Alexandre Coninx, Stephane Doncieux", "title": "From exploration to control: learning object manipulation skills through\n  novelty search and local adaptation", "comments": "30 pages, 18 figures, accepted for publication in Robotics and\n  Autonomous Systems", "journal-ref": null, "doi": "10.1016/j.robot.2020.103710", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming a robot to deal with open-ended tasks remains a challenge, in\nparticular if the robot has to manipulate objects. Launching, grasping, pushing\nor any other object interaction can be simulated but the corresponding models\nare not reversible and the robot behavior thus cannot be directly deduced.\nThese behaviors are hard to learn without a demonstration as the search space\nis large and the reward sparse. We propose a method to autonomously generate a\ndiverse repertoire of simple object interaction behaviors in simulation. Our\ngoal is to bootstrap a robot learning and development process with limited\ninformation about what the robot has to achieve and how. This repertoire can be\nexploited to solve different tasks in reality thanks to a proposed adaptation\nmethod or could be used as a training set for data-hungry algorithms.\n  The proposed approach relies on the definition of a goal space and generates\na repertoire of trajectories to reach attainable goals, thus allowing the robot\nto control this goal space. The repertoire is built with an off-the-shelf\nsimulation thanks to a quality diversity algorithm. The result is a set of\nsolutions tested in simulation only. It may result in two different problems:\n(1) as the repertoire is discrete and finite, it may not contain the trajectory\nto deal with a given situation or (2) some trajectories may lead to a behavior\nin reality that differs from simulation because of a reality gap. We propose an\napproach to deal with both issues by using a local linearization of the mapping\nbetween the motion parameters and the observed effects. Furthermore, we present\nan approach to update the existing solutions repertoire with the tests done on\nthe real robot. The approach has been validated on two different experiments on\nthe Baxter robot: a ball launching and a joystick manipulation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 16:46:27 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 09:21:35 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Kim", "Seungsu", ""], ["Coninx", "Alexandre", ""], ["Doncieux", "Stephane", ""]]}, {"id": "1901.00898", "submitter": "Horia Porav", "authors": "Horia Porav and Paul Newman", "title": "Imminent Collision Mitigation with Reinforcement Learning and Vision", "comments": "Presented at ITSC2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work examines the role of reinforcement learning in reducing the\nseverity of on-road collisions by controlling velocity and steering in\nsituations in which contact is imminent. We construct a model, given camera\nimages as input, that is capable of learning and predicting the dynamics of\nobstacles, cars and pedestrians, and train our policy using this model. Two\npolicies that control both braking and steering are compared against a baseline\nwhere the only action taken is (conventional) braking in a straight line. The\ntwo policies are trained using two distinct reward structures, one where any\nand all collisions incur a fixed penalty, and a second one where the penalty is\ncalculated based on already established delta-v models of injury severity. The\nresults show that both policies exceed the performance of the baseline, with\nthe policy trained using injury models having the highest performance.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 20:09:40 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Porav", "Horia", ""], ["Newman", "Paul", ""]]}, {"id": "1901.00921", "submitter": "Lantao Liu", "authors": "Shoubhik Debnath, Lantao Liu, Gaurav Sukhatme", "title": "Reachability and Differential based Heuristics for Solving Markov\n  Decision Processes", "comments": "The paper was published in 2017 International Symposium on Robotics\n  Research (ISRR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The solution convergence of Markov Decision Processes (MDPs) can be\naccelerated by prioritized sweeping of states ranked by their potential impacts\nto other states. In this paper, we present new heuristics to speed up the\nsolution convergence of MDPs. First, we quantify the level of reachability of\nevery state using the Mean First Passage Time (MFPT) and show that such\nreachability characterization very well assesses the importance of states which\nis used for effective state prioritization. Then, we introduce the notion of\nbackup differentials as an extension to the prioritized sweeping mechanism, in\norder to evaluate the impacts of states at an even finer scale. Finally, we\nextend the state prioritization to the temporal process, where only partial\nsweeping can be performed during certain intermediate value iteration stages.\nTo validate our design, we have performed numerical evaluations by comparing\nthe proposed new heuristics with corresponding classic baseline mechanisms. The\nevaluation results showed that our reachability based framework and its\ndifferential variants have outperformed the state-of-the-art solutions in terms\nof both practical runtime and number of iterations.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 22:01:26 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Debnath", "Shoubhik", ""], ["Liu", "Lantao", ""], ["Sukhatme", "Gaurav", ""]]}, {"id": "1901.00942", "submitter": "Florian Richoux", "authors": "Valentin Antuori and Florian Richoux", "title": "Constrained optimization under uncertainty for decision-making problems:\n  Application to Real-Time Strategy games", "comments": "Published at the 2019 IEEE Congress on Evolutionary Computation\n  (CEC'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-making problems can be modeled as combinatorial optimization\nproblems with Constraint Programming formalisms such as Constrained\nOptimization Problems. However, few Constraint Programming formalisms can deal\nwith both optimization and uncertainty at the same time, and none of them are\nconvenient to model problems we tackle in this paper.\n  Here, we propose a way to deal with combinatorial optimization problems under\nuncertainty within the classical Constrained Optimization Problems formalism by\ninjecting the Rank Dependent Utility from decision theory. We also propose a\nproof of concept of our method to show it is implementable and can solve\nconcrete decision-making problems using a regular constraint solver, and\npropose a bot that won the partially observable track of the 2018 {\\mu}RTS AI\ncompetition.\n  Our result shows it is possible to handle uncertainty with regular Constraint\nProgramming solvers, without having to define a new formalism neither to\ndevelop dedicated solvers. This brings new perspective to tackle uncertainty in\nConstraint Programming.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 23:45:00 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 08:47:41 GMT"}, {"version": "v3", "created": "Tue, 23 Apr 2019 05:09:11 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Antuori", "Valentin", ""], ["Richoux", "Florian", ""]]}, {"id": "1901.00943", "submitter": "Carlos Florensa", "authors": "Carlos Florensa, Jonas Degrave, Nicolas Heess, Jost Tobias\n  Springenberg, Martin Riedmiller", "title": "Self-supervised Learning of Image Embedding for Continuous Control", "comments": "Contributed talk at Inference to Control workshop at NeurIPS2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operating directly from raw high dimensional sensory inputs like images is\nstill a challenge for robotic control. Recently, Reinforcement Learning methods\nhave been proposed to solve specific tasks end-to-end, from pixels to torques.\nHowever, these approaches assume the access to a specified reward which may\nrequire specialized instrumentation of the environment. Furthermore, the\nobtained policy and representations tend to be task specific and may not\ntransfer well. In this work we investigate completely self-supervised learning\nof a general image embedding and control primitives, based on finding the\nshortest time to reach any state. We also introduce a new structure for the\nstate-action value function that builds a connection between model-free and\nmodel-based methods, and improves the performance of the learning algorithm. We\nexperimentally demonstrate these findings in three simulated robotic tasks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 23:49:09 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Florensa", "Carlos", ""], ["Degrave", "Jonas", ""], ["Heess", "Nicolas", ""], ["Springenberg", "Jost Tobias", ""], ["Riedmiller", "Martin", ""]]}, {"id": "1901.00949", "submitter": "Hussein Abbass A", "authors": "Nicholas R. Clayton and Hussein Abbass", "title": "Machine Teaching in Hierarchical Genetic Reinforcement Learning:\n  Curriculum Design of Reward Functions for Swarm Shepherding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of reward functions in reinforcement learning is a human skill\nthat comes with experience. Unfortunately, there is not any methodology in the\nliterature that could guide a human to design the reward function or to allow a\nhuman to transfer the skills developed in designing reward functions to another\nhuman and in a systematic manner. In this paper, we use Systematic\nInstructional Design, an approach in human education, to engineer a machine\neducation methodology to design reward functions for reinforcement learning. We\ndemonstrate the methodology in designing a hierarchical genetic reinforcement\nlearner that adopts a neural network representation to evolve a swarm\ncontroller for an agent shepherding a boids-based swarm. The results reveal\nthat the methodology is able to guide the design of hierarchical reinforcement\nlearners, with each model in the hierarchy learning incrementally through a\nmulti-part reward function. The hierarchy acts as a decision fusion function\nthat combines the individual behaviours and skills learnt by each instruction\nto create a smart shepherd to control the swarm.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 00:10:46 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Clayton", "Nicholas R.", ""], ["Abbass", "Hussein", ""]]}, {"id": "1901.00983", "submitter": "Satyarth Vaidya", "authors": "Satyarth Vaidya, Arshveer Kaur, Lavika Goel", "title": "Brief Review of Computational Intelligence Algorithms", "comments": "major error and re-ordering needed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational Intelligence algorithms have gained a lot of attention of\nresearchers in the recent years due to their ability to deliver near optimal\nsolutions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 05:21:29 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 09:50:23 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 13:41:54 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Vaidya", "Satyarth", ""], ["Kaur", "Arshveer", ""], ["Goel", "Lavika", ""]]}, {"id": "1901.01010", "submitter": "Aili Shen", "authors": "Aili Shen, Bahar Salehi, Timothy Baldwin, and Jianzhong Qi", "title": "A Joint Model for Multimodal Document Quality Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of a document is affected by various factors, including\ngrammaticality, readability, stylistics, and expertise depth, making the task\nof document quality assessment a complex one. In this paper, we explore this\ntask in the context of assessing the quality of Wikipedia articles and academic\npapers. Observing that the visual rendering of a document can capture implicit\nquality indicators that are not present in the document text --- such as\nimages, font choices, and visual layout --- we propose a joint model that\ncombines the text content with a visual rendering of the document for document\nquality assessment. Experimental results over two datasets reveal that textual\nand visual features are complementary, achieving state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 08:05:56 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 00:46:42 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Shen", "Aili", ""], ["Salehi", "Bahar", ""], ["Baldwin", "Timothy", ""], ["Qi", "Jianzhong", ""]]}, {"id": "1901.01051", "submitter": "Rahul Vigneswaran K", "authors": "Rahul Vigneswaran K, Soman KP", "title": "An Insight into the Dynamics and State Space Modelling of a 3-D\n  Quadrotor", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.RO math.CA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Drones have gained popularity in a wide range of field ranging from aerial\nphotography, aerial mapping, and investigation of electric power lines. Every\ndrone that we know today is carrying out some kind of control algorithm at the\nlow level in order to manoeuvre itself around. For the quadrotor to either\ncontrol itself autonomously or to develop a high-level user interface for us to\ncontrol it, we need to understand the basic mathematics behind how it\nfunctions. This paper aims to explain the mathematical modelling of the\ndynamics of a 3 Dimensional quadrotor. As it may seem like a trivial task, it\nplays a vital role in how we control the drone. Also, additional effort has\nbeen taken to explain the transformations of the drone's frame of reference to\nthe inertial frame of reference.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 11:02:38 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["K", "Rahul Vigneswaran", ""], ["KP", "Soman", ""]]}, {"id": "1901.01229", "submitter": "Lantao Liu", "authors": "Shoubhik Debnath, Lantao Liu, Gaurav Sukhatme", "title": "Solving Markov Decision Processes with Reachability Characterization\n  from Mean First Passage Times", "comments": "The paper was published in 2018 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new mechanism for efficiently solving the Markov decision processes (MDPs)\nis proposed in this paper. We introduce the notion of reachability landscape\nwhere we use the Mean First Passage Time (MFPT) as a means to characterize the\nreachability of every state in the state space. We show that such reachability\ncharacterization very well assesses the importance of states and thus provides\na natural basis for effectively prioritizing states and approximating policies.\nBuilt on such a novel observation, we design two new algorithms -- Mean First\nPassage Time based Value Iteration (MFPT-VI) and Mean First Passage Time based\nPolicy Iteration (MFPT-PI) -- that have been modified from the state-of-the-art\nsolution methods. To validate our design, we have performed numerical\nevaluations in robotic decision-making scenarios, by comparing the proposed new\nmethods with corresponding classic baseline mechanisms. The evaluation results\nshowed that MFPT-VI and MFPT-PI have outperformed the state-of-the-art\nsolutions in terms of both practical runtime and number of iterations. Aside\nfrom the advantage of fast convergence, this new solution method is intuitively\neasy to understand and practically simple to implement.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 18:00:32 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Debnath", "Shoubhik", ""], ["Liu", "Lantao", ""], ["Sukhatme", "Gaurav", ""]]}, {"id": "1901.01325", "submitter": "Roi Ceren", "authors": "Roi Ceren", "title": "Optimal Decision-Making in Mixed-Agent Partially Observable Stochastic\n  Environments via Reinforcement Learning", "comments": "Phd thesis, University of Georgia (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal decision making with limited or no information in stochastic\nenvironments where multiple agents interact is a challenging topic in the realm\nof artificial intelligence. Reinforcement learning (RL) is a popular approach\nfor arriving at optimal strategies by predicating stimuli, such as the reward\nfor following a strategy, on experience. RL is heavily explored in the\nsingle-agent context, but is a nascent concept in multiagent problems. To this\nend, I propose several principled model-free and partially model-based\nreinforcement learning approaches for several multiagent settings. In the realm\nof normative reinforcement learning, I introduce scalable extensions to Monte\nCarlo exploring starts for partially observable Markov Decision Processes\n(POMDP), dubbed MCES-P, where I expand the theory and algorithm to the\nmultiagent setting. I first examine MCES-P with probably approximately correct\n(PAC) bounds in the context of multiagent setting, showing MCESP+PAC holds in\nthe presence of other agents. I then propose a more sample-efficient\nmethodology for antagonistic settings, MCESIP+PAC. For cooperative settings, I\nextend MCES-P to the Multiagent POMDP, dubbed MCESMP+PAC. I then explore the\nuse of reinforcement learning as a methodology in searching for optima in\nrealistic and latent model environments. First, I explore a parameterized\nQ-learning approach in modeling humans learning to reason in an uncertain,\nmultiagent environment. Next, I propose an implementation of MCES-P, along with\nimage segmentation, to create an adaptive team-based reinforcement learning\ntechnique to positively identify the presence of phenotypically-expressed water\nand pathogen stress in crop fields.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 21:59:28 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Ceren", "Roi", ""]]}, {"id": "1901.01365", "submitter": "Takayuki Osa", "authors": "Takayuki Osa and Voot Tangkaratt and Masashi Sugiyama", "title": "Hierarchical Reinforcement Learning via Advantage-Weighted Information\n  Maximization", "comments": "16 pages, ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world tasks are often highly structured. Hierarchical reinforcement\nlearning (HRL) has attracted research interest as an approach for leveraging\nthe hierarchical structure of a given task in reinforcement learning (RL).\nHowever, identifying the hierarchical policy structure that enhances the\nperformance of RL is not a trivial task. In this paper, we propose an HRL\nmethod that learns a latent variable of a hierarchical policy using mutual\ninformation maximization. Our approach can be interpreted as a way to learn a\ndiscrete and latent representation of the state-action space. To learn option\npolicies that correspond to modes of the advantage function, we introduce\nadvantage-weighted importance sampling. In our HRL method, the gating policy\nlearns to select option policies based on an option-value function, and these\noption policies are optimized based on the deterministic policy gradient\nmethod. This framework is derived by leveraging the analogy between a\nmonolithic policy in standard RL and a hierarchical policy in HRL by using a\ndeterministic option policy. Experimental results indicate that our HRL\napproach can learn a diversity of options and that it can enhance the\nperformance of RL in continuous control tasks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 04:43:05 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 06:34:21 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Osa", "Takayuki", ""], ["Tangkaratt", "Voot", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1901.01379", "submitter": "Enlu Lin", "authors": "Enlu Lin and Qiong Chen and Xiaoming Qi", "title": "Deep Reinforcement Learning for Imbalanced Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data in real-world application often exhibit skewed class distribution which\nposes an intense challenge for machine learning. Conventional classification\nalgorithms are not effective in the case of imbalanced data distribution, and\nmay fail when the data distribution is highly imbalanced. To address this\nissue, we propose a general imbalanced classification model based on deep\nreinforcement learning. We formulate the classification problem as a sequential\ndecision-making process and solve it by deep Q-learning network. The agent\nperforms a classification action on one sample at each time step, and the\nenvironment evaluates the classification action and returns a reward to the\nagent. The reward from minority class sample is larger so the agent is more\nsensitive to the minority class. The agent finally finds an optimal\nclassification policy in imbalanced data under the guidance of specific reward\nfunction and beneficial learning environment. Experiments show that our\nproposed model outperforms the other imbalanced classification algorithms, and\nit can identify more minority samples and has great classification performance.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 07:59:47 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Lin", "Enlu", ""], ["Chen", "Qiong", ""], ["Qi", "Xiaoming", ""]]}, {"id": "1901.01549", "submitter": "Guojun Chen", "authors": "Guojun Chen, Xianghong Lin and Guoen Wang", "title": "An online supervised learning algorithm based on triple spikes for\n  spiking neural networks", "comments": "11 pages, 5 figures and 5 tables, partly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using precise times of every spike, spiking supervised learning has more\neffects on complex spatial-temporal pattern than supervised learning only\nthrough neuronal firing rates. The purpose of spiking supervised learning after\nspatial-temporal encoding is to emit desired spike trains with precise times.\nExisting algorithms of spiking supervised learning have excellent performances,\nbut mechanisms of them still have some problems, such as the limitation of\nneuronal types and complex computation. Based on an online regulative mechanism\nof biological synapses, this paper proposes an online supervised learning\nalgorithm of multiple spike trains for spiking neural networks. The proposed\nalgorithm with a spatial-temporal transformation can make a simple direct\nregulation of synaptic weights as soon as firing time of an output spike is\nobtained. Besides, it is also not restricted by types of spiking neuron models.\nRelationship among desired output, actual output and input spike trains is\nfirstly analyzed and synthesized to simply select a unit of pair-spike for a\ndirect regulation. And then a computational method is constructed based on\nsimple triple spikes using this direct regulation. Compared with other learning\nalgorithms, results of experiments show that proposed algorithm has higher\nlearning accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 15:11:10 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 06:27:38 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Chen", "Guojun", ""], ["Lin", "Xianghong", ""], ["Wang", "Guoen", ""]]}, {"id": "1901.01592", "submitter": "Andrey Kormilitzin", "authors": "Luka Gligic, Andrey Kormilitzin, Paul Goldberg, Alejo Nevado-Holgado", "title": "Named Entity Recognition in Electronic Health Records Using Transfer\n  Learning Bootstrapped Neural Networks", "comments": "11 pages, 4 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks (NNs) have become the state of the art in many machine\nlearning applications, especially in image and sound processing [1]. The same,\nalthough to a lesser extent [2,3], could be said in natural language processing\n(NLP) tasks, such as named entity recognition. However, the success of NNs\nremains dependent on the availability of large labelled datasets, which is a\nsignificant hurdle in many important applications. One such case are electronic\nhealth records (EHRs), which are arguably the largest source of medical data,\nmost of which lies hidden in natural text [4,5]. Data access is difficult due\nto data privacy concerns, and therefore annotated datasets are scarce. With\nscarce data, NNs will likely not be able to extract this hidden information\nwith practical accuracy. In our study, we develop an approach that solves these\nproblems for named entity recognition, obtaining 94.6 F1 score in I2B2 2009\nMedical Extraction Challenge [6], 4.3 above the architecture that won the\ncompetition. Beyond the official I2B2 challenge, we further achieve 82.4 F1 on\nextracting relationships between medical terms. To reach this state-of-the-art\naccuracy, our approach applies transfer learning to leverage on datasets\nannotated for other I2B2 tasks, and designs and trains embeddings that\nspecially benefit from such transfer.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 18:53:12 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 15:26:21 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Gligic", "Luka", ""], ["Kormilitzin", "Andrey", ""], ["Goldberg", "Paul", ""], ["Nevado-Holgado", "Alejo", ""]]}, {"id": "1901.01672", "submitter": "Vaishnavh Nagarajan", "authors": "Vaishnavh Nagarajan, J. Zico Kolter", "title": "Generalization in Deep Networks: The Role of Distance from\n  Initialization", "comments": "Spotlight paper at NeurIPS 2017 workshop on Deep Learning: Bridging\n  Theory and Practice", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Why does training deep neural networks using stochastic gradient descent\n(SGD) result in a generalization error that does not worsen with the number of\nparameters in the network? To answer this question, we advocate a notion of\neffective model capacity that is dependent on {\\em a given random\ninitialization of the network} and not just the training algorithm and the data\ndistribution. We provide empirical evidences that demonstrate that the model\ncapacity of SGD-trained deep networks is in fact restricted through implicit\nregularization of {\\em the $\\ell_2$ distance from the initialization}. We also\nprovide theoretical arguments that further highlight the need for\ninitialization-dependent notions of model capacity. We leave as open questions\nhow and why distance from initialization is regularized, and whether it is\nsufficient to explain generalization.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 05:59:11 GMT"}, {"version": "v2", "created": "Sun, 13 Jan 2019 08:08:13 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Nagarajan", "Vaishnavh", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1901.01706", "submitter": "Jong Chul Ye", "authors": "Shujaat Khan, Jaeyoung Huh, Jong Chul Ye", "title": "Universal Deep Beamformer for Variable Rate Ultrasound Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasound (US) imaging is based on the time-reversal principle, in which\nindividual channel RF measurements are back-propagated and accumulated to form\nan image after applying specific delays. While this time reversal is usually\nimplemented as a delay-and-sum (DAS) beamformer, the image quality quickly\ndegrades as the number of measurement channels decreases. To address this\nproblem, various types of adaptive beamforming techniques have been proposed\nusing predefined models of the signals. However, the performance of these\nadaptive beamforming approaches degrade when the underlying model is not\nsufficiently accurate. Here, we demonstrate for the first time that a single\nuniversal deep beamformer trained using a purely data-driven way can generate\nsignificantly improved images over widely varying aperture and channel\nsubsampling patterns. In particular, we design an end-to-end deep learning\nframework that can directly process sub-sampled RF data acquired at different\nsubsampling rate and detector configuration to generate high quality ultrasound\nimages using a single beamformer. Experimental results using B-mode focused\nultrasound confirm the efficacy of the proposed methods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 08:52:02 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Khan", "Shujaat", ""], ["Huh", "Jaeyoung", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1901.01826", "submitter": "Elias Alevizos", "authors": "Elias Alevizos, Alexander Artikis, Georgios Paliouras", "title": "Wayeb: a Tool for Complex Event Forecasting", "comments": null, "journal-ref": "LPAR-22.Proc. 57(2018) 16-35", "doi": "10.29007/2s9t", "report-no": null, "categories": "cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex Event Processing (CEP) systems have appeared in abundance during the\nlast two decades. Their purpose is to detect in real-time interesting patterns\nupon a stream of events and to inform an analyst for the occurrence of such\npatterns in a timely manner. However, there is a lack of methods for\nforecasting when a pattern might occur before such an occurrence is actually\ndetected by a CEP engine. We present Wayeb, a tool that attempts to address the\nissue of Complex Event Forecasting. Wayeb employs symbolic automata as a\ncomputational model for pattern detection and Markov chains for deriving a\nprobabilistic description of a symbolic automaton.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 13:23:28 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Alevizos", "Elias", ""], ["Artikis", "Alexander", ""], ["Paliouras", "Georgios", ""]]}, {"id": "1901.01830", "submitter": "Christophe Lecoutre", "authors": "Christophe Lecoutre and Olivier Roussel", "title": "Proceedings of the 2018 XCSP3 Competition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document represents the proceedings of the 2018 XCSP3 Competition. The\nresults of this competition of constraint solvers were presented at CP'18, the\n24th International Conference on Principles and Practice of Constraint\nProgramming, held in Lille, France from 27th August 2018 to 31th August, 2018.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 14:29:45 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Lecoutre", "Christophe", ""], ["Roussel", "Olivier", ""]]}, {"id": "1901.01831", "submitter": "Mihir Jain", "authors": "Mihir Jain, Kyle Brown, Ahmed K. Sadek", "title": "Multi-Fidelity Recursive Behavior Prediction", "comments": null, "journal-ref": "Conference on Neural Information Processing Systems 2018", "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the behavior of surrounding vehicles is a critical problem in\nautomated driving. We present a novel game theoretic behavior prediction model\nthat achieves state of the art prediction accuracy by explicitly reasoning\nabout possible future interaction between agents. We evaluate our approach on\nthe NGSIM vehicle trajectory data set and demonstrate lower root mean square\nerror than state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 14:49:54 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Jain", "Mihir", ""], ["Brown", "Kyle", ""], ["Sadek", "Ahmed K.", ""]]}, {"id": "1901.01834", "submitter": "Baogang Hu", "authors": "Baogang Hu, Weiming Dong", "title": "\"Ge Shu Zhi Zhi\": Towards Deep Understanding about Worlds", "comments": "10 pages, in Chinese. 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Ge She Zhi Zhi\" is a novel saying in Chinese, stated as \"To investigate\nthings from the underlying principle(s) and to acquire knowledge in the form of\nmathematical representations\". The saying is adopted and modified based on the\nideas from the Eastern and Western philosophers. This position paper discusses\nthe saying in the background of artificial intelligence (AI). Some related\nsubjects, such as the ultimate goals of AI and two levels of knowledge\nrepresentations, are discussed from the perspective of machine learning. A case\nstudy on objective evaluations over multi attributes, a typical problem in the\nfiled of social computing, is given to support the saying for wide\napplications. A methodology of meta rules is proposed for examining the\nobjectiveness of the evaluations. The possible problems of the saying are also\npresented.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 05:18:20 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2019 01:25:59 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 01:32:04 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Hu", "Baogang", ""], ["Dong", "Weiming", ""]]}, {"id": "1901.01837", "submitter": "Karl-Heinz Zimmermann", "authors": "Robert Leppert, Karl-Heinz Zimmermann", "title": "Inference in Graded Bayesian Networks", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning provides algorithms that can learn from data and make\ninferences or predictions on data. Bayesian networks are a class of graphical\nmodels that allow to represent a collection of random variables and their\ncondititional dependencies by directed acyclic graphs. In this paper, an\ninference algorithm for the hidden random variables of a Bayesian network is\ngiven by using the tropicalization of the marginal distribution of the observed\nvariables. By restricting the topological structure to graded networks, an\ninference algorithm for graded Bayesian networks will be established that\nevaluates the hidden random variables rank by rank and in this way yields the\nmost probable states of the hidden variables. This algorithm can be viewed as a\ngeneralized version of the Viterbi algorithm for graded Bayesian networks.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 10:58:04 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Leppert", "Robert", ""], ["Zimmermann", "Karl-Heinz", ""]]}, {"id": "1901.01851", "submitter": "Roman Yampolskiy", "authors": "Roman V. Yampolskiy", "title": "Personal Universes: A Solution to the Multi-Agent Value Alignment\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI Safety researchers attempting to align values of highly capable\nintelligent systems with those of humanity face a number of challenges\nincluding personal value extraction, multi-agent value merger and finally\nin-silico encoding. State-of-the-art research in value alignment shows\ndifficulties in every stage in this process, but merger of incompatible\npreferences is a particularly difficult challenge to overcome. In this paper we\nassume that the value extraction problem will be solved and propose a possible\nway to implement an AI solution which optimally aligns with individual\npreferences of each user. We conclude by analyzing benefits and limitations of\nthe proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 18:05:43 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Yampolskiy", "Roman V.", ""]]}, {"id": "1901.01855", "submitter": "Xiaojie Gao", "authors": "Xiaojie Gao, Shikui Tu, Lei Xu", "title": "A* Tree Search for Portfolio Management", "comments": "The paper needs a major revision including the title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a planning-based method to teach an agent to manage portfolio from\nscratch. Our approach combines deep reinforcement learning techniques with\nsearch techniques like AlphaGo. By uniting the advantages in A* search\nalgorithm with Monte Carlo tree search, we come up with a new algorithm named\nA* tree search in which best information is returned to guide next search.\nAlso, the expansion mode of Monte Carlo tree is improved for a higher\nutilization of the neural network. The suggested algorithm can also optimize\nnon-differentiable utility function by combinatorial search. This technique is\nthen used in our trading system. The major component is a neural network that\nis trained by trading experiences from tree search and outputs prior\nprobability to guide search by pruning away branches in turn. Experimental\nresults on simulated and real financial data verify the robustness of the\nproposed trading system and the trading system produces better strategies than\nseveral approaches based on reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 14:59:15 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 10:26:13 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Gao", "Xiaojie", ""], ["Tu", "Shikui", ""], ["Xu", "Lei", ""]]}, {"id": "1901.01856", "submitter": "Krishn Bera", "authors": "Krishn Bera, Tejas Savalia and Bapi Raju", "title": "A Computational Framework for Motor Skill Acquisition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There have been numerous attempts in explaining the general learning\nbehaviours by various cognitive models. Multiple hypotheses have been put\nfurther to qualitatively argue the best-fit model for motor skill acquisition\ntask and its variations. In this context, for a discrete sequence production\n(DSP) task, one of the most insightful models is Verwey's Dual Processor Model\n(DPM). It largely explains the learning and behavioural phenomenon of skilled\ndiscrete key-press sequences without providing any concrete computational basis\nof reinforcement. Therefore, we propose a quantitative explanation for Verwey's\nDPM hypothesis by experimentally establishing a general computational framework\nfor motor skill learning. We attempt combining the qualitative and quantitative\ntheories based on a best-fit model of the experimental simulations of\nvariations of dual processor models. The fundamental premise of sequential\ndecision making for skill learning is based on interacting model-based (MB) and\nmodel-free (MF) reinforcement learning (RL) processes. Our unifying framework\nshows the proposed idea agrees well to Verwey's DPM and Fitts' three phases of\nskill learning. The accuracy of our model can further be validated by its\nstatistical fit with the human-generated data on simple environment tasks like\nthe grid-world.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 09:06:56 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Bera", "Krishn", ""], ["Savalia", "Tejas", ""], ["Raju", "Bapi", ""]]}, {"id": "1901.01970", "submitter": "Jos\\'e Cl\\'audio do Nascimento", "authors": "Jos\\'e Cl\\'audio do Nascimento", "title": "Decision-making and Fuzzy Temporal Logic", "comments": "11 pages, 7 figures. This new version has a new subsection and news\n  references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI econ.TH math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that the fuzzy temporal logic can model figures of thought\nto describe decision-making behaviors. In order to exemplify, some economic\nbehaviors observed experimentally were modeled from problems of choice\ncontaining time, uncertainty and fuzziness. Related to time preference, it is\nnoted that the subadditive discounting is mandatory in positive rewards\nsituations and, consequently, results in the magnitude effect and time effect,\nwhere the last has a stronger discounting for earlier delay periods (as in, one\nhour, one day), but a weaker discounting for longer delay periods (for\ninstance, six months, one year, ten years). In addition, it is possible to\nexplain the preference reversal (change of preference when two rewards proposed\non different dates are shifted in the time). Related to the Prospect Theory, it\nis shown that the risk seeking and the risk aversion are magnitude dependents,\nwhere the risk seeking may disappear when the values to be lost are very high.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 18:56:24 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 13:51:32 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Nascimento", "Jos\u00e9 Cl\u00e1udio do", ""]]}, {"id": "1901.01977", "submitter": "Lantao Liu", "authors": "Shoubhik Debnath, Gaurav Sukhatme, Lantao Liu", "title": "Accelerating Goal-Directed Reinforcement Learning by Model\n  Characterization", "comments": "The paper was published in 2018 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hybrid approach aimed at improving the sample efficiency in\ngoal-directed reinforcement learning. We do this via a two-step mechanism where\nfirstly, we approximate a model from Model-Free reinforcement learning. Then,\nwe leverage this approximate model along with a notion of reachability using\nMean First Passage Times to perform Model-Based reinforcement learning. Built\non such a novel observation, we design two new algorithms - Mean First Passage\nTime based Q-Learning (MFPT-Q) and Mean First Passage Time based DYNA\n(MFPT-DYNA), that have been fundamentally modified from the state-of-the-art\nreinforcement learning techniques. Preliminary results have shown that our\nhybrid approaches converge with much fewer iterations than their corresponding\nstate-of-the-art counterparts and therefore requiring much fewer samples and\nmuch fewer training trials to converge.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 19:04:37 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Debnath", "Shoubhik", ""], ["Sukhatme", "Gaurav", ""], ["Liu", "Lantao", ""]]}, {"id": "1901.01989", "submitter": "Fernando Corbacho", "authors": "Fernando J. Corbacho", "title": "Towards Self-constructive Artificial Intelligence: Algorithmic basis\n  (Part I)", "comments": "arXiv admin note: substantial text overlap with arXiv:1608.02229", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence frameworks should allow for ever more autonomous and\ngeneral systems in contrast to very narrow and restricted (human pre-defined)\ndomain systems, in analogy to how the brain works. Self-constructive Artificial\nIntelligence ($SCAI$) is one such possible framework. We herein propose that\n$SCAI$ is based on three principles of organization: self-growing,\nself-experimental and self-repairing. Self-growing: the ability to autonomously\nand incrementally construct structures and functionality as needed to solve\nencountered (sub)problems. Self-experimental: the ability to internally\nsimulate, anticipate and take decisions based on these expectations.\nSelf-repairing: the ability to autonomously re-construct a previously\nsuccessful functionality or pattern of interaction lost from a possible\nsub-component failure (damage). To implement these principles of organization,\na constructive architecture capable of evolving adaptive autonomous agents is\nrequired. We present Schema-based learning as one such architecture capable of\nincrementally constructing a myriad of internal models of three kinds:\npredictive schemas, dual (inverse models) schemas and goal schemas as they are\nnecessary to autonomously develop increasing functionality.\n  We claim that artificial systems, whether in the digital or in the physical\nworld, can benefit very much form this constructive architecture and should be\norganized around these principles of organization. To illustrate the generality\nof the proposed framework, we include several test cases in structural adaptive\nnavigation in artificial intelligence systems in Paper II of this series, and\nresilient robot motor control in Paper III of this series. Paper IV of this\nseries will also include $SCAI$ for problem structural discovery in predictive\nBusiness Intelligence.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 19:57:24 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Corbacho", "Fernando J.", ""]]}, {"id": "1901.01994", "submitter": "Vincent Liu", "authors": "Vincent Liu, Ademi Adeniji, Nathaniel Lee, Jason Zhao, Mario Srouji", "title": "Recurrent Control Nets for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Central Pattern Generators (CPGs) are biological neural circuits capable of\nproducing coordinated rhythmic outputs in the absence of rhythmic input. As a\nresult, they are responsible for most rhythmic motion in living organisms. This\nrhythmic control is broadly applicable to fields such as locomotive robotics\nand medical devices. In this paper, we explore the possibility of creating a\nself-sustaining CPG network for reinforcement learning that learns rhythmic\nmotion more efficiently and across more general environments than the current\nmultilayer perceptron (MLP) baseline models. Recent work introduces the\nStructured Control Net (SCN), which maintains linear and nonlinear modules for\nlocal and global control, respectively. Here, we show that time-sequence\narchitectures such as Recurrent Neural Networks (RNNs) model CPGs effectively.\nCombining previous work with RNNs and SCNs, we introduce the Recurrent Control\nNet (RCN), which adds a linear component to the, RCNs match and exceed the\nperformance of baseline MLPs and SCNs across all environment tasks. Our\nfindings confirm existing intuitions for RNNs on reinforcement learning tasks,\nand demonstrate promise of SCN-like structures in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 23:35:07 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 03:24:29 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Liu", "Vincent", ""], ["Adeniji", "Ademi", ""], ["Lee", "Nathaniel", ""], ["Zhao", "Jason", ""], ["Srouji", "Mario", ""]]}, {"id": "1901.02001", "submitter": "Mohsen Ahmadi Fahandar", "authors": "Mohsen Ahmadi Fahandar, Eyke H\\\"ullermeier", "title": "Analogy-Based Preference Learning with Kernels", "comments": "arXiv admin note: substantial text overlap with arXiv:1711.10207", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on a specific formalization of analogical relationships of the form\n\"A relates to B as C relates to D\", we establish a connection between two\nimportant subfields of artificial intelligence, namely analogical reasoning and\nkernel-based machine learning. More specifically, we show that so-called\nanalogical proportions are closely connected to kernel functions on pairs of\nobjects. Based on this result, we introduce the analogy kernel, which can be\nseen as a measure of how strongly four objects are in analogical relationship.\nAs an application, we consider the problem of object ranking in the realm of\npreference learning, for which we develop a new method based on support vector\nmachines trained with the analogy kernel. Our first experimental results for\ndata sets from different domains (sports, education, tourism, etc.) are\npromising and suggest that our approach is competitive to state-of-the-art\nalgorithms in terms of predictive accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 11:23:12 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Fahandar", "Mohsen Ahmadi", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1901.02035", "submitter": "Roi Ceren", "authors": "Roi Ceren, Shannon Quinn, Glen Raines", "title": "Towards a Decentralized, Autonomous Multiagent Framework for Mitigating\n  Crop Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generalized decision-theoretic system for a heterogeneous team\nof autonomous agents who are tasked with online identification of\nphenotypically expressed stress in crop fields.. This system employs four\ndistinct types of agents, specific to four available sensor modalities:\nsatellites (Layer 3), uninhabited aerial vehicles (L2), uninhabited ground\nvehicles (L1), and static ground-level sensors (L0). Layers 3, 2, and 1 are\ntasked with performing image processing at the available resolution of the\nsensor modality and, along with data generated by layer 0 sensors, identify\nerroneous differences that arise over time. Our goal is to limit the use of the\nmore computationally and temporally expensive subsequent layers. Therefore,\nfrom layer 3 to 1, each layer only investigates areas that previous layers have\nidentified as potentially afflicted by stress. We introduce a reinforcement\nlearning technique based on Perkins' Monte Carlo Exploring Starts for a\ngeneralized Markovian model for each layer's decision problem, and label the\nsystem the Agricultural Distributed Decision Framework (ADDF). As our domain is\nreal-world and online, we illustrate implementations of the two major\ncomponents of our system: a clustering-based image processing methodology and a\ntwo-layer POMDP implementation.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 19:44:44 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Ceren", "Roi", ""], ["Quinn", "Shannon", ""], ["Raines", "Glen", ""]]}, {"id": "1901.02039", "submitter": "Chiyu Jiang", "authors": "Chiyu \"Max\" Jiang, Jingwei Huang, Karthik Kashinath, Prabhat, Philip\n  Marcus, Matthias Niessner", "title": "Spherical CNNs on Unstructured Grids", "comments": "Accepted as a conference paper at ICLR 2019. Codes available at\n  https://github.com/maxjiang93/ugscnn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient convolution kernel for Convolutional Neural Networks\n(CNNs) on unstructured grids using parameterized differential operators while\nfocusing on spherical signals such as panorama images or planetary signals. To\nthis end, we replace conventional convolution kernels with linear combinations\nof differential operators that are weighted by learnable parameters.\nDifferential operators can be efficiently estimated on unstructured grids using\none-ring neighbors, and learnable parameters can be optimized through standard\nback-propagation. As a result, we obtain extremely efficient neural networks\nthat match or outperform state-of-the-art network architectures in terms of\nperformance but with a significantly lower number of network parameters. We\nevaluate our algorithm in an extensive series of experiments on a variety of\ncomputer vision and climate science tasks, including shape classification,\nclimate pattern segmentation, and omnidirectional image semantic segmentation.\nOverall, we present (1) a novel CNN approach on unstructured grids using\nparameterized differential operators for spherical signals, and (2) we show\nthat our unique kernel parameterization allows our model to achieve the same or\nhigher accuracy with significantly fewer network parameters.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 19:56:19 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Jiang", "Chiyu \"Max\"", ""], ["Huang", "Jingwei", ""], ["Kashinath", "Karthik", ""], ["Prabhat", "", ""], ["Marcus", "Philip", ""], ["Niessner", "Matthias", ""]]}, {"id": "1901.02046", "submitter": "Hui Jiang", "authors": "Hui Jiang", "title": "A New Perspective on Machine Learning: How to do Perfect Supervised\n  Learning", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce the concept of bandlimiting into the theory of\nmachine learning because all physical processes are bandlimited by nature,\nincluding real-world machine learning tasks. After the bandlimiting constraint\nis taken into account, our theoretical analysis has shown that all practical\nmachine learning tasks are asymptotically solvable in a perfect sense.\nFurthermore, the key towards this solvability almost solely relies on two\nfactors: i) a sufficiently large amount of training samples beyond a threshold\ndetermined by a difficulty measurement of the underlying task; ii) a\nsufficiently complex and bandlimited model. Moreover, for some special cases,\nwe have derived new error bounds for perfect learning, which can quantify the\ndifficulty of learning. These generalization bounds are not only asymptotically\nconvergent but also irrelevant to model complexity. Our new results on\ngeneralization have provided a new perspective to explain the recent successes\nof large-scale supervised learning using complex models like neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 20:10:55 GMT"}, {"version": "v2", "created": "Sat, 19 Jan 2019 21:15:29 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2019 16:40:02 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Jiang", "Hui", ""]]}, {"id": "1901.02055", "submitter": "Molka Tounsi Dhouib", "authors": "C\\'edric Lopez (TEXTE), Molka Dhouib (I3S, WIMMICS), Elena Cabrio\n  (WIMMICS), Catherine Faron Zucker (I3S, WIMMICS), Fabien Gandon (UCA,\n  WIMMICS), Fr\\'ed\\'erique Segond", "title": "SMILK, linking natural language and data from the web", "comments": "in French", "journal-ref": "RIA - Revue d'Intelligence Artificielle, 2018", "doi": "10.3166/RIA.32.287-312", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As part of the SMILK Joint Lab, we studied the use of Natural Language\nProcessing to: (1) enrich knowledge bases and link data on the web, and\nconversely (2) use this linked data to contribute to the improvement of text\nanalysis and the annotation of textual content, and to support knowledge\nextraction. The evaluation focused on brand-related information retrieval in\nthe field of cosmetics. This article describes each step of our approach: the\ncreation of ProVoc, an ontology to describe products and brands; the automatic\npopulation of a knowledge base mainly based on ProVoc from heterogeneous\ntextual resources; and the evaluation of an application which that takes the\nform of a browser plugin providing additional knowledge to users browsing the\nweb.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 12:35:19 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Lopez", "C\u00e9dric", "", "TEXTE"], ["Dhouib", "Molka", "", "I3S, WIMMICS"], ["Cabrio", "Elena", "", "WIMMICS"], ["Zucker", "Catherine Faron", "", "I3S, WIMMICS"], ["Gandon", "Fabien", "", "UCA,\n  WIMMICS"], ["Segond", "Fr\u00e9d\u00e9rique", ""]]}, {"id": "1901.02058", "submitter": "Manuele Leonelli", "authors": "Manuele Leonelli and Eva Riccomagno", "title": "A geometric characterisation of sensitivity analysis in monomial models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensitivity analysis in probabilistic discrete graphical models is usually\nconducted by varying one probability value at a time and observing how this\naffects output probabilities of interest. When one probability is varied then\nothers are proportionally covaried to respect the sum-to-one condition of\nprobability laws. The choice of proportional covariation is justified by a\nvariety of optimality conditions, under which the original and the varied\ndistributions are as close as possible under different measures of closeness.\nFor variations of more than one parameter at a time proportional covariation is\njustified in some special cases only. In this work, for the large class of\ndiscrete statistical models entertaining a regular monomial parametrisation, we\ndemonstrate the optimality of newly defined proportional multi-way schemes with\nrespect to an optimality criterion based on the notion of I-divergence. We\ndemonstrate that there are varying parameters choices for which proportional\ncovariation is not optimal and identify the sub-family of model distributions\nwhere the distance between the original distribution and the one where\nprobabilities are covaried proportionally is minimum. This is shown by adopting\na new formal, geometric characterization of sensitivity analysis in monomial\nmodels, which include a wide array of probabilistic graphical models. We also\ndemonstrate the optimality of proportional covariation for multi-way analyses\nin Naive Bayes classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 11:21:53 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 17:27:45 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Leonelli", "Manuele", ""], ["Riccomagno", "Eva", ""]]}, {"id": "1901.02063", "submitter": "Morteza Haghir Chehreghani", "authors": "Morteza Haghir Chehreghani", "title": "Reliable Agglomerative Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the general behavior of agglomerative clustering methods, and\nargue that their strategy yields establishment of a new reliable linkage at\neach step. However, in order to provide adaptive, density-consistent and\nflexible solutions, we propose to extract all the reliable linkages at each\nstep, instead of the smallest one. This leads to a new agglomerative clustering\nstrategy, called reliable agglomerative clustering, which similar to the\nstandard agglomerative variant can be applied with all common criteria.\nMoreover, we prove that this strategy with the single linkage criterion yields\na minimum spanning tree algorithm. We perform experiments on several real-world\ndatasets to demonstrate the superior performance of this strategy, compared to\nthe standard alternative.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 11:01:05 GMT"}, {"version": "v2", "created": "Sun, 16 Jun 2019 14:34:46 GMT"}, {"version": "v3", "created": "Sat, 26 Sep 2020 13:10:29 GMT"}, {"version": "v4", "created": "Tue, 29 Sep 2020 21:49:24 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Chehreghani", "Morteza Haghir", ""]]}, {"id": "1901.02070", "submitter": "Chiyu Jiang", "authors": "Chiyu \"Max\" Jiang, Dequan Wang, Jingwei Huang, Philip Marcus, Matthias\n  Nie{\\ss}ner", "title": "Convolutional Neural Networks on non-uniform geometrical signals using\n  Euclidean spectral transformation", "comments": "Accepted as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CG cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) have been successful in processing data\nsignals that are uniformly sampled in the spatial domain (e.g., images).\nHowever, most data signals do not natively exist on a grid, and in the process\nof being sampled onto a uniform physical grid suffer significant aliasing error\nand information loss. Moreover, signals can exist in different topological\nstructures as, for example, points, lines, surfaces and volumes. It has been\nchallenging to analyze signals with mixed topologies (for example, point cloud\nwith surface mesh). To this end, we develop mathematical formulations for\nNon-Uniform Fourier Transforms (NUFT) to directly, and optimally, sample\nnonuniform data signals of different topologies defined on a simplex mesh into\nthe spectral domain with no spatial sampling error. The spectral transform is\nperformed in the Euclidean space, which removes the translation ambiguity from\nworks on the graph spectrum. Our representation has four distinct advantages:\n(1) the process causes no spatial sampling error during the initial sampling,\n(2) the generality of this approach provides a unified framework for using CNNs\nto analyze signals of mixed topologies, (3) it allows us to leverage\nstate-of-the-art backbone CNN architectures for effective learning without\nhaving to design a particular architecture for a particular data structure in\nan ad-hoc fashion, and (4) the representation allows weighted meshes where each\nelement has a different weight (i.e., texture) indicating local properties. We\nachieve results on par with the state-of-the-art for the 3D shape retrieval\ntask, and a new state-of-the-art for the point cloud to surface reconstruction\ntask.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 21:23:33 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Jiang", "Chiyu \"Max\"", ""], ["Wang", "Dequan", ""], ["Huang", "Jingwei", ""], ["Marcus", "Philip", ""], ["Nie\u00dfner", "Matthias", ""]]}, {"id": "1901.02104", "submitter": "Hanie Sedghi", "authors": "Philip M. Long and Hanie Sedghi", "title": "On the effect of the activation function on the distribution of hidden\n  nodes in a deep network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the joint probability distribution on the lengths of the vectors\nof hidden variables in different layers of a fully connected deep network, when\nthe weights and biases are chosen randomly according to Gaussian distributions,\nand the input is in $\\{ -1, 1\\}^N$. We show that, if the activation function\n$\\phi$ satisfies a minimal set of assumptions, satisfied by all activation\nfunctions that we know that are used in practice, then, as the width of the\nnetwork gets large, the `length process' converges in probability to a length\nmap that is determined as a simple function of the variances of the random\nweights and biases, and the activation function $\\phi$. We also show that this\nconvergence may fail for $\\phi$ that violate our assumptions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 23:33:14 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Long", "Philip M.", ""], ["Sedghi", "Hanie", ""]]}, {"id": "1901.02219", "submitter": "Andreas Sedlmeier", "authors": "Andreas Sedlmeier, Thomas Gabor, Thomy Phan, Lenz Belzner, Claudia\n  Linnhoff-Popien", "title": "Uncertainty-Based Out-of-Distribution Detection in Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting out-of-distribution (OOD) samples in\ndeep reinforcement learning. In a value based reinforcement learning setting,\nwe propose to use uncertainty estimation techniques directly on the agent's\nvalue estimating neural network to detect OOD samples. The focus of our work\nlies in analyzing the suitability of approximate Bayesian inference methods and\nrelated ensembling techniques that generate uncertainty estimates. Although\nprior work has shown that dropout-based variational inference techniques and\nbootstrap-based approaches can be used to model epistemic uncertainty, the\nsuitability for detecting OOD samples in deep reinforcement learning remains an\nopen question. Our results show that uncertainty estimation can be used to\ndifferentiate in- from out-of-distribution samples. Over the complete training\nprocess of the reinforcement learning agents, bootstrap-based approaches tend\nto produce more reliable epistemic uncertainty estimates, when compared to\ndropout-based approaches.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 09:41:11 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Sedlmeier", "Andreas", ""], ["Gabor", "Thomas", ""], ["Phan", "Thomy", ""], ["Belzner", "Lenz", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "1901.02307", "submitter": "Nikhil Bhargava", "authors": "Nikhil Bhargava, Brian Williams", "title": "Complexity Bounds for the Controllability of Temporal Networks with\n  Conditions, Disjunctions, and Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In temporal planning, many different temporal network formalisms are used to\nmodel real world situations. Each of these formalisms has different features\nwhich affect how easy it is to determine whether the underlying network of\ntemporal constraints is consistent. While many of the simpler models have been\nwell-studied from a computational complexity perspective, the algorithms\ndeveloped for advanced models which combine features have very loose complexity\nbounds. In this paper, we provide tight completeness bounds for strong, weak,\nand dynamic controllability checking of temporal networks that have conditions,\ndisjunctions, and temporal uncertainty. Our work exposes some of the subtle\ndifferences between these different structures and, remarkably, establishes a\nguarantee that all of these problems are computable in PSPACE.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 13:47:12 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Bhargava", "Nikhil", ""], ["Williams", "Brian", ""]]}, {"id": "1901.02322", "submitter": "Philipp Blandfort", "authors": "Philipp Blandfort, Tushar Karayil, Federico Raue, J\\\"orn Hees, Andreas\n  Dengel", "title": "Fusion Strategies for Learning User Embeddings with Neural Networks", "comments": "submitted to IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Growing amounts of online user data motivate the need for automated\nprocessing techniques. In case of user ratings, one interesting option is to\nuse neural networks for learning to predict ratings given an item and a user.\nWhile training for prediction, such an approach at the same time learns to map\neach user to a vector, a so-called user embedding. Such embeddings can for\nexample be valuable for estimating user similarity. However, there are various\nways how item and user information can be combined in neural networks, and it\nis unclear how the way of combining affects the resulting embeddings. In this\npaper, we run an experiment on movie ratings data, where we analyze the effect\non embedding quality caused by several fusion strategies in neural networks.\nFor evaluating embedding quality, we propose a novel measure, Pair-Distance\nCorrelation, which quantifies the condition that similar users should have\nsimilar embedding vectors. We find that the fusion strategy affects results in\nterms of both prediction performance and embedding quality. Surprisingly, we\nfind that prediction performance not necessarily reflects embedding quality.\nThis suggests that if embeddings are of interest, the common tendency to select\nmodels based on their prediction ability should be reconsidered.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 14:24:43 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Blandfort", "Philipp", ""], ["Karayil", "Tushar", ""], ["Raue", "Federico", ""], ["Hees", "J\u00f6rn", ""], ["Dengel", "Andreas", ""]]}, {"id": "1901.02354", "submitter": "Xiao Dong", "authors": "Xiao Dong, Ling Zhou", "title": "Geometrization of deep networks for the interpretability of deep\n  learning systems", "comments": "9 pages, draft version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to understand deep learning systems remains an open problem. In this\npaper we propose that the answer may lie in the geometrization of deep\nnetworks. Geometrization is a bridge to connect physics, geometry, deep network\nand quantum computation and this may result in a new scheme to reveal the rule\nof the physical world. By comparing the geometry of image matching and deep\nnetworks, we show that geometrization of deep networks can be used to\nunderstand existing deep learning systems and it may also help to solve the\ninterpretability problem of deep learning systems.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 14:32:45 GMT"}, {"version": "v2", "created": "Sun, 13 Jan 2019 17:20:05 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Dong", "Xiao", ""], ["Zhou", "Ling", ""]]}, {"id": "1901.02358", "submitter": "Aditya Kusupati", "authors": "Aditya Kusupati, Manish Singh, Kush Bhatia, Ashish Kumar, Prateek Jain\n  and Manik Varma", "title": "FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated\n  Recurrent Neural Network", "comments": "23 pages, 10 figures, Published at Advances in Neural Information\n  Processing Systems (NeurIPS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops the FastRNN and FastGRNN algorithms to address the twin\nRNN limitations of inaccurate training and inefficient prediction. Previous\napproaches have improved accuracy at the expense of prediction costs making\nthem infeasible for resource-constrained and real-time applications. Unitary\nRNNs have increased accuracy somewhat by restricting the range of the state\ntransition matrix's singular values but have also increased the model size as\nthey require a larger number of hidden units to make up for the loss in\nexpressive power. Gated RNNs have obtained state-of-the-art accuracies by\nadding extra parameters thereby resulting in even larger models. FastRNN\naddresses these limitations by adding a residual connection that does not\nconstrain the range of the singular values explicitly and has only two extra\nscalar parameters. FastGRNN then extends the residual connection to a gate by\nreusing the RNN matrices to match state-of-the-art gated RNN accuracies but\nwith a 2-4x smaller model. Enforcing FastGRNN's matrices to be low-rank, sparse\nand quantized resulted in accurate models that could be up to 35x smaller than\nleading gated and unitary RNNs. This allowed FastGRNN to accurately recognize\nthe \"Hey Cortana\" wakeword with a 1 KB model and to be deployed on severely\nresource-constrained IoT microcontrollers too tiny to store other RNN models.\nFastGRNN's code is available at https://github.com/Microsoft/EdgeML/.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 15:19:13 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Kusupati", "Aditya", ""], ["Singh", "Manish", ""], ["Bhatia", "Kush", ""], ["Kumar", "Ashish", ""], ["Jain", "Prateek", ""], ["Varma", "Manik", ""]]}, {"id": "1901.02404", "submitter": "Ori Bar El", "authors": "Ori Bar El, Ori Licht, Netanel Yosephian", "title": "GILT: Generating Images from Long Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating an image reflecting the content of a long text is a complex process\nthat requires a sense of creativity. For example, creating a book cover or a\nmovie poster based on their summary or a food image based on its recipe. In\nthis paper we present the new task of generating images from long text that\ndoes not describe the visual content of the image directly. For this, we build\na system for generating high-resolution 256 $\\times$ 256 images of food\nconditioned on their recipes. The relation between the recipe text (without its\ntitle) to the visual content of the image is vague, and the textual structure\nof recipes is complex, consisting of two sections (ingredients and\ninstructions) both containing multiple sentences.\n  We used the recipe1M dataset to train and evaluate our model that is based on\na the StackGAN-v2 architecture.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 16:59:46 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["El", "Ori Bar", ""], ["Licht", "Ori", ""], ["Yosephian", "Netanel", ""]]}, {"id": "1901.02412", "submitter": "Ritwik Sinha", "authors": "Ritwik Sinha, Dhruv Singal, Pranav Maneriker, Kushal Chawla, Yash\n  Shrivastava, Deepak Pai, Atanu R Sinha", "title": "Forecasting Granular Audience Size for Online Advertising", "comments": "Published at AdKDD & TargetAd 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orchestration of campaigns for online display advertising requires marketers\nto forecast audience size at the granularity of specific attributes of web\ntraffic, characterized by the categorical nature of all attributes (e.g. {US,\nChrome, Mobile}). With each attribute taking many values, the very large\nattribute combination set makes estimating audience size for any specific\nattribute combination challenging. We modify Eclat, a frequent itemset mining\n(FIM) algorithm, to accommodate categorical variables. For consequent frequent\nand infrequent itemsets, we then provide forecasts using time series analysis\nwith conditional probabilities to aid approximation. An extensive simulation,\nbased on typical characteristics of audience data, is built to stress test our\nmodified-FIM approach. In two real datasets, comparison with baselines\nincluding neural network models, shows that our method lowers computation time\nof FIM for categorical data. On hold out samples we show that the proposed\nforecasting method outperforms these baselines.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 17:13:51 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Sinha", "Ritwik", ""], ["Singal", "Dhruv", ""], ["Maneriker", "Pranav", ""], ["Chawla", "Kushal", ""], ["Shrivastava", "Yash", ""], ["Pai", "Deepak", ""], ["Sinha", "Atanu R", ""]]}, {"id": "1901.02420", "submitter": "Cristina Cornelio PhD", "authors": "Cristina Cornelio, Lucrezia Furian, Antonio Nicolo' and Francesca\n  Rossi", "title": "Using deceased-donor kidneys to initiate chains of living donor kidney\n  paired donations: algorithms and experimentation", "comments": "To be published in AIES 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.TO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a flexible algorithm that exploits deceased donor kidneys to\ninitiate chains of living donor kidney paired donations, combining deceased and\nliving donor allocation mechanisms to improve the quantity and quality of\nkidney transplants. The advantages of this approach have been measured using\nretrospective data on the pool of donor/recipient incompatible and desensitized\npairs at the Padua University Hospital, the largest center for living donor\nkidney transplants in Italy. The experiments show a remarkable improvement on\nthe number of patients with incompatible donor who could be transplanted, a\ndecrease in the number of desensitization procedures, and an increase in the\nnumber of UT patients (that is, patients unlikely to be transplanted for\nimmunological reasons) in the waiting list who could receive an organ.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 15:56:18 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Cornelio", "Cristina", ""], ["Furian", "Lucrezia", ""], ["Nicolo'", "Antonio", ""], ["Rossi", "Francesca", ""]]}, {"id": "1901.02522", "submitter": "Daniel Khashabi Mr.", "authors": "Daniel Khashabi, Erfan Sadeqi Azer, Tushar Khot, Ashish Sabharwal, Dan\n  Roth", "title": "On the Possibilities and Limitations of Multi-hop Reasoning Under\n  Linguistic Imperfections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems for language understanding have become remarkably strong at\novercoming linguistic imperfections in tasks involving phrase matching or\nsimple reasoning. Yet, their accuracy drops dramatically as the number of\nreasoning steps increases. We present the first formal framework to study such\nempirical observations. It allows one to quantify the amount and effect of\nambiguity, redundancy, incompleteness, and inaccuracy that the use of language\nintroduces when representing a hidden conceptual space. The idea is to consider\ntwo interrelated spaces: a conceptual meaning space that is unambiguous and\ncomplete but hidden, and a linguistic space that captures a noisy grounding of\nthe meaning space in the words of a language---the level at which all systems,\nwhether neural or symbolic, operate. Applying this framework to a special class\nof multi-hop reasoning, namely the connectivity problem in graphs of\nrelationships between concepts, we derive rigorous intuitions and impossibility\nresults even under this simplified setting. For instance, if a query requires a\nmoderately large (logarithmic) number of hops in the meaning graph, no\nreasoning system operating over a noisy graph grounded in language is likely to\ncorrectly answer it. This highlights a fundamental barrier that extends to a\nbroader class of reasoning problems and systems, and suggests an alternative\npath forward: focusing on aligning the two spaces via richer representations,\nbefore investing in reasoning with many hops.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 21:19:34 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 05:00:14 GMT"}, {"version": "v3", "created": "Fri, 1 May 2020 04:43:45 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Khashabi", "Daniel", ""], ["Azer", "Erfan Sadeqi", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Roth", "Dan", ""]]}, {"id": "1901.02527", "submitter": "Dong Huk Park", "authors": "Dong Huk Park, Trevor Darrell, Anna Rohrbach", "title": "Robust Change Captioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Describing what has changed in a scene can be useful to a user, but only if\ngenerated text focuses on what is semantically relevant. It is thus important\nto distinguish distractors (e.g. a viewpoint change) from relevant changes\n(e.g. an object has moved). We present a novel Dual Dynamic Attention Model\n(DUDA) to perform robust Change Captioning. Our model learns to distinguish\ndistractors from semantic changes, localize the changes via Dual Attention over\n\"before\" and \"after\" images, and accurately describe them in natural language\nvia Dynamic Speaker, by adaptively focusing on the necessary visual inputs\n(e.g. \"before\" or \"after\" image). To study the problem in depth, we collect a\nCLEVR-Change dataset, built off the CLEVR engine, with 5 types of scene\nchanges. We benchmark a number of baselines on our dataset, and systematically\nstudy different change types and robustness to distractors. We show the\nsuperiority of our DUDA model in terms of both change captioning and\nlocalization. We also show that our approach is general, obtaining\nstate-of-the-art results on the recent realistic Spot-the-Diff dataset which\nhas no distractors.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 21:29:42 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 00:18:00 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Park", "Dong Huk", ""], ["Darrell", "Trevor", ""], ["Rohrbach", "Anna", ""]]}, {"id": "1901.02543", "submitter": "Shlomo Argamon", "authors": "Shlomo Engelson Argamon", "title": "Computational Register Analysis and Synthesis", "comments": "A version of this article is to appear in Register Studies, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of register in computational language research has historically\nbeen divided into register analysis, seeking to determine the registerial\ncharacter of a text or corpus, and register synthesis, seeking to generate a\ntext in a desired register. This article surveys the different approaches to\nthese disparate tasks. Register synthesis has tended to use more theoretically\narticulated notions of register and genre than analysis work, which often seeks\nto categorize on the basis of intuitive and somewhat incoherent notions of\nprelabeled 'text types'. I argue that an integration of computational register\nanalysis and synthesis will benefit register studies as a whole, by enabling a\nnew large-scale research program in register studies. It will enable\ncomprehensive global mapping of functional language varieties in multiple\nlanguages, including the relationships between them. Furthermore, computational\nmethods together with high coverage systematically collected and analyzed data\nwill thus enable rigorous empirical validation and refinement of different\ntheories of register, which will have also implications for our understanding\nof linguistic variation in general.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 22:35:03 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Argamon", "Shlomo Engelson", ""]]}, {"id": "1901.02565", "submitter": "Maxwell Crouse", "authors": "Maxwell Crouse, Achille Fokoue, Maria Chang, Pavan Kapanipathi, Ryan\n  Musa, Constantine Nakos, Lingfei Wu, Kenneth Forbus, Michael Witbrock", "title": "High-Fidelity Vector Space Models of Structured Data", "comments": "updated to reflect conference submission, new experiment added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems regularly deal with structured data in real-world\napplications. Unfortunately, such data has been difficult to faithfully\nrepresent in a way that most machine learning techniques would expect, i.e. as\na real-valued vector of a fixed, pre-specified size. In this work, we introduce\na novel approach that compiles structured data into a satisfiability problem\nwhich has in its set of solutions at least (and often only) the input data. The\nsatisfiability problem is constructed from constraints which are generated\nautomatically a priori from a given signature, thus trivially allowing for a\nbag-of-words-esque vector representation of the input to be constructed. The\nmethod is demonstrated in two areas, automated reasoning and natural language\nprocessing, where it is shown to produce vector representations of\nnatural-language sentences and first-order logic clauses that can be precisely\ntranslated back to their original, structured input forms.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 00:26:00 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 14:03:52 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Crouse", "Maxwell", ""], ["Fokoue", "Achille", ""], ["Chang", "Maria", ""], ["Kapanipathi", "Pavan", ""], ["Musa", "Ryan", ""], ["Nakos", "Constantine", ""], ["Wu", "Lingfei", ""], ["Forbus", "Kenneth", ""], ["Witbrock", "Michael", ""]]}, {"id": "1901.02577", "submitter": "Apoorva Sharma", "authors": "Apoorva Sharma, James Harrison, Matthew Tsao, Marco Pavone", "title": "Robust and Adaptive Planning under Model Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning under model uncertainty is a fundamental problem across many\napplications of decision making and learning. In this paper, we propose the\nRobust Adaptive Monte Carlo Planning (RAMCP) algorithm, which allows\ncomputation of risk-sensitive Bayes-adaptive policies that optimally trade off\nexploration, exploitation, and robustness. RAMCP formulates the risk-sensitive\nplanning problem as a two-player zero-sum game, in which an adversary perturbs\nthe agent's belief over the models. We introduce two versions of the RAMCP\nalgorithm. The first, RAMCP-F, converges to an optimal risk-sensitive policy\nwithout having to rebuild the search tree as the underlying belief over models\nis perturbed. The second version, RAMCP-I, improves computational efficiency at\nthe cost of losing theoretical guarantees, but is shown to yield empirical\nresults comparable to RAMCP-F. RAMCP is demonstrated on an n-pull multi-armed\nbandit problem, as well as a patient treatment scenario.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 01:32:43 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Sharma", "Apoorva", ""], ["Harrison", "James", ""], ["Tsao", "Matthew", ""], ["Pavone", "Marco", ""]]}, {"id": "1901.02703", "submitter": "Zhaohong Deng", "authors": "Peng Xu, Zhaohong Deng, Jun Wang, Qun Zhang, Shitong Wang", "title": "Transfer Representation Learning with TSK Fuzzy System", "comments": "More interpretable feature transfer learning method with rules, which\n  has been submited to IEEE Trans. Fuzzy Systems in Sept. 27 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning can address the learning tasks of unlabeled data in the\ntarget domain by leveraging plenty of labeled data from a different but related\nsource domain. A core issue in transfer learning is to learn a shared feature\nspace in where the distributions of the data from two domains are matched. This\nlearning process can be named as transfer representation learning (TRL). The\nfeature transformation methods are crucial to ensure the success of TRL. The\nmost commonly used feature transformation method in TRL is kernel-based\nnonlinear mapping to the high-dimensional space followed by linear\ndimensionality reduction. But the kernel functions are lack of interpretability\nand are difficult to be selected. To this end, the TSK fuzzy system (TSK-FS) is\ncombined with transfer learning and a more intuitive and interpretable modeling\nmethod, called transfer representation learning with TSK-FS (TRL-TSK-FS) is\nproposed in this paper. Specifically, TRL-TSK-FS realizes TRL from two aspects.\nOn one hand, the data in the source and target domains are transformed into the\nfuzzy feature space in which the distribution distance of the data between two\ndomains is min-imized. On the other hand, discriminant information and\ngeo-metric properties of the data are preserved by linear discriminant analysis\nand principal component analysis. In addition, another advantage arises with\nthe proposed method, that is, the nonlinear transformation is realized by\nconstructing fuzzy mapping with the antecedent part of the TSK-FS instead of\nkernel functions which are difficult to be selected. Extensive experiments are\nconducted on the text and image datasets. The results obviously show the\nsuperiority of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 12:55:10 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Xu", "Peng", ""], ["Deng", "Zhaohong", ""], ["Wang", "Jun", ""], ["Zhang", "Qun", ""], ["Wang", "Shitong", ""]]}, {"id": "1901.02705", "submitter": "Mikael Henaff", "authors": "Mikael Henaff, Alfredo Canziani and Yann LeCun", "title": "Model-Predictive Policy Learning with Uncertainty Regularization for\n  Driving in Dense Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a policy using only observational data is challenging because the\ndistribution of states it induces at execution time may differ from the\ndistribution observed during training. We propose to train a policy by\nunrolling a learned model of the environment dynamics over multiple time steps\nwhile explicitly penalizing two costs: the original cost the policy seeks to\noptimize, and an uncertainty cost which represents its divergence from the\nstates it is trained on. We measure this second cost by using the uncertainty\nof the dynamics model about its own predictions, using recent ideas from\nuncertainty estimation for deep networks. We evaluate our approach using a\nlarge-scale observational dataset of driving behavior recorded from traffic\ncameras, and show that we are able to learn effective driving policies from\npurely observational data, with no environment interaction.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 00:39:21 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Henaff", "Mikael", ""], ["Canziani", "Alfredo", ""], ["LeCun", "Yann", ""]]}, {"id": "1901.02839", "submitter": "Jean Kossaifi", "authors": "Jean Kossaifi, Robert Walecki, Yannis Panagakis, Jie Shen, Maximilian\n  Schmitt, Fabien Ringeval, Jing Han, Vedhas Pandit, Antoine Toisoul, Bjorn\n  Schuller, Kam Star, Elnar Hajiyev and Maja Pantic", "title": "SEWA DB: A Rich Database for Audio-Visual Emotion and Sentiment Research\n  in the Wild", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  (TPAMI), 2019", "doi": "10.1109/TPAMI.2019.2944808", "report-no": null, "categories": "cs.HC cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural human-computer interaction and audio-visual human behaviour sensing\nsystems, which would achieve robust performance in-the-wild are more needed\nthan ever as digital devices are increasingly becoming an indispensable part of\nour life. Accurately annotated real-world data are the crux in devising such\nsystems. However, existing databases usually consider controlled settings, low\ndemographic variability, and a single task. In this paper, we introduce the\nSEWA database of more than 2000 minutes of audio-visual data of 398 people\ncoming from six cultures, 50% female, and uniformly spanning the age range of\n18 to 65 years old. Subjects were recorded in two different contexts: while\nwatching adverts and while discussing adverts in a video chat. The database\nincludes rich annotations of the recordings in terms of facial landmarks,\nfacial action units (FAU), various vocalisations, mirroring, and continuously\nvalued valence, arousal, liking, agreement, and prototypic examples of\n(dis)liking. This database aims to be an extremely valuable resource for\nresearchers in affective computing and automatic human sensing and is expected\nto push forward the research in human behaviour analysis, including cultural\nstudies. Along with the database, we provide extensive baseline experiments for\nautomatic FAU detection and automatic valence, arousal and (dis)liking\nintensity estimation.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 17:28:57 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 22:52:44 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Kossaifi", "Jean", ""], ["Walecki", "Robert", ""], ["Panagakis", "Yannis", ""], ["Shen", "Jie", ""], ["Schmitt", "Maximilian", ""], ["Ringeval", "Fabien", ""], ["Han", "Jing", ""], ["Pandit", "Vedhas", ""], ["Toisoul", "Antoine", ""], ["Schuller", "Bjorn", ""], ["Star", "Kam", ""], ["Hajiyev", "Elnar", ""], ["Pantic", "Maja", ""]]}, {"id": "1901.02868", "submitter": "Paulo Vitor Campos Souza", "authors": "Lucas Oliveira Batista, Gabriel Adriano de Silva, Vanessa Souza\n  Ara\\'ujo, Vin\\'icius Jonathan Silva Ara\\'ujo, Thiago Silva Rezende, Augusto\n  Junio Guimar\\~aes, Paulo Vitor de Campos Souza", "title": "Fuzzy neural networks to create an expert system for detecting attacks\n  by SQL Injection", "comments": null, "journal-ref": "The International Journal of Forensic Computer Science, Volume 13,\n  Number 1, pages 8-21, 2018", "doi": "10.5769/J201801001", "report-no": null, "categories": "cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Its constant technological evolution characterizes the contemporary world,\nand every day the processes, once manual, become computerized. Data are stored\nin the cyberspace, and as a consequence, one must increase the concern with the\nsecurity of this environment. Cyber-attacks are represented by a growing\nworldwide scale and are characterized as one of the significant challenges of\nthe century. This article aims to propose a computational system based on\nintelligent hybrid models, which through fuzzy rules allows the construction of\nexpert systems in cybernetic data attacks, focusing on the SQL Injection\nattack. The tests were performed with real bases of SQL Injection attacks on\ngovernment computers, using fuzzy neural networks. According to the results\nobtained, the feasibility of constructing a system based on fuzzy rules, with\nthe classification accuracy of cybernetic invasions within the margin of the\nstandard deviation (compared to the state-of-the-art model in solving this type\nof problem) is real. The model helps countries prepare to protect their data\nnetworks and information systems, as well as create opportunities for expert\nsystems to automate the identification of attacks in cyberspace.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 18:41:56 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Batista", "Lucas Oliveira", ""], ["de Silva", "Gabriel Adriano", ""], ["Ara\u00fajo", "Vanessa Souza", ""], ["Ara\u00fajo", "Vin\u00edcius Jonathan Silva", ""], ["Rezende", "Thiago Silva", ""], ["Guimar\u00e3es", "Augusto Junio", ""], ["Souza", "Paulo Vitor de Campos", ""]]}, {"id": "1901.02875", "submitter": "Jiajun Wu", "authors": "Yonglong Tian, Andrew Luo, Xingyuan Sun, Kevin Ellis, William T.\n  Freeman, Joshua B. Tenenbaum, Jiajun Wu", "title": "Learning to Infer and Execute 3D Shape Programs", "comments": "ICLR 2019. Project page: http://shape2prog.csail.mit.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human perception of 3D shapes goes beyond reconstructing them as a set of\npoints or a composition of geometric primitives: we also effortlessly\nunderstand higher-level shape structure such as the repetition and reflective\nsymmetry of object parts. In contrast, recent advances in 3D shape sensing\nfocus more on low-level geometry but less on these higher-level relationships.\nIn this paper, we propose 3D shape programs, integrating bottom-up recognition\nsystems with top-down, symbolic program structure to capture both low-level\ngeometry and high-level structural priors for 3D shapes. Because there are no\nannotations of shape programs for real shapes, we develop neural modules that\nnot only learn to infer 3D shape programs from raw, unannotated shapes, but\nalso to execute these programs for shape reconstruction. After initial\nbootstrapping, our end-to-end differentiable model learns 3D shape programs by\nreconstructing shapes in a self-supervised manner. Experiments demonstrate that\nour model accurately infers and executes 3D shape programs for highly complex\nshapes from various categories. It can also be integrated with an\nimage-to-shape module to infer 3D shape programs directly from an RGB image,\nleading to 3D shape reconstructions that are both more accurate and more\nphysically plausible.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 18:55:03 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 19:37:26 GMT"}, {"version": "v3", "created": "Fri, 9 Aug 2019 23:07:36 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Tian", "Yonglong", ""], ["Luo", "Andrew", ""], ["Sun", "Xingyuan", ""], ["Ellis", "Kevin", ""], ["Freeman", "William T.", ""], ["Tenenbaum", "Joshua B.", ""], ["Wu", "Jiajun", ""]]}, {"id": "1901.02884", "submitter": "Philipp V. Rouast", "authors": "Philipp V. Rouast, Marc T. P. Adam, and Raymond Chiong", "title": "Deep Learning for Human Affect Recognition: Insights and New\n  Developments", "comments": "To be published in IEEE Transactions on Affective Computing. 20\n  pages, 7 figures, 6 tables", "journal-ref": null, "doi": "10.1109/TAFFC.2018.2890471", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic human affect recognition is a key step towards more natural\nhuman-computer interaction. Recent trends include recognition in the wild using\na fusion of audiovisual and physiological sensors, a challenging setting for\nconventional machine learning algorithms. Since 2010, novel deep learning\nalgorithms have been applied increasingly in this field. In this paper, we\nreview the literature on human affect recognition between 2010 and 2017, with a\nspecial focus on approaches using deep neural networks. By classifying a total\nof 950 studies according to their usage of shallow or deep architectures, we\nare able to show a trend towards deep learning. Reviewing a subset of 233\nstudies that employ deep neural networks, we comprehensively quantify their\napplications in this field. We find that deep learning is used for learning of\n(i) spatial feature representations, (ii) temporal feature representations, and\n(iii) joint feature representations for multimodal sensor data. Exemplary\nstate-of-the-art architectures illustrate the progress. Our findings show the\nrole deep architectures will play in human affect recognition, and can serve as\na reference point for researchers working on related applications.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 23:33:47 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Rouast", "Philipp V.", ""], ["Adam", "Marc T. P.", ""], ["Chiong", "Raymond", ""]]}, {"id": "1901.02918", "submitter": "Barry Smith", "authors": "Jobst Landgrebe and Barry Smith", "title": "Making AI meaningful again", "comments": "23 pages, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) research enjoyed an initial period of enthusiasm\nin the 1970s and 80s. But this enthusiasm was tempered by a long interlude of\nfrustration when genuinely useful AI applications failed to be forthcoming.\nToday, we are experiencing once again a period of enthusiasm, fired above all\nby the successes of the technology of deep neural networks or deep machine\nlearning. In this paper we draw attention to what we take to be serious\nproblems underlying current views of artificial intelligence encouraged by\nthese successes, especially in the domain of language processing. We then show\nan alternative approach to language-centric AI, in which we identify a role for\nphilosophy.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 20:16:44 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 11:07:26 GMT"}, {"version": "v3", "created": "Sat, 23 Mar 2019 06:17:08 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Landgrebe", "Jobst", ""], ["Smith", "Barry", ""]]}, {"id": "1901.02920", "submitter": "Tao Sun", "authors": "Tao Sun, Zhewei Wang, C. D. Smith, Jundong Liu", "title": "TraceCaps: A Capsule-based Neural Network for Semantic Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a capsule-based neural network model to solve the\nsemantic segmentation problem. By taking advantage of the extractable\npart-whole dependencies available in capsule layers, we derive the\nprobabilities of the class labels for individual capsules through a recursive,\nlayer-by-layer procedure. We model this procedure as a traceback pipeline and\ntake it as a central piece to build an end-to-end segmentation network. Under\nthe proposed framework, image-level class labels and object boundaries are\njointly sought in an explicit manner, which poses a significant advantage over\nthe state-of-the-art fully convolutional network (FCN) solutions. With the\ncapability to extracted part-whole information, our traceback pipeline can\npotentially be utilized as the building blocks to design interpretable neural\nnetworks. Experiments conducted on modified MNIST and neuroimages demonstrate\nthat our model considerably enhance the segmentation performance compared to\nthe leading FCN variants.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 20:23:13 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 19:22:44 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Sun", "Tao", ""], ["Wang", "Zhewei", ""], ["Smith", "C. D.", ""], ["Liu", "Jundong", ""]]}, {"id": "1901.02999", "submitter": "Chang-Shing Lee", "authors": "Chang-Shing Lee, Mei-Hui Wang, Li-Wei Ko, Bo-Yu Tsai, Yi-Lin Tsai,\n  Sheng-Chi Yang, Lu-An Lin, Yi-Hsiu Lee, Hirofumi Ohashi, Naoyuki Kubota, and\n  Nan Shuo", "title": "PFML-based Semantic BCI Agent for Game of Go Learning and Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a semantic brain computer interface (BCI) agent with\nparticle swarm optimization (PSO) based on a Fuzzy Markup Language (FML) for Go\nlearning and prediction applications. Additionally, we also establish an Open\nGo Darkforest (OGD) cloud platform with Facebook AI research (FAIR) open source\nDarkforest and ELF OpenGo AI bots. The Japanese robot Palro will simultaneously\npredict the move advantage in the board game Go to the Go players for reference\nor learning. The proposed semantic BCI agent operates efficiently by the\nhuman-based BCI data from their brain waves and machine-based game data from\nthe prediction of the OGD cloud platform for optimizing the parameters between\nhumans and machines. Experimental results show that the proposed human and\nsmart machine co-learning mechanism performs favorably. We hope to provide\nstudents with a better online learning environment, combining different kinds\nof handheld devices, robots, or computer equipment, to achieve a desired and\nintellectual learning goal in the future.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 02:32:26 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Lee", "Chang-Shing", ""], ["Wang", "Mei-Hui", ""], ["Ko", "Li-Wei", ""], ["Tsai", "Bo-Yu", ""], ["Tsai", "Yi-Lin", ""], ["Yang", "Sheng-Chi", ""], ["Lin", "Lu-An", ""], ["Lee", "Yi-Hsiu", ""], ["Ohashi", "Hirofumi", ""], ["Kubota", "Naoyuki", ""], ["Shuo", "Nan", ""]]}, {"id": "1901.03035", "submitter": "Chih-Yao Ma", "authors": "Chih-Yao Ma, Jiasen Lu, Zuxuan Wu, Ghassan AlRegib, Zsolt Kira,\n  Richard Socher, Caiming Xiong", "title": "Self-Monitoring Navigation Agent via Auxiliary Progress Estimation", "comments": "ICLR 2019, code is available at\n  https://github.com/chihyaoma/selfmonitoring-agent", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Vision-and-Language Navigation (VLN) task entails an agent following\nnavigational instruction in photo-realistic unknown environments. This\nchallenging task demands that the agent be aware of which instruction was\ncompleted, which instruction is needed next, which way to go, and its\nnavigation progress towards the goal. In this paper, we introduce a\nself-monitoring agent with two complementary components: (1) visual-textual\nco-grounding module to locate the instruction completed in the past, the\ninstruction required for the next action, and the next moving direction from\nsurrounding images and (2) progress monitor to ensure the grounded instruction\ncorrectly reflects the navigation progress. We test our self-monitoring agent\non a standard benchmark and analyze our proposed approach through a series of\nablation studies that elucidate the contributions of the primary components.\nUsing our proposed method, we set the new state of the art by a significant\nmargin (8% absolute increase in success rate on the unseen test set). Code is\navailable at https://github.com/chihyaoma/selfmonitoring-agent .\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 06:46:50 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Ma", "Chih-Yao", ""], ["Lu", "Jiasen", ""], ["Wu", "Zuxuan", ""], ["AlRegib", "Ghassan", ""], ["Kira", "Zsolt", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "1901.03162", "submitter": "Artemij Amiranashvili", "authors": "Artemij Amiranashvili, Alexey Dosovitskiy, Vladlen Koltun, Thomas Brox", "title": "Motion Perception in Reinforcement Learning with Dynamic Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In dynamic environments, learned controllers are supposed to take motion into\naccount when selecting the action to be taken. However, in existing\nreinforcement learning works motion is rarely treated explicitly; it is rather\nassumed that the controller learns the necessary motion representation from\ntemporal stacks of frames implicitly. In this paper, we show that for\ncontinuous control tasks learning an explicit representation of motion improves\nthe quality of the learned controller in dynamic scenarios. We demonstrate this\non common benchmark tasks (Walker, Swimmer, Hopper), on target reaching and\nball catching tasks with simulated robotic arms, and on a dynamic single ball\njuggling task. Moreover, we find that when equipped with an appropriate network\narchitecture, the agent can, on some tasks, learn motion features also with\npure reinforcement learning, without additional supervision. Further we find\nthat using an image difference between the current and the previous frame as an\nadditional input leads to better results than a temporal stack of frames.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 13:59:19 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 15:30:32 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Amiranashvili", "Artemij", ""], ["Dosovitskiy", "Alexey", ""], ["Koltun", "Vladlen", ""], ["Brox", "Thomas", ""]]}, {"id": "1901.03253", "submitter": "Robert West", "authors": "Robert West and Eric Horvitz", "title": "Reverse-Engineering Satire, or \"Paper on Computational Humor Accepted\n  Despite Making Serious Advances\"", "comments": "Proceedings of the 33rd AAAI Conference on Artificial Intelligence,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humor is an essential human trait. Efforts to understand humor have called\nout links between humor and the foundations of cognition, as well as the\nimportance of humor in social engagement. As such, it is a promising and\nimportant subject of study, with relevance for artificial intelligence and\nhuman-computer interaction. Previous computational work on humor has mostly\noperated at a coarse level of granularity, e.g., predicting whether an entire\nsentence, paragraph, document, etc., is humorous. As a step toward deep\nunderstanding of humor, we seek fine-grained models of attributes that make a\ngiven text humorous. Starting from the observation that satirical news\nheadlines tend to resemble serious news headlines, we build and analyze a\ncorpus of satirical headlines paired with nearly identical but serious\nheadlines. The corpus is constructed via Unfun.me, an online game that\nincentivizes players to make minimal edits to satirical headlines with the goal\nof making other players believe the results are serious headlines. The edit\noperations used to successfully remove humor pinpoint the words and concepts\nthat play a key role in making the original, satirical headline funny. Our\nanalysis reveals that the humor tends to reside toward the end of headlines,\nand primarily in noun phrases, and that most satirical headlines follow a\ncertain logical pattern, which we term false analogy. Overall, this paper\ndeepens our understanding of the syntactic and semantic structure of satirical\nnews headlines and provides insights for building humor-producing systems.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 16:25:53 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 16:04:31 GMT"}, {"version": "v3", "created": "Tue, 13 Aug 2019 09:35:52 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["West", "Robert", ""], ["Horvitz", "Eric", ""]]}, {"id": "1901.03327", "submitter": "Thanh Thi Nguyen", "authors": "Thanh Thi Nguyen, Ngoc Duy Nguyen, Fernando Bello, Saeid Nahavandi", "title": "A New Tensioning Method using Deep Reinforcement Learning for Surgical\n  Pattern Cutting", "comments": "2019 IEEE International Conference on Industrial Technology (ICIT),\n  Melbourne, Australia (to appear)", "journal-ref": "2019 IEEE International Conference on Industrial Technology (ICIT)", "doi": "10.1109/ICIT.2019.8755235", "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surgeons normally need surgical scissors and tissue grippers to cut through a\ndeformable surgical tissue. The cutting accuracy depends on the skills to\nmanipulate these two tools. Such skills are part of basic surgical skills\ntraining as in the Fundamentals of Laparoscopic Surgery. The gripper is used to\npinch a point on the surgical sheet and pull the tissue to a certain direction\nto maintain the tension while the scissors cut through a trajectory. As the\nsurgical materials are deformable, it requires a comprehensive tensioning\npolicy to yield appropriate tensioning direction at each step of the cutting\nprocess. Automating a tensioning policy for a given cutting trajectory will\nsupport not only the human surgeons but also the surgical robots to improve the\ncutting accuracy and reliability. This paper presents a multiple pinch point\napproach to modelling an autonomous tensioning planner based on a deep\nreinforcement learning algorithm. Experiments on a simulator show that the\nproposed method is superior to existing methods in terms of both performance\nand robustness.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 13:30:46 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Nguyen", "Thanh Thi", ""], ["Nguyen", "Ngoc Duy", ""], ["Bello", "Fernando", ""], ["Nahavandi", "Saeid", ""]]}, {"id": "1901.03559", "submitter": "Mehdi Mirza", "authors": "Arthur Guez, Mehdi Mirza, Karol Gregor, Rishabh Kabra, S\\'ebastien\n  Racani\\`ere, Th\\'eophane Weber, David Raposo, Adam Santoro, Laurent Orseau,\n  Tom Eccles, Greg Wayne, David Silver, Timothy Lillicrap", "title": "An investigation of model-free planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of reinforcement learning (RL) is facing increasingly challenging\ndomains with combinatorial complexity. For an RL agent to address these\nchallenges, it is essential that it can plan effectively. Prior work has\ntypically utilized an explicit model of the environment, combined with a\nspecific planning algorithm (such as tree search). More recently, a new family\nof methods have been proposed that learn how to plan, by providing the\nstructure for planning via an inductive bias in the function approximator (such\nas a tree structured neural network), trained end-to-end by a model-free RL\nalgorithm. In this paper, we go even further, and demonstrate empirically that\nan entirely model-free approach, without special structure beyond standard\nneural network components such as convolutional networks and LSTMs, can learn\nto exhibit many of the characteristics typically associated with a model-based\nplanner. We measure our agent's effectiveness at planning in terms of its\nability to generalize across a combinatorial and irreversible state space, its\ndata efficiency, and its ability to utilize additional thinking time. We find\nthat our agent has many of the characteristics that one might expect to find in\na planning algorithm. Furthermore, it exceeds the state-of-the-art in\nchallenging combinatorial domains such as Sokoban and outperforms other\nmodel-free approaches that utilize strong inductive biases toward planning.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 11:42:51 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 12:39:51 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Guez", "Arthur", ""], ["Mirza", "Mehdi", ""], ["Gregor", "Karol", ""], ["Kabra", "Rishabh", ""], ["Racani\u00e8re", "S\u00e9bastien", ""], ["Weber", "Th\u00e9ophane", ""], ["Raposo", "David", ""], ["Santoro", "Adam", ""], ["Orseau", "Laurent", ""], ["Eccles", "Tom", ""], ["Wayne", "Greg", ""], ["Silver", "David", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1901.03571", "submitter": "Mickael Randour", "authors": "Thomas Brihaye, Florent Delgrange, Youssouf Oualhadj, and Mickael\n  Randour", "title": "Life is Random, Time is Not: Markov Decision Processes with Window\n  Objectives", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 4 (December\n  14, 2020) lmcs:6975", "doi": "10.23638/LMCS-16(4:13)2020", "report-no": null, "categories": "cs.LO cs.AI cs.FL cs.GT math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The window mechanism was introduced by Chatterjee et al. to strengthen\nclassical game objectives with time bounds. It permits to synthesize system\ncontrollers that exhibit acceptable behaviors within a configurable time frame,\nall along their infinite execution, in contrast to the traditional objectives\nthat only require correctness of behaviors in the limit. The window concept has\nproved its interest in a variety of two-player zero-sum games because it\nenables reasoning about such time bounds in system specifications, but also\nthanks to the increased tractability that it usually yields.\n  In this work, we extend the window framework to stochastic environments by\nconsidering Markov decision processes. A fundamental problem in this context is\nthe threshold probability problem: given an objective it aims to synthesize\nstrategies that guarantee satisfying runs with a given probability. We solve it\nfor the usual variants of window objectives, where either the time frame is set\nas a parameter, or we ask if such a time frame exists. We develop a generic\napproach for window-based objectives and instantiate it for the classical\nmean-payoff and parity objectives, already considered in games. Our work paves\nthe way to a wide use of the window mechanism in stochastic models.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 12:20:34 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 16:52:04 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2019 09:11:52 GMT"}, {"version": "v4", "created": "Thu, 2 Apr 2020 13:53:51 GMT"}, {"version": "v5", "created": "Thu, 10 Dec 2020 19:59:49 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Brihaye", "Thomas", ""], ["Delgrange", "Florent", ""], ["Oualhadj", "Youssouf", ""], ["Randour", "Mickael", ""]]}, {"id": "1901.03674", "submitter": "Qi Cai", "authors": "Qi Cai, Mingyi Hong, Yongxin Chen and Zhaoran Wang", "title": "On the Global Convergence of Imitation Learning: A Case for Linear\n  Quadratic Regulator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the global convergence of generative adversarial imitation learning\nfor linear quadratic regulators, which is posed as minimax optimization. To\naddress the challenges arising from non-convex-concave geometry, we analyze the\nalternating gradient algorithm and establish its Q-linear rate of convergence\nto a unique saddle point, which simultaneously recovers the globally optimal\npolicy and reward function. We hope our results may serve as a small step\ntowards understanding and taming the instability in imitation learning as well\nas in more general non-convex-concave alternating minimax optimization that\narises from reinforcement learning and generative adversarial learning.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 17:54:47 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Cai", "Qi", ""], ["Hong", "Mingyi", ""], ["Chen", "Yongxin", ""], ["Wang", "Zhaoran", ""]]}, {"id": "1901.03678", "submitter": "Franz J. Kir\\'aly", "authors": "Viktor Kazakov and Franz J. Kir\\'aly", "title": "Machine Learning Automation Toolbox (MLaut)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present MLaut (Machine Learning AUtomation Toolbox) for the\npython data science ecosystem. MLaut automates large-scale evaluation and\nbenchmarking of machine learning algorithms on a large number of datasets.\nMLaut provides a high-level workflow interface to machine algorithm algorithms,\nimplements a local back-end to a database of dataset collections, trained\nalgorithms, and experimental results, and provides easy-to-use interfaces to\nthe scikit-learn and keras modelling libraries. Experiments are easy to set up\nwith default settings in a few lines of code, while remaining fully\ncustomizable to the level of hyper-parameter tuning, pipeline composition, or\ndeep learning architecture.\n  As a principal test case for MLaut, we conducted a large-scale supervised\nclassification study in order to benchmark the performance of a number of\nmachine learning algorithms - to our knowledge also the first larger-scale\nstudy on standard supervised learning data sets to include deep learning\nalgorithms. While corroborating a number of previous findings in literature, we\nfound (within the limitations of our study) that deep neural networks do not\nperform well on basic supervised learning, i.e., outside the more specialized,\nimage-, audio-, or text-based tasks.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 18:06:05 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Kazakov", "Viktor", ""], ["Kir\u00e1ly", "Franz J.", ""]]}, {"id": "1901.03729", "submitter": "Mark Riedl", "authors": "Upol Ehsan, Pradyumna Tambwekar, Larry Chan, Brent Harrison, Mark\n  Riedl", "title": "Automated Rationale Generation: A Technique for Explainable AI and its\n  Effects on Human Perceptions", "comments": "Accepted to the 2019 International Conference on Intelligent User\n  Interfaces", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated rationale generation is an approach for real-time explanation\ngeneration whereby a computational model learns to translate an autonomous\nagent's internal state and action data representations into natural language.\nTraining on human explanation data can enable agents to learn to generate\nhuman-like explanations for their behavior. In this paper, using the context of\nan agent that plays Frogger, we describe (a) how to collect a corpus of\nexplanations, (b) how to train a neural rationale generator to produce\ndifferent styles of rationales, and (c) how people perceive these rationales.\nWe conducted two user studies. The first study establishes the plausibility of\neach type of generated rationale and situates their user perceptions along the\ndimensions of confidence, humanlike-ness, adequate justification, and\nunderstandability. The second study further explores user preferences between\nthe generated rationales with regard to confidence in the autonomous agent,\ncommunicating failure and unexpected behavior. Overall, we find alignment\nbetween the intended differences in features of the generated rationales and\nthe perceived differences by users. Moreover, context permitting, participants\npreferred detailed rationales to form a stable mental model of the agent's\nbehavior.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 19:55:48 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Ehsan", "Upol", ""], ["Tambwekar", "Pradyumna", ""], ["Chan", "Larry", ""], ["Harrison", "Brent", ""], ["Riedl", "Mark", ""]]}, {"id": "1901.03756", "submitter": "Esube Bekele", "authors": "Esube Bekele and Wallace Lawson", "title": "The Deeper, the Better: Analysis of Person Attributes Recognition", "comments": "8 pages, 34 png figures and 1 pdf figure, uses FG2019.sty, submitted\n  to FG2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In person attributes recognition, we describe a person in terms of their\nappearance. Typically, this includes a wide range of traits including age,\ngender, clothing, and footwear. Although this could be used in a wide variety\nof scenarios, it generally is applied to video surveillance, where attribute\nrecognition is impacted by low resolution, and other issues such as variable\npose, occlusion and shadow. Recent approaches have used deep convolutional\nneural networks (CNNs) to improve the accuracy in person attribute recognition.\nHowever, many of these networks are relatively shallow and it is unclear to\nwhat extent they use contextual cues to improve classification accuracy. In\nthis paper, we propose deeper methods for person attribute recognition.\nInterpreting the reasons behind the classification is highly important, as it\ncan provide insight into how the classifier is making decisions. Interpretation\nsuggests that deeper networks generally take more contextual information into\nconsideration, which helps improve classification accuracy and\ngeneralizability. We present experimental analysis and results for whole body\nattributes using the PA-100K and PETA datasets and facial attributes using the\nCelebA dataset.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 21:52:57 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Bekele", "Esube", ""], ["Lawson", "Wallace", ""]]}, {"id": "1901.03775", "submitter": "Risto Miikkulainen", "authors": "Risto Miikkulainen", "title": "Creative AI Through Evolutionary Computation", "comments": null, "journal-ref": "In Banzhaf et al. (editors), Evolution in Action---Past, Present\n  and Future. New York: Springer. 2020", "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main power of artificial intelligence is not in modeling what we already\nknow, but in creating solutions that are new. Such solutions exist in extremely\nlarge, high-dimensional, and complex search spaces. Population-based search\ntechniques, i.e. variants of evolutionary computation, are well suited to\nfinding them. These techniques are also well positioned to take advantage of\nlarge-scale parallel computing resources, making creative AI through\nevolutionary computation the likely \"next deep learning\".\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 00:26:13 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 23:15:46 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Miikkulainen", "Risto", ""]]}, {"id": "1901.03887", "submitter": "Emanuele Pesce Mr.", "authors": "Emanuele Pesce, Giovanni Montana", "title": "Improving Coordination in Small-Scale Multi-Agent Deep Reinforcement\n  Learning through Memory-driven Communication", "comments": null, "journal-ref": "Machine Learning (2020)", "doi": "10.1007/s10994-019-05864-5", "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning algorithms have recently been used to train\nmultiple interacting agents in a centralised manner whilst keeping their\nexecution decentralised. When the agents can only acquire partial observations\nand are faced with tasks requiring coordination and synchronisation skills,\ninter-agent communication plays an essential role. In this work, we propose a\nframework for multi-agent training using deep deterministic policy gradients\nthat enables concurrent, end-to-end learning of an explicit communication\nprotocol through a memory device. During training, the agents learn to perform\nread and write operations enabling them to infer a shared representation of the\nworld. We empirically demonstrate that concurrent learning of the communication\ndevice and individual policies can improve inter-agent coordination and\nperformance in small-scale systems. Our experimental results show that the\nproposed method achieves superior performance in scenarios with up to six\nagents. We illustrate how different communication patterns can emerge on six\ndifferent tasks of increasing complexity. Furthermore, we study the effects of\ncorrupting the communication channel, provide a visualisation of the\ntime-varying memory content as the underlying task is being solved and validate\nthe building blocks of the proposed memory device through ablation studies.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 18:12:15 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 10:30:21 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 14:36:46 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Pesce", "Emanuele", ""], ["Montana", "Giovanni", ""]]}, {"id": "1901.04011", "submitter": "Basel  Magableh Dr", "authors": "Basel Magableh", "title": "A Deep Recurrent Q Network towards Self-adapting Distributed\n  Microservices architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  One desired aspect of microservices architecture is the ability to self-adapt\nits own architecture and behaviour in response to changes in the operational\nenvironment. To achieve the desired high levels of self-adaptability, this\nresearch implements the distributed microservices architectures model, as\ninformed by the MAPE-K model. The proposed architecture employs a multi\nadaptation agents supported by a centralised controller, that can observe the\nenvironment and execute a suitable adaptation action. The adaptation planning\nis managed by a deep recurrent Q-network (DRQN). It is argued that such\nintegration between DRQN and MDP agents in a MAPE-K model offers distributed\nmicroservice architecture with self-adaptability and high levels of\navailability and scalability. Integrating DRQN into the adaptation process\nimproves the effectiveness of the adaptation and reduces any adaptation risks,\nincluding resources over-provisioning and thrashing. The performance of DRQN is\nevaluated against deep Q-learning and policy gradient algorithms including: i)\ndeep q-network (DQN), ii) dulling deep Q-network (DDQN), iii) a policy gradient\nneural network (PGNN), and iv) deep deterministic policy gradient (DDPG). The\nDRQN implementation in this paper manages to outperform the above mentioned\nalgorithms in terms of total reward, less adaptation time, lower error rates,\nplus faster convergence and training times. We strongly believe that DRQN is\nmore suitable for driving the adaptation in distributed services-oriented\narchitecture and offers better performance than other dynamic decision-making\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 16:22:58 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 03:11:17 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Magableh", "Basel", ""]]}, {"id": "1901.04140", "submitter": "Zihan Zhou", "authors": "Xuehui Sun, Zihan Zhou, Yuda Fan", "title": "Image Based Review Text Generation with Emotional Guidance", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current field of computer vision, automatically generating texts from\ngiven images has been a fully worked technique. Up till now, most works of this\narea focus on image content describing, namely image-captioning. However, rare\nresearches focus on generating product review texts, which is ubiquitous in the\nonline shopping malls and is crucial for online shopping selection and\nevaluation. Different from content describing, review texts include more\nsubjective information of customers, which may bring difference to the results.\nTherefore, we aimed at a new field concerning generating review text from\ncustomers based on images together with the ratings of online shopping\nproducts, which appear as non-image attributes. We made several adjustments to\nthe existing image-captioning model to fit our task, in which we should also\ntake non-image features into consideration. We also did experiments based on\nour model and get effective primary results.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 05:42:51 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Sun", "Xuehui", ""], ["Zhou", "Zihan", ""], ["Fan", "Yuda", ""]]}, {"id": "1901.04199", "submitter": "Ana-Maria Olteteanu", "authors": "Ana-Maria Olteteanu, Zoe Falomir", "title": "Proceedings of the 2nd Symposium on Problem-solving, Creativity and\n  Spatial Reasoning in Cognitive Systems, ProSocrates 2017", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This book contains the accepted papers at ProSocrates 2017 Symposium:\nProblem-solving,Creativity and Spatial Reasoning in Cognitive Systems.\nProSocrates 2017 symposium was held at the Hansewissenschaftkolleg (HWK) of\nAdvanced Studies in Delmenhorst, 20-21July 2017. This was the second edition of\nthis symposium which aims to bring together researchers interested in spatial\nreasoning, problem solving and creativity.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 09:16:11 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Olteteanu", "Ana-Maria", ""], ["Falomir", "Zoe", ""]]}, {"id": "1901.04274", "submitter": "Tobias Joppen", "authors": "Tobias Joppen and Johannes F\\\"urnkranz", "title": "Ordinal Monte Carlo Tree Search", "comments": "preview", "journal-ref": "IJCAI Workshop on Monte Carlo Tree Search, 2020", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many problem settings, most notably in game playing, an agent receives a\npossibly delayed reward for its actions. Often, those rewards are handcrafted\nand not naturally given. Even simple terminal-only rewards, like winning equals\n1 and losing equals -1, can not be seen as an unbiased statement, since these\nvalues are chosen arbitrarily, and the behavior of the learner may change with\ndifferent encodings, such as setting the value of a loss to -0:5, which is\noften done in practice to encourage learning. It is hard to argue about good\nrewards and the performance of an agent often depends on the design of the\nreward signal. In particular, in domains where states by nature only have an\nordinal ranking and where meaningful distance information between game state\nvalues are not available, a numerical reward signal is necessarily biased. In\nthis paper, we take a look at Monte Carlo Tree Search (MCTS), a popular\nalgorithm to solve MDPs, highlight a reoccurring problem concerning its use of\nrewards, and show that an ordinal treatment of the rewards overcomes this\nproblem. Using the General Video Game Playing framework we show a dominance of\nour newly proposed ordinal MCTS algorithm over preference-based MCTS, vanilla\nMCTS and various other MCTS variants.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 13:01:59 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Joppen", "Tobias", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1901.04562", "submitter": "Alex Beutel", "authors": "Alex Beutel, Jilin Chen, Tulsee Doshi, Hai Qian, Allison Woodruff,\n  Christine Luu, Pierre Kreitmann, Jonathan Bischof, Ed H. Chi", "title": "Putting Fairness Principles into Practice: Challenges, Metrics, and\n  Improvements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more researchers have become aware of and passionate about algorithmic\nfairness, there has been an explosion in papers laying out new metrics,\nsuggesting algorithms to address issues, and calling attention to issues in\nexisting applications of machine learning. This research has greatly expanded\nour understanding of the concerns and challenges in deploying machine learning,\nbut there has been much less work in seeing how the rubber meets the road.\n  In this paper we provide a case-study on the application of fairness in\nmachine learning research to a production classification system, and offer new\ninsights in how to measure and address algorithmic fairness issues. We discuss\nopen questions in implementing equality of opportunity and describe our\nfairness metric, conditional equality, that takes into account distributional\ndifferences. Further, we provide a new approach to improve on the fairness\nmetric during model training and demonstrate its efficacy in improving\nperformance for a real-world product\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 21:02:29 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Beutel", "Alex", ""], ["Chen", "Jilin", ""], ["Doshi", "Tulsee", ""], ["Qian", "Hai", ""], ["Woodruff", "Allison", ""], ["Luu", "Christine", ""], ["Kreitmann", "Pierre", ""], ["Bischof", "Jonathan", ""], ["Chi", "Ed H.", ""]]}, {"id": "1901.04592", "submitter": "Chandan Singh", "authors": "W. James Murdoch, Chandan Singh, Karl Kumbier, Reza Abbasi-Asl, Bin Yu", "title": "Interpretable machine learning: definitions, methods, and applications", "comments": "11 pages", "journal-ref": "Published in PNAS 2019", "doi": "10.1073/pnas.1900654116", "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning models have demonstrated great success in learning complex\npatterns that enable them to make predictions about unobserved data. In\naddition to using models for prediction, the ability to interpret what a model\nhas learned is receiving an increasing amount of attention. However, this\nincreased focus has led to considerable confusion about the notion of\ninterpretability. In particular, it is unclear how the wide array of proposed\ninterpretation methods are related, and what common concepts can be used to\nevaluate them.\n  We aim to address these concerns by defining interpretability in the context\nof machine learning and introducing the Predictive, Descriptive, Relevant (PDR)\nframework for discussing interpretations. The PDR framework provides three\noverarching desiderata for evaluation: predictive accuracy, descriptive\naccuracy and relevancy, with relevancy judged relative to a human audience.\nMoreover, to help manage the deluge of interpretation methods, we introduce a\ncategorization of existing techniques into model-based and post-hoc categories,\nwith sub-groups including sparsity, modularity and simulatability. To\ndemonstrate how practitioners can use the PDR framework to evaluate and\nunderstand interpretations, we provide numerous real-world examples. These\nexamples highlight the often under-appreciated role played by human audiences\nin discussions of interpretability. Finally, based on our framework, we discuss\nlimitations of existing methods and directions for future work. We hope that\nthis work will provide a common vocabulary that will make it easier for both\npractitioners and researchers to discuss and choose from the full range of\ninterpretation methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 22:35:26 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Murdoch", "W. James", ""], ["Singh", "Chandan", ""], ["Kumbier", "Karl", ""], ["Abbasi-Asl", "Reza", ""], ["Yu", "Bin", ""]]}, {"id": "1901.04626", "submitter": "Liudmyla Nechepurenko", "authors": "Liudmyla Nechepurenko, Viktor Voss, and Vyacheslav Gritsenko", "title": "Comparing Knowledge-based Reinforcement Learning to Neural Networks in a\n  Strategy Game", "comments": "7 pages, 6 figures", "journal-ref": "Hybrid Artificial Intelligent Systems. HAIS 2020. Lecture Notes in\n  Computer Science, vol 12344", "doi": "10.1007/978-3-030-61705-9_26", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper reports on an experiment, in which a Knowledge-Based Reinforcement\nLearning (KB-RL) method was compared to a Neural Network (NN) approach in\nsolving a classical Artificial Intelligence (AI) task. In contrast to NNs,\nwhich require a substantial amount of data to learn a good policy, the KB-RL\nmethod seeks to encode human knowledge into the solution, considerably reducing\nthe amount of data needed for a good policy. By means of Reinforcement Learning\n(RL), KB-RL learns to optimize the model and improves the output of the system.\nFurthermore, KB-RL offers the advantage of a clear explanation of the taken\ndecisions as well as transparent reasoning behind the solution.\n  The goal of the reported experiment was to examine the performance of the\nKB-RL method in contrast to the Neural Network and to explore the capabilities\nof KB-RL to deliver a strong solution for the AI tasks. The results show that,\nwithin the designed settings, KB-RL outperformed the NN, and was able to learn\na better policy from the available amount of data. These results support the\nopinion that Artificial Intelligence can benefit from the discovery and study\nof alternative approaches, potentially extending the frontiers of AI.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 01:23:38 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 11:01:33 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Nechepurenko", "Liudmyla", ""], ["Voss", "Viktor", ""], ["Gritsenko", "Vyacheslav", ""]]}, {"id": "1901.04670", "submitter": "Xuefeng Peng", "authors": "Xuefeng Peng, Yi Ding, David Wihl, Omer Gottesman, Matthieu\n  Komorowski, Li-wei H. Lehman, Andrew Ross, Aldo Faisal, Finale Doshi-Velez", "title": "Improving Sepsis Treatment Strategies by Combining Deep and Kernel-Based\n  Reinforcement Learning", "comments": "AMIA 2018 Annual Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sepsis is the leading cause of mortality in the ICU. It is challenging to\nmanage because individual patients respond differently to treatment. Thus,\ntailoring treatment to the individual patient is essential for the best\noutcomes. In this paper, we take steps toward this goal by applying a\nmixture-of-experts framework to personalize sepsis treatment. The mixture model\nselectively alternates between neighbor-based (kernel) and deep reinforcement\nlearning (DRL) experts depending on patient's current history. On a large\nretrospective cohort, this mixture-based approach outperforms physician, kernel\nonly, and DRL-only experts.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 05:40:27 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Peng", "Xuefeng", ""], ["Ding", "Yi", ""], ["Wihl", "David", ""], ["Gottesman", "Omer", ""], ["Komorowski", "Matthieu", ""], ["Lehman", "Li-wei H.", ""], ["Ross", "Andrew", ""], ["Faisal", "Aldo", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1901.04693", "submitter": "Guanyu Gao", "authors": "Guanyu Gao, Jie Li, Yonggang Wen", "title": "Energy-Efficient Thermal Comfort Control in Smart Buildings via Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heating, Ventilation, and Air Conditioning (HVAC) is extremely\nenergy-consuming, accounting for 40% of total building energy consumption.\nTherefore, it is crucial to design some energy-efficient building thermal\ncontrol policies which can reduce the energy consumption of HVAC while\nmaintaining the comfort of the occupants. However, implementing such a policy\nis challenging, because it involves various influencing factors in a building\nenvironment, which are usually hard to model and may be different from case to\ncase. To address this challenge, we propose a deep reinforcement learning based\nframework for energy optimization and thermal comfort control in smart\nbuildings. We formulate the building thermal control as a cost-minimization\nproblem which jointly considers the energy consumption of HVAC and the thermal\ncomfort of the occupants. To solve the problem, we first adopt a deep neural\nnetwork based approach for predicting the occupants' thermal comfort, and then\nadopt Deep Deterministic Policy Gradients (DDPG) for learning the thermal\ncontrol policy. To evaluate the performance, we implement a building thermal\ncontrol simulation system and evaluate the performance under various settings.\nThe experiment results show that our method can improve the thermal comfort\nprediction accuracy, and reduce the energy consumption of HVAC while improving\nthe occupants' thermal comfort.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 07:36:55 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Gao", "Guanyu", ""], ["Li", "Jie", ""], ["Wen", "Yonggang", ""]]}, {"id": "1901.04713", "submitter": "Chien-Sheng Wu", "authors": "Chien-Sheng Wu, Richard Socher, Caiming Xiong", "title": "Global-to-local Memory Pointer Networks for Task-Oriented Dialogue", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end task-oriented dialogue is challenging since knowledge bases are\nusually large, dynamic and hard to incorporate into a learning framework. We\npropose the global-to-local memory pointer (GLMP) networks to address this\nissue. In our model, a global memory encoder and a local memory decoder are\nproposed to share external knowledge. The encoder encodes dialogue history,\nmodifies global contextual representation, and generates a global memory\npointer. The decoder first generates a sketch response with unfilled slots.\nNext, it passes the global memory pointer to filter the external knowledge for\nrelevant information, then instantiates the slots via the local memory\npointers. We empirically show that our model can improve copy accuracy and\nmitigate the common out-of-vocabulary problem. As a result, GLMP is able to\nimprove over the previous state-of-the-art models in both simulated bAbI\nDialogue dataset and human-human Stanford Multi-domain Dialogue dataset on\nautomatic and human evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 08:55:53 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 05:13:11 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Wu", "Chien-Sheng", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "1901.04772", "submitter": "Montaser Mohammedalamen", "authors": "Montaser Mohammedalamen, Waleed D. Khamies, Benjamin Rosman", "title": "Transfer Learning for Prosthetics Using Imitation Learning", "comments": "Workshop paper, Black in AI, NeurIPS 2018", "journal-ref": "Black in AI Workshop, NeurIPS 2018", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, We Apply Reinforcement learning (RL) techniques to train a\nrealistic biomechanical model to work with different people and on different\nwalking environments. We benchmarking 3 RL algorithms: Deep Deterministic\nPolicy Gradient (DDPG), Trust Region Policy Optimization (TRPO) and Proximal\nPolicy Optimization (PPO) in OpenSim environment, Also we apply imitation\nlearning to a prosthetics domain to reduce the training time needed to design\ncustomized prosthetics. We use DDPG algorithm to train an original expert\nagent. We then propose a modification to the Dataset Aggregation (DAgger)\nalgorithm to reuse the expert knowledge and train a new target agent to\nreplicate that behaviour in fewer than 5 iterations, compared to the 100\niterations taken by the expert agent which means reducing training time by 95%.\nOur modifications to the DAgger algorithm improve the balance between\nexploiting the expert policy and exploring the environment. We show empirically\nthat these improve convergence time of the target agent, particularly when\nthere is some degree of variation between expert and naive agent.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 11:35:26 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Mohammedalamen", "Montaser", ""], ["Khamies", "Waleed D.", ""], ["Rosman", "Benjamin", ""]]}, {"id": "1901.04824", "submitter": "Detlef Steuer", "authors": "Ursula Garzcarek and Detlef Steuer", "title": "Approaching Ethical Guidelines for Data Scientists", "comments": "18 pages, submitted Nov 12th 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this article is to inspire data scientists to participate in the\ndebate on the impact that their professional work has on society, and to become\nactive in public debates on the digital world as data science professionals.\nHow do ethical principles (e.g., fairness, justice, beneficence, and\nnon-maleficence) relate to our professional lives? What lies in our\nresponsibility as professionals by our expertise in the field? More\nspecifically this article makes an appeal to statisticians to join that debate,\nand to be part of the community that establishes data science as a proper\nprofession in the sense of Airaksinen, a philosopher working on professional\nethics. As we will argue, data science has one of its roots in statistics and\nextends beyond it. To shape the future of statistics, and to take\nresponsibility for the statistical contributions to data science, statisticians\nshould actively engage in the discussions. First the term data science is\ndefined, and the technical changes that have led to a strong influence of data\nscience on society are outlined. Next the systematic approach from CNIL is\nintroduced. Prominent examples are given for ethical issues arising from the\nwork of data scientists. Further we provide reasons why data scientists should\nengage in shaping morality around and to formulate codes of conduct and codes\nof practice for data science. Next we present established ethical guidelines\nfor the related fields of statistics and computing machinery. Thereafter\nnecessary steps in the community to develop professional ethics for data\nscience are described. Finally we give our starting statement for the debate:\nData science is in the focal point of current societal development. Without\nbecoming a profession with professional ethics, data science will fail in\nbuilding trust in its interaction with and its much needed contributions to\nsociety!\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 16:13:27 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Garzcarek", "Ursula", ""], ["Steuer", "Detlef", ""]]}, {"id": "1901.04831", "submitter": "Loreto Parisi", "authors": "Loreto Parisi, Simone Francia, Silvio Olivastri, Maria Stella Tavella", "title": "Exploiting Synchronized Lyrics And Vocal Features For Music Emotion\n  Detection", "comments": "8 pages, 5 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key points in music recommendation is authoring engaging playlists\naccording to sentiment and emotions. While previous works were mostly based on\naudio for music discovery and playlists generation, we take advantage of our\nsynchronized lyrics dataset to combine text representations and music features\nin a novel way; we therefore introduce the Synchronized Lyrics Emotion Dataset.\nUnlike other approaches that randomly exploited the audio samples and the whole\ntext, our data is split according to the temporal information provided by the\nsynchronization between lyrics and audio. This work shows a comparison between\ntext-based and audio-based deep learning classification models using different\ntechniques from Natural Language Processing and Music Information Retrieval\ndomains. From the experiments on audio we conclude that using vocals only,\ninstead of the whole audio data improves the overall performances of the audio\nclassifier. In the lyrics experiments we exploit the state-of-the-art word\nrepresentations applied to the main Deep Learning architectures available in\nliterature. In our benchmarks the results show how the Bilinear LSTM classifier\nwith Attention based on fastText word embedding performs better than the CNN\napplied on audio.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 14:10:25 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Parisi", "Loreto", ""], ["Francia", "Simone", ""], ["Olivastri", "Silvio", ""], ["Tavella", "Maria Stella", ""]]}, {"id": "1901.04847", "submitter": "Hisham Al-Mubaid", "authors": "Hisham Al-Mubaid, Sasikanth Potu, and M. Shenify", "title": "Determining Multifunctional Genes and Diseases in Human Using Gene\n  Ontology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of human genes and diseases is very rewarding and can lead to\nimprovements in healthcare, disease diagnostics and drug discovery. In this\npaper, we further our previous study on gene disease relationship specifically\nwith the multifunctional genes. We investigate the multifunctional gene disease\nrelationship based on the published molecular function annotations of genes\nfrom the Gene Ontology which is the most comprehensive source on gene\nfunctions.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 23:53:33 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Al-Mubaid", "Hisham", ""], ["Potu", "Sasikanth", ""], ["Shenify", "M.", ""]]}, {"id": "1901.04866", "submitter": "James Townsend", "authors": "James Townsend, Tom Bird, David Barber", "title": "Practical Lossless Compression with Latent Variables using Bits Back\n  Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep latent variable models have seen recent success in many data domains.\nLossless compression is an application of these models which, despite having\nthe potential to be highly useful, has yet to be implemented in a practical\nmanner. We present `Bits Back with ANS' (BB-ANS), a scheme to perform lossless\ncompression with latent variable models at a near optimal rate. We demonstrate\nthis scheme by using it to compress the MNIST dataset with a variational\nauto-encoder model (VAE), achieving compression rates superior to standard\nmethods with only a simple VAE. Given that the scheme is highly amenable to\nparallelization, we conclude that with a sufficiently high quality generative\nmodel this scheme could be used to achieve substantial improvements in\ncompression rate with acceptable running time. We make our implementation\navailable open source at https://github.com/bits-back/bits-back .\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 14:45:47 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Townsend", "James", ""], ["Bird", "Tom", ""], ["Barber", "David", ""]]}, {"id": "1901.04936", "submitter": "Samira Abnar", "authors": "Samira Abnar, Tania Bedrax-weiss, Tom Kwiatkowski, William W. Cohen", "title": "Incremental Reading for Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any system which performs goal-directed continual learning must not only\nlearn incrementally but process and absorb information incrementally. Such a\nsystem also has to understand when its goals have been achieved. In this paper,\nwe consider these issues in the context of question answering. Current\nstate-of-the-art question answering models reason over an entire passage, not\nincrementally. As we will show, naive approaches to incremental reading, such\nas restriction to unidirectional language models in the model, perform poorly.\nWe present extensions to the DocQA [2] model to allow incremental reading\nwithout loss of accuracy. The model also jointly learns to provide the best\nanswer given the text that is seen so far and predict whether this best-so-far\nanswer is sufficient.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 17:03:32 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Abnar", "Samira", ""], ["Bedrax-weiss", "Tania", ""], ["Kwiatkowski", "Tom", ""], ["Cohen", "William W.", ""]]}, {"id": "1901.04947", "submitter": "Sze Teng Liong", "authors": "Y.S. Gan, Sze-Teng Liong and Yen-Chang Huang", "title": "Automatic Surface Area and Volume Prediction on Ellipsoidal Ham using\n  Deep Learning", "comments": "This paper contains 19 pages, 12 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents novel methods to predict the surface and volume of the\nham through a camera. This implies that the conventional weight measurement to\nobtain in the object's volume can be neglected and hence it is economically\neffective. Both of the measurements are obtained in the following two ways:\nmanually and automatically. The former is assume as the true or exact\nmeasurement and the latter is through a computer vision technique with some\ngeometrical analysis that includes mathematical derived functions. For the\nautomatic implementation, most of the existing approaches extract the features\nof the food material based on handcrafted features and to the best of our\nknowledge this is the first attempt to estimate the surface area and volume on\nham with deep learning features. We address the estimation task with a Mask\nRegion-based CNN (Mask R-CNN) approach, which well performs the ham detection\nand semantic segmentation from a video. The experimental results demonstrate\nthat the algorithm proposed is robust as promising surface area and volume\nestimation are obtained for two angles of the ellipsoidal ham (i.e., horizontal\nand vertical positions). Specifically, in the vertical ham point of view, it\nachieves an overall accuracy up to 95% whereas the horizontal ham reaches 80%\nof accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 17:26:43 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Gan", "Y. S.", ""], ["Liong", "Sze-Teng", ""], ["Huang", "Yen-Chang", ""]]}, {"id": "1901.04966", "submitter": "Heinrich Jiang", "authors": "Heinrich Jiang, Ofir Nachum", "title": "Identifying and Correcting Label Bias in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets often contain biases which unfairly disadvantage certain groups, and\nclassifiers trained on such datasets can inherit these biases. In this paper,\nwe provide a mathematical formulation of how this bias can arise. We do so by\nassuming the existence of underlying, unknown, and unbiased labels which are\noverwritten by an agent who intends to provide accurate labels but may have\nbiases against certain groups. Despite the fact that we only observe the biased\nlabels, we are able to show that the bias may nevertheless be corrected by\nre-weighting the data points without changing the labels. We show, with\ntheoretical guarantees, that training on the re-weighted dataset corresponds to\ntraining on the unobserved but unbiased labels, thus leading to an unbiased\nmachine learning classifier. Our procedure is fast and robust and can be used\nwith virtually any learning algorithm. We evaluate on a number of standard\nmachine learning fairness datasets and a variety of fairness notions, finding\nthat our method outperforms standard approaches in achieving fair\nclassification.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 18:40:06 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Jiang", "Heinrich", ""], ["Nachum", "Ofir", ""]]}, {"id": "1901.04969", "submitter": "Thiam Khean Hah", "authors": "Thiam Khean Hah, Yeong Tat Liew, Jason Ong", "title": "Low Precision Constant Parameter CNN on FPGA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report FPGA implementation results of low precision CNN convolution layers\noptimized for sparse and constant parameters. We describe techniques that\namortizes the cost of common factor multiplication and automatically leverage\ndense hand tuned LUT structures. We apply this method to corner case residual\nblocks of Resnet on a sparse Resnet50 model to assess achievable utilization\nand frequency and demonstrate an effective performance of 131 and 23 TOP/chip\nfor the corner case blocks. The projected performance on a multichip persistent\nimplementation of all Resnet50 convolution layers is 10k im/s/chip at batch\nsize 2. This is 1.37x higher than V100 GPU upper bound at the same batch size\nafter normalizing for sparsity.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 23:40:35 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Hah", "Thiam Khean", ""], ["Liew", "Yeong Tat", ""], ["Ong", "Jason", ""]]}, {"id": "1901.04985", "submitter": "MyungJoo Ham", "authors": "MyungJoo Ham and Ji Joong Moon and Geunsik Lim and Wook Song and\n  Jaeyun Jung and Hyoungjoo Ahn and Sangjung Woo and Youngchul Cho and Jinhyuck\n  Park and Sewon Oh and Hong-Seok Kim", "title": "NNStreamer: Stream Processing Paradigm for Neural Networks, Toward\n  Efficient Development and Execution of On-Device AI Applications", "comments": "This is a technical report from Samsung Electronics, which will be\n  published via conference proceedings (ACM/IEEE/USENIX, to be determined)\n  later", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose nnstreamer, a software system that handles neural networks as\nfilters of stream pipelines, applying the stream processing paradigm to neural\nnetwork applications. A new trend with the wide-spread of deep neural network\napplications is on-device AI; i.e., processing neural networks directly on\nmobile devices or edge/IoT devices instead of cloud servers. Emerging privacy\nissues, data transmission costs, and operational costs signifies the need for\non-device AI especially when a huge number of devices with real-time data\nprocessing are deployed. Nnstreamer efficiently handles neural networks with\ncomplex data stream pipelines on devices, improving the overall performance\nsignificantly with minimal efforts. Besides, nnstreamer simplifies the neural\nnetwork pipeline implementations and allows reusing off-shelf multimedia stream\nfilters directly; thus it reduces the developmental costs significantly.\nNnstreamer is already being deployed with a product releasing soon and is open\nsource software applicable to a wide range of hardware architectures and\nsoftware platforms.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 06:00:05 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Ham", "MyungJoo", ""], ["Moon", "Ji Joong", ""], ["Lim", "Geunsik", ""], ["Song", "Wook", ""], ["Jung", "Jaeyun", ""], ["Ahn", "Hyoungjoo", ""], ["Woo", "Sangjung", ""], ["Cho", "Youngchul", ""], ["Park", "Jinhyuck", ""], ["Oh", "Sewon", ""], ["Kim", "Hong-Seok", ""]]}, {"id": "1901.05101", "submitter": "Jacob Beck", "authors": "Jacob Beck, Zoe Papakipos, Michael Littman", "title": "ReNeg and Backseat Driver: Learning from Demonstration with Continuous\n  Human Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In autonomous vehicle (AV) control, allowing mistakes can be quite dangerous\nand costly in the real world. For this reason we investigate methods of\ntraining an AV without allowing the agent to explore and instead having a human\nexplorer collect the data. Supervised learning has been explored for AV\ncontrol, but it encounters the issue of the covariate shift. That is, training\ndata collected from an optimal demonstration consists only of the states\ninduced by the optimal control policy, but at runtime, the trained agent may\nencounter a vastly different state distribution with little relevant training\ndata. To mitigate this issue, we have our human explorer make sub-optimal\ndecisions. In order to have our agent not replicate these sub-optimal\ndecisions, supervised learning requires that we either erase these actions, or\nreplace these action with the correct action. Erasing is wasteful and replacing\nis difficult, since it is not easy to know the correct action without driving.\nWe propose an alternate framework that includes continuous scalar feedback for\neach action, marking which actions we should replicate, which we should avoid,\nand how sure we are. Our framework learns continuous control from sub-optimal\ndemonstration and evaluative feedback collected before training. We find that a\nhuman demonstrator can explore sub-optimal states in a safe manner, while still\ngetting enough gradation to benefit learning. The collection method for data\nand feedback we call \"Backseat Driver.\" We call the more general learning\nframework ReNeg, since it learns a regression from states to actions given\nnegative as well as positive examples. We empirically validate several models\nin the ReNeg framework, testing on lane-following with limited data. We find\nthat the best solution is a generalization of mean-squared error and\noutperforms supervised learning on the positive examples alone.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 01:20:00 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Beck", "Jacob", ""], ["Papakipos", "Zoe", ""], ["Littman", "Michael", ""]]}, {"id": "1901.05105", "submitter": "Xin Huang", "authors": "Xin Huang, Stephen McGill, Brian C. Williams, Luke Fletcher, Guy\n  Rosman", "title": "Uncertainty-Aware Driver Trajectory Prediction at Urban Intersections", "comments": "Accepted at ICRA'19. 8 pages, 9 figures, 1 table. Video at\n  https://youtu.be/clR08hRdtlM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the motion of a driver's vehicle is crucial for advanced driving\nsystems, enabling detection of potential risks towards shared control between\nthe driver and automation systems. In this paper, we propose a variational\nneural network approach that predicts future driver trajectory distributions\nfor the vehicle based on multiple sensors. Our predictor generates both a\nconditional variational distribution of future trajectories, as well as a\nconfidence estimate for different time horizons. Our approach allows us to\nhandle inherently uncertain situations, and reason about information gain from\neach input, as well as combine our model with additional predictors, creating a\nmixture of experts. We show how to augment the variational predictor with a\nphysics-based predictor, and based on their confidence estimations, improve\noverall system performance. The resulting combined model is aware of the\nuncertainty associated with its predictions, which can help the vehicle\nautonomy to make decisions with more confidence. The model is validated on\nreal-world urban driving data collected in multiple locations. This validation\ndemonstrates that our approach improves the prediction error of a physics-based\nmodel by 25% while successfully identifying the uncertain cases with 82%\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 01:46:57 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 03:31:12 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Huang", "Xin", ""], ["McGill", "Stephen", ""], ["Williams", "Brian C.", ""], ["Fletcher", "Luke", ""], ["Rosman", "Guy", ""]]}, {"id": "1901.05123", "submitter": "Simon Denman", "authors": "Tharindu Fernando, Simon Denman, Sridha Sridharan, Clinton Fookes", "title": "Memory Augmented Deep Generative models for Forecasting the Next Shot\n  Location in Tennis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel framework for predicting shot location and type\nin tennis. Inspired by recent neuroscience discoveries we incorporate neural\nmemory modules to model the episodic and semantic memory components of a tennis\nplayer. We propose a Semi Supervised Generative Adversarial Network\narchitecture that couples these memory models with the automatic feature\nlearning power of deep neural networks and demonstrate methodologies for\nlearning player level behavioural patterns with the proposed framework. We\nevaluate the effectiveness of the proposed model on tennis tracking data from\nthe 2012 Australian Tennis open and exhibit applications of the proposed method\nin discovering how players adapt their style depending on the match context.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 03:16:28 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Fernando", "Tharindu", ""], ["Denman", "Simon", ""], ["Sridharan", "Sridha", ""], ["Fookes", "Clinton", ""]]}, {"id": "1901.05138", "submitter": "Abhinav Jangda", "authors": "Abhinav Jangda, Gaurav Anand", "title": "Predicting Variable Types in Dynamically Typed Programming Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Programming Languages are quite popular because they increase the\nprogrammer's productivity. However, the absence of types in the source code\nmakes the program written in these languages difficult to understand and\nvirtual machines that execute these programs cannot produced optimized code. To\novercome this challenge, we develop a technique to predict types of all\nidentifiers including variables, and function return types.\n  We propose the first implementation of $2^{nd}$ order Inside Outside\nRecursive Neural Networks with two variants (i) Child-Sum Tree-LSTMs and (ii)\nN-ary RNNs that can handle large number of tree branching. We predict the types\nof all the identifiers given the Abstract Syntax Tree by performing just two\npasses over the tree, bottom-up and top-down, keeping both the content and\ncontext representation for all the nodes of the tree. This allows these\nrepresentations to interact by combining different paths from the parent,\nsiblings and children which is crucial for predicting types. Our best model\nachieves 44.33\\% across 21 classes and top-3 accuracy of 71.5\\% on our gathered\nPython data set from popular Python benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 05:42:22 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Jangda", "Abhinav", ""], ["Anand", "Gaurav", ""]]}, {"id": "1901.05233", "submitter": "Blerina Gkotse", "authors": "Blerina Gkotse, Pierre Jouvelot and Federico Ravotti", "title": "IEDM, an Ontology for Irradiation Experiment Data Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Irradiation experiments (IE) are an essential step in the development of\nHigh-Energy Physics (HEP) particle accelerators and detectors. They assess the\nradiation hardness of materials used in HEP experimental devices by simulating,\nin a short time, the common long-term degradation effects due to their\nbombardment by high-energy particles. IEs are also used in other scientific and\nindustrial fields such as medicine (e.g., for cancer treatment, medical\nimaging, etc.), space/avionics (e.g., for radiation testing of payload\nequipment) as well as in industry (e.g., for food sterilization). Usually\ncarried out with ionizing radiation, these complex processes require highly\nspecialized infrastructures: the irradiation facilities. Currently, hundreds of\nsuch facilities exist worldwide. To help develop best practices and promote\ncomputer-assisted handling and management of IEs, we introduce IEDM, a new\nOWL-based Irradiation Experiment Data Management ontology. This paper provides\nan overview of the classes and properties of IEDM. Since one of the key design\nchoices for IEDM was to maximize the reuse of existing foundational ontologies\nsuch as the Ontology of Scientific Experiments (EXPO), the Ontology of Units of\nMeasure (OM) and the Friend-of-a-Friend Ontology (FOAF), we discuss the\nmethodological issues of the integration of IEDM with these imported\nontologies. We illustrate the use of IEDM via an actual IE recently performed\nat IRRAD, the CERN proton irradiation facility. Finally, we discuss other\nmotivations for this work, including the use of IEDM for the generation of user\ninterfaces for IE management, and their impact on our methodology.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 11:18:03 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Gkotse", "Blerina", ""], ["Jouvelot", "Pierre", ""], ["Ravotti", "Federico", ""]]}, {"id": "1901.05322", "submitter": "Saeid Amiri", "authors": "Saeid Amiri, Mohammad Shokrolah Shirazi, Shiqi Zhang", "title": "Learning and Reasoning for Robot Sequential Decision Making under\n  Uncertainty", "comments": "In proceedings of 34th AAAI conference on Artificial Intelligence,\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots frequently face complex tasks that require more than one action, where\nsequential decision-making (SDM) capabilities become necessary. The key\ncontribution of this work is a robot SDM framework, called LCORPP, that\nsupports the simultaneous capabilities of supervised learning for passive state\nestimation, automated reasoning with declarative human knowledge, and planning\nunder uncertainty toward achieving long-term goals. In particular, we use a\nhybrid reasoning paradigm to refine the state estimator, and provide\ninformative priors for the probabilistic planner. In experiments, a mobile\nrobot is tasked with estimating human intentions using their motion\ntrajectories, declarative contextual knowledge, and human-robot interaction\n(dialog-based and motion-based). Results suggest that, in efficiency and\naccuracy, our framework performs better than its no-learning and no-reasoning\ncounterparts in office environment.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 14:47:14 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 16:56:47 GMT"}, {"version": "v3", "created": "Tue, 10 Dec 2019 13:42:31 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Amiri", "Saeid", ""], ["Shirazi", "Mohammad Shokrolah", ""], ["Zhang", "Shiqi", ""]]}, {"id": "1901.05415", "submitter": "Braden Hancock", "authors": "Braden Hancock, Antoine Bordes, Pierre-Emmanuel Mazar\\'e, Jason Weston", "title": "Learning from Dialogue after Deployment: Feed Yourself, Chatbot!", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of conversations a dialogue agent sees over its lifetime occur\nafter it has already been trained and deployed, leaving a vast store of\npotential training signal untapped. In this work, we propose the self-feeding\nchatbot, a dialogue agent with the ability to extract new training examples\nfrom the conversations it participates in. As our agent engages in\nconversation, it also estimates user satisfaction in its responses. When the\nconversation appears to be going well, the user's responses become new training\nexamples to imitate. When the agent believes it has made a mistake, it asks for\nfeedback; learning to predict the feedback that will be given improves the\nchatbot's dialogue abilities further. On the PersonaChat chit-chat dataset with\nover 131k training examples, we find that learning from dialogue with a\nself-feeding chatbot significantly improves performance, regardless of the\namount of traditional supervision.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 18:02:44 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 07:03:17 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 03:23:04 GMT"}, {"version": "v4", "created": "Thu, 13 Jun 2019 06:01:04 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Hancock", "Braden", ""], ["Bordes", "Antoine", ""], ["Mazar\u00e9", "Pierre-Emmanuel", ""], ["Weston", "Jason", ""]]}, {"id": "1901.05431", "submitter": "Michael Green", "authors": "Michael Cerny Green, Benjamin Sergent, Pushyami Shandilya and Vibhor\n  Kumar", "title": "Evolutionarily-Curated Curriculum Learning for Deep Reinforcement\n  Learning Agents", "comments": "9 pages, 7 figures, accepted to the Reinforcement Learning in Games\n  workshop at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new training loop for deep reinforcement learning\nagents with an evolutionary generator. Evolutionary procedural content\ngeneration has been used in the creation of maps and levels for games before.\nOur system incorporates an evolutionary map generator to construct a training\ncurriculum that is evolved to maximize loss within the state-of-the-art Double\nDueling Deep Q Network architecture with prioritized replay. We present a\ncase-study in which we prove the efficacy of our new method on a game with a\ndiscrete, large action space we made called Attackers and Defenders. Our\nresults demonstrate that training on an evolutionarily-curated curriculum\n(directed sampling) of maps both expedites training and improves generalization\nwhen compared to a network trained on an undirected sampling of maps.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 18:53:14 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Green", "Michael Cerny", ""], ["Sergent", "Benjamin", ""], ["Shandilya", "Pushyami", ""], ["Kumar", "Vibhor", ""]]}, {"id": "1901.05437", "submitter": "Zenna Tavares", "authors": "Zenna Tavares, Javier Burroni, Edgar Minaysan, Armando Solar Lezama,\n  Rajesh Ranganath", "title": "Soft Constraints for Inference with Declarative Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a likelihood free inference procedure for conditioning a\nprobabilistic model on a predicate. A predicate is a Boolean valued function\nwhich expresses a yes/no question about a domain. Our contribution, which we\ncall predicate exchange, constructs a softened predicate which takes value in\nthe unit interval [0, 1] as opposed to a simply true or false. Intuitively, 1\ncorresponds to true, and a high value (such as 0.999) corresponds to \"nearly\ntrue\" as determined by a distance metric. We define Boolean algebra for soft\npredicates, such that they can be negated, conjoined and disjoined arbitrarily.\nA softened predicate can serve as a tractable proxy to a likelihood function\nfor approximate posterior inference. However, to target exact inference, we\ntemper the relaxation by a temperature parameter, and add a accept/reject phase\nuse to replica exchange Markov Chain Mont Carlo, which exchanges states between\na sequence of models conditioned on predicates at varying temperatures. We\ndescribe a lightweight implementation of predicate exchange that it provides a\nlanguage independent layer that can be implemented on top of existingn modeling\nformalisms.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 18:59:38 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Tavares", "Zenna", ""], ["Burroni", "Javier", ""], ["Minaysan", "Edgar", ""], ["Lezama", "Armando Solar", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "1901.05506", "submitter": "Konstantin Yakovlev S", "authors": "Anton Andreychuk, Konstantin Yakovlev, Dor Atzmon, Roni Stern", "title": "Multi-Agent Pathfinding with Continuous Time", "comments": "Camera-ready version of the paper as to appear in IJCAI'19\n  proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Agent Pathfinding (MAPF) is the problem of finding paths for multiple\nagents such that every agent reaches its goal and the agents do not collide.\nMost prior work on MAPF was on grids, assumed agents' actions have uniform\nduration, and that time is discretized into timesteps. We propose a MAPF\nalgorithm that does not rely on these assumptions, is complete, and provides\nprovably optimal solutions. This algorithm is based on a novel adaptation of\nSafe interval path planning (SIPP), a continuous time single-agent planning\nalgorithm, and a modified version of Conflict-based search (CBS), a state of\nthe art multi-agent pathfinding algorithm. We analyze this algorithm, discuss\nits pros and cons, and evaluate it experimentally on several standard\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 19:34:03 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 21:08:24 GMT"}, {"version": "v3", "created": "Fri, 14 Jun 2019 17:50:35 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Andreychuk", "Anton", ""], ["Yakovlev", "Konstantin", ""], ["Atzmon", "Dor", ""], ["Stern", "Roni", ""]]}, {"id": "1901.05517", "submitter": "Roc\\'io D\\'iaz de Le\\'on Torres", "authors": "Roc\\'io D\\'iaz de Le\\'on Torres, Mart\\'in Molina, Pascual Campoy", "title": "Survey of Bayesian Networks Applications to Intelligent Autonomous\n  Vehicles", "comments": "34 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article reviews the applications of Bayesian Networks to Intelligent\nAutonomous Vehicles (IAV) from the decision making point of view, which\nrepresents the final step for fully Autonomous Vehicles (currently under\ndiscussion). Until now, when it comes making high level decisions for\nAutonomous Vehicles (AVs), humans have the last word. Based on the works cited\nin this article and analysis done here, the modules of a general decision\nmaking framework and its variables are inferred. Many efforts have been made in\nthe labs showing Bayesian Networks as a promising computer model for decision\nmaking. Further research should go into the direction of testing Bayesian\nNetwork models in real situations. In addition to the applications, Bayesian\nNetwork fundamentals are introduced as elements to consider when developing\nIAVs with the potential of making high level judgement calls.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 20:32:17 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 21:17:39 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Torres", "Roc\u00edo D\u00edaz de Le\u00f3n", ""], ["Molina", "Mart\u00edn", ""], ["Campoy", "Pascual", ""]]}, {"id": "1901.05564", "submitter": "Soheila Sadeghiram", "authors": "Soheila Sadeghiram, Hui MA, Gang Chen", "title": "Distance-Guided GA-Based Approach to Distributed Data-Intensive Web\n  Service Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed computing which uses Web services as fundamental elements,\nenables high-speed development of software applications through composing many\ninteroperating, distributed, re-usable, and autonomous services. As a\nfundamental challenge for service developers, service composition must fulfil\nfunctional requirements and optimise Quality of Service (QoS) attributes,\nsimultaneously. On the other hand, huge amounts of data have been created by\nadvances in technologies, which may be exchanged between services.\nData-intensive Web services are of great interest to implement data-intensive\nprocesses. However, current approaches to Web service composition have omitted\neither the effect of data, or the distribution of services. Evolutionary\nComputing (EC) techniques allow for the creation of compositions that meet all\nthe above factors. In this paper, we will develop Genetic Algorithm (GA)-based\napproach for solving the problem of distributed data-intensive Web service\ncomposition (DWSC). In particular, we will introduce two new heuristics, i.e.\nLongest Common Subsequence(LCS) distance of services, in designing crossover\noperators. Additionally, a new local search technique incorporating distance of\nservices will be proposed.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 23:48:57 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Sadeghiram", "Soheila", ""], ["MA", "Hui", ""], ["Chen", "Gang", ""]]}, {"id": "1901.05577", "submitter": "Neil Veira", "authors": "Thang Doan, Neil Veira, Saibal Ray, Brian Keng", "title": "Generating Realistic Sequences of Customer-level Transactions for Retail\n  Datasets", "comments": "Published at IEEE ICDM Workshop on Data Mining for Services 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to better engage with customers, retailers rely on extensive\ncustomer and product databases which allows them to better understand customer\nbehaviour and purchasing patterns. This has long been a challenging task as\ncustomer modelling is a multi-faceted, noisy and time-dependent problem. The\nmost common way to tackle this problem is indirectly through task-specific\nsupervised learning prediction problems, with relatively little literature on\nmodelling a customer by directly simulating their future transactions. In this\npaper we propose a method for generating realistic sequences of baskets that a\ngiven customer is likely to purchase over a period of time. Customer embedding\nrepresentations are learned using a Recurrent Neural Network (RNN) which takes\ninto account the entire sequence of transaction data. Given the customer state\nat a specific point in time, a Generative Adversarial Network (GAN) is trained\nto generate a plausible basket of products for the following week. The newly\ngenerated basket is then fed back into the RNN to update the customer's state.\nThe GAN is thus used in tandem with the RNN module in a pipeline alternating\nbetween basket generation and customer state updating steps. This allows for\nsampling over a distribution of a customer's future sequence of baskets, which\nthen can be used to gain insight into how to service the customer more\neffectively. The methodology is empirically shown to produce baskets that\nappear similar to real baskets and enjoy many common properties, including\nfrequencies of different product types, brands, and prices. Furthermore, the\ngenerated data is able to replicate most of the strongest sequential patterns\nthat exist between product types in the real data.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 01:24:24 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 03:05:24 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Doan", "Thang", ""], ["Veira", "Neil", ""], ["Ray", "Saibal", ""], ["Keng", "Brian", ""]]}, {"id": "1901.05642", "submitter": "Mehrdad Zakershahrak", "authors": "Mehrdad Zakershahrak and Yu Zhang", "title": "Interactive Plan Explicability in Human-Robot Teaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-robot teaming is one of the most important applications of artificial\nintelligence in the fast-growing field of robotics. For effective teaming, a\nrobot must not only maintain a behavioral model of its human teammates to\nproject the team status, but also be aware that its human teammates'\nexpectation of itself. Being aware of the human teammates' expectation leads to\nrobot behaviors that better align with human expectation, thus facilitating\nmore efficient and potentially safer teams. Our work addresses the problem of\nhuman-robot cooperation with the consideration of such teammate models in\nsequential domains by leveraging the concept of plan explicability. In plan\nexplicability, however, the human is considered solely as an observer. In this\npaper, we extend plan explicability to consider interactive settings where\nhuman and robot behaviors can influence each other. We term this new measure as\nInteractive Plan Explicability. We compare the joint plan generated with the\nconsideration of this measure using the fast forward planner (FF) with the plan\ncreated by FF without such consideration, as well as the plan created with\nactual human subjects. Results indicate that the explicability score of plans\ngenerated by our algorithm is comparable to the human plan, and better than the\nplan created by FF without considering the measure, implying that the plans\ncreated by our algorithms align better with expected joint plans of the human\nduring execution. This can lead to more efficient collaboration in practice.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 06:32:02 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Zakershahrak", "Mehrdad", ""], ["Zhang", "Yu", ""]]}, {"id": "1901.05847", "submitter": "Vaishak Belle", "authors": "Amelie Levray and Vaishak Belle", "title": "Learning Credal Sum-Product Networks", "comments": "Accepted to AKBC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic representations, such as Bayesian and Markov networks, are\nfundamental to much of statistical machine learning. Thus, learning\nprobabilistic representations directly from data is a deep challenge, the main\ncomputational bottleneck being inference that is intractable. Tractable\nlearning is a powerful new paradigm that attempts to learn distributions that\nsupport efficient probabilistic querying. By leveraging local structure,\nrepresentations such as sum-product networks (SPNs) can capture high tree-width\nmodels with many hidden layers, essentially a deep architecture, while still\nadmitting a range of probabilistic queries to be computable in time polynomial\nin the network size. While the progress is impressive, numerous data sources\nare incomplete, and in the presence of missing data, structure learning methods\nnonetheless revert to single distributions without characterizing the loss in\nconfidence. In recent work, credal sum-product networks, an imprecise extension\nof sum-product networks, were proposed to capture this robustness angle. In\nthis work, we are interested in how such representations can be learnt and thus\nstudy how the computational machinery underlying tractable learning and\ninference can be generalized for imprecise probabilities.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 15:32:12 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 14:41:35 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Levray", "Amelie", ""], ["Belle", "Vaishak", ""]]}, {"id": "1901.05850", "submitter": "Aly El Gamal", "authors": "Sharan Ramjee, Shengtai Ju, Diyu Yang, Xiaoyu Liu, Aly El Gamal,\n  Yonina C. Eldar", "title": "Fast Deep Learning for Automatic Modulation Classification", "comments": "29 pages, 30 figures, submitted to Journal on Selected Areas in\n  Communications - Special Issue on Machine Learning in Wireless Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the feasibility and effectiveness of employing\ndeep learning algorithms for automatic recognition of the modulation type of\nreceived wireless communication signals from subsampled data. Recent work\nconsidered a GNU radio-based data set that mimics the imperfections in a real\nwireless channel and uses 10 different modulation types. A Convolutional Neural\nNetwork (CNN) architecture was then developed and shown to achieve performance\nthat exceeds that of expert-based approaches. Here, we continue this line of\nwork and investigate deep neural network architectures that deliver high\nclassification accuracy. We identify three architectures - namely, a\nConvolutional Long Short-term Deep Neural Network (CLDNN), a Long Short-Term\nMemory neural network (LSTM), and a deep Residual Network (ResNet) - that lead\nto typical classification accuracy values around 90% at high SNR. We then study\nalgorithms to reduce the training time by minimizing the size of the training\ndata set, while incurring a minimal loss in classification accuracy. To this\nend, we demonstrate the performance of Principal Component Analysis in\nsignificantly reducing the training time, while maintaining good performance at\nlow SNR. We also investigate subsampling techniques that further reduce the\ntraining time, and pave the way for online classification at high SNR. Finally,\nwe identify representative SNR values for training each of the candidate\narchitectures, and consequently, realize drastic reductions of the training\ntime, with negligible loss in classification accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 01:15:50 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Ramjee", "Sharan", ""], ["Ju", "Shengtai", ""], ["Yang", "Diyu", ""], ["Liu", "Xiaoyu", ""], ["Gamal", "Aly El", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "1901.05856", "submitter": "Gyeong Taek Lee", "authors": "Gyeong Taek Lee and Chang Ouk Kim", "title": "Amplifying the Imitation Effect for Reinforcement Learning of UCAV's\n  Mission Execution", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new reinforcement learning (RL) algorithm that enhances\nexploration by amplifying the imitation effect (AIE). This algorithm consists\nof self-imitation learning and random network distillation algorithms. We argue\nthat these two algorithms complement each other and that combining these two\nalgorithms can amplify the imitation effect for exploration. In addition, by\nadding an intrinsic penalty reward to the state that the RL agent frequently\nvisits and using replay memory for learning the feature state when using an\nexploration bonus, the proposed approach leads to deep exploration and deviates\nfrom the current converged policy. We verified the exploration performance of\nthe algorithm through experiments in a two-dimensional grid environment. In\naddition, we applied the algorithm to a simulated environment of unmanned\ncombat aerial vehicle (UCAV) mission execution, and the empirical results show\nthat AIE is very effective for finding the UCAV's shortest flight path to avoid\nan enemy's missiles.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 15:47:12 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Lee", "Gyeong Taek", ""], ["Kim", "Chang Ouk", ""]]}, {"id": "1901.06085", "submitter": "Max Kleiman-Weiner", "authors": "Michael Shum, Max Kleiman-Weiner, Michael L. Littman, Joshua B.\n  Tenenbaum", "title": "Theory of Minds: Understanding Behavior in Groups Through Inverse\n  Planning", "comments": "published in AAAI 2019; Michael Shum and Max Kleiman-Weiner\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human social behavior is structured by relationships. We form teams, groups,\ntribes, and alliances at all scales of human life. These structures guide\nmulti-agent cooperation and competition, but when we observe others these\nunderlying relationships are typically unobservable and hence must be inferred.\nHumans make these inferences intuitively and flexibly, often making rapid\ngeneralizations about the latent relationships that underlie behavior from just\nsparse and noisy observations. Rapid and accurate inferences are important for\ndetermining who to cooperate with, who to compete with, and how to cooperate in\norder to compete. Towards the goal of building machine-learning algorithms with\nhuman-like social intelligence, we develop a generative model of multi-agent\naction understanding based on a novel representation for these latent\nrelationships called Composable Team Hierarchies (CTH). This representation is\ngrounded in the formalism of stochastic games and multi-agent reinforcement\nlearning. We use CTH as a target for Bayesian inference yielding a new\nalgorithm for understanding behavior in groups that can both infer hidden\nrelationships as well as predict future actions for multiple agents interacting\ntogether. Our algorithm rapidly recovers an underlying causal model of how\nagents relate in spatial stochastic games from just a few observations. The\npatterns of inference made by this algorithm closely correspond with human\njudgments and the algorithm makes the same rapid generalizations that people\ndo.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 04:50:08 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Shum", "Michael", ""], ["Kleiman-Weiner", "Max", ""], ["Littman", "Michael L.", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1901.06199", "submitter": "Kaizhu Huang", "authors": "Zhuang Qian, Kaizhu Huang, Qiufeng Wang, Jimin Xiao, Rui Zhang", "title": "Generative Adversarial Classifier for Handwriting Characters\n  Super-Resolution", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GAN) receive great attentions recently due\nto its excellent performance in image generation, transformation, and\nsuper-resolution. However, GAN has rarely been studied and trained for\nclassification, leading that the generated images may not be appropriate for\nclassification. In this paper, we propose a novel Generative Adversarial\nClassifier (GAC) particularly for low-resolution Handwriting Character\nRecognition. Specifically, involving additionally a classifier in the training\nprocess of normal GANs, GAC is calibrated for learning suitable structures and\nrestored characters images that benefits the classification. Experimental\nresults show that our proposed method can achieve remarkable performance in\nhandwriting characters 8x super-resolution, approximately 10% and 20% higher\nthan the present state-of-the-art methods respectively on benchmark data\nCASIA-HWDB1.1 and MNIST.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 12:10:50 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Qian", "Zhuang", ""], ["Huang", "Kaizhu", ""], ["Wang", "Qiufeng", ""], ["Xiao", "Jimin", ""], ["Zhang", "Rui", ""]]}, {"id": "1901.06212", "submitter": "Dmitry Kangin", "authors": "Dmitry Kangin and Nicolas Pugeault", "title": "On-Policy Trust Region Policy Optimisation with Replay Buffers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building upon the recent success of deep reinforcement learning methods, we\ninvestigate the possibility of on-policy reinforcement learning improvement by\nreusing the data from several consecutive policies. On-policy methods bring\nmany benefits, such as ability to evaluate each resulting policy. However, they\nusually discard all the information about the policies which existed before. In\nthis work, we propose adaptation of the replay buffer concept, borrowed from\nthe off-policy learning setting, to create the method, combining advantages of\non- and off-policy learning. To achieve this, the proposed algorithm\ngeneralises the $Q$-, value and advantage functions for data from multiple\npolicies. The method uses trust region optimisation, while avoiding some of the\ncommon problems of the algorithms such as TRPO or ACKTR: it uses\nhyperparameters to replace the trust region selection heuristics, as well as\nthe trainable covariance matrix instead of the fixed one. In many cases, the\nmethod not only improves the results comparing to the state-of-the-art trust\nregion on-policy learning algorithms such as PPO, ACKTR and TRPO, but also with\nrespect to their off-policy counterpart DDPG.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 13:09:18 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Kangin", "Dmitry", ""], ["Pugeault", "Nicolas", ""]]}, {"id": "1901.06221", "submitter": "Andrea Celli", "authors": "Andrea Celli, Stefano Coniglio, Nicola Gatti", "title": "Computing Optimal Coarse Correlated Equilibria in Sequential Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the computation of equilibria in extensive-form games where ex\nante correlation is possible, focusing on correlated equilibria requiring the\nleast amount of communication between the players and the mediator. Motivated\nby the hardness results on the computation of normal-form correlated\nequilibria, we introduce the notion of normal-form coarse correlated\nequilibrium, extending the definition of coarse correlated equilibrium to\nsequential games. We show that, in two-player games without chance moves, an\noptimal (e.g., social welfare maximizing) normal-form coarse correlated\nequilibrium can be computed in polynomial time, and that in general\nmulti-player games (including two-player games with Chance), the problem is\nNP-hard. For the former case, we provide a polynomial-time algorithm based on\nthe ellipsoid method and also propose a more practical one, which can be\nefficiently applied to problems of considerable size. Then, we discuss how our\nalgorithm can be extended to games with Chance and games with more than two\nplayers.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 13:32:52 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Celli", "Andrea", ""], ["Coniglio", "Stefano", ""], ["Gatti", "Nicola", ""]]}, {"id": "1901.06230", "submitter": "Alexander Peysakhovich", "authors": "Christian Kroer, Alexander Peysakhovich, Eric Sodomka, Nicolas E.\n  Stier-Moses", "title": "Computing large market equilibria using abstractions", "comments": null, "journal-ref": "Proceedings of the 2019 ACM Conference on Economics and\n  Computation. Association for Computing Machinery, New York, NY, USA, 745-746,\n  2019", "doi": "10.1145/3328526.3329553", "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing market equilibria is an important practical problem for market\ndesign (e.g. fair division, item allocation). However, computing equilibria\nrequires large amounts of information (e.g. all valuations for all buyers for\nall items) and compute power. We consider ameliorating these issues by applying\na method used for solving complex games: constructing a coarsened abstraction\nof a given market, solving for the equilibrium in the abstraction, and lifting\nthe prices and allocations back to the original market. We show how to bound\nimportant quantities such as regret, envy, Nash social welfare, Pareto\noptimality, and maximin share when the abstracted prices and allocations are\nused in place of the real equilibrium. We then study two abstraction methods of\ninterest for practitioners: 1) filling in unknown valuations using techniques\nfrom matrix completion, 2) reducing the problem size by aggregating groups of\nbuyers/items into smaller numbers of representative buyers/items and solving\nfor equilibrium in this coarsened market. We find that in real data\nallocations/prices that are relatively close to equilibria can be computed from\neven very coarse abstractions.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 13:50:35 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Kroer", "Christian", ""], ["Peysakhovich", "Alexander", ""], ["Sodomka", "Eric", ""], ["Stier-Moses", "Nicolas E.", ""]]}, {"id": "1901.06253", "submitter": "Huimin Lu", "authors": "Huimin Lu, Dong Wang, Yujie Li, Jianru Li, Xin Li, Hyoungseop Kim,\n  Seiichi Serikawa, Iztok Humar", "title": "CONet: A Cognitive Ocean Network", "comments": "Accepted by IEEE Wireless Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The scientific and technological revolution of the Internet of Things has\nbegun in the area of oceanography. Historically, humans have observed the ocean\nfrom an external viewpoint in order to study it. In recent years, however,\nchanges have occurred in the ocean, and laboratories have been built on the\nseafloor. Approximately 70.8% of the Earth's surface is covered by oceans and\nrivers. The Ocean of Things is expected to be important for disaster\nprevention, ocean-resource exploration, and underwater environmental\nmonitoring. Unlike traditional wireless sensor networks, the Ocean Network has\nits own unique features, such as low reliability and narrow bandwidth. These\nfeatures will be great challenges for the Ocean Network. Furthermore, the\nintegration of the Ocean Network with artificial intelligence has become a\ntopic of increasing interest for oceanology researchers. The Cognitive Ocean\nNetwork (CONet) will become the mainstream of future ocean science and\nengineering developments. In this article, we define the CONet. The\ncontributions of the paper are as follows: (1) a CONet architecture is proposed\nand described in detail; (2) important and useful demonstration applications of\nthe CONet are proposed; and (3) future trends in CONet research are presented.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 04:20:55 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Lu", "Huimin", ""], ["Wang", "Dong", ""], ["Li", "Yujie", ""], ["Li", "Jianru", ""], ["Li", "Xin", ""], ["Kim", "Hyoungseop", ""], ["Serikawa", "Seiichi", ""], ["Humar", "Iztok", ""]]}, {"id": "1901.06343", "submitter": "G\\'erald Rocher", "authors": "G\\'erald Rocher, Jean-Yves Tigli, St\\'ephane Lavirotte and Nhan Le\n  Thanh", "title": "Effectiveness Assessment of Cyber-Physical Systems", "comments": "Preprint submitted to International Journal of Approximate Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By achieving their purposes through interactions with the physical world,\nCyber-Physical Systems (CPS) pose new challenges in terms of dependability.\nIndeed, the evolution of the physical systems they control with transducers can\nbe affected by surrounding physical processes over which they have no control\nand which may potentially hamper the achievement of their purposes. While it is\nillusory to hope for a comprehensive model of the physical environment at\ndesign time to anticipate and remove faults that may occur once these systems\nare deployed, it becomes necessary to evaluate their degree of effectiveness in\nvivo. In this paper, the degree of effectiveness is formally defined and\ngeneralized in the context of the measure theory. The measure is developed in\nthe context of the Transferable Belief Model (TBM), an elaboration on the\nDempster-Shafer Theory (DST) of evidence so as to handle epistemic and aleatory\nuncertainties respectively pertaining the users' expectations and the natural\nvariability of the physical environment. The TBM is used in conjunction with\nthe Input/Output Hidden Markov Modeling framework (we denote by Ev-IOHMM) to\nspecify the expected evolution of the physical system controlled by the CPS and\nthe tolerances towards uncertainties. The measure of effectiveness is then\nobtained from the forward algorithm, leveraging the conflict entailed by the\nsuccessive combinations of the beliefs obtained from observations of the\nphysical system and the beliefs corresponding to its expected evolution. The\nproposed approach is applied to autonomous vehicles and show how the degree of\neffectiveness can be used for bench-marking their controller relative to the\nhighway code speed limitations and passengers' well-being constraints, both\nmodeled through an Ev-IOHMM.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 10:35:41 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 07:30:53 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 14:40:51 GMT"}, {"version": "v4", "created": "Fri, 13 Dec 2019 12:52:59 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Rocher", "G\u00e9rald", ""], ["Tigli", "Jean-Yves", ""], ["Lavirotte", "St\u00e9phane", ""], ["Thanh", "Nhan Le", ""]]}, {"id": "1901.06378", "submitter": "Ryuta Arisaka", "authors": "Ryuta Arisaka, Stefano Bistarelli, Francesco Santini", "title": "Block Argumentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We contemplate a higher-level bipolar abstract argumentation for\nnon-elementary arguments such as: X argues against Ys sincerity with the fact\nthat Y has presented his argument to draw a conclusion C, by omitting other\nfacts which would not have validated C. Argumentation involving such arguments\nrequires us to potentially consider an argument as a coherent block of\nargumentation, i.e. an argument may itself be an argumentation. In this work,\nwe formulate block argumentation as a specific instance of Dung-style bipolar\nabstract argumentation with the dual nature of arguments. We consider internal\nconsistency of an argument(ation) under a set of constraints, of graphical\n(syntactic) and of semantic nature, and formulate acceptability semantics in\nrelation to them. We discover that classical acceptability semantics do not in\ngeneral hold good with the constraints. In particular, acceptability of\nunattacked arguments is not always warranted. Further, there may not be a\nunique minimal member in complete semantics, thus sceptic (grounded) semantics\nmay not be its subset. To retain set-theoretically minimal semantics as a\nsubset of complete semantics, we define semi-grounded semantics. Through\ncomparisons, we show how the concept of block argumentation may further\ngeneralise structured argumentation.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 18:44:26 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Arisaka", "Ryuta", ""], ["Bistarelli", "Stefano", ""], ["Santini", "Francesco", ""]]}, {"id": "1901.06401", "submitter": "Fathi Salem", "authors": "Atra Akandeh and Fathi M. Salem", "title": "Slim LSTM networks: LSTM_6 and LSTM_C6", "comments": "6 pages, 12 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have shown previously that our parameter-reduced variants of Long\nShort-Term Memory (LSTM) Recurrent Neural Networks (RNN) are comparable in\nperformance to the standard LSTM RNN on the MNIST dataset. In this study, we\nshow that this is also the case for two diverse benchmark datasets, namely, the\nreview sentiment IMDB and the 20 Newsgroup datasets. Specifically, we focus on\ntwo of the simplest variants, namely LSTM_6 (i.e., standard LSTM with three\nconstant fixed gates) and LSTM_C6 (i.e., LSTM_6 with further reduced cell body\ninput block). We demonstrate that these two aggressively reduced-parameter\nvariants are competitive with the standard LSTM when hyper-parameters, e.g.,\nlearning parameter, number of hidden units and gate constants are set properly.\nThese architectures enable speeding up training computations and hence, these\nnetworks would be more suitable for online training and inference onto portable\ndevices with relatively limited computational resources.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 19:36:41 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Akandeh", "Atra", ""], ["Salem", "Fathi M.", ""]]}, {"id": "1901.06437", "submitter": "Karishma Sharma", "authors": "Karishma Sharma, Feng Qian, He Jiang, Natali Ruchansky, Ming Zhang,\n  Yan Liu", "title": "Combating Fake News: A Survey on Identification and Mitigation\n  Techniques", "comments": null, "journal-ref": "ACM Transactions on Intelligent Systems and Technology, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of fake news on social media has opened up new directions\nof research for timely identification and containment of fake news, and\nmitigation of its widespread impact on public opinion. While much of the\nearlier research was focused on identification of fake news based on its\ncontents or by exploiting users' engagements with the news on social media,\nthere has been a rising interest in proactive intervention strategies to\ncounter the spread of misinformation and its impact on society. In this survey,\nwe describe the modern-day problem of fake news and, in particular, highlight\nthe technical challenges associated with it. We discuss existing methods and\ntechniques applicable to both identification and mitigation, with a focus on\nthe significant advances in each method and their advantages and limitations.\nIn addition, research has often been limited by the quality of existing\ndatasets and their specific application contexts. To alleviate this problem, we\ncomprehensively compile and summarize characteristic features of available\ndatasets. Furthermore, we outline new directions of research to facilitate\nfuture development of effective and interdisciplinary solutions.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 22:57:09 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Sharma", "Karishma", ""], ["Qian", "Feng", ""], ["Jiang", "He", ""], ["Ruchansky", "Natali", ""], ["Zhang", "Ming", ""], ["Liu", "Yan", ""]]}, {"id": "1901.06444", "submitter": "Ahmed Elkelesh", "authors": "Ahmed Elkelesh, Moustafa Ebada, Sebastian Cammerer and Stephan ten\n  Brink", "title": "Genetic Algorithm-based Polar Code Construction for the AWGN Channel", "comments": "SCC 2019; 12th International ITG Conference on Systems,\n  Communications and Coding, Rostock, Germany, Feb. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new polar code construction framework (i.e., selecting the\nfrozen bit positions) for the additive white Gaussian noise (AWGN) channel,\ntailored to a given decoding algorithm, rather than based on the (not\nnecessarily optimal) assumption of successive cancellation (SC) decoding. The\nproposed framework is based on the Genetic Algorithm (GenAlg), where\npopulations (i.e., collections) of information sets evolve successively via\nevolutionary transformations based on their individual error-rate performance.\nThese populations converge towards an information set that fits the decoding\nbehavior. Using our proposed algorithm, we construct a polar code of length\n2048 with code rate 0.5, without the CRC-aid, tailored to plain successive\ncancellation list (SCL) decoding, achieving the same error-rate performance as\nthe CRC-aided SCL decoding, and leading to a coding gain of 1 dB at BER of\n$10^{-6}$. Further, a belief propagation (BP)-tailored polar code approaches\nthe SCL error-rate performance without any modifications in the decoding\nalgorithm itself.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 00:06:35 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Elkelesh", "Ahmed", ""], ["Ebada", "Moustafa", ""], ["Cammerer", "Sebastian", ""], ["Brink", "Stephan ten", ""]]}, {"id": "1901.06455", "submitter": "Boyi Liu", "authors": "Boyi Liu, Lujia Wang, Ming Liu", "title": "Lifelong Federated Reinforcement Learning: A Learning Architecture for\n  Navigation in Cloud Robotic Systems", "comments": null, "journal-ref": "IEEE Robotics and Automation Letters, Volume: 4, Issue:4, On\n  Page(s): 4555-4562, 2019", "doi": "10.1109/LRA.2019.2931179", "report-no": null, "categories": "cs.RO cs.AI cs.DC cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper was motivated by the problem of how to make robots fuse and\ntransfer their experience so that they can effectively use prior knowledge and\nquickly adapt to new environments. To address the problem, we present a\nlearning architecture for navigation in cloud robotic systems: Lifelong\nFederated Reinforcement Learning (LFRL). In the work, We propose a knowledge\nfusion algorithm for upgrading a shared model deployed on the cloud. Then,\neffective transfer learning methods in LFRL are introduced. LFRL is consistent\nwith human cognitive science and fits well in cloud robotic systems.\nExperiments show that LFRL greatly improves the efficiency of reinforcement\nlearning for robot navigation. The cloud robotic system deployment also shows\nthat LFRL is capable of fusing prior knowledge. In addition, we release a cloud\nrobotic navigation-learning website based on LFRL.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 02:09:14 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 08:32:03 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 07:09:50 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Liu", "Boyi", ""], ["Wang", "Lujia", ""], ["Liu", "Ming", ""]]}, {"id": "1901.06560", "submitter": "Leilani Gilpin", "authors": "Leilani H. Gilpin and Cecilia Testart and Nathaniel Fruchter and\n  Julius Adebayo", "title": "Explaining Explanations to Society", "comments": "NeurIPS 2018 Workshop on Ethical, Social and Governance Issues in AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a disconnect between explanatory artificial intelligence (XAI)\nmethods and the types of explanations that are useful for and demanded by\nsociety (policy makers, government officials, etc.) Questions that experts in\nartificial intelligence (AI) ask opaque systems provide inside explanations,\nfocused on debugging, reliability, and validation. These are different from\nthose that society will ask of these systems to build trust and confidence in\ntheir decisions. Although explanatory AI systems can answer many questions that\nexperts desire, they often don't explain why they made decisions in a way that\nis precise (true to the model) and understandable to humans. These outside\nexplanations can be used to build trust, comply with regulatory and policy\nchanges, and act as external validation. In this paper, we focus on XAI methods\nfor deep neural networks (DNNs) because of DNNs' use in decision-making and\ninherent opacity. We explore the types of questions that explanatory DNN\nsystems can answer and discuss challenges in building explanatory systems that\nprovide outside explanations for societal requirements and benefit.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 17:33:10 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Gilpin", "Leilani H.", ""], ["Testart", "Cecilia", ""], ["Fruchter", "Nathaniel", ""], ["Adebayo", "Julius", ""]]}, {"id": "1901.06569", "submitter": "John Schreck", "authors": "John S. Schreck, Connor W. Coley, Kyle J. M. Bishop", "title": "Learning retrosynthetic planning through self-play", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of retrosynthetic planning can be framed as one player game, in\nwhich the chemist (or a computer program) works backwards from a molecular\ntarget to simpler starting materials though a series of choices regarding which\nreactions to perform. This game is challenging as the combinatorial space of\npossible choices is astronomical, and the value of each choice remains\nuncertain until the synthesis plan is completed and its cost evaluated. Here,\nwe address this problem using deep reinforcement learning to identify policies\nthat make (near) optimal reaction choices during each step of retrosynthetic\nplanning. Using simulated experience or self-play, we train neural networks to\nestimate the expected synthesis cost or value of any given molecule based on a\nrepresentation of its molecular structure. We show that learned policies based\non this value network outperform heuristic approaches in synthesizing\nunfamiliar molecules from available starting materials using the fewest number\nof reactions. We discuss how the learned policies described here can be\nincorporated into existing synthesis planning tools and how they can be adapted\nto changes in the synthesis cost objective or material availability.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 18:43:43 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Schreck", "John S.", ""], ["Coley", "Connor W.", ""], ["Bishop", "Kyle J. M.", ""]]}, {"id": "1901.06595", "submitter": "Hexiang Hu", "authors": "Hexiang Hu, Ishan Misra, Laurens van der Maaten", "title": "Evaluating Text-to-Image Matching using Binary Image Selection (BISON)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing systems the ability to relate linguistic and visual content is one\nof the hallmarks of computer vision. Tasks such as text-based image retrieval\nand image captioning were designed to test this ability but come with\nevaluation measures that have a high variance or are difficult to interpret. We\nstudy an alternative task for systems that match text and images: given a text\nquery, the system is asked to select the image that best matches the query from\na pair of semantically similar images. The system's accuracy on this Binary\nImage SelectiON (BISON) task is interpretable, eliminates the reliability\nproblems of retrieval evaluations, and focuses on the system's ability to\nunderstand fine-grained visual structure. We gather a BISON dataset that\ncomplements the COCO dataset and use it to evaluate modern text-based image\nretrieval and image captioning systems. Our results provide novel insights into\nthe performance of these systems. The COCO-BISON dataset and corresponding\nevaluation code are publicly available from \\url{http://hexianghu.com/bison/}.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 22:12:01 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 16:34:48 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Hu", "Hexiang", ""], ["Misra", "Ishan", ""], ["van der Maaten", "Laurens", ""]]}, {"id": "1901.06610", "submitter": "Luis Fred", "authors": "Jader Abreu, Luis Fred, David Mac\\^edo, Cleber Zanchettin", "title": "Hierarchical Attentional Hybrid Neural Networks for Document\n  Classification", "comments": "Paper accepted at International Conference on Artificial Neural\n  Networks - ICANN 2019", "journal-ref": "2019 International Conference on Artificial Neural Networks\n  (ICANN)", "doi": "10.1007/978-3-030-30493-5_39", "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Document classification is a challenging task with important applications.\nThe deep learning approaches to the problem have gained much attention\nrecently. Despite the progress, the proposed models do not incorporate the\nknowledge of the document structure in the architecture efficiently and not\ntake into account the contexting importance of words and sentences. In this\npaper, we propose a new approach based on a combination of convolutional neural\nnetworks, gated recurrent units, and attention mechanisms for document\nclassification tasks. The main contribution of this work is the use of\nconvolution layers to extract more meaningful, generalizable and abstract\nfeatures by the hierarchical representation. The proposed method in this paper\nimproves the results of the current attention-based approaches for document\nclassification.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 01:48:43 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 17:49:18 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Abreu", "Jader", ""], ["Fred", "Luis", ""], ["Mac\u00eado", "David", ""], ["Zanchettin", "Cleber", ""]]}, {"id": "1901.06613", "submitter": "Tiancheng Zhao", "authors": "Maxine Eskenazi, Shikib Mehri, Evgeniia Razumovskaia and Tiancheng\n  Zhao", "title": "Beyond Turing: Intelligent Agents Centered on the User", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most research on intelligent agents centers on the agent and not on the user.\nWe look at the origins of agent-centric research for slot-filling, gaming and\nchatbot agents. We then argue that it is important to concentrate more on the\nuser. After reviewing relevant literature, some approaches for creating and\nassessing user-centric systems are proposed.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 02:25:23 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 12:28:57 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Eskenazi", "Maxine", ""], ["Mehri", "Shikib", ""], ["Razumovskaia", "Evgeniia", ""], ["Zhao", "Tiancheng", ""]]}, {"id": "1901.06620", "submitter": "Seyedeh Zahra Razavi", "authors": "S. Zahra Razavi, Lenhart K. Schubert, Benjamin Kane, Mohammad Rafayet\n  Ali, Kimberly Van Orden and Tianyi Ma", "title": "Dialogue Design and Management for Multi-Session Casual Conversation\n  with Older Adults", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of designing a conversational avatar capable of a\nsequence of casual conversations with older adults. Users at risk of\nloneliness, social anxiety or a sense of ennui may benefit from practicing such\nconversations in private, at their convenience. We describe an automatic spoken\ndialogue manager for LISSA, an on-screen virtual agent that can keep older\nusers involved in conversations over several sessions, each lasting 10-20\nminutes. The idea behind LISSA is to improve users' communication skills by\nproviding feedback on their non-verbal behavior at certain points in the course\nof the conversations. In this paper, we analyze the dialogues collected from\nthe first session between LISSA and each of 8 participants. We examine the\nquality of the conversations by comparing the transcripts with those collected\nin a WOZ setting. LISSA's contributions to the conversations were judged by\nresearch assistants who rated the extent to which the contributions were\n\"natural\", \"on track\", \"encouraging\", \"understanding\", \"relevant\", and\n\"polite\". The results show that the automatic dialogue manager was able to\nhandle conversation with the users smoothly and naturally.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 04:38:57 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 14:53:15 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Razavi", "S. Zahra", ""], ["Schubert", "Lenhart K.", ""], ["Kane", "Benjamin", ""], ["Ali", "Mohammad Rafayet", ""], ["Van Orden", "Kimberly", ""], ["Ma", "Tianyi", ""]]}, {"id": "1901.06622", "submitter": "Sandra Carrico", "authors": "Sandra Carrico", "title": "Mixed Formal Learning: A Path to Transparent Machine Learning", "comments": "Accepted IEEE ICSC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Mixed Formal Learning, a new architecture that learns\nmodels based on formal mathematical representations of the domain of interest\nand exposes latent variables. The second element in the architecture learns a\nparticular skill, typically by using traditional prediction or classification\nmechanisms. Our key findings include that this architecture: (1) Facilitates\ntransparency by exposing key latent variables based on a learned mathematical\nmodel; (2) Enables Low Shot and Zero Shot training of machine learning without\nsacrificing accuracy or recall.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 04:44:12 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Carrico", "Sandra", ""]]}, {"id": "1901.06631", "submitter": "Yuting Jia", "authors": "Yuting Jia, Qinqin Zhang, Weinan Zhang, Xinbing Wang", "title": "CommunityGAN: Community Detection with Generative Adversarial Nets", "comments": "11 pages, 9 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection refers to the task of discovering groups of vertices\nsharing similar properties or functions so as to understand the network data.\nWith the recent development of deep learning, graph representation learning\ntechniques are also utilized for community detection. However, the communities\ncan only be inferred by applying clustering algorithms based on learned vertex\nembeddings. These general cluster algorithms like K-means and Gaussian Mixture\nModel cannot output much overlapped communities, which have been proved to be\nvery common in many real-world networks. In this paper, we propose\nCommunityGAN, a novel community detection framework that jointly solves\noverlapping community detection and graph representation learning. First,\nunlike the embedding of conventional graph representation learning algorithms\nwhere the vector entry values have no specific meanings, the embedding of\nCommunityGAN indicates the membership strength of vertices to communities.\nSecond, a specifically designed Generative Adversarial Net (GAN) is adopted to\noptimize such embedding. Through the minimax competition between the\nmotif-level generator and discriminator, both of them can alternatively and\niteratively boost their performance and finally output a better community\nstructure. Extensive experiments on synthetic data and real-world tasks\ndemonstrate that CommunityGAN achieves substantial community detection\nperformance gains over the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 07:01:13 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 02:44:07 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 07:04:02 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Jia", "Yuting", ""], ["Zhang", "Qinqin", ""], ["Zhang", "Weinan", ""], ["Wang", "Xinbing", ""]]}, {"id": "1901.06773", "submitter": "Jinrong Guo", "authors": "Jinrong Guo, Wantao Liu, Wang Wang, Qu Lu, Songlin Hu, Jizhong Han,\n  Ruixuan Li", "title": "AccUDNN: A GPU Memory Efficient Accelerator for Training Ultra-deep\n  Neural Networks", "comments": "12 pages,11 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typically, Ultra-deep neural network(UDNN) tends to yield high-quality model,\nbut its training process is usually resource intensive and time-consuming.\nModern GPU's scarce DRAM capacity is the primary bottleneck that hinders the\ntrainability and the training efficiency of UDNN. In this paper, we present\n\"AccUDNN\", an accelerator that aims to make the utmost use of finite GPU memory\nresources to speed up the training process of UDNN. AccUDNN mainly includes two\nmodules: memory optimizer and hyperparameter tuner. Memory optimizer develops a\nperformance-model guided dynamic swap out/in strategy, by offloading\nappropriate data to host memory, GPU memory footprint can be significantly\nslashed to overcome the restriction of trainability of UDNN. After applying the\nmemory optimization strategy, hyperparameter tuner is designed to explore the\nefficiency-optimal minibatch size and the matched learning rate. Evaluations\ndemonstrate that AccUDNN cuts down the GPU memory requirement of ResNet-152\nfrom more than 24GB to 8GB. In turn, given 12GB GPU memory budget, the\nefficiency-optimal minibatch size can reach 4.2x larger than original Caffe.\nBenefiting from better utilization of single GPU's computing resources and\nfewer parameter synchronization of large minibatch size, 7.7x speed-up is\nachieved by 8 GPUs' cluster without any communication optimization and no\naccuracy losses.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 02:52:09 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 10:19:32 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Guo", "Jinrong", ""], ["Liu", "Wantao", ""], ["Wang", "Wang", ""], ["Lu", "Qu", ""], ["Hu", "Songlin", ""], ["Han", "Jizhong", ""], ["Li", "Ruixuan", ""]]}, {"id": "1901.06803", "submitter": "Sumit Kumar", "authors": "Sumit Kumar, Wenhao Luo, George Kantor, Katia Sycara", "title": "Active Learning with Gaussian Processes for High Throughput Phenotyping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A looming question that must be solved before robotic plant phenotyping\ncapabilities can have significant impact to crop improvement programs is\nscalability. High Throughput Phenotyping (HTP) uses robotic technologies to\nanalyze crops in order to determine species with favorable traits, however, the\ncurrent practices rely on exhaustive coverage and data collection from the\nentire crop field being monitored under the breeding experiment. This works\nwell in relatively small agricultural fields but can not be scaled to the\nlarger ones, thus limiting the progress of genetics research. In this work, we\npropose an active learning algorithm to enable an autonomous system to collect\nthe most informative samples in order to accurately learn the distribution of\nphenotypes in the field with the help of a Gaussian Process model. We\ndemonstrate the superior performance of our proposed algorithm compared to the\ncurrent practices on sorghum phenotype data collection.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 06:35:02 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Kumar", "Sumit", ""], ["Luo", "Wenhao", ""], ["Kantor", "George", ""], ["Sycara", "Katia", ""]]}, {"id": "1901.06834", "submitter": "Mahmoud Salamati", "authors": "Mahmoud Salamati, Sadegh Soudjani and Rupak Majumdar", "title": "Perception-in-the-Loop Adversarial Examples", "comments": "13 pages, 13 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a scalable, black box, perception-in-the-loop technique to find\nadversarial examples for deep neural network classifiers. Black box means that\nour procedure only has input-output access to the classifier, and not to the\ninternal structure, parameters, or intermediate confidence values.\nPerception-in-the-loop means that the notion of proximity between inputs can be\ndirectly queried from human participants rather than an arbitrarily chosen\nmetric. Our technique is based on covariance matrix adaptation evolution\nstrategy (CMA-ES), a black box optimization approach. CMA-ES explores the\nsearch space iteratively in a black box manner, by generating populations of\ncandidates according to a distribution, choosing the best candidates according\nto a cost function, and updating the posterior distribution to favor the best\ncandidates. We run CMA-ES using human participants to provide the fitness\nfunction, using the insight that the choice of best candidates in CMA-ES can be\nnaturally modeled as a perception task: pick the top $k$ inputs perceptually\nclosest to a fixed input. We empirically demonstrate that finding adversarial\nexamples is feasible using small populations and few iterations. We compare the\nperformance of CMA-ES on the MNIST benchmark with other black-box approaches\nusing $L_p$ norms as a cost function, and show that it performs favorably both\nin terms of success in finding adversarial examples and in minimizing the\ndistance between the original and the adversarial input. In experiments on the\nMNIST, CIFAR10, and GTSRB benchmarks, we demonstrate that CMA-ES can find\nperceptually similar adversarial inputs with a small number of iterations and\nsmall population sizes when using perception-in-the-loop. Finally, we show that\nnetworks trained specifically to be robust against $L_\\infty$ norm can still be\nsusceptible to perceptually similar adversarial examples.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 09:09:35 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Salamati", "Mahmoud", ""], ["Soudjani", "Sadegh", ""], ["Majumdar", "Rupak", ""]]}, {"id": "1901.06949", "submitter": "Ferdinando Fioretto", "authors": "Ferdinando Fioretto, Terrence W.K. Mak, Pascal Van Hentenryck", "title": "Differential Privacy for Power Grid Obfuscation", "comments": null, "journal-ref": "IEEE Transactions on Smart Grid, vol. 11, no. 2, pp. 1356-1366,\n  March 2020", "doi": "10.1109/TSG.2019.2936712", "report-no": null, "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of high-fidelity energy networks brings significant value to\nacademic and commercial research. However, such releases also raise fundamental\nconcerns related to privacy and security as they can reveal sensitive\ncommercial information and expose system vulnerabilities. This paper\ninvestigates how to release power networks where the parameters of transmission\nlines and transformers are obfuscated. It does so by using the framework of\nDifferential Privacy (DP), that provides strong privacy guarantees and has\nattracted significant attention in recent years. Unfortunately, simple DP\nmechanisms often result in AC-infeasible networks. To address these concerns,\nthis paper presents a novel differential privacy mechanism that guarantees\nAC-feasibility and largely preserves the fidelity of the obfuscated network.\nExperimental results also show that the obfuscation significantly reduces the\npotential damage of an attacker exploiting the release of the dataset.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 15:07:17 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 14:34:32 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Fioretto", "Ferdinando", ""], ["Mak", "Terrence W. K.", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1901.06965", "submitter": "Hongyang Gao", "authors": "Hongyang Gao, Yongjun Chen, Shuiwang Ji", "title": "Learning Graph Pooling and Hybrid Convolutional Operations for Text\n  Representations", "comments": "7 pages, WWW19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of graph convolutional networks (GCN), deep learning\nmethods have started to be used on graph data. In additional to convolutional\nlayers, pooling layers are another important components of deep learning.\nHowever, no effective pooling methods have been developed for graphs currently.\nIn this work, we propose the graph pooling (gPool) layer, which employs a\ntrainable projection vector to measure the importance of nodes in graphs. By\nselecting the k-most important nodes to form the new graph, gPool achieves the\nsame objective as regular max pooling layers operating on images. Another\nlimitation of GCN when used on graph-based text representation tasks is that,\nGCNs do not consider the order information of nodes in graph. To address this\nlimitation, we propose the hybrid convolutional (hConv) layer that combines GCN\nand regular convolutional operations. The hConv layer is capable of increasing\nreceptive fields quickly and computing features automatically. Based on the\nproposed gPool and hConv layers, we develop new deep networks for text\ncategorization tasks. Our results show that the networks based on gPool and\nhConv layers achieves new state-of-the-art performance as compared to baseline\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 15:35:43 GMT"}, {"version": "v2", "created": "Sun, 10 Mar 2019 04:48:56 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Gao", "Hongyang", ""], ["Chen", "Yongjun", ""], ["Ji", "Shuiwang", ""]]}, {"id": "1901.07005", "submitter": "Canwen Xu", "authors": "Canwen Xu, Jing Li, Xiangyang Luo, Jiaxin Pei, Chenliang Li and\n  Donghong Ji", "title": "DLocRL: A Deep Learning Pipeline for Fine-Grained Location Recognition\n  and Linking in Tweets", "comments": "7 pages, 4 figures, accepted by The Web Conf (WWW) 2019; final\n  version", "journal-ref": null, "doi": "10.1145/3308558.3313491", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, with the prevalence of social media and smart devices,\npeople causally reveal their locations such as shops, hotels, and restaurants\nin their tweets. Recognizing and linking such fine-grained location mentions to\nwell-defined location profiles are beneficial for retrieval and recommendation\nsystems. In this paper, we propose DLocRL, a new deep learning pipeline for\nfine-grained location recognition and linking in tweets, and verify its\neffectiveness on a real-world Twitter dataset.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 17:36:19 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 15:48:52 GMT"}, {"version": "v3", "created": "Sat, 2 Mar 2019 14:20:55 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Xu", "Canwen", ""], ["Li", "Jing", ""], ["Luo", "Xiangyang", ""], ["Pei", "Jiaxin", ""], ["Li", "Chenliang", ""], ["Ji", "Donghong", ""]]}, {"id": "1901.07023", "submitter": "Michael Garvie", "authors": "Michael Garvie and Phil Husbands", "title": "Automatic Synthesis of Totally Self-Checking Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Totally self-checking (TSC) circuits are synthesised with a grid of computers\nrunning a distributed population based stochastic optimisation algorithm. The\npresented method is the first to automatically synthesise TSC circuits from\narbitrary logic as all previous methods fail to guarantee the checker is\nself-testing (ST) for circuits with limited output codespaces. The circuits\nsynthesised by the presented method have significantly lower overhead than the\npreviously reported best for every one of a set of 11 frequently used\nbenchmarks. Average overhead across the entire set is 23% of duplication and\ncomparison overhead, compared with an average of 69% for the previous best\nreported values across the set. The methodology presented represents a\nbreakthrough in concurrent error detection (CED). The highly efficient, novel\ndesigns produced are tailored to each circuit's function, rather than being\nconstrained by a particular modular CED design methodology. Results are\nsynthesised using two-input gates and are TSC with respect to all gate input\nand output stuck-at faults. The method can be used to add CED with or without\nmodifications to the original logic, and can be generalised to any\nimplementation technology and fault model. An example circuit is analysed and\nrigorously proven to be TSC.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 18:26:46 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Garvie", "Michael", ""], ["Husbands", "Phil", ""]]}, {"id": "1901.07031", "submitter": "Jeremy Irvin", "authors": "Jeremy Irvin, Pranav Rajpurkar, Michael Ko, Yifan Yu, Silviana\n  Ciurea-Ilcus, Chris Chute, Henrik Marklund, Behzad Haghgoo, Robyn Ball, Katie\n  Shpanskaya, Jayne Seekins, David A. Mong, Safwan S. Halabi, Jesse K.\n  Sandberg, Ricky Jones, David B. Larson, Curtis P. Langlotz, Bhavik N. Patel,\n  Matthew P. Lungren, Andrew Y. Ng", "title": "CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and\n  Expert Comparison", "comments": "Published in AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large, labeled datasets have driven deep learning methods to achieve\nexpert-level performance on a variety of medical imaging tasks. We present\nCheXpert, a large dataset that contains 224,316 chest radiographs of 65,240\npatients. We design a labeler to automatically detect the presence of 14\nobservations in radiology reports, capturing uncertainties inherent in\nradiograph interpretation. We investigate different approaches to using the\nuncertainty labels for training convolutional neural networks that output the\nprobability of these observations given the available frontal and lateral\nradiographs. On a validation set of 200 chest radiographic studies which were\nmanually annotated by 3 board-certified radiologists, we find that different\nuncertainty approaches are useful for different pathologies. We then evaluate\nour best model on a test set composed of 500 chest radiographic studies\nannotated by a consensus of 5 board-certified radiologists, and compare the\nperformance of our model to that of 3 additional radiologists in the detection\nof 5 selected pathologies. On Cardiomegaly, Edema, and Pleural Effusion, the\nmodel ROC and PR curves lie above all 3 radiologist operating points. We\nrelease the dataset to the public as a standard benchmark to evaluate\nperformance of chest radiograph interpretation models.\n  The dataset is freely available at\nhttps://stanfordmlgroup.github.io/competitions/chexpert .\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 18:41:59 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Irvin", "Jeremy", ""], ["Rajpurkar", "Pranav", ""], ["Ko", "Michael", ""], ["Yu", "Yifan", ""], ["Ciurea-Ilcus", "Silviana", ""], ["Chute", "Chris", ""], ["Marklund", "Henrik", ""], ["Haghgoo", "Behzad", ""], ["Ball", "Robyn", ""], ["Shpanskaya", "Katie", ""], ["Seekins", "Jayne", ""], ["Mong", "David A.", ""], ["Halabi", "Safwan S.", ""], ["Sandberg", "Jesse K.", ""], ["Jones", "Ricky", ""], ["Larson", "David B.", ""], ["Langlotz", "Curtis P.", ""], ["Patel", "Bhavik N.", ""], ["Lungren", "Matthew P.", ""], ["Ng", "Andrew Y.", ""]]}, {"id": "1901.07152", "submitter": "Hai Shu", "authors": "Hai Shu, Hongtu Zhu", "title": "Sensitivity Analysis of Deep Neural Networks", "comments": "Accepted by AAAI-19", "journal-ref": "AAAI Conference on Artificial Intelligence (2019), pp. 4943-4950", "doi": "10.1609/aaai.v33i01.33014943", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved superior performance in various\nprediction tasks, but can be very vulnerable to adversarial examples or\nperturbations. Therefore, it is crucial to measure the sensitivity of DNNs to\nvarious forms of perturbations in real applications. We introduce a novel\nperturbation manifold and its associated influence measure to quantify the\neffects of various perturbations on DNN classifiers. Such perturbations include\nvarious external and internal perturbations to input samples and network\nparameters. The proposed measure is motivated by information geometry and\nprovides desirable invariance properties. We demonstrate that our influence\nmeasure is useful for four model building tasks: detecting potential\n'outliers', analyzing the sensitivity of model architectures, comparing network\nsensitivity between training and test sets, and locating vulnerable areas.\nExperiments show reasonably good performance of the proposed measure for the\npopular DNN models ResNet50 and DenseNet121 on CIFAR10 and MNIST datasets.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 02:14:16 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Shu", "Hai", ""], ["Zhu", "Hongtu", ""]]}, {"id": "1901.07176", "submitter": "Anupiya Nugaliyadde Mr", "authors": "Anupiya Nugaliyadde, Kok Wai Wong, Ferdous Sohel, Hong Xie", "title": "Enhancing Semantic Word Representations by Embedding Deeper Word\n  Relationships", "comments": "Accepted for the International Conference on Computer and Automation\n  Engineering (ICCAE) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word representations are created using analogy context-based statistics and\nlexical relations on words. Word representations are inputs for the learning\nmodels in Natural Language Understanding (NLU) tasks. However, to understand\nlanguage, knowing only the context is not sufficient. Reading between the lines\nis a key component of NLU. Embedding deeper word relationships which are not\nrepresented in the context enhances the word representation. This paper\npresents a word embedding which combines an analogy, context-based statistics\nusing Word2Vec, and deeper word relationships using Conceptnet, to create an\nexpanded word representation. In order to fine-tune the word representation,\nSelf-Organizing Map is used to optimize it. The proposed word representation is\ncompared with semantic word representations using Simlex 999. Furthermore, the\nuse of 3D visual representations has shown to be capable of representing the\nsimilarity and association between words. The proposed word representation\nshows a Spearman correlation score of 0.886 and provided the best results when\ncompared to the current state-of-the-art methods, and exceed the human\nperformance of 0.78.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 05:31:54 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Nugaliyadde", "Anupiya", ""], ["Wong", "Kok Wai", ""], ["Sohel", "Ferdous", ""], ["Xie", "Hong", ""]]}, {"id": "1901.07191", "submitter": "Chang-Shing Lee", "authors": "Chang-Shing Lee, Mei-Hui Wang, Li-Chuang Chen, Yusuke Nojima,\n  Tzong-Xiang Huang, Jinseok Woo, Naoyuki Kubota, Eri Sato-Shimokawara, Toru\n  Yamaguchi", "title": "A GFML-based Robot Agent for Human and Machine Cooperative Learning on\n  Game of Go", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper applies a genetic algorithm and fuzzy markup language to construct\na human and smart machine cooperative learning system on game of Go. The\ngenetic fuzzy markup language (GFML)-based Robot Agent can work on various\nkinds of robots, including Palro, Pepper, and TMUs robots. We use the\nparameters of FAIR open source Darkforest and OpenGo AI bots to construct the\nknowledge base of Open Go Darkforest (OGD) cloud platform for student learning\non the Internet. In addition, we adopt the data from AlphaGo Master sixty\nonline games as the training data to construct the knowledge base and rule base\nof the co-learning system. First, the Darkforest predicts the win rate based on\nvarious simulation numbers and matching rates for each game on OGD platform,\nthen the win rate of OpenGo is as the final desired output. The experimental\nresults show that the proposed approach can improve knowledge base and rule\nbase of the prediction ability based on Darkforest and OpenGo AI bot with\nvarious simulation numbers.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 07:35:08 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Lee", "Chang-Shing", ""], ["Wang", "Mei-Hui", ""], ["Chen", "Li-Chuang", ""], ["Nojima", "Yusuke", ""], ["Huang", "Tzong-Xiang", ""], ["Woo", "Jinseok", ""], ["Kubota", "Naoyuki", ""], ["Sato-Shimokawara", "Eri", ""], ["Yamaguchi", "Toru", ""]]}, {"id": "1901.07199", "submitter": "Guangneng Hu", "authors": "Guangneng Hu, Yu Zhang, and Qiang Yang", "title": "Transfer Meets Hybrid: A Synthetic Approach for Cross-Domain\n  Collaborative Filtering with Text", "comments": "11 pages, 7 figures, a full version for the WWW 2019 short paper", "journal-ref": "WWW 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering (CF) is the key technique for recommender systems\n(RSs). CF exploits user-item behavior interactions (e.g., clicks) only and\nhence suffers from the data sparsity issue. One research thread is to integrate\nauxiliary information such as product reviews and news titles, leading to\nhybrid filtering methods. Another thread is to transfer knowledge from other\nsource domains such as improving the movie recommendation with the knowledge\nfrom the book domain, leading to transfer learning methods. In real-world life,\nno single service can satisfy a user's all information needs. Thus it motivates\nus to exploit both auxiliary and source information for RSs in this paper. We\npropose a novel neural model to smoothly enable Transfer Meeting Hybrid (TMH)\nmethods for cross-domain recommendation with unstructured text in an end-to-end\nmanner. TMH attentively extracts useful content from unstructured text via a\nmemory module and selectively transfers knowledge from a source domain via a\ntransfer network. On two real-world datasets, TMH shows better performance in\nterms of three ranking metrics by comparing with various baselines. We conduct\nthorough analyses to understand how the text content and transferred knowledge\nhelp the proposed model.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 08:05:34 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Hu", "Guangneng", ""], ["Zhang", "Yu", ""], ["Yang", "Qiang", ""]]}, {"id": "1901.07222", "submitter": "Deepak Gupta", "authors": "Deepak K. Gupta, Rohit K. Shrivastava, Suhas Phadke and Jeroen\n  Goudswaard", "title": "Unsupervised Automated Event Detection using an Iterative Clustering\n  based Segmentation Approach", "comments": "14 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A class of vision problems, less commonly studied, consists of detecting\nobjects in imagery obtained from physics-based experiments. These objects can\nspan in 4D (x, y, z, t) and are visible as disturbances (caused due to physical\nphenomena) in the image with background distribution being approximately\nuniform. Such objects, occasionally referred to as `events', can be considered\nas high energy blobs in the image. Unlike the images analyzed in conventional\nvision problems, very limited features are associated with such events, and\ntheir shape, size and count can vary significantly. This poses a challenge on\nthe use of pre-trained models obtained from supervised approaches.\n  In this paper, we propose an unsupervised approach involving iterative\nclustering based segmentation (ICS) which can detect target objects (events) in\nreal-time. In this approach, a test image is analyzed over several cycles, and\none event is identified per cycle. Each cycle consists of the following steps:\n(1) image segmentation using a modified k-means clustering method, (2)\nelimination of empty (with no events) segments based on statistical analysis of\neach segment, (3) merging segments that overlap (correspond to same event), and\n(4) selecting the strongest event. These four steps are repeated until all the\nevents have been identified. The ICS approach consists of a few\nhyper-parameters that have been chosen based on statistical study performed\nover a set of test images. The applicability of ICS method is demonstrated on\nseveral 2D and 3D test examples.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 09:24:58 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Gupta", "Deepak K.", ""], ["Shrivastava", "Rohit K.", ""], ["Phadke", "Suhas", ""], ["Goudswaard", "Jeroen", ""]]}, {"id": "1901.07223", "submitter": "Rong Kang", "authors": "Rong Kang, Jieqi Shi, Xueming Li, Yang Liu, Xiao Liu", "title": "DF-SLAM: A Deep-Learning Enhanced Visual SLAM System based on Deep Local\n  Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the foundation of driverless vehicle and intelligent robots, Simultaneous\nLocalization and Mapping(SLAM) has attracted much attention these days.\nHowever, non-geometric modules of traditional SLAM algorithms are limited by\ndata association tasks and have become a bottleneck preventing the development\nof SLAM. To deal with such problems, many researchers seek to Deep Learning for\nhelp. But most of these studies are limited to virtual datasets or specific\nenvironments, and even sacrifice efficiency for accuracy. Thus, they are not\npractical enough.\n  We propose DF-SLAM system that uses deep local feature descriptors obtained\nby the neural network as a substitute for traditional hand-made features.\nExperimental results demonstrate its improvements in efficiency and stability.\nDF-SLAM outperforms popular traditional SLAM systems in various scenes,\nincluding challenging scenes with intense illumination changes. Its versatility\nand mobility fit well into the need for exploring new environments. Since we\nadopt a shallow network to extract local descriptors and remain others the same\nas original SLAM systems, our DF-SLAM can still run in real-time on GPU.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 09:25:08 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 11:22:55 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Kang", "Rong", ""], ["Shi", "Jieqi", ""], ["Li", "Xueming", ""], ["Liu", "Yang", ""], ["Liu", "Xiao", ""]]}, {"id": "1901.07272", "submitter": "Kai Olav Ellefsen", "authors": "Kai Olav Ellefsen, Herman A. Lepikson and Jan C. Albiez", "title": "Multiobjective Coverage Path Planning: Enabling Automated Inspection of\n  Complex, Real-World Structures", "comments": "Video Summary available at: https://youtu.be/ESzqJsDusd8", "journal-ref": "Applied Soft Computing 61 (2017): 264-282", "doi": "10.1016/j.asoc.2017.07.051", "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important open problem in robotic planning is the autonomous generation of\n3D inspection paths -- that is, planning the best path to move a robot along in\norder to inspect a target structure. We recently suggested a new method for\nplanning paths allowing the inspection of complex 3D structures, given a\ntriangular mesh model of the structure. The method differs from previous\napproaches in its emphasis on generating and considering also plans that result\nin imperfect coverage of the inspection target. In many practical tasks, one\nwould accept imperfections in coverage if this results in a substantially more\nenergy efficient inspection path. The key idea is using a multiobjective\nevolutionary algorithm to optimize the energy usage and coverage of inspection\nplans simultaneously - and the result is a set of plans exploring the different\nways to balance the two objectives. We here test our method on a set of\ninspection targets with large variation in size and complexity, and compare its\nperformance with two state-of-the-art methods for complete coverage path\nplanning. The results strengthen our confidence in the ability of our method to\ngenerate good inspection plans for different types of targets. The method's\nadvantage is most clearly seen for real-world inspection targets, since\ntraditional complete coverage methods have no good way of generating plans for\nstructures with hidden parts. Multiobjective evolution, by optimizing energy\nusage and coverage together ensures a good balance between the two - both when\n100% coverage is feasible, and when large parts of the object are hidden.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 11:42:41 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Ellefsen", "Kai Olav", ""], ["Lepikson", "Herman A.", ""], ["Albiez", "Jan C.", ""]]}, {"id": "1901.07387", "submitter": "Asifullah Khan", "authors": "Asifullah Khan, Aqsa Saeed Qureshi, Noorul Wahab, Mutawara Hussain,\n  and Muhammad Yousaf Hamza", "title": "A Recent Survey on the Applications of Genetic Programming in Image\n  Processing", "comments": "31 pages, 12 figures, and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic Programming (GP) has been primarily used to tackle optimization,\nclassification, and feature selection related tasks. The widespread use of GP\nis due to its flexible and comprehensible tree-type structure. Similarly,\nresearch is also gaining momentum in the field of Image Processing, because of\nits promising results over vast areas of applications ranging from medical\nImage Processing to multispectral imaging. Image Processing is mainly involved\nin applications such as computer vision, pattern recognition, image\ncompression, storage, and medical diagnostics. This universal nature of images\nand their associated algorithm, i.e., complexities, gave an impetus to the\nexploration of GP. GP has thus been used in different ways for Image Processing\nsince its inception. Many interesting GP techniques have been developed and\nemployed in the field of Image Processing, and consequently, we aim to provide\nthe research community an extensive view of these techniques. This survey thus\npresents the diverse applications of GP in Image Processing and provides useful\nresources for further research. Also, the comparison of different parameters\nused in different applications of Image Processing is summarized in tabular\nform. Moreover, analysis of the different parameters used in Image Processing\nrelated tasks is carried-out to save the time needed in the future for\nevaluating the parameters of GP. As more advancement is made in GP\nmethodologies, its success in solving complex tasks, not only in Image\nProcessing but also in other fields, may increase. Additionally, guidelines are\nprovided for applying GP in Image Processing related tasks, the pros and cons\nof GP techniques are discussed, and some future directions are also set.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 14:12:32 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 09:22:33 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 20:42:22 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Khan", "Asifullah", ""], ["Qureshi", "Aqsa Saeed", ""], ["Wahab", "Noorul", ""], ["Hussain", "Mutawara", ""], ["Hamza", "Muhammad Yousaf", ""]]}, {"id": "1901.07469", "submitter": "Nilavra Pathak", "authors": "Nilavra Pathak, James Foulds, Nirmalya Roy, Nilanjan Banerjee, Ryan\n  Robucci", "title": "Estimating Buildings' Parameters over Time Including Prior Knowledge", "comments": "11 pages with reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling buildings' heat dynamics is a complex process which depends on\nvarious factors including weather, building thermal capacity, insulation\npreservation, and residents' behavior. Gray-box models offer a causal inference\nof those dynamics expressed in few parameters specific to built environments.\nThese parameters can provide compelling insights into the characteristics of\nbuilding artifacts and have various applications such as forecasting HVAC\nusage, indoor temperature control monitoring of built environments, etc. In\nthis paper, we present a systematic study of modeling buildings' thermal\ncharacteristics and thus derive the parameters of built conditions with a\nBayesian approach. We build a Bayesian state-space model that can adapt and\nincorporate buildings' thermal equations and propose a generalized solution\nthat can easily adapt prior knowledge regarding the parameters. We show that a\nfaster approximate approach using variational inference for parameter\nestimation can provide similar parameters as that of a more time-consuming\nMarkov Chain Monte Carlo (MCMC) approach. We perform extensive evaluations on\ntwo datasets to understand the generative process and show that the Bayesian\napproach is more interpretable. We further study the effects of prior selection\nfor the model parameters and transfer learning, where we learn parameters from\none season and use them to fit the model in the other. We perform extensive\nevaluations on controlled and real data traces to enumerate buildings'\nparameter within a 95% credible interval.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 03:37:32 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 22:47:47 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2019 23:53:36 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Pathak", "Nilavra", ""], ["Foulds", "James", ""], ["Roy", "Nirmalya", ""], ["Banerjee", "Nilanjan", ""], ["Robucci", "Ryan", ""]]}, {"id": "1901.07474", "submitter": "Xiao Wang", "authors": "Xiao Wang, Shaofei Zheng, Rui Yang, Bin Luo and Jin Tang", "title": "Pedestrian Attribute Recognition: A Survey", "comments": "Check our project page for High Resolution version of this survey:\n  https://sites.google.com/view/ahu-pedestrianattributes/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing pedestrian attributes is an important task in computer vision\ncommunity due to it plays an important role in video surveillance. Many\nalgorithms has been proposed to handle this task. The goal of this paper is to\nreview existing works using traditional methods or based on deep learning\nnetworks. Firstly, we introduce the background of pedestrian attributes\nrecognition (PAR, for short), including the fundamental concepts of pedestrian\nattributes and corresponding challenges. Secondly, we introduce existing\nbenchmarks, including popular datasets and evaluation criterion. Thirdly, we\nanalyse the concept of multi-task learning and multi-label learning, and also\nexplain the relations between these two learning algorithms and pedestrian\nattribute recognition. We also review some popular network architectures which\nhave widely applied in the deep learning community. Fourthly, we analyse\npopular solutions for this task, such as attributes group, part-based,\n\\emph{etc}. Fifthly, we shown some applications which takes pedestrian\nattributes into consideration and achieve better performance. Finally, we\nsummarized this paper and give several possible research directions for\npedestrian attributes recognition. The project page of this paper can be found\nfrom the following website:\n\\url{https://sites.google.com/view/ahu-pedestrianattributes/}.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 17:16:49 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Wang", "Xiao", ""], ["Zheng", "Shaofei", ""], ["Yang", "Rui", ""], ["Luo", "Bin", ""], ["Tang", "Jin", ""]]}, {"id": "1901.07517", "submitter": "Joonho Lee", "authors": "Joonho Lee, Jemin Hwangbo, and Marco Hutter", "title": "Robust Recovery Controller for a Quadrupedal Robot using Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to recover from a fall is an essential feature for a legged robot\nto navigate in challenging environments robustly. Until today, there has been\nvery little progress on this topic. Current solutions mostly build upon\n(heuristically) predefined trajectories, resulting in unnatural behaviors and\nrequiring considerable effort in engineering system-specific components. In\nthis paper, we present an approach based on model-free Deep Reinforcement\nLearning (RL) to control recovery maneuvers of quadrupedal robots using a\nhierarchical behavior-based controller. The controller consists of four neural\nnetwork policies including three behaviors and one behavior selector to\ncoordinate them. Each of them is trained individually in simulation and\ndeployed directly on a real system. We experimentally validate our approach on\nthe quadrupedal robot ANYmal, which is a dog-sized quadrupedal system with 12\ndegrees of freedom. With our method, ANYmal manifests dynamic and reactive\nrecovery behaviors to recover from an arbitrary fall configuration within less\nthan 5 seconds. We tested the recovery maneuver more than 100 times, and the\nsuccess rate was higher than 97 %.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 18:45:42 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Lee", "Joonho", ""], ["Hwangbo", "Jemin", ""], ["Hutter", "Marco", ""]]}, {"id": "1901.07538", "submitter": "Quanshi Zhang", "authors": "Quanshi Zhang, Yu Yang, Ying Nian Wu", "title": "Unsupervised Learning of Neural Networks to Explain Neural Networks\n  (extended abstract)", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning.\n  arXiv admin note: substantial text overlap with arXiv:1805.07468", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an unsupervised method to learn a neural network, namely\nan explainer, to interpret a pre-trained convolutional neural network (CNN),\ni.e., the explainer uses interpretable visual concepts to explain features in\nmiddle conv-layers of a CNN. Given feature maps of a conv-layer of the CNN, the\nexplainer performs like an auto-encoder, which decomposes the feature maps into\nobject-part features. The object-part features are learned to reconstruct CNN\nfeatures without much loss of information. We can consider the disentangled\nrepresentations of object parts a paraphrase of CNN features, which help people\nunderstand the knowledge encoded by the CNN. More crucially, we learn the\nexplainer via knowledge distillation without using any annotations of object\nparts or textures for supervision. In experiments, our method was widely used\nto interpret features of different benchmark CNNs, and explainers significantly\nboosted the feature interpretability without hurting the discrimination power\nof the CNNs.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 16:03:31 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Zhang", "Quanshi", ""], ["Yang", "Yu", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1901.07592", "submitter": "Christian H\\\"ager", "authors": "Mengke Lian, Christian H\\\"ager, Henry D. Pfister", "title": "What Can Machine Learning Teach Us about Communications?", "comments": "5 pages, 4 figures, paper presented at ITW 2018, corrected version\n  and updated reference list", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid improvements in machine learning over the past decade are beginning to\nhave far-reaching effects. For communications, engineers with limited domain\nexpertise can now use off-the-shelf learning packages to design\nhigh-performance systems based on simulations. Prior to the current revolution\nin machine learning, the majority of communication engineers were quite aware\nthat system parameters (such as filter coefficients) could be learned using\nstochastic gradient descent. It was not at all clear, however, that more\ncomplicated parts of the system architecture could be learned as well. In this\npaper, we discuss the application of machine-learning techniques to two\ncommunications problems and focus on what can be learned from the resulting\nsystems. We were pleasantly surprised that the observed gains in one example\nhave a simple explanation that only became clear in hindsight. In essence, deep\nlearning discovered a simple and effective strategy that had not been\nconsidered earlier.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 19:41:44 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 01:29:07 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Lian", "Mengke", ""], ["H\u00e4ger", "Christian", ""], ["Pfister", "Henry D.", ""]]}, {"id": "1901.07621", "submitter": "Eric Steinberger", "authors": "Eric Steinberger", "title": "Single Deep Counterfactual Regret Minimization", "comments": "4th version changes: fix minor notational errors; improve format;\n  incorporate structural feedback from NeurIPS review; *RESULTS ARE UNCHANGED*", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual Regret Minimization (CFR) is the most successful algorithm for\nfinding approximate Nash equilibria in imperfect information games. However,\nCFR's reliance on full game-tree traversals limits its scalability. For this\nreason, the game's state- and action-space is often abstracted (i.e.\nsimplified) for CFR, and the resulting strategy is then translated back to the\nfull game, which requires extensive expert-knowledge and often converges to\nhighly exploitable policies. A recently proposed method, Deep CFR, applies deep\nlearning directly to CFR, allowing the agent to intrinsically abstract and\ngeneralize over the state-space from samples, without requiring expert\nknowledge. In this paper, we introduce Single Deep CFR (SD-CFR), a simplified\nvariant of Deep CFR that has a lower overall approximation error by avoiding\nthe training of an average strategy network. We show that SD-CFR is more\nattractive from a theoretical perspective and empirically outperforms Deep CFR\nwith respect to exploitability and one-on-one play in poker.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 21:52:29 GMT"}, {"version": "v2", "created": "Sun, 10 Feb 2019 15:04:02 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2019 17:32:41 GMT"}, {"version": "v4", "created": "Fri, 4 Oct 2019 14:55:20 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Steinberger", "Eric", ""]]}, {"id": "1901.07646", "submitter": "Sumit Kumar", "authors": "Sumit Kumar, Shushman Choudhary, Siddhartha Srinivasa", "title": "Learning Configuration Space Belief Model from Collision Checks for\n  Motion Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For motion planning in high dimensional configuration spaces, a significant\ncomputational bottleneck is collision detection. Our aim is to reduce the\nexpected number of collision checks by creating a belief model of the\nconfiguration space using results from collision tests. We assume the robot's\nconfiguration space to be a continuous ambient space whereby neighbouring\npoints tend to share the same collision state. This enables us to formulate a\nprobabilistic model that assigns to unevaluated configurations a belief\nestimate of being collision-free. We have presented a detailed comparative\nanalysis of various kNN methods and distance metrics used to evaluate C-space\nbelief. We have also proposed a weighting matrix in C-space to improve the\nperformance of kNN methods. Moreover, we have proposed a topological method\nthat exploits the higher order structure of the C-space to generate a belief\nmodel. Our results indicate that our proposed topological method outperforms\nkNN methods by achieving higher model accuracy while being computationally\nefficient.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 23:33:34 GMT"}, {"version": "v2", "created": "Sun, 10 Feb 2019 04:43:53 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Kumar", "Sumit", ""], ["Choudhary", "Shushman", ""], ["Srinivasa", "Siddhartha", ""]]}, {"id": "1901.07647", "submitter": "Jong Chul Ye", "authors": "Jong Chul Ye and Woon Kyoung Sung", "title": "Understanding Geometry of Encoder-Decoder CNNs", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoder-decoder networks using convolutional neural network (CNN)\narchitecture have been extensively used in deep learning literatures thanks to\nits excellent performance for various inverse problems. However, it is still\ndifficult to obtain coherent geometric view why such an architecture gives the\ndesired performance. Inspired by recent theoretical understanding on\ngeneralizability, expressivity and optimization landscape of neural networks,\nas well as the theory of convolutional framelets, here we provide a unified\ntheoretical framework that leads to a better understanding of geometry of\nencoder-decoder CNNs. Our unified mathematical framework shows that\nencoder-decoder CNN architecture is closely related to nonlinear basis\nrepresentation using combinatorial convolution frames, whose expressibility\nincreases exponentially with the network depth. We also demonstrate the\nimportance of skipped connection in terms of expressibility, and optimization\nlandscape.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 23:37:43 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 13:56:00 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Ye", "Jong Chul", ""], ["Sung", "Woon Kyoung", ""]]}, {"id": "1901.07667", "submitter": "Yeu-Chern Harn", "authors": "Yeu-Chern Harn, Zhenghao Chen, and Vladimir Jojic", "title": "Composition and decomposition of GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a composition/decomposition framework for\nadversarially training generative models on composed data - data where each\nsample can be thought of as being constructed from a fixed number of\ncomponents. In our framework, samples are generated by sampling components from\ncomponent generators and feeding these components to a composition function\nwhich combines them into a \"composed sample\". This compositional training\napproach improves the modularity, extensibility and interpretability of\nGenerative Adversarial Networks (GANs) - providing a principled way to\nincrementally construct complex models out of simpler component models, and\nallowing for explicit \"division of responsibility\" between these components.\nUsing this framework, we define a family of learning tasks and evaluate their\nfeasibility on two datasets in two different data modalities (image and text).\nLastly, we derive sufficient conditions such that these compositional\ngenerative models are identifiable. Our work provides a principled approach to\nbuilding on pre-trained generative models or for exploiting the compositional\nnature of data distributions to train extensible and interpretable models.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 00:48:45 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Harn", "Yeu-Chern", ""], ["Chen", "Zhenghao", ""], ["Jojic", "Vladimir", ""]]}, {"id": "1901.07677", "submitter": "Dario Pavllo", "authors": "Dario Pavllo, Christoph Feichtenhofer, Michael Auli, David Grangier", "title": "Modeling Human Motion with Quaternion-based Neural Networks", "comments": "Follow-up work of arXiv:1805.06485. This is a pre-print of an article\n  published in IJCV. The final authenticated version is available online at\n  https://doi.org/10.1007/s11263-019-01245-6", "journal-ref": "International Journal of Computer Vision (Special Issue on Machine\n  Vision with Deep Learning), 2019. Online ISSN: 1573-1405", "doi": "10.1007/s11263-019-01245-6", "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work on predicting or generating 3D human pose sequences regresses\neither joint rotations or joint positions. The former strategy is prone to\nerror accumulation along the kinematic chain, as well as discontinuities when\nusing Euler angles or exponential maps as parameterizations. The latter\nrequires re-projection onto skeleton constraints to avoid bone stretching and\ninvalid configurations. This work addresses both limitations. QuaterNet\nrepresents rotations with quaternions and our loss function performs forward\nkinematics on a skeleton to penalize absolute position errors instead of angle\nerrors. We investigate both recurrent and convolutional architectures and\nevaluate on short-term prediction and long-term generation. For the latter, our\napproach is qualitatively judged as realistic as recent neural strategies from\nthe graphics literature. Our experiments compare quaternions to Euler angles as\nwell as exponential maps and show that only a very short context is required to\nmake reliable future predictions. Finally, we show that the standard evaluation\nprotocol for Human3.6M produces high variance results and we propose a simple\nsolution.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 23:56:54 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 14:49:53 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Pavllo", "Dario", ""], ["Feichtenhofer", "Christoph", ""], ["Auli", "Michael", ""], ["Grangier", "David", ""]]}, {"id": "1901.07696", "submitter": "Shen Gao", "authors": "Shen Gao, Zhaochun Ren, Yihong Eric Zhao, Dongyan Zhao, Dawei Yin, Rui\n  Yan", "title": "Product-Aware Answer Generation in E-Commerce Question-Answering", "comments": "Accepted by WSDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In e-commerce portals, generating answers for product-related questions has\nbecome a crucial task. In this paper, we propose the task of product-aware\nanswer generation, which tends to generate an accurate and complete answer from\nlarge-scale unlabeled e-commerce reviews and product attributes. Unlike\nexisting question-answering problems, answer generation in e-commerce confronts\nthree main challenges: (1) Reviews are informal and noisy; (2) joint modeling\nof reviews and key-value product attributes is challenging; (3) traditional\nmethods easily generate meaningless answers. To tackle above challenges, we\npropose an adversarial learning based model, named PAAG, which is composed of\nthree components: a question-aware review representation module, a key-value\nmemory network encoding attributes, and a recurrent neural network as a\nsequence generator. Specifically, we employ a convolutional discriminator to\ndistinguish whether our generated answer matches the facts. To extract the\nsalience part of reviews, an attention-based review reader is proposed to\ncapture the most relevant words given the question. Conducted on a large-scale\nreal-world e-commerce dataset, our extensive experiments verify the\neffectiveness of each module in our proposed model. Moreover, our experiments\nshow that our model achieves the state-of-the-art performance in terms of both\nautomatic metrics and human evaluations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 02:33:52 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 04:31:56 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Gao", "Shen", ""], ["Ren", "Zhaochun", ""], ["Zhao", "Yihong Eric", ""], ["Zhao", "Dongyan", ""], ["Yin", "Dawei", ""], ["Yan", "Rui", ""]]}, {"id": "1901.07733", "submitter": "Peng Jiang Dr.", "authors": "Shucai Li, Bin Liu, Yuxiao Ren, Yangkang Chen, Senlin Yang, Yunhai\n  Wang, Peng Jiang", "title": "Deep-Learning Inversion of Seismic Data", "comments": null, "journal-ref": "IEEE Transactions on Geoscience and Remote Sensing, vol. 58, no.\n  3, pp. 2135-2149, March 2020", "doi": "10.1109/TGRS.2019.2953473", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method to tackle the mapping challenge from time-series data\nto spatial image in the field of seismic exploration, i.e., reconstructing the\nvelocity model directly from seismic data by deep neural networks (DNNs). The\nconventional way of addressing this ill-posed inversion problem is through\niterative algorithms, which suffer from poor nonlinear mapping and strong\nnonuniqueness. Other attempts may either import human intervention errors or\nunderuse seismic data. The challenge for DNNs mainly lies in the weak spatial\ncorrespondence, the uncertain reflection-reception relationship between seismic\ndata and velocity model, as well as the time-varying property of seismic data.\nTo tackle these challenges, we propose end-to-end seismic inversion networks\n(SeisInvNets) with novel components to make the best use of all seismic data.\nSpecifically, we start with every seismic trace and enhance it with its\nneighborhood information, its observation setup, and the global context of its\ncorresponding seismic profile. From the enhanced seismic traces, the spatially\naligned feature maps can be learned and further concatenated to reconstruct a\nvelocity model. In general, we let every seismic trace contribute to the\nreconstruction of the whole velocity model by finding spatial correspondence.\nThe proposed SeisInvNet consistently produces improvements over the baselines\nand achieves promising performance on our synthesized and proposed SeisInv data\nset according to various evaluation metrics. The inversion results are more\nconsistent with the target from the aspects of velocity values, subsurface\nstructures, and geological interfaces. Moreover, the mechanism and the\ngeneralization of the proposed method are discussed and verified. Nevertheless,\nthe generalization of deep-learning-based inversion methods on real data is\nstill challenging and considering physics may be one potential solution.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 05:51:05 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 07:34:55 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Li", "Shucai", ""], ["Liu", "Bin", ""], ["Ren", "Yuxiao", ""], ["Chen", "Yangkang", ""], ["Yang", "Senlin", ""], ["Wang", "Yunhai", ""], ["Jiang", "Peng", ""]]}, {"id": "1901.07786", "submitter": "Valentin Malykh", "authors": "Daniil Gavrilov and Pavel Kalaidin and Valentin Malykh", "title": "Self-Attentive Model for Headline Generation", "comments": "accepted for ECIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Headline generation is a special type of text summarization task. While the\namount of available training data for this task is almost unlimited, it still\nremains challenging, as learning to generate headlines for news articles\nimplies that the model has strong reasoning about natural language. To overcome\nthis issue, we applied recent Universal Transformer architecture paired with\nbyte-pair encoding technique and achieved new state-of-the-art results on the\nNew York Times Annotated corpus with ROUGE-L F1-score 24.84 and ROUGE-2\nF1-score 13.48. We also present the new RIA corpus and reach ROUGE-L F1-score\n36.81 and ROUGE-2 F1-score 22.15 on it.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 09:39:45 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Gavrilov", "Daniil", ""], ["Kalaidin", "Pavel", ""], ["Malykh", "Valentin", ""]]}, {"id": "1901.07829", "submitter": "Valentin Malykh", "authors": "Sergey I. Nikolenko, Elena Tutubalina, Valentin Malykh, Ilya Shenbin,\n  Anton Alekseev", "title": "AspeRa: Aspect-based Rating Prediction Model", "comments": "accepted to ECIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel end-to-end Aspect-based Rating Prediction model (AspeRa)\nthat estimates user rating based on review texts for the items and at the same\ntime discovers coherent aspects of reviews that can be used to explain\npredictions or profile users. The AspeRa model uses max-margin losses for joint\nitem and user embedding learning and a dual-headed architecture; it\nsignificantly outperforms recently proposed state-of-the-art models such as\nDeepCoNN, HFT, NARRE, and TransRev on two real world data sets of user reviews.\nWith qualitative examination of the aspects and quantitative evaluation of\nrating prediction models based on these aspects, we show how aspect embeddings\ncan be used in a recommender system.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 11:38:15 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Nikolenko", "Sergey I.", ""], ["Tutubalina", "Elena", ""], ["Malykh", "Valentin", ""], ["Shenbin", "Ilya", ""], ["Alekseev", "Anton", ""]]}, {"id": "1901.07859", "submitter": "Kai Olav Ellefsen", "authors": "Kai Olav Ellefsen, Charles Patrick Martin and Jim Torresen", "title": "How do Mixture Density RNNs Predict the Future?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaining a better understanding of how and what machine learning systems learn\nis important to increase confidence in their decisions and catalyze further\nresearch. In this paper, we analyze the predictions made by a specific type of\nrecurrent neural network, mixture density RNNs (MD-RNNs). These networks learn\nto model predictions as a combination of multiple Gaussian distributions,\nmaking them particularly interesting for problems where a sequence of inputs\nmay lead to several distinct future possibilities. An example is learning\ninternal models of an environment, where different events may or may not occur,\nbut where the average over different events is not meaningful. By analyzing the\npredictions made by trained MD-RNNs, we find that their different Gaussian\ncomponents have two complementary roles: 1) Separately modeling different\nstochastic events and 2) Separately modeling scenarios governed by different\nrules. These findings increase our understanding of what is learned by\npredictive MD-RNNs, and open up new research directions for further\nunderstanding how we can benefit from their self-organizing model\ndecomposition.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 13:06:09 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Ellefsen", "Kai Olav", ""], ["Martin", "Charles Patrick", ""], ["Torresen", "Jim", ""]]}, {"id": "1901.07910", "submitter": "Oscar J. Romero", "authors": "Oscar J. Romero, Ankit Dangi, Sushma A. Akoju", "title": "NLSC: Unrestricted Natural Language-based Service Composition through\n  Sentence Embeddings", "comments": "This paper will appear on SCC'19 (IEEE International Conference on\n  Services Computing) on July 13", "journal-ref": "2019 IEEE International Conference on Services Computing (SCC)", "doi": "10.1109/SCC.2019.00031", "report-no": null, "categories": "cs.SE cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches for service composition (assemblies of atomic services)\nrequire developers to use: (a) domain-specific semantics to formalize services\nthat restrict the vocabulary for their descriptions, and (b) translation\nmechanisms for service retrieval to convert unstructured user requests to\nstrongly-typed semantic representations. In our work, we argue that effort to\ndeveloping service descriptions, request translations, and matching mechanisms\ncould be reduced using unrestricted natural language; allowing both: (1)\nend-users to intuitively express their needs using natural language, and (2)\nservice developers to develop services without relying on syntactic/semantic\ndescription languages. Although there are some natural language-based service\ncomposition approaches, they restrict service retrieval to syntactic/semantic\nmatching. With recent developments in Machine learning and Natural Language\nProcessing, we motivate the use of Sentence Embeddings by leveraging richer\nsemantic representations of sentences for service description, matching and\nretrieval. Experimental results show that service composition development\neffort may be reduced by more than 44\\% while keeping a high precision/recall\nwhen matching high-level user requests with low-level service method\ninvocations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 14:18:26 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 20:01:02 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 13:03:00 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Romero", "Oscar J.", ""], ["Dangi", "Ankit", ""], ["Akoju", "Sushma A.", ""]]}, {"id": "1901.07984", "submitter": "Pedro Henrique da Costa Avelar", "authors": "Marcelo O. R. Prates, Pedro H. C. Avelar, Henrique Lemos, Marco Gori,\n  Luis Lamb", "title": "Typed Graph Networks", "comments": "Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the deep learning community has given growing attention to neural\narchitectures engineered to learn problems in relational domains. Convolutional\nNeural Networks employ parameter sharing over the image domain, tying the\nweights of neural connections on a grid topology and thus enforcing the\nlearning of a number of convolutional kernels. By instantiating trainable\nneural modules and assembling them in varied configurations (apart from grids),\none can enforce parameter sharing over graphs, yielding models which can\neffectively be fed with relational data. In this context, vertices in a graph\ncan be projected into a hyperdimensional real space and iteratively refined\nover many message-passing iterations in an end-to-end differentiable\narchitecture. Architectures of this family have been referred to with several\ndefinitions in the literature, such as Graph Neural Networks, Message-passing\nNeural Networks, Relational Networks and Graph Networks. In this paper, we\nrevisit the original Graph Neural Network model and show that it generalises\nmany of the recent models, which in turn benefit from the insight of thinking\nabout vertex \\textbf{types}. To illustrate the generality of the original\nmodel, we present a Graph Neural Network formalisation, which partitions the\nvertices of a graph into a number of types. Each type represents an entity in\nthe ontology of the problem one wants to learn. This allows - for instance -\none to assign embeddings to edges, hyperedges, and any number of global\nattributes of the graph. As a companion to this paper we provide a\nPython/Tensorflow library to facilitate the development of such architectures,\nwith which we instantiate the formalisation to reproduce a number of models\nproposed in the current literature.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 16:29:24 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 11:44:20 GMT"}, {"version": "v3", "created": "Sun, 24 Feb 2019 18:07:38 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Prates", "Marcelo O. R.", ""], ["Avelar", "Pedro H. C.", ""], ["Lemos", "Henrique", ""], ["Gori", "Marco", ""], ["Lamb", "Luis", ""]]}, {"id": "1901.08004", "submitter": "Zhijain Zhang", "authors": "Zhijian Zhang, Haozheng Li, Luo Zhang, Tianyin Zheng, Ting Zhang,\n  Xiong Hao, Xiaoxin Chen, Min Chen, Fangxu Xiao, Wei Zhou", "title": "Hierarchical Reinforcement Learning for Multi-agent MOBA Game", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real Time Strategy (RTS) games require macro strategies as well as micro\nstrategies to obtain satisfactory performance since it has large state space,\naction space, and hidden information. This paper presents a novel hierarchical\nreinforcement learning model for mastering Multiplayer Online Battle Arena\n(MOBA) games, a sub-genre of RTS games. The novelty of this work are: (1)\nproposing a hierarchical framework, where agents execute macro strategies by\nimitation learning and carry out micromanipulations through reinforcement\nlearning, (2) developing a simple self-learning method to get better sample\nefficiency for training, and (3) designing a dense reward function for\nmulti-agent cooperation in the absence of game engine or Application\nProgramming Interface (API). Finally, various experiments have been performed\nto validate the superior performance of the proposed method over other\nstate-of-the-art reinforcement learning algorithms. Agent successfully learns\nto combat and defeat bronze-level built-in AI with 100% win rate, and\nexperiments show that our method can create a competitive multi-agent for a\nkind of mobile MOBA game {\\it King of Glory} in 5v5 mode.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 17:08:15 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 09:42:36 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 07:46:40 GMT"}, {"version": "v4", "created": "Fri, 31 May 2019 03:00:05 GMT"}, {"version": "v5", "created": "Wed, 5 Jun 2019 06:40:17 GMT"}, {"version": "v6", "created": "Fri, 21 Jun 2019 06:37:40 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Zhang", "Zhijian", ""], ["Li", "Haozheng", ""], ["Zhang", "Luo", ""], ["Zheng", "Tianyin", ""], ["Zhang", "Ting", ""], ["Hao", "Xiong", ""], ["Chen", "Xiaoxin", ""], ["Chen", "Min", ""], ["Xiao", "Fangxu", ""], ["Zhou", "Wei", ""]]}, {"id": "1901.08079", "submitter": "Asma Ben Abacha", "authors": "Asma Ben Abacha and Dina Demner-Fushman", "title": "A Question-Entailment Approach to Question Answering", "comments": null, "journal-ref": "BMC Bioinformatics 20, 511 (2019)", "doi": "10.1186/s12859-019-3119-4", "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges in large-scale information retrieval (IR) is to develop\nfine-grained and domain-specific methods to answer natural language questions.\nDespite the availability of numerous sources and datasets for answer retrieval,\nQuestion Answering (QA) remains a challenging problem due to the difficulty of\nthe question understanding and answer extraction tasks. One of the promising\ntracks investigated in QA is to map new questions to formerly answered\nquestions that are `similar'. In this paper, we propose a novel QA approach\nbased on Recognizing Question Entailment (RQE) and we describe the QA system\nand resources that we built and evaluated on real medical questions. First, we\ncompare machine learning and deep learning methods for RQE using different\nkinds of datasets, including textual inference, question similarity and\nentailment in both the open and clinical domains. Second, we combine IR models\nwith the best RQE method to select entailed questions and rank the retrieved\nanswers. To study the end-to-end QA approach, we built the MedQuAD collection\nof 47,457 question-answer pairs from trusted medical sources, that we introduce\nand share in the scope of this paper. Following the evaluation process used in\nTREC 2017 LiveQA, we find that our approach exceeds the best results of the\nmedical task with a 29.8% increase over the best official score. The evaluation\nresults also support the relevance of question entailment for QA and highlight\nthe effectiveness of combining IR and RQE for future QA efforts. Our findings\nalso show that relying on a restricted set of reliable answer sources can bring\na substantial improvement in medical QA.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 19:02:27 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Abacha", "Asma Ben", ""], ["Demner-Fushman", "Dina", ""]]}, {"id": "1901.08114", "submitter": "Yanlu Xie", "authors": "Yanlu Xie, Yue Chen, Man Li", "title": "Convolution Forgetting Curve Model for Repeated Learning", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of mathematic forgetting curve models fit well with the forgetting data\nunder the learning condition of one time rather than repeated. In the paper, a\nconvolution model of forgetting curve is proposed to simulate the memory\nprocess during learning. In this model, the memory ability (i.e. the central\nprocedure in the working memory model) and learning material (i.e. the input in\nthe working memory model) is regarded as the system function and the input\nfunction, respectively. The status of forgetting (i.e. the output in the\nworking memory model) is regarded as output function or the convolution result\nof the memory ability and learning material. The model is applied to simulate\nthe forgetting curves in different situations. The results show that the model\nis able to simulate the forgetting curves not only in one time learning\ncondition but also in multi-times condition. The model is further verified in\nthe experiments of Mandarin tone learning for Japanese learners. And the\npredicted curve fits well on the test points.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 08:09:58 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Xie", "Yanlu", ""], ["Chen", "Yue", ""], ["Li", "Man", ""]]}, {"id": "1901.08128", "submitter": "Sam Green", "authors": "Sam Green, Craig M. Vineyard, \\c{C}etin Kaya Ko\\c{c}", "title": "Distillation Strategies for Proximal Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-based deep reinforcement learning (RL) typically obtains performance\nbenefit by using high capacity and relatively large convolutional neural\nnetworks (CNN). However, a large network leads to higher inference costs\n(power, latency, silicon area, MAC count). Many inference optimizations have\nbeen developed for CNNs. Some optimization techniques offer theoretical\nefficiency, such as sparsity, but designing actual hardware to support them is\ndifficult. On the other hand, distillation is a simple general-purpose\noptimization technique which is broadly applicable for transferring knowledge\nfrom a trained, high capacity teacher network to an untrained, low capacity\nstudent network. DQN distillation extended the original distillation idea to\ntransfer information stored in a high performance, high capacity teacher\nQ-function trained via the Deep Q-Learning (DQN) algorithm. Our work adapts the\nDQN distillation work to the actor-critic Proximal Policy Optimization\nalgorithm. PPO is simple to implement and has much higher performance than the\nseminal DQN algorithm. We show that a distilled PPO student can attain far\nhigher performance compared to a DQN teacher. We also show that a low capacity\ndistilled student is generally able to outperform a low capacity agent that\ndirectly trains in the environment. Finally, we show that distillation,\nfollowed by \"fine-tuning\" in the environment, enables the distilled PPO student\nto achieve parity with teacher performance. In general, the lessons learned in\nthis work should transfer to other modern actor-critic RL algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 21:00:33 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 17:24:32 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Green", "Sam", ""], ["Vineyard", "Craig M.", ""], ["Ko\u00e7", "\u00c7etin Kaya", ""]]}, {"id": "1901.08129", "submitter": "Diego Perez Liebana Dr.", "authors": "Diego Perez-Liebana, Katja Hofmann, Sharada Prasanna Mohanty, Noburu\n  Kuno, Andre Kramer, Sam Devlin, Raluca D. Gaina, Daniel Ionita", "title": "The Multi-Agent Reinforcement Learning in Malm\\\"O (MARL\\\"O) Competition", "comments": "2 pages plus references", "journal-ref": "Challenges in Machine Learning (NIPS Workshop), 2018", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in multi-agent scenarios is a fruitful research direction, but\ncurrent approaches still show scalability problems in multiple games with\ngeneral reward settings and different opponent types. The Multi-Agent\nReinforcement Learning in Malm\\\"O (MARL\\\"O) competition is a new challenge that\nproposes research in this domain using multiple 3D games. The goal of this\ncontest is to foster research in general agents that can learn across different\ngames and opponent types, proposing a challenge as a milestone in the direction\nof Artificial General Intelligence.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 21:01:27 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Perez-Liebana", "Diego", ""], ["Hofmann", "Katja", ""], ["Mohanty", "Sharada Prasanna", ""], ["Kuno", "Noburu", ""], ["Kramer", "Andre", ""], ["Devlin", "Sam", ""], ["Gaina", "Raluca D.", ""], ["Ionita", "Daniel", ""]]}, {"id": "1901.08162", "submitter": "Ishita Dasgupta", "authors": "Ishita Dasgupta, Jane Wang, Silvia Chiappa, Jovana Mitrovic, Pedro\n  Ortega, David Raposo, Edward Hughes, Peter Battaglia, Matthew Botvinick, Zeb\n  Kurth-Nelson", "title": "Causal Reasoning from Meta-reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering and exploiting the causal structure in the environment is a\ncrucial challenge for intelligent agents. Here we explore whether causal\nreasoning can emerge via meta-reinforcement learning. We train a recurrent\nnetwork with model-free reinforcement learning to solve a range of problems\nthat each contain causal structure. We find that the trained agent can perform\ncausal reasoning in novel situations in order to obtain rewards. The agent can\nselect informative interventions, draw causal inferences from observational\ndata, and make counterfactual predictions. Although established formal causal\nreasoning algorithms also exist, in this paper we show that such reasoning can\narise from model-free reinforcement learning, and suggest that causal reasoning\nin complex settings may benefit from the more end-to-end learning-based\napproaches presented here. This work also offers new strategies for structured\nexploration in reinforcement learning, by providing agents with the ability to\nperform -- and interpret -- experiments.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 23:03:59 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Dasgupta", "Ishita", ""], ["Wang", "Jane", ""], ["Chiappa", "Silvia", ""], ["Mitrovic", "Jovana", ""], ["Ortega", "Pedro", ""], ["Raposo", "David", ""], ["Hughes", "Edward", ""], ["Battaglia", "Peter", ""], ["Botvinick", "Matthew", ""], ["Kurth-Nelson", "Zeb", ""]]}, {"id": "1901.08221", "submitter": "Ajit Narayanan", "authors": "Ajit Narayanan", "title": "When is it right and good for an intelligent autonomous vehicle to take\n  over control (and hand it back)?", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is much debate in machine ethics about the most appropriate way to\nintroduce ethical reasoning capabilities into intelligent autonomous machines.\nRecent incidents involving autonomous vehicles in which humans have been killed\nor injured have raised questions about how we ensure that such vehicles have an\nethical dimension to their behaviour and are therefore trustworthy. The main\nproblem is that hardwiring such machines with rules not to cause harm or damage\nis not consistent with the notion of autonomy and intelligence. Also, such\nethical hardwiring does not leave intelligent autonomous machines with any\ncourse of action if they encounter situations or dilemmas for which they are\nnot programmed or where some harm is caused no matter what course of action is\ntaken. Teaching machines so that they learn ethics may also be problematic\ngiven recent findings in machine learning that machines pick up the prejudices\nand biases embedded in their learning algorithms or data. This paper describes\na fuzzy reasoning approach to machine ethics. The paper shows how it is\npossible for an ethics architecture to reason when taking over from a human\ndriver is morally justified. The design behind such an ethical reasoner is also\napplied to an ethical dilemma resolution case. One major advantage of the\napproach is that the ethical reasoner can generate its own data for learning\nmoral rules (hence, autometric) and thereby reduce the possibility of picking\nup human biases and prejudices. The results show that a new type of\nmetric-based ethics appropriate for autonomous intelligent machines is feasible\nand that our current concept of ethical reasoning being largely qualitative in\nnature may need revising if want to construct future autonomous machines that\nhave an ethical dimension to their reasoning so that they become moral\nmachines.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 03:51:10 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Narayanan", "Ajit", ""]]}, {"id": "1901.08237", "submitter": "Liu Liu", "authors": "Liu Liu, Tianyang Li, Constantine Caramanis", "title": "High Dimensional Robust $M$-Estimation: Arbitrary Corruption and Heavy\n  Tails", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sparsity-constrained $M$-estimation when both\nexplanatory and response variables have heavy tails (bounded 4-th moments), or\na fraction of arbitrary corruptions. We focus on the $k$-sparse,\nhigh-dimensional regime where the number of variables $d$ and the sample size\n$n$ are related through $n \\sim k \\log d$. We define a natural condition we\ncall the Robust Descent Condition (RDC), and show that if a gradient estimator\nsatisfies the RDC, then Robust Hard Thresholding (IHT using this gradient\nestimator), is guaranteed to obtain good statistical rates. The contribution of\nthis paper is in showing that this RDC is a flexible enough concept to recover\nknown results, and obtain new robustness results. Specifically, new results\ninclude: (a) For $k$-sparse high-dimensional linear- and logistic-regression\nwith heavy tail (bounded 4-th moment) explanatory and response variables, a\nlinear-time-computable median-of-means gradient estimator satisfies the RDC,\nand hence Robust Hard Thresholding is minimax optimal; (b) When instead of\nheavy tails we have $O(1/\\sqrt{k}\\log(nd))$-fraction of arbitrary corruptions\nin explanatory and response variables, a near linear-time computable trimmed\ngradient estimator satisfies the RDC, and hence Robust Hard Thresholding is\nminimax optimal. We demonstrate the effectiveness of our approach in sparse\nlinear, logistic regression, and sparse precision matrix estimation on\nsynthetic and real-world US equities data.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 05:20:29 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 19:02:20 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Liu", "Liu", ""], ["Li", "Tianyang", ""], ["Caramanis", "Constantine", ""]]}, {"id": "1901.08259", "submitter": "Qian Liu", "authors": "Qian Liu, Bei Chen, Jian-Guang Lou, Ge Jin, Dongmei Zhang", "title": "FANDA: A Novel Approach to Perform Follow-up Query Analysis", "comments": "Accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on Natural Language Interfaces to Databases (NLIDB) has attracted\nconsiderable attention. NLIDB allow users to search databases using natural\nlanguage instead of SQL-like query languages. While saving the users from\nhaving to learn query languages, multi-turn interaction with NLIDB usually\ninvolves multiple queries where contextual information is vital to understand\nthe users' query intents. In this paper, we address a typical contextual\nunderstanding problem, termed as follow-up query analysis. In spite of its\nubiquity, follow-up query analysis has not been well studied due to two primary\nobstacles: the multifarious nature of follow-up query scenarios and the lack of\nhigh-quality datasets. Our work summarizes typical follow-up query scenarios\nand provides a new FollowUp dataset with $1000$ query triples on 120 tables.\nMoreover, we propose a novel approach FANDA, which takes into account the\nstructures of queries and employs a ranking model with weakly supervised\nmax-margin learning. The experimental results on FollowUp demonstrate the\nsuperiority of FANDA over multiple baselines across multiple metrics.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 07:25:16 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Liu", "Qian", ""], ["Chen", "Bei", ""], ["Lou", "Jian-Guang", ""], ["Jin", "Ge", ""], ["Zhang", "Dongmei", ""]]}, {"id": "1901.08277", "submitter": "Wenfeng Feng", "authors": "Hankz Hankui Zhuo, Wenfeng Feng, Yufeng Lin, Qian Xu, Qiang Yang", "title": "Federated Deep Reinforcement Learning", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep reinforcement learning, building policies of high-quality is\nchallenging when the feature space of states is small and the training data is\nlimited. Despite the success of previous transfer learning approaches in deep\nreinforcement learning, directly transferring data or models from an agent to\nanother agent is often not allowed due to the privacy of data and/or models in\nmany privacy-aware applications. In this paper, we propose a novel deep\nreinforcement learning framework to federatively build models of high-quality\nfor agents with consideration of their privacies, namely Federated deep\nReinforcement Learning (FedRL). To protect the privacy of data and models, we\nexploit Gausian differentials on the information shared with each other when\nupdating their local models. In the experiment, we evaluate our FedRL framework\nin two diverse domains, Grid-world and Text2Action domains, by comparing to\nvarious baselines.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 08:25:29 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 07:02:15 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 12:30:36 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Zhuo", "Hankz Hankui", ""], ["Feng", "Wenfeng", ""], ["Lin", "Yufeng", ""], ["Xu", "Qian", ""], ["Yang", "Qiang", ""]]}, {"id": "1901.08387", "submitter": "Arghya Roy Chaudhuri", "authors": "Arghya Roy Chaudhuri, Shivaram Kalyanakrishnan", "title": "Regret Minimisation in Multi-Armed Bandits Using Bounded Arm Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a constant word (RAM model) algorithm for regret\nminimisation for both finite and infinite Stochastic Multi-Armed Bandit (MAB)\ninstances. Most of the existing regret minimisation algorithms need to remember\nthe statistics of all the arms they encounter. This may become a problem for\nthe cases where the number of available words of memory is limited. Designing\nan efficient regret minimisation algorithm that uses a constant number of words\nhas long been interesting to the community. Some early attempts consider the\nnumber of arms to be infinite, and require the reward distribution of the arms\nto belong to some particular family. Recently, for finitely many-armed bandits\nan explore-then-commit based algorithm~\\citep{Liau+PSY:2018} seems to escape\nsuch assumption. However, due to the underlying PAC-based elimination their\nmethod incurs a high regret. We present a conceptually simple, and efficient\nalgorithm that needs to remember statistics of at most $M$ arms, and for any\n$K$-armed finite bandit instance it enjoys a $O(KM +K^{1.5}\\sqrt{T\\log\n(T/MK)}/M)$ upper-bound on regret. We extend it to achieve sub-linear\n\\textit{quantile-regret}~\\citep{RoyChaudhuri+K:2018} and empirically verify the\nefficiency of our algorithm via experiments.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 12:56:46 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Chaudhuri", "Arghya Roy", ""], ["Kalyanakrishnan", "Shivaram", ""]]}, {"id": "1901.08460", "submitter": "Valentina Zantedeschi Dr", "authors": "Valentina Zantedeschi, Aur\\'elien Bellet, Marc Tommasi", "title": "Fully Decentralized Joint Learning of Personalized Models and\n  Collaboration Graphs", "comments": "To appear in the proceedings of the 23rd International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the fully decentralized machine learning scenario where many\nusers with personal datasets collaborate to learn models through local\npeer-to-peer exchanges, without a central coordinator. We propose to train\npersonalized models that leverage a collaboration graph describing the\nrelationships between user personal tasks, which we learn jointly with the\nmodels. Our fully decentralized optimization procedure alternates between\ntraining nonlinear models given the graph in a greedy boosting manner, and\nupdating the collaboration graph (with controlled sparsity) given the models.\nThroughout the process, users exchange messages only with a small number of\npeers (their direct neighbors when updating the models, and a few random users\nwhen updating the graph), ensuring that the procedure naturally scales with the\nnumber of users. Overall, our approach is communication-efficient and avoids\nexchanging personal data. We provide an extensive analysis of the convergence\nrate, memory and communication complexity of our approach, and demonstrate its\nbenefits compared to competing techniques on synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 15:44:42 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 13:33:17 GMT"}, {"version": "v3", "created": "Mon, 3 Jun 2019 21:56:19 GMT"}, {"version": "v4", "created": "Thu, 26 Mar 2020 09:34:43 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Zantedeschi", "Valentina", ""], ["Bellet", "Aur\u00e9lien", ""], ["Tommasi", "Marc", ""]]}, {"id": "1901.08467", "submitter": "Pavel Naumov", "authors": "Rui Cao and Pavel Naumov", "title": "The Limits of Morality in Strategic Games", "comments": "arXiv admin note: text overlap with arXiv:1809.05485", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A coalition is blameable for an outcome if the coalition had a strategy to\nprevent it. It has been previously suggested that the cost of prevention, or\nthe cost of sacrifice, can be used to measure the degree of blameworthiness.\nThe paper adopts this approach and proposes a modal logical system for\nreasoning about the degree of blameworthiness. The main technical result is a\ncompleteness theorem for the proposed system.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 19:40:46 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Cao", "Rui", ""], ["Naumov", "Pavel", ""]]}, {"id": "1901.08486", "submitter": "HsuanKung Yang", "authors": "Hsuan-Kung Yang, Po-Han Chiang, Kuan-Wei Ho, Min-Fong Hong, and\n  Chun-Yi Lee", "title": "Never Forget: Balancing Exploration and Exploitation via Learning\n  Optical Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration bonus derived from the novelty of the states in an environment\nhas become a popular approach to motivate exploration for deep reinforcement\nlearning agents in the past few years. Recent methods such as curiosity-driven\nexploration usually estimate the novelty of new observations by the prediction\nerrors of their system dynamics models. Due to the capacity limitation of the\nmodels and difficulty of performing next-frame prediction, however, these\nmethods typically fail to balance between exploration and exploitation in\nhigh-dimensional observation tasks, resulting in the agents forgetting the\nvisited paths and exploring those states repeatedly. Such inefficient\nexploration behavior causes significant performance drops, especially in large\nenvironments with sparse reward signals. In this paper, we propose to introduce\nthe concept of optical flow estimation from the field of computer vision to\ndeal with the above issue. We propose to employ optical flow estimation errors\nto examine the novelty of new observations, such that agents are able to\nmemorize and understand the visited states in a more comprehensive fashion. We\ncompare our method against the previous approaches in a number of experimental\nexperiments. Our results indicate that the proposed method appears to deliver\nsuperior and long-lasting performance than the previous methods. We further\nprovide a set of comprehensive ablative analysis of the proposed method, and\ninvestigate the impact of optical flow estimation on the learning curves of the\nDRL agents.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 16:26:16 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Yang", "Hsuan-Kung", ""], ["Chiang", "Po-Han", ""], ["Ho", "Kuan-Wei", ""], ["Hong", "Min-Fong", ""], ["Lee", "Chun-Yi", ""]]}, {"id": "1901.08492", "submitter": "Sanjeevan Ahilan", "authors": "Sanjeevan Ahilan and Peter Dayan", "title": "Feudal Multi-Agent Hierarchies for Cooperative Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how reinforcement learning agents can learn to cooperate.\nDrawing inspiration from human societies, in which successful coordination of\nmany individuals is often facilitated by hierarchical organisation, we\nintroduce Feudal Multi-agent Hierarchies (FMH). In this framework, a 'manager'\nagent, which is tasked with maximising the environmentally-determined reward\nfunction, learns to communicate subgoals to multiple, simultaneously-operating,\n'worker' agents. Workers, which are rewarded for achieving managerial subgoals,\ntake concurrent actions in the world. We outline the structure of FMH and\ndemonstrate its potential for decentralised learning and control. We find that,\ngiven an adequate set of subgoals from which to choose, FMH performs, and\nparticularly scales, substantially better than cooperative approaches that use\na shared reward function.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 16:44:16 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Ahilan", "Sanjeevan", ""], ["Dayan", "Peter", ""]]}, {"id": "1901.08508", "submitter": "Rithesh Kumar", "authors": "Rithesh Kumar, Sherjil Ozair, Anirudh Goyal, Aaron Courville, Yoshua\n  Bengio", "title": "Maximum Entropy Generators for Energy-Based Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Maximum likelihood estimation of energy-based models is a challenging problem\ndue to the intractability of the log-likelihood gradient. In this work, we\npropose learning both the energy function and an amortized approximate sampling\nmechanism using a neural generator network, which provides an efficient\napproximation of the log-likelihood gradient. The resulting objective requires\nmaximizing entropy of the generated samples, which we perform using recently\nproposed nonparametric mutual information estimators. Finally, to stabilize the\nresulting adversarial game, we use a zero-centered gradient penalty derived as\na necessary condition from the score matching literature. The proposed\ntechnique can generate sharp images with Inception and FID scores competitive\nwith recent GAN techniques, does not suffer from mode collapse, and is\ncompetitive with state-of-the-art anomaly detection techniques.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 17:03:41 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 18:52:19 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Kumar", "Rithesh", ""], ["Ozair", "Sherjil", ""], ["Goyal", "Anirudh", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1901.08547", "submitter": "Quanshi Zhang", "authors": "Yuxia Geng, Jiaoyan Chen, Ernesto Jimenez-Ruiz, Huajun Chen", "title": "Human-centric Transfer Learning Explanation via Knowledge Graph\n  [Extended Abstract]", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning which aims at utilizing knowledge learned from one problem\n(source domain) to solve another different but related problem (target domain)\nhas attracted wide research attentions. However, the current transfer learning\nmethods are mostly uninterpretable, especially to people without ML expertise.\nIn this extended abstract, we brief introduce two knowledge graph (KG) based\nframeworks towards human understandable transfer learning explanation. The\nfirst one explains the transferability of features learned by Convolutional\nNeural Network (CNN) from one domain to another through pre-training and\nfine-tuning, while the second justifies the model of a target domain predicted\nby models from multiple source domains in zero-shot learning (ZSL). Both\nmethods utilize KG and its reasoning capability to provide rich and human\nunderstandable explanations to the transfer procedure.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:51:15 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Geng", "Yuxia", ""], ["Chen", "Jiaoyan", ""], ["Jimenez-Ruiz", "Ernesto", ""], ["Chen", "Huajun", ""]]}, {"id": "1901.08579", "submitter": "Ross Gruetzemacher", "authors": "Ross Gruetzemacher, David Paradice, Kang Bok Lee", "title": "Forecasting Transformative AI: An Expert Survey", "comments": "11 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformative AI technologies have the potential to reshape critical aspects\nof society in the near future. However, in order to properly prepare policy\ninitiatives for the arrival of such technologies accurate forecasts and\ntimelines are necessary. A survey was administered to attendees of three AI\nconferences during the summer of 2018 (ICML, IJCAI and the HLAI conference).\nThe survey included questions for estimating AI capabilities over the next\ndecade, questions for forecasting five scenarios of transformative AI and\nquestions concerning the impact of computational resources in AI research.\nRespondents indicated a median of 21.5% of human tasks (i.e., all tasks that\nhumans are currently paid to do) can be feasibly automated now, and that this\nfigure would rise to 40% in 5 years and 60% in 10 years. Median forecasts\nindicated a 50% probability of AI systems being capable of automating 90% of\ncurrent human tasks in 25 years and 99% of current human tasks in 50 years. The\nconference of attendance was found to have a statistically significant impact\non all forecasts, with attendees of HLAI providing more optimistic timelines\nwith less uncertainty. These findings suggest that AI experts expect major\nadvances in AI technology to continue over the next decade to a degree that\nwill likely have profound transformative impacts on society.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 18:53:07 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 16:23:00 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Gruetzemacher", "Ross", ""], ["Paradice", "David", ""], ["Lee", "Kang Bok", ""]]}, {"id": "1901.08612", "submitter": "Tom Zahavy", "authors": "Tom Zahavy and Shie Mannor", "title": "Deep Neural Linear Bandits: Overcoming Catastrophic Forgetting through\n  Likelihood Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the neural-linear bandit model for solving sequential\ndecision-making problems with high dimensional side information. Neural-linear\nbandits leverage the representation power of deep neural networks and combine\nit with efficient exploration mechanisms, designed for linear contextual\nbandits, on top of the last hidden layer. Since the representation is being\noptimized during learning, information regarding exploration with \"old\"\nfeatures is lost. Here, we propose the first limited memory neural-linear\nbandit that is resilient to this phenomenon, which we term catastrophic\nforgetting. We evaluate our method on a variety of real-world data sets,\nincluding regression, classification, and sentiment analysis, and observe that\nour algorithm is resilient to catastrophic forgetting and achieves superior\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 19:15:17 GMT"}, {"version": "v2", "created": "Sun, 11 Aug 2019 11:55:34 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Zahavy", "Tom", ""], ["Mannor", "Shie", ""]]}, {"id": "1901.08621", "submitter": "Mengke Lian", "authors": "Mengke Lian, Fabrizio Carpi, Christian H\\\"ager, Henry D. Pfister", "title": "Learned Belief-Propagation Decoding with Simple Scaling and SNR\n  Adaptation", "comments": "5 pages, 5 figures, submitted to ISIT 2019", "journal-ref": null, "doi": "10.1109/ISIT.2019.8849419", "report-no": null, "categories": "cs.IT cs.AI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the weighted belief-propagation (WBP) decoder recently proposed\nby Nachmani et al. where different weights are introduced for each Tanner graph\nedge and optimized using machine learning techniques. Our focus is on\nsimple-scaling models that use the same weights across certain edges to reduce\nthe storage and computational burden. The main contribution is to show that\nsimple scaling with few parameters often achieves the same gain as the full\nparameterization. Moreover, several training improvements for WBP are proposed.\nFor example, it is shown that minimizing average binary cross-entropy is\nsuboptimal in general in terms of bit error rate (BER) and a new \"soft-BER\"\nloss is proposed which can lead to better performance. We also investigate\nparameter adapter networks (PANs) that learn the relation between the\nsignal-to-noise ratio and the WBP parameters. As an example, for the (32,16)\nReed-Muller code with a highly redundant parity-check matrix, training a PAN\nwith soft-BER loss gives near-maximum-likelihood performance assuming simple\nscaling with only three parameters.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 19:37:04 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Lian", "Mengke", ""], ["Carpi", "Fabrizio", ""], ["H\u00e4ger", "Christian", ""], ["Pfister", "Henry D.", ""]]}, {"id": "1901.08649", "submitter": "Christopher Grimm", "authors": "Christopher Grimm and Satinder Singh", "title": "Learning Independently-Obtainable Reward Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for learning a set of disentangled reward functions\nthat sum to the original environment reward and are constrained to be\nindependently obtainable. We define independent obtainability in terms of value\nfunctions with respect to obtaining one learned reward while pursuing another\nlearned reward. Empirically, we illustrate that our method can learn meaningful\nreward decompositions in a variety of domains and that these decompositions\nexhibit some form of generalization performance when the environment's reward\nis modified. Theoretically, we derive results about the effect of maximizing\nour method's objective on the resulting reward functions and their\ncorresponding optimal policies.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 21:46:39 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2019 20:28:12 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 17:26:51 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Grimm", "Christopher", ""], ["Singh", "Satinder", ""]]}, {"id": "1901.08654", "submitter": "Lawrence Chan", "authors": "Lawrence Chan, Dylan Hadfield-Menell, Siddhartha Srinivasa, Anca\n  Dragan", "title": "The Assistive Multi-Armed Bandit", "comments": "Accepted to HRI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning preferences implicit in the choices humans make is a well studied\nproblem in both economics and computer science. However, most work makes the\nassumption that humans are acting (noisily) optimally with respect to their\npreferences. Such approaches can fail when people are themselves learning about\nwhat they want. In this work, we introduce the assistive multi-armed bandit,\nwhere a robot assists a human playing a bandit task to maximize cumulative\nreward. In this problem, the human does not know the reward function but can\nlearn it through the rewards received from arm pulls; the robot only observes\nwhich arms the human pulls but not the reward associated with each pull. We\noffer sufficient and necessary conditions for successfully assisting the human\nin this framework. Surprisingly, better human performance in isolation does not\nnecessarily lead to better performance when assisted by the robot: a human\npolicy can do better by effectively communicating its observed rewards to the\nrobot. We conduct proof-of-concept experiments that support these results. We\nsee this work as contributing towards a theory behind algorithms for\nhuman-robot interaction.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 21:52:01 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Chan", "Lawrence", ""], ["Hadfield-Menell", "Dylan", ""], ["Srinivasa", "Siddhartha", ""], ["Dragan", "Anca", ""]]}, {"id": "1901.08706", "submitter": "Douwe Kiela", "authors": "Laura Graesser, Kyunghyun Cho, Douwe Kiela", "title": "Emergent Linguistic Phenomena in Multi-Agent Communication Games", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a computational framework in which agents equipped\nwith communication capabilities simultaneously play a series of referential\ngames, where agents are trained using deep reinforcement learning. We\ndemonstrate that the framework mirrors linguistic phenomena observed in natural\nlanguage: i) the outcome of contact between communities is a function of inter-\nand intra-group connectivity; ii) linguistic contact either converges to the\nmajority protocol, or in balanced cases leads to novel creole languages of\nlower complexity; and iii) a linguistic continuum emerges where neighboring\nlanguages are more mutually intelligible than farther removed languages. We\nconclude that intricate properties of language evolution need not depend on\ncomplex evolved linguistic capabilities, but can emerge from simple social\nexchanges between perceptually-enabled agents playing communication games.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 01:18:04 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 19:32:05 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Graesser", "Laura", ""], ["Cho", "Kyunghyun", ""], ["Kiela", "Douwe", ""]]}, {"id": "1901.08711", "submitter": "Palash Dey", "authors": "Palash Dey", "title": "Local Distance Constrained Bribery in Voting", "comments": "Published in Theoretical Computer Science journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying complexity of various bribery problems has been one of the main\nresearch focus in computational social choice. In all the models of bribery\nstudied so far, the briber has to pay every voter some amount of money\ndepending on what the briber wants the voter to report and the briber has some\nbudget at her disposal. Although these models successfully capture many real\nworld applications, in many other scenarios, the voters may be unwilling to\ndeviate too much from their true preferences. In this paper, we study the\ncomputational complexity of the problem of finding a preference profile which\nis as close to the true preference profile as possible and still achieves the\nbriber's goal subject to budget constraints. We call this problem Optimal\nBribery. We consider three important measures of distances, namely, swap\ndistance, footrule distance, and maximum displacement distance, and resolve the\ncomplexity of the optimal bribery problem for many common voting rules. We show\nthat the problem is polynomial time solvable for the plurality and veto voting\nrules for all the three measures of distance. On the other hand, we prove that\nthe problem is NP-complete for a class of scoring rules which includes the\nBorda voting rule, maximin, Copeland$^\\alpha$ for any $\\alpha\\in[0,1]$, and\nBucklin voting rules for all the three measures of distance even when the\ndistance allowed per voter is $1$ for the swap and maximum displacement\ndistances and $2$ for the footrule distance even without the budget constraints\n(which corresponds to having an infinite budget). For the $k$-approval voting\nrule for any constant $k>1$ and the simplified Bucklin voting rule, we show\nthat the problem is NP-complete for the swap distance even when the distance\nallowed is $2$ and for the footrule distance even when the distance allowed is\n$4$ even without the budget constraints.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 02:04:21 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 12:00:32 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 12:15:11 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Dey", "Palash", ""]]}, {"id": "1901.08728", "submitter": "Rishabh Agarwal", "authors": "Rishabh Agarwal", "title": "Evaluation Function Approximation for Scrabble", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The current state-of-the-art Scrabble agents are not learning-based but\ndepend on truncated Monte Carlo simulations and the quality of such agents is\ncontingent upon the time available for running the simulations. This thesis\ntakes steps towards building a learning-based Scrabble agent using self-play.\nSpecifically, we try to find a better function approximation for the static\nevaluation function used in Scrabble which determines the move goodness at a\ngiven board configuration. In this work, we experimented with evolutionary\nalgorithms and Bayesian Optimization to learn the weights for an approximate\nfeature-based evaluation function. However, these optimization methods were not\nquite effective, which lead us to explore the given problem from an Imitation\nLearning point of view. We also tried to imitate the ranking of moves produced\nby the Quackle simulation agent using supervised learning with a neural network\nfunction approximator which takes the raw representation of the Scrabble board\nas the input instead of using only a fixed number of handcrafted features.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 04:05:52 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Agarwal", "Rishabh", ""]]}, {"id": "1901.08740", "submitter": "Pengqian Yu", "authors": "Pengqian Yu, Joon Sern Lee, Ilya Kulyatin, Zekun Shi, Sakyasingha\n  Dasgupta", "title": "Model-based Deep Reinforcement Learning for Dynamic Portfolio\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic portfolio optimization is the process of sequentially allocating\nwealth to a collection of assets in some consecutive trading periods, based on\ninvestors' return-risk profile. Automating this process with machine learning\nremains a challenging problem. Here, we design a deep reinforcement learning\n(RL) architecture with an autonomous trading agent such that, investment\ndecisions and actions are made periodically, based on a global objective, with\nautonomy. In particular, without relying on a purely model-free RL agent, we\ntrain our trading agent using a novel RL architecture consisting of an infused\nprediction module (IPM), a generative adversarial data augmentation module\n(DAM) and a behavior cloning module (BCM). Our model-based approach works with\nboth on-policy or off-policy RL algorithms. We further design the back-testing\nand execution engine which interact with the RL agent in real time. Using\nhistorical {\\em real} financial market data, we simulate trading with practical\nconstraints, and demonstrate that our proposed model is robust, profitable and\nrisk-sensitive, as compared to baseline trading strategies and model-free RL\nagents from prior work.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 04:55:02 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Yu", "Pengqian", ""], ["Lee", "Joon Sern", ""], ["Kulyatin", "Ilya", ""], ["Shi", "Zekun", ""], ["Dasgupta", "Sakyasingha", ""]]}, {"id": "1901.08761", "submitter": "Lenz Belzner", "authors": "Thomy Phan, Kyrill Schmid, Lenz Belzner, Thomas Gabor, Sebastian Feld,\n  Claudia Linnhoff-Popien", "title": "Distributed Policy Iteration for Scalable Approximation of Cooperative\n  Multi-Agent Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision making in multi-agent systems (MAS) is a great challenge due to\nenormous state and joint action spaces as well as uncertainty, making\ncentralized control generally infeasible. Decentralized control offers better\nscalability and robustness but requires mechanisms to coordinate on joint tasks\nand to avoid conflicts. Common approaches to learn decentralized policies for\ncooperative MAS suffer from non-stationarity and lacking credit assignment,\nwhich can lead to unstable and uncoordinated behavior in complex environments.\nIn this paper, we propose Strong Emergent Policy approximation (STEP), a\nscalable approach to learn strong decentralized policies for cooperative MAS\nwith a distributed variant of policy iteration. For that, we use function\napproximation to learn from action recommendations of a decentralized\nmulti-agent planning algorithm. STEP combines decentralized multi-agent\nplanning with centralized learning, only requiring a generative model for\ndistributed black box optimization. We experimentally evaluate STEP in two\nchallenging and stochastic domains with large state and joint action spaces and\nshow that STEP is able to learn stronger policies than standard multi-agent\nreinforcement learning algorithms, when combining multi-agent open-loop\nplanning with centralized function approximation. The learned policies can be\nreintegrated into the multi-agent planning process to further improve\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 07:13:29 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Phan", "Thomy", ""], ["Schmid", "Kyrill", ""], ["Belzner", "Lenz", ""], ["Gabor", "Thomas", ""], ["Feld", "Sebastian", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "1901.08813", "submitter": "Quanshi Zhang", "authors": "Quanshi Zhang, Lixin Fan, Bolei Zhou", "title": "Proceedings of AAAI 2019 Workshop on Network Interpretability for Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of AAAI 2019 Workshop on Network Interpretability for\nDeep Learning\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 10:12:23 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 04:29:29 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 13:49:07 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Zhang", "Quanshi", ""], ["Fan", "Lixin", ""], ["Zhou", "Bolei", ""]]}, {"id": "1901.08925", "submitter": "Yang You", "authors": "Yang You, Liangwei Li, Baisong Guo, Weiming Wang, Cewu Lu", "title": "Combinational Q-Learning for Dou Di Zhu", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has gained a lot of attention in recent\nyears, and has been proven to be able to play Atari games and Go at or above\nhuman levels. However, those games are assumed to have a small fixed number of\nactions and could be trained with a simple CNN network. In this paper, we study\na special class of Asian popular card games called Dou Di Zhu, in which two\nadversarial groups of agents must consider numerous card combinations at each\ntime step, leading to huge number of actions. We propose a novel method to\nhandle combinatorial actions, which we call combinational Q-learning (CQL). We\nemploy a two-stage network to reduce action space and also leverage\norder-invariant max-pooling operations to extract relationships between\nprimitive actions. Results show that our method prevails over state-of-the art\nmethods like naive Q-learning and A3C. We develop an easy-to-use card game\nenvironments and train all agents adversarially from sractch, with only\nknowledge of game rules and verify that our agents are comparative to humans.\nOur code to reproduce all reported results will be available online.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 08:28:04 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 14:03:30 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["You", "Yang", ""], ["Li", "Liangwei", ""], ["Guo", "Baisong", ""], ["Wang", "Weiming", ""], ["Lu", "Cewu", ""]]}, {"id": "1901.08928", "submitter": "Huibing Wang", "authors": "Caifeng Liu, Lin Feng, Guochao Liu, Huibing Wang, Shenglan Liu", "title": "Bottom-up Broadcast Neural Network For Music Genre Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music genre recognition based on visual representation has been successfully\nexplored over the last years. Recently, there has been increasing interest in\nattempting convolutional neural networks (CNNs) to achieve the task. However,\nmost of existing methods employ the mature CNN structures proposed in image\nrecognition without any modification, which results in the learning features\nthat are not adequate for music genre classification. Faced with the challenge\nof this issue, we fully exploit the low-level information from spectrograms of\naudios and develop a novel CNN architecture in this paper. The proposed CNN\narchitecture takes the long contextual information into considerations, which\ntransfers more suitable information for the decision-making layer. Various\nexperiments on several benchmark datasets, including GTZAN, Ballroom, and\nExtended Ballroom, have verified the excellent performances of the proposed\nneural network. Codes and model will be available at\n\"ttps://github.com/CaifengLiu/music-genre-classification\".\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 02:01:00 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Liu", "Caifeng", ""], ["Feng", "Lin", ""], ["Liu", "Guochao", ""], ["Wang", "Huibing", ""], ["Liu", "Shenglan", ""]]}, {"id": "1901.09006", "submitter": "Martin Engelcke", "authors": "Edward Wagstaff, Fabian B. Fuchs, Martin Engelcke, Ingmar Posner,\n  Michael Osborne", "title": "On the Limitations of Representing Functions on Sets", "comments": "Published at the International Conference on Machine Learning (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on the representation of functions on sets has considered the use\nof summation in a latent space to enforce permutation invariance. In\nparticular, it has been conjectured that the dimension of this latent space may\nremain fixed as the cardinality of the sets under consideration increases.\nHowever, we demonstrate that the analysis leading to this conjecture requires\nmappings which are highly discontinuous and argue that this is only of limited\npractical use. Motivated by this observation, we prove that an implementation\nof this model via continuous mappings (as provided by e.g. neural networks or\nGaussian processes) actually imposes a constraint on the dimensionality of the\nlatent space. Practical universal function representation for set inputs can\nonly be achieved with a latent dimension at least the size of the maximum\nnumber of input elements.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 18:11:52 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 10:12:47 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Wagstaff", "Edward", ""], ["Fuchs", "Fabian B.", ""], ["Engelcke", "Martin", ""], ["Posner", "Ingmar", ""], ["Osborne", "Michael", ""]]}, {"id": "1901.09125", "submitter": "Yuliya Lierler", "authors": "Marc Denecker, Yuliya Lierler, Miroslaw truszczynski, Joost Vennekens", "title": "The informal semantics of Answer Set Programming: A Tarskian perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Knowledge Representation, it is crucial that knowledge engineers have a\ngood understanding of the formal expressions that they write. What formal\nexpressions state intuitively about the domain of discourse is studied in the\ntheory of the informal semantics of a logic. In this paper we study the\ninformal semantics of Answer Set Programming. The roots of answer set\nprogramming lie in the language of Extended Logic Programming, which was\nintroduced initially as an epistemic logic for default and autoepistemic\nreasoning. In 1999, the seminal papers on answer set programming proposed to\nuse this logic for a different purpose, namely, to model and solve search\nproblems. Currently, the language is used primarily in this new role. However,\nthe original epistemic intuitions lose their explanatory relevance in this new\ncontext. How answer set programs are connected to the specifications of\nproblems they model is more easily explained in a classical Tarskian semantics,\nin which models correspond to possible worlds, rather than to belief states of\nan epistemic agent. In this paper, we develop a new theory of the informal\nsemantics of answer set programming, which is formulated in the Tarskian\nsetting and based on Frege's compositionality principle. It differs\nsubstantially from the earlier epistemic theory of informal semantics,\nproviding a different view on the meaning of the connectives in answer set\nprogramming and on its relation to other logics, in particular classical logic.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 00:24:22 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Denecker", "Marc", ""], ["Lierler", "Yuliya", ""], ["truszczynski", "Miroslaw", ""], ["Vennekens", "Joost", ""]]}, {"id": "1901.09127", "submitter": "Yuliya Lierler", "authors": "Yuliya Lierler", "title": "Strong Equivalence and Program's Structure in Arguing Essential\n  Equivalence between Logic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer set programming is a prominent declarative programming paradigm used\nin formulating combinatorial search problems and implementing distinct\nknowledge representation formalisms. It is common that several related and yet\nsubstantially different answer set programs exist for a given problem.\nSometimes these encodings may display significantly different performance.\nUncovering {\\em precise formal} links between these programs is often important\nand yet far from trivial. This paper claims the correctness of a number of\ninteresting program rewritings.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 00:28:58 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 18:21:22 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Lierler", "Yuliya", ""]]}, {"id": "1901.09135", "submitter": "Alexander Wong", "authors": "Zhong Qiu Lin and Alexander Wong", "title": "Progressive Label Distillation: Learning Input-Efficient Deep Neural\n  Networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the focus in the area of knowledge distillation has been on\ndistilling knowledge from a larger teacher network to a smaller student\nnetwork. However, there has been little research on how the concept of\ndistillation can be leveraged to distill the knowledge encapsulated in the\ntraining data itself into a reduced form. In this study, we explore the concept\nof progressive label distillation, where we leverage a series of\nteacher-student network pairs to progressively generate distilled training data\nfor learning deep neural networks with greatly reduced input dimensions. To\ninvestigate the efficacy of the proposed progressive label distillation\napproach, we experimented with learning a deep limited vocabulary speech\nrecognition network based on generated 500ms input utterances distilled\nprogressively from 1000ms source training data, and demonstrated a significant\nincrease in test accuracy of almost 78% compared to direct learning.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 01:22:14 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Lin", "Zhong Qiu", ""], ["Wong", "Alexander", ""]]}, {"id": "1901.09207", "submitter": "Ying Wen", "authors": "Ying Wen, Yaodong Yang, Rui Luo, Jun Wang, Wei Pan", "title": "Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are capable of attributing latent mental contents such as beliefs or\nintentions to others. The social skill is critical in daily life for reasoning\nabout the potential consequences of others' behaviors so as to plan ahead. It\nis known that humans use such reasoning ability recursively by considering what\nothers believe about their own beliefs. In this paper, we start from level-$1$\nrecursion and introduce a probabilistic recursive reasoning (PR2) framework for\nmulti-agent reinforcement learning. Our hypothesis is that it is beneficial for\neach agent to account for how the opponents would react to its future\nbehaviors. Under the PR2 framework, we adopt variational Bayes methods to\napproximate the opponents' conditional policies, to which each agent finds the\nbest response and then improve their own policies. We develop\ndecentralized-training-decentralized-execution algorithms, namely PR2-Q and\nPR2-Actor-Critic, that are proved to converge in the self-play scenarios when\nthere exists one Nash equilibrium. Our methods are tested on both the matrix\ngame and the differential game, which have a non-trivial equilibrium where\ncommon gradient-based methods fail to converge. Our experiments show that it is\ncritical to reason about how the opponents believe about what the agent\nbelieves. We expect our work to contribute a new idea of modeling the opponents\nto the multi-agent reinforcement learning community.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 13:08:08 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 11:06:20 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Wen", "Ying", ""], ["Yang", "Yaodong", ""], ["Luo", "Rui", ""], ["Wang", "Jun", ""], ["Pan", "Wei", ""]]}, {"id": "1901.09216", "submitter": "Yaodong Yang Mr.", "authors": "Ying Wen, Yaodong Yang, Rui Luo, Jun Wang", "title": "Modelling Bounded Rationality in Multi-Agent Interactions by Generalized\n  Recursive Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though limited in real-world decision making, most multi-agent reinforcement\nlearning (MARL) models assume perfectly rational agents -- a property hardly\nmet due to individual's cognitive limitation and/or the tractability of the\ndecision problem. In this paper, we introduce generalized recursive reasoning\n(GR2) as a novel framework to model agents with different \\emph{hierarchical}\nlevels of rationality; our framework enables agents to exhibit varying levels\nof \"thinking\" ability thereby allowing higher-level agents to best respond to\nvarious less sophisticated learners. We contribute both theoretically and\nempirically. On the theory side, we devise the hierarchical framework of GR2\nthrough probabilistic graphical models and prove the existence of a perfect\nBayesian equilibrium. Within the GR2, we propose a practical actor-critic\nsolver, and demonstrate its convergent property to a stationary point in\ntwo-player games through Lyapunov analysis. On the empirical side, we validate\nour findings on a variety of MARL benchmarks. Precisely, we first illustrate\nthe hierarchical thinking process on the Keynes Beauty Contest, and then\ndemonstrate significant improvements compared to state-of-the-art opponent\nmodeling baselines on the normal-form games and the cooperative navigation\nbenchmark.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 13:55:55 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 22:28:11 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wen", "Ying", ""], ["Yang", "Yaodong", ""], ["Luo", "Rui", ""], ["Wang", "Jun", ""]]}, {"id": "1901.09387", "submitter": "Yueh-Hua Wu", "authors": "Yueh-Hua Wu, Nontawat Charoenphakdee, Han Bao, Voot Tangkaratt,\n  Masashi Sugiyama", "title": "Imitation Learning from Imperfect Demonstration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning (IL) aims to learn an optimal policy from demonstrations.\nHowever, such demonstrations are often imperfect since collecting optimal ones\nis costly. To effectively learn from imperfect demonstrations, we propose a\nnovel approach that utilizes confidence scores, which describe the quality of\ndemonstrations. More specifically, we propose two confidence-based IL methods,\nnamely two-step importance weighting IL (2IWIL) and generative adversarial IL\nwith imperfect demonstration and confidence (IC-GAIL). We show that confidence\nscores given only to a small portion of sub-optimal demonstrations\nsignificantly improve the performance of IL both theoretically and empirically.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 14:42:53 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 13:47:40 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 01:43:01 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Wu", "Yueh-Hua", ""], ["Charoenphakdee", "Nontawat", ""], ["Bao", "Han", ""], ["Tangkaratt", "Voot", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1901.09453", "submitter": "Han Zhao", "authors": "Han Zhao, Remi Tachet des Combes, Kun Zhang, Geoffrey J. Gordon", "title": "On Learning Invariant Representation for Domain Adaptation", "comments": "Compared with the last version, the current one adds a new corollary\n  for the case of different feature transformations (encoders) on source/target\n  domains. Fix a typo in Fig. 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the ability of deep neural nets to learn rich representations, recent\nadvances in unsupervised domain adaptation have focused on learning\ndomain-invariant features that achieve a small error on the source domain. The\nhope is that the learnt representation, together with the hypothesis learnt\nfrom the source domain, can generalize to the target domain. In this paper, we\nfirst construct a simple counterexample showing that, contrary to common\nbelief, the above conditions are not sufficient to guarantee successful domain\nadaptation. In particular, the counterexample exhibits \\emph{conditional\nshift}: the class-conditional distributions of input features change between\nsource and target domains. To give a sufficient condition for domain\nadaptation, we propose a natural and interpretable generalization upper bound\nthat explicitly takes into account the aforementioned shift. Moreover, we shed\nnew light on the problem by proving an information-theoretic lower bound on the\njoint error of \\emph{any} domain adaptation method that attempts to learn\ninvariant representations. Our result characterizes a fundamental tradeoff\nbetween learning invariant representations and achieving small joint error on\nboth domains when the marginal label distributions differ from source to\ntarget. Finally, we conduct experiments on real-world datasets that corroborate\nour theoretical findings. We believe these insights are helpful in guiding the\nfuture design of domain adaptation and representation learning algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 22:44:00 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 16:17:02 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Zhao", "Han", ""], ["Combes", "Remi Tachet des", ""], ["Zhang", "Kun", ""], ["Gordon", "Geoffrey J.", ""]]}, {"id": "1901.09465", "submitter": "Banghua Zhu", "authors": "Banghua Zhu, Jiantao Jiao and David Tse", "title": "Deconstructing Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We deconstruct the performance of GANs into three components:\n  1. Formulation: we propose a perturbation view of the population target of\nGANs. Building on this interpretation, we show that GANs can be viewed as a\ngeneralization of the robust statistics framework, and propose a novel GAN\narchitecture, termed as Cascade GANs, to provably recover meaningful\nlow-dimensional generator approximations when the real distribution is\nhigh-dimensional and corrupted by outliers.\n  2. Generalization: given a population target of GANs, we design a systematic\nprinciple, projection under admissible distance, to design GANs to meet the\npopulation requirement using finite samples. We implement our principle in\nthree cases to achieve polynomial and sometimes near-optimal sample\ncomplexities: (1) learning an arbitrary generator under an arbitrary\npseudonorm; (2) learning a Gaussian location family under TV distance, where we\nutilize our principle provide a new proof for the optimality of Tukey median\nviewed as GANs; (3) learning a low-dimensional Gaussian approximation of a\nhigh-dimensional arbitrary distribution under Wasserstein distance. We\ndemonstrate a fundamental trade-off in the approximation error and statistical\nerror in GANs, and show how to apply our principle with empirical samples to\npredict how many samples are sufficient for GANs in order not to suffer from\nthe discriminator winning problem.\n  3. Optimization: we demonstrate alternating gradient descent is provably not\nlocally asymptotically stable in optimizing the GAN formulation of PCA. We\ndiagnose the problem as the minimax duality gap being non-zero, and propose a\nnew GAN architecture whose duality gap is zero, where the value of the game is\nequal to the previous minimax value (not the maximin value). We prove the new\nGAN architecture is globally asymptotically stable in optimization under\nalternating gradient descent.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 23:53:32 GMT"}, {"version": "v2", "created": "Sun, 10 Feb 2019 22:11:56 GMT"}, {"version": "v3", "created": "Tue, 7 May 2019 22:39:30 GMT"}, {"version": "v4", "created": "Thu, 9 May 2019 07:07:40 GMT"}, {"version": "v5", "created": "Sat, 11 May 2019 18:59:04 GMT"}, {"version": "v6", "created": "Fri, 17 May 2019 04:53:36 GMT"}, {"version": "v7", "created": "Mon, 20 May 2019 01:11:05 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Zhu", "Banghua", ""], ["Jiao", "Jiantao", ""], ["Tse", "David", ""]]}, {"id": "1901.09492", "submitter": "Yongzhen Wang", "authors": "Yongzhen Wang, Xiaozhong Liu, Zheng Gao", "title": "Neural Related Work Summarization with a Joint Context-driven Attention\n  Mechanism", "comments": "11 pages, 3 figures, in the Proceedings of EMNLP 2018", "journal-ref": null, "doi": "10.18653/v1/D18-1204", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional solutions to automatic related work summarization rely heavily\non human-engineered features. In this paper, we develop a neural data-driven\nsummarizer by leveraging the seq2seq paradigm, in which a joint context-driven\nattention mechanism is proposed to measure the contextual relevance within full\ntexts and a heterogeneous bibliography graph simultaneously. Our motivation is\nto maintain the topic coherency between a related work section and its target\ndocument, where both the textual and graphic contexts play a big role in\ncharacterizing the relationship among scientific publications accurately.\nExperimental results on a large dataset show that our approach achieves a\nconsiderable improvement over a typical seq2seq summarizer and five classical\nsummarization baselines.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 03:00:06 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Wang", "Yongzhen", ""], ["Liu", "Xiaozhong", ""], ["Gao", "Zheng", ""]]}, {"id": "1901.09501", "submitter": "Shuai Lin", "authors": "Shuai Lin, Wentao Wang, Zichao Yang, Xiaodan Liang, Frank F. Xu, Eric\n  Xing and Zhiting Hu", "title": "Data-to-Text Generation with Style Imitation", "comments": "Accepted by EMNLP 2020 Findings. Significant updates over the\n  previous version. Code & data are available at\n  https://github.com/ha-lins/DTG-SI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural approaches to data-to-text generation have mostly focused on\nimproving content fidelity while lacking explicit control over writing styles\n(e.g., word choices, sentence structures). More traditional systems use\ntemplates to determine the realization of text. Yet manual or automatic\nconstruction of high-quality templates is difficult, and a template acting as\nhard constraints could harm content fidelity when it does not match the record\nperfectly. We study a new way of stylistic control by using existing sentences\nas soft templates. That is, the model learns to imitate the writing style of\nany given exemplar sentence, with automatic adaptions to faithfully describe\nthe content record. The problem is challenging due to the lack of parallel\ndata. We develop a neural approach that includes a hybrid attention-copy\nmechanism, learns with weak supervisions, and is enhanced with a new content\ncoverage constraint. We conduct experiments in restaurants and sports domains.\nResults show our approach achieves stronger performance than a range of\ncomparison methods. Our approach balances well between content fidelity and\nstyle control given exemplars that match the records to varying degrees.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 03:38:08 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 17:08:56 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 08:09:14 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Lin", "Shuai", ""], ["Wang", "Wentao", ""], ["Yang", "Zichao", ""], ["Liang", "Xiaodan", ""], ["Xu", "Frank F.", ""], ["Xing", "Eric", ""], ["Hu", "Zhiting", ""]]}, {"id": "1901.09774", "submitter": "Hao Tang", "authors": "Hao Tang, Xinya Chen, Wei Wang, Dan Xu, Jason J. Corso, Nicu Sebe, Yan\n  Yan", "title": "Attribute-Guided Sketch Generation", "comments": "7 pages, 6 figures, accepted to FG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial attributes are important since they provide a detailed description and\ndetermine the visual appearance of human faces. In this paper, we aim at\nconverting a face image to a sketch while simultaneously generating facial\nattributes. To this end, we propose a novel Attribute-Guided Sketch Generative\nAdversarial Network (ASGAN) which is an end-to-end framework and contains two\npairs of generators and discriminators, one of which is used to generate faces\nwith attributes while the other one is employed for image-to-sketch\ntranslation. The two generators form a W-shaped network (W-net) and they are\ntrained jointly with a weight-sharing constraint. Additionally, we also propose\ntwo novel discriminators, the residual one focusing on attribute generation and\nthe triplex one helping to generate realistic looking sketches. To validate our\nmodel, we have created a new large dataset with 8,804 images, named the\nAttribute Face Photo & Sketch (AFPS) dataset which is the first dataset\ncontaining attributes associated to face sketch images. The experimental\nresults demonstrate that the proposed network (i) generates more\nphoto-realistic faces with sharper facial attributes than baselines and (ii)\nhas good generalization capability on different generative tasks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 16:20:20 GMT"}, {"version": "v2", "created": "Sun, 14 Apr 2019 15:27:38 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Tang", "Hao", ""], ["Chen", "Xinya", ""], ["Wang", "Wei", ""], ["Xu", "Dan", ""], ["Corso", "Jason J.", ""], ["Sebe", "Nicu", ""], ["Yan", "Yan", ""]]}, {"id": "1901.09784", "submitter": "Yunjuan Wang", "authors": "Yunjuan Wang and Yong Deng", "title": "OWA aggregation of multi-criteria with mixed uncertain fuzzy\n  satisfactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply the Ordered Weighted Averaging (OWA) operator in multi-criteria\ndecision-making. To satisfy different kinds of uncertainty, measure based\ndominance has been presented to gain the order of different criterion. However,\nthis idea has not been applied in fuzzy system until now. In this paper, we\nfocus on the situation where the linguistic satisfactions are fuzzy measures\ninstead of the exact values. We review the concept of OWA operator and discuss\nthe order mechanism of fuzzy number. Then we combine with measure-based\ndominance to give an overall score of each alternatives. An example is\nillustrated to show the whole procedure.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 01:20:27 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Wang", "Yunjuan", ""], ["Deng", "Yong", ""]]}, {"id": "1901.09786", "submitter": "David Kupeev", "authors": "Dr. David Kupeev", "title": "AlteregoNets: a way to human augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A person dependent network, called an AlterEgo net, is proposed for\ndevelopment. The networks are created per person. It receives at input an\nobject descriptions and outputs a simulation of the internal person's\nrepresentation of the objects. The network generates a textual stream\nresembling the narrative stream of consciousness depicting multitudinous\nthoughts and feelings related to a perceived object. In this way, the object is\ndescribed not by a 'static' set of its properties, like a dictionary, but by\nthe stream of words and word combinations referring to the object. The network\nsimulates a person's dialogue with a representation of the object. It is based\non an introduced algorithmic scheme, where perception is modeled by two\ninteracting iterative cycles, reminding one respectively the forward and\nbackward propagation executed at training convolution neural networks. The\n'forward' iterations generate a stream representing the 'internal world' of a\nhuman. The 'backward' iterations generate a stream representing an internal\nrepresentation of the object. People perceive the world differently. Tuning\nAlterEgo nets to a specific person or group of persons, will allow simulation\nof their thoughts and feelings. Thereby these nets is potentially a new human\naugmentation technology for various applications.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 16:21:02 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Kupeev", "Dr. David", ""]]}, {"id": "1901.09790", "submitter": "Azzeddine Benabbou", "authors": "Azzeddine Benabbou (Heudiasyc), Domitile Lourdeaux (Heudiasyc),\n  Dominique Lenne (Heudiasyc)", "title": "A model for prohibition and obligation dilemmas generation in virtual\n  environments", "comments": "in French", "journal-ref": "Sciences et Technologies de l'Information et de la Communication\n  pour l'{\\'E}ducation et la Formation, ATIEF, 2018", "doi": "10.23709/sticef.25.1.4", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the project Maccoy Critical, we would like to train individuals, in\nvirtual environments, to handle critical situations such as dilemmas. These\nlatter refer to situations where there is no ``good'' solution. In other words,\nsituations that lead to negative consequences whichever choice is made. Our\nobjective is to use Knowledge Models to extract necessary properties for\ndilemmas to emerge. To do so, our approach consists in developing a Scenario\nOrchestration System that generates dilemma situations dynamically without\nhaving to write them beforehand. In this paper we present this approach and\nexpose a proof of concept of the generation process.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 08:06:52 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Benabbou", "Azzeddine", "", "Heudiasyc"], ["Lourdeaux", "Domitile", "", "Heudiasyc"], ["Lenne", "Dominique", "", "Heudiasyc"]]}, {"id": "1901.09791", "submitter": "Jun Wang", "authors": "Jun Wang, Sujoy Sikdar, Tyler Shepherd, Zhibing Zhao, Chunheng Jiang\n  and Lirong Xia", "title": "Practical Algorithms for Multi-Stage Voting Rules with Parallel\n  Universes Tiebreaking", "comments": "arXiv admin note: substantial text overlap with arXiv:1805.06992", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  STV and ranked pairs (RP) are two well-studied voting rules for group\ndecision-making. They proceed in multiple rounds, and are affected by how ties\nare broken in each round. However, the literature is surprisingly vague about\nhow ties should be broken. We propose the first algorithms for computing the\nset of alternatives that are winners under some tiebreaking mechanism under STV\nand RP, which is also known as parallel-universes tiebreaking (PUT).\nUnfortunately, PUT-winners are NP-complete to compute under STV and RP, and\nstandard search algorithms from AI do not apply. We propose multiple DFS-based\nalgorithms along with pruning strategies, heuristics, sampling and machine\nlearning to prioritize search direction to significantly improve the\nperformance. We also propose novel ILP formulations for PUT-winners under STV\nand RP, respectively. Experiments on synthetic and real-world data show that\nour algorithms are overall faster than ILP.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 21:41:39 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Wang", "Jun", ""], ["Sikdar", "Sujoy", ""], ["Shepherd", "Tyler", ""], ["Zhao", "Zhibing", ""], ["Jiang", "Chunheng", ""], ["Xia", "Lirong", ""]]}, {"id": "1901.09792", "submitter": "Pablo Lanillos", "authors": "German Diez-Valencia, Takuya Ohashi, Pablo Lanillos, Gordon Cheng", "title": "Sensorimotor learning for artificial body perception", "comments": "Workshop on Crossmodal Learning for Intelligent Robotics. IEEE Int.\n  Conference on Intelligent Robots and Systems (IROS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial self-perception is the machine ability to perceive its own body,\ni.e., the mastery of modal and intermodal contingencies of performing an action\nwith a specific sensors/actuators body configuration. In other words, the\nspatio-temporal patterns that relate its sensors (e.g. visual, proprioceptive,\ntactile, etc.), its actions and its body latent variables are responsible of\nthe distinction between its own body and the rest of the world. This paper\ndescribes some of the latest approaches for modelling artificial body\nself-perception: from Bayesian estimation to deep learning. Results show the\npotential of these free-model unsupervised or semi-supervised\ncrossmodal/intermodal learning approaches. However, there are still challenges\nthat should be overcome before we achieve artificial multisensory body\nperception.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 15:34:35 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Diez-Valencia", "German", ""], ["Ohashi", "Takuya", ""], ["Lanillos", "Pablo", ""], ["Cheng", "Gordon", ""]]}, {"id": "1901.09793", "submitter": "Nicolas Beldiceanu", "authors": "Ekaterina Arafailova and Nicolas Beldiceanu and Helmut Simonis", "title": "Synthesising a Database of Parameterised Linear and Non-Linear\n  Invariants for Time-Series Constraints", "comments": "42 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many constraints restricting the result of some computations over an integer\nsequence can be compactly represented by register automata. We improve the\npropagation of the conjunction of such constraints on the same sequence by\nsynthesising a database of linear and non-linear invariants using their\nregister-automaton representation. The obtained invariants are formulae\nparameterised by a function of the sequence length and proven to be true for\nany long enough sequence. To assess the quality of such linear invariants, we\ndeveloped a method to verify whether a generated linear invariant is a facet of\nthe convex hull of the feasible points. This method, as well as the proof of\nnon-linear invariants, are based on the systematic generation of constant-size\ndeterministic finite automata that accept all integer sequences whose result\nverifies some simple condition. We apply such methodology to a set of 44\ntime-series constraints and obtain 1400 linear invariants from which 70% are\nfacet defining, and 600 non-linear invariants, which were tested on short-term\nelectricity production problems.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 13:43:42 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Arafailova", "Ekaterina", ""], ["Beldiceanu", "Nicolas", ""], ["Simonis", "Helmut", ""]]}, {"id": "1901.09867", "submitter": "Claudio Tomazzoli", "authors": "Matteo Cristani, Francesco Domenichini, Claudio Tomazzoli, and Luca\n  Vigan\\`o and Margherita Zorzi", "title": "It could be worse, it could be raining: reliable automatic\n  meteorological forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meteorological forecasting provides reliable prediction about the future\nweather within a given interval of time. Meteorological forecasting can be\nviewed as a form of hybrid diagnostic reasoning and can be mapped onto an\nintegrated conceptual framework. The automation of the forecasting process\nwould be helpful in a number of contexts, in particular: when the amount of\ndata is too wide to be dealt with manually; to support forecasters education;\nwhen forecasting about underpopulated geographic areas is not interesting for\neveryday life (and then is out from human forecasters' tasks) but is central\nfor tourism sponsorship. We present logic MeteoLOG, a framework that models the\nmain steps of the reasoner the forecaster adopts to provide a bulletin.\nMeteoLOG rests on several traditions, mainly on fuzzy, temporal and\nprobabilistic logics. On this basis, we also introduce the algorithm\nTournament, that transforms a set of MeteoLOG rules into a defeasible theory,\nthat can be implemented into an automatic reasoner. We finally propose an\nexample that models a real world forecasting scenario.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 18:18:04 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 08:43:05 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Cristani", "Matteo", ""], ["Domenichini", "Francesco", ""], ["Tomazzoli", "Claudio", ""], ["Vigan\u00f2", "Luca", ""], ["Zorzi", "Margherita", ""]]}, {"id": "1901.09888", "submitter": "Muhammad Ammad-Ud-Din Ph.D.", "authors": "Muhammad Ammad-ud-din, Elena Ivannikova, Suleiman A. Khan, Were\n  Oyomno, Qiang Fu, Kuan Eeik Tan and Adrian Flanagan", "title": "Federated Collaborative Filtering for Privacy-Preserving Personalized\n  Recommendation System", "comments": "12 pages, 2 figures, 2 tables, submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The increasing interest in user privacy is leading to new privacy preserving\nmachine learning paradigms. In the Federated Learning paradigm, a master\nmachine learning model is distributed to user clients, the clients use their\nlocally stored data and model for both inference and calculating model updates.\nThe model updates are sent back and aggregated on the server to update the\nmaster model then redistributed to the clients. In this paradigm, the user data\nnever leaves the client, greatly enhancing the user' privacy, in contrast to\nthe traditional paradigm of collecting, storing and processing user data on a\nbackend server beyond the user's control. In this paper we introduce, as far as\nwe are aware, the first federated implementation of a Collaborative Filter. The\nfederated updates to the model are based on a stochastic gradient approach. As\na classical case study in machine learning, we explore a personalized\nrecommendation system based on users' implicit feedback and demonstrate the\nmethod's applicability to both the MovieLens and an in-house dataset. Empirical\nvalidation confirms a collaborative filter can be federated without a loss of\naccuracy compared to a standard implementation, hence enhancing the user's\nprivacy in a widely used recommender application while maintaining recommender\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 14:18:38 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Ammad-ud-din", "Muhammad", ""], ["Ivannikova", "Elena", ""], ["Khan", "Suleiman A.", ""], ["Oyomno", "Were", ""], ["Fu", "Qiang", ""], ["Tan", "Kuan Eeik", ""], ["Flanagan", "Adrian", ""]]}, {"id": "1901.09890", "submitter": "Yu Cheng", "authors": "Yu Cheng, Mo Yu, Xiaoxiao Guo, Bowen Zhou", "title": "Few-shot Learning with Meta Metric Learners", "comments": "Published in NIPS 2017 workshop on Meta-Learning, arXiv version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot Learning aims to learn classifiers for new classes with only a few\ntraining examples per class. Existing meta-learning or metric-learning based\nfew-shot learning approaches are limited in handling diverse domains with\nvarious number of labels. The meta-learning approaches train a meta learner to\npredict weights of homogeneous-structured task-specific networks, requiring a\nuniform number of classes across tasks. The metric-learning approaches learn\none task-invariant metric for all the tasks, and they fail if the tasks\ndiverge. We propose to deal with these limitations with meta metric learning.\nOur meta metric learning approach consists of task-specific learners, that\nexploit metric learning to handle flexible labels, and a meta learner, that\ndiscovers good parameters and gradient decent to specify the metrics in\ntask-specific learners. Thus the proposed model is able to handle unbalanced\nclasses as well as to generate task-specific metrics. We test our approach in\nthe `$k$-shot $N$-way' few-shot learning setting used in previous work and new\nrealistic few-shot setting with diverse multi-domain tasks and flexible label\nnumbers. Experiments show that our approach attains superior performances in\nboth settings.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 01:55:33 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Cheng", "Yu", ""], ["Yu", "Mo", ""], ["Guo", "Xiaoxiao", ""], ["Zhou", "Bowen", ""]]}, {"id": "1901.09894", "submitter": "Soheila Sadeghiram", "authors": "Soheila Sadeghiram, Hui Ma, Gang Chen", "title": "Composing Distributed Data-intensive Web Services Using a Flexible\n  Memetic Algorithm", "comments": "arXiv admin note: text overlap with arXiv:1901.05564", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web Service Composition (WSC) is a particularly promising application of Web\nservices, where multiple individual services with specific functionalities are\ncomposed to accomplish a more complex task, which must fulfil functional\nrequirements and optimise Quality of Service (QoS) attributes, simultaneously.\nAdditionally, large quantities of data, produced by technological advances,\nneed to be exchanged between services. Data-intensive Web services, which\nmanipulate and deal with those data, are of great interest to implement\ndata-intensive processes, such as distributed Data-intensive Web Service\nComposition (DWSC). Researchers have proposed Evolutionary Computing (EC)\nfully-automated WSC techniques that meet all the above factors. Some of these\nworks employed Memetic Algorithms (MAs) to enhance the performance of EC\nthrough increasing its exploitation ability of in searching neighbourhood area\nof a solution. However, those works are not efficient or effective. This paper\nproposes an MA-based approach to solving the problem of distributed DWSC in an\neffective and efficient manner. In particular, we develop an MA that hybridises\nEC with a flexible local search technique incorporating distance of services.\nAn evaluation using benchmark datasets is carried out, comparing existing\nstate-of-the-art methods. Results show that our proposed method has the highest\nquality and an acceptable execution time overall.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 23:50:05 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Sadeghiram", "Soheila", ""], ["Ma", "Hui", ""], ["Chen", "Gang", ""]]}, {"id": "1901.09895", "submitter": "Andrew Melnik", "authors": "Andrew Melnik, Sascha Fleer, Malte Schilling, Helge Ritter", "title": "Modularization of End-to-End Learning: Case Study in Arcade Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Complex environments and tasks pose a difficult problem for holistic\nend-to-end learning approaches. Decomposition of an environment into\ninteracting controllable and non-controllable objects allows supervised\nlearning for non-controllable objects and universal value function approximator\nlearning for controllable objects. Such decomposition should lead to a shorter\nlearning time and better generalisation capability. Here, we consider\narcade-game environments as sets of interacting objects (controllable,\nnon-controllable) and propose a set of functional modules that are specialized\non mastering different types of interactions in a broad range of environments.\nThe modules utilize regression, supervised learning, and reinforcement learning\nalgorithms. Results of this case study in different Atari games suggest that\nhuman-level performance can be achieved by a learning agent within a human\namount of game experience (10-15 minutes game time) when a proper decomposition\nof an environment or a task is provided. However, automatization of such\ndecomposition remains a challenging problem. This case study shows how a model\nof a causal structure underlying an environment or a task can benefit learning\ntime and generalization capability of the agent, and argues in favor of\nexploiting modular structure in contrast to using pure end-to-end learning\napproaches.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 05:06:30 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Melnik", "Andrew", ""], ["Fleer", "Sascha", ""], ["Schilling", "Malte", ""], ["Ritter", "Helge", ""]]}, {"id": "1901.09971", "submitter": "Felix Stephenson", "authors": "Felix Stephenson, Toby Breckon and Ioannis Katramados", "title": "DeGraF-Flow: Extending DeGraF Features for accurate and efficient\n  sparse-to-dense optical flow estimation", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern optical flow methods make use of salient scene feature points detected\nand matched within the scene as a basis for sparse-to-dense optical flow\nestimation. Current feature detectors however either give sparse, non uniform\npoint clouds (resulting in flow inaccuracies) or lack the efficiency for\nframe-rate real-time applications. In this work we use the novel Dense Gradient\nBased Features (DeGraF) as the input to a sparse-to-dense optical flow scheme.\nThis consists of three stages: 1) efficient detection of uniformly distributed\nDense Gradient Based Features (DeGraF); 2) feature tracking via robust local\noptical flow; and 3) edge preserving flow interpolation to recover overall\ndense optical flow. The tunable density and uniformity of DeGraF features yield\nsuperior dense optical flow estimation compared to other popular feature\ndetectors within this three stage pipeline. Furthermore, the comparable speed\nof feature detection also lends itself well to the aim of real-time optical\nflow recovery. Evaluation on established real-world benchmark datasets show\ntest performance in an autonomous vehicle setting where DeGraF-Flow shows\npromising results in terms of accuracy with competitive computational\nefficiency among non-GPU based methods, including a marked increase in speed\nover the conceptually similar EpicFlow approach.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 19:55:40 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 16:42:22 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Stephenson", "Felix", ""], ["Breckon", "Toby", ""], ["Katramados", "Ioannis", ""]]}, {"id": "1901.09972", "submitter": "David Mac\\^edo", "authors": "Jefferson L. P. Lima, David Mac\\^edo, Cleber Zanchettin", "title": "Heartbeat Anomaly Detection using Adversarial Oversampling", "comments": null, "journal-ref": "2019 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN.2019.8852242", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardiovascular diseases are one of the most common causes of death in the\nworld. Prevention, knowledge of previous cases in the family, and early\ndetection is the best strategy to reduce this fact. Different machine learning\napproaches to automatic diagnostic are being proposed to this task. As in most\nhealth problems, the imbalance between examples and classes is predominant in\nthis problem and affects the performance of the automated solution. In this\npaper, we address the classification of heartbeats images in different\ncardiovascular diseases. We propose a two-dimensional Convolutional Neural\nNetwork for classification after using a InfoGAN architecture for generating\nsynthetic images to unbalanced classes. We call this proposal Adversarial\nOversampling and compare it with the classical oversampling methods as SMOTE,\nADASYN, and RandomOversampling. The results show that the proposed approach\nimproves the classifier performance for the minority classes without harming\nthe performance in the balanced classes.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 19:55:42 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Lima", "Jefferson L. P.", ""], ["Mac\u00eado", "David", ""], ["Zanchettin", "Cleber", ""]]}, {"id": "1901.09993", "submitter": "Qimai Li", "authors": "Qimai Li, Xiao-Ming Wu, Han Liu, Xiaotong Zhang, Zhichao Guan", "title": "Label Efficient Semi-Supervised Learning via Graph Filtering", "comments": "Accepted by 2019 IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based methods have been demonstrated as one of the most effective\napproaches for semi-supervised learning, as they can exploit the connectivity\npatterns between labeled and unlabeled data samples to improve learning\nperformance. However, existing graph-based methods either are limited in their\nability to jointly model graph structures and data features, such as the\nclassical label propagation methods, or require a considerable amount of\nlabeled data for training and validation due to high model complexity, such as\nthe recent neural-network-based methods. In this paper, we address label\nefficient semi-supervised learning from a graph filtering perspective.\nSpecifically, we propose a graph filtering framework that injects graph\nsimilarity into data features by taking them as signals on the graph and\napplying a low-pass graph filter to extract useful data representations for\nclassification, where label efficiency can be achieved by conveniently\nadjusting the strength of the graph filter. Interestingly, this framework\nunifies two seemingly very different methods -- label propagation and graph\nconvolutional networks. Revisiting them under the graph filtering framework\nleads to new insights that improve their modeling capabilities and reduce model\ncomplexity. Experiments on various semi-supervised classification tasks on four\ncitation networks and one knowledge graph and one semi-supervised regression\ntask for zero-shot image recognition validate our findings and proposals.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 20:45:27 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 08:00:15 GMT"}, {"version": "v3", "created": "Fri, 28 Jun 2019 08:22:10 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Li", "Qimai", ""], ["Wu", "Xiao-Ming", ""], ["Liu", "Han", ""], ["Zhang", "Xiaotong", ""], ["Guan", "Zhichao", ""]]}, {"id": "1901.10031", "submitter": "Yinlam Chow", "authors": "Yinlam Chow and Ofir Nachum and Aleksandra Faust and Edgar\n  Duenez-Guzman and Mohammad Ghavamzadeh", "title": "Lyapunov-based Safe Policy Optimization for Continuous Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study continuous action reinforcement learning problems in which it is\ncrucial that the agent interacts with the environment only through safe\npolicies, i.e.,~policies that do not take the agent to undesirable situations.\nWe formulate these problems as constrained Markov decision processes (CMDPs)\nand present safe policy optimization algorithms that are based on a Lyapunov\napproach to solve them. Our algorithms can use any standard policy gradient\n(PG) method, such as deep deterministic policy gradient (DDPG) or proximal\npolicy optimization (PPO), to train a neural network policy, while guaranteeing\nnear-constraint satisfaction for every policy update by projecting either the\npolicy parameter or the action onto the set of feasible solutions induced by\nthe state-dependent linearized Lyapunov constraints. Compared to the existing\nconstrained PG algorithms, ours are more data efficient as they are able to\nutilize both on-policy and off-policy data. Moreover, our action-projection\nalgorithm often leads to less conservative policy updates and allows for\nnatural integration into an end-to-end PG training pipeline. We evaluate our\nalgorithms and compare them with the state-of-the-art baselines on several\nsimulated (MuJoCo) tasks, as well as a real-world indoor robot navigation\nproblem, demonstrating their effectiveness in terms of balancing performance\nand constraint satisfaction. Videos of the experiments can be found in the\nfollowing link:\nhttps://drive.google.com/file/d/1pzuzFqWIE710bE2U6DmS59AfRzqK2Kek/view?usp=sharing.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 23:14:58 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 20:52:42 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Chow", "Yinlam", ""], ["Nachum", "Ofir", ""], ["Faust", "Aleksandra", ""], ["Duenez-Guzman", "Edgar", ""], ["Ghavamzadeh", "Mohammad", ""]]}, {"id": "1901.10040", "submitter": "Quanshi Zhang", "authors": "Umang Bhatt, Pradeep Ravikumar, Jose M. F. Moura", "title": "Towards Aggregating Weighted Feature Attributions", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches for explaining machine learning models fall into two\ndistinct classes: antecedent event influence and value attribution. The former\nleverages training instances to describe how much influence a training point\nexerts on a test point, while the latter attempts to attribute value to the\nfeatures most pertinent to a given prediction. In this work, we discuss an\nalgorithm, AVA: Aggregate Valuation of Antecedents, that fuses these two\nexplanation classes to form a new approach to feature attribution that not only\nretrieves local explanations but also captures global patterns learned by a\nmodel. Our experimentation convincingly favors weighting and aggregating\nfeature attributions via AVA.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:45:50 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Bhatt", "Umang", ""], ["Ravikumar", "Pradeep", ""], ["Moura", "Jose M. F.", ""]]}, {"id": "1901.10051", "submitter": "Kun Qian", "authors": "Phokion G. Kolaitis, Lucian Popa, and Kun Qian", "title": "Knowledge Refinement via Rule Selection", "comments": null, "journal-ref": null, "doi": "10.1609/aaai.v33i01.33012886", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several different applications, including data transformation and entity\nresolution, rules are used to capture aspects of knowledge about the\napplication at hand. Often, a large set of such rules is generated\nautomatically or semi-automatically, and the challenge is to refine the\nencapsulated knowledge by selecting a subset of rules based on the expected\noperational behavior of the rules on available data. In this paper, we carry\nout a systematic complexity-theoretic investigation of the following rule\nselection problem: given a set of rules specified by Horn formulas, and a pair\nof an input database and an output database, find a subset of the rules that\nminimizes the total error, that is, the number of false positive and false\nnegative errors arising from the selected rules. We first establish\ncomputational hardness results for the decision problems underlying this\nminimization problem, as well as upper and lower bounds for its\napproximability. We then investigate a bi-objective optimization version of the\nrule selection problem in which both the total error and the size of the\nselected rules are taken into account. We show that testing for membership in\nthe Pareto front of this bi-objective optimization problem is DP-complete.\nFinally, we show that a similar DP-completeness result holds for a bi-level\noptimization version of the rule selection problem, where one minimizes first\nthe total error and then the size.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 00:37:24 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Kolaitis", "Phokion G.", ""], ["Popa", "Lucian", ""], ["Qian", "Kun", ""]]}, {"id": "1901.10064", "submitter": "Vikas Kumar", "authors": "Venkateswara Rao Kagita, Arun K Pujari, Vineet Padmanabhan, Vikas\n  Kumar", "title": "Committee Selection with Attribute Level Preferences", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of committee selection from a fixed set of candidates\nwhere each candidate has multiple quantifiable attributes. To select the best\npossible committee, instead of voting for a candidate, a voter is allowed to\napprove the preferred attributes of a given candidate. Though attribute based\npreference is addressed in several contexts, committee selection problem with\nattribute approval of voters has not been attempted earlier. A committee formed\non attribute preferences is more likely to be a better representative of the\nqualities desired by the voters and is less likely to be susceptible to\ncollusion or manipulation. In this work, we provide a formal study of the\ndifferent aspects of this problem and define properties of weak unanimity,\nstrong unanimity, simple justified representations and compound justified\nrepresentation, that are required to be satisfied by the selected committee. We\nshow that none of the existing vote/approval aggregation rules satisfy these\nnew properties for attribute aggregation. We describe a greedy approach for\nattribute aggregation that satisfies the first three properties, but not the\nfourth, i.e., compound justified representation, which we prove to be\nNP-complete. Furthermore, we prove that finding a committee with justified\nrepresentation and the highest approval voting score is NP-complete.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 01:42:22 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 05:40:22 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Kagita", "Venkateswara Rao", ""], ["Pujari", "Arun K", ""], ["Padmanabhan", "Vineet", ""], ["Kumar", "Vikas", ""]]}, {"id": "1901.10072", "submitter": "Xinyang Deng", "authors": "Xinyang Deng and Wen Jiang", "title": "On the negation of a Dempster-Shafer belief structure based on maximum\n  uncertainty allocation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probability theory and Dempster-Shafer theory are two germane theories to\nrepresent and handle uncertain information. Recent study suggested a\ntransformation to obtain the negation of a probability distribution based on\nthe maximum entropy. Correspondingly, determining the negation of a belief\nstructure, however, is still an open issue in Dempster-Shafer theory, which is\nvery important in theoretical research and practical applications. In this\npaper, a negation transformation for belief structures is proposed based on\nmaximum uncertainty allocation, and several important properties satisfied by\nthe transformation have been studied. The proposed negation transformation is\nmore general and could totally compatible with existing transformation for\nprobability distributions.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 02:35:19 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Deng", "Xinyang", ""], ["Jiang", "Wen", ""]]}, {"id": "1901.10098", "submitter": "Du Xu", "authors": "Di Xu, Manjing Fang, Xia Hong, Junbin Gao", "title": "Sparse Least Squares Low Rank Kernel Machines", "comments": "2019 ICONIP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general framework of least squares support vector machine with low rank\nkernels, referred to as LR-LSSVM, is introduced in this paper. The special\nstructure of low rank kernels with a controlled model size brings sparsity as\nwell as computational efficiency to the proposed model. Meanwhile, a two-step\noptimization algorithm with three different criteria is proposed and various\nexperiments are carried out using the example of the so-call robust RBF kernel\nto validate the model. The experiment results show that the performance of the\nproposed algorithm is comparable or superior to several existing kernel\nmachines.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 04:50:59 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 23:59:15 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Xu", "Di", ""], ["Fang", "Manjing", ""], ["Hong", "Xia", ""], ["Gao", "Junbin", ""]]}, {"id": "1901.10114", "submitter": "EPTCS", "authors": "Andrew Fagan, Ross Duncan", "title": "Optimising Clifford Circuits with Quantomatic", "comments": "In Proceedings QPL 2018, arXiv:1901.09476", "journal-ref": "EPTCS 287, 2019, pp. 85-105", "doi": "10.4204/EPTCS.287.5", "report-no": null, "categories": "quant-ph cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system of equations between Clifford circuits, all derivable in\nthe ZX-calculus, and formalised as rewrite rules in the Quantomatic proof\nassistant. By combining these rules with some non-trivial simplification\nprocedures defined in the Quantomatic tactic language, we demonstrate the use\nof Quantomatic as a circuit optimisation tool. We prove that the system always\nreduces Clifford circuits of one or two qubits to their minimal form, and give\nnumerical results demonstrating its performance on larger Clifford circuits.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 05:35:43 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Fagan", "Andrew", ""], ["Duncan", "Ross", ""]]}, {"id": "1901.10124", "submitter": "Shubham Atreja", "authors": "Shanu Kumar, Shubham Atreja, Anjali Singh, Mohit Jain", "title": "Adversarial Adaptation of Scene Graph Models for Understanding Civic\n  Issues", "comments": "Accepted at WWW'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citizen engagement and technology usage are two emerging trends driven by\nsmart city initiatives. Governments around the world are adopting technology\nfor faster resolution of civic issues. Typically, citizens report issues, such\nas broken roads, garbage dumps, etc. through web portals and mobile apps, in\norder for the government authorities to take appropriate actions. Several\nmediums -- text, image, audio, video -- are used to report these issues.\nThrough a user study with 13 citizens and 3 authorities, we found that image is\nthe most preferred medium to report civic issues. However, analyzing civic\nissue related images is challenging for the authorities as it requires manual\neffort. Moreover, previous works have been limited to identifying a specific\nset of issues from images. In this work, given an image, we propose to generate\na Civic Issue Graph consisting of a set of objects and the semantic relations\nbetween them, which are representative of the underlying civic issue. We also\nrelease two multi-modal (text and images) datasets, that can help in further\nanalysis of civic issues from images. We present a novel approach for\nadversarial training of existing scene graph models that enables the use of\nscene graphs for new applications in the absence of any labelled training data.\nWe conduct several experiments to analyze the efficacy of our approach, and\nusing human evaluation, we establish the appropriateness of our model at\nrepresenting different civic issues.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 06:02:45 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Kumar", "Shanu", ""], ["Atreja", "Shubham", ""], ["Singh", "Anjali", ""], ["Jain", "Mohit", ""]]}, {"id": "1901.10125", "submitter": "Jiwei Li", "authors": "Yuxian Meng, Wei Wu, Fei Wang, Xiaoya Li, Ping Nie, Fan Yin, Muyu Li,\n  Qinghong Han, Xiaofei Sun, Jiwei Li", "title": "Glyce: Glyph-vectors for Chinese Character Representations", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is intuitive that NLP tasks for logographic languages like Chinese should\nbenefit from the use of the glyph information in those languages. However, due\nto the lack of rich pictographic evidence in glyphs and the weak generalization\nability of standard computer vision models on character data, an effective way\nto utilize the glyph information remains to be found. In this paper, we address\nthis gap by presenting Glyce, the glyph-vectors for Chinese character\nrepresentations. We make three major innovations: (1) We use historical Chinese\nscripts (e.g., bronzeware script, seal script, traditional Chinese, etc) to\nenrich the pictographic evidence in characters; (2) We design CNN structures\n(called tianzege-CNN) tailored to Chinese character image processing; and (3)\nWe use image-classification as an auxiliary task in a multi-task learning setup\nto increase the model's ability to generalize. We show that glyph-based models\nare able to consistently outperform word/char ID-based models in a wide range\nof Chinese NLP tasks. We are able to set new state-of-the-art results for a\nvariety of Chinese NLP tasks, including tagging (NER, CWS, POS), sentence pair\nclassification, single sentence classification tasks, dependency parsing, and\nsemantic role labeling. For example, the proposed model achieves an F1 score of\n80.6 on the OntoNotes dataset of NER, +1.5 over BERT; it achieves an almost\nperfect accuracy of 99.8\\% on the Fudan corpus for text classification. Code\nfound at https://github.com/ShannonAI/glyce.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 06:15:36 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 17:20:19 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 06:36:27 GMT"}, {"version": "v4", "created": "Wed, 4 Sep 2019 12:15:19 GMT"}, {"version": "v5", "created": "Thu, 21 May 2020 09:05:11 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Meng", "Yuxian", ""], ["Wu", "Wei", ""], ["Wang", "Fei", ""], ["Li", "Xiaoya", ""], ["Nie", "Ping", ""], ["Yin", "Fan", ""], ["Li", "Muyu", ""], ["Han", "Qinghong", ""], ["Sun", "Xiaofei", ""], ["Li", "Jiwei", ""]]}, {"id": "1901.10263", "submitter": "Simon Razniewski", "authors": "Cuong Xuan Chu, Simon Razniewski, Gerhard Weikum", "title": "TiFi: Taxonomy Induction for Fictional Domains [Extended version]", "comments": "Extended version of The Web Conference 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taxonomies are important building blocks of structured knowledge bases, and\ntheir construction from text sources and Wikipedia has received much attention.\nIn this paper we focus on the construction of taxonomies for fictional domains,\nusing noisy category systems from fan wikis or text extraction as input. Such\nfictional domains are archetypes of entity universes that are poorly covered by\nWikipedia, such as also enterprise-specific knowledge bases or highly\nspecialized verticals. Our fiction-targeted approach, called TiFi, consists of\nthree phases: (i) category cleaning, by identifying candidate categories that\ntruly represent classes in the domain of interest, (ii) edge cleaning, by\nselecting subcategory relationships that correspond to class subsumption, and\n(iii) top-level construction, by mapping classes onto a subset of high-level\nWordNet categories. A comprehensive evaluation shows that TiFi is able to\nconstruct taxonomies for a diverse range of fictional domains such as Lord of\nthe Rings, The Simpsons or Greek Mythology with very high precision and that it\noutperforms state-of-the-art baselines for taxonomy induction by a substantial\nmargin.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 13:07:13 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Chu", "Cuong Xuan", ""], ["Razniewski", "Simon", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1901.10314", "submitter": "Yuhui Wang", "authors": "Yuhui Wang, Hao He, Xiaoyang Tan, Yaozhong Gan", "title": "Trust Region-Guided Proximal Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proximal policy optimization (PPO) is one of the most popular deep\nreinforcement learning (RL) methods, achieving state-of-the-art performance\nacross a wide range of challenging tasks. However, as a model-free RL method,\nthe success of PPO relies heavily on the effectiveness of its exploratory\npolicy search. In this paper, we give an in-depth analysis on the exploration\nbehavior of PPO, and show that PPO is prone to suffer from the risk of lack of\nexploration especially under the case of bad initialization, which may lead to\nthe failure of training or being trapped in bad local optima. To address these\nissues, we proposed a novel policy optimization method, named Trust\nRegion-Guided PPO (TRGPPO), which adaptively adjusts the clipping range within\nthe trust region. We formally show that this method not only improves the\nexploration ability within the trust region but enjoys a better performance\nbound compared to the original PPO as well. Extensive experiments verify the\nadvantage of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 14:45:08 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 02:35:07 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Wang", "Yuhui", ""], ["He", "Hao", ""], ["Tan", "Xiaoyang", ""], ["Gan", "Yaozhong", ""]]}, {"id": "1901.10323", "submitter": "Okan K\\\"op\\\"ukl\\\"u", "authors": "Okan K\\\"op\\\"ukl\\\"u, Ahmet Gunduz, Neslihan Kose, Gerhard Rigoll", "title": "Real-time Hand Gesture Detection and Classification Using Convolutional\n  Neural Networks", "comments": "Published at IEEE International Conference on Automatic Face and\n  Gesture Recognition (FG 2019) - Best student paper award! -", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time recognition of dynamic hand gestures from video streams is a\nchallenging task since (i) there is no indication when a gesture starts and\nends in the video, (ii) performed gestures should only be recognized once, and\n(iii) the entire architecture should be designed considering the memory and\npower budget. In this work, we address these challenges by proposing a\nhierarchical structure enabling offline-working convolutional neural network\n(CNN) architectures to operate online efficiently by using sliding window\napproach. The proposed architecture consists of two models: (1) A detector\nwhich is a lightweight CNN architecture to detect gestures and (2) a classifier\nwhich is a deep CNN to classify the detected gestures. In order to evaluate the\nsingle-time activations of the detected gestures, we propose to use Levenshtein\ndistance as an evaluation metric since it can measure misclassifications,\nmultiple detections, and missing detections at the same time. We evaluate our\narchitecture on two publicly available datasets - EgoGesture and NVIDIA Dynamic\nHand Gesture Datasets - which require temporal detection and classification of\nthe performed hand gestures. ResNeXt-101 model, which is used as a classifier,\nachieves the state-of-the-art offline classification accuracy of 94.04% and\n83.82% for depth modality on EgoGesture and NVIDIA benchmarks, respectively. In\nreal-time detection and classification, we obtain considerable early detections\nwhile achieving performances close to offline operation. The codes and\npretrained models used in this work are publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 14:52:51 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 13:17:34 GMT"}, {"version": "v3", "created": "Fri, 18 Oct 2019 08:14:35 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["K\u00f6p\u00fckl\u00fc", "Okan", ""], ["Gunduz", "Ahmet", ""], ["Kose", "Neslihan", ""], ["Rigoll", "Gerhard", ""]]}, {"id": "1901.10341", "submitter": "Mohammadreza Mousaei", "authors": "Heather Jones, Siri Maley, Mohammadreza Mousaei, David Kohanbash,\n  Warren Whittaker, James Teza, Andrew Zhang, Nikhil Jog, William Whittaker", "title": "A Robot for Nondestructive Assay of Holdup Deposits in Gaseous Diffusion\n  Piping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Miles of contaminated pipe must be measured, foot by foot, as part of the\ndecommissioning effort at deactivated gaseous diffusion enrichment facilities.\nThe current method requires cutting away asbestos-lined thermal enclosures and\nperforming repeated, elevated operations to manually measure pipe from the\noutside. The RadPiper robot, part of the Pipe Crawling Activity Measurement\nSystem (PCAMS) developed by Carnegie Mellon University and commissioned for use\nat the DOE Portsmouth Gaseous Diffusion Enrichment Facility, automatically\nmeasures U-235 in pipes from the inside. This improves certainty, increases\nsafety, and greatly reduces measurement time. The heart of the RadPiper robot\nis a sodium iodide scintillation detector in an innovative disc-collimated\nassembly. By measuring from inside pipes, the robot significantly increases its\ncount rate relative to external through-pipe measurements. The robot also\nprovides imagery, models interior pipe geometry, and precisely measures\ndistance in order to localize radiation measurements. Data collected by this\nsystem provides insight into pipe interiors that is simply not possible from\nexterior measurements, all while keeping operators safer. This paper describes\nthe technical details of the PCAMS RadPiper robot. Key features for this robot\ninclude precision distance measurement, in-pipe obstacle detection, ability to\ntransform for two pipe sizes, and robustness in autonomous operation. Test\nresults demonstrating the robot's functionality are presented, including\ndeployment tolerance tests, safeguarding tests, and localization tests.\nIntegrated robot tests are also shown.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 15:36:29 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Jones", "Heather", ""], ["Maley", "Siri", ""], ["Mousaei", "Mohammadreza", ""], ["Kohanbash", "David", ""], ["Whittaker", "Warren", ""], ["Teza", "James", ""], ["Zhang", "Andrew", ""], ["Jog", "Nikhil", ""], ["Whittaker", "William", ""]]}, {"id": "1901.10348", "submitter": "Francesco Locatello", "authors": "Francesco Locatello, Alp Yurtsever, Olivier Fercoq, Volkan Cevher", "title": "Stochastic Frank-Wolfe for Composite Convex Minimization", "comments": null, "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A broad class of convex optimization problems can be formulated as a\nsemidefinite program (SDP), minimization of a convex function over the\npositive-semidefinite cone subject to some affine constraints. The majority of\nclassical SDP solvers are designed for the deterministic setting where problem\ndata is readily available. In this setting, generalized conditional gradient\nmethods (aka Frank-Wolfe-type methods) provide scalable solutions by leveraging\nthe so-called linear minimization oracle instead of the projection onto the\nsemidefinite cone. Most problems in machine learning and modern engineering\napplications, however, contain some degree of stochasticity. In this work, we\npropose the first conditional-gradient-type method for solving stochastic\noptimization problems under affine constraints. Our method guarantees\n$\\mathcal{O}(k^{-1/3})$ convergence rate in expectation on the objective\nresidual and $\\mathcal{O}(k^{-5/12})$ on the feasibility gap.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 15:53:16 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 18:40:10 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 11:10:21 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Locatello", "Francesco", ""], ["Yurtsever", "Alp", ""], ["Fercoq", "Olivier", ""], ["Cevher", "Volkan", ""]]}, {"id": "1901.10405", "submitter": "Thomas Ringstrom", "authors": "Thomas J. Ringstrom, Paul R. Schrater", "title": "Constraint Satisfaction Propagation: Non-stationary Policy Synthesis for\n  Temporal Logic Planning", "comments": "Preprint. In progress. 10 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Problems arise when using reward functions to capture dependencies between\nsequential time-constrained goal states because the state-space must be\nprohibitively expanded to accommodate a history of successfully achieved\nsub-goals. Also, policies and value functions derived with stationarity\nassumptions are not readily decomposable, leading to a tension between reward\nmaximization and task generalization. We demonstrate a logic-compatible\napproach using model-based knowledge of environment dynamics and deadline\ninformation to directly infer non-stationary policies composed of reusable\nstationary policies. The policies are constructed to maximize the probability\nof satisfying time-sensitive goals while respecting time-varying obstacles. Our\napproach explicitly maintains two different spaces, a high-level logical task\nspecification where the task-variables are grounded onto the low-level\nstate-space of a Markov decision process. Computing satisfiability at the\ntask-level is made possible by a Bellman-like equation which operates on a\ntensor that links the temporal relationship between the two spaces; the\nequation solves for a value function that can be explicitly interpreted as the\nprobability of sub-goal satisfaction under the synthesized non-stationary\npolicy, an approach we term Constraint Satisfaction Propagation (CSP).\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 17:19:06 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 20:34:57 GMT"}, {"version": "v3", "created": "Mon, 11 Feb 2019 21:55:44 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Ringstrom", "Thomas J.", ""], ["Schrater", "Paul R.", ""]]}, {"id": "1901.10452", "submitter": "Ahsan Alvi", "authors": "Ahsan S. Alvi, Binxin Ru, Jan Calliess, Stephen J. Roberts, Michael A.\n  Osborne", "title": "Asynchronous Batch Bayesian Optimisation with Improved Local\n  Penalisation", "comments": "Camera-ready version after incorporating reviewers' suggestions", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Bayesian optimisation (BO) has been successfully applied to\nhyperparameter tuning using parallel computing, but it is wasteful of\nresources: workers that complete jobs ahead of others are left idle. We address\nthis problem by developing an approach, Penalising Locally for Asynchronous\nBayesian Optimisation on $k$ workers (PLAyBOOK), for asynchronous parallel BO.\nWe demonstrate empirically the efficacy of PLAyBOOK and its variants on\nsynthetic tasks and a real-world problem. We undertake a comparison between\nsynchronous and asynchronous BO, and show that asynchronous BO often\noutperforms synchronous batch BO in both wall-clock time and number of function\nevaluations.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 18:56:59 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 15:36:41 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 14:23:47 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Alvi", "Ahsan S.", ""], ["Ru", "Binxin", ""], ["Calliess", "Jan", ""], ["Roberts", "Stephen J.", ""], ["Osborne", "Michael A.", ""]]}, {"id": "1901.10464", "submitter": "Ahmed Elkelesh", "authors": "Ahmed Elkelesh, Moustafa Ebada, Sebastian Cammerer and Stephan ten\n  Brink", "title": "Decoder-tailored Polar Code Design Using the Genetic Algorithm", "comments": "This work has been submitted to the IEEE for possible publication.\n  Manuscript submitted September 20, 2018; revised January 28, 2019; date of\n  current version January 28, 2019. arXiv admin note: substantial text overlap\n  with arXiv:1901.06444", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for constructing polar codes (i.e., selecting the\nfrozen bit positions) for arbitrary channels, and tailored to a given decoding\nalgorithm, rather than based on the (not necessarily optimal) assumption of\nsuccessive cancellation (SC) decoding. The proposed framework is based on the\nGenetic Algorithm (GenAlg), where populations (i.e., collections) of\ninformation sets evolve successively via evolutionary transformations based on\ntheir individual error-rate performance. These populations converge towards an\ninformation set that fits both the decoding behavior and the defined channel.\nUsing our proposed algorithm over the additive white Gaussian noise (AWGN)\nchannel, we construct a polar code of length 2048 with code rate 0.5, without\nthe CRC-aid, tailored to plain successive cancellation list (SCL) decoding,\nachieving the same error-rate performance as the CRC-aided SCL decoding, and\nleading to a coding gain of 1 dB at BER of $10^{-6}$. Further, a belief\npropagation (BP)-tailored construction approaches the SCL error-rate\nperformance without any modifications in the decoding algorithm itself. The\nperformance gains can be attributed to the significant reduction in the total\nnumber of low-weight codewords. To demonstrate the flexibility, coding gains\nfor the Rayleigh channel are shown under SCL and BP decoding. Besides\nimprovements in error-rate performance, we show that, when required, the GenAlg\ncan be also set up to reduce the decoding complexity, e.g., the SCL list size\nor the number of BP iterations can be reduced, while maintaining the same\nerror-rate performance.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 22:10:40 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Elkelesh", "Ahmed", ""], ["Ebada", "Moustafa", ""], ["Cammerer", "Sebastian", ""], ["Brink", "Stephan ten", ""]]}, {"id": "1901.10500", "submitter": "Yunhao Tang", "authors": "Yunhao Tang, Shipra Agrawal", "title": "Discretizing Continuous Action Space for On-Policy Optimization", "comments": "Accepted at AAAI Conference on Artificial Intelligence (2020) in New\n  York, NY, USA. An open source implementation can be found at\n  https://github.com/robintyh1/onpolicybaselines", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we show that discretizing action space for continuous control\nis a simple yet powerful technique for on-policy optimization. The explosion in\nthe number of discrete actions can be efficiently addressed by a policy with\nfactorized distribution across action dimensions. We show that the discrete\npolicy achieves significant performance gains with state-of-the-art on-policy\noptimization algorithms (PPO, TRPO, ACKTR) especially on high-dimensional tasks\nwith complex dynamics. Additionally, we show that an ordinal parameterization\nof the discrete distribution can introduce the inductive bias that encodes the\nnatural ordering between discrete actions. This ordinal architecture further\nsignificantly improves the performance of PPO/TRPO.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 19:19:50 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 14:25:14 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2020 18:38:24 GMT"}, {"version": "v4", "created": "Thu, 19 Mar 2020 22:00:21 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Tang", "Yunhao", ""], ["Agrawal", "Shipra", ""]]}, {"id": "1901.10634", "submitter": "Baoxiang Wang", "authors": "Baoxiang Wang and Nidhi Hegde", "title": "Privacy-preserving Q-Learning with Functional Noise in Continuous State\n  Spaces", "comments": "Advances in Neural Information Processing Systems (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider differentially private algorithms for reinforcement learning in\ncontinuous spaces, such that neighboring reward functions are\nindistinguishable. This protects the reward information from being exploited by\nmethods such as inverse reinforcement learning. Existing studies that guarantee\ndifferential privacy are not extendable to infinite state spaces, as the noise\nlevel to ensure privacy will scale accordingly to infinity. Our aim is to\nprotect the value function approximator, without regard to the number of states\nqueried to the function. It is achieved by adding functional noise to the value\nfunction iteratively in the training. We show rigorous privacy guarantees by a\nseries of analyses on the kernel of the noise space, the probabilistic bound of\nsuch noise samples, and the composition over the iterations. We gain insight\ninto the utility analysis by proving the algorithm's approximate optimality\nwhen the state space is discrete. Experiments corroborate our theoretical\nfindings and show improvement over existing approaches.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 01:31:03 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 07:36:18 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 08:31:36 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Wang", "Baoxiang", ""], ["Hegde", "Nidhi", ""]]}, {"id": "1901.10653", "submitter": "Francisco Mena", "authors": "F. A. Mena (Universidad T\\'ecnica Federico Santa Mar\\'ia, Chile), R.\n  \\~Nanculef (Universidad T\\'ecnica Federico Santa Mar\\'ia, Chile)", "title": "Evaluating Bregman Divergences for Probability Learning from Crowd", "comments": "A report of results, 7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The crowdsourcing scenarios are a good example of having a probability\ndistribution over some categories showing what the people in a global\nperspective thinks. Learn a predictive model of this probability distribution\ncan be of much more valuable that learn only a discriminative model that gives\nthe most likely category of the data. Here we present differents models that\nadapts having probability distribution as target to train a machine learning\nmodel. We focus on the Bregman divergences framework to used as objective\nfunction to minimize. The results show that special care must be taken when\nbuild a objective function and consider a equal optimization on neural network\nin Keras framework.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 02:53:39 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Mena", "F. A.", "", "Universidad T\u00e9cnica Federico Santa Mar\u00eda, Chile"], ["\u00d1anculef", "R.", "", "Universidad T\u00e9cnica Federico Santa Mar\u00eda, Chile"]]}, {"id": "1901.10698", "submitter": "Hossein Esfandiari", "authors": "Hossein Esfandiari, MohammadTaghi Hajiaghayi, Brendan Lucier, Michael\n  Mitzenmacher", "title": "Online Pandora's Boxes and Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online variations of the Pandora's box problem (Weitzman. 1979),\na standard model for understanding issues related to the cost of acquiring\ninformation for decision-making. Our problem generalizes both the classic\nPandora's box problem and the prophet inequality framework. Boxes are presented\nonline, each with a random value and cost drew jointly from some known\ndistribution. Pandora chooses online whether to open each box given its cost,\nand then chooses irrevocably whether to keep the revealed prize or pass on it.\nWe aim for approximation algorithms against adversaries that can choose the\nlargest prize over any opened box, and use optimal offline policies to decide\nwhich boxes to open (without knowledge of the value inside). We consider\nvariations where Pandora can collect multiple prizes subject to feasibility\nconstraints, such as cardinality, matroid, or knapsack constraints. We also\nconsider variations related to classic multi-armed bandit problems from\nreinforcement learning. Our results use a reduction-based framework where we\nseparate the issues of the cost of acquiring information from the online\ndecision process of which prizes to keep. Our work shows that in many\nscenarios, Pandora can achieve a good approximation to the best possible\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 07:52:39 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Esfandiari", "Hossein", ""], ["Hajiaghayi", "MohammadTaghi", ""], ["Lucier", "Brendan", ""], ["Mitzenmacher", "Michael", ""]]}, {"id": "1901.10706", "submitter": "Harukazu Igarashi", "authors": "Harukazu Igarashi, Yuichi Morioka, Kazumasa Yamamoto", "title": "Learning Position Evaluation Functions Used in Monte Carlo Softmax\n  Search", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper makes two proposals for Monte Carlo Softmax Search, which is a\nrecently proposed method that is classified as a selective search like the\nMonte Carlo Tree Search. The first proposal separately defines the\nnode-selection and backup policies to allow researchers to freely design a\nnode-selection policy based on their searching strategies and confirms the\nprincipal variation produced by the Monte Carlo Softmax Search to that produced\nby a minimax search. The second proposal modifies commonly used learning\nmethods for positional evaluation functions. In our new proposals, evaluation\nfunctions are learned by Monte Carlo sampling, which is performed with the\nbackup policy in the search tree produced by Monte Carlo Softmax Search. The\nlearning methods under consideration include supervised learning, reinforcement\nlearning, regression learning, and search bootstrapping. Our sampling-based\nlearning not only uses current positions and principal variations but also the\ninternal nodes and important variations of a search tree. This step reduces the\nnumber of games necessary for learning. New learning rules are derived for\nsampling-based learning based on the Monte Carlo Softmax Search and\ncombinations of the modified learning methods are also proposed in this paper.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 08:21:34 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 01:19:29 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Igarashi", "Harukazu", ""], ["Morioka", "Yuichi", ""], ["Yamamoto", "Kazumasa", ""]]}, {"id": "1901.10723", "submitter": "Martha Lewis", "authors": "Martha Lewis", "title": "Compositionality for Recursive Neural Networks", "comments": "presented at NeSy2018, Thirteenth International Workshop on\n  Neural-Symbolic Learning and Reasoning, co-located with Human-Level AI 2018,\n  Prague, CZ, August 23-24, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling compositionality has been a longstanding area of research in the\nfield of vector space semantics. The categorical approach to compositionality\nmaps grammar onto vector spaces in a principled way, but comes under fire for\nrequiring the formation of very high-dimensional matrices and tensors, and\ntherefore being computationally infeasible. In this paper I show how a linear\nsimplification of recursive neural tensor network models can be mapped directly\nonto the categorical approach, giving a way of computing the required matrices\nand tensors. This mapping suggests a number of lines of research for both\ncategorical compositional vector space models of meaning and for recursive\nneural network models of compositionality.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 09:32:51 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Lewis", "Martha", ""]]}, {"id": "1901.10795", "submitter": "Mohammadreza Mousaei", "authors": "Heather Jones, Siri Maley, Kenji Yonekawa, Mohammadreza Mousaei, J.\n  David Yesso, David Kohanbash, William Whittaker", "title": "Automated Analysis, Reporting, and Archiving for Robotic Nondestructive\n  Assay of Holdup Deposits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To decommission deactivated gaseous diffusion enrichment facilities, miles of\ncontaminated pipe must be measured. The current method requires thousands of\nmanual measurements, repeated manual data transcription, and months of manual\nanalysis. The Pipe Crawling Activity Measurement System (PCAMS), developed by\nCarnegie Mellon University and in commissioning for use at the DOE Portsmouth\nGaseous Diffusion Enrichment Facility, uses a robot to measure Uranium-235 from\ninside pipes and automatically log the data. Radiation measurements, as well as\nimagery, geometric modeling, and precise measurement positioning data are\ndigitally transferred to the PCAMS server. On the server, data can be\nautomatically processed in minutes and summarized for analyst review.\nMeasurement reports are auto-generated with the push of a button. A database\nspecially-configured to hold heterogeneous data such as spectra, images, and\nrobot trajectories serves as archive. This paper outlines the features and\ndesign of the PCAMS Post-Processing Software, currently in commissioning for\nuse at the Portsmouth Gaseous Diffusion Enrichment Facility. The analysis\nprocess, the analyst interface to the system, and the content of auto-generated\nreports are each described. Example pipe-interior geometric surface models,\nillustration of how key report features apply in operational runs, and user\nfeedback are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 15:46:24 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Jones", "Heather", ""], ["Maley", "Siri", ""], ["Yonekawa", "Kenji", ""], ["Mousaei", "Mohammadreza", ""], ["Yesso", "J. David", ""], ["Kohanbash", "David", ""], ["Whittaker", "William", ""]]}, {"id": "1901.10799", "submitter": "Sebastian Mathias Keller", "authors": "Sebastian Mathias Keller, Maxim Samarin, Mario Wieser, Volker Roth", "title": "Deep Archetypal Analysis", "comments": "Published at the German Conference on Pattern Recognition 2019 (GCPR)", "journal-ref": "41th German Conference on Pattern Recognition, GCPR 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Deep Archetypal Analysis\" generates latent representations of\nhigh-dimensional datasets in terms of fractions of intuitively understandable\nbasic entities called archetypes. The proposed method is an extension of linear\n\"Archetypal Analysis\" (AA), an unsupervised method to represent multivariate\ndata points as sparse convex combinations of extremal elements of the dataset.\nUnlike the original formulation of AA, \"Deep AA\" can also handle side\ninformation and provides the ability for data-driven representation learning\nwhich reduces the dependence on expert knowledge. Our method is motivated by\nstudies of evolutionary trade-offs in biology where archetypes are species\nhighly adapted to a single task. Along these lines, we demonstrate that \"Deep\nAA\" also lends itself to the supervised exploration of chemical space, marking\na distinct starting point for de novo molecular design. In the unsupervised\nsetting we show how \"Deep AA\" is used on CelebA to identify archetypal faces.\nThese can then be superimposed in order to generate new faces which inherit\ndominant traits of the archetypes they are based on.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 13:04:53 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 16:37:27 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Keller", "Sebastian Mathias", ""], ["Samarin", "Maxim", ""], ["Wieser", "Mario", ""], ["Roth", "Volker", ""]]}, {"id": "1901.10802", "submitter": "Md Ashraful Alam Milton", "authors": "Md Ashraful Alam Milton", "title": "Automated Skin Lesion Classification Using Ensemble of Deep Neural\n  Networks in ISIC 2018: Skin Lesion Analysis Towards Melanoma Detection\n  Challenge", "comments": "ISIC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we studied extensively on different deep learning based\nmethods to detect melanoma and skin lesion cancers. Melanoma, a form of\nmalignant skin cancer is very threatening to health. Proper diagnosis of\nmelanoma at an earlier stage is crucial for the success rate of complete cure.\nDermoscopic images with Benign and malignant forms of skin cancer can be\nanalyzed by computer vision system to streamline the process of skin cancer\ndetection. In this study, we experimented with various neural networks which\nemploy recent deep learning based models like PNASNet-5-Large,\nInceptionResNetV2, SENet154, InceptionV4. Dermoscopic images are properly\nprocessed and augmented before feeding them into the network. We tested our\nmethods on International Skin Imaging Collaboration (ISIC) 2018 challenge\ndataset. Our system has achieved best validation score of 0.76 for\nPNASNet-5-Large model. Further improvement and optimization of the proposed\nmethods with a bigger training dataset and carefully chosen hyper-parameter\ncould improve the performances. The code available for download at\nhttps://github.com/miltonbd/ISIC_2018_classification\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 13:10:11 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Milton", "Md Ashraful Alam", ""]]}, {"id": "1901.10837", "submitter": "Ziyuan Zhong", "authors": "Alexandre Louis Lamy, Ziyuan Zhong, Aditya Krishna Menon, Nakul Verma", "title": "Noise-tolerant fair classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness-aware learning involves designing algorithms that do not\ndiscriminate with respect to some sensitive feature (e.g., race or gender).\nExisting work on the problem operates under the assumption that the sensitive\nfeature available in one's training sample is perfectly reliable. This\nassumption may be violated in many real-world cases: for example, respondents\nto a survey may choose to conceal or obfuscate their group identity out of fear\nof potential discrimination. This poses the question of whether one can still\nlearn fair classifiers given noisy sensitive features. In this paper, we answer\nthe question in the affirmative: we show that if one measures fairness using\nthe mean-difference score, and sensitive features are subject to noise from the\nmutually contaminated learning model, then owing to a simple identity we only\nneed to change the desired fairness-tolerance. The requisite tolerance can be\nestimated by leveraging existing noise-rate estimators from the label noise\nliterature. We finally show that our procedure is empirically effective on two\ncase-studies involving sensitive feature censoring.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 14:11:05 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 18:08:36 GMT"}, {"version": "v3", "created": "Tue, 10 Dec 2019 07:07:43 GMT"}, {"version": "v4", "created": "Thu, 9 Jan 2020 14:44:05 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Lamy", "Alexandre Louis", ""], ["Zhong", "Ziyuan", ""], ["Menon", "Aditya Krishna", ""], ["Verma", "Nakul", ""]]}, {"id": "1901.10915", "submitter": "Dmytro Mishkin", "authors": "Dmytro Mishkin, Alexey Dosovitskiy and Vladlen Koltun", "title": "Benchmarking Classic and Learned Navigation in Complex 3D Environments", "comments": "Added CNN-Monodepth and OpenCV Stereo agents", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Navigation research is attracting renewed interest with the advent of\nlearning-based methods. However, this new line of work is largely disconnected\nfrom well-established classic navigation approaches. In this paper, we take a\nstep towards coordinating these two directions of research. We set up classic\nand learning-based navigation systems in common simulated environments and\nthoroughly evaluate them in indoor spaces of varying complexity, with access to\ndifferent sensory modalities. Additionally, we measure human performance in the\nsame environments. We find that a classic pipeline, when properly tuned, can\nperform very well in complex cluttered environments. On the other hand, learned\nsystems can operate more robustly with a limited sensor suite. Overall, both\napproaches are still far from human-level performance.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 15:50:54 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 11:58:29 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Mishkin", "Dmytro", ""], ["Dosovitskiy", "Alexey", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1901.10964", "submitter": "Andr\\'e Barreto", "authors": "Andr\\'e Barreto, Diana Borsa, John Quan, Tom Schaul, David Silver,\n  Matteo Hessel, Daniel Mankowitz, Augustin \\v{Z}\\'idek, R\\'emi Munos", "title": "Transfer in Deep Reinforcement Learning Using Successor Features and\n  Generalised Policy Improvement", "comments": "Published at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to transfer skills across tasks has the potential to scale up\nreinforcement learning (RL) agents to environments currently out of reach.\nRecently, a framework based on two ideas, successor features (SFs) and\ngeneralised policy improvement (GPI), has been introduced as a principled way\nof transferring skills. In this paper we extend the SFs & GPI framework in two\nways. One of the basic assumptions underlying the original formulation of SFs &\nGPI is that rewards for all tasks of interest can be computed as linear\ncombinations of a fixed set of features. We relax this constraint and show that\nthe theoretical guarantees supporting the framework can be extended to any set\nof tasks that only differ in the reward function. Our second contribution is to\nshow that one can use the reward functions themselves as features for future\ntasks, without any loss of expressiveness, thus removing the need to specify a\nset of features beforehand. This makes it possible to combine SFs & GPI with\ndeep learning in a more stable way. We empirically verify this claim on a\ncomplex 3D environment where observations are images from a first-person\nperspective. We show that the transfer promoted by SFs & GPI leads to very good\npolicies on unseen tasks almost instantaneously. We also describe how to learn\npolicies specialised to the new tasks in a way that allows them to be added to\nthe agent's set of skills, and thus be reused in the future.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 17:30:31 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Barreto", "Andr\u00e9", ""], ["Borsa", "Diana", ""], ["Quan", "John", ""], ["Schaul", "Tom", ""], ["Silver", "David", ""], ["Hessel", "Matteo", ""], ["Mankowitz", "Daniel", ""], ["\u017d\u00eddek", "Augustin", ""], ["Munos", "R\u00e9mi", ""]]}, {"id": "1901.10968", "submitter": "Alexandre Coninx", "authors": "L\\'eni K. Le Goff, Ghanim Mukhtar, Alexandre Coninx and St\\'ephane\n  Doncieux", "title": "Bootstrapping Robotic Ecological Perception from a Limited Set of\n  Hypotheses Through Interactive Perception", "comments": "21 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To solve its task, a robot needs to have the ability to interpret its\nperceptions. In vision, this interpretation is particularly difficult and\nrelies on the understanding of the structure of the scene, at least to the\nextent of its task and sensorimotor abilities. A robot with the ability to\nbuild and adapt this interpretation process according to its own tasks and\ncapabilities would push away the limits of what robots can achieve in a non\ncontrolled environment. A solution is to provide the robot with processes to\nbuild such representations that are not specific to an environment or a\nsituation. A lot of works focus on objects segmentation, recognition and\nmanipulation. Defining an object solely on the basis of its visual appearance\nis challenging given the wide range of possible objects and environments.\nTherefore, current works make simplifying assumptions about the structure of a\nscene. Such assumptions reduce the adaptivity of the object extraction process\nto the environments in which the assumption holds. To limit such assumptions,\nwe introduce an exploration method aimed at identifying moveable elements in a\nscene without considering the concept of object. By using the interactive\nperception framework, we aim at bootstrapping the acquisition process of a\nrepresentation of the environment with a minimum of context specific\nassumptions. The robotic system builds a perceptual map called relevance map\nwhich indicates the moveable parts of the current scene. A classifier is\ntrained online to predict the category of each region (moveable or\nnon-moveable). It is also used to select a region with which to interact, with\nthe goal of minimizing the uncertainty of the classification. A specific\nclassifier is introduced to fit these needs: the collaborative mixture models\nclassifier. The method is tested on a set of scenarios of increasing\ncomplexity, using both simulations and a PR2 robot.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 17:35:42 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Goff", "L\u00e9ni K. Le", ""], ["Mukhtar", "Ghanim", ""], ["Coninx", "Alexandre", ""], ["Doncieux", "St\u00e9phane", ""]]}, {"id": "1901.10995", "submitter": "Adrien Ecoffet", "authors": "Adrien Ecoffet, Joost Huizinga, Joel Lehman, Kenneth O. Stanley, Jeff\n  Clune", "title": "Go-Explore: a New Approach for Hard-Exploration Problems", "comments": "37 pages, 14 figures; added references to Goyal et al. and Oh et al.,\n  updated reference to Colas et al; updated author emails; point readers to\n  updated paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A grand challenge in reinforcement learning is intelligent exploration,\nespecially when rewards are sparse or deceptive. Two Atari games serve as\nbenchmarks for such hard-exploration domains: Montezuma's Revenge and Pitfall.\nOn both games, current RL algorithms perform poorly, even those with intrinsic\nmotivation, which is the dominant method to improve performance on\nhard-exploration domains. To address this shortfall, we introduce a new\nalgorithm called Go-Explore. It exploits the following principles: (1) remember\npreviously visited states, (2) first return to a promising state (without\nexploration), then explore from it, and (3) solve simulated environments\nthrough any available means (including by introducing determinism), then\nrobustify via imitation learning. The combined effect of these principles is a\ndramatic performance improvement on hard-exploration problems. On Montezuma's\nRevenge, Go-Explore scores a mean of over 43k points, almost 4 times the\nprevious state of the art. Go-Explore can also harness human-provided domain\nknowledge and, when augmented with it, scores a mean of over 650k points on\nMontezuma's Revenge. Its max performance of nearly 18 million surpasses the\nhuman world record, meeting even the strictest definition of \"superhuman\"\nperformance. On Pitfall, Go-Explore with domain knowledge is the first\nalgorithm to score above zero. Its mean score of almost 60k points exceeds\nexpert human performance. Because Go-Explore produces high-performing\ndemonstrations automatically and cheaply, it also outperforms imitation\nlearning work where humans provide solution demonstrations. Go-Explore opens up\nmany new research directions into improving it and weaving its insights into\ncurrent RL algorithms. It may also enable progress on previously unsolvable\nhard-exploration problems in many domains, especially those that harness a\nsimulator during training (e.g. robotics).\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 18:40:37 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 19:16:49 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 02:10:07 GMT"}, {"version": "v4", "created": "Fri, 26 Feb 2021 21:21:11 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Ecoffet", "Adrien", ""], ["Huizinga", "Joost", ""], ["Lehman", "Joel", ""], ["Stanley", "Kenneth O.", ""], ["Clune", "Jeff", ""]]}, {"id": "1901.11168", "submitter": "Anahita Hosseini", "authors": "Anahita Hosseini, Majid Sarrafzadeh", "title": "Unsupervised Prediction of Negative Health Events Ahead of Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of continuous health monitoring and the availability of an\nenormous amount of time series data has provided a great opportunity for the\nadvancement of personal health tracking. In recent years, unsupervised learning\nmethods have drawn special attention of researchers to tackle the sparse\nannotation of health data and real-time detection of anomalies has been a\ncentral problem of interest. However, one problem that has not been well\naddressed before is the early prediction of forthcoming negative health events.\nEarly signs of an event can introduce subtle and gradual changes in the health\nsignal prior to its onset, detection of which can be invaluable in effective\nprevention. In this study, we first demonstrate our observations on the\nshortcoming of widely adopted anomaly detection methods in uncovering the\nchanges prior to a negative health event. We then propose a framework which\nrelies on online clustering of signal segment representations which are\nautomatically learned by a specially designed LSTM auto-encoder. We show the\neffectiveness of our approach by predicting Bradycardia events in infants using\nMIT-PICS dataset 1.3 minutes ahead of time with 68\\% AUC score on average,\nusing no label supervision. Results of our study can indicate the viability of\nour approach in the early detection of health events in other applications as\nwell.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 01:46:52 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Hosseini", "Anahita", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1901.11184", "submitter": "Mark Riedl", "authors": "Mark O. Riedl", "title": "Human-Centered Artificial Intelligence and Machine Learning", "comments": "Human Behavior and Emerging Technologies, volume 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are increasingly coming into contact with artificial intelligence and\nmachine learning systems. Human-centered artificial intelligence is a\nperspective on AI and ML that algorithms must be designed with awareness that\nthey are part of a larger system consisting of humans. We lay forth an argument\nthat human-centered artificial intelligence can be broken down into two\naspects: (1) AI systems that understand humans from a sociocultural\nperspective, and (2) AI systems that help humans understand them. We further\nargue that issues of social responsibility such as fairness, accountability,\ninterpretability, and transparency.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 02:47:16 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Riedl", "Mark O.", ""]]}, {"id": "1901.11333", "submitter": "Zhijing Jin", "authors": "Zhijing Jin, Di Jin, Jonas Mueller, Nicholas Matthews, Enrico Santus", "title": "IMaT: Unsupervised Text Attribute Transfer via Iterative Matching and\n  Translation", "comments": "EMNLP 2019 (Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Text attribute transfer aims to automatically rewrite sentences such that\nthey possess certain linguistic attributes, while simultaneously preserving\ntheir semantic content. This task remains challenging due to a lack of\nsupervised parallel data. Existing approaches try to explicitly disentangle\ncontent and attribute information, but this is difficult and often results in\npoor content-preservation and ungrammaticality. In contrast, we propose a\nsimpler approach, Iterative Matching and Translation (IMaT), which: (1)\nconstructs a pseudo-parallel corpus by aligning a subset of semantically\nsimilar sentences from the source and the target corpora; (2) applies a\nstandard sequence-to-sequence model to learn the attribute transfer; (3)\niteratively improves the learned transfer function by refining imperfections in\nthe alignment. In sentiment modification and formality transfer tasks, our\nmethod outperforms complex state-of-the-art systems by a large margin. As an\nauxiliary contribution, we produce a publicly-available test set with\nhuman-generated transfer references.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 12:41:57 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2019 05:53:24 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 05:18:44 GMT"}, {"version": "v4", "created": "Fri, 24 Jan 2020 05:12:45 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Jin", "Zhijing", ""], ["Jin", "Di", ""], ["Mueller", "Jonas", ""], ["Matthews", "Nicholas", ""], ["Santus", "Enrico", ""]]}, {"id": "1901.11344", "submitter": "Ya Li", "authors": "Ya Li, Xinyu Liu, Dan Liu, Xueqiang Zhang, Junhua Liu", "title": "Learning Efficient Lexically-Constrained Neural Machine Translation with\n  External Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years has witnessed dramatic progress of neural machine translation\n(NMT), however, the method of manually guiding the translation procedure\nremains to be better explored. Previous works proposed to handle such problem\nthrough lexcially-constrained beam search in the decoding phase. Unfortunately,\nthese lexically-constrained beam search methods suffer two fatal disadvantages:\nhigh computational complexity and hard beam search which generates unexpected\ntranslations. In this paper, we propose to learn the ability of\nlexically-constrained translation with external memory, which can overcome the\nabove mentioned disadvantages. For the training process, automatically\nextracted phrase pairs are extracted from alignment and sentence parsing, then\nfurther be encoded into an external memory. This memory is then used to provide\nlexically-constrained information for training through a memory-attention\nmachanism. Various experiments are conducted on WMT Chinese to English and\nEnglish to German tasks. All the results can demonstrate the effectiveness of\nour method.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 13:26:28 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Li", "Ya", ""], ["Liu", "Xinyu", ""], ["Liu", "Dan", ""], ["Zhang", "Xueqiang", ""], ["Liu", "Junhua", ""]]}, {"id": "1901.11398", "submitter": "Zahra Sadeghi", "authors": "Zahra Sadeghi", "title": "Visual Categorization of Objects into Animal and Plant Classes Using\n  Global Shape Descriptors", "comments": "10 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How humans can distinguish between general categories of objects? Are the\nsubcategories of living things visually distinctive? In a number of\nsemantic-category deficits, patients are good at making broad categorization\nbut are unable to remember fine and specific details. It has been well accepted\nthat general information about concepts are more robust to damages related to\nsemantic memory. Results from patients with semantic memory disorders\ndemonstrate the loss of ability in subcategory recognition. While bottom-up\nfeature construction has been studied in detail, little attention has been\nserved to top-down approach and the type of features that could account for\ngeneral categorization. In this paper, we show that broad categories of animal\nand plant are visually distinguishable without processing textural information.\nTo this aim, we utilize shape descriptors with an additional phase of feature\nlearning. The results are evaluated with both supervised and unsupervised\nlearning mechanisms. The obtained results demonstrate that global encoding of\nvisual appearance of objects accounts for high discrimination between animal\nand plant object categories.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 23:57:36 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Sadeghi", "Zahra", ""]]}, {"id": "1901.11437", "submitter": "Lucas Lehnert", "authors": "Lucas Lehnert and Michael L. Littman", "title": "Successor Features Combine Elements of Model-Free and Model-based\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key question in reinforcement learning is how an intelligent agent can\ngeneralize knowledge across different inputs. By generalizing across different\ninputs, information learned for one input can be immediately reused for\nimproving predictions for another input. Reusing information allows an agent to\ncompute an optimal decision-making strategy using less data. State\nrepresentation is a key element of the generalization process, compressing a\nhigh-dimensional input space into a low-dimensional latent state space. This\narticle analyzes properties of different latent state spaces, leading to new\nconnections between model-based and model-free reinforcement learning.\nSuccessor features, which predict frequencies of future observations, form a\nlink between model-based and model-free learning: Learning to predict future\nexpected reward outcomes, a key characteristic of model-based agents, is\nequivalent to learning successor features. Learning successor features is a\nform of temporal difference learning and is equivalent to learning to predict a\nsingle policy's utility, which is a characteristic of model-free agents.\nDrawing on the connection between model-based reinforcement learning and\nsuccessor features, we demonstrate that representations that are predictive of\nfuture reward outcomes generalize across variations in both transitions and\nrewards. This result extends previous work on successor features, which is\nconstrained to fixed transitions and assumes re-learning of the transferred\nstate representation.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 15:52:16 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 00:51:48 GMT"}, {"version": "v3", "created": "Sun, 4 Oct 2020 19:48:05 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Lehnert", "Lucas", ""], ["Littman", "Michael L.", ""]]}, {"id": "1901.11459", "submitter": "Fabrizio Sebastiani", "authors": "Andrea Esuli, Alejandro Moreo, Fabrizio Sebastiani", "title": "Funnelling: A New Ensemble Method for Heterogeneous Transfer Learning\n  and its Application to Cross-Lingual Text Classification", "comments": "28 pages, 4 figures", "journal-ref": "Forthcoming in the ACM Transactions on Information Systems, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual Text Classification (CLC) consists of automatically\nclassifying, according to a common set C of classes, documents each written in\none of a set of languages L, and doing so more accurately than when naively\nclassifying each document via its corresponding language-specific classifier.\nIn order to obtain an increase in the classification accuracy for a given\nlanguage, the system thus needs to also leverage the training examples written\nin the other languages. We tackle multilabel CLC via funnelling, a new ensemble\nlearning method that we propose here. Funnelling consists of generating a\ntwo-tier classification system where all documents, irrespectively of language,\nare classified by the same (2nd-tier) classifier. For this classifier all\ndocuments are represented in a common, language-independent feature space\nconsisting of the posterior probabilities generated by 1st-tier,\nlanguage-dependent classifiers. This allows the classification of all test\ndocuments, of any language, to benefit from the information present in all\ntraining documents, of any language. We present substantial experiments, run on\npublicly available multilingual text collections, in which funnelling is shown\nto significantly outperform a number of state-of-the-art baselines. All code\nand datasets (in vector form) are made publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 16:32:08 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 16:06:09 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Esuli", "Andrea", ""], ["Moreo", "Alejandro", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "1901.11462", "submitter": "Gerasimos Spanakis", "authors": "Raffaele Piccini, Gerasimos Spanakis", "title": "Exploring the context of recurrent neural network based conversational\n  agents", "comments": "Accepted at ICAART 2019, 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents have begun to rise both in the academic (in terms of\nresearch) and commercial (in terms of applications) world. This paper\ninvestigates the task of building a non-goal driven conversational agent, using\nneural network generative models and analyzes how the conversation context is\nhandled. It compares a simpler Encoder-Decoder with a Hierarchical Recurrent\nEncoder-Decoder architecture, which includes an additional module to model the\ncontext of the conversation using previous utterances information. We found\nthat the hierarchical model was able to extract relevant context information\nand include them in the generation of the output. However, it performed worse\n(35-40%) than the simple Encoder-Decoder model regarding both grammatically\ncorrect output and meaningful response. Despite these results, experiments\ndemonstrate how conversations about similar topics appear close to each other\nin the context space due to the increased frequency of specific topic-related\nwords, thus leaving promising directions for future research and how the\ncontext of a conversation can be exploited.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 16:40:26 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Piccini", "Raffaele", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "1901.11467", "submitter": "Gerasimos Spanakis", "authors": "Wouter Leeftink, Gerasimos Spanakis", "title": "Towards Controlled Transformation of Sentiment in Sentences", "comments": "Accepted at ICAART 2019, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An obstacle to the development of many natural language processing products\nis the vast amount of training examples necessary to get satisfactory results.\nThe generation of these examples is often a tedious and time-consuming task.\nThis paper this paper proposes a method to transform the sentiment of sentences\nin order to limit the work necessary to generate more training data. This means\nthat one sentence can be transformed to an opposite sentiment sentence and\nshould reduce by half the work required in the generation of text. The proposed\npipeline consists of a sentiment classifier with an attention mechanism to\nhighlight the short phrases that determine the sentiment of a sentence. Then,\nthese phrases are changed to phrases of the opposite sentiment using a baseline\nmodel and an autoencoder approach. Experiments are run on both the separate\nparts of the pipeline as well as on the end-to-end model. The sentiment\nclassifier is tested on its accuracy and is found to perform adequately. The\nautoencoder is tested on how well it is able to change the sentiment of an\nencoded phrase and it was found that such a task is possible. We use human\nevaluation to judge the performance of the full (end-to-end) pipeline and that\nreveals that a model using word vectors outperforms the encoder model.\nNumerical evaluation shows that a success rate of 54.7% is achieved on the\nsentiment change.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 16:51:49 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Leeftink", "Wouter", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "1901.11477", "submitter": "Amarnath R", "authors": "Amarnath R and P Nagabhushan", "title": "Text line Segmentation in Compressed Representation of Handwritten\n  Document using Tunneling Algorithm", "comments": "Compressed Representation, Handwritten Document Image, Text-Line\n  Terminal Point, Text-Line Segmentation, Search Space, Grid", "journal-ref": "International Journal of Intelligent Systems and Applications in\n  Engineering, Vol 6, No 4 (2018)", "doi": "10.18201/ijisae.2018448451", "report-no": null, "categories": "cs.CV cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research work, we perform text line segmentation directly in\ncompressed representation of an unconstrained handwritten document image. In\nthis relation, we make use of text line terminal points which is the current\nstate-of-the-art. The terminal points spotted along both margins (left and\nright) of a document image for every text line are considered as source and\ntarget respectively. The tunneling algorithm uses a single agent (or robot) to\nidentify the coordinate positions in the compressed representation to perform\ntext-line segmentation of the document. The agent starts at a source point and\nprogressively tunnels a path routing in between two adjacent text lines and\nreaches the probable target. The agent's navigation path from source to the\ntarget bypassing obstacles, if any, results in segregating the two adjacent\ntext lines. However, the target point would be known only when the agent\nreaches the destination; this is applicable for all source points and\nhenceforth we could analyze the correspondence between source and target nodes.\nArtificial Intelligence in Expert systems, dynamic programming and greedy\nstrategies are employed for every search space while tunneling. An exhaustive\nexperimentation is carried out on various benchmark datasets including ICDAR13\nand the performances are reported.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 05:19:38 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["R", "Amarnath", ""], ["Nagabhushan", "P", ""]]}, {"id": "1901.11478", "submitter": "Francesco Foglino", "authors": "Francesco Foglino, Christiano Coletto Christakou, Matteo Leonetti", "title": "An Optimization Framework for Task Sequencing in Curriculum Learning", "comments": "Proceedings of 9th Joint IEEE International Conference on Development\n  and Learning and on Epigenetic Robotics (ICDL-EpiRob)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curriculum learning in reinforcement learning is used to shape exploration by\npresenting the agent with increasingly complex tasks. The idea of curriculum\nlearning has been largely applied in both animal training and pedagogy. In\nreinforcement learning, all previous task sequencing methods have shaped\nexploration with the objective of reducing the time to reach a given\nperformance level. We propose novel uses of curriculum learning, which arise\nfrom choosing different objective functions. Furthermore, we define a general\noptimization framework for task sequencing and evaluate the performance of\npopular metaheuristic search methods on several tasks. We show that curriculum\nlearning can be successfully used to: improve the initial performance, take\nfewer suboptimal actions during exploration, and discover better policies.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 17:08:27 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 13:50:49 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 14:56:44 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Foglino", "Francesco", ""], ["Christakou", "Christiano Coletto", ""], ["Leonetti", "Matteo", ""]]}, {"id": "1901.11494", "submitter": "Quanshi Zhang", "authors": "Xianglei Xing, Song-Chun Zhu, Ying Nian Wu", "title": "Inducing Sparse Coding and And-Or Grammar from Generator Network", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an explainable generative model by applying sparse operation on\nthe feature maps of the generator network. Meaningful hierarchical\nrepresentations are obtained using the proposed generative model with sparse\nactivations. The convolutional kernels from the bottom layer to the top layer\nof the generator network can learn primitives such as edges and colors, object\nparts, and whole objects layer by layer. From the perspective of the generator\nnetwork, we propose a method for inducing both sparse coding and the AND-OR\ngrammar for images. Experiments show that our method is capable of learning\nmeaningful and explainable hierarchical representations.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:47:18 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Xing", "Xianglei", ""], ["Zhu", "Song-Chun", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1901.11503", "submitter": "Anirudh Vemula", "authors": "Anirudh Vemula, Wen Sun, J. Andrew Bagnell", "title": "Contrasting Exploration in Parameter and Action Space: A Zeroth-Order\n  Optimization Perspective", "comments": "Accepted at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box optimizers that explore in parameter space have often been shown to\noutperform more sophisticated action space exploration methods developed\nspecifically for the reinforcement learning problem. We examine these black-box\nmethods closely to identify situations in which they are worse than action\nspace exploration methods and those in which they are superior. Through simple\ntheoretical analyses, we prove that complexity of exploration in parameter\nspace depends on the dimensionality of parameter space, while complexity of\nexploration in action space depends on both the dimensionality of action space\nand horizon length. This is also demonstrated empirically by comparing simple\nexploration methods on several model problems, including Contextual Bandit,\nLinear Regression and Reinforcement Learning in continuous control.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 18:05:05 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Vemula", "Anirudh", ""], ["Sun", "Wen", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "1901.11515", "submitter": "Willie Neiswanger", "authors": "Willie Neiswanger, Kirthevasan Kandasamy, Barnabas Poczos, Jeff\n  Schneider, Eric Xing", "title": "ProBO: Versatile Bayesian Optimization Using Any Probabilistic\n  Programming Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing an expensive-to-query function is a common task in science and\nengineering, where it is beneficial to keep the number of queries to a minimum.\nA popular strategy is Bayesian optimization (BO), which leverages probabilistic\nmodels for this task. Most BO today uses Gaussian processes (GPs), or a few\nother surrogate models. However, there is a broad set of Bayesian modeling\ntechniques that could be used to capture complex systems and reduce the number\nof queries in BO. Probabilistic programming languages (PPLs) are modern tools\nthat allow for flexible model definition, prior specification, model\ncomposition, and automatic inference. In this paper, we develop ProBO, a BO\nprocedure that uses only standard operations common to most PPLs. This allows a\nuser to drop in a model built with an arbitrary PPL and use it directly in BO.\nWe describe acquisition functions for ProBO, and strategies for efficiently\noptimizing these functions given complex models or costly inference procedures.\nUsing existing PPLs, we implement new models to aid in a few challenging\noptimization settings, and demonstrate these on model hyperparameter and\narchitecture search tasks.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 18:35:56 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 17:49:10 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Neiswanger", "Willie", ""], ["Kandasamy", "Kirthevasan", ""], ["Poczos", "Barnabas", ""], ["Schneider", "Jeff", ""], ["Xing", "Eric", ""]]}, {"id": "1901.11524", "submitter": "Robert Dadashi", "authors": "Robert Dadashi, Adrien Ali Ta\\\"iga, Nicolas Le Roux, Dale Schuurmans,\n  Marc G. Bellemare", "title": "The Value Function Polytope in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish geometric and topological properties of the space of value\nfunctions in finite state-action Markov decision processes. Our main\ncontribution is the characterization of the nature of its shape: a general\npolytope (Aigner et al., 2010). To demonstrate this result, we exhibit several\nproperties of the structural relationship between policies and value functions\nincluding the line theorem, which shows that the value functions of policies\nconstrained on all but one state describe a line segment. Finally, we use this\nnovel perspective to introduce visualizations to enhance the understanding of\nthe dynamics of reinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 18:45:04 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 17:47:59 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 18:22:34 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Dadashi", "Robert", ""], ["Ta\u00efga", "Adrien Ali", ""], ["Roux", "Nicolas Le", ""], ["Schuurmans", "Dale", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "1901.11528", "submitter": "Kory W Mathewson", "authors": "Kory W. Mathewson, Pablo Samuel Castro, Colin Cherry, George Foster,\n  Marc G. Bellemare", "title": "Shaping the Narrative Arc: An Information-Theoretic Approach to\n  Collaborative Dialogue", "comments": "20 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider the problem of designing an artificial agent capable of\ninteracting with humans in collaborative dialogue to produce creative, engaging\nnarratives. In this task, the goal is to establish universe details, and to\ncollaborate on an interesting story in that universe, through a series of\nnatural dialogue exchanges. Our model can augment any probabilistic\nconversational agent by allowing it to reason about universe information\nestablished and what potential next utterances might reveal. Ideally, with each\nutterance, agents would reveal just enough information to add specificity and\nreduce ambiguity without limiting the conversation. We empirically show that\nour model allows control over the rate at which the agent reveals information\nand that doing so significantly improves accuracy in predicting the next line\nof dialogues from movies. We close with a case-study with four professional\ntheatre performers, who preferred interactions with our model-augmented agent\nover an unaugmented agent.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 18:48:19 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Mathewson", "Kory W.", ""], ["Castro", "Pablo Samuel", ""], ["Cherry", "Colin", ""], ["Foster", "George", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "1901.11529", "submitter": "Himanshu Sahni", "authors": "Himanshu Sahni, Toby Buckley, Pieter Abbeel, Ilya Kuzovkin", "title": "Addressing Sample Complexity in Visual Tasks Using HER and Hallucinatory\n  GANs", "comments": "To appear in Neural Information Processing Systems (NeurIPS 2019),\n  Vancouver, Canada. Code available at\n  https://github.com/offworld-projects/research-halgan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) algorithms typically require millions of\nenvironment interactions to learn successful policies in sparse reward\nsettings. Hindsight Experience Replay (HER) was introduced as a technique to\nincrease sample efficiency by reimagining unsuccessful trajectories as\nsuccessful ones by altering the originally intended goals. However, it cannot\nbe directly applied to visual environments where goal states are often\ncharacterized by the presence of distinct visual features. In this work, we\nshow how visual trajectories can be hallucinated to appear successful by\naltering agent observations using a generative model trained on relatively few\nsnapshots of the goal. We then use this model in combination with HER to train\nRL agents in visual settings. We validate our approach on 3D navigation tasks\nand a simulated robotics application and show marked improvement over baselines\nderived from previous work.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 18:50:44 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 02:23:49 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Sahni", "Himanshu", ""], ["Buckley", "Toby", ""], ["Abbeel", "Pieter", ""], ["Kuzovkin", "Ilya", ""]]}, {"id": "1901.11530", "submitter": "Marc G. Bellemare", "authors": "Marc G. Bellemare, Will Dabney, Robert Dadashi, Adrien Ali Taiga,\n  Pablo Samuel Castro, Nicolas Le Roux, Dale Schuurmans, Tor Lattimore, Clare\n  Lyle", "title": "A Geometric Perspective on Optimal Representations for Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new perspective on representation learning in reinforcement\nlearning based on geometric properties of the space of value functions. We\nleverage this perspective to provide formal evidence regarding the usefulness\nof value functions as auxiliary tasks. Our formulation considers adapting the\nrepresentation to minimize the (linear) approximation of the value function of\nall stationary policies for a given environment. We show that this optimization\nreduces to making accurate predictions regarding a special class of value\nfunctions which we call adversarial value functions (AVFs). We demonstrate that\nusing value functions as auxiliary tasks corresponds to an expected-error\nrelaxation of our formulation, with AVFs a natural candidate, and identify a\nclose relationship with proto-value functions (Mahadevan, 2005). We highlight\ncharacteristics of AVFs and their usefulness as auxiliary tasks in a series of\nexperiments on the four-room domain.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 18:52:40 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 00:35:07 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Bellemare", "Marc G.", ""], ["Dabney", "Will", ""], ["Dadashi", "Robert", ""], ["Taiga", "Adrien Ali", ""], ["Castro", "Pablo Samuel", ""], ["Roux", "Nicolas Le", ""], ["Schuurmans", "Dale", ""], ["Lattimore", "Tor", ""], ["Lyle", "Clare", ""]]}]