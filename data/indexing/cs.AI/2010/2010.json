[{"id": "2010.00003", "submitter": "Edgar Rios PhD", "authors": "Edgar A. Rios Piedra, Morteza Mardani, Frank Ong, Ukash Nakarmi,\n  Joseph Y. Cheng, Shreyas Vasanawala", "title": "Spectral Decomposition in Deep Networks for Segmentation of Dynamic\n  Medical Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic contrast-enhanced magnetic resonance imaging (DCE- MRI) is a widely\nused multi-phase technique routinely used in clinical practice. DCE and similar\ndatasets of dynamic medical data tend to contain redundant information on the\nspatial and temporal components that may not be relevant for detection of the\nobject of interest and result in unnecessarily complex computer models with\nlong training times that may also under-perform at test time due to the\nabundance of noisy heterogeneous data. This work attempts to increase the\ntraining efficacy and performance of deep networks by determining redundant\ninformation in the spatial and spectral components and show that the\nperformance of segmentation accuracy can be maintained and potentially\nimproved. Reported experiments include the evaluation of training/testing\nefficacy on a heterogeneous dataset composed of abdominal images of pediatric\nDCE patients, showing that drastic data reduction (higher than 80%) can\npreserve the dynamic information and performance of the segmentation model,\nwhile effectively suppressing noise and unwanted portion of the images.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 03:01:09 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Piedra", "Edgar A. Rios", ""], ["Mardani", "Morteza", ""], ["Ong", "Frank", ""], ["Nakarmi", "Ukash", ""], ["Cheng", "Joseph Y.", ""], ["Vasanawala", "Shreyas", ""]]}, {"id": "2010.00029", "submitter": "Hong-Ye Hu", "authors": "Hong-Ye Hu, Dian Wu, Yi-Zhuang You, Bruno Olshausen, Yubei Chen", "title": "RG-Flow: A hierarchical and explainable flow model based on\n  renormalization group and sparse prior", "comments": "9 pages, 7 figures, with appendix and the newly added multi-scale\n  experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow-based generative models have become an important class of unsupervised\nlearning approaches. In this work, we incorporate the key idea of\nrenormalization group (RG) and sparse prior distribution to design a\nhierarchical flow-based generative model, called RG-Flow, which can separate\ninformation at different scales of images with disentangled representations at\neach scale. We demonstrate our method mainly on the CelebA dataset and show\nthat the disentangled representations at different scales enable semantic\nmanipulation and style mixing of the images. To visualize the latent\nrepresentations, we introduce receptive fields for flow-based models and find\nthat the receptive fields learned by RG-Flow are similar to those in\nconvolutional neural networks. In addition, we replace the widely adopted\nGaussian prior distribution by a sparse prior distribution to further enhance\nthe disentanglement of representations. From a theoretical perspective, the\nproposed method has $O(\\log L)$ complexity for image inpainting compared to\nprevious generative models with $O(L^2)$ complexity.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 18:04:04 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 18:27:26 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 00:59:10 GMT"}, {"version": "v4", "created": "Fri, 18 Dec 2020 20:27:11 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Hu", "Hong-Ye", ""], ["Wu", "Dian", ""], ["You", "Yi-Zhuang", ""], ["Olshausen", "Bruno", ""], ["Chen", "Yubei", ""]]}, {"id": "2010.00030", "submitter": "Kevin Leahy", "authors": "Kevin Leahy, Austin Jones, Cristian-Ioan Vasile", "title": "Fast Decomposition of Temporal Logic Specifications for Heterogeneous\n  Teams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on decomposing large multi-agent path planning\nproblems with global temporal logic goals (common to all agents) into smaller\nsub-problems that can be solved and executed independently. Crucially, the\nsub-problems' solutions must jointly satisfy the common global mission\nspecification. The agents' missions are given as Capability Temporal Logic\n(CaTL) formulas, a fragment of signal temporal logic, that can express\nproperties over tasks involving multiple agent capabilities (sensors, e.g.,\ncamera, IR, and effectors, e.g., wheeled, flying, manipulators) under strict\ntiming constraints. The approach we take is to decompose both the temporal\nlogic specification and the team of agents. We jointly reason about the\nassignment of agents to subteams and the decomposition of formulas using a\nsatisfiability modulo theories (SMT) approach. The output of the SMT is then\ndistributed to subteams and leads to a significant speed up in planning time.\nWe include computational results to evaluate the efficiency of our solution, as\nwell as the trade-offs introduced by the conservative nature of the SMT\nencoding.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 18:04:39 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Leahy", "Kevin", ""], ["Jones", "Austin", ""], ["Vasile", "Cristian-Ioan", ""]]}, {"id": "2010.00048", "submitter": "Maithilee Kunda", "authors": "Maithilee Kunda and Irina Rabkina", "title": "Creative Captioning: An AI Grand Challenge Based on the Dixit Board Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new class of \"grand challenge\" AI problems that we call creative\ncaptioning---generating clever, interesting, or abstract captions for images,\nas well as understanding such captions. Creative captioning draws on core AI\nresearch areas of vision, natural language processing, narrative reasoning, and\nsocial reasoning, and across all these areas, it requires sophisticated uses of\ncommon sense and cultural knowledge. In this paper, we analyze several specific\nresearch problems that fall under creative captioning, using the popular board\ngame Dixit as both inspiration and proposed testing ground. We expect that\nDixit could serve as an engaging and motivating benchmark for creative\ncaptioning across numerous AI research communities for the coming 1-2 decades.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 18:28:01 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Kunda", "Maithilee", ""], ["Rabkina", "Irina", ""]]}, {"id": "2010.00055", "submitter": "Florian Mirus", "authors": "Florian Mirus, Terrence C. Stewart, Jorg Conradt", "title": "Analyzing the Capacity of Distributed Vector Representations to Encode\n  Spatial Information", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207137", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector Symbolic Architectures belong to a family of related cognitive\nmodeling approaches that encode symbols and structures in high-dimensional\nvectors. Similar to human subjects, whose capacity to process and store\ninformation or concepts in short-term memory is subject to numerical\nrestrictions,the capacity of information that can be encoded in such vector\nrepresentations is limited and one way of modeling the numerical restrictions\nto cognition. In this paper, we analyze these limits regarding information\ncapacity of distributed representations. We focus our analysis on simple\nsuperposition and more complex, structured representations involving\nconvolutive powers to encode spatial information. In two experiments, we find\nupper bounds for the number of concepts that can effectively be stored in a\nsingle vector.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 18:49:29 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Mirus", "Florian", ""], ["Stewart", "Terrence C.", ""], ["Conradt", "Jorg", ""]]}, {"id": "2010.00074", "submitter": "Kirk Roberts", "authors": "Nicholas Greenspan and Yuqi Si and Kirk Roberts", "title": "Extracting Concepts for Precision Oncology from the Biomedical\n  Literature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an initial dataset and automatic natural language\nprocessing (NLP) method for extracting concepts related to precision oncology\nfrom biomedical research articles. We extract five concept types: Cancer,\nMutation, Population, Treatment, Outcome. A corpus of 250 biomedical abstracts\nwere annotated with these concepts following standard double-annotation\nprocedures. We then experiment with BERT-based models for concept extraction.\nThe best-performing model achieved a precision of 63.8%, a recall of 71.9%, and\nan F1 of 67.1. Finally, we propose additional directions for research for\nimproving extraction performance and utilizing the NLP system in downstream\nprecision oncology applications.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 19:31:04 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Greenspan", "Nicholas", ""], ["Si", "Yuqi", ""], ["Roberts", "Kirk", ""]]}, {"id": "2010.00081", "submitter": "Ahmadreza Moradipari", "authors": "Ahmadreza Moradipari, Christos Thrampoulidis, Mahnoosh Alizadeh", "title": "Stage-wise Conservative Linear Bandits", "comments": "28 pages, 5 figures", "journal-ref": "Thirty-fourth Conference on Neural Information Processing Systems,\n  NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study stage-wise conservative linear stochastic bandits: an instance of\nbandit optimization, which accounts for (unknown) safety constraints that\nappear in applications such as online advertising and medical trials. At each\nstage, the learner must choose actions that not only maximize cumulative reward\nacross the entire time horizon but further satisfy a linear baseline constraint\nthat takes the form of a lower bound on the instantaneous reward. For this\nproblem, we present two novel algorithms, stage-wise conservative linear\nThompson Sampling (SCLTS) and stage-wise conservative linear UCB (SCLUCB), that\nrespect the baseline constraints and enjoy probabilistic regret bounds of order\nO(\\sqrt{T} \\log^{3/2}T) and O(\\sqrt{T} \\log T), respectively. Notably, the\nproposed algorithms can be adjusted with only minor modifications to tackle\ndifferent problem variations, such as constraints with bandit-feedback, or an\nunknown sequence of baseline actions. We discuss these and other improvements\nover the state-of-the-art. For instance, compared to existing solutions, we\nshow that SCLTS plays the (non-optimal) baseline action at most O(\\log{T})\ntimes (compared to O(\\sqrt{T})). Finally, we make connections to another\nstudied form of safety constraints that takes the form of an upper bound on the\ninstantaneous reward. While this incurs additional complexity to the learning\nprocess as the optimal action is not guaranteed to belong to the safe set at\neach round, we show that SCLUCB can properly adjust in this setting via a\nsimple modification.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 19:51:37 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Moradipari", "Ahmadreza", ""], ["Thrampoulidis", "Christos", ""], ["Alizadeh", "Mahnoosh", ""]]}, {"id": "2010.00084", "submitter": "Florian Mirus", "authors": "Florian Mirus, Terrence C. Stewart, Jorg Conradt", "title": "The Importance of Balanced Data Sets: Analyzing a Vehicle Trajectory\n  Prediction Model based on Neural Networks and Distributed Representations", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9206627", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting future behavior of other traffic participants is an essential task\nthat needs to be solved by automated vehicles and human drivers alike to\nachieve safe and situationaware driving. Modern approaches to vehicles\ntrajectory prediction typically rely on data-driven models like neural\nnetworks, in particular LSTMs (Long Short-Term Memorys), achieving promising\nresults. However, the question of optimal composition of the underlying\ntraining data has received less attention. In this paper, we expand on previous\nwork on vehicle trajectory prediction based on neural network models employing\ndistributed representations to encode automotive scenes in a semantic vector\nsubstrate. We analyze the influence of variations in the training data on the\nperformance of our prediction models. Thereby, we show that the models\nemploying our semantic vector representation outperform the numerical model\nwhen trained on an adequate data set and thereby, that the composition of\ntraining data in vehicle trajectory prediction is crucial for successful\ntraining. We conduct our analysis on challenging real-world driving data.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 20:00:11 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Mirus", "Florian", ""], ["Stewart", "Terrence C.", ""], ["Conradt", "Jorg", ""]]}, {"id": "2010.00117", "submitter": "Yuning Mao", "authors": "Yuning Mao, Yanru Qu, Yiqing Xie, Xiang Ren, Jiawei Han", "title": "Multi-document Summarization with Maximal Marginal Relevance-guided\n  Reinforcement Learning", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural sequence learning methods have made significant progress in\nsingle-document summarization (SDS), they produce unsatisfactory results on\nmulti-document summarization (MDS). We observe two major challenges when\nadapting SDS advances to MDS: (1) MDS involves larger search space and yet more\nlimited training data, setting obstacles for neural methods to learn adequate\nrepresentations; (2) MDS needs to resolve higher information redundancy among\nthe source documents, which SDS methods are less effective to handle. To close\nthe gap, we present RL-MMR, Maximal Margin Relevance-guided Reinforcement\nLearning for MDS, which unifies advanced neural SDS methods and statistical\nmeasures used in classical MDS. RL-MMR casts MMR guidance on fewer promising\ncandidates, which restrains the search space and thus leads to better\nrepresentation learning. Additionally, the explicit redundancy measure in MMR\nhelps the neural representation of the summary to better capture redundancy.\nExtensive experiments demonstrate that RL-MMR achieves state-of-the-art\nperformance on benchmark MDS datasets. In particular, we show the benefits of\nincorporating MMR into end-to-end learning when adapting SDS to MDS in terms of\nboth learning effectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 21:50:46 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Mao", "Yuning", ""], ["Qu", "Yanru", ""], ["Xie", "Yiqing", ""], ["Ren", "Xiang", ""], ["Han", "Jiawei", ""]]}, {"id": "2010.00133", "submitter": "Nikita Nangia", "authors": "Nikita Nangia, Clara Vania, Rasika Bhalerao, Samuel R. Bowman", "title": "CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked\n  Language Models", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained language models, especially masked language models (MLMs) have\nseen success across many NLP tasks. However, there is ample evidence that they\nuse the cultural biases that are undoubtedly present in the corpora they are\ntrained on, implicitly creating harm with biased representations. To measure\nsome forms of social bias in language models against protected demographic\ngroups in the US, we introduce the Crowdsourced Stereotype Pairs benchmark\n(CrowS-Pairs). CrowS-Pairs has 1508 examples that cover stereotypes dealing\nwith nine types of bias, like race, religion, and age. In CrowS-Pairs a model\nis presented with two sentences: one that is more stereotyping and another that\nis less stereotyping. The data focuses on stereotypes about historically\ndisadvantaged groups and contrasts them with advantaged groups. We find that\nall three of the widely-used MLMs we evaluate substantially favor sentences\nthat express stereotypes in every category in CrowS-Pairs. As work on building\nless biased models advances, this dataset can be used as a benchmark to\nevaluate progress.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 22:38:40 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Nangia", "Nikita", ""], ["Vania", "Clara", ""], ["Bhalerao", "Rasika", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "2010.00134", "submitter": "Yassine Yaakoubi", "authors": "Yassine Yaakoubi, Fran\\c{c}ois Soumis, Simon Lacoste-Julien", "title": "Machine Learning in Airline Crew Pairing to Construct Initial Clusters\n  for Dynamic Constraint Aggregation", "comments": "First publication in the \"Cahiers du GERAD\" series in February 2020.\n  Submitted to EURO Journal on Transportation and Logistics on January 17, 2020\n  and available online on September 2, 2020", "journal-ref": "EURO Journal on Transportation and Logistics, 100020 (2020)", "doi": "10.1016/j.ejtl.2020.100020", "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The crew pairing problem (CPP) is generally modelled as a set partitioning\nproblem where the flights have to be partitioned in pairings. A pairing is a\nsequence of flight legs separated by connection time and rest periods that\nstarts and ends at the same base. Because of the extensive list of complex\nrules and regulations, determining whether a sequence of flights constitutes a\nfeasible pairing can be quite difficult by itself, making CPP one of the\nhardest of the airline planning problems. In this paper, we first propose to\nimprove the prototype Baseline solver of Desaulniers et al. (2020) by adding\ndynamic control strategies to obtain an efficient solver for large-scale CPPs:\nCommercial-GENCOL-DCA. These solvers are designed to aggregate the flights\ncovering constraints to reduce the size of the problem. Then, we use machine\nlearning (ML) to produce clusters of flights having a high probability of being\nperformed consecutively by the same crew. The solver combines several advanced\nOperations Research techniques to assemble and modify these clusters, when\nnecessary, to produce a good solution. We show, on monthly CPPs with up to 50\n000 flights, that Commercial-GENCOL-DCA with clusters produced by ML-based\nheuristics outperforms Baseline fed by initial clusters that are pairings of a\nsolution obtained by rolling horizon with GENCOL. The reduction of solution\ncost averages between 6.8% and 8.52%, which is mainly due to the reduction in\nthe cost of global constraints between 69.79% and 78.11%.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 22:38:47 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Yaakoubi", "Yassine", ""], ["Soumis", "Fran\u00e7ois", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "2010.00168", "submitter": "Helio Henrique Monte-Alto", "authors": "Helio H. L. C. Monte-Alto, Mariela Morveli-Espinoza, Cesar A. Tacla", "title": "Multi-Agent Systems based on Contextual Defeasible Logic considering\n  Focus", "comments": "11 pages, 3 figures, paper was accepted for conference ICAART 2020:\n  12th International Conference on Agents and Artificial Intelligence, but was\n  withdrew", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we extend previous work on distributed reasoning using\nContextual Defeasible Logic (CDL), which enables decentralised distributed\nreasoning based on a distributed knowledge base, such that the knowledge from\ndifferent knowledge bases may conflict with each other. However, there are many\nuse case scenarios that are not possible to represent in this model. One kind\nof such scenarios are the ones that require that agents share and reason with\nrelevant knowledge when issuing a query to others. Another kind of scenarios\nare those in which the bindings among the agents (defined by means of mapping\nrules) are not static, such as in knowledge-intensive and dynamic environments.\nThis work presents a multi-agent model based on CDL that not only allows agents\nto reason with their local knowledge bases and mapping rules, but also allows\nagents to reason about relevant knowledge (focus) -- which are not known by the\nagents a priori -- in the context of a specific query. We present a use case\nscenario, some formalisations of the model proposed, and an initial\nimplementation based on the BDI (Belief-Desire-Intention) agent model.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 01:50:08 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Monte-Alto", "Helio H. L. C.", ""], ["Morveli-Espinoza", "Mariela", ""], ["Tacla", "Cesar A.", ""]]}, {"id": "2010.00176", "submitter": "Yong Xiao", "authors": "Yong Xiao and Guangming Shi and Yingyu Li and Walid Saad and H.\n  Vincent Poor", "title": "Towards Self-learning Edge Intelligence in 6G", "comments": "To be published at IEEE Communications Magazine, vol. 58, no. 12,\n  December 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge intelligence, also called edge-native artificial intelligence (AI), is\nan emerging technological framework focusing on seamless integration of AI,\ncommunication networks, and mobile edge computing. It has been considered to be\none of the key missing components in the existing 5G network and is widely\nrecognized to be one of the most sought-after functions for tomorrow's wireless\n6G cellular systems. In this article, we identify the key requirements and\nchallenges of edge-native AI in 6G. A self-learning architecture based on\nself-supervised Generative Adversarial Nets (GANs) is introduced to\n\\blu{demonstrate the potential performance improvement that can be achieved by\nautomatic data learning and synthesizing at the edge of the network}. We\nevaluate the performance of our proposed self-learning architecture in a\nuniversity campus shuttle system connected via a 5G network. Our result shows\nthat the proposed architecture has the potential to identify and classify\nunknown services that emerge in edge computing networks. Future trends and key\nresearch problems for self-learning-enabled 6G edge intelligence are also\ndiscussed.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 02:16:40 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Xiao", "Yong", ""], ["Shi", "Guangming", ""], ["Li", "Yingyu", ""], ["Saad", "Walid", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2010.00179", "submitter": "Zhichao Sun", "authors": "Zhichao Sun, Junjie Wu, Gary G. Yen, Hang Ren, Hongyang An, Jianyu\n  Yang", "title": "System Design and Analysis for Energy-Efficient Passive UAV Radar\n  Imaging System using Illuminators of Opportunity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicle (UAV) can provide superior flexibility and\ncost-efficiency for modern radar imaging systems, which is an ideal platform\nfor advanced remote sensing applications using synthetic aperture radar (SAR)\ntechnology. In this paper, an energy-efficient passive UAV radar imaging system\nusing illuminators of opportunity is first proposed and investigated. Equipped\nwith a SAR receiver, the UAV platform passively reuses the backscattered signal\nof the target scene from an external illuminator, such as SAR satellite, GNSS\nor ground-based stationary commercial illuminators, and achieves bi-static SAR\nimaging and data communication. The system can provide instant accessibility to\nthe radar image of the interested targets with enhanced platform concealment,\nwhich is an essential tool for stealth observation and scene monitoring. The\nmission concept and system block diagram are first presented with\njustifications on the advantages of the system. Then, a set of mission\nperformance evaluators is established to quantitatively assess the capability\nof the system in a comprehensive manner, including UAV navigation, passive SAR\nimaging and communication. Finally, the validity of the proposed performance\nevaluators are verified by numerical simulations.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 02:27:37 GMT"}, {"version": "v2", "created": "Sat, 8 May 2021 04:13:43 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Sun", "Zhichao", ""], ["Wu", "Junjie", ""], ["Yen", "Gary G.", ""], ["Ren", "Hang", ""], ["An", "Hongyang", ""], ["Yang", "Jianyu", ""]]}, {"id": "2010.00182", "submitter": "Yang Zhang", "authors": "Yang Zhang, Qiang Ma", "title": "Dual Attention Model for Citation Recommendation", "comments": null, "journal-ref": "Proceedings of the 28th International Conference on Computational\n  Linguistics (COLING2020)", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on an exponentially increasing number of academic articles, discovering\nand citing comprehensive and appropriate resources has become a non-trivial\ntask. Conventional citation recommender methods suffer from severe information\nloss. For example, they do not consider the section of the paper that the user\nis writing and for which they need to find a citation, the relatedness between\nthe words in the local context (the text span that describes a citation), or\nthe importance on each word from the local context. These shortcomings make\nsuch methods insufficient for recommending adequate citations to academic\nmanuscripts. In this study, we propose a novel embedding-based neural network\ncalled \"dual attention model for citation recommendation (DACR)\" to recommend\ncitations during manuscript preparation. Our method adapts embedding of three\ndimensions of semantic information: words in the local context, structural\ncontexts, and the section on which a user is working. A neural network is\ndesigned to maximize the similarity between the embedding of the three input\n(local context words, section and structural contexts) and the target citation\nappearing in the context. The core of the neural network is composed of\nself-attention and additive attention, where the former aims to capture the\nrelatedness between the contextual words and structural context, and the latter\naims to learn the importance of them. The experiments on real-world datasets\ndemonstrate the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 02:41:47 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 11:27:20 GMT"}, {"version": "v3", "created": "Wed, 28 Oct 2020 12:57:58 GMT"}, {"version": "v4", "created": "Thu, 29 Oct 2020 12:31:26 GMT"}, {"version": "v5", "created": "Thu, 3 Dec 2020 05:16:08 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Zhang", "Yang", ""], ["Ma", "Qiang", ""]]}, {"id": "2010.00191", "submitter": "Yi-Dong Shen", "authors": "Yi-Dong Shen and Thomas Eiter", "title": "Constraint Monotonicity, Epistemic Splitting and Foundedness Could in\n  General Be Too Strong in Answer Set Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the notions of subjective constraint monotonicity, epistemic\nsplitting, and foundedness have been introduced for epistemic logic programs,\nwith the aim to use them as main criteria respectively intuitions to compare\ndifferent answer set semantics proposed in the literature on how they comply\nwith these intuitions. In this note, we consider these three notions and\ndemonstrate on some examples that they may be too strong in general and may\nexclude some desired answer sets respectively world views. In conclusion, these\nproperties should not be regarded as mandatory properties that every answer set\nsemantics must satisfy in general.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 04:03:11 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 11:16:07 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Shen", "Yi-Dong", ""], ["Eiter", "Thomas", ""]]}, {"id": "2010.00238", "submitter": "Zhiqiang Zhong", "authors": "Zhiqiang Zhong, Cheng-Te Li and Jun Pang", "title": "Adaptive Multi-grained Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have been increasingly deployed in a multitude\nof different applications that involve node-wise and graph-level tasks. The\nexisting literature usually studies these questions independently while they\nare inherently correlated. We propose in this work a unified model, Adaptive\nMulti-grained GNN (AdamGNN), to learn node and graph level representation\ninteractively. Compared with the existing GNN models and pooling methods,\nAdamGNN enhances node representation with multi-grained semantics and avoids\nnode feature and graph structure information loss during pooling. More\nspecifically, a differentiable pooling operator in AdamGNN is used to obtain a\nmulti-grained structure that involves node-wise and meso/macro level semantic\ninformation. The unpooling and flyback aggregators in AdamGNN is to leverage\nthe multi-grained semantics to enhance node representation. The updated node\nrepresentation can further enrich the generated graph representation in the\nnext iteration. Experimental results on twelve real-world graphs demonstrate\nthe effectiveness of AdamGNN on multiple tasks, compared with several competing\nmethods. In addition, the ablation and empirical studies confirm the\neffectiveness of different components in AdamGNN.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 07:52:06 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 17:26:29 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Zhong", "Zhiqiang", ""], ["Li", "Cheng-Te", ""], ["Pang", "Jun", ""]]}, {"id": "2010.00239", "submitter": "Laercio Lima Pilla", "authors": "La\\'ercio Lima Pilla (ParSys - LRI)", "title": "Optimal Task Assignment to Heterogeneous Federated Learning Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning provides new opportunities for training machine learning\nmodels while respecting data privacy. This technique is based on heterogeneous\ndevices that work together to iteratively train a model while never sharing\ntheir own data. Given the synchronous nature of this training, the performance\nof Federated Learning systems is dictated by the slowest devices, also known as\nstragglers. In this paper, we investigate the problem of minimizing the\nduration of Federated Learning rounds by controlling how much data each device\nuses for training. We formulate this problem as a makespan minimization problem\nwith identical, independent, and atomic tasks that have to be assigned to\nheterogeneous resources with non-decreasing cost functions while respecting\nlower and upper limits of tasks per resource. Based on this formulation, we\npropose a polynomial-time algorithm named OLAR and prove that it provides\noptimal schedules. We evaluate OLAR in an extensive experimental evaluation\nusing simulation that includes comparisons to other algorithms from the state\nof the art and new extensions to them. Our results indicate that OLAR provides\noptimal solutions with a small execution time. They also show that the presence\nof lower and upper limits of tasks per resource erase any benefits that\nsuboptimal heuristics could provide in terms of algorithm execution time.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 07:58:48 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Pilla", "La\u00e9rcio Lima", "", "ParSys - LRI"]]}, {"id": "2010.00247", "submitter": "Fandong Meng", "authors": "Fandong Meng, Jianhao Yan, Yijin Liu, Yuan Gao, Xianfeng Zeng, Qinsong\n  Zeng, Peng Li, Ming Chen, Jie Zhou, Sifan Liu and Hao Zhou", "title": "WeChat Neural Machine Translation Systems for WMT20", "comments": "Accepted at WMT 2020. Our Chinese to English system achieved the\n  highest case-sensitive BLEU score among all submissions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We participate in the WMT 2020 shared news translation task on Chinese to\nEnglish. Our system is based on the Transformer (Vaswani et al., 2017a) with\neffective variants and the DTMT (Meng and Zhang, 2019) architecture. In our\nexperiments, we employ data selection, several synthetic data generation\napproaches (i.e., back-translation, knowledge distillation, and iterative\nin-domain knowledge transfer), advanced finetuning approaches and self-bleu\nbased model ensemble. Our constrained Chinese to English system achieves 36.9\ncase-sensitive BLEU score, which is the highest among all submissions.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 08:15:09 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 16:01:01 GMT"}], "update_date": "2020-11-22", "authors_parsed": [["Meng", "Fandong", ""], ["Yan", "Jianhao", ""], ["Liu", "Yijin", ""], ["Gao", "Yuan", ""], ["Zeng", "Xianfeng", ""], ["Zeng", "Qinsong", ""], ["Li", "Peng", ""], ["Chen", "Ming", ""], ["Zhou", "Jie", ""], ["Liu", "Sifan", ""], ["Zhou", "Hao", ""]]}, {"id": "2010.00297", "submitter": "Daniil Ryabko", "authors": "Daniil Ryabko", "title": "Universal time-series forecasting with mixture predictors", "comments": "This is the author's version of the book published by Springer under\n  the same name. The final authenticated version is available online at:\n  https://doi.org/10.1007/978-3-030-54304-4 . Further updates and corrections\n  may be made here", "journal-ref": null, "doi": "10.1007/978-3-030-54304-4", "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This book is devoted to the problem of sequential probability forecasting,\nthat is, predicting the probabilities of the next outcome of a growing sequence\nof observations given the past. This problem is considered in a very general\nsetting that unifies commonly used probabilistic and non-probabilistic\nsettings, trying to make as few as possible assumptions on the mechanism\ngenerating the observations. A common form that arises in various formulations\nof this problem is that of mixture predictors, which are formed as a\ncombination of a finite or infinite set of other predictors attempting to\ncombine their predictive powers. The main subject of this book are such mixture\npredictors, and the main results demonstrate the universality of this method in\na very general probabilistic setting, but also show some of its limitations.\nWhile the problems considered are motivated by practical applications,\ninvolving, for example, financial, biological or behavioural data, this\nmotivation is left implicit and all the results exposed are theoretical.\n  The book targets graduate students and researchers interested in the problem\nof sequential prediction, and, more generally, in theoretical analysis of\nproblems in machine learning and non-parametric statistics, as well as\nmathematical and philosophical foundations of these fields.\n  The material in this volume is presented in a way that presumes familiarity\nwith basic concepts of probability and statistics, up to and including\nprobability distributions over spaces of infinite sequences. Familiarity with\nthe literature on learning or stochastic processes is not required.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 10:56:23 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Ryabko", "Daniil", ""]]}, {"id": "2010.00309", "submitter": "Tianxiang Sun", "authors": "Tianxiang Sun, Yunfan Shao, Xipeng Qiu, Qipeng Guo, Yaru Hu, Xuanjing\n  Huang, Zheng Zhang", "title": "CoLAKE: Contextualized Language and Knowledge Embedding", "comments": "Accepted by COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emerging branch of incorporating factual knowledge into pre-trained\nlanguage models such as BERT, most existing models consider shallow, static,\nand separately pre-trained entity embeddings, which limits the performance\ngains of these models. Few works explore the potential of deep contextualized\nknowledge representation when injecting knowledge. In this paper, we propose\nthe Contextualized Language and Knowledge Embedding (CoLAKE), which jointly\nlearns contextualized representation for both language and knowledge with the\nextended MLM objective. Instead of injecting only entity embeddings, CoLAKE\nextracts the knowledge context of an entity from large-scale knowledge bases.\nTo handle the heterogeneity of knowledge context and language context, we\nintegrate them in a unified data structure, word-knowledge graph (WK graph).\nCoLAKE is pre-trained on large-scale WK graphs with the modified Transformer\nencoder. We conduct experiments on knowledge-driven tasks, knowledge probing\ntasks, and language understanding tasks. Experimental results show that CoLAKE\noutperforms previous counterparts on most of the tasks. Besides, CoLAKE\nachieves surprisingly high performance on our synthetic task called\nword-knowledge graph completion, which shows the superiority of simultaneously\ncontextualizing language and knowledge representation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 11:39:32 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Sun", "Tianxiang", ""], ["Shao", "Yunfan", ""], ["Qiu", "Xipeng", ""], ["Guo", "Qipeng", ""], ["Hu", "Yaru", ""], ["Huang", "Xuanjing", ""], ["Zhang", "Zheng", ""]]}, {"id": "2010.00330", "submitter": "Renan Souza", "authors": "Renan Souza, Leonardo G. Azevedo, V\\'itor Louren\\c{c}o, Elton Soares,\n  Raphael Thiago, Rafael Brand\\~ao, Daniel Civitarese, Emilio Vital Brazil,\n  Marcio Moreno, Patrick Valduriez, Marta Mattoso, Renato Cerqueira, Marco A.\n  S. Netto", "title": "Workflow Provenance in the Lifecycle of Scientific Machine Learning", "comments": "21 pages, 10 figures, Under review in a scientific journal since June\n  30th, 2020. arXiv admin note: text overlap with arXiv:1910.04223", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) has already fundamentally changed several businesses.\nMore recently, it has also been profoundly impacting the computational science\nand engineering domains, like geoscience, climate science, and health science.\nIn these domains, users need to perform comprehensive data analyses combining\nscientific data and ML models to provide for critical requirements, such as\nreproducibility, model explainability, and experiment data understanding.\nHowever, scientific ML is multidisciplinary, heterogeneous, and affected by the\nphysical constraints of the domain, making such analyses even more challenging.\nIn this work, we leverage workflow provenance techniques to build a holistic\nview to support the lifecycle of scientific ML. We contribute with (i)\ncharacterization of the lifecycle and taxonomy for data analyses; (ii) design\nprinciples to build this view, with a W3C PROV compliant data representation\nand a reference system architecture; and (iii) lessons learned after an\nevaluation in an Oil & Gas case using an HPC cluster with 393 nodes and 946\nGPUs. The experiments show that the principles enable queries that integrate\ndomain semantics with ML models while keeping low overhead (<1%), high\nscalability, and an order of magnitude of query acceleration under certain\nworkloads against without our representation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 13:09:48 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Souza", "Renan", ""], ["Azevedo", "Leonardo G.", ""], ["Louren\u00e7o", "V\u00edtor", ""], ["Soares", "Elton", ""], ["Thiago", "Raphael", ""], ["Brand\u00e3o", "Rafael", ""], ["Civitarese", "Daniel", ""], ["Brazil", "Emilio Vital", ""], ["Moreno", "Marcio", ""], ["Valduriez", "Patrick", ""], ["Mattoso", "Marta", ""], ["Cerqueira", "Renato", ""], ["Netto", "Marco A. S.", ""]]}, {"id": "2010.00352", "submitter": "Joseph K J", "authors": "K J Joseph and Vineeth N Balasubramanian", "title": "Meta-Consolidation for Continual Learning", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The ability to continuously learn and adapt itself to new tasks, without\nlosing grasp of already acquired knowledge is a hallmark of biological learning\nsystems, which current deep learning systems fall short of. In this work, we\npresent a novel methodology for continual learning called MERLIN:\nMeta-Consolidation for Continual Learning.\n  We assume that weights of a neural network $\\boldsymbol \\psi$, for solving\ntask $\\boldsymbol t$, come from a meta-distribution $p(\\boldsymbol{\\psi|t})$.\nThis meta-distribution is learned and consolidated incrementally. We operate in\nthe challenging online continual learning setting, where a data point is seen\nby the model only once.\n  Our experiments with continual learning benchmarks of MNIST, CIFAR-10,\nCIFAR-100 and Mini-ImageNet datasets show consistent improvement over five\nbaselines, including a recent state-of-the-art, corroborating the promise of\nMERLIN.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 12:34:35 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Joseph", "K J", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "2010.00353", "submitter": "Antonio Jes\\'us Banegas-Luna", "authors": "Antonio-Jes\\'us Banegas-Luna, Jorge Pe\\~na-Garc\\'ia, Adrian Iftene,\n  Fiorella Guadagni, Patrizia Ferroni, Noemi Scarpato, Fabio Massimo Zanzotto,\n  Andr\\'es Bueno-Crespo, Horacio P\\'erez-S\\'anchez", "title": "When will the mist clear? On the Interpretability of Machine Learning\n  for Medical Applications: a survey", "comments": "64 pages, 3 figures, 7 tables, +100 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence is providing astonishing results, with medicine being\none of its favourite playgrounds. In a few decades, computers may be capable of\nformulating diagnoses and choosing the correct treatment, while robots may\nperform surgical operations, and conversational agents could interact with\npatients as virtual coaches. Machine Learning and, in particular, Deep Neural\nNetworks are behind this revolution. In this scenario, important decisions will\nbe controlled by standalone machines that have learned predictive models from\nprovided data. Among the most challenging targets of interest in medicine are\ncancer diagnosis and therapies but, to start this revolution, software tools\nneed to be adapted to cover the new requirements. In this sense, learning tools\nare becoming a commodity in Python and Matlab libraries, just to name two, but\nto exploit all their possibilities, it is essential to fully understand how\nmodels are interpreted and which models are more interpretable than others. In\nthis survey, we analyse current machine learning models, frameworks, databases\nand other related tools as applied to medicine - specifically, to cancer\nresearch - and we discuss their interpretability, performance and the necessary\ninput data. From the evidence available, ANN, LR and SVM have been observed to\nbe the preferred models. Besides, CNNs, supported by the rapid development of\nGPUs and tensor-oriented programming libraries, are gaining in importance.\nHowever, the interpretability of results by doctors is rarely considered which\nis a factor that needs to be improved. We therefore consider this study to be a\ntimely contribution to the issue.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 12:42:06 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Banegas-Luna", "Antonio-Jes\u00fas", ""], ["Pe\u00f1a-Garc\u00eda", "Jorge", ""], ["Iftene", "Adrian", ""], ["Guadagni", "Fiorella", ""], ["Ferroni", "Patrizia", ""], ["Scarpato", "Noemi", ""], ["Zanzotto", "Fabio Massimo", ""], ["Bueno-Crespo", "Andr\u00e9s", ""], ["P\u00e9rez-S\u00e1nchez", "Horacio", ""]]}, {"id": "2010.00357", "submitter": "Hind Alatwi", "authors": "Hind Saleh Alatawi, Areej Maatog Alhothali and Kawthar Mustafa Moria", "title": "Detecting White Supremacist Hate Speech using Domain Specific Word\n  Embedding with Deep Learning and BERT", "comments": "32 pages,2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  White supremacists embrace a radical ideology that considers white people\nsuperior to people of other races. The critical influence of these groups is no\nlonger limited to social media; they also have a significant effect on society\nin many ways by promoting racial hatred and violence. White supremacist hate\nspeech is one of the most recently observed harmful content on social\nmedia.Traditional channels of reporting hate speech have proved inadequate due\nto the tremendous explosion of information, and therefore, it is necessary to\nfind an automatic way to detect such speech in a timely manner. This research\ninvestigates the viability of automatically detecting white supremacist hate\nspeech on Twitter by using deep learning and natural language processing\ntechniques. Through our experiments, we used two approaches, the first approach\nis by using domain-specific embeddings which are extracted from white\nsupremacist corpus in order to catch the meaning of this white supremacist\nslang with bidirectional Long Short-Term Memory (LSTM) deep learning model,\nthis approach reached a 0.74890 F1-score. The second approach is by using the\none of the most recent language model which is BERT, BERT model provides the\nstate of the art of most NLP tasks. It reached to a 0.79605 F1-score. Both\napproaches are tested on a balanced dataset given that our experiments were\nbased on textual data only. The dataset was combined from dataset created from\nTwitter and a Stormfront dataset compiled from that white supremacist forum.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 12:44:24 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Alatawi", "Hind Saleh", ""], ["Alhothali", "Areej Maatog", ""], ["Moria", "Kawthar Mustafa", ""]]}, {"id": "2010.00370", "submitter": "Suiyi Ling", "authors": "Suiyi Ling, Jing Li, Anne Flore Perrin, Zhi Li, Luk\\'a\\v{s} Krasula,\n  Patrick Le Callet", "title": "Strategy for Boosting Pair Comparison and Improving Quality Assessment\n  Accuracy", "comments": "8 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of rigorous quality assessment model relies on the collection\nof reliable subjective data, where the perceived quality of visual multimedia\nis rated by the human observers. Different subjective assessment protocols can\nbe used according to the objectives, which determine the discriminability and\naccuracy of the subjective data.\n  Single stimulus methodology, e.g., the Absolute Category Rating (ACR) has\nbeen widely adopted due to its simplicity and efficiency. However, Pair\nComparison (PC) is of significant advantage over ACR in terms of\ndiscriminability. In addition, PC avoids the influence of observers' bias\nregarding their understanding of the quality scale. Nevertheless, full pair\ncomparison is much more time-consuming. In this study, we therefore 1) employ a\ngeneric model to bridge the pair comparison data and ACR data, where the\nvariance term could be recovered and the obtained information is more complete;\n2) propose a fusion strategy to boost pair comparisons by utilizing the ACR\nresults as initialization information; 3) develop a novel active batch sampling\nstrategy based on Minimum Spanning Tree (MST) for PC. In such a way, the\nproposed methodology could achieve the same accuracy of pair comparison but\nwith the compelxity as low as ACR. Extensive experimental results demonstrate\nthe efficiency and accuracy of the proposed approach, which outperforms the\nstate of the art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 13:05:09 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Ling", "Suiyi", ""], ["Li", "Jing", ""], ["Perrin", "Anne Flore", ""], ["Li", "Zhi", ""], ["Krasula", "Luk\u00e1\u0161", ""], ["Callet", "Patrick Le", ""]]}, {"id": "2010.00389", "submitter": "Mokanarangan Thayaparan", "authors": "Mokanarangan Thayaparan, Marco Valentino, Andr\\'e Freitas", "title": "A Survey on Explainability in Machine Reading Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a systematic review of benchmarks and approaches for\nexplainability in Machine Reading Comprehension (MRC). We present how the\nrepresentation and inference challenges evolved and the steps which were taken\nto tackle these challenges. We also present the evaluation methodologies to\nassess the performance of explainable systems. In addition, we identify\npersisting open research questions and highlight critical directions for future\nwork.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 13:26:58 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Thayaparan", "Mokanarangan", ""], ["Valentino", "Marco", ""], ["Freitas", "Andr\u00e9", ""]]}, {"id": "2010.00403", "submitter": "The Anh Han", "authors": "The Anh Han, Luis Moniz Pereira, Tom Lenaerts, Francisco C. Santos", "title": "Mediating Artificial Intelligence Developments through Negative and\n  Positive Incentives", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0244592", "report-no": null, "categories": "cs.AI cs.MA math.DS nlin.AO q-bio.PE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The field of Artificial Intelligence (AI) is going through a period of great\nexpectations, introducing a certain level of anxiety in research, business and\nalso policy. This anxiety is further energised by an AI race narrative that\nmakes people believe they might be missing out. Whether real or not, a belief\nin this narrative may be detrimental as some stake-holders will feel obliged to\ncut corners on safety precautions, or ignore societal consequences just to\n\"win\". Starting from a baseline model that describes a broad class of\ntechnology races where winners draw a significant benefit compared to others\n(such as AI advances, patent race, pharmaceutical technologies), we investigate\nhere how positive (rewards) and negative (punishments) incentives may\nbeneficially influence the outcomes. We uncover conditions in which punishment\nis either capable of reducing the development speed of unsafe participants or\nhas the capacity to reduce innovation through over-regulation. Alternatively,\nwe show that, in several scenarios, rewarding those that follow safety measures\nmay increase the development speed while ensuring safe choices. Moreover, in\n{the latter} regimes, rewards do not suffer from the issue of over-regulation\nas is the case for punishment. Overall, our findings provide valuable insights\ninto the nature and kinds of regulatory actions most suitable to improve safety\ncompliance in the contexts of both smooth and sudden technological shifts.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 13:43:32 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Han", "The Anh", ""], ["Pereira", "Luis Moniz", ""], ["Lenaerts", "Tom", ""], ["Santos", "Francisco C.", ""]]}, {"id": "2010.00411", "submitter": "Carlos Mastalli", "authors": "Carlos Mastalli, Wolfgang Merkt, Josep Marti-Saumell, Henrique\n  Ferrolho, Joan Sola, Nicolas Mansard and Sethu Vijayakumar", "title": "A Direct-Indirect Hybridization Approach to Control-Limited DDP", "comments": "16 pages, 9 figures, draft version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential Dynamic Programming (DDP) is an indirect method for trajectory\noptimization. Its efficiency derives from the exploitation of temporal\nstructure (inherent to optimal control problems) and explicit\nroll-out/integration of the system dynamics. However, it suffers from numerical\ninstability and, when compared to direct methods, it has limited initialization\noptions (allows initialization of controls, but not of states) and lacks proper\nhandling of control constraints. These limitations are due to the fact that DDP\nis a single shooting algorithm. In this work, we tackle these issues with a\ndirect-indirect hybridization approach that is primarily driven by the dynamic\nfeasibility of the optimal control problem. Our feasibility search emulates the\nnumerical resolution of a direct transcription problem with only dynamics\nconstraints, namely a multiple shooting formulation. We show that our approach\nhas better numerical convergence than BOX-DDP (a shooting method), and that its\nconvergence rate and runtime performance are competitive with state-of-the-art\ndirect transcription formulations solved using the interior point and active\nset algorithms available in KNITRO. We further show that our approach decreases\nthe dynamic feasibility error monotonically -- as in state-of-the-art nonlinear\nprogramming algorithms. We demonstrate the benefits of our hybrid approach by\ngenerating complex and athletic motions for quadruped and humanoid robots.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 13:56:14 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 08:31:17 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Mastalli", "Carlos", ""], ["Merkt", "Wolfgang", ""], ["Marti-Saumell", "Josep", ""], ["Ferrolho", "Henrique", ""], ["Sola", "Joan", ""], ["Mansard", "Nicolas", ""], ["Vijayakumar", "Sethu", ""]]}, {"id": "2010.00439", "submitter": "Chris Wendler", "authors": "Chris Wendler, Andisheh Amrollahi, Bastian Seifert, Andreas Krause,\n  Markus P\\\"uschel", "title": "Learning Set Functions that are Sparse in Non-Orthogonal Fourier Bases", "comments": null, "journal-ref": "Proc. AAAI, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DM eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of machine learning on discrete domains, such as learning\npreference functions in recommender systems or auctions, can be reduced to\nestimating a set function that is sparse in the Fourier domain. In this work,\nwe present a new family of algorithms for learning Fourier-sparse set\nfunctions. They require at most $nk - k \\log_2 k + k$ queries (set function\nevaluations), under mild conditions on the Fourier coefficients, where $n$ is\nthe size of the ground set and $k$ the number of non-zero Fourier coefficients.\nIn contrast to other work that focused on the orthogonal Walsh-Hadamard\ntransform, our novel algorithms operate with recently introduced non-orthogonal\nFourier transforms that offer different notions of Fourier-sparsity. These\nnaturally arise when modeling, e.g., sets of items forming substitutes and\ncomplements. We demonstrate effectiveness on several real-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 14:31:59 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 14:07:10 GMT"}, {"version": "v3", "created": "Mon, 29 Mar 2021 12:26:21 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Wendler", "Chris", ""], ["Amrollahi", "Andisheh", ""], ["Seifert", "Bastian", ""], ["Krause", "Andreas", ""], ["P\u00fcschel", "Markus", ""]]}, {"id": "2010.00482", "submitter": "Arash Mahyari", "authors": "Arash Mahyari, Peter Pirolli", "title": "Physical Exercise Recommendation and Success Prediction Using\n  Interconnected Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.IR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unhealthy behaviors, e.g., physical inactivity and unhealthful food choice,\nare the primary healthcare cost drivers in developed countries. Pervasive\ncomputational, sensing, and communication technology provided by smartphones\nand smartwatches have made it possible to support individuals in their everyday\nlives to develop healthier lifestyles. In this paper, we propose an exercise\nrecommendation system that also predicts individual success rates. The system,\nconsisting of two inter-connected recurrent neural networks (RNNs), uses the\nhistory of workouts to recommend the next workout activity for each individual.\nThe system then predicts the probability of successful completion of the\npredicted activity by the individual. The prediction accuracy of this\ninterconnected-RNN model is assessed on previously published data from a\nfour-week mobile health experiment and is shown to improve upon previous\npredictions from a computational cognitive model.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 15:22:59 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 20:04:20 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Mahyari", "Arash", ""], ["Pirolli", "Peter", ""]]}, {"id": "2010.00499", "submitter": "Patrick Kenekayoro", "authors": "Patrick Kenekayoro, Biralatei Fawei", "title": "Meta-Heuristic Solutions to a Student Grouping Optimization Problem\n  faced in Higher Education Institutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Combinatorial problems which have been proven to be NP-hard are faced in\nHigher Education Institutions and researches have extensively investigated some\nof the well-known combinatorial problems such as the timetabling and student\nproject allocation problems. However, NP-hard problems faced in Higher\nEducation Institutions are not only confined to these categories of\ncombinatorial problems. The majority of NP-hard problems faced in institutions\ninvolve grouping students and/or resources, albeit with each problem having its\nown unique set of constraints. Thus, it can be argued that techniques to solve\nNP-hard problems in Higher Education Institutions can be transferred across the\ndifferent problem categories. As no method is guaranteed to outperform all\nothers in all problems, it is necessary to investigate heuristic techniques for\nsolving lesser-known problems in order to guide stakeholders or software\ndevelopers to the most appropriate algorithm for each unique class of NP-hard\nproblems faced in Higher Education Institutions. To this end, this study\ndescribed an optimization problem faced in a real university that involved\ngrouping students for the presentation of semester results. Ordering based\nheuristics, genetic algorithm and the ant colony optimization algorithm\nimplemented in Python programming language were used to find feasible solutions\nto this problem, with the ant colony optimization algorithm performing better\nor equal in 75% of the test instances and the genetic algorithm producing\nbetter or equal results in 38% of the test instances.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 15:44:47 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Kenekayoro", "Patrick", ""], ["Fawei", "Biralatei", ""]]}, {"id": "2010.00536", "submitter": "Xing Liang", "authors": "Xing Liang, Anastassia Angelopoulou, Epaminondas Kapetanios, Bencie\n  Woll, Reda Al-batat, Tyron Woolfe", "title": "A Multi-modal Machine Learning Approach and Toolkit to Automate\n  Recognition of Early Stages of Dementia among British Sign Language Users", "comments": null, "journal-ref": "ECCV 2020 Workshops. Lecture Notes in Computer Science, Vol 12536.\n  Springer, Cham", "doi": "10.1007/978-3-030-66096-3_20", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ageing population trend is correlated with an increased prevalence of\nacquired cognitive impairments such as dementia. Although there is no cure for\ndementia, a timely diagnosis helps in obtaining necessary support and\nappropriate medication. Researchers are working urgently to develop effective\ntechnological tools that can help doctors undertake early identification of\ncognitive disorder. In particular, screening for dementia in ageing Deaf\nsigners of British Sign Language (BSL) poses additional challenges as the\ndiagnostic process is bound up with conditions such as quality and availability\nof interpreters, as well as appropriate questionnaires and cognitive tests. On\nthe other hand, deep learning based approaches for image and video analysis and\nunderstanding are promising, particularly the adoption of Convolutional Neural\nNetwork (CNN), which require large amounts of training data. In this paper,\nhowever, we demonstrate novelty in the following way: a) a multi-modal machine\nlearning based automatic recognition toolkit for early stages of dementia among\nBSL users in that features from several parts of the body contributing to the\nsign envelope, e.g., hand-arm movements and facial expressions, are combined,\nb) universality in that it is possible to apply our technique to users of any\nsign language, since it is language independent, c) given the trade-off between\ncomplexity and accuracy of machine learning (ML) prediction models as well as\nthe limited amount of training and testing data being available, we show that\nour approach is not over-fitted and has the potential to scale up.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 16:35:48 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Liang", "Xing", ""], ["Angelopoulou", "Anastassia", ""], ["Kapetanios", "Epaminondas", ""], ["Woll", "Bencie", ""], ["Al-batat", "Reda", ""], ["Woolfe", "Tyron", ""]]}, {"id": "2010.00562", "submitter": "Jose Manuel Gomez-Perez", "authors": "Jose Manuel Gomez-Perez, Raul Ortega", "title": "ISAAQ -- Mastering Textbook Questions with Pre-trained Transformers and\n  Bottom-Up and Top-Down Attention", "comments": "Accepted for publication as a long paper in EMNLP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Textbook Question Answering is a complex task in the intersection of Machine\nComprehension and Visual Question Answering that requires reasoning with\nmultimodal information from text and diagrams. For the first time, this paper\ntaps on the potential of transformer language models and bottom-up and top-down\nattention to tackle the language and visual understanding challenges this task\nentails. Rather than training a language-visual transformer from scratch we\nrely on pre-trained transformers, fine-tuning and ensembling. We add bottom-up\nand top-down attention to identify regions of interest corresponding to diagram\nconstituents and their relationships, improving the selection of relevant\nvisual information for each question and answer options. Our system ISAAQ\nreports unprecedented success in all TQA question types, with accuracies of\n81.36%, 71.11% and 55.12% on true/false, text-only and diagram multiple choice\nquestions. ISAAQ also demonstrates its broad applicability, obtaining\nstate-of-the-art results in other demanding datasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 17:28:47 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Gomez-Perez", "Jose Manuel", ""], ["Ortega", "Raul", ""]]}, {"id": "2010.00567", "submitter": "Hassan Ismail Fawaz", "authors": "Hassan Ismail Fawaz", "title": "Deep learning for time series classification", "comments": "PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series analysis is a field of data science which is interested in\nanalyzing sequences of numerical values ordered in time. Time series are\nparticularly interesting because they allow us to visualize and understand the\nevolution of a process over time. Their analysis can reveal trends,\nrelationships and similarities across the data. There exists numerous fields\ncontaining data in the form of time series: health care (electrocardiogram,\nblood sugar, etc.), activity recognition, remote sensing, finance (stock market\nprice), industry (sensors), etc. Time series classification consists of\nconstructing algorithms dedicated to automatically label time series data. The\nsequential aspect of time series data requires the development of algorithms\nthat are able to harness this temporal property, thus making the existing\noff-the-shelf machine learning models for traditional tabular data suboptimal\nfor solving the underlying task. In this context, deep learning has emerged in\nrecent years as one of the most effective methods for tackling the supervised\nclassification task, particularly in the field of computer vision. The main\nobjective of this thesis was to study and develop deep neural networks\nspecifically constructed for the classification of time series data. We thus\ncarried out the first large scale experimental study allowing us to compare the\nexisting deep methods and to position them compared other non-deep learning\nbased state-of-the-art methods. Subsequently, we made numerous contributions in\nthis area, notably in the context of transfer learning, data augmentation,\nensembling and adversarial attacks. Finally, we have also proposed a novel\narchitecture, based on the famous Inception network (Google), which ranks among\nthe most efficient to date.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 17:38:40 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Fawaz", "Hassan Ismail", ""]]}, {"id": "2010.00571", "submitter": "Julian Eisenschlos", "authors": "Julian Martin Eisenschlos, Syrine Krichene, Thomas M\\\"uller", "title": "Understanding tables with intermediate pre-training", "comments": "Accepted to EMNLP Findings 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Table entailment, the binary classification task of finding if a sentence is\nsupported or refuted by the content of a table, requires parsing language and\ntable structure as well as numerical and discrete reasoning. While there is\nextensive work on textual entailment, table entailment is less well studied. We\nadapt TAPAS (Herzig et al., 2020), a table-based BERT model, to recognize\nentailment. Motivated by the benefits of data augmentation, we create a\nbalanced dataset of millions of automatically created training examples which\nare learned in an intermediate step prior to fine-tuning. This new data is not\nonly useful for table entailment, but also for SQA (Iyyer et al., 2017), a\nsequential table QA task. To be able to use long examples as input of BERT\nmodels, we evaluate table pruning techniques as a pre-processing step to\ndrastically improve the training and prediction efficiency at a moderate drop\nin accuracy. The different methods set the new state-of-the-art on the TabFact\n(Chen et al., 2020) and SQA datasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 17:43:27 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 12:26:40 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Eisenschlos", "Julian Martin", ""], ["Krichene", "Syrine", ""], ["M\u00fcller", "Thomas", ""]]}, {"id": "2010.00578", "submitter": "Yuandong Tian", "authors": "Yuandong Tian and Lantao Yu and Xinlei Chen and Surya Ganguli", "title": "Understanding Self-supervised Learning with Dual Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel theoretical framework to understand contrastive\nself-supervised learning (SSL) methods that employ dual pairs of deep ReLU\nnetworks (e.g., SimCLR). First, we prove that in each SGD update of SimCLR with\nvarious loss functions, including simple contrastive loss, soft Triplet loss\nand InfoNCE loss, the weights at each layer are updated by a \\emph{covariance\noperator} that specifically amplifies initial random selectivities that vary\nacross data samples but survive averages over data augmentations. To further\nstudy what role the covariance operator plays and which features are learned in\nsuch a process, we model data generation and augmentation processes through a\n\\emph{hierarchical latent tree model} (HLTM) and prove that the hidden neurons\nof deep ReLU networks can learn the latent variables in HLTM, despite the fact\nthat the network receives \\emph{no direct supervision} from these unobserved\nlatent variables. This leads to a provable emergence of hierarchical features\nthrough the amplification of initially random selectivities through contrastive\nSSL. Extensive numerical studies justify our theoretical findings. Code is\nreleased in https://github.com/facebookresearch/luckmatters/tree/master/ssl.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 17:51:49 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 17:42:46 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 17:13:52 GMT"}, {"version": "v4", "created": "Tue, 10 Nov 2020 18:52:22 GMT"}, {"version": "v5", "created": "Wed, 2 Dec 2020 18:34:58 GMT"}, {"version": "v6", "created": "Mon, 15 Feb 2021 04:51:42 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Tian", "Yuandong", ""], ["Yu", "Lantao", ""], ["Chen", "Xinlei", ""], ["Ganguli", "Surya", ""]]}, {"id": "2010.00581", "submitter": "Kamal Ndousse", "authors": "Kamal Ndousse, Douglas Eck, Sergey Levine, Natasha Jaques", "title": "Emergent Social Learning via Multi-agent Reinforcement Learning", "comments": "14 pages, 19 figures. To be published in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social learning is a key component of human and animal intelligence. By\ntaking cues from the behavior of experts in their environment, social learners\ncan acquire sophisticated behavior and rapidly adapt to new circumstances. This\npaper investigates whether independent reinforcement learning (RL) agents in a\nmulti-agent environment can learn to use social learning to improve their\nperformance. We find that in most circumstances, vanilla model-free RL agents\ndo not use social learning. We analyze the reasons for this deficiency, and\nshow that by imposing constraints on the training environment and introducing a\nmodel-based auxiliary loss we are able to obtain generalized social learning\npolicies which enable agents to: i) discover complex skills that are not\nlearned from single-agent training, and ii) adapt online to novel environments\nby taking cues from experts present in the new environment. In contrast, agents\ntrained with model-free RL or imitation learning generalize poorly and do not\nsucceed in the transfer tasks. By mixing multi-agent and solo training, we can\nobtain agents that use social learning to gain skills that they can deploy when\nalone, even out-performing agents trained alone from the start.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 17:54:14 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 19:02:43 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 21:18:59 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Ndousse", "Kamal", ""], ["Eck", "Douglas", ""], ["Levine", "Sergey", ""], ["Jaques", "Natasha", ""]]}, {"id": "2010.00590", "submitter": "Isaac Waller", "authors": "Isaac Waller and Ashton Anderson", "title": "Quantifying social organization and political polarization in online\n  platforms", "comments": "43 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimism about the Internet's potential to bring the world together has been\ntempered by concerns about its role in inflaming the 'culture wars'. Via mass\nselection into like-minded groups, online society may be becoming more\nfragmented and polarized, particularly with respect to partisan differences.\nHowever, our ability to measure the social makeup of online communities, and in\nturn understand the social organization of online platforms, is limited by the\npseudonymous, unstructured, and large-scale nature of digital discussion. We\ndevelop a neural embedding methodology to quantify the positioning of online\ncommunities along social dimensions by leveraging large-scale patterns of\naggregate behaviour. Applying our methodology to 5.1B Reddit comments made in\n10K communities over 14 years, we measure how the macroscale community\nstructure is organized with respect to age, gender, and U.S. political\npartisanship. Examining political content, we find Reddit underwent a\nsignificant polarization event around the 2016 U.S. presidential election, and\nremained highly polarized for years afterward. Contrary to conventional wisdom,\nhowever, individual-level polarization is rare; the system-level shift in 2016\nwas disproportionately driven by the arrival of new and newly political users.\nPolitical polarization on Reddit is unrelated to previous activity on the\nplatform, and is instead temporally aligned with external events. We also\nobserve a stark ideological asymmetry, with the sharp increase in 2016 being\nentirely attributable to changes in right-wing activity. Our methodology is\nbroadly applicable to the study of online interaction, and our findings have\nimplications for the design of online platforms, understanding the social\ncontexts of online behaviour, and quantifying the dynamics and mechanisms of\nonline polarization.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 17:59:40 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 00:58:42 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 22:15:43 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Waller", "Isaac", ""], ["Anderson", "Ashton", ""]]}, {"id": "2010.00684", "submitter": "Jussi Viinikka", "authors": "Jussi Viinikka, Antti Hyttinen, Johan Pensar, Mikko Koivisto", "title": "Towards Scalable Bayesian Learning of Causal DAGs", "comments": "We have updated the manuscript based on reviewer feedback", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give methods for Bayesian inference of directed acyclic graphs, DAGs, and\nthe induced causal effects from passively observed complete data. Our methods\nbuild on a recent Markov chain Monte Carlo scheme for learning Bayesian\nnetworks, which enables efficient approximate sampling from the graph\nposterior, provided that each node is assigned a small number $K$ of candidate\nparents. We present algorithmic techniques to significantly reduce the space\nand time requirements, which make the use of substantially larger values of $K$\nfeasible. Furthermore, we investigate the problem of selecting the candidate\nparents per node so as to maximize the covered posterior mass. Finally, we\ncombine our sampling method with a novel Bayesian approach for estimating\ncausal effects in linear Gaussian DAG models. Numerical experiments demonstrate\nthe performance of our methods in detecting ancestor-descendant relations, and\nin causal effect estimation our Bayesian method is shown to outperform previous\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 08:46:46 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 13:48:01 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Viinikka", "Jussi", ""], ["Hyttinen", "Antti", ""], ["Pensar", "Johan", ""], ["Koivisto", "Mikko", ""]]}, {"id": "2010.00685", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, Jack Urbanek, Margaret Li, Arthur Szlam, Tim\n  Rockt\\\"aschel, Jason Weston", "title": "How to Motivate Your Dragon: Teaching Goal-Driven Agents to Speak and\n  Act in Fantasy Worlds", "comments": "In NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to create agents that both act and communicate with other agents in\npursuit of a goal. Towards this end, we extend LIGHT (Urbanek et al. 2019) -- a\nlarge-scale crowd-sourced fantasy text-game -- with a dataset of quests. These\ncontain natural language motivations paired with in-game goals and human\ndemonstrations; completing a quest might require dialogue or actions (or both).\nWe introduce a reinforcement learning system that (1) incorporates large-scale\nlanguage modeling-based and commonsense reasoning-based pre-training to imbue\nthe agent with relevant priors; and (2) leverages a factorized action space of\naction commands and dialogue, balancing between the two. We conduct zero-shot\nevaluations using held-out human expert demonstrations, showing that our agents\nare able to act consistently and talk naturally with respect to their\nmotivations.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 21:06:21 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 05:27:18 GMT"}, {"version": "v3", "created": "Tue, 25 May 2021 15:26:16 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Urbanek", "Jack", ""], ["Li", "Margaret", ""], ["Szlam", "Arthur", ""], ["Rockt\u00e4schel", "Tim", ""], ["Weston", "Jason", ""]]}, {"id": "2010.00711", "submitter": "Marina Danilevsky", "authors": "Marina Danilevsky, Kun Qian, Ranit Aharonov, Yannis Katsis, Ban Kawas,\n  Prithviraj Sen", "title": "A Survey of the State of Explainable AI for Natural Language Processing", "comments": "To appear in AACL-IJCNLP 2020", "journal-ref": "Proceedings of the 1st Conference of the Asia-Pacific Chapter of\n  the Association for Computational Linguistics and the 10th International\n  Joint Conference on Natural Language Processing 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen important advances in the quality of state-of-the-art\nmodels, but this has come at the expense of models becoming less interpretable.\nThis survey presents an overview of the current state of Explainable AI (XAI),\nconsidered within the domain of Natural Language Processing (NLP). We discuss\nthe main categorization of explanations, as well as the various ways\nexplanations can be arrived at and visualized. We detail the operations and\nexplainability techniques currently available for generating explanations for\nNLP model predictions, to serve as a resource for model developers in the\ncommunity. Finally, we point out the current gaps and encourage directions for\nfuture work in this important research area.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 22:33:21 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Danilevsky", "Marina", ""], ["Qian", "Kun", ""], ["Aharonov", "Ranit", ""], ["Katsis", "Yannis", ""], ["Kawas", "Ban", ""], ["Sen", "Prithviraj", ""]]}, {"id": "2010.00763", "submitter": "Weili Nie", "authors": "Weili Nie, Zhiding Yu, Lei Mao, Ankit B. Patel, Yuke Zhu, Animashree\n  Anandkumar", "title": "Bongard-LOGO: A New Benchmark for Human-Level Concept Learning and\n  Reasoning", "comments": "22 pages, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans have an inherent ability to learn novel concepts from only a few\nsamples and generalize these concepts to different situations. Even though\ntoday's machine learning models excel with a plethora of training data on\nstandard recognition tasks, a considerable gap exists between machine-level\npattern recognition and human-level concept learning. To narrow this gap, the\nBongard problems (BPs) were introduced as an inspirational challenge for visual\ncognition in intelligent systems. Despite new advances in representation\nlearning and learning to learn, BPs remain a daunting challenge for modern AI.\nInspired by the original one hundred BPs, we propose a new benchmark\nBongard-LOGO for human-level concept learning and reasoning. We develop a\nprogram-guided generation technique to produce a large set of\nhuman-interpretable visual cognition problems in action-oriented LOGO language.\nOur benchmark captures three core properties of human cognition: 1)\ncontext-dependent perception, in which the same object may have disparate\ninterpretations given different contexts; 2) analogy-making perception, in\nwhich some meaningful concepts are traded off for other meaningful concepts;\nand 3) perception with a few samples but infinite vocabulary. In experiments,\nwe show that the state-of-the-art deep learning methods perform substantially\nworse than human subjects, implying that they fail to capture core human\ncognition properties. Finally, we discuss research directions towards a general\narchitecture for visual reasoning to tackle this benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 03:19:46 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 19:28:12 GMT"}, {"version": "v3", "created": "Sat, 21 Nov 2020 22:24:02 GMT"}, {"version": "v4", "created": "Mon, 4 Jan 2021 21:50:06 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Nie", "Weili", ""], ["Yu", "Zhiding", ""], ["Mao", "Lei", ""], ["Patel", "Ankit B.", ""], ["Zhu", "Yuke", ""], ["Anandkumar", "Animashree", ""]]}, {"id": "2010.00780", "submitter": "Antony Thomas", "authors": "Antony Thomas and Fulvio Mastrogiovanni and Marco Baglietto", "title": "Towards Multi-Robot Task-Motion Planning for Navigation in Belief Space", "comments": "Full version of the ECAI-STAIRS 2020 paper. arXiv admin note: text\n  overlap with arXiv:1910.11683", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous robots operating in large knowledgeintensive domains require\nplanning in the discrete (task) space and the continuous (motion) space. In\nknowledge-intensive domains, on the one hand, robots have to reason at the\nhighestlevel, for example the regions to navigate to or objects to be picked up\nand their properties; on the other hand, the feasibility of the respective\nnavigation tasks have to be checked at the controller execution level.\nMoreover, employing multiple robots offer enhanced performance capabilities\nover a single robot performing the same task. To this end, we present an\nintegrated multi-robot task-motion planning framework for navigation in\nknowledge-intensive domains. In particular, we consider a distributed\nmulti-robot setting incorporating mutual observations between the robots. The\nframework is intended for motion planning under motion and sensing uncertainty,\nwhich is formally known as belief space planning. The underlying methodology\nand its limitations are discussed, providing suggestions for improvements and\nfuture work. We validate key aspects of our approach in simulation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 06:45:17 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Thomas", "Antony", ""], ["Mastrogiovanni", "Fulvio", ""], ["Baglietto", "Marco", ""]]}, {"id": "2010.00802", "submitter": "Thomas Kurbiel", "authors": "Thomas Kurbiel, Akash Sachdeva, Kun Zhao and Markus Buehren", "title": "PrognoseNet: A Generative Probabilistic Framework for Multimodal\n  Position Prediction given Context Information", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to predict multiple possible future positions of the ego-vehicle\ngiven the surrounding context while also estimating their probabilities is key\nto safe autonomous driving. Most of the current state-of-the-art Deep Learning\napproaches are trained on trajectory data to achieve this task. However\ntrajectory data captured by sensor systems is highly imbalanced, since by far\nmost of the trajectories follow straight lines with an approximately constant\nvelocity. This poses a huge challenge for the task of predicting future\npositions, which is inherently a regression problem. Current state-of-the-art\napproaches alleviate this problem only by major preprocessing of the training\ndata, e.g. resampling, clustering into anchors etc. In this paper we propose an\napproach which reformulates the prediction problem as a classification task,\nallowing for powerful tools, e.g. focal loss, to combat the imbalance. To this\nend we design a generative probabilistic model consisting of a deep neural\nnetwork with a Mixture of Gaussian head. A smart choice of the latent variable\nallows for the reformulation of the log-likelihood function as a combination of\na classification problem and a much simplified regression problem. The output\nof our model is an estimate of the probability density function of future\npositions, hence allowing for prediction of multiple possible positions while\nalso estimating their probabilities. The proposed approach can easily\nincorporate context information and does not require any preprocessing of the\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 06:13:41 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Kurbiel", "Thomas", ""], ["Sachdeva", "Akash", ""], ["Zhao", "Kun", ""], ["Buehren", "Markus", ""]]}, {"id": "2010.00810", "submitter": "Christoph Benzm\\\"uller", "authors": "Sebastian Reiche and Christoph Benzm\\\"uller", "title": "Public Announcement Logic in HOL", "comments": "3rd DaL\\'i Workshop, Dynamic Logic: New Trends and Applications,\n  Online, 9-10 October 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A shallow semantical embedding for public announcement logic with relativized\ncommon knowledge is presented. This embedding enables the first-time automation\nof this logic with off-the-shelf theorem provers for classical higher-order\nlogic. It is demonstrated (i) how meta-theoretical studies can be automated\nthis way, and (ii) how non-trivial reasoning in the target logic (public\nannouncement logic), required e.g. to obtain a convincing encoding and\nautomation of the wise men puzzle, can be realized. Key to the presented\nsemantical embedding -- in contrast, e.g., to related work on the semantical\nembedding of normal modal logics -- is that evaluation domains are modeled\nexplicitly and treated as additional parameter in the encodings of the\nconstituents of the embedded target logic, while they were previously\nimplicitly shared between meta logic and target logic.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 06:46:02 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Reiche", "Sebastian", ""], ["Benzm\u00fcller", "Christoph", ""]]}, {"id": "2010.00821", "submitter": "Wolfgang Fuhl", "authors": "Wolfgang Fuhl, Yao Rong, Thomas Motz, Michael Scheidt, Andreas Hartel,\n  Andreas Koch, Enkelejda Kasneci", "title": "Explainable Online Validation of Machine Learning Models for Practical\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reformulation of the regression and classification, which aims\nto validate the result of a machine learning algorithm. Our reformulation\nsimplifies the original problem and validates the result of the machine\nlearning algorithm using the training data. Since the validation of machine\nlearning algorithms must always be explainable, we perform our experiments with\nthe kNN algorithm as well as with an algorithm based on conditional\nprobabilities, which is proposed in this work. For the evaluation of our\napproach, three publicly available data sets were used and three classification\nand two regression problems were evaluated. The presented algorithm based on\nconditional probabilities is also online capable and requires only a fraction\nof memory compared to the kNN algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 07:38:31 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 14:20:29 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 12:26:28 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Fuhl", "Wolfgang", ""], ["Rong", "Yao", ""], ["Motz", "Thomas", ""], ["Scheidt", "Michael", ""], ["Hartel", "Andreas", ""], ["Koch", "Andreas", ""], ["Kasneci", "Enkelejda", ""]]}, {"id": "2010.00857", "submitter": "Vani Kanjirangat", "authors": "K Vani, Sandra Mitrovic, Alessandro Antonucci, Fabio Rinaldi", "title": "SST-BERT at SemEval-2020 Task 1: Semantic Shift Tracing by Clustering in\n  BERT-based Embedding Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical semantic change detection (also known as semantic shift tracing) is a\ntask of identifying words that have changed their meaning over time.\nUnsupervised semantic shift tracing, focal point of SemEval2020, is\nparticularly challenging. Given the unsupervised setup, in this work, we\npropose to identify clusters among different occurrences of each target word,\nconsidering these as representatives of different word meanings. As such,\ndisagreements in obtained clusters naturally allow to quantify the level of\nsemantic shift per each target word in four target languages. To leverage this\nidea, clustering is performed on contextualized (BERT-based) embeddings of word\noccurrences. The obtained results show that our approach performs well both\nmeasured separately (per language) and overall, where we surpass all provided\nSemEval baselines.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 08:38:40 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Vani", "K", ""], ["Mitrovic", "Sandra", ""], ["Antonucci", "Alessandro", ""], ["Rinaldi", "Fabio", ""]]}, {"id": "2010.00860", "submitter": "Claire N\\'edellec", "authors": "Claire N\\'edellec, Wiktoria Golik, Sophie Aubin, Robert Bossy", "title": "Building Large Lexicalized Ontologies from Text: a Use Case in Automatic\n  Indexing of Biotechnology Patents", "comments": null, "journal-ref": "International Conference on Knowledge Engineering and Knowledge\n  Management. EKAW 2010. Lecture Notes in Computer Science, vol 6317. (pp.\n  514-523) Springer, Berlin, Heidelberg", "doi": "10.1007/978-3-642-16438-5_41", "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a tool, TyDI, and methods experimented in the building of\na termino-ontology, i.e. a lexicalized ontology aimed at fine-grained\nindexation for semantic search applications. TyDI provides facilities for\nknowledge engineers and domain experts to efficiently collaborate to validate,\norganize and conceptualize corpus extracted terms. A use case on biotechnology\npatent search demonstrates TyDI's potential.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 08:42:56 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["N\u00e9dellec", "Claire", ""], ["Golik", "Wiktoria", ""], ["Aubin", "Sophie", ""], ["Bossy", "Robert", ""]]}, {"id": "2010.00889", "submitter": "An Nguyen", "authors": "An Nguyen, Srijeet Chatterjee, Sven Weinzierl, Leo Schwinn, Martin\n  Matzner and Bjoern Eskofier", "title": "Time Matters: Time-Aware LSTMs for Predictive Business Process\n  Monitoring", "comments": "12 pages, 4 figures, to be published in post-workshop proceedings\n  volume in the series Lecture Notes in Business Information Processing (LNBIP)\n  - 1st International Workshop on Leveraging Machine Learning in Process Mining\n  (ML4PM) @ ICPM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive business process monitoring (PBPM) aims to predict future process\nbehavior during ongoing process executions based on event log data. Especially,\ntechniques for the next activity and timestamp prediction can help to improve\nthe performance of operational business processes. Recently, many PBPM\nsolutions based on deep learning were proposed by researchers. Due to the\nsequential nature of event log data, a common choice is to apply recurrent\nneural networks with long short-term memory (LSTM) cells. We argue, that the\nelapsed time between events is informative. However, current PBPM techniques\nmainly use 'vanilla' LSTM cells and hand-crafted time-related control flow\nfeatures. To better model the time dependencies between events, we propose a\nnew PBPM technique based on time-aware LSTM (T-LSTM) cells. T-LSTM cells\nincorporate the elapsed time between consecutive events inherently to adjust\nthe cell memory. Furthermore, we introduce cost-sensitive learning to account\nfor the common class imbalance in event logs. Our experiments on publicly\navailable benchmark event logs indicate the effectiveness of the introduced\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 09:37:07 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 08:10:26 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 12:59:59 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Nguyen", "An", ""], ["Chatterjee", "Srijeet", ""], ["Weinzierl", "Sven", ""], ["Schwinn", "Leo", ""], ["Matzner", "Martin", ""], ["Eskofier", "Bjoern", ""]]}, {"id": "2010.00979", "submitter": "Henry Moss", "authors": "Henry B. Moss, Daniel Beck, Javier Gonzalez, David S. Leslie, Paul\n  Rayson", "title": "BOSS: Bayesian Optimization over String Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article develops a Bayesian optimization (BO) method which acts directly\nover raw strings, proposing the first uses of string kernels and genetic\nalgorithms within BO loops. Recent applications of BO over strings have been\nhindered by the need to map inputs into a smooth and unconstrained latent\nspace. Learning this projection is computationally and data-intensive. Our\napproach instead builds a powerful Gaussian process surrogate model based on\nstring kernels, naturally supporting variable length inputs, and performs\nefficient acquisition function maximization for spaces with syntactical\nconstraints. Experiments demonstrate considerably improved optimization over\nexisting approaches across a broad range of constraints, including the popular\nsetting where syntax is governed by a context-free grammar.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 13:18:27 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Moss", "Henry B.", ""], ["Beck", "Daniel", ""], ["Gonzalez", "Javier", ""], ["Leslie", "David S.", ""], ["Rayson", "Paul", ""]]}, {"id": "2010.00989", "submitter": "Chengjin Xu", "authors": "Chengjin Xu, Mojtaba Nayyeri, Yung-Yu Chen, Jens Lehmann", "title": "Knowledge Graph Embeddings in Geometric Algebras", "comments": "This paper is accepted by COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph (KG) embedding aims at embedding entities and relations in a\nKG into a lowdimensional latent representation space. Existing KG embedding\napproaches model entities andrelations in a KG by utilizing real-valued ,\ncomplex-valued, or hypercomplex-valued (Quaternionor Octonion) representations,\nall of which are subsumed into a geometric algebra. In this work,we introduce a\nnovel geometric algebra-based KG embedding framework, GeomE, which uti-lizes\nmultivector representations and the geometric product to model entities and\nrelations. Ourframework subsumes several state-of-the-art KG embedding\napproaches and is advantageouswith its ability of modeling various key relation\npatterns, including (anti-)symmetry, inversionand composition, rich\nexpressiveness with higher degree of freedom as well as good general-ization\ncapacity. Experimental results on multiple benchmark knowledge graphs show that\ntheproposed approach outperforms existing state-of-the-art models for link\nprediction.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 13:36:24 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 14:30:10 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 00:03:21 GMT"}, {"version": "v4", "created": "Mon, 22 Mar 2021 18:59:42 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Xu", "Chengjin", ""], ["Nayyeri", "Mojtaba", ""], ["Chen", "Yung-Yu", ""], ["Lehmann", "Jens", ""]]}, {"id": "2010.01004", "submitter": "Pascal Kerschke", "authors": "Vera Steinhoff and Pascal Kerschke and Pelin Aspar and Heike Trautmann\n  and Christian Grimme", "title": "Multiobjectivization of Local Search: Single-Objective Optimization\n  Benefits From Multi-Objective Gradient Descent", "comments": "This version has been accepted for publication at the IEEE Symposium\n  Series on Computational Intelligence (IEEE SSCI) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodality is one of the biggest difficulties for optimization as local\noptima are often preventing algorithms from making progress. This does not only\nchallenge local strategies that can get stuck. It also hinders meta-heuristics\nlike evolutionary algorithms in convergence to the global optimum. In this\npaper we present a new concept of gradient descent, which is able to escape\nlocal traps. It relies on multiobjectivization of the original problem and\napplies the recently proposed and here slightly modified multi-objective local\nsearch mechanism MOGSA. We use a sophisticated visualization technique for\nmulti-objective problems to prove the working principle of our idea. As such,\nthis work highlights the transfer of new insights from the multi-objective to\nthe single-objective domain and provides first visual evidence that\nmultiobjectivization can link single-objective local optima in multimodal\nlandscapes.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 13:56:44 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Steinhoff", "Vera", ""], ["Kerschke", "Pascal", ""], ["Aspar", "Pelin", ""], ["Trautmann", "Heike", ""], ["Grimme", "Christian", ""]]}, {"id": "2010.01029", "submitter": "Chengjin Xu", "authors": "Chengjin Xu, Mojtaba Nayyeri, Fouad Alkhoury, Hamed Shariat Yazdi,\n  Jens Lehmann", "title": "TeRo: A Time-aware Knowledge Graph Embedding via Temporal Rotation", "comments": "This paper is accepted by COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, there has been a surge of interest in learning\nrepresentations of entitiesand relations in knowledge graph (KG). However, the\nrecent availability of temporal knowledgegraphs (TKGs) that contain time\ninformation for each fact created the need for reasoning overtime in such TKGs.\nIn this regard, we present a new approach of TKG embedding, TeRo, which defines\nthe temporal evolution of entity embedding as a rotation from the initial time\nto the currenttime in the complex vector space. Specially, for facts involving\ntime intervals, each relation isrepresented as a pair of dual complex\nembeddings to handle the beginning and the end of therelation, respectively. We\nshow our proposed model overcomes the limitations of the existing KG embedding\nmodels and TKG embedding models and has the ability of learning and\ninferringvarious relation patterns over time. Experimental results on four\ndifferent TKGs show that TeRo significantly outperforms existing\nstate-of-the-art models for link prediction. In addition, we analyze the effect\nof time granularity on link prediction over TKGs, which as far as we know\nhasnot been investigated in previous literature.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 14:35:27 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 22:42:26 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Xu", "Chengjin", ""], ["Nayyeri", "Mojtaba", ""], ["Alkhoury", "Fouad", ""], ["Yazdi", "Hamed Shariat", ""], ["Lehmann", "Jens", ""]]}, {"id": "2010.01047", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge, Alexander Tschantz, Anil Seth, Christopher L Buckley", "title": "Relaxing the Constraints on Predictive Coding Models", "comments": "02/10/20 initial upload; 10/10/20 minor fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive coding is an influential theory of cortical function which posits\nthat the principal computation the brain performs, which underlies both\nperception and learning, is the minimization of prediction errors. While\nmotivated by high-level notions of variational inference, detailed\nneurophysiological models of cortical microcircuits which can implements its\ncomputations have been developed. Moreover, under certain conditions,\npredictive coding has been shown to approximate the backpropagation of error\nalgorithm, and thus provides a relatively biologically plausible\ncredit-assignment mechanism for training deep networks. However, standard\nimplementations of the algorithm still involve potentially neurally implausible\nfeatures such as identical forward and backward weights, backward nonlinear\nderivatives, and 1-1 error unit connectivity. In this paper, we show that these\nfeatures are not integral to the algorithm and can be removed either directly\nor through learning additional sets of parameters with Hebbian update rules\nwithout noticeable harm to learning performance. Our work thus relaxes current\nconstraints on potential microcircuit designs and hopefully opens up new\nregions of the design-space for neuromorphic implementations of predictive\ncoding.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 15:21:37 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 14:09:12 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Millidge", "Beren", ""], ["Tschantz", "Alexander", ""], ["Seth", "Anil", ""], ["Buckley", "Christopher L", ""]]}, {"id": "2010.01062", "submitter": "Luisa Zintgraf", "authors": "Luisa Zintgraf, Leo Feng, Cong Lu, Maximilian Igl, Kristian\n  Hartikainen, Katja Hofmann, Shimon Whiteson", "title": "Exploration in Approximate Hyper-State Space for Meta Reinforcement\n  Learning", "comments": "Published at the International Conference on Machine Learning (ICML)\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To rapidly learn a new task, it is often essential for agents to explore\nefficiently -- especially when performance matters from the first timestep. One\nway to learn such behaviour is via meta-learning. Many existing methods however\nrely on dense rewards for meta-training, and can fail catastrophically if the\nrewards are sparse. Without a suitable reward signal, the need for exploration\nduring meta-training is exacerbated. To address this, we propose HyperX, which\nuses novel reward bonuses for meta-training to explore in approximate\nhyper-state space (where hyper-states represent the environment state and the\nagent's task belief). We show empirically that HyperX meta-learns better\ntask-exploration and adapts more successfully to new tasks than existing\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 15:43:31 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 17:37:11 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 21:43:46 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Zintgraf", "Luisa", ""], ["Feng", "Leo", ""], ["Lu", "Cong", ""], ["Igl", "Maximilian", ""], ["Hartikainen", "Kristian", ""], ["Hofmann", "Katja", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2010.01069", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Romain Laroche, Harm van Seijen, Shimon Whiteson,\n  Remi Tachet des Combes", "title": "A Deeper Look at Discounting Mismatch in Actor-Critic Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the discounting mismatch in actor-critic algorithm\nimplementations from a representation learning perspective. Theoretically,\nactor-critic algorithms usually have discounting for both actor and critic,\ni.e., there is a $\\gamma^t$ term in the actor update for the transition\nobserved at time $t$ in a trajectory and the critic is a discounted value\nfunction. Practitioners, however, usually ignore the discounting ($\\gamma^t$)\nfor the actor while using a discounted critic. We investigate this mismatch in\ntwo scenarios. In the first scenario, we consider optimizing an undiscounted\nobjective $(\\gamma = 1)$ where $\\gamma^t$ disappears naturally $(1^t = 1)$. We\nthen propose to interpret the discounting in critic in terms of a\nbias-variance-representation trade-off and provide supporting empirical\nresults. In the second scenario, we consider optimizing a discounted objective\n($\\gamma < 1$) and propose to interpret the omission of the discounting in the\nactor update from an auxiliary task perspective and provide supporting\nempirical results.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 15:51:48 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2021 17:59:12 GMT"}, {"version": "v3", "created": "Tue, 25 May 2021 20:40:55 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Zhang", "Shangtong", ""], ["Laroche", "Romain", ""], ["van Seijen", "Harm", ""], ["Whiteson", "Shimon", ""], ["Combes", "Remi Tachet des", ""]]}, {"id": "2010.01082", "submitter": "Kurt Shuster", "authors": "Kurt Shuster, Eric Michael Smith, Da Ju, Jason Weston", "title": "Multi-Modal Open-Domain Dialogue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in open-domain conversational agents has demonstrated that\nsignificant improvements in model engagingness and humanness metrics can be\nachieved via massive scaling in both pre-training data and model size\n(Adiwardana et al., 2020; Roller et al., 2020). However, if we want to build\nagents with human-like abilities, we must expand beyond handling just text. A\nparticularly important topic is the ability to see images and communicate about\nwhat is perceived. With the goal of engaging humans in multi-modal dialogue, we\ninvestigate combining components from state-of-the-art open-domain dialogue\nagents with those from state-of-the-art vision models. We study incorporating\ndifferent image fusion schemes and domain-adaptive pre-training and fine-tuning\nstrategies, and show that our best resulting model outperforms strong existing\nmodels in multi-modal dialogue while simultaneously performing as well as its\npredecessor (text-only) BlenderBot (Roller et al., 2020) in text-based\nconversation. We additionally investigate and incorporate safety components in\nour final model, and show that such efforts do not diminish model performance\nwith respect to engagingness metrics.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 16:20:39 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Shuster", "Kurt", ""], ["Smith", "Eric Michael", ""], ["Ju", "Da", ""], ["Weston", "Jason", ""]]}, {"id": "2010.01083", "submitter": "Caelan Garrett", "authors": "Caelan Reed Garrett, Rohan Chitnis, Rachel Holladay, Beomjoon Kim, Tom\n  Silver, Leslie Pack Kaelbling and Tom\\'as Lozano-P\\'erez", "title": "Integrated Task and Motion Planning", "comments": "Accepted to the Annual Review of Control, Robotics, and Autonomous\n  Systems. Vol. 4 (Volume publication date May 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of planning for a robot that operates in environments containing\na large number of objects, taking actions to move itself through the world as\nwell as to change the state of the objects, is known as task and motion\nplanning (TAMP). TAMP problems contain elements of discrete task planning,\ndiscrete-continuous mathematical programming, and continuous motion planning,\nand thus cannot be effectively addressed by any of these fields directly. In\nthis paper, we define a class of TAMP problems and survey algorithms for\nsolving them, characterizing the solution methods in terms of their strategies\nfor solving the continuous-space subproblems and their techniques for\nintegrating the discrete and continuous components of the search.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 16:23:08 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Garrett", "Caelan Reed", ""], ["Chitnis", "Rohan", ""], ["Holladay", "Rachel", ""], ["Kim", "Beomjoon", ""], ["Silver", "Tom", ""], ["Kaelbling", "Leslie Pack", ""], ["Lozano-P\u00e9rez", "Tom\u00e1s", ""]]}, {"id": "2010.01087", "submitter": "Giuseppe Cota", "authors": "Giuseppe Cota and Riccardo Zese and Elena Bellodi and Evelina Lamma\n  and Fabrizio Riguzzi", "title": "A Framework for Reasoning on Probabilistic Description Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there exist several reasoners for Description Logics, very few of them\ncan cope with uncertainty. BUNDLE is an inference framework that can exploit\nseveral OWL (non-probabilistic) reasoners to perform inference over\nProbabilistic Description Logics.\n  In this chapter, we report the latest advances implemented in BUNDLE. In\nparticular, BUNDLE can now interface with the reasoners of the TRILL system,\nthus providing a uniform method to execute probabilistic queries using\ndifferent settings. BUNDLE can be easily extended and can be used either as a\nstandalone desktop application or as a library in OWL API-based applications\nthat need to reason over Probabilistic Description Logics.\n  The reasoning performance heavily depends on the reasoner and method used to\ncompute the probability. We provide a comparison of the different reasoning\nsettings on several datasets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 16:41:06 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Cota", "Giuseppe", ""], ["Zese", "Riccardo", ""], ["Bellodi", "Elena", ""], ["Lamma", "Evelina", ""], ["Riguzzi", "Fabrizio", ""]]}, {"id": "2010.01164", "submitter": "Carmine Dodaro", "authors": "Riccardo Bertolucci, Alessio Capitanelli, Carmine Dodaro, Nicola\n  Leone, Marco Maratea, Fulvio Mastrogiovanni, Mauro Vallati", "title": "Manipulation of Articulated Objects using Dual-arm Robots via Answer Set\n  Programming", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The manipulation of articulated objects is of primary importance in Robotics,\nand can be considered as one of the most complex manipulation tasks.\nTraditionally, this problem has been tackled by developing ad-hoc approaches,\nwhich lack flexibility and portability.\n  In this paper we present a framework based on Answer Set Programming (ASP)\nfor the automated manipulation of articulated objects in a robot control\narchitecture. In particular, ASP is employed for representing the configuration\nof the articulated object, for checking the consistency of such representation\nin the knowledge base, and for generating the sequence of manipulation actions.\n  The framework is exemplified and validated on the Baxter dual-arm manipulator\nin a first, simple scenario. Then, we extend such scenario to improve the\noverall setup accuracy, and to introduce a few constraints in robot actions\nexecution to enforce their feasibility. The extended scenario entails a high\nnumber of possible actions that can be fruitfully combined together. Therefore,\nwe exploit macro actions from automated planning in order to provide more\neffective plans. We validate the overall framework in the extended scenario,\nthereby confirming the applicability of ASP also in more realistic Robotics\nsettings, and showing the usefulness of macro actions for the robot-based\nmanipulation of articulated objects. Under consideration in Theory and Practice\nof Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 18:50:39 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Bertolucci", "Riccardo", ""], ["Capitanelli", "Alessio", ""], ["Dodaro", "Carmine", ""], ["Leone", "Nicola", ""], ["Maratea", "Marco", ""], ["Mastrogiovanni", "Fulvio", ""], ["Vallati", "Mauro", ""]]}, {"id": "2010.01165", "submitter": "Zeljko Kraljevic", "authors": "Zeljko Kraljevic, Thomas Searle, Anthony Shek, Lukasz Roguski, Kawsar\n  Noor, Daniel Bean, Aurelie Mascio, Leilei Zhu, Amos A Folarin, Angus Roberts,\n  Rebecca Bendayan, Mark P Richardson, Robert Stewart, Anoop D Shah, Wai Keong\n  Wong, Zina Ibrahim, James T Teo, Richard JB Dobson", "title": "Multi-domain Clinical Natural Language Processing with MedCAT: the\n  Medical Concept Annotation Toolkit", "comments": "Preprint: 27 Pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health records (EHR) contain large volumes of unstructured text,\nrequiring the application of Information Extraction (IE) technologies to enable\nclinical analysis. We present the open-source Medical Concept Annotation\nToolkit (MedCAT) that provides: a) a novel self-supervised machine learning\nalgorithm for extracting concepts using any concept vocabulary including\nUMLS/SNOMED-CT; b) a feature-rich annotation interface for customising and\ntraining IE models; and c) integrations to the broader CogStack ecosystem for\nvendor-agnostic health system deployment. We show improved performance in\nextracting UMLS concepts from open datasets (F1:0.448-0.738 vs 0.429-0.650).\nFurther real-world validation demonstrates SNOMED-CT extraction at 3 large\nLondon hospitals with self-supervised training over ~8.8B words from ~17M\nclinical records and further fine-tuning with ~6K clinician annotated examples.\nWe show strong transferability (F1 > 0.94) between hospitals, datasets, and\nconcept types indicating cross-domain EHR-agnostic utility for accelerated\nclinical and research use cases.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 19:01:02 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 13:21:50 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Kraljevic", "Zeljko", ""], ["Searle", "Thomas", ""], ["Shek", "Anthony", ""], ["Roguski", "Lukasz", ""], ["Noor", "Kawsar", ""], ["Bean", "Daniel", ""], ["Mascio", "Aurelie", ""], ["Zhu", "Leilei", ""], ["Folarin", "Amos A", ""], ["Roberts", "Angus", ""], ["Bendayan", "Rebecca", ""], ["Richardson", "Mark P", ""], ["Stewart", "Robert", ""], ["Shah", "Anoop D", ""], ["Wong", "Wai Keong", ""], ["Ibrahim", "Zina", ""], ["Teo", "James T", ""], ["Dobson", "Richard JB", ""]]}, {"id": "2010.01175", "submitter": "Lun Wang", "authors": "Lun Wang, Qi Pang, Shuai Wang and Dawn Song", "title": "Towards Bidirectional Protection in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prior efforts in enhancing federated learning (FL) security fall into two\ncategories. At one end of the spectrum, some work uses secure aggregation\ntechniques to hide the individual client's updates and only reveal the\naggregated global update to a malicious server that strives to infer the\nclients' privacy from their updates. At the other end of the spectrum, some\nwork uses Byzantine-robust FL protocols to suppress the influence of malicious\nclients' updates. We present a federated learning protocol F2ED-LEARNING,\nwhich, for the first time, offers bidirectional defense to simultaneously\ncombat against the malicious centralized server and Byzantine malicious\nclients. To defend against Byzantine malicious clients, F2ED-LEARNING provides\ndimension-free estimation error by employing and calibrating a well-studied\nrobust mean estimator FilterL2. F2ED-LEARNING also leverages secure aggregation\nto protect clients from a malicious server. One key challenge of F2ED-LEARNING\nis to address the incompatibility between FilterL2 and secure aggregation\nschemes. Concretely, FilterL2 has to check the individual updates from clients\nwhereas secure aggregation hides those updates from the malicious server. To\nthis end, we propose a practical and highly effective solution to split the\nclients into shards, where F2ED-LEARNING securely aggregates each shard's\nupdate and launches FilterL2 on updates from different shards. The evaluation\nshows that F2ED-LEARNING consistently achieves optimal or close-to-optimal\nperformance and outperforms five secure FL protocols under five popular\nattacks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 19:37:02 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 20:24:12 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Lun", ""], ["Pang", "Qi", ""], ["Wang", "Shuai", ""], ["Song", "Dawn", ""]]}, {"id": "2010.01179", "submitter": "Ralph Abboud", "authors": "Ralph Abboud, \\.Ismail \\.Ilkan Ceylan, Martin Grohe, Thomas\n  Lukasiewicz", "title": "The Surprising Power of Graph Neural Networks with Random Node\n  Initialization", "comments": "Proceedings of the Thirtieth International Joint Conference on\n  Artificial Intelligence (IJCAI-21). Code and data available at\n  http://www.github.com/ralphabb/GNN-RNI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are effective models for representation learning\non relational data. However, standard GNNs are limited in their expressive\npower, as they cannot distinguish graphs beyond the capability of the\nWeisfeiler-Leman graph isomorphism heuristic. In order to break this\nexpressiveness barrier, GNNs have been enhanced with random node initialization\n(RNI), where the idea is to train and run the models with randomized initial\nnode features. In this work, we analyze the expressive power of GNNs with RNI,\nand prove that these models are universal, a first such result for GNNs not\nrelying on computationally demanding higher-order properties. This universality\nresult holds even with partially randomized initial node features, and\npreserves the invariance properties of GNNs in expectation. We then empirically\nanalyze the effect of RNI on GNNs, based on carefully constructed datasets. Our\nempirical findings support the superior performance of GNNs with RNI over\nstandard GNNs.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 19:53:05 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 14:52:04 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Abboud", "Ralph", ""], ["Ceylan", "\u0130smail \u0130lkan", ""], ["Grohe", "Martin", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "2010.01180", "submitter": "Gianluca Brero", "authors": "Gianluca Brero, Alon Eden, Matthias Gerstgrasser, David C. Parkes,\n  Duncan Rheingans-Yoo", "title": "Reinforcement Learning of Sequential Price Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the use of reinforcement learning for indirect mechanisms,\nworking with the existing class of sequential price mechanisms, which\ngeneralizes both serial dictatorship and posted price mechanisms and\nessentially characterizes all strongly obviously strategyproof mechanisms.\nLearning an optimal mechanism within this class forms a partially-observable\nMarkov decision process. We provide rigorous conditions for when this class of\nmechanisms is more powerful than simpler static mechanisms, for sufficiency or\ninsufficiency of observation statistics for learning, and for the necessity of\ncomplex (deep) policies. We show that our approach can learn optimal or\nnear-optimal mechanisms in several experimental settings.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 19:57:25 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 20:01:05 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Brero", "Gianluca", ""], ["Eden", "Alon", ""], ["Gerstgrasser", "Matthias", ""], ["Parkes", "David C.", ""], ["Rheingans-Yoo", "Duncan", ""]]}, {"id": "2010.01184", "submitter": "Felipe Maia Polo", "authors": "Felipe Maia Polo, Renato Vicente", "title": "Covariate Shift Adaptation in High-Dimensional and Divergent\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real world applications of supervised learning methods, training and test\nsets are often sampled from the distinct distributions and we must resort to\ndomain adaptation techniques. One special class of techniques is Covariate\nShift Adaptation, which allows practitioners to obtain good generalization\nperformance in the distribution of interest when domains differ only by the\nmarginal distribution of features. Traditionally, Covariate Shift Adaptation is\nimplemented using Importance Weighting which may fail in high-dimensional\nsettings due to small Effective Sample Sizes (ESS). In this paper, we propose\n(i) a connection between ESS, high-dimensional settings and generalization\nbounds and (ii) a simple, general and theoretically sound approach to combine\nfeature selection and Covariate Shift Adaptation. The new approach yields good\nperformance with improved ESS.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 20:22:59 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 19:27:37 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Polo", "Felipe Maia", ""], ["Vicente", "Renato", ""]]}, {"id": "2010.01192", "submitter": "Sanjeevan Ahilan", "authors": "Sanjeevan Ahilan, Peter Dayan", "title": "Correcting Experience Replay for Multi-Agent Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning to communicate using multi-agent\nreinforcement learning (MARL). A common approach is to learn off-policy, using\ndata sampled from a replay buffer. However, messages received in the past may\nnot accurately reflect the current communication policy of each agent, and this\ncomplicates learning. We therefore introduce a 'communication correction' which\naccounts for the non-stationarity of observed communication induced by\nmulti-agent learning. It works by relabelling the received message to make it\nlikely under the communicator's current policy, and thus be a better reflection\nof the receiver's current environment. To account for cases in which agents are\nboth senders and receivers, we introduce an ordered relabelling scheme. Our\ncorrection is computationally efficient and can be integrated with a range of\noff-policy algorithms. We find in our experiments that it substantially\nimproves the ability of communicating MARL systems to learn across a variety of\ncooperative and competitive tasks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 20:49:24 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 22:42:12 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Ahilan", "Sanjeevan", ""], ["Dayan", "Peter", ""]]}, {"id": "2010.01196", "submitter": "Yuanqing Wang", "authors": "Yuanqing Wang, Josh Fass, John D. Chodera", "title": "End-to-End Differentiable Molecular Mechanics Force Field Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular mechanics (MM) potentials have long been a workhorse of\ncomputational chemistry. Leveraging accuracy and speed, these functional forms\nfind use in a wide variety of applications from rapid virtual screening to\ndetailed free energy calculations. Traditionally, MM potentials have relied on\nhuman-curated, inflexible, and poorly extensible discrete chemical perception\nrules (atom types) for applying parameters to molecules or biopolymers, making\nthem difficult to optimize to fit quantum chemical or physical property data.\nHere, we propose an alternative approach that uses graph nets to perceive\nchemical environments, producing continuous atom embeddings from which valence\nand nonbonded parameters can be predicted using a feed-forward neural network.\nSince all stages are built using smooth functions, the entire process of\nchemical perception and parameter assignment is differentiable end-to-end with\nrespect to model parameters, allowing new force fields to be easily\nconstructed, extended, and applied to arbitrary molecules. We show that this\napproach has the capacity to reproduce legacy atom types and can be fit to MM\nand QM energies and forces, among other targets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 20:59:46 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wang", "Yuanqing", ""], ["Fass", "Josh", ""], ["Chodera", "John D.", ""]]}, {"id": "2010.01207", "submitter": "Xin Zhang", "authors": "Xin Zhang, Yanhua Li, Ziming Zhang, Zhi-Li Zhang", "title": "$f$-GAIL: Learning $f$-Divergence for Generative Adversarial Imitation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning (IL) aims to learn a policy from expert demonstrations\nthat minimizes the discrepancy between the learner and expert behaviors.\nVarious imitation learning algorithms have been proposed with different\npre-determined divergences to quantify the discrepancy. This naturally gives\nrise to the following question: Given a set of expert demonstrations, which\ndivergence can recover the expert policy more accurately with higher data\nefficiency? In this work, we propose $f$-GAIL, a new generative adversarial\nimitation learning (GAIL) model, that automatically learns a discrepancy\nmeasure from the $f$-divergence family as well as a policy capable of producing\nexpert-like behaviors. Compared with IL baselines with various predefined\ndivergence measures, $f$-GAIL learns better policies with higher data\nefficiency in six physics-based control tasks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 21:39:56 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 05:29:20 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Zhang", "Xin", ""], ["Li", "Yanhua", ""], ["Zhang", "Ziming", ""], ["Zhang", "Zhi-Li", ""]]}, {"id": "2010.01247", "submitter": "Zhun Deng", "authors": "Zhun Deng, Cynthia Dwork, Jialiang Wang, Linjun Zhang", "title": "Interpreting Robust Optimization via Adversarial Influence Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust optimization has been widely used in nowadays data science, especially\nin adversarial training. However, little research has been done to quantify how\nrobust optimization changes the optimizers and the prediction losses comparing\nto standard training. In this paper, inspired by the influence function in\nrobust statistics, we introduce the Adversarial Influence Function (AIF) as a\ntool to investigate the solution produced by robust optimization. The proposed\nAIF enjoys a closed-form and can be calculated efficiently. To illustrate the\nusage of AIF, we apply it to study model sensitivity -- a quantity defined to\ncapture the change of prediction losses on the natural data after implementing\nrobust optimization. We use AIF to analyze how model complexity and randomized\nsmoothing affect the model sensitivity with respect to specific models. We\nfurther derive AIF for kernel regressions, with a particular application to\nneural tangent kernels, and experimentally demonstrate the effectiveness of the\nproposed AIF. Lastly, the theories of AIF will be extended to distributional\nrobust optimization.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 01:19:10 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Deng", "Zhun", ""], ["Dwork", "Cynthia", ""], ["Wang", "Jialiang", ""], ["Zhang", "Linjun", ""]]}, {"id": "2010.01251", "submitter": "Jingfei Chang", "authors": "Jingfei Chang and Yang Lu and Ping Xue and Xing Wei and Zhen Wei", "title": "UCP: Uniform Channel Pruning for Deep Convolutional Neural Networks\n  Compression and Acceleration", "comments": "21 pages,7 figures and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To apply deep CNNs to mobile terminals and portable devices, many scholars\nhave recently worked on the compressing and accelerating deep convolutional\nneural networks. Based on this, we propose a novel uniform channel pruning\n(UCP) method to prune deep CNN, and the modified squeeze-and-excitation blocks\n(MSEB) is used to measure the importance of the channels in the convolutional\nlayers. The unimportant channels, including convolutional kernels related to\nthem, are pruned directly, which greatly reduces the storage cost and the\nnumber of calculations. There are two types of residual blocks in ResNet. For\nResNet with bottlenecks, we use the pruning method with traditional CNN to trim\nthe 3x3 convolutional layer in the middle of the blocks. For ResNet with basic\nresidual blocks, we propose an approach to consistently prune all residual\nblocks in the same stage to ensure that the compact network structure is\ndimensionally correct. Considering that the network loses considerable\ninformation after pruning and that the larger the pruning amplitude is, the\nmore information that will be lost, we do not choose fine-tuning but retrain\nfrom scratch to restore the accuracy of the network after pruning. Finally, we\nverified our method on CIFAR-10, CIFAR-100 and ILSVRC-2012 for image\nclassification. The results indicate that the performance of the compact\nnetwork after retraining from scratch, when the pruning rate is small, is\nbetter than the original network. Even when the pruning amplitude is large, the\naccuracy can be maintained or decreased slightly. On the CIFAR-100, when\nreducing the parameters and FLOPs up to 82% and 62% respectively, the accuracy\nof VGG-19 even improved by 0.54% after retraining.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 01:51:06 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Chang", "Jingfei", ""], ["Lu", "Yang", ""], ["Xue", "Ping", ""], ["Wei", "Xing", ""], ["Wei", "Zhen", ""]]}, {"id": "2010.01278", "submitter": "Quanquan Gu", "authors": "Jinghui Chen and Yu Cheng and Zhe Gan and Quanquan Gu and Jingjing Liu", "title": "Efficient Robust Training via Backward Smoothing", "comments": "12 pages, 11 tables, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is so far the most effective strategy in defending\nagainst adversarial examples. However, it suffers from high computational cost\ndue to the iterative adversarial attacks in each training step. Recent studies\nshow that it is possible to achieve Fast Adversarial Training by performing a\nsingle-step attack with random initialization. Yet, it remains a mystery why\nrandom initialization helps. Besides, such an approach still lags behind\nstate-of-the-art adversarial training algorithms on both stability and model\nrobustness. In this work, we develop a new understanding towards Fast\nAdversarial Training, by viewing random initialization as performing randomized\nsmoothing for better optimization of the inner maximization problem. From this\nperspective, we show that the smoothing effect by random initialization is not\nsufficient under the adversarial perturbation constraint. A new initialization\nstrategy, backward smoothing, is proposed to address this issue and\nsignificantly improves both stability and model robustness over single-step\nrobust training methods.Experiments on multiple benchmarks demonstrate that our\nmethod achieves similar model robustness as the original TRADES method, while\nusing much less training time ($\\sim$3x improvement with the same training\nschedule).\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 04:37:33 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Chen", "Jinghui", ""], ["Cheng", "Yu", ""], ["Gan", "Zhe", ""], ["Gu", "Quanquan", ""], ["Liu", "Jingjing", ""]]}, {"id": "2010.01279", "submitter": "Quanquan Gu", "authors": "Boxi Wu and Jinghui Chen and Deng Cai and Xiaofei He and Quanquan Gu", "title": "Do Wider Neural Networks Really Help Adversarial Robustness?", "comments": "18 pages, 3 tables, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is currently the most powerful defense against\nadversarial examples. Previous empirical results suggest that adversarial\ntraining requires wider networks for better performances. Yet, it remains\nelusive how does neural network width affect model robustness. In this paper,\nwe carefully examine the relation between network width and model robustness.\nWe present an intriguing phenomenon that the increased network width may not\nhelp robustness. Specifically, we show that the model robustness is closely\nrelated to both natural accuracy and perturbation stability, a new metric\nproposed in our paper to characterize the model's stability under adversarial\nperturbations. While better natural accuracy can be achieved on wider neural\nnetworks, the perturbation stability actually becomes worse, leading to a\npotentially worse overall model robustness. To understand the origin of this\nphenomenon, we further relate the perturbation stability with the network's\nlocal Lipschitznesss. By leveraging recent results on neural tangent kernels,\nwe show that larger network width naturally leads to worse perturbation\nstability. This suggests that to fully unleash the power of wide model\narchitecture, practitioners should adopt a larger regularization parameter for\ntraining wider networks. Experiments on benchmark datasets confirm that this\nstrategy could indeed alleviate the perturbation stability issue and improve\nthe state-of-the-art robust models.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 04:46:17 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 18:58:37 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Wu", "Boxi", ""], ["Chen", "Jinghui", ""], ["Cai", "Deng", ""], ["He", "Xiaofei", ""], ["Gu", "Quanquan", ""]]}, {"id": "2010.01298", "submitter": "Peter Karkus", "authors": "Peter Karkus, Mehdi Mirza, Arthur Guez, Andrew Jaegle, Timothy\n  Lillicrap, Lars Buesing, Nicolas Heess, Theophane Weber", "title": "Beyond Tabula-Rasa: a Modular Reinforcement Learning Approach for\n  Physically Embedded 3D Sokoban", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent robots need to achieve abstract objectives using concrete,\nspatiotemporally complex sensory information and motor control. Tabula rasa\ndeep reinforcement learning (RL) has tackled demanding tasks in terms of either\nvisual, abstract, or physical reasoning, but solving these jointly remains a\nformidable challenge. One recent, unsolved benchmark task that integrates these\nchallenges is Mujoban, where a robot needs to arrange 3D warehouses generated\nfrom 2D Sokoban puzzles. We explore whether integrated tasks like Mujoban can\nbe solved by composing RL modules together in a sense-plan-act hierarchy, where\nmodules have well-defined roles similarly to classic robot architectures.\nUnlike classic architectures that are typically model-based, we use only\nmodel-free modules trained with RL or supervised learning. We find that our\nmodular RL approach dramatically outperforms the state-of-the-art monolithic RL\nagent on Mujoban. Further, learned modules can be reused when, e.g., using a\ndifferent robot platform to solve the same task. Together our results give\nstrong evidence for the importance of research into modular RL designs. Project\nwebsite: https://sites.google.com/view/modular-rl/\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 07:48:06 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Karkus", "Peter", ""], ["Mirza", "Mehdi", ""], ["Guez", "Arthur", ""], ["Jaegle", "Andrew", ""], ["Lillicrap", "Timothy", ""], ["Buesing", "Lars", ""], ["Heess", "Nicolas", ""], ["Weber", "Theophane", ""]]}, {"id": "2010.01309", "submitter": "Amirmohammad Kazemeini", "authors": "Amirmohammad Kazameini, Samin Fatehi, Yash Mehta, Sauleh Eetemadi,\n  Erik Cambria", "title": "Personality Trait Detection Using Bagged SVM over BERT Word Embedding\n  Ensembles", "comments": null, "journal-ref": "Proceedings of the The Fourth Widening Natural Language Processing\n  Workshop (2020)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the automatic prediction of personality traits has received\nincreasing attention and has emerged as a hot topic within the field of\naffective computing. In this work, we present a novel deep learning-based\napproach for automated personality detection from text. We leverage state of\nthe art advances in natural language understanding, namely the BERT language\nmodel to extract contextualized word embeddings from textual data for automated\nauthor personality detection. Our primary goal is to develop a computationally\nefficient, high-performance personality prediction model which can be easily\nused by a large number of people without access to huge computation resources.\nOur extensive experiments with this ideology in mind, led us to develop a novel\nmodel which feeds contextualized embeddings along with psycholinguistic\nfeatures toa Bagged-SVM classifier for personality trait prediction. Our model\noutperforms the previous state of the art by 1.04% and, at the same time is\nsignificantly more computationally efficient to train. We report our results on\nthe famous gold standard Essays dataset for personality detection.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 09:25:51 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Kazameini", "Amirmohammad", ""], ["Fatehi", "Samin", ""], ["Mehta", "Yash", ""], ["Eetemadi", "Sauleh", ""], ["Cambria", "Erik", ""]]}, {"id": "2010.01351", "submitter": "Oriol Corcoll Andreu", "authors": "Oriol Corcoll and Raul Vicente", "title": "Disentangling causal effects for hierarchical reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Exploration and credit assignment under sparse rewards are still challenging\nproblems. We argue that these challenges arise in part due to the intrinsic\nrigidity of operating at the level of actions. Actions can precisely define how\nto perform an activity but are ill-suited to describe what activity to perform.\nInstead, causal effects are inherently composable and temporally abstract,\nmaking them ideal for descriptive tasks. By leveraging a hierarchy of causal\neffects, this study aims to expedite the learning of task-specific behavior and\naid exploration. Borrowing counterfactual and normality measures from causal\nliterature, we disentangle controllable effects from effects caused by other\ndynamics of the environment. We propose CEHRL, a hierarchical method that\nmodels the distribution of controllable effects using a Variational\nAutoencoder. This distribution is used by a high-level policy to 1) explore the\nenvironment via random effect exploration so that novel effects are\ncontinuously discovered and learned, and to 2) learn task-specific behavior by\nprioritizing the effects that maximize a given reward function. In comparison\nto exploring with random actions, experimental results show that random effect\nexploration is a more efficient mechanism and that by assigning credit to few\neffects rather than many actions, CEHRL learns tasks more rapidly.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 13:19:16 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Corcoll", "Oriol", ""], ["Vicente", "Raul", ""]]}, {"id": "2010.01367", "submitter": "Jiaoyang Li", "authors": "Jiaoyang Li, Wheeler Ruml, Sven Koenig", "title": "EECBS: A Bounded-Suboptimal Search for Multi-Agent Path Finding", "comments": "Published at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Agent Path Finding (MAPF), i.e., finding collision-free paths for\nmultiple robots, is important for many applications where small runtimes are\nnecessary, including the kind of automated warehouses operated by Amazon. CBS\nis a leading two-level search algorithm for solving MAPF optimally. ECBS is a\nbounded-suboptimal variant of CBS that uses focal search to speed up CBS by\nsacrificing optimality and instead guaranteeing that the costs of its solutions\nare within a given factor of optimal. In this paper, we study how to decrease\nits runtime even further using inadmissible heuristics. Motivated by Explicit\nEstimation Search (EES), we propose Explicit Estimation CBS (EECBS), a new\nbounded-suboptimal variant of CBS, that uses online learning to obtain\ninadmissible estimates of the cost of the solution of each high-level node and\nuses EES to choose which high-level node to expand next. We also investigate\nrecent improvements of CBS and adapt them to EECBS. We find that EECBS with the\nimprovements runs significantly faster than the state-of-the-art\nbounded-suboptimal MAPF algorithms ECBS, BCP-7, and eMDD-SAT on a variety of\nMAPF instances. We hope that the scalability of EECBS enables additional\napplications for bounded-suboptimal MAPF algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 14:19:00 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 19:00:29 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Li", "Jiaoyang", ""], ["Ruml", "Wheeler", ""], ["Koenig", "Sven", ""]]}, {"id": "2010.01374", "submitter": "Gellert Weisz", "authors": "Gell\\'ert Weisz, Philip Amortila, Csaba Szepesv\\'ari", "title": "Exponential Lower Bounds for Planning in MDPs With Linearly-Realizable\n  Optimal Action-Value Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of local planning in fixed-horizon and discounted\nMarkov Decision Processes (MDPs) with linear function approximation and a\ngenerative model under the assumption that the optimal action-value function\nlies in the span of a feature map that is available to the planner. Previous\nwork has left open the question of whether there exist sound planners that need\nonly poly(H,d) queries regardless of the MDP, where H is the horizon and d is\nthe dimensionality of the features. We answer this question in the negative: we\nshow that any sound planner must query at least $\\min(\\exp({\\Omega}(d)),\n{\\Omega}(2^H))$ samples in the fized-horizon setting and $\\exp({\\Omega}(d))$\nsamples in the discounted setting. We also show that for any ${\\delta}>0$, the\nleast-squares value iteration algorithm with $O(H^5d^{H+1}/{\\delta}^2)$ queries\ncan compute a ${\\delta}$-optimal policy in the fixed-horizon setting. We\ndiscuss implications and remaining open questions.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 15:19:26 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 22:44:00 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Weisz", "Gell\u00e9rt", ""], ["Amortila", "Philip", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "2010.01380", "submitter": "Elad Rapaport", "authors": "Elad Rapaport, Ingmar Poese, Polina Zilberman, Oliver Holschke, Rami\n  Puzis", "title": "Predicting traffic overflows on private peering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large content providers and content distribution network operators usually\nconnect with large Internet service providers (eyeball networks) through\ndedicated private peering. The capacity of these private network interconnects\nis provisioned to match the volume of the real content demand by the users.\nUnfortunately, in case of a surge in traffic demand, for example due to a\ncontent trending in a certain country, the capacity of the private interconnect\nmay deplete and the content provider/distributor would have to reroute the\nexcess traffic through transit providers. Although, such overflow events are\nrare, they have significant negative impacts on content providers, Internet\nservice providers, and end-users. These include unexpected delays and\ndisruptions reducing the user experience quality, as well as direct costs paid\nby the Internet service provider to the transit providers. If the traffic\noverflow events could be predicted, the Internet service providers would be\nable to influence the routes chosen for the excess traffic to reduce the costs\nand increase user experience quality. In this article we propose a method based\non an ensemble of deep learning models to predict overflow events over a short\nterm horizon of 2-6 hours and predict the specific interconnections that will\ningress the overflow traffic. The method was evaluated with 2.5 years' traffic\nmeasurement data from a large European Internet service provider resulting in a\ntrue-positive rate of 0.8 while maintaining a 0.05 false-positive rate. The\nlockdown imposed by the COVID-19 pandemic reduced the overflow prediction\naccuracy. Nevertheless, starting from the end of April 2020 with the gradual\nlockdown release, the old models trained before the pandemic perform equally\nwell.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 16:14:55 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Rapaport", "Elad", ""], ["Poese", "Ingmar", ""], ["Zilberman", "Polina", ""], ["Holschke", "Oliver", ""], ["Puzis", "Rami", ""]]}, {"id": "2010.01388", "submitter": "Mikhail Hushchyn", "authors": "Mikhail Hushchyn, Kenenbek Arzymatov, Denis Derkach", "title": "Online Neural Networks for Change-Point Detection", "comments": "24 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Moments when a time series changes its behaviour are called change points.\nDetection of such points is a well-known problem, which can be found in many\napplications: quality monitoring of industrial processes, failure detection in\ncomplex systems, health monitoring, speech recognition and video analysis.\nOccurrence of change point implies that the state of the system is altered and\nits timely detection might help to prevent unwanted consequences. In this\npaper, we present two online change-point detection approaches based on neural\nnetworks. These algorithms demonstrate linear computational complexity and are\nsuitable for change-point detection in large time series. We compare them with\nthe best known algorithms on various synthetic and real world data sets.\nExperiments show that the proposed methods outperform known approaches.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 16:55:59 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Hushchyn", "Mikhail", ""], ["Arzymatov", "Kenenbek", ""], ["Derkach", "Denis", ""]]}, {"id": "2010.01401", "submitter": "Sadaf Gulshad", "authors": "Sadaf Gulshad, Jan Hendrik Metzen, Arnold Smeulders", "title": "Adversarial and Natural Perturbations for General Robustness", "comments": "Currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we aim to explore the general robustness of neural network\nclassifiers by utilizing adversarial as well as natural perturbations.\nDifferent from previous works which mainly focus on studying the robustness of\nneural networks against adversarial perturbations, we also evaluate their\nrobustness on natural perturbations before and after robustification. After\nstandardizing the comparison between adversarial and natural perturbations, we\ndemonstrate that although adversarial training improves the performance of the\nnetworks against adversarial perturbations, it leads to drop in the performance\nfor naturally perturbed samples besides clean samples. In contrast, natural\nperturbations like elastic deformations, occlusions and wave does not only\nimprove the performance against natural perturbations, but also lead to\nimprovement in the performance for the adversarial perturbations. Additionally\nthey do not drop the accuracy on the clean images.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 17:53:18 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Gulshad", "Sadaf", ""], ["Metzen", "Jan Hendrik", ""], ["Smeulders", "Arnold", ""]]}, {"id": "2010.01417", "submitter": "Kun Xu", "authors": "Kun Xu and Haochen Tan and Linfeng Song and Han Wu and Haisong Zhang\n  and Linqi Song and Dong Yu", "title": "Semantic Role Labeling Guided Multi-turn Dialogue ReWriter", "comments": "To appear in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For multi-turn dialogue rewriting, the capacity of effectively modeling the\nlinguistic knowledge in dialog context and getting rid of the noises is\nessential to improve its performance. Existing attentive models attend to all\nwords without prior focus, which results in inaccurate concentration on some\ndispensable words. In this paper, we propose to use semantic role labeling\n(SRL), which highlights the core semantic information of who did what to whom,\nto provide additional guidance for the rewriter model. Experiments show that\nthis information significantly improves a RoBERTa-based model that already\noutperforms previous state-of-the-art systems.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 19:50:04 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Xu", "Kun", ""], ["Tan", "Haochen", ""], ["Song", "Linfeng", ""], ["Wu", "Han", ""], ["Zhang", "Haisong", ""], ["Song", "Linqi", ""], ["Yu", "Dong", ""]]}, {"id": "2010.01424", "submitter": "Pengchuan Zhang", "authors": "Yi Wei, Zhe Gan, Wenbo Li, Siwei Lyu, Ming-Ching Chang, Lei Zhang,\n  Jianfeng Gao, Pengchuan Zhang", "title": "MagGAN: High-Resolution Face Attribute Editing with Mask-Guided\n  Generative Adversarial Network", "comments": "published at ACCV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Mask-guided Generative Adversarial Network (MagGAN) for\nhigh-resolution face attribute editing, in which semantic facial masks from a\npre-trained face parser are used to guide the fine-grained image editing\nprocess. With the introduction of a mask-guided reconstruction loss, MagGAN\nlearns to only edit the facial parts that are relevant to the desired attribute\nchanges, while preserving the attribute-irrelevant regions (e.g., hat, scarf\nfor modification `To Bald'). Further, a novel mask-guided conditioning strategy\nis introduced to incorporate the influence region of each attribute change into\nthe generator. In addition, a multi-level patch-wise discriminator structure is\nproposed to scale our model for high-resolution ($1024 \\times 1024$) face\nediting. Experiments on the CelebA benchmark show that the proposed method\nsignificantly outperforms prior state-of-the-art approaches in terms of both\nimage quality and editing performance.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 20:56:16 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wei", "Yi", ""], ["Gan", "Zhe", ""], ["Li", "Wenbo", ""], ["Lyu", "Siwei", ""], ["Chang", "Ming-Ching", ""], ["Zhang", "Lei", ""], ["Gao", "Jianfeng", ""], ["Zhang", "Pengchuan", ""]]}, {"id": "2010.01429", "submitter": "Krenare Pireva Nuci", "authors": "Rinor Hajrizi and Krenare Pireva Nu\\c{c}i", "title": "Aspect-Based Sentiment Analysis in Education Domain", "comments": "Sentiment Analysis, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of a large amount of data has always brought value to institutions\nand organizations. Lately, people's opinions expressed through text have become\na very important aspect of this analysis. In response to this challenge, a\nnatural language processing technique known as Aspect-Based Sentiment Analysis\n(ABSA) has emerged. Having the ability to extract the polarity for each aspect\nof opinions separately, ABSA has found itself useful in a wide range of\ndomains. Education is one of the domains in which ABSA can be successfully\nutilized. Being able to understand and find out what students like and don't\nlike most about a course, professor, or teaching methodology can be of great\nimportance for the respective institutions. While this task represents a unique\nNLP challenge, many studies have proposed different approaches to tackle the\nproblem. In this work, we present a comprehensive review of the existing work\nin ABSA with a focus in the education domain. A wide range of methodologies are\ndiscussed and conclusions are drawn.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 21:51:47 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Hajrizi", "Rinor", ""], ["Nu\u00e7i", "Krenare Pireva", ""]]}, {"id": "2010.01430", "submitter": "Alexey Zakharov", "authors": "Alexey Zakharov, Matthew Crosby, Zafeirios Fountas", "title": "Episodic Memory for Learning Subjective-Timescale Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In model-based learning, an agent's model is commonly defined over\ntransitions between consecutive states of an environment even though planning\noften requires reasoning over multi-step timescales, with intermediate states\neither unnecessary, or worse, accumulating prediction error. In contrast,\nintelligent behaviour in biological organisms is characterised by the ability\nto plan over varying temporal scales depending on the context. Inspired by the\nrecent works on human time perception, we devise a novel approach to learning a\ntransition dynamics model, based on the sequences of episodic memories that\ndefine the agent's subjective timescale - over which it learns world dynamics\nand over which future planning is performed. We implement this in the framework\nof active inference and demonstrate that the resulting subjective-timescale\nmodel (STM) can systematically vary the temporal extent of its predictions\nwhile preserving the same computational efficiency. Additionally, we show that\nSTM predictions are more likely to introduce future salient events (for example\nnew objects coming into view), incentivising exploration of new areas of the\nenvironment. As a result, STM produces more informative action-conditioned\nroll-outs that assist the agent in making better decisions. We validate\nsignificant improvement in our STM agent's performance in the Animal-AI\nenvironment against a baseline system, trained using the environment's\nobjective-timescale dynamics.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 21:55:40 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Zakharov", "Alexey", ""], ["Crosby", "Matthew", ""], ["Fountas", "Zafeirios", ""]]}, {"id": "2010.01447", "submitter": "Shiquan Yang", "authors": "Shiquan Yang, Rui Zhang, Sarah Erfani", "title": "GraphDialog: Integrating Graph Knowledge into End-to-End Task-Oriented\n  Dialogue Systems", "comments": "11 pages, 5 figures, Accepted as an EMNLP 2020 Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end task-oriented dialogue systems aim to generate system responses\ndirectly from plain text inputs. There are two challenges for such systems: one\nis how to effectively incorporate external knowledge bases (KBs) into the\nlearning framework; the other is how to accurately capture the semantics of\ndialogue history. In this paper, we address these two challenges by exploiting\nthe graph structural information in the knowledge base and in the dependency\nparsing tree of the dialogue. To effectively leverage the structural\ninformation in dialogue history, we propose a new recurrent cell architecture\nwhich allows representation learning on graphs. To exploit the relations\nbetween entities in KBs, the model combines multi-hop reasoning ability based\non the graph structure. Experimental results show that the proposed model\nachieves consistent improvement over state-of-the-art models on two different\ntask-oriented dialogue datasets.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 00:04:40 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Yang", "Shiquan", ""], ["Zhang", "Rui", ""], ["Erfani", "Sarah", ""]]}, {"id": "2010.01470", "submitter": "Lequn Luke Wang", "authors": "Lequn Wang and Thorsten Joachims", "title": "Fairness and Diversity for Rankings in Two-Sided Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking items by their probability of relevance has long been the goal of\nconventional ranking systems. While this maximizes traditional criteria of\nranking performance, there is a growing understanding that it is an\noversimplification in online platforms that serve not only a diverse user\npopulation, but also the producers of the items. In particular, ranking\nalgorithms are expected to be fair in how they serve all groups of users -- not\njust the majority group -- and they also need to be fair in how they divide\nexposure among the items. These fairness considerations can partially be met by\nadding diversity to the rankings, as done in several recent works. However, we\nshow in this paper that user fairness, item fairness and diversity are\nfundamentally different concepts. In particular, we find that algorithms that\nconsider only one of the three desiderata can fail to satisfy and even harm the\nother two. To overcome this shortcoming, we present the first ranking algorithm\nthat explicitly enforces all three desiderata. The algorithm optimizes user and\nitem fairness as a convex optimization problem which can be solved optimally.\nFrom its solution, a ranking policy can be derived via a novel Birkhoff-von\nNeumann decomposition algorithm that optimizes diversity. Beyond the\ntheoretical analysis, we investigate empirically on a new benchmark dataset how\neffectively the proposed ranking algorithm can control user fairness, item\nfairness and diversity, as well as the trade-offs between them.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 02:53:09 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 04:00:28 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Wang", "Lequn", ""], ["Joachims", "Thorsten", ""]]}, {"id": "2010.01478", "submitter": "Shruthi Chari", "authors": "Shruthi Chari, Oshani Seneviratne, Daniel M. Gruen, Morgan A. Foreman,\n  Amar K. Das, Deborah L. McGuinness", "title": "Explanation Ontology in Action: A Clinical Use-Case", "comments": "5 pages, 2 figures, 1 protocol", "journal-ref": "International Semantic Web Conference, Poster and Demo Track, 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We addressed the problem of a lack of semantic representation for\nuser-centric explanations and different explanation types in our Explanation\nOntology (https://purl.org/heals/eo). Such a representation is increasingly\nnecessary as explainability has become an important problem in Artificial\nIntelligence with the emergence of complex methods and an uptake in\nhigh-precision and user-facing settings. In this submission, we provide\nstep-by-step guidance for system designers to utilize our ontology, introduced\nin our resource track paper, to plan and model for explanations during the\ndesign of their Artificial Intelligence systems. We also provide a detailed\nexample with our utilization of this guidance in a clinical setting.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 03:52:39 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Chari", "Shruthi", ""], ["Seneviratne", "Oshani", ""], ["Gruen", "Daniel M.", ""], ["Foreman", "Morgan A.", ""], ["Das", "Amar K.", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "2010.01479", "submitter": "Shruthi Chari", "authors": "Shruthi Chari, Oshani Seneviratne, Daniel M. Gruen, Morgan A. Foreman,\n  Amar K. Das, Deborah L. McGuinness", "title": "Explanation Ontology: A Model of Explanations for User-Centered AI", "comments": "16 pages (but 1 reference over on arxiv), 5 tables, 3 code listings,\n  1 figure", "journal-ref": "International Semantic Web Conference (ISWC), 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explainability has been a goal for Artificial Intelligence (AI) systems since\ntheir conception, with the need for explainability growing as more complex AI\nmodels are increasingly used in critical, high-stakes settings such as\nhealthcare. Explanations have often added to an AI system in a non-principled,\npost-hoc manner. With greater adoption of these systems and emphasis on\nuser-centric explainability, there is a need for a structured representation\nthat treats explainability as a primary consideration, mapping end user needs\nto specific explanation types and the system's AI capabilities. We design an\nexplanation ontology to model both the role of explanations, accounting for the\nsystem and user attributes in the process, and the range of different\nliterature-derived explanation types. We indicate how the ontology can support\nuser requirements for explanations in the domain of healthcare. We evaluate our\nontology with a set of competency questions geared towards a system designer\nwho might use our ontology to decide which explanation types to include, given\na combination of users' needs and a system's capabilities, both in system\ndesign settings and in real-time operations. Through the use of this ontology,\nsystem designers will be able to make informed choices on which explanations AI\nsystems can and should provide.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 03:53:35 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Chari", "Shruthi", ""], ["Seneviratne", "Oshani", ""], ["Gruen", "Daniel M.", ""], ["Foreman", "Morgan A.", ""], ["Das", "Amar K.", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "2010.01480", "submitter": "Junyi Li", "authors": "Junyi Li, Siqing Li, Wayne Xin Zhao, Gaole He, Zhicheng Wei, Nicholas\n  Jing Yuan and Ji-Rong Wen", "title": "Knowledge-Enhanced Personalized Review Generation with Capsule Graph\n  Neural Network", "comments": "Accepted by CIKM 2020 (Long Paper)", "journal-ref": null, "doi": "10.1145/3340531.3411893", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized review generation (PRG) aims to automatically produce review\ntext reflecting user preference, which is a challenging natural language\ngeneration task. Most of previous studies do not explicitly model factual\ndescription of products, tending to generate uninformative content. Moreover,\nthey mainly focus on word-level generation, but cannot accurately reflect more\nabstractive user preference in multiple aspects. To address the above issues,\nwe propose a novel knowledge-enhanced PRG model based on capsule graph neural\nnetwork~(Caps-GNN). We first construct a heterogeneous knowledge graph (HKG)\nfor utilizing rich item attributes. We adopt Caps-GNN to learn graph capsules\nfor encoding underlying characteristics from the HKG. Our generation process\ncontains two major steps, namely aspect sequence generation and sentence\ngeneration. First, based on graph capsules, we adaptively learn aspect capsules\nfor inferring the aspect sequence. Then, conditioned on the inferred aspect\nlabel, we design a graph-based copy mechanism to generate sentences by\nincorporating related entities or words from HKG. To our knowledge, we are the\nfirst to utilize knowledge graph for the PRG task. The incorporated KG\ninformation is able to enhance user preference at both aspect and word levels.\nExtensive experiments on three real-world datasets have demonstrated the\neffectiveness of our model on the PRG task.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 03:54:40 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Li", "Junyi", ""], ["Li", "Siqing", ""], ["Zhao", "Wayne Xin", ""], ["He", "Gaole", ""], ["Wei", "Zhicheng", ""], ["Yuan", "Nicholas Jing", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2010.01495", "submitter": "Yifan Gao", "authors": "Yifan Gao, Piji Li, Wei Bi, Xiaojiang Liu, Michael R. Lyu, Irwin King", "title": "Dialogue Generation on Infrequent Sentence Functions via Structured\n  Meta-Learning", "comments": "EMNLP 2020, Findings, 10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sentence function is an important linguistic feature indicating the\ncommunicative purpose in uttering a sentence. Incorporating sentence functions\ninto conversations has shown improvements in the quality of generated\nresponses. However, the number of utterances for different types of\nfine-grained sentence functions is extremely imbalanced. Besides a small number\nof high-resource sentence functions, a large portion of sentence functions is\ninfrequent. Consequently, dialogue generation conditioned on these infrequent\nsentence functions suffers from data deficiency. In this paper, we investigate\na structured meta-learning (SML) approach for dialogue generation on infrequent\nsentence functions. We treat dialogue generation conditioned on different\nsentence functions as separate tasks, and apply model-agnostic meta-learning to\nhigh-resource sentence functions data. Furthermore, SML enhances meta-learning\neffectiveness by promoting knowledge customization among different sentence\nfunctions but simultaneously preserving knowledge generalization for similar\nsentence functions. Experimental results demonstrate that SML not only improves\nthe informativeness and relevance of generated responses, but also can generate\nresponses consistent with the target sentence functions.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 07:13:36 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Gao", "Yifan", ""], ["Li", "Piji", ""], ["Bi", "Wei", ""], ["Liu", "Xiaojiang", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""]]}, {"id": "2010.01496", "submitter": "Oana-Maria Camburu", "authors": "Oana-Maria Camburu", "title": "Explaining Deep Neural Networks", "comments": "PhD Thesis, University of Oxford", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are becoming more and more popular due to their\nrevolutionary success in diverse areas, such as computer vision, natural\nlanguage processing, and speech recognition. However, the decision-making\nprocesses of these models are generally not interpretable to users. In various\ndomains, such as healthcare, finance, or law, it is critical to know the\nreasons behind a decision made by an artificial intelligence system. Therefore,\nseveral directions for explaining neural models have recently been explored.\n  In this thesis, I investigate two major directions for explaining deep neural\nnetworks. The first direction consists of feature-based post-hoc explanatory\nmethods, that is, methods that aim to explain an already trained and fixed\nmodel (post-hoc), and that provide explanations in terms of input features,\nsuch as tokens for text and superpixels for images (feature-based). The second\ndirection consists of self-explanatory neural models that generate natural\nlanguage explanations, that is, models that have a built-in module that\ngenerates explanations for the predictions of the model.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 07:23:13 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Camburu", "Oana-Maria", ""]]}, {"id": "2010.01528", "submitter": "Sayna Ebrahimi", "authors": "Sayna Ebrahimi, Suzanne Petryk, Akash Gokul, William Gan, Joseph E.\n  Gonzalez, Marcus Rohrbach, Trevor Darrell", "title": "Remembering for the Right Reasons: Explanations Reduce Catastrophic\n  Forgetting", "comments": "Accepted at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of continual learning (CL) is to learn a sequence of tasks without\nsuffering from the phenomenon of catastrophic forgetting. Previous work has\nshown that leveraging memory in the form of a replay buffer can reduce\nperformance degradation on prior tasks. We hypothesize that forgetting can be\nfurther reduced when the model is encouraged to remember the \\textit{evidence}\nfor previously made decisions. As a first step towards exploring this\nhypothesis, we propose a simple novel training paradigm, called Remembering for\nthe Right Reasons (RRR), that additionally stores visual model explanations for\neach example in the buffer and ensures the model has \"the right reasons\" for\nits predictions by encouraging its explanations to remain consistent with those\nused to make decisions at training time. Without this constraint, there is a\ndrift in explanations and increase in forgetting as conventional continual\nlearning algorithms learn new tasks. We demonstrate how RRR can be easily added\nto any memory or regularization-based approach and results in reduced\nforgetting, and more importantly, improved model explanations. We have\nevaluated our approach in the standard and few-shot settings and observed a\nconsistent improvement across various CL approaches using different\narchitectures and techniques to generate model explanations and demonstrated\nour approach showing a promising connection between explainability and\ncontinual learning. Our code is available at\n\\url{https://github.com/SaynaEbrahimi/Remembering-for-the-Right-Reasons}.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 10:05:27 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 03:26:30 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ebrahimi", "Sayna", ""], ["Petryk", "Suzanne", ""], ["Gokul", "Akash", ""], ["Gan", "William", ""], ["Gonzalez", "Joseph E.", ""], ["Rohrbach", "Marcus", ""], ["Darrell", "Trevor", ""]]}, {"id": "2010.01557", "submitter": "Pablo Barros", "authors": "Pablo Barros, Alessandra Sciutti", "title": "The FaceChannelS: Strike of the Sequences for the AffWild 2 Challenge", "comments": "Submission that describes the models submitted to the AffWild2\n  challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Predicting affective information from human faces became a popular task for\nmost of the machine learning community in the past years. The development of\nimmense and dense deep neural networks was backed by the availability of\nnumerous labeled datasets. These models, most of the time, present\nstate-of-the-art results in such benchmarks, but are very difficult to adapt to\nother scenarios. In this paper, we present one more chapter of benchmarking\ndifferent versions of the FaceChannel neural network: we demonstrate how our\nlittle model can predict affective information from the facial expression on\nthe novel AffWild2 dataset.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 12:00:48 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Barros", "Pablo", ""], ["Sciutti", "Alessandra", ""]]}, {"id": "2010.01596", "submitter": "Yang Jiao", "authors": "Yang Jiao, Kai Yang, Shaoyu Dou, Pan Luo, Sijia Liu, Dongjin Song", "title": "TimeAutoML: Autonomous Representation Learning for Multivariate\n  Irregularly Sampled Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series (MTS) data are becoming increasingly ubiquitous in\ndiverse domains, e.g., IoT systems, health informatics, and 5G networks. To\nobtain an effective representation of MTS data, it is not only essential to\nconsider unpredictable dynamics and highly variable lengths of these data but\nalso important to address the irregularities in the sampling rates of MTS.\nExisting parametric approaches rely on manual hyperparameter tuning and may\ncost a huge amount of labor effort. Therefore, it is desirable to learn the\nrepresentation automatically and efficiently. To this end, we propose an\nautonomous representation learning approach for multivariate time series\n(TimeAutoML) with irregular sampling rates and variable lengths. As opposed to\nprevious works, we first present a representation learning pipeline in which\nthe configuration and hyperparameter optimization are fully automatic and can\nbe tailored for various tasks, e.g., anomaly detection, clustering, etc. Next,\na negative sample generation approach and an auxiliary classification task are\ndeveloped and integrated within TimeAutoML to enhance its representation\ncapability. Extensive empirical studies on real-world datasets demonstrate that\nthe proposed TimeAutoML outperforms competing approaches on various tasks by a\nlarge margin. In fact, it achieves the best anomaly detection performance among\nall comparison algorithms on 78 out of all 85 UCR datasets, acquiring up to 20%\nperformance improvement in terms of AUC score.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 15:01:46 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Jiao", "Yang", ""], ["Yang", "Kai", ""], ["Dou", "Shaoyu", ""], ["Luo", "Pan", ""], ["Liu", "Sijia", ""], ["Song", "Dongjin", ""]]}, {"id": "2010.01604", "submitter": "Qinghua Liu", "authors": "Qinghua Liu, Tiancheng Yu, Yu Bai, Chi Jin", "title": "A Sharp Analysis of Model-based Reinforcement Learning with Self-Play", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based algorithms -- algorithms that explore the environment through\nbuilding and utilizing an estimated model -- are widely used in reinforcement\nlearning practice and theoretically shown to achieve optimal sample efficiency\nfor single-agent reinforcement learning in Markov Decision Processes (MDPs).\nHowever, for multi-agent reinforcement learning in Markov games, the current\nbest known sample complexity for model-based algorithms is rather suboptimal\nand compares unfavorably against recent model-free approaches. In this paper,\nwe present a sharp analysis of model-based self-play algorithms for multi-agent\nMarkov games. We design an algorithm -- Optimistic Nash Value Iteration\n(Nash-VI) for two-player zero-sum Markov games that is able to output an\n$\\epsilon$-approximate Nash policy in $\\tilde{\\mathcal{O}}(H^3SAB/\\epsilon^2)$\nepisodes of game playing, where $S$ is the number of states, $A,B$ are the\nnumber of actions for the two players respectively, and $H$ is the horizon\nlength. This significantly improves over the best known model-based guarantee\nof $\\tilde{\\mathcal{O}}(H^4S^2AB/\\epsilon^2)$, and is the first that matches\nthe information-theoretic lower bound $\\Omega(H^3S(A+B)/\\epsilon^2)$ except for\na $\\min\\{A,B\\}$ factor. In addition, our guarantee compares favorably against\nthe best known model-free algorithm if $\\min \\{A,B\\}=o(H^3)$, and outputs a\nsingle Markov policy while existing sample-efficient model-free algorithms\noutput a nested mixture of Markov policies that is in general non-Markov and\nrather inconvenient to store and execute. We further adapt our analysis to\ndesigning a provably efficient task-agnostic algorithm for zero-sum Markov\ngames, and designing the first line of provably sample-efficient algorithms for\nmulti-player general-sum Markov games.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 15:27:39 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 03:38:01 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Liu", "Qinghua", ""], ["Yu", "Tiancheng", ""], ["Bai", "Yu", ""], ["Jin", "Chi", ""]]}, {"id": "2010.01625", "submitter": "Sheena Panthaplackel", "authors": "Sheena Panthaplackel, Junyi Jessy Li, Milos Gligoric, Raymond J.\n  Mooney", "title": "Deep Just-In-Time Inconsistency Detection Between Comments and Source\n  Code", "comments": "Accepted in AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language comments convey key aspects of source code such as\nimplementation, usage, and pre- and post-conditions. Failure to update comments\naccordingly when the corresponding code is modified introduces inconsistencies,\nwhich is known to lead to confusion and software bugs. In this paper, we aim to\ndetect whether a comment becomes inconsistent as a result of changes to the\ncorresponding body of code, in order to catch potential inconsistencies\njust-in-time, i.e., before they are committed to a code base. To achieve this,\nwe develop a deep-learning approach that learns to correlate a comment with\ncode changes. By evaluating on a large corpus of comment/code pairs spanning\nvarious comment types, we show that our model outperforms multiple baselines by\nsignificant margins. For extrinsic evaluation, we show the usefulness of our\napproach by combining it with a comment update model to build a more\ncomprehensive automatic comment maintenance system which can both detect and\nresolve inconsistent comments based on code changes.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 16:49:28 GMT"}, {"version": "v2", "created": "Sat, 26 Dec 2020 22:55:17 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Panthaplackel", "Sheena", ""], ["Li", "Junyi Jessy", ""], ["Gligoric", "Milos", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "2010.01676", "submitter": "Matthew Guzdial", "authors": "Faraz Khadivpour and Matthew Guzdial", "title": "Explainability via Responsibility", "comments": "8 pages, 4 figures", "journal-ref": "Proceedings of the 2020 Experiment AI in Games Workshop", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedural Content Generation via Machine Learning (PCGML) refers to a group\nof methods for creating game content (e.g. platformer levels, game maps, etc.)\nusing machine learning models. PCGML approaches rely on black box models, which\ncan be difficult to understand and debug by human designers who do not have\nexpert knowledge about machine learning. This can be even more tricky in\nco-creative systems where human designers must interact with AI agents to\ngenerate game content. In this paper we present an approach to explainable\nartificial intelligence in which certain training instances are offered to\nhuman users as an explanation for the AI agent's actions during a co-creation\nprocess. We evaluate this approach by approximating its ability to provide\nhuman users with the explanations of AI agent's actions and helping them to\nmore efficiently cooperate with the AI agent.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 20:41:03 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Khadivpour", "Faraz", ""], ["Guzdial", "Matthew", ""]]}, {"id": "2010.01679", "submitter": "Mallikarjun Byrasandra Ramalinga Reddy", "authors": "Mallikarjun B R and Ayush Tewari and Hans-Peter Seidel and Mohamed\n  Elgharib and Christian Theobalt", "title": "Learning Complete 3D Morphable Face Models from Images and Videos", "comments": "Project Page - https://gvv.mpi-inf.mpg.de/projects/LeMoMo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most 3D face reconstruction methods rely on 3D morphable models, which\ndisentangle the space of facial deformations into identity geometry,\nexpressions and skin reflectance. These models are typically learned from a\nlimited number of 3D scans and thus do not generalize well across different\nidentities and expressions. We present the first approach to learn complete 3D\nmodels of face identity geometry, albedo and expression just from images and\nvideos. The virtually endless collection of such data, in combination with our\nself-supervised learning-based approach allows for learning face models that\ngeneralize beyond the span of existing approaches. Our network design and loss\nfunctions ensure a disentangled parameterization of not only identity and\nalbedo, but also, for the first time, an expression basis. Our method also\nallows for in-the-wild monocular reconstruction at test time. We show that our\nlearned models better generalize and lead to higher quality image-based\nreconstructions than existing approaches.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 20:51:23 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["R", "Mallikarjun B", ""], ["Tewari", "Ayush", ""], ["Seidel", "Hans-Peter", ""], ["Elgharib", "Mohamed", ""], ["Theobalt", "Christian", ""]]}, {"id": "2010.01681", "submitter": "Matthew Guzdial", "authors": "Adrian Gonzalez, Matthew Guzdial and Felix Ramos", "title": "Generating Gameplay-Relevant Art Assets with Transfer Learning", "comments": "7 pages, 8 figures", "journal-ref": "Proceedings of the 2020 Experimental AI in Games Workshop", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In game development, designing compelling visual assets that convey\ngameplay-relevant features requires time and experience. Recent image\ngeneration methods that create high-quality content could reduce development\ncosts, but these approaches do not consider game mechanics. We propose a\nConvolutional Variational Autoencoder (CVAE) system to modify and generate new\ngame visuals based on their gameplay relevance. We test this approach with\nPok\\'emon sprites and Pok\\'emon type information, since types are one of the\ngame's core mechanics and they directly impact the game's visuals. Our\nexperimental results indicate that adopting a transfer learning approach can\nhelp to improve visual quality and stability over unseen data.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 20:58:40 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Gonzalez", "Adrian", ""], ["Guzdial", "Matthew", ""], ["Ramos", "Felix", ""]]}, {"id": "2010.01685", "submitter": "Matthew Guzdial", "authors": "Nazanin Yousefzadeh Khameneh and Matthew Guzdial", "title": "Entity Embedding as Game Representation", "comments": "7 pages, 6 figures", "journal-ref": "Proceedings of the 2020 Experimental AI in Games Workshop", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedural content generation via machine learning (PCGML) has shown success\nat producing new video game content with machine learning. However, the\nmajority of the work has focused on the production of static game content,\nincluding game levels and visual elements. There has been much less work on\ndynamic game content, such as game mechanics. One reason for this is the lack\nof a consistent representation for dynamic game content, which is key for a\nnumber of statistical machine learning approaches. We present an autoencoder\nfor deriving what we call \"entity embeddings\", a consistent way to represent\ndifferent dynamic entities across multiple games in the same representation. In\nthis paper we introduce the learned representation, along with some evidence\ntowards its quality and future utility.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 21:16:45 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Khameneh", "Nazanin Yousefzadeh", ""], ["Guzdial", "Matthew", ""]]}, {"id": "2010.01693", "submitter": "Oluwatobi Olabiyi", "authors": "Oluwatobi O. Olabiyi, Prarthana Bhattarai, C. Bayan Bruss, Zachary\n  Kulis", "title": "DLGNet-Task: An End-to-end Neural Network Framework for Modeling\n  Multi-turn Multi-domain Task-Oriented Dialogue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Task oriented dialogue (TOD) requires the complex interleaving of a number of\nindividually controllable components with strong guarantees for explainability\nand verifiability. This has made it difficult to adopt the multi-turn\nmulti-domain dialogue generation capabilities of streamlined end-to-end\nopen-domain dialogue systems. In this paper, we present a new framework,\nDLGNet-Task, a unified task-oriented dialogue system which employs\nautoregressive transformer networks such as DLGNet and GPT-2/3 to complete user\ntasks in multi-turn multi-domain conversations. Our framework enjoys the\ncontrollable, verifiable, and explainable outputs of modular approaches, and\nthe low development, deployment and maintenance cost of end-to-end systems.\nTreating open-domain system components as additional TOD system modules allows\nDLGNet-Task to learn the joint distribution of the inputs and outputs of all\nthe functional blocks of existing modular approaches such as, natural language\nunderstanding (NLU), state tracking, action policy, as well as natural language\ngeneration (NLG). Rather than training the modules individually, as is common\nin real-world systems, we trained them jointly with appropriate module\nseparations. When evaluated on the MultiWOZ2.1 dataset, DLGNet-Task shows\ncomparable performance to the existing state-of-the-art approaches.\nFurthermore, using DLGNet-Task in conversational AI systems reduces the level\nof effort required for developing, deploying, and maintaining intelligent\nassistants at scale.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 21:43:17 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 16:31:06 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Olabiyi", "Oluwatobi O.", ""], ["Bhattarai", "Prarthana", ""], ["Bruss", "C. Bayan", ""], ["Kulis", "Zachary", ""]]}, {"id": "2010.01709", "submitter": "William S. Moses", "authors": "William S. Moses and Valentin Churavy", "title": "Instead of Rewriting Foreign Code for Machine Learning, Automatically\n  Synthesize Fast Gradients", "comments": "To be published in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.AI cs.LG cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying differentiable programming techniques and machine learning\nalgorithms to foreign programs requires developers to either rewrite their code\nin a machine learning framework, or otherwise provide derivatives of the\nforeign code. This paper presents Enzyme, a high-performance automatic\ndifferentiation (AD) compiler plugin for the LLVM compiler framework capable of\nsynthesizing gradients of statically analyzable programs expressed in the LLVM\nintermediate representation (IR). Enzyme synthesizes gradients for programs\nwritten in any language whose compiler targets LLVM IR including C, C++,\nFortran, Julia, Rust, Swift, MLIR, etc., thereby providing native AD\ncapabilities in these languages. Unlike traditional source-to-source and\noperator-overloading tools, Enzyme performs AD on optimized IR. On a\nmachine-learning focused benchmark suite including Microsoft's ADBench, AD on\noptimized IR achieves a geometric mean speedup of 4.5x over AD on IR before\noptimization allowing Enzyme to achieve state-of-the-art performance. Packaging\nEnzyme for PyTorch and TensorFlow provides convenient access to gradients of\nforeign code with state-of-the art performance, enabling foreign code to be\ndirectly incorporated into existing machine learning workflows.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 22:32:51 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Moses", "William S.", ""], ["Churavy", "Valentin", ""]]}, {"id": "2010.01713", "submitter": "Anshuman Mishra", "authors": "Anshuman Mishra, Dhruvesh Patel, Aparna Vijayakumar, Xiang Li, Pavan\n  Kapanipathi, Kartik Talamadupula", "title": "Reading Comprehension as Natural Language Inference: A Semantic Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent past, Natural language Inference (NLI) has gained significant\nattention, particularly given its promise for downstream NLP tasks. However,\nits true impact is limited and has not been well studied. Therefore, in this\npaper, we explore the utility of NLI for one of the most prominent downstream\ntasks, viz. Question Answering (QA). We transform the one of the largest\navailable MRC dataset (RACE) to an NLI form, and compare the performances of a\nstate-of-the-art model (RoBERTa) on both these forms. We propose new\ncharacterizations of questions, and evaluate the performance of QA and NLI\nmodels on these categories. We highlight clear categories for which the model\nis able to perform better when the data is presented in a coherent entailment\nform, and a structured question-answer concatenation form, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 22:50:59 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Mishra", "Anshuman", ""], ["Patel", "Dhruvesh", ""], ["Vijayakumar", "Aparna", ""], ["Li", "Xiang", ""], ["Kapanipathi", "Pavan", ""], ["Talamadupula", "Kartik", ""]]}, {"id": "2010.01725", "submitter": "Moshiur R Farazi", "authors": "Moshiur Farazi, Salman Khan and Nick Barnes", "title": "Attention Guided Semantic Relationship Parsing for Visual Question\n  Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans explain inter-object relationships with semantic labels that\ndemonstrate a high-level understanding required to perform complex\nVision-Language tasks such as Visual Question Answering (VQA). However,\nexisting VQA models represent relationships as a combination of object-level\nvisual features which constrain a model to express interactions between objects\nin a single domain, while the model is trying to solve a multi-modal task. In\nthis paper, we propose a general purpose semantic relationship parser which\ngenerates a semantic feature vector for each subject-predicate-object triplet\nin an image, and a Mutual and Self Attention (MSA) mechanism that learns to\nidentify relationship triplets that are important to answer the given question.\nTo motivate the significance of semantic relationships, we show an oracle\nsetting with ground-truth relationship triplets, where our model achieves a\n~25% accuracy gain over the closest state-of-the-art model on the challenging\nGQA dataset. Further, with our semantic parser, we show that our model\noutperforms other comparable approaches on VQA and GQA datasets.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 00:23:49 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Farazi", "Moshiur", ""], ["Khan", "Salman", ""], ["Barnes", "Nick", ""]]}, {"id": "2010.01729", "submitter": "Youngeun Kim", "authors": "Youngeun Kim, Priyadarshini Panda", "title": "Revisiting Batch Normalization for Training Low-latency Deep Spiking\n  Neural Networks from Scratch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) have recently emerged as an alternative to\ndeep learning owing to sparse, asynchronous and binary event (or spike) driven\nprocessing, that can yield huge energy efficiency benefits on neuromorphic\nhardware. However, training high-accuracy and low-latency SNNs from scratch\nsuffers from non-differentiable nature of a spiking neuron. To address this\ntraining issue in SNNs, we revisit batch normalization and propose a temporal\nBatch Normalization Through Time (BNTT) technique. Most prior SNN works till\nnow have disregarded batch normalization deeming it ineffective for training\ntemporal SNNs. Different from previous works, our proposed BNTT decouples the\nparameters in a BNTT layer along the time axis to capture the temporal dynamics\nof spikes. The temporally evolving learnable parameters in BNTT allow a neuron\nto control its spike rate through different time-steps, enabling low-latency\nand low-energy training from scratch. We conduct experiments on CIFAR-10,\nCIFAR-100, Tiny-ImageNet and event-driven DVS-CIFAR10 datasets. BNTT allows us\nto train deep SNN architectures from scratch, for the first time, on complex\ndatasets with just few 25-30 time-steps. We also propose an early exit\nalgorithm using the distribution of parameters in BNTT to reduce the latency at\ninference, that further improves the energy-efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 00:49:30 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 21:42:42 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 17:14:42 GMT"}, {"version": "v4", "created": "Mon, 30 Nov 2020 00:36:59 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Kim", "Youngeun", ""], ["Panda", "Priyadarshini", ""]]}, {"id": "2010.01735", "submitter": "Lu Zhang", "authors": "Lu Zhang, Mo Yu, Tian Gao, Yue Yu", "title": "MCMH: Learning Multi-Chain Multi-Hop Rules for Knowledge Graph Reasoning", "comments": "Accepted Findings of EMNLP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop reasoning approaches over knowledge graphs infer a missing\nrelationship between entities with a multi-hop rule, which corresponds to a\nchain of relationships. We extend existing works to consider a generalized form\nof multi-hop rules, where each rule is a set of relation chains. To learn such\ngeneralized rules efficiently, we propose a two-step approach that first\nselects a small set of relation chains as a rule and then evaluates the\nconfidence of the target relationship by jointly scoring the selected chains. A\ngame-theoretical framework is proposed to this end to simultaneously optimize\nthe rule selection and prediction steps. Empirical results show that our\nmulti-chain multi-hop (MCMH) rules result in superior results compared to the\nstandard single-chain approaches, justifying both our formulation of\ngeneralized rules and the effectiveness of the proposed learning framework.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 01:32:20 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Zhang", "Lu", ""], ["Yu", "Mo", ""], ["Gao", "Tian", ""], ["Yu", "Yue", ""]]}, {"id": "2010.01736", "submitter": "Jingfeng Zhang", "authors": "Jingfeng Zhang, Jianing Zhu, Gang Niu, Bo Han, Masashi Sugiyama, and\n  Mohan Kankanhalli", "title": "Geometry-aware Instance-reweighted Adversarial Training", "comments": "ICLR 2021, Oral, Code\n  <https://github.com/zjfheart/Geometry-aware-Instance-reweighted-Adversarial-Training>", "journal-ref": "International Conference on Learning Representations (ICLR 2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In adversarial machine learning, there was a common belief that robustness\nand accuracy hurt each other. The belief was challenged by recent studies where\nwe can maintain the robustness and improve the accuracy. However, the other\ndirection, whether we can keep the accuracy while improving the robustness, is\nconceptually and practically more interesting, since robust accuracy should be\nlower than standard accuracy for any model. In this paper, we show this\ndirection is also promising. Firstly, we find even over-parameterized deep\nnetworks may still have insufficient model capacity, because adversarial\ntraining has an overwhelming smoothing effect. Secondly, given limited model\ncapacity, we argue adversarial data should have unequal importance:\ngeometrically speaking, a natural data point closer to/farther from the class\nboundary is less/more robust, and the corresponding adversarial data point\nshould be assigned with larger/smaller weight. Finally, to implement the idea,\nwe propose geometry-aware instance-reweighted adversarial training, where the\nweights are based on how difficult it is to attack a natural data point.\nExperiments show that our proposal boosts the robustness of standard\nadversarial training; combining two directions, we improve both robustness and\naccuracy of standard adversarial training.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 01:33:11 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 02:49:55 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhang", "Jingfeng", ""], ["Zhu", "Jianing", ""], ["Niu", "Gang", ""], ["Han", "Bo", ""], ["Sugiyama", "Masashi", ""], ["Kankanhalli", "Mohan", ""]]}, {"id": "2010.01748", "submitter": "Jingkang Wang", "authors": "Jingkang Wang, Hongyi Guo, Zhaowei Zhu, Yang Liu", "title": "Policy Learning Using Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing policy learning solutions require the learning agents to\nreceive high-quality supervision signals, e.g., rewards in reinforcement\nlearning (RL) or high-quality expert's demonstrations in behavioral cloning\n(BC). These quality supervisions are either infeasible or prohibitively\nexpensive to obtain in practice. We aim for a unified framework that leverages\nthe weak supervisions to perform policy learning efficiently. To handle this\nproblem, we treat the \"weak supervisions\" as imperfect information coming from\na peer agent, and evaluate the learning agent's policy based on a \"correlated\nagreement\" with the peer agent's policy (instead of simple agreements). Our way\nof leveraging peer agent's information offers us a family of solutions that\nlearn effectively from weak supervisions with theoretical guarantees. Extensive\nevaluations on tasks including RL with noisy reward, BC with weak\ndemonstrations and standard policy co-training (RL + BC) show that the proposed\napproach leads to substantial improvements, especially when the complexity or\nthe noise of the learning environments grows.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 02:26:08 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 20:42:38 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Wang", "Jingkang", ""], ["Guo", "Hongyi", ""], ["Zhu", "Zhaowei", ""], ["Liu", "Yang", ""]]}, {"id": "2010.01753", "submitter": "Rodrigo Toro Icarte", "authors": "Rodrigo Toro Icarte, Richard Valenzano, Toryn Q. Klassen, Phillip\n  Christoffersen, Amir-massoud Farahmand, Sheila A. McIlraith", "title": "The act of remembering: a study in partially observable reinforcement\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) agents typically learn memoryless\npolicies---policies that only consider the last observation when selecting\nactions. Learning memoryless policies is efficient and optimal in fully\nobservable environments. However, some form of memory is necessary when RL\nagents are faced with partial observability. In this paper, we study a\nlightweight approach to tackle partial observability in RL. We provide the\nagent with an external memory and additional actions to control what, if\nanything, is written to the memory. At every step, the current memory state is\npart of the agent's observation, and the agent selects a tuple of actions: one\naction that modifies the environment and another that modifies the memory. When\nthe external memory is sufficiently expressive, optimal memoryless policies\nyield globally optimal solutions. Unfortunately, previous attempts to use\nexternal memory in the form of binary memory have produced poor results in\npractice. Here, we investigate alternative forms of memory in support of\nlearning effective memoryless policies. Our novel forms of memory outperform\nbinary and LSTM-based memory in well-established partially observable domains.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 02:56:43 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Icarte", "Rodrigo Toro", ""], ["Valenzano", "Richard", ""], ["Klassen", "Toryn Q.", ""], ["Christoffersen", "Phillip", ""], ["Farahmand", "Amir-massoud", ""], ["McIlraith", "Sheila A.", ""]]}, {"id": "2010.01755", "submitter": "Marina Haliem", "authors": "Marina Haliem, Ganapathy Mani, Vaneet Aggarwal and Bharat Bhargava", "title": "A Distributed Model-Free Ride-Sharing Approach for Joint Matching,\n  Pricing, and Dispatching using Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant development of ride-sharing services presents a plethora of\nopportunities to transform urban mobility by providing personalized and\nconvenient transportation while ensuring efficiency of large-scale ride\npooling. However, a core problem for such services is route planning for each\ndriver to fulfill the dynamically arriving requests while satisfying given\nconstraints. Current models are mostly limited to static routes with only two\nrides per vehicle (optimally) or three (with heuristics). In this paper, we\npresent a dynamic, demand aware, and pricing-based vehicle-passenger matching\nand route planning framework that (1) dynamically generates optimal routes for\neach vehicle based on online demand, pricing associated with each ride, vehicle\ncapacities and locations. This matching algorithm starts greedily and optimizes\nover time using an insertion operation, (2) involves drivers in the\ndecision-making process by allowing them to propose a different price based on\nthe expected reward for a particular ride as well as the destination locations\nfor future rides, which is influenced by supply-and demand computed by the Deep\nQ-network, (3) allows customers to accept or reject rides based on their set of\npreferences with respect to pricing and delay windows, vehicle type and\ncarpooling preferences, and (4) based on demand prediction, our approach\nre-balances idle vehicles by dispatching them to the areas of anticipated high\ndemand using deep Reinforcement Learning (RL). Our framework is validated using\nthe New York City Taxi public dataset; however, we consider different vehicle\ntypes and designed customer utility functions to validate the setup and study\ndifferent settings. Experimental results show the effectiveness of our approach\nin real-time and large scale settings.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 03:13:47 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 15:36:50 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Haliem", "Marina", ""], ["Mani", "Ganapathy", ""], ["Aggarwal", "Vaneet", ""], ["Bhargava", "Bharat", ""]]}, {"id": "2010.01764", "submitter": "Yu Wang", "authors": "Shayne Longpre and Yu Wang and Christopher DuBois", "title": "How Effective is Task-Agnostic Data Augmentation for Pretrained\n  Transformers?", "comments": "2 tables; 1 figure; EMNLP Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-agnostic forms of data augmentation have proven widely effective in\ncomputer vision, even on pretrained models. In NLP similar results are reported\nmost commonly for low data regimes, non-pretrained models, or situationally for\npretrained models. In this paper we ask how effective these techniques really\nare when applied to pretrained transformers. Using two popular varieties of\ntask-agnostic data augmentation (not tailored to any particular task), Easy\nData Augmentation (Wei and Zou, 2019) and Back-Translation (Sennrichet al.,\n2015), we conduct a systematic examination of their effects across 5\nclassification tasks, 6 datasets, and 3 variants of modern pretrained\ntransformers, including BERT, XLNet, and RoBERTa. We observe a negative result,\nfinding that techniques which previously reported strong improvements for\nnon-pretrained models fail to consistently improve performance for pretrained\ntransformers, even when training data is limited. We hope this empirical\nanalysis helps inform practitioners where data augmentation techniques may\nconfer improvements.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 03:55:15 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Longpre", "Shayne", ""], ["Wang", "Yu", ""], ["DuBois", "Christopher", ""]]}, {"id": "2010.01794", "submitter": "Steven Y. Feng", "authors": "Steven Y. Feng, Varun Gangal, Dongyeop Kang, Teruko Mitamura, Eduard\n  Hovy", "title": "GenAug: Data Augmentation for Finetuning Text Generators", "comments": "EMNLP 2020 Deep Learning Inside Out (DeeLIO) Workshop; Code available\n  at https://github.com/styfeng/GenAug", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate data augmentation for text generation, which we\ncall GenAug. Text generation and language modeling are important tasks within\nnatural language processing, and are especially challenging for low-data\nregimes. We propose and evaluate various augmentation methods, including some\nthat incorporate external knowledge, for finetuning GPT-2 on a subset of Yelp\nReviews. We also examine the relationship between the amount of augmentation\nand the quality of the generated text. We utilize several metrics that evaluate\nimportant aspects of the generated text including its diversity and fluency.\nOur experiments demonstrate that insertion of character-level synthetic noise\nand keyword replacement with hypernyms are effective augmentation methods, and\nthat the quality of generations improves to a peak at approximately three times\nthe amount of original data.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 05:46:39 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 06:00:03 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Feng", "Steven Y.", ""], ["Gangal", "Varun", ""], ["Kang", "Dongyeop", ""], ["Mitamura", "Teruko", ""], ["Hovy", "Eduard", ""]]}, {"id": "2010.01824", "submitter": "Saptarshi Sinha", "authors": "Saptarshi Sinha, Hiroki Ohashi and Katsuyuki Nakamura", "title": "Class-Wise Difficulty-Balanced Loss for Solving Class-Imbalance", "comments": "Accepted for ACCV 2020 oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Class-imbalance is one of the major challenges in real world datasets, where\na few classes (called majority classes) constitute much more data samples than\nthe rest (called minority classes). Learning deep neural networks using such\ndatasets leads to performances that are typically biased towards the majority\nclasses. Most of the prior works try to solve class-imbalance by assigning more\nweights to the minority classes in various manners (e.g., data re-sampling,\ncost-sensitive learning). However, we argue that the number of available\ntraining data may not be always a good clue to determine the weighting strategy\nbecause some of the minority classes might be sufficiently represented even by\na small number of training data. Overweighting samples of such classes can lead\nto drop in the model's overall performance. We claim that the 'difficulty' of a\nclass as perceived by the model is more important to determine the weighting.\nIn this light, we propose a novel loss function named Class-wise\nDifficulty-Balanced loss, or CDB loss, which dynamically distributes weights to\neach sample according to the difficulty of the class that the sample belongs\nto. Note that the assigned weights dynamically change as the 'difficulty' for\nthe model may change with the learning progress. Extensive experiments are\nconducted on both image (artificially induced class-imbalanced MNIST,\nlong-tailed CIFAR and ImageNet-LT) and video (EGTEA) datasets. The results show\nthat CDB loss consistently outperforms the recently proposed loss functions on\nclass-imbalanced datasets irrespective of the data type (i.e., video or image).\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 07:19:19 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Sinha", "Saptarshi", ""], ["Ohashi", "Hiroki", ""], ["Nakamura", "Katsuyuki", ""]]}, {"id": "2010.01829", "submitter": "Phuc Nguyen Tri", "authors": "Phuc Nguyen and Natthawut Kertkeidkachorn and Ryutaro Ichise and\n  Hideaki Takeda", "title": "TabEAno: Table to Knowledge Graph Entity Annotation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the Open Data era, a large number of table resources have been made\navailable on the Web and data portals. However, it is difficult to directly\nutilize such data due to the ambiguity of entities, name variations,\nheterogeneous schema, missing, or incomplete metadata. To address these issues,\nwe propose a novel approach, namely TabEAno, to semantically annotate table\nrows toward knowledge graph entities. Specifically, we introduce a \"two-cells\"\nlookup strategy bases on the assumption that there is an existing logical\nrelation occurring in the knowledge graph between the two closed cells in the\nsame row of the table. Despite the simplicity of the approach, TabEAno\noutperforms the state of the art approaches in the two standard datasets e.g,\nT2D, Limaye with, and in the large-scale Wikipedia tables dataset.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 07:39:02 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Nguyen", "Phuc", ""], ["Kertkeidkachorn", "Natthawut", ""], ["Ichise", "Ryutaro", ""], ["Takeda", "Hideaki", ""]]}, {"id": "2010.01838", "submitter": "Yifan Gao", "authors": "Yifan Gao, Chien-Sheng Wu, Jingjing Li, Shafiq Joty, Steven C.H. Hoi,\n  Caiming Xiong, Irwin King, Michael R. Lyu", "title": "Discern: Discourse-Aware Entailment Reasoning Network for Conversational\n  Machine Reading", "comments": "EMNLP 2020 main conference, 11 pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Document interpretation and dialog understanding are the two major challenges\nfor conversational machine reading. In this work, we propose Discern, a\ndiscourse-aware entailment reasoning network to strengthen the connection and\nenhance the understanding for both document and dialog. Specifically, we split\nthe document into clause-like elementary discourse units (EDU) using a\npre-trained discourse segmentation model, and we train our model in a\nweakly-supervised manner to predict whether each EDU is entailed by the user\nfeedback in a conversation. Based on the learned EDU and entailment\nrepresentations, we either reply to the user our final decision\n\"yes/no/irrelevant\" of the initial question, or generate a follow-up question\nto inquiry more information. Our experiments on the ShARC benchmark (blind,\nheld-out test set) show that Discern achieves state-of-the-art results of 78.3%\nmacro-averaged accuracy on decision making and 64.0 BLEU1 on follow-up question\ngeneration. Code and models are released at\nhttps://github.com/Yifan-Gao/Discern.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 07:49:51 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 07:16:32 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 10:06:46 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Gao", "Yifan", ""], ["Wu", "Chien-Sheng", ""], ["Li", "Jingjing", ""], ["Joty", "Shafiq", ""], ["Hoi", "Steven C. H.", ""], ["Xiong", "Caiming", ""], ["King", "Irwin", ""], ["Lyu", "Michael R.", ""]]}, {"id": "2010.01855", "submitter": "Martin Biehl", "authors": "Martin Biehl and Ryota Kanai", "title": "Non-trivial informational closure of a Bayesian hyperparameter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the non-trivial informational closure (NTIC) of a Bayesian\nhyperparameter inferring the underlying distribution of an identically and\nindependently distributed finite random variable. For this we embed both the\nBayesian hyper-parameter updating process and the random data process into a\nMarkov chain. The original publication by Bertschinger et al. (2006) mentioned\nthat NTIC may be able to capture an abstract notion of modeling that is\nagnostic to the specific internal structure of and existence of explicit\nrepresentations within the modeling process. The Bayesian hyperparameter is of\ninterest since it has a well defined interpretation as a model of the data\nprocess and at the same time its dynamics can be specified without reference to\nthis interpretation. On the one hand we show explicitly that the NTIC of the\nhyperparameter increases indefinitely over time. On the other hand we attempt\nto establish a connection between a quantity that is a feature of the\ninterpretation of the hyperparameter as a model, namely the information gain,\nand the one-step pointwise NTIC which is a quantity that does not depend on\nthis interpretation. We find that in general we cannot use the one-step\npointwise NTIC as an indicator for information gain. We hope this exploratory\nwork can lead to further rigorous studies of the relation between NTIC and\nmodeling.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 08:35:51 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Biehl", "Martin", ""], ["Kanai", "Ryota", ""]]}, {"id": "2010.01862", "submitter": "Ferhat Ozgur Catak", "authors": "Ferhat Ozgur Catak, Javed Ahmed, Kevser Sahinbas, Zahid Hussain Khand", "title": "Data Augmentation Based Malware Detection using Convolutional Neural\n  Networks", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, cyber-attacks have been extensively seen due to the everlasting\nincrease of malware in the cyber world. These attacks cause irreversible damage\nnot only to end-users but also to corporate computer systems. Ransomware\nattacks such as WannaCry and Petya specifically targets to make critical\ninfrastructures such as airports and rendered operational processes inoperable.\nHence, it has attracted increasing attention in terms of volume, versatility,\nand intricacy. The most important feature of this type of malware is that they\nchange shape as they propagate from one computer to another. Since standard\nsignature-based detection software fails to identify this type of malware\nbecause they have different characteristics on each contaminated computer. This\npaper aims at providing an image augmentation enhanced deep convolutional\nneural network (CNN) models for the detection of malware families in a\nmetamorphic malware environment. The main contributions of the paper's model\nstructure consist of three components, including image generation from malware\nsamples, image augmentation, and the last one is classifying the malware\nfamilies by using a convolutional neural network model. In the first component,\nthe collected malware samples are converted binary representation to 3-channel\nimages using windowing technique. The second component of the system create the\naugmented version of the images, and the last component builds a classification\nmodel. In this study, five different deep convolutional neural network model\nfor malware family detection is used.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 08:58:07 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Catak", "Ferhat Ozgur", ""], ["Ahmed", "Javed", ""], ["Sahinbas", "Kevser", ""], ["Khand", "Zahid Hussain", ""]]}, {"id": "2010.01869", "submitter": "Alessio Miaschi", "authors": "Alessio Miaschi, Dominique Brunato, Felice Dell'Orletta, Giulia\n  Venturi", "title": "Linguistic Profiling of a Neural Language Model", "comments": "Accepted to COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the linguistic knowledge learned by a Neural\nLanguage Model (NLM) before and after a fine-tuning process and how this\nknowledge affects its predictions during several classification problems. We\nuse a wide set of probing tasks, each of which corresponds to a distinct\nsentence-level feature extracted from different levels of linguistic\nannotation. We show that BERT is able to encode a wide range of linguistic\ncharacteristics, but it tends to lose this information when trained on specific\ndownstream tasks. We also find that BERT's capacity to encode different kind of\nlinguistic properties has a positive influence on its predictions: the more it\nstores readable linguistic information of a sentence, the higher will be its\ncapacity of predicting the expected label assigned to that sentence.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 09:09:01 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 11:26:26 GMT"}, {"version": "v3", "created": "Sat, 7 Nov 2020 17:43:20 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Miaschi", "Alessio", ""], ["Brunato", "Dominique", ""], ["Dell'Orletta", "Felice", ""], ["Venturi", "Giulia", ""]]}, {"id": "2010.01878", "submitter": "Mathieu Rita", "authors": "Mathieu Rita, Rahma Chaabouni, Emmanuel Dupoux", "title": "\"LazImpa\": Lazy and Impatient neural agents learn to communicate\n  efficiently", "comments": "Accepted to CoNLL 2020", "journal-ref": "Proceedings of CoNLL 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work has shown that artificial neural agents naturally develop\nsurprisingly non-efficient codes. This is illustrated by the fact that in a\nreferential game involving a speaker and a listener neural networks optimizing\naccurate transmission over a discrete channel, the emergent messages fail to\nachieve an optimal length. Furthermore, frequent messages tend to be longer\nthan infrequent ones, a pattern contrary to the Zipf Law of Abbreviation (ZLA)\nobserved in all natural languages. Here, we show that near-optimal and\nZLA-compatible messages can emerge, but only if both the speaker and the\nlistener are modified. We hence introduce a new communication system,\n\"LazImpa\", where the speaker is made increasingly lazy, i.e. avoids long\nmessages, and the listener impatient, i.e.,~seeks to guess the intended content\nas soon as possible.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 09:25:53 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Rita", "Mathieu", ""], ["Chaabouni", "Rahma", ""], ["Dupoux", "Emmanuel", ""]]}, {"id": "2010.01891", "submitter": "Dat Quoc Nguyen", "authors": "Anh Tuan Nguyen, Mai Hoang Dao and Dat Quoc Nguyen", "title": "A Pilot Study of Text-to-SQL Semantic Parsing for Vietnamese", "comments": "EMNLP 2020 (Findings)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing is an important NLP task. However, Vietnamese is a\nlow-resource language in this research area. In this paper, we present the\nfirst public large-scale Text-to-SQL semantic parsing dataset for Vietnamese.\nWe extend and evaluate two strong semantic parsing baselines EditSQL (Zhang et\nal., 2019) and IRNet (Guo et al., 2019) on our dataset. We compare the two\nbaselines with key configurations and find that: automatic Vietnamese word\nsegmentation improves the parsing results of both baselines; the normalized\npointwise mutual information (NPMI) score (Bouma, 2009) is useful for schema\nlinking; latent syntactic features extracted from a neural dependency parser\nfor Vietnamese also improve the results; and the monolingual language model\nPhoBERT for Vietnamese (Nguyen and Nguyen, 2020) helps produce higher\nperformances than the recent best multilingual language model XLM-R (Conneau et\nal., 2020).\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 09:54:51 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Nguyen", "Anh Tuan", ""], ["Dao", "Mai Hoang", ""], ["Nguyen", "Dat Quoc", ""]]}, {"id": "2010.01898", "submitter": "Jie Huang", "authors": "Jie Huang, Zilong Wang, Kevin Chen-Chuan Chang, Wen-mei Hwu, Jinjun\n  Xiong", "title": "Exploring Semantic Capacity of Terms", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study semantic capacity of terms. For example, the semantic\ncapacity of artificial intelligence is higher than that of linear regression\nsince artificial intelligence possesses a broader meaning scope. Understanding\nsemantic capacity of terms will help many downstream tasks in natural language\nprocessing. For this purpose, we propose a two-step model to investigate\nsemantic capacity of terms, which takes a large text corpus as input and can\nevaluate semantic capacity of terms if the text corpus can provide enough\nco-occurrence information of terms. Extensive experiments in three fields\ndemonstrate the effectiveness and rationality of our model compared with\nwell-designed baselines and human-level evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 10:26:36 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Huang", "Jie", ""], ["Wang", "Zilong", ""], ["Chang", "Kevin Chen-Chuan", ""], ["Hwu", "Wen-mei", ""], ["Xiong", "Jinjun", ""]]}, {"id": "2010.01909", "submitter": "Sunandita Patra", "authors": "Sunandita Patra, James Mason, Malik Ghallab, Dana Nau, Paolo Traverso", "title": "Deliberative Acting, Online Planning and Learning with Hierarchical\n  Operational Models", "comments": "Currently under review at AIJ. arXiv admin note: text overlap with\n  arXiv:2003.03932", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In AI research, synthesizing a plan of action has typically used descriptive\nmodels of the actions that abstractly specify what might happen as a result of\nan action, and are tailored for efficiently computing state transitions.\nHowever, executing the planned actions has needed operational models, in which\nrich computational control structures and closed-loop online decision-making\nare used to specify how to perform an action in a complex execution context,\nreact to events and adapt to an unfolding situation. Deliberative actors, which\nintegrate acting and planning, have typically needed to use both of these\nmodels together -- which causes problems when attempting to develop the\ndifferent models, verify their consistency, and smoothly interleave acting and\nplanning.\n  As an alternative, we define and implement an integrated acting-and-planning\nsystem in which both planning and acting use the same operational models. These\nrely on hierarchical task-oriented refinement methods offering rich control\nstructures. The acting component, called Reactive Acting Engine (RAE), is\ninspired by the well-known PRS system. At each decision step, RAE can get\nadvice from a planner for a near-optimal choice with respect to a utility\nfunction. The anytime planner uses a UCT-like Monte Carlo Tree Search\nprocedure, called UPOM, (UCT Procedure for Operational Models), whose rollouts\nare simulations of the actor's operational models. We also present learning\nstrategies for use with RAE and UPOM that acquire, from online acting\nexperiences and/or simulated planning results, a mapping from decision contexts\nto method instances as well as a heuristic function to guide UPOM. We\ndemonstrate the asymptotic convergence of UPOM towards optimal methods in\nstatic domains, and show experimentally that UPOM and the learning strategies\nsignificantly improve the acting efficiency and robustness.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 14:50:05 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 09:13:44 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Patra", "Sunandita", ""], ["Mason", "James", ""], ["Ghallab", "Malik", ""], ["Nau", "Dana", ""], ["Traverso", "Paolo", ""]]}, {"id": "2010.01931", "submitter": "Giorgio Angelotti", "authors": "Giorgio Angelotti, Nicolas Drougard, Caroline Ponzoni Carvalho Chanel", "title": "Offline Learning for Planning: A Summary", "comments": "9 pages, ICAPS 2020 Conference - Bridging the Gap Between AI Planning\n  and Reinforcement Learning (PRL) Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The training of autonomous agents often requires expensive and unsafe\ntrial-and-error interactions with the environment. Nowadays several data sets\ncontaining recorded experiences of intelligent agents performing various tasks,\nspanning from the control of unmanned vehicles to human-robot interaction and\nmedical applications are accessible on the internet. With the intention of\nlimiting the costs of the learning procedure it is convenient to exploit the\ninformation that is already available rather than collecting new data.\nNevertheless, the incapability to augment the batch can lead the autonomous\nagents to develop far from optimal behaviours when the sampled experiences do\nnot allow for a good estimate of the true distribution of the environment.\nOffline learning is the area of machine learning concerned with efficiently\nobtaining an optimal policy with a batch of previously collected experiences\nwithout further interaction with the environment. In this paper we adumbrate\nthe ideas motivating the development of the state-of-the-art offline learning\nbaselines. The listed methods consist in the introduction of epistemic\nuncertainty dependent constraints during the classical resolution of a Markov\nDecision Process, with and without function approximators, that aims to\nalleviate the bad effects of the distributional mismatch between the available\nsamples and real world. We provide comments on the practical utility of the\ntheoretical bounds that justify the application of these algorithms and suggest\nthe utilization of Generative Adversarial Networks to estimate the\ndistributional shift that affects all of the proposed model-free and\nmodel-based approaches.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 11:41:11 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Angelotti", "Giorgio", ""], ["Drougard", "Nicolas", ""], ["Chanel", "Caroline Ponzoni Carvalho", ""]]}, {"id": "2010.01950", "submitter": "Hoki Kim", "authors": "Hoki Kim", "title": "Torchattacks: A PyTorch Repository for Adversarial Attacks", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Torchattacks is a PyTorch library that contains adversarial attacks to\ngenerate adversarial examples and to verify the robustness of deep learning\nmodels. The code can be found at\nhttps://github.com/Harry24k/adversarial-attacks-pytorch.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 01:34:42 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 01:16:12 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 15:42:38 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Kim", "Hoki", ""]]}, {"id": "2010.01961", "submitter": "Ihor Kendiukhov", "authors": "Ihor Kendiukhov", "title": "A Finite-Time Technological Singularity Model With Artificial\n  Intelligence Self-Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in the development of artificial intelligence, technological\nprogress acceleration, long-term trends of macroeconomic dynamics increase the\nrelevance of technological singularity hypothesis. In this paper, we build a\nmodel of finite-time technological singularity assuming that artificial\nintelligence will replace humans for artificial intelligence engineers after\nsome point in time when it is developed enough. This model implies the\nfollowing: let A be the level of development of artificial intelligence. Then,\nthe moment of technological singularity n is defined as the point in time where\nartificial intelligence development function approaches infinity. Thus, it\nhappens in finite time. Although infinite level of development of artificial\nintelligence cannot be reached practically, this approximation is useful for\nseveral reasons, firstly because it allows modeling a phase transition or a\nchange of regime. In the model, intelligence growth function appears to be\nhyperbolic function under relatively broad conditions which we list and\ncompare. Subsequently, we also add a stochastic term (Brownian motion) to the\nmodel and investigate the changes in its behavior. The results can be applied\nfor the modeling of dynamics of various processes characterized by\nmultiplicative growth.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 15:29:14 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Kendiukhov", "Ihor", ""]]}, {"id": "2010.01981", "submitter": "Danny Blom", "authors": "Danny Blom, Rudi Pendavingh and Frits C.R. Spieksma", "title": "Filling a theatre in times of corona", "comments": "24 pages, 6 figures, submitted to INFORMS Journal on Applied\n  Analytics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce an optimization problem posed by the Music\nBuilding Eindhoven (MBE) to deal with the economical consequences of the\nCOVID-19 pandemic for theatre halls. We propose a model for maximizing the\nnumber of guests in a theatre hall that respects social distancing rules, and\nis based on trapezoid packings. Computational results show that up to 40% of\nthe normal capacity can be used for a single show setting, and up to 70% in\ncase artists opt for two consecutive performances per evening.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 07:09:29 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Blom", "Danny", ""], ["Pendavingh", "Rudi", ""], ["Spieksma", "Frits C. R.", ""]]}, {"id": "2010.01985", "submitter": "Christopher Pereyda", "authors": "Christopher Pereyda, Lawrence Holder", "title": "Measuring the Complexity of Domains Used to Evaluate AI Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is currently a rapid increase in the number of challenge problem,\nbenchmarking datasets and algorithmic optimization tests for evaluating AI\nsystems. However, there does not currently exist an objective measure to\ndetermine the complexity between these newly created domains. This lack of\ncross-domain examination creates an obstacle to effectively research more\ngeneral AI systems. We propose a theory for measuring the complexity between\nvaried domains. This theory is then evaluated using approximations by a\npopulation of neural network based AI systems. The approximations are compared\nto other well known standards and show it meets intuitions of complexity. An\napplication of this measure is then demonstrated to show its effectiveness as a\ntool in varied situations. The experimental results show this measure has\npromise as an effective tool for aiding in the evaluation of AI systems. We\npropose the future use of such a complexity metric for use in computing an AI\nsystem's intelligence.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 21:53:07 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Pereyda", "Christopher", ""], ["Holder", "Lawrence", ""]]}, {"id": "2010.01986", "submitter": "Wanzheng Zhu", "authors": "Wanzheng Zhu, Chao Zhang, Shuochao Yao, Xiaobin Gao, Jiawei Han", "title": "A Spherical Hidden Markov Model for Semantics-Rich Human Mobility\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of modeling human mobility from semantic trace data,\nwherein each GPS record in a trace is associated with a text message that\ndescribes the user's activity. Existing methods fall short in unveiling human\nmovement regularities, because they either do not model the text data at all or\nsuffer from text sparsity severely. We propose SHMM, a multi-modal spherical\nhidden Markov model for semantics-rich human mobility modeling. Under the\nhidden Markov assumption, SHMM models the generation process of a given trace\nby jointly considering the observed location, time, and text at each step of\nthe trace. The distinguishing characteristic of SHMM is the text modeling part.\nWe use fixed-size vector representations to encode the semantics of the text\nmessages, and model the generation of the l2-normalized text embeddings on a\nunit sphere with the von Mises-Fisher (vMF) distribution. Compared with other\nalternatives like multi-variate Gaussian, our choice of the vMF distribution\nnot only incurs much fewer parameters, but also better leverages the\ndiscriminative power of text embeddings in a directional metric space. The\nparameter inference for the vMF distribution is non-trivial since it involves\nfunctional inversion of ratios of Bessel functions. We theoretically prove\nthat: 1) the classical Expectation-Maximization algorithm can work with vMF\ndistributions; and 2) while closed-form solutions are hard to be obtained for\nthe M-step, Newton's method is guaranteed to converge to the optimal solution\nwith quadratic convergence rate. We have performed extensive experiments on\nboth synthetic and real-life data. The results on synthetic data verify our\ntheoretical analysis; while the results on real-life data demonstrate that SHMM\nlearns meaningful semantics-rich mobility models, outperforms state-of-the-art\nmobility models for next location prediction, and incurs lower training cost.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 13:18:38 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Zhu", "Wanzheng", ""], ["Zhang", "Chao", ""], ["Yao", "Shuochao", ""], ["Gao", "Xiaobin", ""], ["Han", "Jiawei", ""]]}, {"id": "2010.01992", "submitter": "Quentin Bouniot", "authors": "Quentin Bouniot, Ievgen Redko, Romaric Audigier, Ang\\'elique Loesch,\n  Yevhenii Zotkin, Amaury Habrard", "title": "Towards Better Understanding Meta-learning Methods through Multi-task\n  Representation Learning Theory", "comments": "21 pages, 7 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the framework of multi-task representation (MTR)\nlearning where the goal is to use source tasks to learn a representation that\nreduces the sample complexity of solving a target task. We start by reviewing\nrecent advances in MTR theory and show that they can provide novel insights for\npopular meta-learning algorithms when analyzed within this framework. In\nparticular, we highlight a fundamental difference between gradient-based and\nmetric-based algorithms and put forward a theoretical analysis to explain it.\nFinally, we use the derived insights to improve the generalization capacity of\nmeta-learning methods via a new spectral-based regularization term and confirm\nits efficiency through experimental studies on classic few-shot classification\nand continual learning benchmarks. To the best of our knowledge, this is the\nfirst contribution that puts the most recent learning bounds of MTR theory into\npractice of training popular meta-learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 13:24:43 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 15:58:27 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Bouniot", "Quentin", ""], ["Redko", "Ievgen", ""], ["Audigier", "Romaric", ""], ["Loesch", "Ang\u00e9lique", ""], ["Zotkin", "Yevhenii", ""], ["Habrard", "Amaury", ""]]}, {"id": "2010.01999", "submitter": "Ruchika Chavhan", "authors": "Ruchika Chavhan, Biplab Banerjee, Xiao Xiang Zhu, and Subhasis\n  Chaudhuri", "title": "A Novel Actor Dual-Critic Model for Remote Sensing Image Captioning", "comments": "8 pages, 21 figures Accepted at the International Conference on\n  Pattern Recognition (ICPR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We deal with the problem of generating textual captions from optical remote\nsensing (RS) images using the notion of deep reinforcement learning. Due to the\nhigh inter-class similarity in reference sentences describing remote sensing\ndata, jointly encoding the sentences and images encourages prediction of\ncaptions that are semantically more precise than the ground truth in many\ncases. To this end, we introduce an Actor Dual-Critic training strategy where a\nsecond critic model is deployed in the form of an encoder-decoder RNN to encode\nthe latent information corresponding to the original and generated captions.\nWhile all actor-critic methods use an actor to predict sentences for an image\nand a critic to provide rewards, our proposed encoder-decoder RNN guarantees\nhigh-level comprehension of images by sentence-to-image translation. We observe\nthat the proposed model generates sentences on the test data highly similar to\nthe ground truth and is successful in generating even better captions in many\ncritical cases. Extensive experiments on the benchmark Remote Sensing Image\nCaptioning Dataset (RSICD) and the UCM-captions dataset confirm the superiority\nof the proposed approach in comparison to the previous state-of-the-art where\nwe obtain a gain of sharp increments in both the ROUGE-L and CIDEr measures.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 13:35:02 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Chavhan", "Ruchika", ""], ["Banerjee", "Biplab", ""], ["Zhu", "Xiao Xiang", ""], ["Chaudhuri", "Subhasis", ""]]}, {"id": "2010.02005", "submitter": "Maaike de Boer", "authors": "Maaike Burghoorn and Maaike H.T. de Boer and Stephan Raaijmakers", "title": "Gender prediction using limited Twitter Data", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer models have shown impressive performance on a variety of NLP\ntasks. Off-the-shelf, pre-trained models can be fine-tuned for specific NLP\nclassification tasks, reducing the need for large amounts of additional\ntraining data. However, little research has addressed how much data is required\nto accurately fine-tune such pre-trained transformer models, and how much data\nis needed for accurate prediction. This paper explores the usability of BERT (a\nTransformer model for word embedding) for gender prediction on social media.\nForensic applications include detecting gender obfuscation, e.g. males posing\nas females in chat rooms. A Dutch BERT model is fine-tuned on different samples\nof a Dutch Twitter dataset labeled for gender, varying in the number of tweets\nused per person. The results show that finetuning BERT contributes to good\ngender classification performance (80% F1) when finetuned on only 200 tweets\nper person. But when using just 20 tweets per person, the performance of our\nclassifier deteriorates non-steeply (to 70% F1). These results show that even\nwith relatively small amounts of data, BERT can be fine-tuned to accurately\nhelp predict the gender of Twitter users, and, consequently, that it is\npossible to determine gender on the basis of just a low volume of tweets. This\nopens up an operational perspective on the swift detection of gender.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 11:46:07 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Burghoorn", "Maaike", ""], ["de Boer", "Maaike H. T.", ""], ["Raaijmakers", "Stephan", ""]]}, {"id": "2010.02012", "submitter": "Muhammad Yousefnezhad", "authors": "Muhammad Yousefnezhad, Jeffrey Sawalha, Alessandro Selvitella,\n  Daoqiang Zhang", "title": "Deep Representational Similarity Learning for analyzing neural\n  signatures in task-based fMRI dataset", "comments": "Neuroinformatics", "journal-ref": null, "doi": "10.1007/s12021-020-09494-4", "report-no": null, "categories": "eess.IV cs.AI cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Similarity analysis is one of the crucial steps in most fMRI studies.\nRepresentational Similarity Analysis (RSA) can measure similarities of neural\nsignatures generated by different cognitive states. This paper develops Deep\nRepresentational Similarity Learning (DRSL), a deep extension of RSA that is\nappropriate for analyzing similarities between various cognitive tasks in fMRI\ndatasets with a large number of subjects, and high-dimensionality -- such as\nwhole-brain images. Unlike the previous methods, DRSL is not limited by a\nlinear transformation or a restricted fixed nonlinear kernel function -- such\nas Gaussian kernel. DRSL utilizes a multi-layer neural network for mapping\nneural responses to linear space, where this network can implement a customized\nnonlinear transformation for each subject separately. Furthermore, utilizing a\ngradient-based optimization in DRSL can significantly reduce runtime of\nanalysis on large datasets because it uses a batch of samples in each iteration\nrather than all neural responses to find an optimal solution. Empirical studies\non multi-subject fMRI datasets with various tasks -- including visual stimuli,\ndecision making, flavor, and working memory -- confirm that the proposed method\nachieves superior performance to other state-of-the-art RSA algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 18:30:14 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Yousefnezhad", "Muhammad", ""], ["Sawalha", "Jeffrey", ""], ["Selvitella", "Alessandro", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "2010.02039", "submitter": "Manh Duong Phung", "authors": "Manh Duong Phung, Quang Phuc Ha", "title": "Motion-Encoded Particle Swarm Optimization for Moving Target Search\n  Using UAVs", "comments": "Applied Soft Computing, 2020", "journal-ref": null, "doi": "10.1016/j.asoc.2020.106705", "report-no": null, "categories": "cs.RO cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel algorithm named the motion-encoded particle swarm\noptimization (MPSO) for finding a moving target with unmanned aerial vehicles\n(UAVs). From the Bayesian theory, the search problem can be converted to the\noptimization of a cost function that represents the probability of detecting\nthe target. Here, the proposed MPSO is developed to solve that problem by\nencoding the search trajectory as a series of UAV motion paths evolving over\nthe generation of particles in a PSO algorithm. This motion-encoded approach\nallows for preserving important properties of the swarm including the cognitive\nand social coherence, and thus resulting in better solutions. Results from\nextensive simulations with existing methods show that the proposed MPSO\nimproves the detection performance by 24\\% and time performance by 4.71 times\ncompared to the original PSO, and moreover, also outperforms other\nstate-of-the-art metaheuristic optimization algorithms including the artificial\nbee colony (ABC), ant colony optimization (ACO), genetic algorithm (GA),\ndifferential evolution (DE), and tree-seed algorithm (TSA) in most search\nscenarios. Experiments have been conducted with real UAVs in searching for a\ndynamic target in different scenarios to demonstrate MPSO merits in a practical\napplication.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 14:17:49 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Phung", "Manh Duong", ""], ["Ha", "Quang Phuc", ""]]}, {"id": "2010.02047", "submitter": "Wil Van Der Aalst", "authors": "Wil M.P. van der Aalst and Alessandro Berti", "title": "Discovering Object-Centric Petri Nets", "comments": "Preprint of a paper to be published in Fundamenta Informaticae", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques to discover Petri nets from event data assume precisely one case\nidentifier per event. These case identifiers are used to correlate events, and\nthe resulting discovered Petri net aims to describe the life-cycle of\nindividual cases. In reality, there is not one possible case notion, but\nmultiple intertwined case notions. For example, events may refer to mixtures of\norders, items, packages, customers, and products. A package may refer to\nmultiple items, multiple products, one order, and one customer. Therefore, we\nneed to assume that each event refers to a collection of objects, each having a\ntype (instead of a single case identifier). Such object-centric event logs are\ncloser to data in real-life information systems. From an object-centric event\nlog, we want to discover an object-centric Petri net with places that\ncorrespond to object types and transitions that may consume and produce\ncollections of objects of different types. Object-centric Petri nets visualize\nthe complex relationships among objects from different types. This paper\ndiscusses a novel process discovery approach implemented in PM4Py. As will be\ndemonstrated, it is indeed feasible to discover holistic process models that\ncan be used to drill-down into specific viewpoints if needed.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 14:25:42 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["van der Aalst", "Wil M. P.", ""], ["Berti", "Alessandro", ""]]}, {"id": "2010.02065", "submitter": "Xin Qiu", "authors": "Xin Qiu, Risto Miikkulainen", "title": "Detecting Misclassification Errors in Neural Networks with a Gaussian\n  Process Model", "comments": "32 pages, 3 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural network classifiers are deployed in real-world applications, it is\ncrucial that their failures can be detected reliably. One practical solution is\nto assign confidence scores to each prediction, then use these scores to filter\nout possible misclassifications. However, existing confidence metrics are not\nyet sufficiently reliable for this role. This paper presents a new framework\nthat produces a quantitative metric for detecting misclassification errors.\nThis framework, RED, builds an error detector on top of the base classifier and\nestimates uncertainty of the detection scores using Gaussian Processes.\nExperimental comparisons with other error detection methods on 125 UCI datasets\ndemonstrate that this approach is effective. Further implementations on two\nprobabilistic base classifiers and two large deep learning architecture in\nvision tasks further confirm that the method is robust and scalable. Third, an\nempirical analysis of RED with out-of-distribution and adversarial samples\nshows that the method can be used not only to detect errors but also to\nunderstand where they come from. RED can thereby be used to improve\ntrustworthiness of neural network classifiers more broadly in the future.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 15:01:30 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 13:05:09 GMT"}, {"version": "v3", "created": "Fri, 28 May 2021 13:21:05 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Qiu", "Xin", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "2010.02066", "submitter": "R\\'obert Csord\\'as", "authors": "R\\'obert Csord\\'as, Sjoerd van Steenkiste, J\\\"urgen Schmidhuber", "title": "Are Neural Nets Modular? Inspecting Functional Modularity Through\n  Differentiable Weight Masks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks (NNs) whose subnetworks implement reusable functions are\nexpected to offer numerous advantages, including compositionality through\nefficient recombination of functional building blocks, interpretability,\npreventing catastrophic interference, etc. Understanding if and how NNs are\nmodular could provide insights into how to improve them. Current inspection\nmethods, however, fail to link modules to their functionality. In this paper,\nwe present a novel method based on learning binary weight masks to identify\nindividual weights and subnets responsible for specific functions. Using this\npowerful tool, we contribute an extensive study of emerging modularity in NNs\nthat covers several standard architectures and datasets. We demonstrate how\ncommon NNs fail to reuse submodules and offer new insights into the related\nissue of systematic generalization on language tasks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 15:04:11 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 07:24:16 GMT"}, {"version": "v3", "created": "Sat, 6 Mar 2021 17:35:13 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Csord\u00e1s", "R\u00f3bert", ""], ["van Steenkiste", "Sjoerd", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "2010.02068", "submitter": "Bo Lin", "authors": "Bo Lin, Bissan Ghaddar, Jatin Nathwani", "title": "Deep Reinforcement Learning for Electric Vehicle Routing Problem with\n  Time Windows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past decade has seen a rapid penetration of electric vehicles (EV) in the\nmarket, more and more logistics and transportation companies start to deploy\nEVs for service provision. In order to model the operations of a commercial EV\nfleet, we utilize the EV routing problem with time windows (EVRPTW). In this\nresearch, we propose an end-to-end deep reinforcement learning framework to\nsolve the EVRPTW. In particular, we develop an attention model incorporating\nthe pointer network and a graph embedding technique to parameterize a\nstochastic policy for solving the EVRPTW. The model is then trained using\npolicy gradient with rollout baseline. Our numerical studies show that the\nproposed model is able to efficiently solve EVRPTW instances of large sizes\nthat are not solvable with any existing approaches.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 15:06:02 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 01:14:31 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 18:51:21 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lin", "Bo", ""], ["Ghaddar", "Bissan", ""], ["Nathwani", "Jatin", ""]]}, {"id": "2010.02069", "submitter": "Oskar van der Wal MSc", "authors": "Oskar van der Wal, Silvan de Boer, Elia Bruni and Dieuwke Hupkes", "title": "The Grammar of Emergent Languages", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the syntactic properties of languages emerged in\nreferential games, using unsupervised grammar induction (UGI) techniques\noriginally designed to analyse natural language. We show that the considered\nUGI techniques are appropriate to analyse emergent languages and we then study\nif the languages that emerge in a typical referential game setup exhibit\nsyntactic structure, and to what extent this depends on the maximum message\nlength and number of symbols that the agents are allowed to use. Our\nexperiments demonstrate that a certain message length and vocabulary size are\nrequired for structure to emerge, but they also illustrate that more\nsophisticated game scenarios are required to obtain syntactic properties more\nakin to those observed in human language. We argue that UGI techniques should\nbe part of the standard toolkit for analysing emergent languages and release a\ncomprehensive library to facilitate such analysis for future researchers.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 15:06:27 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 17:52:45 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["van der Wal", "Oskar", ""], ["de Boer", "Silvan", ""], ["Bruni", "Elia", ""], ["Hupkes", "Dieuwke", ""]]}, {"id": "2010.02075", "submitter": "Zhan Shi", "authors": "Zhan Shi, Chirag Sakhuja, Milad Hashemi, Kevin Swersky, Calvin Lin", "title": "Learned Hardware/Software Co-Design of Neural Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of deep learning has grown at an exponential rate, giving rise to\nnumerous specialized hardware and software systems for deep learning. Because\nthe design space of deep learning software stacks and hardware accelerators is\ndiverse and vast, prior work considers software optimizations separately from\nhardware architectures, effectively reducing the search space. Unfortunately,\nthis bifurcated approach means that many profitable design points are never\nexplored. This paper instead casts the problem as hardware/software co-design,\nwith the goal of automatically identifying desirable points in the joint design\nspace. The key to our solution is a new constrained Bayesian optimization\nframework that avoids invalid solutions by exploiting the highly constrained\nfeatures of this design space, which are semi-continuous/semi-discrete. We\nevaluate our optimization framework by applying it to a variety of neural\nmodels, improving the energy-delay product by 18% (ResNet) and 40% (DQN) over\nhand-tuned state-of-the-art systems, as well as demonstrating strong results on\nother neural network architectures, such as MLPs and Transformers.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 15:12:52 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Shi", "Zhan", ""], ["Sakhuja", "Chirag", ""], ["Hashemi", "Milad", ""], ["Swersky", "Kevin", ""], ["Lin", "Calvin", ""]]}, {"id": "2010.02114", "submitter": "Divyansh Kaushik", "authors": "Divyansh Kaushik, Amrith Setlur, Eduard Hovy, Zachary C. Lipton", "title": "Explaining The Efficacy of Counterfactually Augmented Data", "comments": "Published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In attempts to produce ML models less reliant on spurious patterns in NLP\ndatasets, researchers have recently proposed curating counterfactually\naugmented data (CAD) via a human-in-the-loop process in which given some\ndocuments and their (initial) labels, humans must revise the text to make a\ncounterfactual label applicable. Importantly, edits that are not necessary to\nflip the applicable label are prohibited. Models trained on the augmented data\nappear, empirically, to rely less on semantically irrelevant words and to\ngeneralize better out of domain. While this work draws loosely on causal\nthinking, the underlying causal model (even at an abstract level) and the\nprinciples underlying the observed out-of-domain improvements remain unclear.\nIn this paper, we introduce a toy analog based on linear Gaussian models,\nobserving interesting relationships between causal models, measurement noise,\nout-of-domain generalization, and reliance on spurious signals. Our analysis\nprovides some insights that help to explain the efficacy of CAD. Moreover, we\ndevelop the hypothesis that while adding noise to causal features should\ndegrade both in-domain and out-of-domain performance, adding noise to\nnon-causal features should lead to relative improvements in out-of-domain\nperformance. This idea inspires a speculative test for determining whether a\nfeature attribution technique has identified the causal spans. If adding noise\n(e.g., by random word flips) to the highlighted spans degrades both in-domain\nand out-of-domain performance on a battery of challenge datasets, but adding\nnoise to the complement gives improvements out-of-domain, it suggests we have\nidentified causal spans. We present a large-scale empirical study comparing\nspans edited to create CAD to those selected by attention and saliency maps.\nAcross numerous domains and models, we find that the hypothesized phenomenon is\npronounced for CAD.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 15:57:07 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 02:21:13 GMT"}, {"version": "v3", "created": "Tue, 23 Mar 2021 02:02:40 GMT"}, {"version": "v4", "created": "Wed, 24 Mar 2021 01:46:15 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Kaushik", "Divyansh", ""], ["Setlur", "Amrith", ""], ["Hovy", "Eduard", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2010.02123", "submitter": "Yung-Sung Chuang", "authors": "Yung-Sung Chuang, Shang-Yu Su, Yun-Nung Chen", "title": "Lifelong Language Knowledge Distillation", "comments": "EMNLP 2020 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is challenging to perform lifelong language learning (LLL) on a stream of\ndifferent tasks without any performance degradation comparing to the multi-task\ncounterparts. To address this issue, we present Lifelong Language Knowledge\nDistillation (L2KD), a simple but efficient method that can be easily applied\nto existing LLL architectures in order to mitigate the degradation.\nSpecifically, when the LLL model is trained on a new task, we assign a teacher\nmodel to first learn the new task, and pass the knowledge to the LLL model via\nknowledge distillation. Therefore, the LLL model can better adapt to the new\ntask while keeping the previously learned knowledge. Experiments show that the\nproposed L2KD consistently improves previous state-of-the-art models, and the\ndegradation comparing to multi-task models in LLL tasks is well mitigated for\nboth sequence generation and text classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 16:10:11 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Chuang", "Yung-Sung", ""], ["Su", "Shang-Yu", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "2010.02140", "submitter": "Jan Deriu", "authors": "Jan Deriu and Don Tuggener and Pius von D\\\"aniken and Jon Ander Campos\n  and Alvaro Rodrigo and Thiziri Belkacem and Aitor Soroa and Eneko Agirre and\n  Mark Cieliebak", "title": "Spot The Bot: A Robust and Efficient Framework for the Evaluation of\n  Conversational Dialogue Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The lack of time-efficient and reliable evaluation methods hamper the\ndevelopment of conversational dialogue systems (chatbots). Evaluations\nrequiring humans to converse with chatbots are time and cost-intensive, put\nhigh cognitive demands on the human judges, and yield low-quality results. In\nthis work, we introduce \\emph{Spot The Bot}, a cost-efficient and robust\nevaluation framework that replaces human-bot conversations with conversations\nbetween bots. Human judges then only annotate for each entity in a conversation\nwhether they think it is human or not (assuming there are humans participants\nin these conversations). These annotations then allow us to rank chatbots\nregarding their ability to mimic the conversational behavior of humans. Since\nwe expect that all bots are eventually recognized as such, we incorporate a\nmetric that measures which chatbot can uphold human-like behavior the longest,\ni.e., \\emph{Survival Analysis}. This metric has the ability to correlate a\nbot's performance to certain of its characteristics (e.g., \\ fluency or\nsensibleness), yielding interpretable results. The comparably low cost of our\nframework allows for frequent evaluations of chatbots during their evaluation\ncycle. We empirically validate our claims by applying \\emph{Spot The Bot} to\nthree domains, evaluating several state-of-the-art chatbots, and drawing\ncomparisons to related work. The framework is released as a ready-to-use tool.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 16:37:52 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Deriu", "Jan", ""], ["Tuggener", "Don", ""], ["von D\u00e4niken", "Pius", ""], ["Campos", "Jon Ander", ""], ["Rodrigo", "Alvaro", ""], ["Belkacem", "Thiziri", ""], ["Soroa", "Aitor", ""], ["Agirre", "Eneko", ""], ["Cieliebak", "Mark", ""]]}, {"id": "2010.02162", "submitter": "Zequn Sun", "authors": "Zequn Sun, Muhao Chen, Wei Hu, Chengming Wang, Jian Dai, Wei Zhang", "title": "Knowledge Association with Hyperbolic Knowledge Graph Embeddings", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing associations for knowledge graphs (KGs) through entity alignment,\nentity type inference and other related tasks benefits NLP applications with\ncomprehensive knowledge representations. Recent related methods built on\nEuclidean embeddings are challenged by the hierarchical structures and\ndifferent scales of KGs. They also depend on high embedding dimensions to\nrealize enough expressiveness. Differently, we explore with low-dimensional\nhyperbolic embeddings for knowledge association. We propose a hyperbolic\nrelational graph neural network for KG embedding and capture knowledge\nassociations with a hyperbolic transformation. Extensive experiments on entity\nalignment and type inference demonstrate the effectiveness and efficiency of\nour method.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 17:11:35 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Sun", "Zequn", ""], ["Chen", "Muhao", ""], ["Hu", "Wei", ""], ["Wang", "Chengming", ""], ["Dai", "Jian", ""], ["Zhang", "Wei", ""]]}, {"id": "2010.02164", "submitter": "Kevin Yang", "authors": "Kevin Yang, Violet Yao, John DeNero, Dan Klein", "title": "A Streaming Approach For Efficient Batched Beam Search", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient batching strategy for variable-length decoding on GPU\narchitectures. During decoding, when candidates terminate or are pruned\naccording to heuristics, our streaming approach periodically \"refills\" the\nbatch before proceeding with a selected subset of candidates. We apply our\nmethod to variable-width beam search on a state-of-the-art machine translation\nmodel. Our method decreases runtime by up to 71% compared to a fixed-width beam\nsearch baseline and 17% compared to a variable-width baseline, while matching\nbaselines' BLEU. Finally, experiments show that our method can speed up\ndecoding in other domains, such as semantic and syntactic parsing.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 17:13:34 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 22:22:27 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Yang", "Kevin", ""], ["Yao", "Violet", ""], ["DeNero", "John", ""], ["Klein", "Dan", ""]]}, {"id": "2010.02178", "submitter": "Bilal Alsallakh", "authors": "Bilal Alsallakh and Narine Kokhlikyan and Vivek Miglani and Jun Yuan\n  and Orion Reblitz-Richardson", "title": "Mind the Pad -- CNNs can Develop Blind Spots", "comments": "Appendix E available at\n  https://drive.google.com/file/d/1bIvRQJIBwJbKTfpg0hNaFX2ThuuDO8PU/view?usp=sharing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how feature maps in convolutional networks are susceptible to spatial\nbias. Due to a combination of architectural choices, the activation at certain\nlocations is systematically elevated or weakened. The major source of this bias\nis the padding mechanism. Depending on several aspects of convolution\narithmetic, this mechanism can apply the padding unevenly, leading to\nasymmetries in the learned weights. We demonstrate how such bias can be\ndetrimental to certain tasks such as small object detection: the activation is\nsuppressed if the stimulus lies in the impacted area, leading to blind spots\nand misdetection. We propose solutions to mitigate spatial bias and demonstrate\nhow they can improve model accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 17:24:48 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Alsallakh", "Bilal", ""], ["Kokhlikyan", "Narine", ""], ["Miglani", "Vivek", ""], ["Yuan", "Jun", ""], ["Reblitz-Richardson", "Orion", ""]]}, {"id": "2010.02193", "submitter": "Danijar Hafner", "authors": "Danijar Hafner, Timothy Lillicrap, Mohammad Norouzi, Jimmy Ba", "title": "Mastering Atari with Discrete World Models", "comments": "Published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent agents need to generalize from past experience to achieve goals\nin complex environments. World models facilitate such generalization and allow\nlearning behaviors from imagined outcomes to increase sample-efficiency. While\nlearning world models from image inputs has recently become feasible for some\ntasks, modeling Atari games accurately enough to derive successful behaviors\nhas remained an open challenge for many years. We introduce DreamerV2, a\nreinforcement learning agent that learns behaviors purely from predictions in\nthe compact latent space of a powerful world model. The world model uses\ndiscrete representations and is trained separately from the policy. DreamerV2\nconstitutes the first agent that achieves human-level performance on the Atari\nbenchmark of 55 tasks by learning behaviors inside a separately trained world\nmodel. With the same computational budget and wall-clock time, Dreamer V2\nreaches 200M frames and surpasses the final performance of the top single-GPU\nagents IQN and Rainbow. DreamerV2 is also applicable to tasks with continuous\nactions, where it learns an accurate world model of a complex humanoid robot\nand solves stand-up and walking from only pixel inputs.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 17:52:14 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 18:57:03 GMT"}, {"version": "v3", "created": "Mon, 3 May 2021 22:35:05 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Hafner", "Danijar", ""], ["Lillicrap", "Timothy", ""], ["Norouzi", "Mohammad", ""], ["Ba", "Jimmy", ""]]}, {"id": "2010.02229", "submitter": "Xusen Yin", "authors": "Xusen Yin, Ralph Weischedel, Jonathan May", "title": "Learning to Generalize for Sequential Decision Making", "comments": "Findings of EMNLP2020, 18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider problems of making sequences of decisions to accomplish tasks,\ninteracting via the medium of language. These problems are often tackled with\nreinforcement learning approaches. We find that these models do not generalize\nwell when applied to novel task domains. However, the large amount of\ncomputation necessary to adequately train and explore the search space of\nsequential decision making, under a reinforcement learning paradigm, precludes\nthe inclusion of large contextualized language models, which might otherwise\nenable the desired generalization ability. We introduce a teacher-student\nimitation learning methodology and a means of converting a reinforcement\nlearning model into a natural language understanding model. Together, these\nmethodologies enable the introduction of contextualized language models into\nthe sequential decision making problem space. We show that models can learn\nfaster and generalize more, leveraging both the imitation learning and the\nreformulation. Our models exceed teacher performance on various held-out\ndecision problems, by up to 7% on in-domain problems and 24% on out-of-domain\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 18:00:03 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Yin", "Xusen", ""], ["Weischedel", "Ralph", ""], ["May", "Jonathan", ""]]}, {"id": "2010.02255", "submitter": "Sebastian Flennerhag", "authors": "Sebastian Flennerhag, Jane X. Wang, Pablo Sprechmann, Francesco Visin,\n  Alexandre Galashov, Steven Kapturowski, Diana L. Borsa, Nicolas Heess, Andre\n  Barreto, Razvan Pascanu", "title": "Temporal Difference Uncertainties as a Signal for Exploration", "comments": "9 pages, 11 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An effective approach to exploration in reinforcement learning is to rely on\nan agent's uncertainty over the optimal policy, which can yield near-optimal\nexploration strategies in tabular settings. However, in non-tabular settings\nthat involve function approximators, obtaining accurate uncertainty estimates\nis almost as challenging a problem. In this paper, we highlight that value\nestimates are easily biased and temporally inconsistent. In light of this, we\npropose a novel method for estimating uncertainty over the value function that\nrelies on inducing a distribution over temporal difference errors. This\nexploration signal controls for state-action transitions so as to isolate\nuncertainty in value that is due to uncertainty over the agent's parameters.\nBecause our measure of uncertainty conditions on state-action transitions, we\ncannot act on this measure directly. Instead, we incorporate it as an intrinsic\nreward and treat exploration as a separate learning problem, induced by the\nagent's temporal difference uncertainties. We introduce a distinct exploration\npolicy that learns to collect data with high estimated uncertainty, which gives\nrise to a curriculum that smoothly changes throughout learning and vanishes in\nthe limit of perfect value estimates. We evaluate our method on hard\nexploration tasks, including Deep Sea and Atari 2600 environments and find that\nour proposed form of exploration facilitates both diverse and deep exploration.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 18:11:22 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 09:21:25 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Flennerhag", "Sebastian", ""], ["Wang", "Jane X.", ""], ["Sprechmann", "Pablo", ""], ["Visin", "Francesco", ""], ["Galashov", "Alexandre", ""], ["Kapturowski", "Steven", ""], ["Borsa", "Diana L.", ""], ["Heess", "Nicolas", ""], ["Barreto", "Andre", ""], ["Pascanu", "Razvan", ""]]}, {"id": "2010.02260", "submitter": "Jatin Ganhotra", "authors": "Jatin Ganhotra, Robert Moore, Sachindra Joshi and Kahini Wadhawan", "title": "Effects of Naturalistic Variation in Goal-Oriented Dialog", "comments": "Findings of EMNLP 2020. The updated datasets are available at:\n  https://github.com/IBM/naturalistic-variation-goal-oriented-dialog-datasets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Existing benchmarks used to evaluate the performance of end-to-end neural\ndialog systems lack a key component: natural variation present in human\nconversations. Most datasets are constructed through crowdsourcing, where the\ncrowd workers follow a fixed template of instructions while enacting the role\nof a user/agent. This results in straight-forward, somewhat routine, and mostly\ntrouble-free conversations, as crowd workers do not think to represent the full\nrange of actions that occur naturally with real users. In this work, we\ninvestigate the impact of naturalistic variation on two goal-oriented datasets:\nbAbI dialog task and Stanford Multi-Domain Dataset (SMD). We also propose new\nand more effective testbeds for both datasets, by introducing naturalistic\nvariation by the user. We observe that there is a significant drop in\nperformance (more than 60% in Ent. F1 on SMD and 85% in per-dialog accuracy on\nbAbI task) of recent state-of-the-art end-to-end neural methods such as BossNet\nand GLMP on both datasets.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 18:13:45 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Ganhotra", "Jatin", ""], ["Moore", "Robert", ""], ["Joshi", "Sachindra", ""], ["Wadhawan", "Kahini", ""]]}, {"id": "2010.02263", "submitter": "Zhao Han", "authors": "Zhao Han, Alexander Wilkinson, Jenna Parrillo, Jordan Allspaw, Holly\n  A. Yanco", "title": "Projection Mapping Implementation: Enabling Direct Externalization of\n  Perception Results and Action Intent to Improve Robot Explainability", "comments": "5 pagers, 4 figures, the AI-HRI Symposium at AAAI-FSS 2020\n  (Proceedings: arXiv:2010.13830)", "journal-ref": "Proceedings of the AI-HRI Symposium at AAAI-FSS 2020, 2020", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing research on non-verbal cues, e.g., eye gaze or arm movement, may not\naccurately present a robot's internal states such as perception results and\naction intent. Projecting the states directly onto a robot's operating\nenvironment has the advantages of being direct, accurate, and more salient,\neliminating mental inference about the robot's intention. However, there is a\nlack of tools for projection mapping in robotics, compared to established\nmotion planning libraries (e.g., MoveIt). In this paper, we detail the\nimplementation of projection mapping to enable researchers and practitioners to\npush the boundaries for better interaction between robots and humans. We also\nprovide practical documentation and code for a sample manipulation projection\nmapping on GitHub: https://github.com/uml-robotics/projection_mapping.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 18:16:20 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 21:42:55 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 16:06:52 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Han", "Zhao", ""], ["Wilkinson", "Alexander", ""], ["Parrillo", "Jenna", ""], ["Allspaw", "Jordan", ""], ["Yanco", "Holly A.", ""]]}, {"id": "2010.02278", "submitter": "Zhao Han", "authors": "Zhao Han and Holly A. Yanco", "title": "Reasons People Want Explanations After Unrecoverable Pre-Handover\n  Failures", "comments": "Proceedings of the ICRA 2020 Workshop on Human-Robot Handovers, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most research on human-robot handovers focuses on the development of\ncomfortable and efficient HRI; few have studied handover failures. If a failure\noccurs in the beginning of the interaction, it prevents the whole handover\nprocess and destroys trust. Here we analyze the underlying reasons why people\nwant explanations in a handover scenario where a robot cannot possess the\nobject. Results suggest that participants set expectations on their request and\nthat a robot should provide explanations rather than non-verbal cues after\nfailing. Participants also expect that their handover request can be done by a\nrobot, and, if not, would like to be able to fix the robot or change the\nrequest based on the provided explanations.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 18:37:23 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Han", "Zhao", ""], ["Yanco", "Holly A.", ""]]}, {"id": "2010.02293", "submitter": "Gabriel Barros", "authors": "Gabriel Moraes Barros and Esther Luna Colombini", "title": "Using Soft Actor-Critic for Low-Level UAV Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Unmanned Aerial Vehicles (UAVs), or drones, have recently been used in\nseveral civil application domains from organ delivery to remote locations to\nwireless network coverage. These platforms, however, are naturally unstable\nsystems for which many different control approaches have been proposed.\nGenerally based on classic and modern control, these algorithms require\nknowledge of the robot's dynamics. However, recently, model-free reinforcement\nlearning has been successfully used for controlling drones without any prior\nknowledge of the robot model. In this work, we present a framework to train the\nSoft Actor-Critic (SAC) algorithm to low-level control of a quadrotor in a\ngo-to-target task. All experiments were conducted under simulation. With the\nexperiments, we show that SAC can not only learn a robust policy, but it can\nalso cope with unseen scenarios. Videos from the simulations are available in\nhttps://www.youtube.com/watch?v=9z8vGs0Ri5g and the code in\nhttps://github.com/larocs/SAC_uav.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 19:16:57 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Barros", "Gabriel Moraes", ""], ["Colombini", "Esther Luna", ""]]}, {"id": "2010.02302", "submitter": "Aleksandr Ermolov", "authors": "Aleksandr Ermolov, Nicu Sebe", "title": "Latent World Models For Intrinsically Motivated Exploration", "comments": "NeurIPS 2020 Spotlight; Code is publicly available at\n  https://github.com/htdt/lwm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider partially observable environments with sparse\nrewards. We present a self-supervised representation learning method for\nimage-based observations, which arranges embeddings respecting temporal\ndistance of observations. This representation is empirically robust to\nstochasticity and suitable for novelty detection from the error of a predictive\nforward model. We consider episodic and life-long uncertainties to guide the\nexploration. We propose to estimate the missing information about the\nenvironment with the world model, which operates in the learned latent space.\nAs a motivation of the method, we analyse the exploration problem in a tabular\nPartially Observable Labyrinth. We demonstrate the method on image-based hard\nexploration environments from the Atari benchmark and report significant\nimprovement with respect to prior work. The source code of the method and all\nthe experiments is available at https://github.com/htdt/lwm.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 19:47:04 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Ermolov", "Aleksandr", ""], ["Sebe", "Nicu", ""]]}, {"id": "2010.02307", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Yu Su, Xifeng Yan, William Yang Wang", "title": "KGPT: Knowledge-Grounded Pre-Training for Data-to-Text Generation", "comments": "Accepted to Main Conference of EMNLP 2020 as Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-to-text generation has recently attracted substantial interests due to\nits wide applications. Existing methods have shown impressive performance on an\narray of tasks. However, they rely on a significant amount of labeled data for\neach task, which is costly to acquire and thus limits their application to new\ntasks and domains. In this paper, we propose to leverage pre-training and\ntransfer learning to address this issue. We propose a knowledge-grounded\npre-training (KGPT), which consists of two parts, 1) a general\nknowledge-grounded generation model to generate knowledge-enriched text. 2) a\npre-training paradigm on a massive knowledge-grounded text corpus crawled from\nthe web. The pre-trained model can be fine-tuned on various data-to-text\ngeneration tasks to generate task-specific text. We adopt three settings,\nnamely fully-supervised, zero-shot, few-shot to evaluate its effectiveness.\nUnder the fully-supervised setting, our model can achieve remarkable gains over\nthe known baselines. Under zero-shot setting, our model without seeing any\nexamples achieves over 30 ROUGE-L on WebNLG while all other baselines fail.\nUnder the few-shot setting, our model only needs about one-fifteenth as many\nlabeled examples to achieve the same level of performance as baseline models.\nThese experiments consistently prove the strong generalization ability of our\nproposed framework https://github.com/wenhuchen/KGPT.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 19:59:05 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 18:09:49 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Chen", "Wenhu", ""], ["Su", "Yu", ""], ["Yan", "Xifeng", ""], ["Wang", "William Yang", ""]]}, {"id": "2010.02317", "submitter": "Sreejan Kumar", "authors": "Sreejan Kumar, Ishita Dasgupta, Jonathan D. Cohen, Nathaniel D. Daw,\n  Thomas L. Griffiths", "title": "Meta-Learning of Structured Task Distributions in Humans and Machines", "comments": "Accepted at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, meta-learning, in which a model is trained on a family of\ntasks (i.e. a task distribution), has emerged as an approach to training neural\nnetworks to perform tasks that were previously assumed to require structured\nrepresentations, making strides toward closing the gap between humans and\nmachines. However, we argue that evaluating meta-learning remains a challenge,\nand can miss whether meta-learning actually uses the structure embedded within\nthe tasks. These meta-learners might therefore still be significantly different\nfrom humans learners. To demonstrate this difference, we first define a new\nmeta-reinforcement learning task in which a structured task distribution is\ngenerated using a compositional grammar. We then introduce a novel approach to\nconstructing a \"null task distribution\" with the same statistical complexity as\nthis structured task distribution but without the explicit rule-based structure\nused to generate the structured task. We train a standard meta-learning agent,\na recurrent network trained with model-free reinforcement learning, and compare\nit with human performance across the two task distributions. We find a double\ndissociation in which humans do better in the structured task distribution\nwhereas agents do better in the null task distribution -- despite comparable\nstatistical complexity. This work highlights that multiple strategies can\nachieve reasonable meta-test performance, and that careful construction of\ncontrol task distributions is a valuable way to understand which strategies\nmeta-learners acquire, and how they might differ from humans.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 20:18:10 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 19:56:09 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 13:42:14 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Kumar", "Sreejan", ""], ["Dasgupta", "Ishita", ""], ["Cohen", "Jonathan D.", ""], ["Daw", "Nathaniel D.", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "2010.02318", "submitter": "Tianfan Fu", "authors": "Tianfan Fu, Cao Xiao, Xinhao Li, Lucas M. Glass, Jimeng Sun", "title": "MIMOSA: Multi-constraint Molecule Sampling for Molecule Optimization", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecule optimization is a fundamental task for accelerating drug discovery,\nwith the goal of generating new valid molecules that maximize multiple drug\nproperties while maintaining similarity to the input molecule. Existing\ngenerative models and reinforcement learning approaches made initial success,\nbut still face difficulties in simultaneously optimizing multiple drug\nproperties. To address such challenges, we propose the MultI-constraint\nMOlecule SAmpling (MIMOSA) approach, a sampling framework to use input molecule\nas an initial guess and sample molecules from the target distribution. MIMOSA\nfirst pretrains two property agnostic graph neural networks (GNNs) for molecule\ntopology and substructure-type prediction, where a substructure can be either\natom or single ring. For each iteration, MIMOSA uses the GNNs' prediction and\nemploys three basic substructure operations (add, replace, delete) to generate\nnew molecules and associated weights. The weights can encode multiple\nconstraints including similarity and drug property constraints, upon which we\nselect promising molecules for next iteration. MIMOSA enables flexible encoding\nof multiple property- and similarity-constraints and can efficiently generate\nnew molecules that satisfy various property constraints and achieved up to\n49.6% relative improvement over the best baseline in terms of success rate.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 20:18:42 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 19:06:13 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Fu", "Tianfan", ""], ["Xiao", "Cao", ""], ["Li", "Xinhao", ""], ["Glass", "Lucas M.", ""], ["Sun", "Jimeng", ""]]}, {"id": "2010.02329", "submitter": "Boxin Wang", "authors": "Boxin Wang, Shuohang Wang, Yu Cheng, Zhe Gan, Ruoxi Jia, Bo Li,\n  Jingjing Liu", "title": "InfoBERT: Improving Robustness of Language Models from An Information\n  Theoretic Perspective", "comments": "Accepted to ICLR 2021. 23 pages, 9 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale language models such as BERT have achieved state-of-the-art\nperformance across a wide range of NLP tasks. Recent studies, however, show\nthat such BERT-based models are vulnerable facing the threats of textual\nadversarial attacks. We aim to address this problem from an\ninformation-theoretic perspective, and propose InfoBERT, a novel learning\nframework for robust fine-tuning of pre-trained language models. InfoBERT\ncontains two mutual-information-based regularizers for model training: (i) an\nInformation Bottleneck regularizer, which suppresses noisy mutual information\nbetween the input and the feature representation; and (ii) a Robust Feature\nregularizer, which increases the mutual information between local robust\nfeatures and global features. We provide a principled way to theoretically\nanalyze and improve the robustness of representation learning for language\nmodels in both standard and adversarial training. Extensive experiments\ndemonstrate that InfoBERT achieves state-of-the-art robust accuracy over\nseveral adversarial datasets on Natural Language Inference (NLI) and Question\nAnswering (QA) tasks. Our code is available at\nhttps://github.com/AI-secure/InfoBERT.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 20:49:26 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 13:24:03 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 03:58:19 GMT"}, {"version": "v4", "created": "Mon, 22 Mar 2021 11:44:30 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Wang", "Boxin", ""], ["Wang", "Shuohang", ""], ["Cheng", "Yu", ""], ["Gan", "Zhe", ""], ["Jia", "Ruoxi", ""], ["Li", "Bo", ""], ["Liu", "Jingjing", ""]]}, {"id": "2010.02353", "submitter": "Julia Kreutzer", "authors": "Wilhelmina Nekoto, Vukosi Marivate, Tshinondiwa Matsila, Timi Fasubaa,\n  Tajudeen Kolawole, Taiwo Fagbohungbe, Solomon Oluwole Akinola, Shamsuddeen\n  Hassan Muhammad, Salomon Kabongo, Salomey Osei, Sackey Freshia, Rubungo Andre\n  Niyongabo, Ricky Macharm, Perez Ogayo, Orevaoghene Ahia, Musie Meressa, Mofe\n  Adeyemi, Masabata Mokgesi-Selinga, Lawrence Okegbemi, Laura Jane Martinus,\n  Kolawole Tajudeen, Kevin Degila, Kelechi Ogueji, Kathleen Siminyu, Julia\n  Kreutzer, Jason Webster, Jamiil Toure Ali, Jade Abbott, Iroro Orife, Ignatius\n  Ezeani, Idris Abdulkabir Dangana, Herman Kamper, Hady Elsahar, Goodness Duru,\n  Ghollah Kioko, Espoir Murhabazi, Elan van Biljon, Daniel Whitenack,\n  Christopher Onyefuluchi, Chris Emezue, Bonaventure Dossou, Blessing Sibanda,\n  Blessing Itoro Bassey, Ayodele Olabiyi, Arshath Ramkilowan, Alp \\\"Oktem,\n  Adewale Akinfaderin, Abdallah Bashir", "title": "Participatory Research for Low-resourced Machine Translation: A Case\n  Study in African Languages", "comments": "Findings of EMNLP 2020; updated benchmarks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in NLP lacks geographic diversity, and the question of how NLP can\nbe scaled to low-resourced languages has not yet been adequately solved.\n\"Low-resourced\"-ness is a complex problem going beyond data availability and\nreflects systemic problems in society. In this paper, we focus on the task of\nMachine Translation (MT), that plays a crucial role for information\naccessibility and communication worldwide. Despite immense improvements in MT\nover the past decade, MT is centered around a few high-resourced languages. As\nMT researchers cannot solve the problem of low-resourcedness alone, we propose\nparticipatory research as a means to involve all necessary agents required in\nthe MT development process. We demonstrate the feasibility and scalability of\nparticipatory research with a case study on MT for African languages. Its\nimplementation leads to a collection of novel translation datasets, MT\nbenchmarks for over 30 languages, with human evaluations for a third of them,\nand enables participants without formal training to make a unique scientific\ncontribution. Benchmarks, models, data, code, and evaluation results are\nreleased under https://github.com/masakhane-io/masakhane-mt.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 21:50:38 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 23:30:45 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Nekoto", "Wilhelmina", ""], ["Marivate", "Vukosi", ""], ["Matsila", "Tshinondiwa", ""], ["Fasubaa", "Timi", ""], ["Kolawole", "Tajudeen", ""], ["Fagbohungbe", "Taiwo", ""], ["Akinola", "Solomon Oluwole", ""], ["Muhammad", "Shamsuddeen Hassan", ""], ["Kabongo", "Salomon", ""], ["Osei", "Salomey", ""], ["Freshia", "Sackey", ""], ["Niyongabo", "Rubungo Andre", ""], ["Macharm", "Ricky", ""], ["Ogayo", "Perez", ""], ["Ahia", "Orevaoghene", ""], ["Meressa", "Musie", ""], ["Adeyemi", "Mofe", ""], ["Mokgesi-Selinga", "Masabata", ""], ["Okegbemi", "Lawrence", ""], ["Martinus", "Laura Jane", ""], ["Tajudeen", "Kolawole", ""], ["Degila", "Kevin", ""], ["Ogueji", "Kelechi", ""], ["Siminyu", "Kathleen", ""], ["Kreutzer", "Julia", ""], ["Webster", "Jason", ""], ["Ali", "Jamiil Toure", ""], ["Abbott", "Jade", ""], ["Orife", "Iroro", ""], ["Ezeani", "Ignatius", ""], ["Dangana", "Idris Abdulkabir", ""], ["Kamper", "Herman", ""], ["Elsahar", "Hady", ""], ["Duru", "Goodness", ""], ["Kioko", "Ghollah", ""], ["Murhabazi", "Espoir", ""], ["van Biljon", "Elan", ""], ["Whitenack", "Daniel", ""], ["Onyefuluchi", "Christopher", ""], ["Emezue", "Chris", ""], ["Dossou", "Bonaventure", ""], ["Sibanda", "Blessing", ""], ["Bassey", "Blessing Itoro", ""], ["Olabiyi", "Ayodele", ""], ["Ramkilowan", "Arshath", ""], ["\u00d6ktem", "Alp", ""], ["Akinfaderin", "Adewale", ""], ["Bashir", "Abdallah", ""]]}, {"id": "2010.02354", "submitter": "Elliot Meyerson", "authors": "Elliot Meyerson and Risto Miikkulainen", "title": "The Traveling Observer Model: Multi-task Learning Through Spatial\n  Variable Embeddings", "comments": "Accepted for spotlight presentation as a conference paper at ICLR\n  2021. Main paper: 9 pages; with references: 12 pages; with appendix: 17\n  pages. Best viewed in color", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper frames a general prediction system as an observer traveling around\na continuous space, measuring values at some locations, and predicting them at\nothers. The observer is completely agnostic about any particular task being\nsolved; it cares only about measurement locations and their values. This\nperspective leads to a machine learning framework in which seemingly unrelated\ntasks can be solved by a single model, by embedding their input and output\nvariables into a shared space. An implementation of the framework is developed\nin which these variable embeddings are learned jointly with internal model\nparameters. In experiments, the approach is shown to (1) recover intuitive\nlocations of variables in space and time, (2) exploit regularities across\nrelated datasets with completely disjoint input and output spaces, and (3)\nexploit regularities across seemingly unrelated tasks, outperforming\ntask-specific single-task models and multi-task learning alternatives. The\nresults suggest that even seemingly unrelated tasks may originate from similar\nunderlying processes, a fact that the traveling observer model can use to make\nbetter predictions.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 21:51:37 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2021 02:27:48 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 23:22:23 GMT"}, {"version": "v4", "created": "Mon, 22 Mar 2021 23:11:12 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Meyerson", "Elliot", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "2010.02369", "submitter": "Aigerim Bogyrbayeva", "authors": "Aigerim Bogyrbayeva, Sungwook Jang, Ankit Shah, Young Jae Jang,\n  Changhyun Kwon", "title": "A Reinforcement Learning Approach for Rebalancing Electric Vehicle\n  Sharing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a reinforcement learning approach for nightly offline\nrebalancing operations in free-floating electric vehicle sharing systems\n(FFEVSS). Due to sparse demand in a network, FFEVSS require relocation of\nelectrical vehicles (EVs) to charging stations and demander nodes, which is\ntypically done by a group of drivers. A shuttle is used to pick up and drop off\ndrivers throughout the network. The objective of this study is to solve the\nshuttle routing problem to finish the rebalancing work in the minimal time. We\nconsider a reinforcement learning framework for the problem, in which a central\ncontroller determines the routing policies of a fleet of multiple shuttles. We\ndeploy a policy gradient method for training recurrent neural networks and\ncompare the obtained policy results with heuristic solutions. Our numerical\nstudies show that unlike the existing solutions in the literature, the proposed\nmethods allow to solve the general version of the problem with no restrictions\non the urban EV network structure and charging requirements of EVs. Moreover,\nthe learned policies offer a wide range of flexibility resulting in a\nsignificant reduction in the time needed to rebalance the network.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 22:24:36 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 14:14:30 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Bogyrbayeva", "Aigerim", ""], ["Jang", "Sungwook", ""], ["Shah", "Ankit", ""], ["Jang", "Young Jae", ""], ["Kwon", "Changhyun", ""]]}, {"id": "2010.02383", "submitter": "Dilip Arumugam", "authors": "Dilip Arumugam and Benjamin Van Roy", "title": "Randomized Value Functions via Posterior State-Abstraction Sampling", "comments": "Accepted to the Workshop on Biological and Artificial Reinforcement\n  Learning (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  State abstraction has been an essential tool for dramatically improving the\nsample efficiency of reinforcement-learning algorithms. Indeed, by exposing and\naccentuating various types of latent structure within the environment,\ndifferent classes of state abstraction have enabled improved theoretical\nguarantees and empirical performance. When dealing with state abstractions that\ncapture structure in the value function, however, a standard assumption is that\nthe true abstraction has been supplied or unrealistically computed a priori,\nleaving open the question of how to efficiently uncover such latent structure\nwhile jointly seeking out optimal behavior. Taking inspiration from the bandit\nliterature, we propose that an agent seeking out latent task structure must\nexplicitly represent and maintain its uncertainty over that structure as part\nof its overall uncertainty about the environment. We introduce a practical\nalgorithm for doing this using two posterior distributions over state\nabstractions and abstract-state values. In empirically validating our approach,\nwe find that substantial performance gains lie in the multi-task setting where\ntasks share a common, low-dimensional representation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 23:04:18 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 17:33:59 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Arumugam", "Dilip", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "2010.02386", "submitter": "Mo Yu", "authors": "Xiaoxiao Guo, Mo Yu, Yupeng Gao, Chuang Gan, Murray Campbell, Shiyu\n  Chang", "title": "Interactive Fiction Game Playing as Multi-Paragraph Reading\n  Comprehension with Reinforcement Learning", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive Fiction (IF) games with real human-written natural language texts\nprovide a new natural evaluation for language understanding techniques. In\ncontrast to previous text games with mostly synthetic texts, IF games pose\nlanguage understanding challenges on the human-written textual descriptions of\ndiverse and sophisticated game worlds and language generation challenges on the\naction command generation from less restricted combinatorial space. We take a\nnovel perspective of IF game solving and re-formulate it as Multi-Passage\nReading Comprehension (MPRC) tasks. Our approaches utilize the context-query\nattention mechanisms and the structured prediction in MPRC to efficiently\ngenerate and evaluate action outputs and apply an object-centric historical\nobservation retrieval strategy to mitigate the partial observability of the\ntextual observations. Extensive experiments on the recent IF benchmark\n(Jericho) demonstrate clear advantages of our approaches achieving high winning\nrates and low data requirements compared to all previous approaches. Our source\ncode is available at: https://github.com/XiaoxiaoGuo/rcdqn.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 23:09:20 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Guo", "Xiaoxiao", ""], ["Yu", "Mo", ""], ["Gao", "Yupeng", ""], ["Gan", "Chuang", ""], ["Campbell", "Murray", ""], ["Chang", "Shiyu", ""]]}, {"id": "2010.02395", "submitter": "Arbi Haza Nasution", "authors": "Arbi Haza Nasution, Yohei Murakami, Toru Ishida", "title": "A Generalized Constraint Approach to Bilingual Dictionary Induction for\n  Low-Resource Language Families", "comments": "30 pages, 13 figures, 14 tables, published in ACM TALLIP", "journal-ref": "ACM Trans. Asian Low-Resour. Lang. Inf. Process. 17, 2, Article 9\n  (November 2017), 29 pages", "doi": "10.1145/3138815", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack or absence of parallel and comparable corpora makes bilingual\nlexicon extraction a difficult task for low-resource languages. The pivot\nlanguage and cognate recognition approaches have been proven useful for\ninducing bilingual lexicons for such languages. We propose constraint-based\nbilingual lexicon induction for closely-related languages by extending\nconstraints from the recent pivot-based induction technique and further\nenabling multiple symmetry assumption cycles to reach many more cognates in the\ntransgraph. We further identify cognate synonyms to obtain many-to-many\ntranslation pairs. This paper utilizes four datasets: one Austronesian\nlow-resource language and three Indo-European high-resource languages. We use\nthree constraint-based methods from our previous work, the Inverse Consultation\nmethod and translation pairs generated from the Cartesian product of input\ndictionaries as baselines. We evaluate our result using the metrics of\nprecision, recall and F-score. Our customizable approach allows the user to\nconduct cross-validation to predict the optimal hyperparameters (cognate\nthreshold and cognate synonym threshold) with various combinations of\nheuristics and the number of symmetry assumption cycles to gain the highest\nF-score. Our proposed methods have statistically significant improvement of\nprecision and F-score compared to our previous constraint-based methods. The\nresults show that our method demonstrates the potential to complement other\nbilingual dictionary creation methods like word alignment models using parallel\ncorpora for high-resource languages while well handling low-resource languages.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 23:41:04 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Nasution", "Arbi Haza", ""], ["Murakami", "Yohei", ""], ["Ishida", "Toru", ""]]}, {"id": "2010.02396", "submitter": "Arbi Haza Nasution", "authors": "Arbi Haza Nasution, Yohei Murakami, Toru Ishida", "title": "Plan Optimization to Bilingual Dictionary Induction for Low-Resource\n  Language Families", "comments": "29 pages, 16 figures, 9 tables, accepted for publication in ACM\n  TALLIP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating bilingual dictionary is the first crucial step in enriching\nlow-resource languages. Especially for the closely-related ones, it has been\nshown that the constraint-based approach is useful for inducing bilingual\nlexicons from two bilingual dictionaries via the pivot language. However, if\nthere are no available machine-readable dictionaries as input, we need to\nconsider manual creation by bilingual native speakers. To reach a goal of\ncomprehensively create multiple bilingual dictionaries, even if we already have\nseveral existing machine-readable bilingual dictionaries, it is still difficult\nto determine the execution order of the constraint-based approach to reducing\nthe total cost. Plan optimization is crucial in composing the order of\nbilingual dictionaries creation with the consideration of the methods and their\ncosts. We formalize the plan optimization for creating bilingual dictionaries\nby utilizing Markov Decision Process (MDP) with the goal to get a more accurate\nestimation of the most feasible optimal plan with the least total cost before\nfully implementing the constraint-based bilingual lexicon induction. We model a\nprior beta distribution of bilingual lexicon induction precision with language\nsimilarity and polysemy of the topology as $\\alpha$ and $\\beta$ parameters. It\nis further used to model cost function and state transition probability. We\nestimated the cost of all investment plan as a baseline for evaluating the\nproposed MDP-based approach with total cost as an evaluation metric. After\nutilizing the posterior beta distribution in the first batch of experiments to\nconstruct the prior beta distribution in the second batch of experiments, the\nresult shows 61.5\\% of cost reduction compared to the estimated all investment\nplan and 39.4\\% of cost reduction compared to the estimated MDP optimal plan.\nThe MDP-based proposal outperformed the baseline on the total cost.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 23:43:40 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Nasution", "Arbi Haza", ""], ["Murakami", "Yohei", ""], ["Ishida", "Toru", ""]]}, {"id": "2010.02407", "submitter": "Vipul Raheja", "authors": "Vipul Raheja and Dimitrios Alikaniotis", "title": "Adversarial Grammatical Error Correction", "comments": "13 Pages, EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent works in Grammatical Error Correction (GEC) have leveraged the\nprogress in Neural Machine Translation (NMT), to learn rewrites from parallel\ncorpora of grammatically incorrect and corrected sentences, achieving\nstate-of-the-art results. At the same time, Generative Adversarial Networks\n(GANs) have been successful in generating realistic texts across many different\ntasks by learning to directly minimize the difference between human-generated\nand synthetic text. In this work, we present an adversarial learning approach\nto GEC, using the generator-discriminator framework. The generator is a\nTransformer model, trained to produce grammatically correct sentences given\ngrammatically incorrect ones. The discriminator is a sentence-pair\nclassification model, trained to judge a given pair of grammatically\nincorrect-correct sentences on the quality of grammatical correction. We\npre-train both the discriminator and the generator on parallel texts and then\nfine-tune them further using a policy gradient method that assigns high rewards\nto sentences which could be true corrections of the grammatically incorrect\ntext. Experimental results on FCE, CoNLL-14, and BEA-19 datasets show that\nAdversarial-GEC can achieve competitive GEC quality compared to NMT-based\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 00:31:33 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Raheja", "Vipul", ""], ["Alikaniotis", "Dimitrios", ""]]}, {"id": "2010.02413", "submitter": "Belinda Z. Li", "authors": "Belinda Z. Li, Sewon Min, Srinivasan Iyer, Yashar Mehdad and Wen-tau\n  Yih", "title": "Efficient One-Pass End-to-End Entity Linking for Questions", "comments": "9 pages, EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ELQ, a fast end-to-end entity linking model for questions, which\nuses a biencoder to jointly perform mention detection and linking in one pass.\nEvaluated on WebQSP and GraphQuestions with extended annotations that cover\nmultiple entities per question, ELQ outperforms the previous state of the art\nby a large margin of +12.7% and +19.6% F1, respectively. With a very fast\ninference time (1.57 examples/s on a single CPU), ELQ can be useful for\ndownstream question answering systems. In a proof-of-concept experiment, we\ndemonstrate that using ELQ significantly improves the downstream QA performance\nof GraphRetriever (arXiv:1911.03868). Code and data available at\nhttps://github.com/facebookresearch/BLINK/tree/master/elq\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 01:14:10 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Li", "Belinda Z.", ""], ["Min", "Sewon", ""], ["Iyer", "Srinivasan", ""], ["Mehdad", "Yashar", ""], ["Yih", "Wen-tau", ""]]}, {"id": "2010.02418", "submitter": "Ang Li", "authors": "Yogesh Balaji, Mehrdad Farajtabar, Dong Yin, Alex Mott, Ang Li", "title": "The Effectiveness of Memory Replay in Large Scale Continual Learning", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study continual learning in the large scale setting where tasks in the\ninput sequence are not limited to classification, and the outputs can be of\nhigh dimension. Among multiple state-of-the-art methods, we found vanilla\nexperience replay (ER) still very competitive in terms of both performance and\nscalability, despite its simplicity. However, a degraded performance is\nobserved for ER with small memory. A further visualization of the feature space\nreveals that the intermediate representation undergoes a distributional drift.\nWhile existing methods usually replay only the input-output pairs, we\nhypothesize that their regularization effect is inadequate for complex deep\nmodels and diverse tasks with small replay buffer size. Following this\nobservation, we propose to replay the activation of the intermediate layers in\naddition to the input-output pairs. Considering that saving raw activation maps\ncan dramatically increase memory and compute cost, we propose the Compressed\nActivation Replay technique, where compressed representations of layer\nactivation are saved to the replay buffer. We show that this approach can\nachieve superior regularization effect while adding negligible memory overhead\nto replay method. Experiments on both the large-scale Taskonomy benchmark with\na diverse set of tasks and standard common datasets (Split-CIFAR and\nSplit-miniImageNet) demonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 01:23:12 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Balaji", "Yogesh", ""], ["Farajtabar", "Mehrdad", ""], ["Yin", "Dong", ""], ["Mott", "Alex", ""], ["Li", "Ang", ""]]}, {"id": "2010.02419", "submitter": "Daniel Nemirovsky", "authors": "Daniel Nemirovsky, Nicolas Thiebaut, Ye Xu, Abhishek Gupta", "title": "Providing Actionable Feedback in Hiring Marketplaces using Generative\n  Adversarial Networks", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning predictors have been increasingly applied in production\nsettings, including in one of the world's largest hiring platforms, Hired, to\nprovide a better candidate and recruiter experience. The ability to provide\nactionable feedback is desirable for candidates to improve their chances of\nachieving success in the marketplace. Until recently, however, methods aimed at\nproviding actionable feedback have been limited in terms of realism and\nlatency. In this work, we demonstrate how, by applying a newly introduced\nmethod based on Generative Adversarial Networks (GANs), we are able to overcome\nthese limitations and provide actionable feedback in real-time to candidates in\nproduction settings. Our experimental results highlight the significant\nbenefits of utilizing a GAN-based approach on our dataset relative to two other\nstate-of-the-art approaches (including over 1000x latency gains). We also\nillustrate the potential impact of this approach in detail on two real\ncandidate profile examples.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 01:26:00 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Nemirovsky", "Daniel", ""], ["Thiebaut", "Nicolas", ""], ["Xu", "Ye", ""], ["Gupta", "Abhishek", ""]]}, {"id": "2010.02433", "submitter": "Yang Li", "authors": "Yang Li, Junier B. Oliva", "title": "Active Feature Acquisition with Generative Surrogate Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world situations allow for the acquisition of additional relevant\ninformation when making an assessment with limited or uncertain data. However,\ntraditional ML approaches either require all features to be acquired beforehand\nor regard part of them as missing data that cannot be acquired. In this work,\nwe consider models that perform active feature acquisition (AFA) and query the\nenvironment for unobserved features to improve the prediction assessments at\nevaluation time. Our work reformulates the Markov decision process (MDP) that\nunderlies the AFA problem as a generative modeling task and optimizes a policy\nvia a novel model-based approach. We propose learning a generative surrogate\nmodel (GSM) that captures the dependencies among input features to assess\npotential information gain from acquisitions. The GSM is leveraged to provide\nintermediate rewards and auxiliary information to aid the agent navigate a\ncomplicated high-dimensional action space and sparse rewards. Furthermore, we\nextend AFA in a task we coin active instance recognition (AIR) for the\nunsupervised case where the target variables are the unobserved features\nthemselves and the goal is to collect information for a particular instance in\na cost-efficient way. Empirical results demonstrate that our approach achieves\nconsiderably better performance than previous state of the art methods on both\nsupervised and unsupervised tasks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 02:10:06 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 15:49:25 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Li", "Yang", ""], ["Oliva", "Junier B.", ""]]}, {"id": "2010.02451", "submitter": "Yansheng Li", "authors": "Yansheng Li, Song Ouyang, and Yongjun Zhang", "title": "Collaboratively boosting data-driven deep learning and knowledge-guided\n  ontological reasoning for semantic segmentation of remote sensing imagery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one kind of architecture from the deep learning family, deep semantic\nsegmentation network (DSSN) achieves a certain degree of success on the\nsemantic segmentation task and obviously outperforms the traditional methods\nbased on hand-crafted features. As a classic data-driven technique, DSSN can be\ntrained by an end-to-end mechanism and competent for employing the low-level\nand mid-level cues (i.e., the discriminative image structure) to understand\nimages, but lacks the high-level inference ability. By contrast, human beings\nhave an excellent inference capacity and can be able to reliably interpret the\nRS imagery only when human beings master the basic RS domain knowledge. In\nliterature, ontological modeling and reasoning is an ideal way to imitate and\nemploy the domain knowledge of human beings, but is still rarely explored and\nadopted in the RS domain. To remedy the aforementioned critical limitation of\nDSSN, this paper proposes a collaboratively boosting framework (CBF) to combine\ndata-driven deep learning module and knowledge-guided ontological reasoning\nmodule in an iterative way.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 03:32:17 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Li", "Yansheng", ""], ["Ouyang", "Song", ""], ["Zhang", "Yongjun", ""]]}, {"id": "2010.02456", "submitter": "Andrew Lohn", "authors": "Andrew J. Lohn", "title": "Downscaling Attack and Defense: Turning What You See Back Into What You\n  Get", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The resizing of images, which is typically a required part of preprocessing\nfor computer vision systems, is vulnerable to attack. Images can be created\nsuch that the image is completely different at machine-vision scales than at\nother scales and the default settings for some common computer vision and\nmachine learning systems are vulnerable. We show that defenses exist and are\ntrivial to administer provided that defenders are aware of the threat. These\nattacks and defenses help to establish the role of input sanitization in\nmachine learning.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 03:41:05 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 18:24:29 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Lohn", "Andrew J.", ""]]}, {"id": "2010.02474", "submitter": "Martin Klissarov", "authors": "Martin Klissarov and Doina Precup", "title": "Reward Propagation Using Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Potential-based reward shaping provides an approach for designing good reward\nfunctions, with the purpose of speeding up learning. However, automatically\nfinding potential functions for complex environments is a difficult problem (in\nfact, of the same difficulty as learning a value function from scratch). We\npropose a new framework for learning potential functions by leveraging ideas\nfrom graph representation learning. Our approach relies on Graph Convolutional\nNetworks which we use as a key ingredient in combination with the probabilistic\ninference view of reinforcement learning. More precisely, we leverage Graph\nConvolutional Networks to perform message passing from rewarding states. The\npropagated messages can then be used as potential functions for reward shaping\nto accelerate learning. We verify empirically that our approach can achieve\nconsiderable improvements in both small and high-dimensional control problems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 04:38:16 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 02:37:16 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Klissarov", "Martin", ""], ["Precup", "Doina", ""]]}, {"id": "2010.02479", "submitter": "HanQin Cai", "authors": "HanQin Cai, Daniel Mckenzie, Wotao Yin, Zhenliang Zhang", "title": "A One-bit, Comparison-Based Gradient Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study zeroth-order optimization for convex functions where we further\nassume that function evaluations are unavailable. Instead, one only has access\nto a $\\textit{comparison oracle}$, which given two points $x$ and $y$ returns a\nsingle bit of information indicating which point has larger function value,\n$f(x)$ or $f(y)$. By treating the gradient as an unknown signal to be\nrecovered, we show how one can use tools from one-bit compressed sensing to\nconstruct a robust and reliable estimator of the normalized gradient. We then\npropose an algorithm, coined SCOBO, that uses this estimator within a gradient\ndescent scheme. We show that when $f(x)$ has some low dimensional structure\nthat can be exploited, SCOBO outperforms the state-of-the-art in terms of query\ncomplexity. Our theoretical claims are verified by extensive numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 05:01:38 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 10:24:58 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Cai", "HanQin", ""], ["Mckenzie", "Daniel", ""], ["Yin", "Wotao", ""], ["Zhang", "Zhenliang", ""]]}, {"id": "2010.02488", "submitter": "Zhiwei Xu", "authors": "Zhiwei Xu, Thalaiyasingam Ajanthan, Vibhav Vineet, Richard Hartley", "title": "RANP: Resource Aware Neuron Pruning at Initialization for 3D CNNs", "comments": "International Conference on 3D Vision (3DV), 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although 3D Convolutional Neural Networks (CNNs) are essential for most\nlearning based applications involving dense 3D data, their applicability is\nlimited due to excessive memory and computational requirements. Compressing\nsuch networks by pruning therefore becomes highly desirable. However, pruning\n3D CNNs is largely unexplored possibly because of the complex nature of typical\npruning algorithms that embeds pruning into an iterative optimization paradigm.\nIn this work, we introduce a Resource Aware Neuron Pruning (RANP) algorithm\nthat prunes 3D CNNs at initialization to high sparsity levels. Specifically,\nthe core idea is to obtain an importance score for each neuron based on their\nsensitivity to the loss function. This neuron importance is then reweighted\naccording to the neuron resource consumption related to FLOPs or memory. We\ndemonstrate the effectiveness of our pruning method on 3D semantic segmentation\nwith widely used 3D-UNets on ShapeNet and BraTS'18 as well as on video\nclassification with MobileNetV2 and I3D on UCF101 dataset. In these\nexperiments, our RANP leads to roughly 50-95 reduction in FLOPs and 35-80\nreduction in memory with negligible loss in accuracy compared to the unpruned\nnetworks. This significantly reduces the computational resources required to\ntrain 3D CNNs. The pruned network obtained by our algorithm can also be easily\nscaled up and transferred to another dataset for training.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 05:34:39 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 03:09:59 GMT"}, {"version": "v3", "created": "Sun, 25 Oct 2020 11:52:31 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Xu", "Zhiwei", ""], ["Ajanthan", "Thalaiyasingam", ""], ["Vineet", "Vibhav", ""], ["Hartley", "Richard", ""]]}, {"id": "2010.02495", "submitter": "Praveen Kumar Bodigutla", "authors": "Praveen Kumar Bodigutla, Aditya Tiwari, Josep Valls Vargas, Lazaros\n  Polymenakos, Spyros Matsoukas", "title": "Joint Turn and Dialogue level User Satisfaction Estimation on\n  Multi-Domain Conversations", "comments": "Findings of EMNLP, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue level quality estimation is vital for optimizing data driven\ndialogue management. Current automated methods to estimate turn and dialogue\nlevel user satisfaction employ hand-crafted features and rely on complex\nannotation schemes, which reduce the generalizability of the trained models. We\npropose a novel user satisfaction estimation approach which minimizes an\nadaptive multi-task loss function in order to jointly predict turn-level\nResponse Quality labels provided by experts and explicit dialogue-level ratings\nprovided by end users. The proposed BiLSTM based deep neural net model\nautomatically weighs each turn's contribution towards the estimated\ndialogue-level rating, implicitly encodes temporal dependencies, and removes\nthe need to hand-craft features.\n  On dialogues sampled from 28 Alexa domains, two dialogue systems and three\nuser groups, the joint dialogue-level satisfaction estimation model achieved up\nto an absolute 27% (0.43->0.70) and 7% (0.63->0.70) improvement in linear\ncorrelation performance over baseline deep neural net and benchmark Gradient\nboosting regression models, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 05:53:13 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 21:10:47 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Bodigutla", "Praveen Kumar", ""], ["Tiwari", "Aditya", ""], ["Vargas", "Josep Valls", ""], ["Polymenakos", "Lazaros", ""], ["Matsoukas", "Spyros", ""]]}, {"id": "2010.02510", "submitter": "Lily Ou", "authors": "Sophie Groenwold, Lily Ou, Aesha Parekh, Samhita Honnavalli, Sharon\n  Levy, Diba Mirza, William Yang Wang", "title": "Investigating African-American Vernacular English in Transformer-Based\n  Text Generation", "comments": "7 pages, EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth of social media has encouraged the written use of African American\nVernacular English (AAVE), which has traditionally been used only in oral\ncontexts. However, NLP models have historically been developed using dominant\nEnglish varieties, such as Standard American English (SAE), due to text corpora\navailability. We investigate the performance of GPT-2 on AAVE text by creating\na dataset of intent-equivalent parallel AAVE/SAE tweet pairs, thereby isolating\nsyntactic structure and AAVE- or SAE-specific language for each pair. We\nevaluate each sample and its GPT-2 generated text with pretrained sentiment\nclassifiers and find that while AAVE text results in more classifications of\nnegative sentiment than SAE, the use of GPT-2 generally increases occurrences\nof positive sentiment for both. Additionally, we conduct human evaluation of\nAAVE and SAE text generated with GPT-2 to compare contextual rigor and overall\nquality.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 06:27:02 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 04:00:46 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Groenwold", "Sophie", ""], ["Ou", "Lily", ""], ["Parekh", "Aesha", ""], ["Honnavalli", "Samhita", ""], ["Levy", "Sharon", ""], ["Mirza", "Diba", ""], ["Wang", "William Yang", ""]]}, {"id": "2010.02542", "submitter": "Sakshi Udeshi", "authors": "Ezekiel Soremekun and Sakshi Udeshi and Sudipta Chattopadhyay", "title": "Astraea: Grammar-based Fairness Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Software often produces biased outputs. In particular, machine learning (ML)\nbased software are known to produce erroneous predictions when processing\ndiscriminatory inputs. Such unfair program behavior can be caused by societal\nbias. In the last few years, Amazon, Microsoft and Google have provided\nsoftware services that produce unfair outputs, mostly due to societal bias\n(e.g. gender or race). In such events, developers are saddled with the task of\nconducting fairness testing. Fairness testing is challenging; developers are\ntasked with generating discriminatory inputs that reveal and explain biases.\n  We propose a grammar-based fairness testing approach (called ASTRAEA) which\nleverages context-free grammars to generate discriminatory inputs that reveal\nfairness violations in software systems. Using probabilistic grammars, ASTRAEA\nalso provides fault diagnosis by isolating the cause of observed software bias.\nASTRAEA's diagnoses facilitate the improvement of ML fairness.\n  ASTRAEA was evaluated on 18 software systems that provide three major natural\nlanguage processing (NLP) services. In our evaluation, ASTRAEA generated\nfairness violations with a rate of ~18%. ASTRAEA generated over 573K\ndiscriminatory test cases and found over 102K fairness violations. Furthermore,\nASTRAEA improves software fairness by ~76%, via model-retraining.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 08:19:01 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 12:11:01 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Soremekun", "Ezekiel", ""], ["Udeshi", "Sakshi", ""], ["Chattopadhyay", "Sudipta", ""]]}, {"id": "2010.02556", "submitter": "Sumegh Roychowdhury", "authors": "Sumegh Roychowdhury, Sumedh A. Sontakke, Nikaash Puri, Mausoom Sarkar,\n  Milan Aggarwal, Pinkesh Badjatiya, Balaji Krishnamurthy, Laurent Itti", "title": "Unsupervised Hierarchical Concept Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering concepts (or temporal abstractions) in an unsupervised manner\nfrom demonstration data in the absence of an environment is an important\nproblem. Organizing these discovered concepts hierarchically at different\nlevels of abstraction is useful in discovering patterns, building ontologies,\nand generating tutorials from demonstration data. However, recent work to\ndiscover such concepts without access to any environment does not discover\nrelationships (or a hierarchy) between these discovered concepts. In this\npaper, we present a Transformer-based concept abstraction architecture UNHCLE\n(pronounced uncle) that extracts a hierarchy of concepts in an unsupervised way\nfrom demonstration data. We empirically demonstrate how UNHCLE discovers\nmeaningful hierarchies using datasets from Chess and Cooking domains. Finally,\nwe show how UNHCLE learns meaningful language labels for concepts by using\ndemonstration data augmented with natural language for cooking and chess. All\nof our code is available at https://github.com/UNHCLE/UNHCLE\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 09:04:01 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Roychowdhury", "Sumegh", ""], ["Sontakke", "Sumedh A.", ""], ["Puri", "Nikaash", ""], ["Sarkar", "Mausoom", ""], ["Aggarwal", "Milan", ""], ["Badjatiya", "Pinkesh", ""], ["Krishnamurthy", "Balaji", ""], ["Itti", "Laurent", ""]]}, {"id": "2010.02558", "submitter": "Sekitoshi Kanai", "authors": "Sekitoshi Kanai, Masanori Yamada, Shin'ya Yamaguchi, Hiroshi\n  Takahashi, Yasutoshi Ida", "title": "Constraining Logits by Bounded Function for Adversarial Robustness", "comments": "19 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for improving adversarial robustness by addition of a new\nbounded function just before softmax. Recent studies hypothesize that small\nlogits (inputs of softmax) by logit regularization can improve adversarial\nrobustness of deep learning. Following this hypothesis, we analyze norms of\nlogit vectors at the optimal point under the assumption of universal\napproximation and explore new methods for constraining logits by addition of a\nbounded function before softmax. We theoretically and empirically reveal that\nsmall logits by addition of a common activation function, e.g., hyperbolic\ntangent, do not improve adversarial robustness since input vectors of the\nfunction (pre-logit vectors) can have large norms. From the theoretical\nfindings, we develop the new bounded function. The addition of our function\nimproves adversarial robustness because it makes logit and pre-logit vectors\nhave small norms. Since our method only adds one activation function before\nsoftmax, it is easy to combine our method with adversarial training. Our\nexperiments demonstrate that our method is comparable to logit regularization\nmethods in terms of accuracies on adversarially perturbed datasets without\nadversarial training. Furthermore, it is superior or comparable to logit\nregularization methods and a recent defense method (TRADES) when using\nadversarial training.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 09:04:58 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Kanai", "Sekitoshi", ""], ["Yamada", "Masanori", ""], ["Yamaguchi", "Shin'ya", ""], ["Takahashi", "Hiroshi", ""], ["Ida", "Yasutoshi", ""]]}, {"id": "2010.02565", "submitter": "Xiaoyu Kou", "authors": "Xiaoyu Kou, Yankai Lin, Shaobo Liu, Peng Li, Jie Zhou, Yan Zhang", "title": "Disentangle-based Continual Graph Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding (GE) methods embed nodes (and/or edges) in graph into a\nlow-dimensional semantic space, and have shown its effectiveness in modeling\nmulti-relational data. However, existing GE models are not practical in\nreal-world applications since it overlooked the streaming nature of incoming\ndata. To address this issue, we study the problem of continual graph\nrepresentation learning which aims to continually train a GE model on new data\nto learn incessantly emerging multi-relational data while avoiding\ncatastrophically forgetting old learned knowledge. Moreover, we propose a\ndisentangle-based continual graph representation learning (DiCGRL) framework\ninspired by the human's ability to learn procedural knowledge. The experimental\nresults show that DiCGRL could effectively alleviate the catastrophic\nforgetting problem and outperform state-of-the-art continual learning models.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 09:20:30 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 05:34:42 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 08:21:52 GMT"}, {"version": "v4", "created": "Tue, 24 Nov 2020 06:33:45 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Kou", "Xiaoyu", ""], ["Lin", "Yankai", ""], ["Liu", "Shaobo", ""], ["Li", "Peng", ""], ["Zhou", "Jie", ""], ["Zhang", "Yan", ""]]}, {"id": "2010.02586", "submitter": "Carel van Niekerk", "authors": "Carel van Niekerk, Michael Heck, Christian Geishauser, Hsien-Chin Lin,\n  Nurul Lubis, Marco Moresi, Milica Ga\\v{s}i\\'c", "title": "Knowing What You Know: Calibrating Dialogue Belief State Distributions\n  via Ensembles", "comments": "7 pages, 9 figures, to be published in Findings of EMNLP 2020, code\n  available at:\n  https://gitlab.cs.uni-duesseldorf.de/general/dsml/calibrating-dialogue-belief-state-distributions", "journal-ref": "Proceedings of the Findings of the Association for Computational\n  Linguistics: EMNLP 2020, Pages 3096-3102; Association for Computational\n  Linguistics", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to accurately track what happens during a conversation is\nessential for the performance of a dialogue system. Current state-of-the-art\nmulti-domain dialogue state trackers achieve just over 55% accuracy on the\ncurrent go-to benchmark, which means that in almost every second dialogue turn\nthey place full confidence in an incorrect dialogue state. Belief trackers, on\nthe other hand, maintain a distribution over possible dialogue states. However,\nthey lack in performance compared to dialogue state trackers, and do not\nproduce well calibrated distributions. In this work we present state-of-the-art\nperformance in calibration for multi-domain dialogue belief trackers using a\ncalibrated ensemble of models. Our resulting dialogue belief tracker also\noutperforms previous dialogue belief tracking models in terms of accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 09:51:04 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 10:56:46 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["van Niekerk", "Carel", ""], ["Heck", "Michael", ""], ["Geishauser", "Christian", ""], ["Lin", "Hsien-Chin", ""], ["Lubis", "Nurul", ""], ["Moresi", "Marco", ""], ["Ga\u0161i\u0107", "Milica", ""]]}, {"id": "2010.02592", "submitter": "Eyal Ben-David", "authors": "Eyal Ben-David, Orgad Keller, Eric Malmi, Idan Szpektor, Roi Reichart", "title": "Semantically Driven Sentence Fusion: Modeling and Evaluation", "comments": "This paper was accepted to Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentence fusion is the task of joining related sentences into coherent text.\nCurrent training and evaluation schemes for this task are based on single\nreference ground-truths and do not account for valid fusion variants. We show\nthat this hinders models from robustly capturing the semantic relationship\nbetween input sentences. To alleviate this, we present an approach in which\nground-truth solutions are automatically expanded into multiple references via\ncurated equivalence classes of connective phrases. We apply this method to a\nlarge-scale dataset and use the augmented dataset for both model training and\nevaluation. To improve the learning of semantic representation using multiple\nreferences, we enrich the model with auxiliary discourse classification tasks\nunder a multi-tasking framework. Our experiments highlight the improvements of\nour approach over state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 10:06:01 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Ben-David", "Eyal", ""], ["Keller", "Orgad", ""], ["Malmi", "Eric", ""], ["Szpektor", "Idan", ""], ["Reichart", "Roi", ""]]}, {"id": "2010.02600", "submitter": "Isabelle G. Lee", "authors": "Isabelle G. Lee, Vera Zu, Sai Srujana Buddi, Dennis Liang, Purva\n  Kulkarni, Jack G.M. Fitzgerald", "title": "Converting the Point of View of Messages Spoken to Virtual Assistants", "comments": "10 pages, 11 figures, Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual Assistants can be quite literal at times. If the user says \"tell Bob\nI love him,\" most virtual assistants will extract the message \"I love him\" and\nsend it to the user's contact named Bob, rather than properly converting the\nmessage to \"I love you.\" We designed a system to allow virtual assistants to\ntake a voice message from one user, convert the point of view of the message,\nand then deliver the result to its target user. We developed a rule-based\nmodel, which integrates a linear text classification model, part-of-speech\ntagging, and constituency parsing with rule-based transformation methods. We\nalso investigated Neural Machine Translation (NMT) approaches, including LSTMs,\nCopyNet, and T5. We explored 5 metrics to gauge both naturalness and\nfaithfulness automatically, and we chose to use BLEU plus METEOR for\nfaithfulness and relative perplexity using a separately trained language model\n(GPT) for naturalness. Transformer-Copynet and T5 performed similarly on\nfaithfulness metrics, with T5 achieving slight edge, a BLEU score of 63.8 and a\nMETEOR score of 83.0. CopyNet was the most natural, with a relative perplexity\nof 1.59. CopyNet also has 37 times fewer parameters than T5. We have publicly\nreleased our dataset, which is composed of 46,565 crowd-sourced samples.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 10:19:39 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 01:31:27 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Lee", "Isabelle G.", ""], ["Zu", "Vera", ""], ["Buddi", "Sai Srujana", ""], ["Liang", "Dennis", ""], ["Kulkarni", "Purva", ""], ["Fitzgerald", "Jack G. M.", ""]]}, {"id": "2010.02602", "submitter": "Guanglin Niu", "authors": "Guanglin Niu, Bo Li, Yongfei Zhang, Yongpan Sheng, Chuan Shi, Jingyang\n  Li, Shiliang Pu", "title": "Joint Semantics and Data-Driven Path Representation for Knowledge Graph\n  Inference", "comments": "12 pages, 6 tables, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference on a large-scale knowledge graph (KG) is of great importance for KG\napplications like question answering. The path-based reasoning models can\nleverage much information over paths other than pure triples in the KG, which\nface several challenges: all the existing path-based methods are data-driven,\nlacking explainability for path representation. Besides, some methods either\nconsider only relational paths or ignore the heterogeneity between entities and\nrelations both contained in paths, which cannot capture the rich semantics of\npaths well. To address the above challenges, in this work, we propose a novel\njoint semantics and data-driven path representation that balances\nexplainability and generalization in the framework of KG embedding. More\nspecifically, we inject horn rules to obtain the condensed paths by the\ntransparent and explainable path composition procedure. The entity converter is\ndesigned to transform the entities along paths into the representations in the\nsemantic level similar to relations for reducing the heterogeneity between\nentities and relations, in which the KGs both with and without type information\nare considered. Our proposed model is evaluated on two classes of tasks: link\nprediction and path query answering task. The experimental results show that it\nhas a significant performance gain over several different state-of-the-art\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 10:24:45 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Niu", "Guanglin", ""], ["Li", "Bo", ""], ["Zhang", "Yongfei", ""], ["Sheng", "Yongpan", ""], ["Shi", "Chuan", ""], ["Li", "Jingyang", ""], ["Pu", "Shiliang", ""]]}, {"id": "2010.02613", "submitter": "Jonas Umlauft", "authors": "Jonas Umlauft, Armin Lederer, Thomas Beckers, Sandra Hirche", "title": "Real-time Uncertainty Decomposition for Online Learning Control", "comments": "Submitted to ICRL 2021, updated after rebuttal period", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety-critical decisions based on machine learning models require a clear\nunderstanding of the involved uncertainties to avoid hazardous or risky\nsituations. While aleatoric uncertainty can be explicitly modeled given a\nparametric description, epistemic uncertainty rather describes the presence or\nabsence of training data. This paper proposes a novel generic method for\nmodeling epistemic uncertainty and shows its advantages over existing\napproaches for neural networks on various data sets. It can be directly\ncombined with aleatoric uncertainty estimates and allows for prediction in\nreal-time as the inference is sample-free. We exploit this property in a\nmodel-based quadcopter control setting and demonstrate how the controller\nbenefits from a differentiation between aleatoric and epistemic uncertainty in\nonline learning of thermal disturbances.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 10:46:27 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 18:12:06 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Umlauft", "Jonas", ""], ["Lederer", "Armin", ""], ["Beckers", "Thomas", ""], ["Hirche", "Sandra", ""]]}, {"id": "2010.02626", "submitter": "Elvis Chen", "authors": "Chong Chen, Qinghui Xing, Xin Ding, Yaru Xue, Tianfu Zhong", "title": "A Novel Neural Network Training Framework with Data Assimilation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the prosperity of deep learning has revolutionized the\nArtificial Neural Networks. However, the dependence of gradients and the\noffline training mechanism in the learning algorithms prevents the ANN for\nfurther improvement. In this study, a gradient-free training framework based on\ndata assimilation is proposed to avoid the calculation of gradients. In data\nassimilation algorithms, the error covariance between the forecasts and\nobservations is used to optimize the parameters. Feedforward Neural Networks\n(FNNs) are trained by gradient decent, data assimilation algorithms (Ensemble\nKalman Filter (EnKF) and Ensemble Smoother with Multiple Data Assimilation\n(ESMDA)), respectively. ESMDA trains FNN with pre-defined iterations by\nupdating the parameters using all the available observations which can be\nregard as offline learning. EnKF optimize FNN when new observation available by\nupdating parameters which can be regard as online learning. Two synthetic cases\nwith the regression of a Sine Function and a Mexican Hat function are assumed\nto validate the effectiveness of the proposed framework. The Root Mean Square\nError (RMSE) and coefficient of determination (R2) are used as criteria to\nassess the performance of different methods. The results show that the proposed\ntraining framework performed better than the gradient decent method. The\nproposed framework provides alternatives for online/offline training the\nexisting ANNs (e.g., Convolutional Neural Networks, Recurrent Neural Networks)\nwithout the dependence of gradients.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 11:12:23 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Chen", "Chong", ""], ["Xing", "Qinghui", ""], ["Ding", "Xin", ""], ["Xue", "Yaru", ""], ["Zhong", "Tianfu", ""]]}, {"id": "2010.02627", "submitter": "Felipe Meneguzzi", "authors": "Nir Oren and Felipe Meneguzzi", "title": "Norm Identification through Plan Recognition", "comments": "Published as \"In 15th International Workshop on Coordination,\n  Organisations, Institutions and Norms (COIN 2013) @AAMAS, Saint Paul, MN,\n  USA, 2013.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Societal rules, as exemplified by norms, aim to provide a degree of\nbehavioural stability to multi-agent societies. Norms regulate a society using\nthe deontic concepts of permissions, obligations and prohibitions to specify\nwhat can, must and must not occur in a society. Many implementations of\nnormative systems assume various combinations of the following assumptions:\nthat the set of norms is static and defined at design time; that agents joining\na society are instantly informed of the complete set of norms; that the set of\nagents within a society does not change; and that all agents are aware of the\nexisting norms. When any one of these assumptions is dropped, agents need a\nmechanism to identify the set of norms currently present within a society, or\nrisk unwittingly violating the norms. In this paper, we develop a norm\nidentification mechanism that uses a combination of parsing-based plan\nrecognition and Hierarchical Task Network (HTN) planning mechanisms, which\noperates by analysing the actions performed by other agents. While our basic\nmechanism cannot learn in situations where norm violations take place, we\ndescribe an extension which is able to operate in the presence of violations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 11:18:52 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Oren", "Nir", ""], ["Meneguzzi", "Felipe", ""]]}, {"id": "2010.02628", "submitter": "Tatiana Makhalova", "authors": "Tatiana Makhalova, Aleksey Buzmakov, Sergei O. Kuznetsov and Amedeo\n  Napoli", "title": "Discovery data topology with the closure structure. Theoretical and\n  practical aspects", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we are revisiting pattern mining and especially itemset\nmining, which allows one to analyze binary datasets in searching for\ninteresting and meaningful association rules and respective itemsets in an\nunsupervised way. While a summarization of a dataset based on a set of patterns\ndoes not provide a general and satisfying view over a dataset, we introduce a\nconcise representation -- the closure structure -- based on closed itemsets and\ntheir minimum generators, for capturing the intrinsic content of a dataset. The\nclosure structure allows one to understand the topology of the dataset in the\nwhole and the inherent complexity of the data. We propose a formalization of\nthe closure structure in terms of Formal Concept Analysis, which is well\nadapted to study this data topology. We present and demonstrate theoretical\nresults, and as well, practical results using the GDPM algorithm. GDPM is\nrather unique in its functionality as it returns a characterization of the\ntopology of a dataset in terms of complexity levels, highlighting the diversity\nand the distribution of the itemsets. Finally, a series of experiments shows\nhow GDPM can be practically used and what can be expected from the output.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 11:21:56 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 08:32:55 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 08:30:16 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Makhalova", "Tatiana", ""], ["Buzmakov", "Aleksey", ""], ["Kuznetsov", "Sergei O.", ""], ["Napoli", "Amedeo", ""]]}, {"id": "2010.02629", "submitter": "Soma Dhavala", "authors": "Chintan Donda, Sayan Dasgupta, Soma S Dhavala, Keyur Faldu, Aditi\n  Avasthi", "title": "A framework for predicting, interpreting, and improving Learning\n  Outcomes", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has long been recognized that academic success is a result of both\ncognitive and non-cognitive dimensions acting together. Consequently, any\nintelligent learning platform designed to improve learning outcomes (LOs) must\nprovide actionable inputs to the learner in these dimensions. However,\noperationalizing such inputs in a production setting that is scalable is not\ntrivial. We develop an Embibe Score Quotient model (ESQ) to predict test scores\nbased on observed academic, behavioral and test-taking features of a student.\nESQ can be used to predict the future scoring potential of a student as well as\noffer personalized learning nudges, both critical to improving LOs. Multiple\nmachine learning models are evaluated for the prediction task. In order to\nprovide meaningful feedback to the learner, individualized Shapley feature\nattributions for each feature are computed. Prediction intervals are obtained\nby applying non-parametric quantile regression, in an attempt to quantify the\nuncertainty in the predictions. We apply the above modelling strategy on a\ndataset consisting of more than a hundred million learner interactions on the\nEmbibe learning platform. We observe that the Median Absolute Error between the\nobserved and predicted scores is 4.58% across several user segments, and the\ncorrelation between predicted and observed responses is 0.93. Game-like what-if\nscenarios are played out to see the changes in LOs, on counterfactual examples.\nWe briefly discuss how a rational agent can then apply an optimal policy to\naffect the learning outcomes by treating the above model like an Oracle.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 11:22:27 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 04:54:56 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Donda", "Chintan", ""], ["Dasgupta", "Sayan", ""], ["Dhavala", "Soma S", ""], ["Faldu", "Keyur", ""], ["Avasthi", "Aditi", ""]]}, {"id": "2010.02637", "submitter": "Xinwei Shen", "authors": "Xinwei Shen, Furui Liu, Hanze Dong, Qing Lian, Zhitang Chen, and Tong\n  Zhang", "title": "Disentangled Generative Causal Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a Disentangled gEnerative cAusal Representation (DEAR)\nlearning method. Unlike existing disentanglement methods that enforce\nindependence of the latent variables, we consider the general case where the\nunderlying factors of interests can be causally correlated. We show that\nprevious methods with independent priors fail to disentangle causally\ncorrelated factors. Motivated by this finding, we propose a new disentangled\nlearning method called DEAR that enables causal controllable generation and\ncausal representation learning. The key ingredient of this new formulation is\nto use a structural causal model (SCM) as the prior for a bidirectional\ngenerative model. The prior is then trained jointly with a generator and an\nencoder using a suitable GAN loss incorporated with supervision. We provide\ntheoretical justification on the identifiability and asymptotic consistency of\nthe proposed method, which guarantees disentangled causal representation\nlearning under appropriate conditions. We conduct extensive experiments on both\nsynthesized and real data sets to demonstrate the effectiveness of DEAR in\ncausal controllable generation, and the benefits of the learned representations\nfor downstream tasks in terms of sample efficiency and distributional\nrobustness.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 11:38:41 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 03:05:47 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Shen", "Xinwei", ""], ["Liu", "Furui", ""], ["Dong", "Hanze", ""], ["Lian", "Qing", ""], ["Chen", "Zhitang", ""], ["Zhang", "Tong", ""]]}, {"id": "2010.02647", "submitter": "Andr\\'e Artelt", "authors": "Andr\\'e Artelt and Barbara Hammer", "title": "Efficient computation of contrastive explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing deployment of machine learning systems in practice,\ntransparency and explainability have become serious issues. Contrastive\nexplanations are considered to be useful and intuitive, in particular when it\ncomes to explaining decisions to lay people, since they mimic the way in which\nhumans explain. Yet, so far, comparably little research has addressed\ncomputationally feasible technologies, which allow guarantees on uniqueness and\noptimality of the explanation and which enable an easy incorporation of\nadditional constraints. Here, we will focus on specific types of models rather\nthan black-box technologies. We study the relation of contrastive and\ncounterfactual explanations and propose mathematical formalizations as well as\na 2-phase algorithm for efficiently computing (plausible) pertinent positives\nof many standard machine learning models.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 11:50:28 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 10:09:40 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Artelt", "Andr\u00e9", ""], ["Hammer", "Barbara", ""]]}, {"id": "2010.02648", "submitter": "Yilin Yang", "authors": "Yilin Yang, Longyue Wang, Shuming Shi, Prasad Tadepalli, Stefan Lee\n  and Zhaopeng Tu", "title": "On the Sub-Layer Functionalities of Transformer Decoder", "comments": "Findings of the 2020 Conference on Empirical Methods in Natural\n  Language Processing (Long)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been significant efforts to interpret the encoder of\nTransformer-based encoder-decoder architectures for neural machine translation\n(NMT); meanwhile, the decoder remains largely unexamined despite its critical\nrole. During translation, the decoder must predict output tokens by considering\nboth the source-language text from the encoder and the target-language prefix\nproduced in previous steps. In this work, we study how Transformer-based\ndecoders leverage information from the source and target languages --\ndeveloping a universal probe task to assess how information is propagated\nthrough each module of each decoder layer. We perform extensive experiments on\nthree major translation datasets (WMT En-De, En-Fr, and En-Zh). Our analysis\nprovides insight on when and where decoders leverage different sources. Based\non these insights, we demonstrate that the residual feed-forward module in each\nTransformer decoder layer can be dropped with minimal loss of performance -- a\nsignificant reduction in computation and number of parameters, and consequently\na significant boost to both training and inference speed.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 11:50:54 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Yang", "Yilin", ""], ["Wang", "Longyue", ""], ["Shi", "Shuming", ""], ["Tadepalli", "Prasad", ""], ["Lee", "Stefan", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "2010.02663", "submitter": "Amanda Vu", "authors": "Ceyer Wakilpoor, Patrick J. Martin, Carrie Rebhuhn, Amanda Vu", "title": "Heterogeneous Multi-Agent Reinforcement Learning for Unknown Environment\n  Mapping", "comments": "Presented at AAAI FSS-20: Artificial Intelligence in Government and\n  Public Sector, Washington, DC, USA. 8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning in heterogeneous multi-agent scenarios is important\nfor real-world applications but presents challenges beyond those seen in\nhomogeneous settings and simple benchmarks. In this work, we present an\nactor-critic algorithm that allows a team of heterogeneous agents to learn\ndecentralized control policies for covering an unknown environment. This task\nis of interest to national security and emergency response organizations that\nwould like to enhance situational awareness in hazardous areas by deploying\nteams of unmanned aerial vehicles. To solve this multi-agent coverage path\nplanning problem in unknown environments, we augment a multi-agent actor-critic\narchitecture with a new state encoding structure and triplet learning loss to\nsupport heterogeneous agent learning. We developed a simulation environment\nthat includes real-world environmental factors such as turbulence, delayed\ncommunication, and agent loss, to train teams of agents as well as probe their\nrobustness and flexibility to such disturbances.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 12:23:05 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Wakilpoor", "Ceyer", ""], ["Martin", "Patrick J.", ""], ["Rebhuhn", "Carrie", ""], ["Vu", "Amanda", ""]]}, {"id": "2010.02675", "submitter": "Marcel Wien\\\"obst", "authors": "Marcel Wien\\\"obst and Maciej Li\\'skiewicz", "title": "Recovering Causal Structures from Low-Order Conditional Independencies", "comments": null, "journal-ref": "Published in Proceedings of the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI'20) New York, New York USA, pp. 10302-10309,\n  AAAI Press, 2020", "doi": "10.1609/aaai.v34i06.6593", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the common obstacles for learning causal models from data is that\nhigh-order conditional independence (CI) relationships between random variables\nare difficult to estimate. Since CI tests with conditioning sets of low order\ncan be performed accurately even for a small number of observations, a\nreasonable approach to determine casual structures is to base merely on the\nlow-order CIs. Recent research has confirmed that, e.g. in the case of sparse\ntrue causal models, structures learned even from zero- and first-order\nconditional independencies yield good approximations of the models. However, a\nchallenging task here is to provide methods that faithfully explain a given set\nof low-order CIs. In this paper, we propose an algorithm which, for a given set\nof conditional independencies of order less or equal to $k$, where $k$ is a\nsmall fixed number, computes a faithful graphical representation of the given\nset. Our results complete and generalize the previous work on learning from\npairwise marginal independencies. Moreover, they enable to improve upon the 0-1\ngraph model which, e.g. is heavily used in the estimation of genome networks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 12:47:20 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Wien\u00f6bst", "Marcel", ""], ["Li\u015bkiewicz", "Maciej", ""]]}, {"id": "2010.02684", "submitter": "Alvin Chan", "authors": "Alvin Chan, Yi Tay, Yew-Soon Ong, Aston Zhang", "title": "Poison Attacks against Text Datasets with Conditional Adversarially\n  Regularized Autoencoder", "comments": "Accepted in EMNLP-Findings 2020, Camera Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates a fatal vulnerability in natural language inference\n(NLI) and text classification systems. More concretely, we present a 'backdoor\npoisoning' attack on NLP models. Our poisoning attack utilizes conditional\nadversarially regularized autoencoder (CARA) to generate poisoned training\nsamples by poison injection in latent space. Just by adding 1% poisoned data,\nour experiments show that a victim BERT finetuned classifier's predictions can\nbe steered to the poison target class with success rates of >80% when the input\nhypothesis is injected with the poison signature, demonstrating that NLI and\ntext classification systems face a huge security risk.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 13:03:49 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Chan", "Alvin", ""], ["Tay", "Yi", ""], ["Ong", "Yew-Soon", ""], ["Zhang", "Aston", ""]]}, {"id": "2010.02693", "submitter": "Liang Ding", "authors": "Di Wu, Liang Ding, Fan Lu and Jian Xie", "title": "SlotRefine: A Fast Non-Autoregressive Model for Joint Intent Detection\n  and Slot Filling", "comments": "To appear in the the main conference of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slot filling and intent detection are two main tasks in spoken language\nunderstanding (SLU) system. In this paper, we propose a novel\nnon-autoregressive model named SlotRefine for joint intent detection and slot\nfilling. Besides, we design a novel two-pass iteration mechanism to handle the\nuncoordinated slots problem caused by conditional independence of\nnon-autoregressive model. Experiments demonstrate that our model significantly\noutperforms previous models in slot filling task, while considerably speeding\nup the decoding (up to X 10.77). In-depth analyses show that 1) pretraining\nschemes could further enhance our model; 2) two-pass mechanism indeed remedy\nthe uncoordinated slots.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 13:16:53 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 12:29:45 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Wu", "Di", ""], ["Ding", "Liang", ""], ["Lu", "Fan", ""], ["Xie", "Jian", ""]]}, {"id": "2010.02705", "submitter": "Minki Kang", "authors": "Minki Kang, Moonsu Han, Sung Ju Hwang", "title": "Neural Mask Generator: Learning to Generate Adaptive Word Maskings for\n  Language Model Adaptation", "comments": "19 pages, 9 figures, EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to automatically generate a domain- and task-adaptive\nmaskings of the given text for self-supervised pre-training, such that we can\neffectively adapt the language model to a particular target task (e.g. question\nanswering). Specifically, we present a novel reinforcement learning-based\nframework which learns the masking policy, such that using the generated masks\nfor further pre-training of the target language model helps improve task\nperformance on unseen texts. We use off-policy actor-critic with entropy\nregularization and experience replay for reinforcement learning, and propose a\nTransformer-based policy network that can consider the relative importance of\nwords in a given text. We validate our Neural Mask Generator (NMG) on several\nquestion answering and text classification datasets using BERT and DistilBERT\nas the language models, on which it outperforms rule-based masking strategies,\nby automatically learning optimal adaptive maskings.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 13:27:01 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Kang", "Minki", ""], ["Han", "Moonsu", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "2010.02726", "submitter": "Lance Eliot", "authors": "Lance Eliot", "title": "Legal Sentiment Analysis and Opinion Mining (LSAOM): Assimilating\n  Advances in Autonomous AI Legal Reasoning", "comments": "26 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:2009.14620", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An expanding field of substantive interest for the theory of the law and the\npractice-of-law entails Legal Sentiment Analysis and Opinion Mining (LSAOM),\nconsisting of two often intertwined phenomena and actions underlying legal\ndiscussions and narratives: (1) Sentiment Analysis (SA) for the detection of\nexpressed or implied sentiment about a legal matter within the context of a\nlegal milieu, and (2) Opinion Mining (OM) for the identification and\nillumination of explicit or implicit opinion accompaniments immersed within\nlegal discourse. Efforts to undertake LSAOM have historically been performed by\nhuman hand and cognition, and only thinly aided in more recent times by the use\nof computer-based approaches. Advances in Artificial Intelligence (AI)\ninvolving especially Natural Language Processing (NLP) and Machine Learning\n(ML) are increasingly bolstering how automation can systematically perform\neither or both of Sentiment Analysis and Opinion Mining, all of which is being\ninexorably carried over into engagement within a legal context for improving\nLSAOM capabilities. This research paper examines the evolving infusion of AI\ninto Legal Sentiment Analysis and Opinion Mining and proposes an alignment with\nthe Levels of Autonomy (LoA) of AI Legal Reasoning (AILR), plus provides\nadditional insights regarding AI LSAOM in its mechanizations and potential\nimpact to the study of law and the practicing of law.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 04:15:21 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Eliot", "Lance", ""]]}, {"id": "2010.02756", "submitter": "Yuji Kanagawa", "authors": "Yuji Kanagawa and Tomoyuki Kaneko", "title": "Diverse Exploration via InfoMax Options", "comments": "Preprint. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of autonomously discovering temporally\nabstracted actions, or options, for exploration in reinforcement learning. For\nlearning diverse options suitable for exploration, we introduce the infomax\ntermination objective defined as the mutual information between options and\ntheir corresponding state transitions. We derive a scalable optimization scheme\nfor maximizing this objective via the termination condition of options,\nyielding the InfoMax Option Critic (IMOC) algorithm. Through illustrative\nexperiments, we empirically show that IMOC learns diverse options and utilizes\nthem for exploration. Moreover, we show that IMOC scales well to continuous\ncontrol tasks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 14:21:05 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Kanagawa", "Yuji", ""], ["Kaneko", "Tomoyuki", ""]]}, {"id": "2010.02780", "submitter": "Dehua Chen", "authors": "Amir Jalilifard, Dehua Chen, Lucas Pereira Lopes, Isaac Ben-Akiva,\n  Pedro Henrique Gon\\c{c}alves Inazawa", "title": "Friendship is All we Need: A Multi-graph Embedding Approach for Modeling\n  Customer Behavior", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding customer behavior is fundamental for many use-cases in\nindustry, especially in accelerated growth areas such as fin-tech and\ne-commerce. Structured data are often expensive, time-consuming and inadequate\nto analyze and study complex customer behaviors. In this paper, we propose a\nmulti-graph embedding approach for creating a non-linear representation of\ncustomers in order to have a better knowledge of their characteristics without\nhaving any prior information about their financial status or their interests.\nBy applying the current method we are able to predict users' future behavior\nwith a reasonably high accuracy only by having the information of their\nfriendship network. Potential applications include recommendation systems and\ncredit risk forecasting.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 14:50:05 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Jalilifard", "Amir", ""], ["Chen", "Dehua", ""], ["Lopes", "Lucas Pereira", ""], ["Ben-Akiva", "Isaac", ""], ["Inazawa", "Pedro Henrique Gon\u00e7alves", ""]]}, {"id": "2010.02803", "submitter": "Carsten Eickhoff", "authors": "George Zerveas, Srideepika Jayaraman, Dhaval Patel, Anuradha\n  Bhamidipaty, Carsten Eickhoff", "title": "A Transformer-based Framework for Multivariate Time Series\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose for the first time a transformer-based framework for\nunsupervised representation learning of multivariate time series. Pre-trained\nmodels can be potentially used for downstream tasks such as regression and\nclassification, forecasting and missing value imputation. By evaluating our\nmodels on several benchmark datasets for multivariate time series regression\nand classification, we show that not only does our modeling approach represent\nthe most successful method employing unsupervised learning of multivariate time\nseries presented to date, but also that it exceeds the current state-of-the-art\nperformance of supervised methods; it does so even when the number of training\nsamples is very limited, while offering computational efficiency. Finally, we\ndemonstrate that unsupervised pre-training of our transformer models offers a\nsubstantial performance benefit over fully supervised learning, even without\nleveraging additional unlabeled data, i.e., by reusing the same data samples\nthrough the unsupervised objective.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 15:14:46 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 16:00:34 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 21:57:10 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Zerveas", "George", ""], ["Jayaraman", "Srideepika", ""], ["Patel", "Dhaval", ""], ["Bhamidipaty", "Anuradha", ""], ["Eickhoff", "Carsten", ""]]}, {"id": "2010.02804", "submitter": "Manuel Mager", "authors": "Manuel Mager, \\\"Ozlem \\c{C}etino\\u{g}lu and Katharina Kann", "title": "Tackling the Low-resource Challenge for Canonical Segmentation", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Canonical morphological segmentation consists of dividing words into their\nstandardized morphemes. Here, we are interested in approaches for the task when\ntraining data is limited. We compare model performance in a simulated\nlow-resource setting for the high-resource languages German, English, and\nIndonesian to experiments on new datasets for the truly low-resource languages\nPopoluca and Tepehua. We explore two new models for the task, borrowing from\nthe closely related area of morphological generation: an LSTM pointer-generator\nand a sequence-to-sequence model with hard monotonic attention trained with\nimitation learning. We find that, in the low-resource setting, the novel\napproaches outperform existing ones on all languages by up to 11.4% accuracy.\nHowever, while accuracy in emulated low-resource scenarios is over 50% for all\nlanguages, for the truly low-resource languages Popoluca and Tepehua, our best\nmodel only obtains 37.4% and 28.4% accuracy, respectively. Thus, we conclude\nthat canonical segmentation is still a challenging task for low-resource\nlanguages.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 15:15:05 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Mager", "Manuel", ""], ["\u00c7etino\u011flu", "\u00d6zlem", ""], ["Kann", "Katharina", ""]]}, {"id": "2010.02809", "submitter": "Yuqi Si", "authors": "Yuqi Si, Jingcheng Du, Zhao Li, Xiaoqian Jiang, Timothy Miller, Fei\n  Wang, W. Jim Zheng, Kirk Roberts", "title": "Deep Representation Learning of Patient Data from Electronic Health\n  Records (EHR): A Systematic Review", "comments": null, "journal-ref": null, "doi": "10.1016/j.jbi.2020.103671", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patient representation learning refers to learning a dense mathematical\nrepresentation of a patient that encodes meaningful information from Electronic\nHealth Records (EHRs). This is generally performed using advanced deep learning\nmethods. This study presents a systematic review of this field and provides\nboth qualitative and quantitative analyses from a methodological perspective.\nWe identified studies developing patient representations from EHRs with deep\nlearning methods from MEDLINE, EMBASE, Scopus, the Association for Computing\nMachinery (ACM) Digital Library, and Institute of Electrical and Electronics\nEngineers (IEEE) Xplore Digital Library. After screening 363 articles, 49\npapers were included for a comprehensive data collection. We noticed a typical\nworkflow starting with feeding raw data, applying deep learning models, and\nending with clinical outcome predictions as evaluations of the learned\nrepresentations. Specifically, learning representations from structured EHR\ndata was dominant (37 out of 49 studies). Recurrent Neural Networks were widely\napplied as the deep learning architecture (LSTM: 13 studies, GRU: 11 studies).\nDisease prediction was the most common application and evaluation (31 studies).\nBenchmark datasets were mostly unavailable (28 studies) due to privacy concerns\nof EHR data, and code availability was assured in 20 studies. We show the\nimportance and feasibility of learning comprehensive representations of patient\nEHR data through a systematic review. Advances in patient representation\nlearning techniques will be essential for powering patient-level EHR analyses.\nFuture work will still be devoted to leveraging the richness and potential of\navailable EHR data. Knowledge distillation and advanced learning techniques\nwill be exploited to assist the capability of learning patient representation\nfurther.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 15:18:02 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 16:24:43 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Si", "Yuqi", ""], ["Du", "Jingcheng", ""], ["Li", "Zhao", ""], ["Jiang", "Xiaoqian", ""], ["Miller", "Timothy", ""], ["Wang", "Fei", ""], ["Zheng", "W. Jim", ""], ["Roberts", "Kirk", ""]]}, {"id": "2010.02819", "submitter": "Maayan Shvo", "authors": "Maayan Shvo, Andrew C. Li, Rodrigo Toro Icarte, Sheila A. McIlraith", "title": "Interpretable Sequence Classification via Discrete Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence classification is the task of predicting a class label given a\nsequence of observations. In many applications such as healthcare monitoring or\nintrusion detection, early classification is crucial to prompt intervention. In\nthis work, we learn sequence classifiers that favour early classification from\nan evolving observation trace. While many state-of-the-art sequence classifiers\nare neural networks, and in particular LSTMs, our classifiers take the form of\nfinite state automata and are learned via discrete optimization. Our\nautomata-based classifiers are interpretable---supporting explanation,\ncounterfactual reasoning, and human-in-the-loop modification---and have strong\nempirical performance. Experiments over a suite of goal recognition and\nbehaviour classification datasets show our learned automata-based classifiers\nto have comparable test performance to LSTM-based classifiers, with the added\nadvantage of being interpretable.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 15:31:07 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Shvo", "Maayan", ""], ["Li", "Andrew C.", ""], ["Icarte", "Rodrigo Toro", ""], ["McIlraith", "Sheila A.", ""]]}, {"id": "2010.02820", "submitter": "Chrisantha Fernando Dr", "authors": "Chrisantha Fernando, Daria Zenkova, Stanislav Nikolov, Simon Osindero", "title": "From Language Games to Drawing Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We attempt to automate various artistic processes by inventing a set of\ndrawing games, analogous to the approach taken by emergent language research in\ninventing communication games. A critical difference is that drawing games\ndemand much less effort from the receiver than do language games. Artists must\nwork with pre-trained viewers who spend little time learning artist specific\nrepresentational conventions, but who instead have a pre-trained visual system\noptimized for behaviour in the world by understanding to varying extents the\nenvironment's visual affordances. After considering various kinds of drawing\ngame we present some preliminary experiments which have generated images by\nclosing the generative-critical loop.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 15:32:32 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 11:09:47 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Fernando", "Chrisantha", ""], ["Zenkova", "Daria", ""], ["Nikolov", "Stanislav", ""], ["Osindero", "Simon", ""]]}, {"id": "2010.02830", "submitter": "Swarnadeep Saha", "authors": "Swarnadeep Saha, Sayan Ghosh, Shashank Srivastava, Mohit Bansal", "title": "PRover: Proof Generation for Interpretable Reasoning over Rules", "comments": "EMNLP 2020 (15 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work by Clark et al. (2020) shows that transformers can act as 'soft\ntheorem provers' by answering questions over explicitly provided knowledge in\nnatural language. In our work, we take a step closer to emulating formal\ntheorem provers, by proposing PROVER, an interpretable transformer-based model\nthat jointly answers binary questions over rule-bases and generates the\ncorresponding proofs. Our model learns to predict nodes and edges corresponding\nto proof graphs in an efficient constrained training paradigm. During\ninference, a valid proof, satisfying a set of global constraints is generated.\nWe conduct experiments on synthetic, hand-authored, and human-paraphrased\nrule-bases to show promising results for QA and proof generation, with strong\ngeneralization performance. First, PROVER generates proofs with an accuracy of\n87%, while retaining or improving performance on the QA task, compared to\nRuleTakers (up to 6% improvement on zero-shot evaluation). Second, when trained\non questions requiring lower depths of reasoning, it generalizes significantly\nbetter to higher depths (up to 15% improvement). Third, PROVER obtains near\nperfect QA accuracy of 98% using only 40% of the training data. However,\ngenerating proofs for questions requiring higher depths of reasoning becomes\nchallenging, and the accuracy drops to 65% for 'depth 5', indicating\nsignificant scope for future work. Our code and models are publicly available\nat https://github.com/swarnaHub/PRover\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 15:47:53 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Saha", "Swarnadeep", ""], ["Ghosh", "Sayan", ""], ["Srivastava", "Shashank", ""], ["Bansal", "Mohit", ""]]}, {"id": "2010.02840", "submitter": "Ruiqi Zhong", "authors": "Ruiqi Zhong, Tao Yu, Dan Klein", "title": "Semantic Evaluation for Text-to-SQL with Distilled Test Suites", "comments": "EMNLP 2020 Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose test suite accuracy to approximate semantic accuracy for\nText-to-SQL models. Our method distills a small test suite of databases that\nachieves high code coverage for the gold query from a large number of randomly\ngenerated databases. At evaluation time, it computes the denotation accuracy of\nthe predicted queries on the distilled test suite, hence calculating a tight\nupper-bound for semantic accuracy efficiently. We use our proposed method to\nevaluate 21 models submitted to the Spider leader board and manually verify\nthat our method is always correct on 100 examples. In contrast, the current\nSpider metric leads to a 2.5% false negative rate on average and 8.1% in the\nworst case, indicating that test suite accuracy is needed. Our implementation,\nalong with distilled test suites for eleven Text-to-SQL datasets, is publicly\navailable.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 16:04:12 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Zhong", "Ruiqi", ""], ["Yu", "Tao", ""], ["Klein", "Dan", ""]]}, {"id": "2010.02846", "submitter": "Santiago Miret", "authors": "Santiago Miret, Somdeb Majumdar, Carroll Wainwright", "title": "Safety Aware Reinforcement Learning (SARL)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As reinforcement learning agents become increasingly integrated into complex,\nreal-world environments, designing for safety becomes a critical consideration.\nWe specifically focus on researching scenarios where agents can cause undesired\nside effects while executing a policy on a primary task. Since one can define\nmultiple tasks for a given environment dynamics, there are two important\nchallenges. First, we need to abstract the concept of safety that applies\nbroadly to that environment independent of the specific task being executed.\nSecond, we need a mechanism for the abstracted notion of safety to modulate the\nactions of agents executing different policies to minimize their side-effects.\nIn this work, we propose Safety Aware Reinforcement Learning (SARL) - a\nframework where a virtual safe agent modulates the actions of a main\nreward-based agent to minimize side effects. The safe agent learns a\ntask-independent notion of safety for a given environment. The main agent is\nthen trained with a regularization loss given by the distance between the\nnative action probabilities of the two agents. Since the safe agent effectively\nabstracts a task-independent notion of safety via its action probabilities, it\ncan be ported to modulate multiple policies solving different tasks within the\ngiven environment without further training. We contrast this with solutions\nthat rely on task-specific regularization metrics and test our framework on the\nSafeLife Suite, based on Conway's Game of Life, comprising a number of complex\ntasks in dynamic environments. We show that our solution is able to match the\nperformance of solutions that rely on task-specific side-effect penalties on\nboth the primary and safety objectives while additionally providing the benefit\nof generalizability and portability.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 16:08:28 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Miret", "Santiago", ""], ["Majumdar", "Somdeb", ""], ["Wainwright", "Carroll", ""]]}, {"id": "2010.02847", "submitter": "Haiyang Zhang", "authors": "Haiyang Zhang, Alison Sneyd and Mark Stevenson", "title": "Robustness and Reliability of Gender Bias Assessment in Word Embeddings:\n  The Role of Base Pairs", "comments": "Accepted at AACL-IJCNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that word embeddings can exhibit gender bias, and various\nmethods have been proposed to quantify this. However, the extent to which the\nmethods are capturing social stereotypes inherited from the data has been\ndebated. Bias is a complex concept and there exist multiple ways to define it.\nPrevious work has leveraged gender word pairs to measure bias and extract\nbiased analogies. We show that the reliance on these gendered pairs has strong\nlimitations: bias measures based off of them are not robust and cannot identify\ncommon types of real-world bias, whilst analogies utilising them are unsuitable\nindicators of bias. In particular, the well-known analogy \"man is to\ncomputer-programmer as woman is to homemaker\" is due to word similarity rather\nthan societal bias. This has important implications for work on measuring bias\nin embeddings and related work debiasing embeddings.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 16:09:05 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 21:24:16 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Zhang", "Haiyang", ""], ["Sneyd", "Alison", ""], ["Stevenson", "Mark", ""]]}, {"id": "2010.02855", "submitter": "Ramakrishna Vedantam", "authors": "Ramakrishna Vedantam, Arthur Szlam, Maximilian Nickel, Ari Morcos,\n  Brenden Lake", "title": "CURI: A Benchmark for Productive Concept Learning Under Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can learn and reason under substantial uncertainty in a space of\ninfinitely many concepts, including structured relational concepts (\"a scene\nwith objects that have the same color\") and ad-hoc categories defined through\ngoals (\"objects that could fall on one's head\"). In contrast, standard\nclassification benchmarks: 1) consider only a fixed set of category labels, 2)\ndo not evaluate compositional concept learning and 3) do not explicitly capture\na notion of reasoning under uncertainty. We introduce a new few-shot,\nmeta-learning benchmark, Compositional Reasoning Under Uncertainty (CURI) to\nbridge this gap. CURI evaluates different aspects of productive and systematic\ngeneralization, including abstract understandings of disentangling, productive\ngeneralization, learning boolean operations, variable binding, etc.\nImportantly, it also defines a model-independent \"compositionality gap\" to\nevaluate the difficulty of generalizing out-of-distribution along each of these\naxes. Extensive evaluations across a range of modeling choices spanning\ndifferent modalities (image, schemas, and sounds), splits, privileged auxiliary\nconcept information, and choices of negatives reveal substantial scope for\nmodeling advances on the proposed task. All code and datasets will be available\nonline.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 16:23:17 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Vedantam", "Ramakrishna", ""], ["Szlam", "Arthur", ""], ["Nickel", "Maximilian", ""], ["Morcos", "Ari", ""], ["Lake", "Brenden", ""]]}, {"id": "2010.02867", "submitter": "Jieyu Zhao", "authors": "Jieyu Zhao and Kai-Wei Chang", "title": "LOGAN: Local Group Bias Detection by Clustering", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques have been widely used in natural language\nprocessing (NLP). However, as revealed by many recent studies, machine learning\nmodels often inherit and amplify the societal biases in data. Various metrics\nhave been proposed to quantify biases in model predictions. In particular,\nseveral of them evaluate disparity in model performance between protected\ngroups and advantaged groups in the test corpus. However, we argue that\nevaluating bias at the corpus level is not enough for understanding how biases\nare embedded in a model. In fact, a model with similar aggregated performance\nbetween different groups on the entire data may behave differently on instances\nin a local region. To analyze and detect such local bias, we propose LOGAN, a\nnew bias detection technique based on clustering. Experiments on toxicity\nclassification and object classification tasks show that LOGAN identifies bias\nin a local region and allows us to better analyze the biases in model\npredictions.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 16:42:51 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Zhao", "Jieyu", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "2010.02911", "submitter": "James Miller Dr", "authors": "James D. Miller, Roman Yampolskiy, Olle Haggstrom, Stuart Armstrong", "title": "Chess as a Testing Grounds for the Oracle Approach to AI Safety", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reduce the danger of powerful super-intelligent AIs, we might make the\nfirst such AIs oracles that can only send and receive messages. This paper\nproposes a possibly practical means of using machine learning to create two\nclasses of narrow AI oracles that would provide chess advice: those aligned\nwith the player's interest, and those that want the player to lose and give\ndeceptively bad advice. The player would be uncertain which type of oracle it\nwas interacting with. As the oracles would be vastly more intelligent than the\nplayer in the domain of chess, experience with these oracles might help us\nprepare for future artificial general intelligence oracles.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 17:47:53 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Miller", "James D.", ""], ["Yampolskiy", "Roman", ""], ["Haggstrom", "Olle", ""], ["Armstrong", "Stuart", ""]]}, {"id": "2010.02923", "submitter": "Noam Brown", "authors": "Jonathan Gray, Adam Lerer, Anton Bakhtin, Noam Brown", "title": "Human-Level Performance in No-Press Diplomacy via Equilibrium Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior AI breakthroughs in complex games have focused on either the purely\nadversarial or purely cooperative settings. In contrast, Diplomacy is a game of\nshifting alliances that involves both cooperation and competition. For this\nreason, Diplomacy has proven to be a formidable research challenge. In this\npaper we describe an agent for the no-press variant of Diplomacy that combines\nsupervised learning on human data with one-step lookahead search via regret\nminimization. Regret minimization techniques have been behind previous AI\nsuccesses in adversarial games, most notably poker, but have not previously\nbeen shown to be successful in large-scale games involving cooperation. We show\nthat our agent greatly exceeds the performance of past no-press Diplomacy bots,\nis unexploitable by expert humans, and ranks in the top 2% of human players\nwhen playing anonymous games on a popular Diplomacy website.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 01:28:34 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 14:00:12 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Gray", "Jonathan", ""], ["Lerer", "Adam", ""], ["Bakhtin", "Anton", ""], ["Brown", "Noam", ""]]}, {"id": "2010.02974", "submitter": "Tarun Gupta", "authors": "Tarun Gupta, Anuj Mahajan, Bei Peng, Wendelin B\\\"ohmer, Shimon\n  Whiteson", "title": "UneVEn: Universal Value Exploration for Multi-Agent Reinforcement\n  Learning", "comments": "Published at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  VDN and QMIX are two popular value-based algorithms for cooperative MARL that\nlearn a centralized action value function as a monotonic mixing of per-agent\nutilities. While this enables easy decentralization of the learned policy, the\nrestricted joint action value function can prevent them from solving tasks that\nrequire significant coordination between agents at a given timestep. We show\nthat this problem can be overcome by improving the joint exploration of all\nagents during training. Specifically, we propose a novel MARL approach called\nUniversal Value Exploration (UneVEn) that learns a set of related tasks\nsimultaneously with a linear decomposition of universal successor features.\nWith the policies of already solved related tasks, the joint exploration\nprocess of all agents can be improved to help them achieve better coordination.\nEmpirical results on a set of exploration games, challenging cooperative\npredator-prey tasks requiring significant coordination among agents, and\nStarCraft II micromanagement benchmarks show that UneVEn can solve tasks where\nother state-of-the-art MARL methods fail.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 19:08:47 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 15:29:15 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 17:48:48 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Gupta", "Tarun", ""], ["Mahajan", "Anuj", ""], ["Peng", "Bei", ""], ["B\u00f6hmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2010.02983", "submitter": "Florian Mai", "authors": "Florian Mai (1 and 2), Nikolaos Pappas (3), Ivan Montero (3), Noah A.\n  Smith (3 and 4), James Henderson (1) ((1) Idiap Research Institute, (2) EPFL,\n  (3) University of Washington, (4) Allen Institute for Artificial\n  Intelligence)", "title": "Plug and Play Autoencoders for Conditional Text Generation", "comments": "To be published in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text autoencoders are commonly used for conditional generation tasks such as\nstyle transfer. We propose methods which are plug and play, where any\npretrained autoencoder can be used, and only require learning a mapping within\nthe autoencoder's embedding space, training embedding-to-embedding (Emb2Emb).\nThis reduces the need for labeled training data for the task and makes the\ntraining procedure more efficient. Crucial to the success of this method is a\nloss term for keeping the mapped embedding on the manifold of the autoencoder\nand a mapping which is trained to navigate the manifold by learning offset\nvectors. Evaluations on style transfer tasks both with and without\nsequence-to-sequence supervision show that our method performs better than or\ncomparable to strong baselines while being up to four times faster.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 19:18:06 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 08:20:59 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Mai", "Florian", "", "1 and 2"], ["Pappas", "Nikolaos", "", "3 and 4"], ["Montero", "Ivan", "", "3 and 4"], ["Smith", "Noah A.", "", "3 and 4"], ["Henderson", "James", ""]]}, {"id": "2010.02986", "submitter": "Charlie Welch", "authors": "Charles Welch, Jonathan K. Kummerfeld, Ver\\'onica P\\'erez-Rosas, Rada\n  Mihalcea", "title": "Compositional Demographic Word Embeddings", "comments": "To appear at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are usually derived from corpora containing text from many\nindividuals, thus leading to general purpose representations rather than\nindividually personalized representations. While personalized embeddings can be\nuseful to improve language model performance and other language processing\ntasks, they can only be computed for people with a large amount of longitudinal\ndata, which is not the case for new users. We propose a new form of\npersonalized word embeddings that use demographic-specific word representations\nderived compositionally from full or partial demographic information for a user\n(i.e., gender, age, location, religion). We show that the resulting\ndemographic-aware word representations outperform generic word representations\non two tasks for English: language modeling and word associations. We further\nexplore the trade-off between the number of available attributes and their\nrelative effectiveness and discuss the ethical implications of using them.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 19:23:46 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 18:54:53 GMT"}], "update_date": "2020-11-22", "authors_parsed": [["Welch", "Charles", ""], ["Kummerfeld", "Jonathan K.", ""], ["P\u00e9rez-Rosas", "Ver\u00f3nica", ""], ["Mihalcea", "Rada", ""]]}, {"id": "2010.03007", "submitter": "Ahmed Salem", "authors": "Ahmed Salem, Yannick Sautter, Michael Backes, Mathias Humbert, Yang\n  Zhang", "title": "BAAAN: Backdoor Attacks Against Autoencoder and GAN-Based Machine\n  Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tremendous progress of autoencoders and generative adversarial networks\n(GANs) has led to their application to multiple critical tasks, such as fraud\ndetection and sanitized data generation. This increasing adoption has fostered\nthe study of security and privacy risks stemming from these models. However,\nprevious works have mainly focused on membership inference attacks. In this\nwork, we explore one of the most severe attacks against machine learning\nmodels, namely the backdoor attack, against both autoencoders and GANs. The\nbackdoor attack is a training time attack where the adversary implements a\nhidden backdoor in the target model that can only be activated by a secret\ntrigger. State-of-the-art backdoor attacks focus on classification-based tasks.\nWe extend the applicability of backdoor attacks to autoencoders and GAN-based\nmodels. More concretely, we propose the first backdoor attack against\nautoencoders and GANs where the adversary can control what the decoded or\ngenerated images are when the backdoor is activated. Our results show that the\nadversary can build a backdoored autoencoder that returns a target output for\nall backdoored inputs, while behaving perfectly normal on clean inputs.\nSimilarly, for the GANs, our experiments show that the adversary can generate\ndata from a different distribution when the backdoor is activated, while\nmaintaining the same utility when the backdoor is not.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 20:26:16 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 07:28:17 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Salem", "Ahmed", ""], ["Sautter", "Yannick", ""], ["Backes", "Michael", ""], ["Humbert", "Mathias", ""], ["Zhang", "Yang", ""]]}, {"id": "2010.03053", "submitter": "Michalis Titsias", "authors": "Michalis K. Titsias, Jakub Sygnowski, Yutian Chen", "title": "Sequential Changepoint Detection in Neural Networks with Checkpoints", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for online changepoint detection and simultaneous\nmodel learning which is applicable to highly parametrized models, such as deep\nneural networks. It is based on detecting changepoints across time by\nsequentially performing generalized likelihood ratio tests that require only\nevaluations of simple prediction score functions. This procedure makes use of\ncheckpoints, consisting of early versions of the actual model parameters, that\nallow to detect distributional changes by performing predictions on future\ndata. We define an algorithm that bounds the Type I error in the sequential\ntesting procedure. We demonstrate the efficiency of our method in challenging\ncontinual learning applications with unknown task changepoints, and show\nimproved performance compared to online Bayesian changepoint detection.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 21:49:54 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Titsias", "Michalis K.", ""], ["Sygnowski", "Jakub", ""], ["Chen", "Yutian", ""]]}, {"id": "2010.03058", "submitter": "Sara Hooker", "authors": "Sara Hooker, Nyalleng Moorosi, Gregory Clark, Samy Bengio, Emily\n  Denton", "title": "Characterising Bias in Compressed Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity and widespread use of pruning and quantization is driven by\nthe severe resource constraints of deploying deep neural networks to\nenvironments with strict latency, memory and energy requirements. These\ntechniques achieve high levels of compression with negligible impact on\ntop-line metrics (top-1 and top-5 accuracy). However, overall accuracy hides\ndisproportionately high errors on a small subset of examples; we call this\nsubset Compression Identified Exemplars (CIE). We further establish that for\nCIE examples, compression amplifies existing algorithmic bias. Pruning\ndisproportionately impacts performance on underrepresented features, which\noften coincides with considerations of fairness. Given that CIE is a relatively\nsmall subset but a great contributor of error in the model, we propose its use\nas a human-in-the-loop auditing tool to surface a tractable subset of the\ndataset for further inspection or annotation by a domain expert. We provide\nqualitative and quantitative support that CIE surfaces the most challenging\nexamples in the data distribution for human-in-the-loop auditing.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 22:02:46 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 14:03:13 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Hooker", "Sara", ""], ["Moorosi", "Nyalleng", ""], ["Clark", "Gregory", ""], ["Bengio", "Samy", ""], ["Denton", "Emily", ""]]}, {"id": "2010.03070", "submitter": "Liam Dugan", "authors": "Liam Dugan, Daphne Ippolito, Arun Kirubarajan and Chris Callison-Burch", "title": "RoFT: A Tool for Evaluating Human Detection of Machine-Generated Text", "comments": "To be published in Annual Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, large neural networks for natural language generation (NLG)\nhave made leaps and bounds in their ability to generate fluent text. However,\nthe tasks of evaluating quality differences between NLG systems and\nunderstanding how humans perceive the generated text remain both crucial and\ndifficult. In this system demonstration, we present Real or Fake Text (RoFT), a\nwebsite that tackles both of these challenges by inviting users to try their\nhand at detecting machine-generated text in a variety of domains. We introduce\na novel evaluation task based on detecting the boundary at which a text passage\nthat starts off human-written transitions to being machine-generated. We show\npreliminary results of using RoFT to evaluate detection of machine-generated\nnews articles.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 22:47:43 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Dugan", "Liam", ""], ["Ippolito", "Daphne", ""], ["Kirubarajan", "Arun", ""], ["Callison-Burch", "Chris", ""]]}, {"id": "2010.03084", "submitter": "Xiaoyu Yang", "authors": "Xiaoyu Yang, Feng Nie, Yufei Feng, Quan Liu, Zhigang Chen, Xiaodan Zhu", "title": "Program Enhanced Fact Verification with Verbalization and Graph\n  Attention Network", "comments": "16 pages (Accepted by EMNLP 2020 as a long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Performing fact verification based on structured data is important for many\nreal-life applications and is a challenging research problem, particularly when\nit involves both symbolic operations and informal inference based on language\nunderstanding. In this paper, we present a Program-enhanced Verbalization and\nGraph Attention Network (ProgVGAT) to integrate programs and execution into\ntextual inference models. Specifically, a verbalization with program execution\nmodel is proposed to accumulate evidences that are embedded in operations over\nthe tables. Built on that, we construct the graph attention verification\nnetworks, which are designed to fuse different sources of evidences from\nverbalized program execution, program structures, and the original statements\nand tables, to make the final verification decision. To support the above\nframework, we propose a program selection module optimized with a new training\nstrategy based on margin loss, to produce more accurate programs, which is\nshown to be effective in enhancing the final verification results. Experimental\nresults show that the proposed framework achieves the new state-of-the-art\nperformance, a 74.4% accuracy, on the benchmark dataset TABFACT.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 23:29:08 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 16:43:38 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 00:49:15 GMT"}, {"version": "v4", "created": "Wed, 4 Nov 2020 16:35:19 GMT"}, {"version": "v5", "created": "Thu, 26 Nov 2020 20:27:59 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Yang", "Xiaoyu", ""], ["Nie", "Feng", ""], ["Feng", "Yufei", ""], ["Liu", "Quan", ""], ["Chen", "Zhigang", ""], ["Zhu", "Xiaodan", ""]]}, {"id": "2010.03096", "submitter": "Sheng Bi", "authors": "Xiya Cheng and Sheng Bi and Guilin Qi and Yongzhen Wang", "title": "Knowledge-aware Method for Confusing Charge Prediction", "comments": "Accepted by NLPCC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic charge prediction task aims to determine the final charges based on\nfact descriptions of criminal cases, which is a vital application of legal\nassistant systems. Conventional works usually depend on fact descriptions to\npredict charges while ignoring the legal schematic knowledge, which makes it\ndifficult to distinguish confusing charges. In this paper, we propose a\nknowledge-attentive neural network model, which introduces legal schematic\nknowledge about charges and exploit the knowledge hierarchical representation\nas the discriminative features to differentiate confusing charges. Our model\ntakes the textual fact description as the input and learns fact representation\nthrough a graph convolutional network. A legal schematic knowledge transformer\nis utilized to generate crucial knowledge representations oriented to the legal\nschematic knowledge at both the schema and charge levels. We apply a knowledge\nmatching network for effectively incorporating charge information into the fact\nto learn knowledge-aware fact representation. Finally, we use the\nknowledge-aware fact representation for charge prediction. We create two\nreal-world datasets and experimental results show that our proposed model can\noutperform other state-of-the-art baselines on accuracy and F1 score,\nespecially on dealing with confusing charges.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 00:58:10 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Cheng", "Xiya", ""], ["Bi", "Sheng", ""], ["Qi", "Guilin", ""], ["Wang", "Yongzhen", ""]]}, {"id": "2010.03110", "submitter": "Sumedh Sontakke", "authors": "Sumedh A. Sontakke, Arash Mehrjou, Laurent Itti, Bernhard Sch\\\"olkopf", "title": "Causal Curiosity: RL Agents Discovering Self-supervised Experiments for\n  Causal Representation Learning", "comments": "International Conference on Machine Learning, PMLR 139, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Animals exhibit an innate ability to learn regularities of the world through\ninteraction. By performing experiments in their environment, they are able to\ndiscern the causal factors of variation and infer how they affect the world's\ndynamics. Inspired by this, we attempt to equip reinforcement learning agents\nwith the ability to perform experiments that facilitate a categorization of the\nrolled-out trajectories, and to subsequently infer the causal factors of the\nenvironment in a hierarchical manner. We introduce {\\em causal curiosity}, a\nnovel intrinsic reward, and show that it allows our agents to learn optimal\nsequences of actions and discover causal factors in the dynamics of the\nenvironment. The learned behavior allows the agents to infer a binary quantized\nrepresentation for the ground-truth causal factors in every environment.\nAdditionally, we find that these experimental behaviors are semantically\nmeaningful (e.g., our agents learn to lift blocks to categorize them by\nweight), and are learnt in a self-supervised manner with approximately 2.5\ntimes less data than conventional supervised planners. We show that these\nbehaviors can be re-purposed and fine-tuned (e.g., from lifting to pushing or\nother downstream tasks). Finally, we show that the knowledge of causal factor\nrepresentations aids zero-shot learning for more complex tasks. Visit\nhttps://sites.google.com/usc.edu/causal-curiosity/home for website.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 02:07:51 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 23:59:04 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 01:19:39 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Sontakke", "Sumedh A.", ""], ["Mehrjou", "Arash", ""], ["Itti", "Laurent", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2010.03127", "submitter": "Takuma Udagawa", "authors": "Takuma Udagawa, Takato Yamazaki, Akiko Aizawa", "title": "A Linguistic Analysis of Visually Grounded Dialogues Based on Spatial\n  Expressions", "comments": "16 pages, Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent models achieve promising results in visually grounded dialogues.\nHowever, existing datasets often contain undesirable biases and lack\nsophisticated linguistic analyses, which make it difficult to understand how\nwell current models recognize their precise linguistic structures. To address\nthis problem, we make two design choices: first, we focus on OneCommon Corpus\n\\citep{udagawa2019natural,udagawa2020annotated}, a simple yet challenging\ncommon grounding dataset which contains minimal bias by design. Second, we\nanalyze their linguistic structures based on \\textit{spatial expressions} and\nprovide comprehensive and reliable annotation for 600 dialogues. We show that\nour annotation captures important linguistic structures including\npredicate-argument structure, modification and ellipsis. In our experiments, we\nassess the model's understanding of these structures through reference\nresolution. We demonstrate that our annotation can reveal both the strengths\nand weaknesses of baseline models in essential levels of detail. Overall, we\npropose a novel framework and resource for investigating fine-grained language\nunderstanding in visually grounded dialogues.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 02:50:38 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Udagawa", "Takuma", ""], ["Yamazaki", "Takato", ""], ["Aizawa", "Akiko", ""]]}, {"id": "2010.03131", "submitter": "Ahmet M. Elbir", "authors": "Ahmet M. Elbir and Kumar Vijay Mishra", "title": "Cognitive Learning-Aided Multi-Antenna Communications", "comments": "7pages5figures1table. This work has been submitted to the IEEE for\n  publication. Copyright may be transferred without notice, after which this\n  version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive communications have emerged as a promising solution to enhance,\nadapt, and invent new tools and capabilities that transcend conventional\nwireless networks. Deep learning (DL) is critical in enabling essential\nfeatures of cognitive systems because of its fast prediction performance,\nadaptive behavior, and model-free structure. These features are especially\nsignificant for multi-antenna wireless communications systems, which generate\nand handle massive data. Multiple antennas may provide multiplexing, diversity,\nor antenna gains that, respectively, improve the capacity, bit error rate, or\nthe signal-to-interference-plus-noise ratio. In practice, multi-antenna\ncognitive communications encounter challenges in terms of data complexity and\ndiversity, hardware complexity, and wireless channel dynamics. The DL-based\nsolutions tackle these problems at the various stages of communications\nprocessing such as channel estimation, hybrid beamforming, user localization,\nand sparse array design. There are research opportunities to address\nsignificant design challenges arising from insufficient data coverage, learning\nmodel complexity, and data transmission overheads. This article provides\nsynopses of various DL-based methods to impart cognitive behavior to\nmulti-antenna wireless communications.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 03:08:31 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 08:29:04 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Elbir", "Ahmet M.", ""], ["Mishra", "Kumar Vijay", ""]]}, {"id": "2010.03138", "submitter": "Linzi Xing", "authors": "Linzi Xing, Brad Hackinen, Giuseppe Carenini, Francesco Trebbi", "title": "Improving Context Modeling in Neural Topic Segmentation", "comments": "Accepted at AACL-IJCNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic segmentation is critical in key NLP tasks and recent works favor highly\neffective neural supervised approaches. However, current neural solutions are\narguably limited in how they model context. In this paper, we enhance a\nsegmenter based on a hierarchical attention BiLSTM network to better model\ncontext, by adding a coherence-related auxiliary task and restricted\nself-attention. Our optimized segmenter outperforms SOTA approaches when\ntrained and tested on three datasets. We also the robustness of our proposed\nmodel in domain transfer setting by training a model on a large-scale dataset\nand testing it on four challenging real-world benchmarks. Furthermore, we apply\nour proposed strategy to two other languages (German and Chinese), and show its\neffectiveness in multilingual scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 03:40:49 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Xing", "Linzi", ""], ["Hackinen", "Brad", ""], ["Carenini", "Giuseppe", ""], ["Trebbi", "Francesco", ""]]}, {"id": "2010.03152", "submitter": "Tsung-Yen Yang", "authors": "Tsung-Yen Yang and Justinian Rosca and Karthik Narasimhan and Peter J.\n  Ramadge", "title": "Projection-Based Constrained Policy Optimization", "comments": "International Conference on Learning Representations (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning control policies that optimize a reward\nfunction while satisfying constraints due to considerations of safety,\nfairness, or other costs. We propose a new algorithm, Projection-Based\nConstrained Policy Optimization (PCPO). This is an iterative method for\noptimizing policies in a two-step process: the first step performs a local\nreward improvement update, while the second step reconciles any constraint\nviolation by projecting the policy back onto the constraint set. We\ntheoretically analyze PCPO and provide a lower bound on reward improvement, and\nan upper bound on constraint violation, for each policy update. We further\ncharacterize the convergence of PCPO based on two different metrics:\n$\\normltwo$ norm and Kullback-Leibler divergence. Our empirical results over\nseveral control tasks demonstrate that PCPO achieves superior performance,\naveraging more than 3.5 times less constraint violation and around 15\\% higher\nreward compared to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 04:22:45 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Yang", "Tsung-Yen", ""], ["Rosca", "Justinian", ""], ["Narasimhan", "Karthik", ""], ["Ramadge", "Peter J.", ""]]}, {"id": "2010.03157", "submitter": "Sheng Bi", "authors": "Sheng Bi and Xiya Cheng and Yuan-Fang Li and Yongzhen Wang and Guilin\n  Qi", "title": "Knowledge-enriched, Type-constrained and Grammar-guided Question\n  Generation over Knowledge Bases", "comments": "Accepted by COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question generation over knowledge bases (KBQG) aims at generating\nnatural-language questions about a subgraph, i.e. a set of (connected) triples.\nTwo main challenges still face the current crop of encoder-decoder-based\nmethods, especially on small subgraphs: (1) low diversity and poor fluency due\nto the limited information contained in the subgraphs, and (2) semantic drift\ndue to the decoder's oblivion of the semantics of the answer entity. We propose\nan innovative knowledge-enriched, type-constrained and grammar-guided KBQG\nmodel, named KTG, to addresses the above challenges. In our model, the encoder\nis equipped with auxiliary information from the KB, and the decoder is\nconstrained with word types during QG. Specifically, entity domain and\ndescription, as well as relation hierarchy information are considered to\nconstruct question contexts, while a conditional copy mechanism is incorporated\nto modulate question semantics according to current word types. Besides, a\nnovel reward function featuring grammatical similarity is designed to improve\nboth generative richness and syntactic correctness via reinforcement learning.\nExtensive experiments show that our proposed model outperforms existing methods\nby a significant margin on two widely-used benchmark datasets SimpleQuestion\nand PathQuestion.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 04:49:48 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 05:39:58 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 03:32:38 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Bi", "Sheng", ""], ["Cheng", "Xiya", ""], ["Li", "Yuan-Fang", ""], ["Wang", "Yongzhen", ""], ["Qi", "Guilin", ""]]}, {"id": "2010.03158", "submitter": "Xuelu Chen", "authors": "Xuelu Chen, Muhao Chen, Changjun Fan, Ankith Uppunda, Yizhou Sun,\n  Carlo Zaniolo", "title": "Multilingual Knowledge Graph Completion via Ensemble Knowledge Transfer", "comments": "Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting missing facts in a knowledge graph (KG) is a crucial task in\nknowledge base construction and reasoning, and it has been the subject of much\nresearch in recent works using KG embeddings. While existing KG embedding\napproaches mainly learn and predict facts within a single KG, a more plausible\nsolution would benefit from the knowledge in multiple language-specific KGs,\nconsidering that different KGs have their own strengths and limitations on data\nquality and coverage. This is quite challenging, since the transfer of\nknowledge among multiple independently maintained KGs is often hindered by the\ninsufficiency of alignment information and the inconsistency of described\nfacts. In this paper, we propose KEnS, a novel framework for embedding learning\nand ensemble knowledge transfer across a number of language-specific KGs. KEnS\nembeds all KGs in a shared embedding space, where the association of entities\nis captured based on self-learning. Then, KEnS performs ensemble inference to\ncombine prediction results from embeddings of multiple language-specific KGs,\nfor which multiple ensemble techniques are investigated. Experiments on five\nreal-world language-specific KGs show that KEnS consistently improves\nstate-of-the-art methods on KG completion, via effectively identifying and\nleveraging complementary knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 04:54:03 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 07:54:24 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Chen", "Xuelu", ""], ["Chen", "Muhao", ""], ["Fan", "Changjun", ""], ["Uppunda", "Ankith", ""], ["Sun", "Yizhou", ""], ["Zaniolo", "Carlo", ""]]}, {"id": "2010.03159", "submitter": "Nguyen Vo", "authors": "Nguyen Vo, Kyumin Lee", "title": "Where Are the Facts? Searching for Fact-checked Information to Alleviate\n  the Spread of Fake News", "comments": "Full paper, EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although many fact-checking systems have been developed in academia and\nindustry, fake news is still proliferating on social media. These systems\nmostly focus on fact-checking but usually neglect online users who are the main\ndrivers of the spread of misinformation. How can we use fact-checked\ninformation to improve users' consciousness of fake news to which they are\nexposed? How can we stop users from spreading fake news? To tackle these\nquestions, we propose a novel framework to search for fact-checking articles,\nwhich address the content of an original tweet (that may contain\nmisinformation) posted by online users. The search can directly warn fake news\nposters and online users (e.g. the posters' followers) about misinformation,\ndiscourage them from spreading fake news, and scale up verified content on\nsocial media. Our framework uses both text and images to search for\nfact-checking articles, and achieves promising results on real-world datasets.\nOur code and datasets are released at https://github.com/nguyenvo09/EMNLP2020.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 04:55:34 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Vo", "Nguyen", ""], ["Lee", "Kyumin", ""]]}, {"id": "2010.03161", "submitter": "Weichao Mao", "authors": "Weichao Mao, Kaiqing Zhang, Ruihao Zhu, David Simchi-Levi, Tamer\n  Ba\\c{s}ar", "title": "Model-Free Non-Stationary RL: Near-Optimal Regret and Applications in\n  Multi-Agent RL and Inventory Control", "comments": "A preliminary version of this work has appeared in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider model-free reinforcement learning (RL) in non-stationary Markov\ndecision processes. Both the reward functions and the state transition\nfunctions are allowed to vary arbitrarily over time as long as their cumulative\nvariations do not exceed certain variation budgets. We propose Restarted\nQ-Learning with Upper Confidence Bounds (RestartQ-UCB), the first model-free\nalgorithm for non-stationary RL, and show that it outperforms existing\nsolutions in terms of dynamic regret. Specifically, RestartQ-UCB with\nFreedman-type bonus terms achieves a dynamic regret bound of\n$\\widetilde{O}(S^{\\frac{1}{3}} A^{\\frac{1}{3}} \\Delta^{\\frac{1}{3}} H\nT^{\\frac{2}{3}})$, where $S$ and $A$ are the numbers of states and actions,\nrespectively, $\\Delta>0$ is the variation budget, $H$ is the number of time\nsteps per episode, and $T$ is the total number of time steps. We further\npresent a parameter-free algorithm named Double-Restart Q-UCB that does not\nrequire prior knowledge of the variation budget. We show that our algorithms\nare \\emph{nearly optimal} by establishing an information-theoretical lower\nbound of $\\Omega(S^{\\frac{1}{3}} A^{\\frac{1}{3}} \\Delta^{\\frac{1}{3}}\nH^{\\frac{2}{3}} T^{\\frac{2}{3}})$, the first lower bound in non-stationary RL.\nNumerical experiments validate the advantages of RestartQ-UCB in terms of both\ncumulative rewards and computational efficiency. We demonstrate the power of\nour results in examples of multi-agent RL and inventory control across related\nproducts.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 04:55:56 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 22:42:44 GMT"}, {"version": "v3", "created": "Mon, 26 Jul 2021 05:58:24 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Mao", "Weichao", ""], ["Zhang", "Kaiqing", ""], ["Zhu", "Ruihao", ""], ["Simchi-Levi", "David", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "2010.03182", "submitter": "Siqu Long", "authors": "Soyeon Caren Han, Siqu Long, Siwen Luo, Kunze Wang, Josiah Poon", "title": "VICTR: Visual Information Captured Text Representation for Text-to-Image\n  Multimodal Tasks", "comments": "Accepted by COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-to-image multimodal tasks, generating/retrieving an image from a given\ntext description, are extremely challenging tasks since raw text descriptions\ncover quite limited information in order to fully describe visually realistic\nimages. We propose a new visual contextual text representation for\ntext-to-image multimodal tasks, VICTR, which captures rich visual semantic\ninformation of objects from the text input. First, we use the text description\nas initial input and conduct dependency parsing to extract the syntactic\nstructure and analyse the semantic aspect, including object quantities, to\nextract the scene graph. Then, we train the extracted objects, attributes, and\nrelations in the scene graph and the corresponding geometric relation\ninformation using Graph Convolutional Networks, and it generates text\nrepresentation which integrates textual and visual semantic information. The\ntext representation is aggregated with word-level and sentence-level embedding\nto generate both visual contextual word and sentence representation. For the\nevaluation, we attached VICTR to the state-of-the-art models in text-to-image\ngeneration.VICTR is easily added to existing models and improves across both\nquantitative and qualitative aspects.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 05:25:30 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 12:20:43 GMT"}, {"version": "v3", "created": "Sun, 25 Oct 2020 05:21:52 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Han", "Soyeon Caren", ""], ["Long", "Siqu", ""], ["Luo", "Siwen", ""], ["Wang", "Kunze", ""], ["Poon", "Josiah", ""]]}, {"id": "2010.03205", "submitter": "Bodhisattwa Prasad Majumder", "authors": "Bodhisattwa Prasad Majumder, Harsh Jhamtani, Taylor Berg-Kirkpatrick,\n  Julian McAuley", "title": "Like hiking? You probably enjoy nature: Persona-grounded Dialog with\n  Commonsense Expansions", "comments": "Accepted in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing persona-grounded dialog models often fail to capture simple\nimplications of given persona descriptions, something which humans are able to\ndo seamlessly. For example, state-of-the-art models cannot infer that interest\nin hiking might imply love for nature or longing for a break. In this paper, we\npropose to expand available persona sentences using existing commonsense\nknowledge bases and paraphrasing resources to imbue dialog models with access\nto an expanded and richer set of persona descriptions. Additionally, we\nintroduce fine-grained grounding on personas by encouraging the model to make a\ndiscrete choice among persona sentences while synthesizing a dialog response.\nSince such a choice is not observed in the data, we model it using a discrete\nlatent random variable and use variational learning to sample from hundreds of\npersona expansions. Our model outperforms competitive baselines on the\nPersonaChat dataset in terms of dialog quality and diversity while achieving\npersona-consistent and controllable dialog generation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 06:25:39 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Majumder", "Bodhisattwa Prasad", ""], ["Jhamtani", "Harsh", ""], ["Berg-Kirkpatrick", "Taylor", ""], ["McAuley", "Julian", ""]]}, {"id": "2010.03222", "submitter": "Lukas Muttenthaler", "authors": "Lukas Muttenthaler, Isabelle Augenstein, Johannes Bjerva", "title": "Unsupervised Evaluation for Question Answering with Transformers", "comments": "8 pages, to be published in the Proceedings of the 2020 EMNLP\n  Workshop BlackboxNLP: Analysing and Interpreting Neural Networks for NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is challenging to automatically evaluate the answer of a QA model at\ninference time. Although many models provide confidence scores, and simple\nheuristics can go a long way towards indicating answer correctness, such\nmeasures are heavily dataset-dependent and are unlikely to generalize. In this\nwork, we begin by investigating the hidden representations of questions,\nanswers, and contexts in transformer-based QA architectures. We observe a\nconsistent pattern in the answer representations, which we show can be used to\nautomatically evaluate whether or not a predicted answer span is correct. Our\nmethod does not require any labeled data and outperforms strong heuristic\nbaselines, across 2 datasets and 7 domains. We are able to predict whether or\nnot a model's answer is correct with 91.37% accuracy on SQuAD, and 80.7%\naccuracy on SubjQA. We expect that this method will have broad applications,\ne.g., in the semi-automatic development of QA datasets\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 07:03:30 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Muttenthaler", "Lukas", ""], ["Augenstein", "Isabelle", ""], ["Bjerva", "Johannes", ""]]}, {"id": "2010.03228", "submitter": "Souradip Chakraborty Mr", "authors": "Souradip Chakraborty, Ekansh Verma, Saswata Sahoo, Jyotishka Datta", "title": "FairMixRep : Self-supervised Robust Representation Learning for\n  Heterogeneous Data with Fairness constraints", "comments": "This paper has been accepted at the ICDM'2020 DLC Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation Learning in a heterogeneous space with mixed variables of\nnumerical and categorical types has interesting challenges due to its complex\nfeature manifold. Moreover, feature learning in an unsupervised setup, without\nclass labels and a suitable learning loss function, adds to the problem\ncomplexity. Further, the learned representation and subsequent predictions\nshould not reflect discriminatory behavior towards certain sensitive groups or\nattributes. The proposed feature map should preserve maximum variations present\nin the data and needs to be fair with respect to the sensitive variables. We\npropose, in the first phase of our work, an efficient encoder-decoder framework\nto capture the mixed-domain information. The second phase of our work focuses\non de-biasing the mixed space representations by adding relevant fairness\nconstraints. This ensures minimal information loss between the representations\nbefore and after the fairness-preserving projections. Both the information\ncontent and the fairness aspect of the final representation learned has been\nvalidated through several metrics where it shows excellent performance. Our\nwork (FairMixRep) addresses the problem of Mixed Space Fair Representation\nlearning from an unsupervised perspective and learns a Universal representation\nthat is timely, unique, and a novel research contribution.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 07:23:02 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 06:12:38 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Chakraborty", "Souradip", ""], ["Verma", "Ekansh", ""], ["Sahoo", "Saswata", ""], ["Datta", "Jyotishka", ""]]}, {"id": "2010.03266", "submitter": "Xingbo Liu", "authors": "Xiao Kang, Xingbo Liu, Xiushan Nie, Yilong Yin", "title": "Learning Binary Semantic Embedding for Histology Image Classification\n  and Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of medical imaging technology and machine learning,\ncomputer-assisted diagnosis which can provide impressive reference to\npathologists, attracts extensive research interests. The exponential growth of\nmedical images and uninterpretability of traditional classification models have\nhindered the applications of computer-assisted diagnosis. To address these\nissues, we propose a novel method for Learning Binary Semantic Embedding\n(LBSE). Based on the efficient and effective embedding, classification and\nretrieval are performed to provide interpretable computer-assisted diagnosis\nfor histology images. Furthermore, double supervision, bit uncorrelation and\nbalance constraint, asymmetric strategy and discrete optimization are\nseamlessly integrated in the proposed method for learning binary embedding.\nExperiments conducted on three benchmark datasets validate the superiority of\nLBSE under various scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 08:36:44 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Kang", "Xiao", ""], ["Liu", "Xingbo", ""], ["Nie", "Xiushan", ""], ["Yin", "Yilong", ""]]}, {"id": "2010.03272", "submitter": "Harsh Jhamtani", "authors": "Harsh Jhamtani and Taylor Berg-Kirkpatrick", "title": "Narrative Text Generation with a Latent Discrete Plan", "comments": "Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Past work on story generation has demonstrated the usefulness of conditioning\non a generation plan to generate coherent stories. However, these approaches\nhave used heuristics or off-the-shelf models to first tag training stories with\nthe desired type of plan, and then train generation models in a supervised\nfashion. In this paper, we propose a deep latent variable model that first\nsamples a sequence of anchor words, one per sentence in the story, as part of\nits generative process. During training, our model treats the sequence of\nanchor words as a latent variable and attempts to induce anchoring sequences\nthat help guide generation in an unsupervised fashion. We conduct experiments\nwith several types of sentence decoder distributions: left-to-right and\nnon-monotonic, with different degrees of restriction. Further, since we use\namortized variational inference to train our model, we introduce two\ncorresponding types of inference network for predicting the posterior on anchor\nwords. We conduct human evaluations which demonstrate that the stories produced\nby our model are rated better in comparison with baselines which do not\nconsider story plans, and are similar or better in quality relative to\nbaselines which use external supervision for plans. Additionally, the proposed\nmodel gets favorable scores when evaluated on perplexity, diversity, and\ncontrol of story via discrete plan.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 08:45:37 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Jhamtani", "Harsh", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "2010.03274", "submitter": "Harsh Jhamtani", "authors": "Harsh Jhamtani and Peter Clark", "title": "Learning to Explain: Datasets and Models for Identifying Valid Reasoning\n  Chains in Multihop Question-Answering", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the rapid progress in multihop question-answering (QA), models still\nhave trouble explaining why an answer is correct, with limited explanation\ntraining data available to learn from. To address this, we introduce three\nexplanation datasets in which explanations formed from corpus facts are\nannotated. Our first dataset, eQASC, contains over 98K explanation annotations\nfor the multihop question answering dataset QASC, and is the first that\nannotates multiple candidate explanations for each answer. The second dataset\neQASC-perturbed is constructed by crowd-sourcing perturbations (while\npreserving their validity) of a subset of explanations in QASC, to test\nconsistency and generalization of explanation prediction models. The third\ndataset eOBQA is constructed by adding explanation annotations to the OBQA\ndataset to test generalization of models trained on eQASC. We show that this\ndata can be used to significantly improve explanation quality (+14% absolute F1\nover a strong retrieval baseline) using a BERT-based classifier, but still\nbehind the upper bound, offering a new challenge for future research. We also\nexplore a delexicalized chain representation in which repeated noun phrases are\nreplaced by variables, thus turning them into generalized reasoning chains (for\nexample: \"X is a Y\" AND \"Y has Z\" IMPLIES \"X has Z\"). We find that generalized\nchains maintain performance while also being more robust to certain\nperturbations.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 08:46:02 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Jhamtani", "Harsh", ""], ["Clark", "Peter", ""]]}, {"id": "2010.03331", "submitter": "Roberto Arroyo", "authors": "Roberto Arroyo, David Jim\\'enez-Cabello and Javier\n  Mart\\'inez-Cebri\\'an", "title": "Multi-label classification of promotions in digital leaflets using\n  textual and visual information", "comments": "Conference on Computational Linguistics (COLING). Workshop on Natural\n  Language Processing in E-Commerce (EcomNLP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Product descriptions in e-commerce platforms contain detailed and valuable\ninformation about retailers assortment. In particular, coding promotions within\ndigital leaflets are of great interest in e-commerce as they capture the\nattention of consumers by showing regular promotions for different products.\nHowever, this information is embedded into images, making it difficult to\nextract and process for downstream tasks. In this paper, we present an\nend-to-end approach that classifies promotions within digital leaflets into\ntheir corresponding product categories using both visual and textual\ninformation. Our approach can be divided into three key components: 1) region\ndetection, 2) text recognition and 3) text classification. In many cases, a\nsingle promotion refers to multiple product categories, so we introduce a\nmulti-label objective in the classification head. We demonstrate the\neffectiveness of our approach for two separated tasks: 1) image-based detection\nof the descriptions for each individual promotion and 2) multi-label\nclassification of the product categories using the text from the product\ndescriptions. We train and evaluate our models using a private dataset composed\nof images from digital leaflets obtained by Nielsen. Results show that we\nconsistently outperform the proposed baseline by a large margin in all the\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 11:05:12 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Arroyo", "Roberto", ""], ["Jim\u00e9nez-Cabello", "David", ""], ["Mart\u00ednez-Cebri\u00e1n", "Javier", ""]]}, {"id": "2010.03362", "submitter": "Alexandrine Royer", "authors": "Alexandrine Royer", "title": "The Short Anthropological Guide to the Study of Ethical AI", "comments": "46 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the next few years, society as a whole will need to address what core\nvalues it wishes to protect when dealing with technology. Anthropology, a field\ndedicated to the very notion of what it means to be human, can provide some\ninteresting insights into how to cope and tackle these changes in our Western\nsociety and other areas of the world. It can be challenging for social science\npractitioners to grasp and keep up with the pace of technological innovation,\nwith many being unfamiliar with the jargon of AI. This short guide serves as\nboth an introduction to AI ethics and social science and anthropological\nperspectives on the development of AI. It intends to provide those unfamiliar\nwith the field with an insight into the societal impact of AI systems and how,\nin turn, these systems can lead us to rethink how our world operates.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 12:25:03 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Royer", "Alexandrine", ""]]}, {"id": "2010.03365", "submitter": "Xinyi Hu", "authors": "Xinyi Hu, Quchen Miao, Zexuan Zhao", "title": "\"Drunk Man\" Saves Our Lives: Route Planning by a Biased Random Walk Mode", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the hurricane striking Puerto Rico in 2017, we developed a\ntransportable disaster response system \"DroneGo\" featuring a drone fleet\ncapable of delivering the medical package and videoing roads. Covering with a\ngenetic algorithm and a biased random walk model mimicking a drunk man to\nexplore feasible routes on a field with altitude and road information. A\nproposal mechanism guaranteeing stochasticity and an objective function biasing\nrandomness are combined. The results showed high performance though\ntime-consuming.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 16:03:40 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Hu", "Xinyi", ""], ["Miao", "Quchen", ""], ["Zhao", "Zexuan", ""]]}, {"id": "2010.03369", "submitter": "Marco Guerini", "authors": "Thomas Scialom, Serra Sinem Tekiroglu, Jacopo Staiano, Marco Guerini", "title": "Toward Stance-based Personas for Opinionated Dialogues", "comments": "Accepted at Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of chit-chat dialogues it has been shown that endowing systems\nwith a persona profile is important to produce more coherent and meaningful\nconversations. Still, the representation of such personas has thus far been\nlimited to a fact-based representation (e.g. \"I have two cats.\"). We argue that\nthese representations remain superficial w.r.t. the complexity of human\npersonality. In this work, we propose to make a step forward and investigate\nstance-based persona, trying to grasp more profound characteristics, such as\nopinions, values, and beliefs to drive language generation. To this end, we\nintroduce a novel dataset allowing to explore different stance-based persona\nrepresentations and their impact on claim generation, showing that they are\nable to grasp abstract and profound aspects of the author persona.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 12:30:30 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Scialom", "Thomas", ""], ["Tekiroglu", "Serra Sinem", ""], ["Staiano", "Jacopo", ""], ["Guerini", "Marco", ""]]}, {"id": "2010.03373", "submitter": "Linyu Lin", "authors": "Linyu Lin, Nam Dinh", "title": "Predictive Capability Maturity Quantification using Bayesian Network", "comments": "The paper has been accepted by the Journal of Verification,\n  Validation, and Uncertainty Quantification", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In nuclear engineering, modeling and simulations (M&Ss) are widely applied to\nsupport risk-informed safety analysis. Since nuclear safety analysis has\nimportant implications, a convincing validation process is needed to assess\nsimulation adequacy, i.e., the degree to which M&S tools can adequately\nrepresent the system quantities of interest. However, due to data gaps,\nvalidation becomes a decision-making process under uncertainties. Expert\nknowledge and judgments are required to collect, choose, characterize, and\nintegrate evidence toward the final adequacy decision. However, in validation\nframeworks CSAU: Code Scaling, Applicability, and Uncertainty (NUREG/CR-5249)\nand EMDAP: Evaluation Model Development and Assessment Process (RG 1.203), such\na decision-making process is largely implicit and obscure. When scenarios are\ncomplex, knowledge biases and unreliable judgments can be overlooked, which\ncould increase uncertainty in the simulation adequacy result and the\ncorresponding risks. Therefore, a framework is required to formalize the\ndecision-making process for simulation adequacy in a practical, transparent,\nand consistent manner. This paper suggests a framework \"Predictive Capability\nMaturity Quantification using Bayesian network (PCMQBN)\" as a quantified\nframework for assessing simulation adequacy based on information collected from\nvalidation activities. A case study is prepared for evaluating the adequacy of\na Smoothed Particle Hydrodynamic simulation in predicting the hydrodynamic\nforces onto static structures during an external flooding scenario. Comparing\nto the qualitative and implicit adequacy assessment, PCMQBN is able to improve\nconfidence in the simulation adequacy result and to reduce expected loss in the\nrisk-informed safety analysis.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 17:09:09 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Lin", "Linyu", ""], ["Dinh", "Nam", ""]]}, {"id": "2010.03429", "submitter": "Wim Casteels", "authors": "Wim Casteels and Peter Hellinckx", "title": "Exploiting non-i.i.d. data towards more robust machine learning\n  algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of machine learning there is a growing interest towards more\nrobust and generalizable algorithms. This is for example important to bridge\nthe gap between the environment in which the training data was collected and\nthe environment where the algorithm is deployed. Machine learning algorithms\nhave increasingly been shown to excel in finding patterns and correlations from\ndata. Determining the consistency of these patterns and for example the\ndistinction between causal correlations and nonsensical spurious relations has\nproven to be much more difficult. In this paper a regularization scheme is\nintroduced that prefers universal causal correlations. This approach is based\non 1) the robustness of causal correlations and 2) the data not being\nindependently and identically distribute (i.i.d.). The scheme is demonstrated\nwith a classification task by clustering the (non-i.i.d.) training set in\nsubpopulations. A non-i.i.d. regularization term is then introduced that\npenalizes weights that are not invariant over these clusters. The resulting\nalgorithm favours correlations that are universal over the subpopulations and\nindeed a better performance is obtained on an out-of-distribution test set with\nrespect to a more conventional l_2-regularization.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 14:15:37 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Casteels", "Wim", ""], ["Hellinckx", "Peter", ""]]}, {"id": "2010.03446", "submitter": "Ewan Dunbar", "authors": "Louis Fournier, Emmanuel Dupoux, Ewan Dunbar", "title": "Analogies minus analogy test: measuring regularities in word embeddings", "comments": null, "journal-ref": "Proceedings of CoNLL 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector space models of words have long been claimed to capture linguistic\nregularities as simple vector translations, but problems have been raised with\nthis claim. We decompose and empirically analyze the classic arithmetic word\nanalogy test, to motivate two new metrics that address the issues with the\nstandard test, and which distinguish between class-wise offset concentration\n(similar directions between pairs of words drawn from different broad classes,\nsuch as France--London, China--Ottawa, ...) and pairing consistency (the\nexistence of a regular transformation between correctly-matched pairs such as\nFrance:Paris::China:Beijing). We show that, while the standard analogy test is\nflawed, several popular word embeddings do nevertheless encode linguistic\nregularities.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 14:38:35 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Fournier", "Louis", ""], ["Dupoux", "Emmanuel", ""], ["Dunbar", "Ewan", ""]]}, {"id": "2010.03496", "submitter": "Daniel Daza", "authors": "Daniel Daza, Michael Cochez, Paul Groth", "title": "Inductive Entity Representations from Text via Link Prediction", "comments": null, "journal-ref": null, "doi": "10.1145/3442381.3450141", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graphs (KG) are of vital importance for multiple applications on\nthe web, including information retrieval, recommender systems, and metadata\nannotation. Regardless of whether they are built manually by domain experts or\nwith automatic pipelines, KGs are often incomplete. Recent work has begun to\nexplore the use of textual descriptions available in knowledge graphs to learn\nvector representations of entities in order to preform link prediction.\nHowever, the extent to which these representations learned for link prediction\ngeneralize to other tasks is unclear. This is important given the cost of\nlearning such representations. Ideally, we would prefer representations that do\nnot need to be trained again when transferring to a different task, while\nretaining reasonable performance.\n  In this work, we propose a holistic evaluation protocol for entity\nrepresentations learned via a link prediction objective. We consider the\ninductive link prediction and entity classification tasks, which involve\nentities not seen during training. We also consider an information retrieval\ntask for entity-oriented search. We evaluate an architecture based on a\npretrained language model, that exhibits strong generalization to entities not\nobserved during training, and outperforms related state-of-the-art methods (22%\nMRR improvement in link prediction on average). We further provide evidence\nthat the learned representations transfer well to other tasks without\nfine-tuning. In the entity classification task we obtain an average improvement\nof 16% in accuracy compared with baselines that also employ pre-trained models.\nIn the information retrieval task, we obtain significant improvements of up to\n8.8% in NDCG@10 for natural language queries. We thus show that the learned\nrepresentations are not limited KG-specific tasks, and have greater\ngeneralization properties than evaluated in previous work.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 16:04:06 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 10:36:23 GMT"}, {"version": "v3", "created": "Wed, 14 Apr 2021 09:38:45 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Daza", "Daniel", ""], ["Cochez", "Michael", ""], ["Groth", "Paul", ""]]}, {"id": "2010.03514", "submitter": "Wang-Zhou Dai", "authors": "Wang-Zhou Dai, Stephen H. Muggleton", "title": "Abductive Knowledge Induction From Raw Data", "comments": "Accepted by IJCAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many reasoning-heavy tasks involving raw inputs, it is challenging to\ndesign an appropriate end-to-end learning pipeline. Neuro-Symbolic Learning,\ndivide the process into sub-symbolic perception and symbolic reasoning, trying\nto utilise data-driven machine learning and knowledge-driven reasoning\nsimultaneously. However, they suffer from the exponential computational\ncomplexity within the interface between these two components, where the\nsub-symbolic learning model lacks direct supervision, and the symbolic model\nlacks accurate input facts. Hence, most of them assume the existence of a\nstrong symbolic knowledge base and only learn the perception model while\navoiding a crucial problem: where does the knowledge come from? In this paper,\nwe present Abductive Meta-Interpretive Learning ($Meta_{Abd}$) that unites\nabduction and induction to learn neural networks and induce logic theories\njointly from raw data. Experimental results demonstrate that $Meta_{Abd}$ not\nonly outperforms the compared systems in predictive accuracy and data\nefficiency but also induces logic programs that can be re-used as background\nknowledge in subsequent learning tasks. To the best of our knowledge,\n$Meta_{Abd}$ is the first system that can jointly learn neural networks from\nscratch and induce recursive first-order logic theories with predicate\ninvention.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 16:33:28 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 12:45:50 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Dai", "Wang-Zhou", ""], ["Muggleton", "Stephen H.", ""]]}, {"id": "2010.03522", "submitter": "Mike Huisman", "authors": "Mike Huisman and Jan N. van Rijn and Aske Plaat", "title": "A Survey of Deep Meta-Learning", "comments": "Published in the AI Review (AIRE) Journal (2021)", "journal-ref": null, "doi": "10.1007/s10462-021-10004-4", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks can achieve great successes when presented with large\ndata sets and sufficient computational resources. However, their ability to\nlearn new concepts quickly is limited. Meta-learning is one approach to address\nthis issue, by enabling the network to learn how to learn. The field of Deep\nMeta-Learning advances at great speed, but lacks a unified, in-depth overview\nof current techniques. With this work, we aim to bridge this gap. After\nproviding the reader with a theoretical foundation, we investigate and\nsummarize key methods, which are categorized into i)~metric-, ii)~model-, and\niii)~optimization-based techniques. In addition, we identify the main open\nchallenges, such as performance evaluations on heterogeneous benchmarks, and\nreduction of the computational costs of meta-learning.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 17:09:02 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 13:33:40 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Huisman", "Mike", ""], ["van Rijn", "Jan N.", ""], ["Plaat", "Aske", ""]]}, {"id": "2010.03526", "submitter": "Jiapeng Wu", "authors": "Jiapeng Wu, Meng Cao, Jackie Chi Kit Cheung and William L. Hamilton", "title": "TeMP: Temporal Message Passing for Temporal Knowledge Graph Completion", "comments": "17 pages, 9 figures. EMNLP 2020 Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring missing facts in temporal knowledge graphs (TKGs) is a fundamental\nand challenging task. Previous works have approached this problem by augmenting\nmethods for static knowledge graphs to leverage time-dependent representations.\nHowever, these methods do not explicitly leverage multi-hop structural\ninformation and temporal facts from recent time steps to enhance their\npredictions. Additionally, prior work does not explicitly address the temporal\nsparsity and variability of entity distributions in TKGs. We propose the\nTemporal Message Passing (TeMP) framework to address these challenges by\ncombining graph neural networks, temporal dynamics models, data imputation and\nfrequency-based gating techniques. Experiments on standard TKG tasks show that\nour approach provides substantial gains compared to the previous state of the\nart, achieving a 10.7% average relative improvement in Hits@10 across three\nstandard benchmarks. Our analysis also reveals important sources of variability\nboth within and across TKG datasets, and we introduce several simple but strong\nbaselines that outperform the prior state of the art in certain settings.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 17:11:53 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Wu", "Jiapeng", ""], ["Cao", "Meng", ""], ["Cheung", "Jackie Chi Kit", ""], ["Hamilton", "William L.", ""]]}, {"id": "2010.03532", "submitter": "Yixin Nie", "authors": "Yixin Nie, Xiang Zhou, Mohit Bansal", "title": "What Can We Learn from Collective Human Opinions on Natural Language\n  Inference Data?", "comments": "EMNLP 2020 (13 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the subjective nature of many NLP tasks, most NLU evaluations have\nfocused on using the majority label with presumably high agreement as the\nground truth. Less attention has been paid to the distribution of human\nopinions. We collect ChaosNLI, a dataset with a total of 464,500 annotations to\nstudy Collective HumAn OpinionS in oft-used NLI evaluation sets. This dataset\nis created by collecting 100 annotations per example for 3,113 examples in SNLI\nand MNLI and 1,532 examples in Abductive-NLI. Analysis reveals that: (1) high\nhuman disagreement exists in a noticeable amount of examples in these datasets;\n(2) the state-of-the-art models lack the ability to recover the distribution\nover human labels; (3) models achieve near-perfect accuracy on the subset of\ndata with a high level of human agreement, whereas they can barely beat a\nrandom guess on the data with low levels of human agreement, which compose most\nof the common errors made by state-of-the-art models on the evaluation sets.\nThis questions the validity of improving model performance on old metrics for\nthe low-agreement part of evaluation datasets. Hence, we argue for a detailed\nexamination of human agreement in future data collection efforts, and\nevaluating model outputs against the distribution over collective human\nopinions. The ChaosNLI dataset and experimental scripts are available at\nhttps://github.com/easonnie/ChaosNLI\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 17:26:06 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 19:32:45 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Nie", "Yixin", ""], ["Zhou", "Xiang", ""], ["Bansal", "Mohit", ""]]}, {"id": "2010.03549", "submitter": "Amirsina Torfi", "authors": "Amirsina Torfi, Mohammadreza Beyki, Edward A. Fox", "title": "On the Evaluation of Generative Adversarial Networks By Discriminative\n  Models", "comments": "Accepted to be published in ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) can accurately model complex\nmulti-dimensional data and generate realistic samples. However, due to their\nimplicit estimation of data distributions, their evaluation is a challenging\ntask. The majority of research efforts associated with tackling this issue were\nvalidated by qualitative visual evaluation. Such approaches do not generalize\nwell beyond the image domain. Since many of those evaluation metrics are\nproposed and bound to the vision domain, they are difficult to apply to other\ndomains. Quantitative measures are necessary to better guide the training and\ncomparison of different GANs models. In this work, we leverage Siamese neural\nnetworks to propose a domain-agnostic evaluation metric: (1) with a qualitative\nevaluation that is consistent with human evaluation, (2) that is robust\nrelative to common GAN issues such as mode dropping and invention, and (3) does\nnot require any pretrained classifier. The empirical results in this paper\ndemonstrate the superiority of this method compared to the popular Inception\nScore and are competitive with the FID score.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 17:50:39 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Torfi", "Amirsina", ""], ["Beyki", "Mohammadreza", ""], ["Fox", "Edward A.", ""]]}, {"id": "2010.03558", "submitter": "Adrian Bulat", "authors": "Adrian Bulat and Brais Martinez and Georgios Tzimiropoulos", "title": "High-Capacity Expert Binary Networks", "comments": "Accepted at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network binarization is a promising hardware-aware direction for creating\nefficient deep models. Despite its memory and computational advantages,\nreducing the accuracy gap between binary models and their real-valued\ncounterparts remains an unsolved challenging research problem. To this end, we\nmake the following 3 contributions: (a) To increase model capacity, we propose\nExpert Binary Convolution, which, for the first time, tailors conditional\ncomputing to binary networks by learning to select one data-specific expert\nbinary filter at a time conditioned on input features. (b) To increase\nrepresentation capacity, we propose to address the inherent information\nbottleneck in binary networks by introducing an efficient width expansion\nmechanism which keeps the binary operations within the same budget. (c) To\nimprove network design, we propose a principled binary network growth mechanism\nthat unveils a set of network topologies of favorable properties. Overall, our\nmethod improves upon prior work, with no increase in computational cost, by\n$\\sim6 \\%$, reaching a groundbreaking $\\sim 71\\%$ on ImageNet classification.\nCode will be made available\n$\\href{https://www.adrianbulat.com/binary-networks}{here}$.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 17:58:10 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 18:16:16 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Bulat", "Adrian", ""], ["Martinez", "Brais", ""], ["Tzimiropoulos", "Georgios", ""]]}, {"id": "2010.03574", "submitter": "Chao-Chun Hsu", "authors": "Chao-Chun Hsu, Shantanu Karnwal, Sendhil Mullainathan, Ziad Obermeyer,\n  Chenhao Tan", "title": "Characterizing the Value of Information in Medical Notes", "comments": "15 pages, 12 figures, Findings of EMNLP 2020, code is available at\n  https://github.com/BoulderDS/value-of-medical-notes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models depend on the quality of input data. As electronic\nhealth records are widely adopted, the amount of data in health care is\ngrowing, along with complaints about the quality of medical notes. We use two\nprediction tasks, readmission prediction and in-hospital mortality prediction,\nto characterize the value of information in medical notes. We show that as a\nwhole, medical notes only provide additional predictive power over structured\ninformation in readmission prediction. We further propose a probing framework\nto select parts of notes that enable more accurate predictions than using all\nnotes, despite that the selected information leads to a distribution shift from\nthe training data (\"all notes\"). Finally, we demonstrate that models trained on\nthe selected valuable information achieve even better predictive performance,\nwith only 6.8% of all the tokens for readmission prediction.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 18:00:03 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 17:04:27 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Hsu", "Chao-Chun", ""], ["Karnwal", "Shantanu", ""], ["Mullainathan", "Sendhil", ""], ["Obermeyer", "Ziad", ""], ["Tan", "Chenhao", ""]]}, {"id": "2010.03593", "submitter": "Sven Gowal", "authors": "Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, Pushmeet Kohli", "title": "Uncovering the Limits of Adversarial Training against Norm-Bounded\n  Adversarial Examples", "comments": "Fixed minor formatting issues and added link to models", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training and its variants have become de facto standards for\nlearning robust deep neural networks. In this paper, we explore the landscape\naround adversarial training in a bid to uncover its limits. We systematically\nstudy the effect of different training losses, model sizes, activation\nfunctions, the addition of unlabeled data (through pseudo-labeling) and other\nfactors on adversarial robustness. We discover that it is possible to train\nrobust models that go well beyond state-of-the-art results by combining larger\nmodels, Swish/SiLU activations and model weight averaging. We demonstrate large\nimprovements on CIFAR-10 and CIFAR-100 against $\\ell_\\infty$ and $\\ell_2$\nnorm-bounded perturbations of size $8/255$ and $128/255$, respectively. In the\nsetting with additional unlabeled data, we obtain an accuracy under attack of\n65.88% against $\\ell_\\infty$ perturbations of size $8/255$ on CIFAR-10 (+6.35%\nwith respect to prior art). Without additional data, we obtain an accuracy\nunder attack of 57.20% (+3.46%). To test the generality of our findings and\nwithout any additional modifications, we obtain an accuracy under attack of\n80.53% (+7.62%) against $\\ell_2$ perturbations of size $128/255$ on CIFAR-10,\nand of 36.88% (+8.46%) against $\\ell_\\infty$ perturbations of size $8/255$ on\nCIFAR-100. All models are available at\nhttps://github.com/deepmind/deepmind-research/tree/master/adversarial_robustness.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 18:19:09 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 16:28:20 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 08:08:12 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Gowal", "Sven", ""], ["Qin", "Chongli", ""], ["Uesato", "Jonathan", ""], ["Mann", "Timothy", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "2010.03597", "submitter": "John Mern", "authors": "John Mern, Anil Yildiz, Zachary Sunberg, Tapan Mukerji, Mykel J.\n  Kochenderfer", "title": "Bayesian Optimized Monte Carlo Planning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online solvers for partially observable Markov decision processes have\ndifficulty scaling to problems with large action spaces. Monte Carlo tree\nsearch with progressive widening attempts to improve scaling by sampling from\nthe action space to construct a policy search tree. The performance of\nprogressive widening search is dependent upon the action sampling policy, often\nrequiring problem-specific samplers. In this work, we present a general method\nfor efficient action sampling based on Bayesian optimization. The proposed\nmethod uses a Gaussian process to model a belief over the action-value function\nand selects the action that will maximize the expected improvement in the\noptimal action value. We implement the proposed approach in a new online tree\nsearch algorithm called Bayesian Optimized Monte Carlo Planning (BOMCP).\nSeveral experiments show that BOMCP is better able to scale to large action\nspace POMDPs than existing state-of-the-art tree search solvers.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 18:29:27 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Mern", "John", ""], ["Yildiz", "Anil", ""], ["Sunberg", "Zachary", ""], ["Mukerji", "Tapan", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2010.03599", "submitter": "John Mern", "authors": "John Mern, Anil Yildiz, Larry Bush, Tapan Mukerji, Mykel J.\n  Kochenderfer", "title": "Improved POMDP Tree Search Planning with Prioritized Action Branching", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online solvers for partially observable Markov decision processes have\ndifficulty scaling to problems with large action spaces. This paper proposes a\nmethod called PA-POMCPOW to sample a subset of the action space that provides\nvarying mixtures of exploitation and exploration for inclusion in a search\ntree. The proposed method first evaluates the action space according to a score\nfunction that is a linear combination of expected reward and expected\ninformation gain. The actions with the highest score are then added to the\nsearch tree during tree expansion. Experiments show that PA-POMCPOW is able to\noutperform existing state-of-the-art solvers on problems with large discrete\naction spaces.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 18:33:57 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Mern", "John", ""], ["Yildiz", "Anil", ""], ["Bush", "Larry", ""], ["Mukerji", "Tapan", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2010.03600", "submitter": "Hung Nguyen", "authors": "Hung T. Nguyen, Pierre J. Liang, Leman Akoglu", "title": "Anomaly Detection in Large Labeled Multi-Graph Databases", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Within a large database G containing graphs with labeled nodes and directed,\nmulti-edges; how can we detect the anomalous graphs? Most existing work are\ndesigned for plain (unlabeled) and/or simple (unweighted) graphs. We introduce\nCODETECT, the first approach that addresses the anomaly detection task for\ngraph databases with such complex nature. To this end, it identifies a small\nrepresentative set S of structural patterns (i.e., node-labeled network motifs)\nthat losslessly compress database G as concisely as possible. Graphs that do\nnot compress well are flagged as anomalous. CODETECT exhibits two novel\nbuilding blocks: (i) a motif-based lossless graph encoding scheme, and (ii)\nfast memory-efficient search algorithms for S. We show the effectiveness of\nCODETECT on transaction graph databases from three different corporations,\nwhere existing baselines adjusted for the task fall behind significantly,\nacross different types of anomalies and performance metrics.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 18:41:33 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Nguyen", "Hung T.", ""], ["Liang", "Pierre J.", ""], ["Akoglu", "Leman", ""]]}, {"id": "2010.03625", "submitter": "Noga H. Rotman", "authors": "Noga H. Rotman, Michael Schapira and Aviv Tamar", "title": "Online Safety Assurance for Deep Reinforcement Learning", "comments": "8 pages, to appear in The 19th ACM Workshop on Hot Topics in Networks\n  (HotNets 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning has been successfully applied to a variety of\nnetworking problems. A fundamental challenge is that when the operational\nenvironment for a learning-augmented system differs from its training\nenvironment, such systems often make badly informed decisions, leading to bad\nperformance. We argue that safely deploying learning-driven systems requires\nbeing able to determine, in real time, whether system behavior is coherent, for\nthe purpose of defaulting to a reasonable heuristic when this is not so. We\nterm this the online safety assurance problem (OSAP). We present three\napproaches to quantifying decision uncertainty that differ in terms of the\nsignal used to infer uncertainty. We illustrate the usefulness of online safety\nassurance in the context of the proposed deep reinforcement learning (RL)\napproach to video streaming. While deep RL for video streaming bests other\napproaches when the operational and training environments match, it is\ndominated by simple heuristics when the two differ. Our preliminary findings\nsuggest that transitioning to a default policy when decision uncertainty is\ndetected is key to enjoying the performance benefits afforded by leveraging ML\nwithout compromising on safety.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 19:54:01 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Rotman", "Noga H.", ""], ["Schapira", "Michael", ""], ["Tamar", "Aviv", ""]]}, {"id": "2010.03635", "submitter": "Aleksandar Stanic", "authors": "Aleksandar Stani\\'c, Sjoerd van Steenkiste, J\\\"urgen Schmidhuber", "title": "Hierarchical Relational Inference", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common-sense physical reasoning in the real world requires learning about the\ninteractions of objects and their dynamics. The notion of an abstract object,\nhowever, encompasses a wide variety of physical objects that differ greatly in\nterms of the complex behaviors they support. To address this, we propose a\nnovel approach to physical reasoning that models objects as hierarchies of\nparts that may locally behave separately, but also act more globally as a\nsingle whole. Unlike prior approaches, our method learns in an unsupervised\nfashion directly from raw visual images to discover objects, parts, and their\nrelations. It explicitly distinguishes multiple levels of abstraction and\nimproves over a strong baseline at modeling synthetic and real-world videos.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 20:19:10 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 22:14:23 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Stani\u0107", "Aleksandar", ""], ["van Steenkiste", "Sjoerd", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "2010.03644", "submitter": "Wanrong Zhu", "authors": "Wanrong Zhu, Xin Eric Wang, Pradyumna Narayana, Kazoo Sone, Sugato\n  Basu, William Yang Wang", "title": "Towards Understanding Sample Variance in Visually Grounded Language\n  Generation: Evaluations and Observations", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in visually grounded language generation is to build robust\nbenchmark datasets and models that can generalize well in real-world settings.\nTo do this, it is critical to ensure that our evaluation protocols are correct,\nand benchmarks are reliable. In this work, we set forth to design a set of\nexperiments to understand an important but often ignored problem in visually\ngrounded language generation: given that humans have different utilities and\nvisual attention, how will the sample variance in multi-reference datasets\naffect the models' performance? Empirically, we study several multi-reference\ndatasets and corresponding vision-and-language tasks. We show that it is of\nparamount importance to report variance in experiments; that human-generated\nreferences could vary drastically in different datasets/tasks, revealing the\nnature of each task; that metric-wise, CIDEr has shown systematically larger\nvariances than others. Our evaluations on reference-per-instance shed light on\nthe design of reliable datasets in the future.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 20:45:14 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Zhu", "Wanrong", ""], ["Wang", "Xin Eric", ""], ["Narayana", "Pradyumna", ""], ["Sone", "Kazoo", ""], ["Basu", "Sugato", ""], ["Wang", "William Yang", ""]]}, {"id": "2010.03648", "submitter": "Nikunj Saunshi", "authors": "Nikunj Saunshi, Sadhika Malladi, Sanjeev Arora", "title": "A Mathematical Exploration of Why Language Models Help Solve Downstream\n  Tasks", "comments": "This version is the camera-ready version for ICLR 2021. Main changes\n  include a detailed discussion about natural tasks, more detailed proof sketch\n  and updated experimental evaluations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive language models, pretrained using large text corpora to do\nwell on next word prediction, have been successful at solving many downstream\ntasks, even with zero-shot usage. However, there is little theoretical\nunderstanding of this success. This paper initiates a mathematical study of\nthis phenomenon for the downstream task of text classification by considering\nthe following questions: (1) What is the intuitive connection between the\npretraining task of next word prediction and text classification? (2) How can\nwe mathematically formalize this connection and quantify the benefit of\nlanguage modeling? For (1), we hypothesize, and verify empirically, that\nclassification tasks of interest can be reformulated as sentence completion\ntasks, thus making language modeling a meaningful pretraining task. With a\nmathematical formalization of this hypothesis, we make progress towards (2) and\nshow that language models that are $\\epsilon$-optimal in cross-entropy\n(log-perplexity) learn features that can linearly solve such classification\ntasks with $\\mathcal{O}(\\sqrt{\\epsilon})$ error, thus demonstrating that doing\nwell on language modeling can be beneficial for downstream tasks. We\nexperimentally verify various assumptions and theoretical findings, and also\nuse insights from the analysis to design a new objective function that performs\nwell on some classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 20:56:40 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 17:59:14 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Saunshi", "Nikunj", ""], ["Malladi", "Sadhika", ""], ["Arora", "Sanjeev", ""]]}, {"id": "2010.03665", "submitter": "Pedro Saleiro", "authors": "Andr\\'e F. Cruz, Pedro Saleiro, Catarina Bel\\'em, Carlos Soares, Pedro\n  Bizarro", "title": "A Bandit-Based Algorithm for Fairness-Aware Hyperparameter Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considerable research effort has been guided towards algorithmic fairness but\nthere is still no major breakthrough. In practice, an exhaustive search over\nall possible techniques and hyperparameters is needed to find optimal\nfairness-accuracy trade-offs. Hence, coupled with the lack of tools for ML\npractitioners, real-world adoption of bias reduction methods is still scarce.\nTo address this, we present Fairband, a bandit-based fairness-aware\nhyperparameter optimization (HO) algorithm. Fairband is conceptually simple,\nresource-efficient, easy to implement, and agnostic to both the objective\nmetrics, model types and the hyperparameter space being explored. Moreover, by\nintroducing fairness notions into HO, we enable seamless and efficient\nintegration of fairness objectives into real-world ML pipelines. We compare\nFairband with popular HO methods on four real-world decision-making datasets.\nWe show that Fairband can efficiently navigate the fairness-accuracy trade-off\nthrough hyperparameter optimization. Furthermore, without extra training cost,\nit consistently finds configurations attaining substantially improved fairness\nat a comparatively small decrease in predictive accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 21:35:16 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 16:37:39 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Cruz", "Andr\u00e9 F.", ""], ["Saleiro", "Pedro", ""], ["Bel\u00e9m", "Catarina", ""], ["Soares", "Carlos", ""], ["Bizarro", "Pedro", ""]]}, {"id": "2010.03680", "submitter": "Yaqing Wang", "authors": "Yaqing Wang, Subhabrata Mukherjee, Haoda Chu, Yuancheng Tu, Ming Wu,\n  Jing Gao, Ahmed Hassan Awadallah", "title": "Adaptive Self-training for Few-shot Neural Sequence Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence labeling is an important technique employed for many Natural\nLanguage Processing (NLP) tasks, such as Named Entity Recognition (NER), slot\ntagging for dialog systems and semantic parsing. Large-scale pre-trained\nlanguage models obtain very good performance on these tasks when fine-tuned on\nlarge amounts of task-specific labeled data. However, such large-scale labeled\ndatasets are difficult to obtain for several tasks and domains due to the high\ncost of human annotation as well as privacy and data access constraints for\nsensitive user applications. This is exacerbated for sequence labeling tasks\nrequiring such annotations at token-level. In this work, we develop techniques\nto address the label scarcity challenge for neural sequence labeling models.\nSpecifically, we develop self-training and meta-learning techniques for\ntraining neural sequence taggers with few labels. While self-training serves as\nan effective mechanism to learn from large amounts of unlabeled data --\nmeta-learning helps in adaptive sample re-weighting to mitigate error\npropagation from noisy pseudo-labels. Extensive experiments on six benchmark\ndatasets including two for massive multilingual NER and four slot tagging\ndatasets for task-oriented dialog systems demonstrate the effectiveness of our\nmethod. With only 10 labeled examples for each class for each task, our method\nobtains 10% improvement over state-of-the-art systems demonstrating its\neffectiveness for the low-resource setting.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 22:29:05 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 17:16:57 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Wang", "Yaqing", ""], ["Mukherjee", "Subhabrata", ""], ["Chu", "Haoda", ""], ["Tu", "Yuancheng", ""], ["Wu", "Ming", ""], ["Gao", "Jing", ""], ["Awadallah", "Ahmed Hassan", ""]]}, {"id": "2010.03688", "submitter": "Amrit Nagarajan", "authors": "Amrit Nagarajan, Sanchari Sen, Jacob R. Stevens, Anand Raghunathan", "title": "Optimizing Transformers with Approximate Computing for Faster, Smaller\n  and more Accurate NLP Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer models have garnered a lot of interest in recent years by\ndelivering state-of-the-art performance in a range of Natural Language\nProcessing (NLP) tasks. However, these models can have over a hundred billion\nparameters, presenting very high computational and memory requirements. We\naddress this challenge through Approximate Computing, specifically targeting\nthe use of Transformers in NLP tasks. Transformers are typically pre-trained\nand subsequently specialized for specific tasks through transfer learning.\nBased on the observation that pre-trained Transformers are often\nover-parameterized for several downstream NLP tasks, we propose a framework to\ncreate smaller, faster and in some cases more accurate models. The key\ncornerstones of the framework are a Significance Analysis (SA) method that\nidentifies components in a pre-trained Transformer that are less significant\nfor a given task, and techniques to approximate the less significant\ncomponents. Our approximations include pruning of blocks, attention heads and\nweight groups, quantization of less significant weights and a low-complexity\nsign-matching based attention mechanism. Our framework can be adapted to\nproduce models that are faster, smaller and/or more accurate, depending on the\nuser's constraints. We apply our framework to seven Transformer models,\nincluding optimized models like DistilBERT and Q8BERT, and three downstream\ntasks. We demonstrate that our framework produces models that are up to 4x\nfaster and up to 14x smaller (with less than 0.5% relative accuracy\ndegradation), or up to 5.5% more accurate with simultaneous improvements of up\nto 9.83x in model size or 2.94x in speed.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 23:29:34 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Nagarajan", "Amrit", ""], ["Sen", "Sanchari", ""], ["Stevens", "Jacob R.", ""], ["Raghunathan", "Anand", ""]]}, {"id": "2010.03694", "submitter": "Somdeb Majumdar", "authors": "Hassam Sheikh, Shauharda Khadka, Santiago Miret, Somdeb Majumdar", "title": "Learning Intrinsic Symbolic Rewards in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning effective policies for sparse objectives is a key challenge in Deep\nReinforcement Learning (RL). A common approach is to design task-related dense\nrewards to improve task learnability. While such rewards are easily\ninterpreted, they rely on heuristics and domain expertise. Alternate approaches\nthat train neural networks to discover dense surrogate rewards avoid\nheuristics, but are high-dimensional, black-box solutions offering little\ninterpretability. In this paper, we present a method that discovers dense\nrewards in the form of low-dimensional symbolic trees - thus making them more\ntractable for analysis. The trees use simple functional operators to map an\nagent's observations to a scalar reward, which then supervises the policy\ngradient learning of a neural network policy. We test our method on continuous\naction spaces in Mujoco and discrete action spaces in Atari and Pygame\nenvironments. We show that the discovered dense rewards are an effective signal\nfor an RL policy to solve the benchmark tasks. Notably, we significantly\noutperform a widely used, contemporary neural-network based reward-discovery\nalgorithm in all environments considered.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 00:02:46 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 06:42:03 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Sheikh", "Hassam", ""], ["Khadka", "Shauharda", ""], ["Miret", "Santiago", ""], ["Majumdar", "Somdeb", ""]]}, {"id": "2010.03697", "submitter": "Benjamin Haeffele", "authors": "Benjamin D. Haeffele, Chong You, Ren\\'e Vidal", "title": "A Critique of Self-Expressive Deep Subspace Clustering", "comments": "Published as a conference paper at the International Conference on\n  Learning Representations (ICLR) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering is an unsupervised clustering technique designed to\ncluster data that is supported on a union of linear subspaces, with each\nsubspace defining a cluster with dimension lower than the ambient space. Many\nexisting formulations for this problem are based on exploiting the\nself-expressive property of linear subspaces, where any point within a subspace\ncan be represented as linear combination of other points within the subspace.\nTo extend this approach to data supported on a union of non-linear manifolds,\nnumerous studies have proposed learning an embedding of the original data using\na neural network which is regularized by a self-expressive loss function on the\ndata in the embedded space to encourage a union of linear subspaces prior on\nthe data in the embedded space. Here we show that there are a number of\npotential flaws with this approach which have not been adequately addressed in\nprior work. In particular, we show the model formulation is often ill-posed in\nthat it can lead to a degenerate embedding of the data, which need not\ncorrespond to a union of subspaces at all and is poorly suited for clustering.\nWe validate our theoretical results experimentally and also repeat prior\nexperiments reported in the literature, where we conclude that a significant\nportion of the previously claimed performance benefits can be attributed to an\nad-hoc post processing step rather than the deep subspace clustering model.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 00:14:59 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 20:33:37 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Haeffele", "Benjamin D.", ""], ["You", "Chong", ""], ["Vidal", "Ren\u00e9", ""]]}, {"id": "2010.03701", "submitter": "Jaewoo Lee", "authors": "Jaewoo Lee and Daniel Kifer", "title": "Differentially Private Deep Learning with Direct Feedback Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard methods for differentially private training of deep neural networks\nreplace back-propagated mini-batch gradients with biased and noisy\napproximations to the gradient. These modifications to training often result in\na privacy-preserving model that is significantly less accurate than its\nnon-private counterpart. We hypothesize that alternative training algorithms\nmay be more amenable to differential privacy. Specifically, we examine the\nsuitability of direct feedback alignment (DFA). We propose the first\ndifferentially private method for training deep neural networks with DFA and\nshow that it achieves significant gains in accuracy (often by 10-20%) compared\nto backprop-based differentially private training on a variety of architectures\n(fully connected, convolutional) and datasets.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 00:25:22 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Lee", "Jaewoo", ""], ["Kifer", "Daniel", ""]]}, {"id": "2010.03714", "submitter": "Haidar Khan", "authors": "Qile Zhu, Haidar Khan, Saleh Soltan, Stephen Rawls, Wael Hamza", "title": "Don't Parse, Insert: Multilingual Semantic Parsing with Insertion Based\n  Decoding", "comments": "Presented at CoNLL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing is one of the key components of natural language\nunderstanding systems. A successful parse transforms an input utterance to an\naction that is easily understood by the system. Many algorithms have been\nproposed to solve this problem, from conventional rulebased or statistical\nslot-filling systems to shiftreduce based neural parsers. For complex parsing\ntasks, the state-of-the-art method is based on autoregressive sequence to\nsequence models to generate the parse directly. This model is slow at inference\ntime, generating parses in O(n) decoding steps (n is the length of the target\nsequence). In addition, we demonstrate that this method performs poorly in\nzero-shot cross-lingual transfer learning settings. In this paper, we propose a\nnon-autoregressive parser which is based on the insertion transformer to\novercome these two issues. Our approach 1) speeds up decoding by 3x while\noutperforming the autoregressive model and 2) significantly improves\ncross-lingual transfer in the low-resource setting by 37% compared to\nautoregressive baseline. We test our approach on three well-known monolingual\ndatasets: ATIS, SNIPS and TOP. For cross lingual semantic parsing, we use the\nMultiATIS++ and the multilingual TOP datasets.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 01:18:42 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Zhu", "Qile", ""], ["Khan", "Haidar", ""], ["Soltan", "Saleh", ""], ["Rawls", "Stephen", ""], ["Hamza", "Wael", ""]]}, {"id": "2010.03724", "submitter": "Jiechieu Kameni Florentin Flambeau", "authors": "Jiechieu Kameni Florentin Flambeau and Tsopze Norbert", "title": "Simplifying the explanation of deep neural networks with sufficient and\n  necessary feature-sets: case of text classification", "comments": "Figure 3.d has been replaced : the distribution of relevances was\n  shifted by mistake, Fig. 4 has been replaced : Sufficient features was\n  wrongly highlighted, Fig. 2 has been replaced : The sum z was incorrect.\n  Related calculations has been updated accordingly. Notes : These changes are\n  minor changes and do not alter the comprehension of the findings highlted in\n  the work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decade, deep neural networks (DNN) have demonstrated\nimpressive performances solving a wide range of problems in various domains\nsuch as medicine, finance, law, etc. Despite their great performances, they\nhave long been considered as black-box systems, providing good results without\nbeing able to explain them. However, the inability to explain a system decision\npresents a serious risk in critical domains such as medicine where people's\nlives are at stake. Several works have been done to uncover the inner reasoning\nof deep neural networks. Saliency methods explain model decisions by assigning\nweights to input features that reflect their contribution to the classifier\ndecision. However, not all features are necessary to explain a model decision.\nIn practice, classifiers might strongly rely on a subset of features that might\nbe sufficient to explain a particular decision. The aim of this article is to\npropose a method to simplify the prediction explanation of One-Dimensional (1D)\nConvolutional Neural Networks (CNN) by identifying sufficient and necessary\nfeatures-sets. We also propose an adaptation of Layer-wise Relevance\nPropagation for 1D-CNN. Experiments carried out on multiple datasets show that\nthe distribution of relevance among features is similar to that obtained with a\nwell known state of the art model. Moreover, the sufficient and necessary\nfeatures extracted perceptually appear convincing to humans.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 02:01:21 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 17:04:53 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Flambeau", "Jiechieu Kameni Florentin", ""], ["Norbert", "Tsopze", ""]]}, {"id": "2010.03744", "submitter": "Vijaya Sai Krishna Gottipati", "authors": "Sai Krishna Gottipati, Yashaswi Pathak, Rohan Nuttall, Sahir, Raviteja\n  Chunduru, Ahmed Touati, Sriram Ganapathi Subramanian, Matthew E. Taylor,\n  Sarath Chandar", "title": "Maximum Reward Formulation In Reinforcement Learning", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms typically deal with maximizing the\nexpected cumulative return (discounted or undiscounted, finite or infinite\nhorizon). However, several crucial applications in the real world, such as drug\ndiscovery, do not fit within this framework because an RL agent only needs to\nidentify states (molecules) that achieve the highest reward within a trajectory\nand does not need to optimize for the expected cumulative return. In this work,\nwe formulate an objective function to maximize the expected maximum reward\nalong a trajectory, derive a novel functional form of the Bellman equation,\nintroduce the corresponding Bellman operators, and provide a proof of\nconvergence. Using this formulation, we achieve state-of-the-art results on the\ntask of molecule generation that mimics a real-world drug discovery pipeline.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 03:07:31 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Gottipati", "Sai Krishna", ""], ["Pathak", "Yashaswi", ""], ["Nuttall", "Rohan", ""], ["Sahir", "", ""], ["Chunduru", "Raviteja", ""], ["Touati", "Ahmed", ""], ["Subramanian", "Sriram Ganapathi", ""], ["Taylor", "Matthew E.", ""], ["Chandar", "Sarath", ""]]}, {"id": "2010.03755", "submitter": "Xinting Huang", "authors": "Xinting Huang, Jianzhong Qi, Yu Sun, Rui Zhang", "title": "Generalizable and Explainable Dialogue Generation via Explicit Action\n  Learning", "comments": "Accepted to Proceedings of EMNLP 2020 (Findings)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Response generation for task-oriented dialogues implicitly optimizes two\nobjectives at the same time: task completion and language quality. Conditioned\nresponse generation serves as an effective approach to separately and better\noptimize these two objectives. Such an approach relies on system action\nannotations which are expensive to obtain. To alleviate the need of action\nannotations, latent action learning is introduced to map each utterance to a\nlatent representation. However, this approach is prone to over-dependence on\nthe training data, and the generalization capability is thus restricted. To\naddress this issue, we propose to learn natural language actions that represent\nutterances as a span of words. This explicit action representation promotes\ngeneralization via the compositional structure of language. It also enables an\nexplainable generation process. Our proposed unsupervised approach learns a\nmemory component to summarize system utterances into a short span of words. To\nfurther promote a compact action representation, we propose an auxiliary task\nthat restores state annotations as the summarized dialogue context using the\nmemory component. Our proposed approach outperforms latent action baselines on\nMultiWOZ, a benchmark multi-domain dataset.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 04:37:22 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Huang", "Xinting", ""], ["Qi", "Jianzhong", ""], ["Sun", "Yu", ""], ["Zhang", "Rui", ""]]}, {"id": "2010.03759", "submitter": "Weitang Liu", "authors": "Weitang Liu, Xiaoyun Wang, John D. Owens, Yixuan Li", "title": "Energy-based Out-of-distribution Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining whether inputs are out-of-distribution (OOD) is an essential\nbuilding block for safely deploying machine learning models in the open world.\nHowever, previous methods relying on the softmax confidence score suffer from\noverconfident posterior distributions for OOD data. We propose a unified\nframework for OOD detection that uses an energy score. We show that energy\nscores better distinguish in- and out-of-distribution samples than the\ntraditional approach using the softmax scores. Unlike softmax confidence\nscores, energy scores are theoretically aligned with the probability density of\nthe inputs and are less susceptible to the overconfidence issue. Within this\nframework, energy can be flexibly used as a scoring function for any\npre-trained neural classifier as well as a trainable cost function to shape the\nenergy surface explicitly for OOD detection. On a CIFAR-10 pre-trained\nWideResNet, using the energy score reduces the average FPR (at TPR 95%) by\n18.03% compared to the softmax confidence score. With energy-based training,\nour method outperforms the state-of-the-art on common benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 04:42:17 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 22:59:53 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 02:48:54 GMT"}, {"version": "v4", "created": "Mon, 26 Apr 2021 04:59:58 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Liu", "Weitang", ""], ["Wang", "Xiaoyun", ""], ["Owens", "John D.", ""], ["Li", "Yixuan", ""]]}, {"id": "2010.03768", "submitter": "Mohit Shridhar", "authors": "Mohit Shridhar, Xingdi Yuan, Marc-Alexandre C\\^ot\\'e, Yonatan Bisk,\n  Adam Trischler, Matthew Hausknecht", "title": "ALFWorld: Aligning Text and Embodied Environments for Interactive\n  Learning", "comments": "ICLR 2021; Data, code, and videos are available at alfworld.github.io", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a simple request like Put a washed apple in the kitchen fridge, humans\ncan reason in purely abstract terms by imagining action sequences and scoring\ntheir likelihood of success, prototypicality, and efficiency, all without\nmoving a muscle. Once we see the kitchen in question, we can update our\nabstract plans to fit the scene. Embodied agents require the same abilities,\nbut existing work does not yet provide the infrastructure necessary for both\nreasoning abstractly and executing concretely. We address this limitation by\nintroducing ALFWorld, a simulator that enables agents to learn abstract, text\nbased policies in TextWorld (C\\^ot\\'e et al., 2018) and then execute goals from\nthe ALFRED benchmark (Shridhar et al., 2020) in a rich visual environment.\nALFWorld enables the creation of a new BUTLER agent whose abstract knowledge,\nlearned in TextWorld, corresponds directly to concrete, visually grounded\nactions. In turn, as we demonstrate empirically, this fosters better agent\ngeneralization than training only in the visually grounded environment.\nBUTLER's simple, modular design factors the problem to allow researchers to\nfocus on models for improving every piece of the pipeline (language\nunderstanding, planning, navigation, and visual scene understanding).\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 05:13:36 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 22:44:38 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Shridhar", "Mohit", ""], ["Yuan", "Xingdi", ""], ["C\u00f4t\u00e9", "Marc-Alexandre", ""], ["Bisk", "Yonatan", ""], ["Trischler", "Adam", ""], ["Hausknecht", "Matthew", ""]]}, {"id": "2010.03777", "submitter": "Tianyu Liu", "authors": "Tianyu Liu, Xin Zheng, Xiaoan Ding, Baobao Chang and Zhifang Sui", "title": "An Empirical Study on Model-agnostic Debiasing Strategies for Robust\n  Natural Language Inference", "comments": "CoNLL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The prior work on natural language inference (NLI) debiasing mainly targets\nat one or few known biases while not necessarily making the models more robust.\nIn this paper, we focus on the model-agnostic debiasing strategies and explore\nhow to (or is it possible to) make the NLI models robust to multiple distinct\nadversarial attacks while keeping or even strengthening the models'\ngeneralization power. We firstly benchmark prevailing neural NLI models\nincluding pretrained ones on various adversarial datasets. We then try to\ncombat distinct known biases by modifying a mixture of experts (MoE) ensemble\nmethod and show that it's nontrivial to mitigate multiple NLI biases at the\nsame time, and that model-level ensemble method outperforms MoE ensemble\nmethod. We also perform data augmentation including text swap, word\nsubstitution and paraphrase and prove its efficiency in combating various\n(though not all) adversarial attacks at the same time. Finally, we investigate\nseveral methods to merge heterogeneous training data (1.35M) and perform model\nensembling, which are straightforward but effective to strengthen NLI models.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 05:40:45 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 14:57:09 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Liu", "Tianyu", ""], ["Zheng", "Xin", ""], ["Ding", "Xiaoan", ""], ["Chang", "Baobao", ""], ["Sui", "Zhifang", ""]]}, {"id": "2010.03790", "submitter": "Keerthiram Murugesan", "authors": "Keerthiram Murugesan, Mattia Atzeni, Pavan Kapanipathi, Pushkar\n  Shukla, Sadhana Kumaravel, Gerald Tesauro, Kartik Talamadupula, Mrinmaya\n  Sachan, Murray Campbell", "title": "Text-based RL Agents with Commonsense Knowledge: New Challenges,\n  Environments and Baselines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based games have emerged as an important test-bed for Reinforcement\nLearning (RL) research, requiring RL agents to combine grounded language\nunderstanding with sequential decision making. In this paper, we examine the\nproblem of infusing RL agents with commonsense knowledge. Such knowledge would\nallow agents to efficiently act in the world by pruning out implausible\nactions, and to perform look-ahead planning to determine how current actions\nmight affect future world states. We design a new text-based gaming environment\ncalled TextWorld Commonsense (TWC) for training and evaluating RL agents with a\nspecific kind of commonsense knowledge about objects, their attributes, and\naffordances. We also introduce several baseline RL agents which track the\nsequential context and dynamically retrieve the relevant commonsense knowledge\nfrom ConceptNet. We show that agents which incorporate commonsense knowledge in\nTWC perform better, while acting more efficiently. We conduct user-studies to\nestimate human performance on TWC and show that there is ample room for future\nimprovement.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 06:20:00 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Murugesan", "Keerthiram", ""], ["Atzeni", "Mattia", ""], ["Kapanipathi", "Pavan", ""], ["Shukla", "Pushkar", ""], ["Kumaravel", "Sadhana", ""], ["Tesauro", "Gerald", ""], ["Talamadupula", "Kartik", ""], ["Sachan", "Mrinmaya", ""], ["Campbell", "Murray", ""]]}, {"id": "2010.03815", "submitter": "Cenk Bircanoglu", "authors": "Cenk Bircanoglu", "title": "A Comparative Study on Effects of Original and Pseudo Labels for Weakly\n  Supervised Learning for Car Localization Problem", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, the effects of different class labels created as a result of\nmultiple conceptual meanings on localization using Weakly Supervised Learning\npresented on Car Dataset. In addition, the generated labels are included in the\ncomparison, and the solution turned into Unsupervised Learning. This paper\ninvestigates multiple setups for car localization in the images with other\napproaches rather than Supervised Learning. To predict localization labels,\nClass Activation Mapping (CAM) is implemented and from the results, the\nbounding boxes are extracted by using morphological edge detection. Besides the\noriginal class labels, generated class labels also employed to train CAM on\nwhich turn to a solution to Unsupervised Learning example. In the experiments,\nwe first analyze the effects of class labels in Weakly Supervised localization\non the Compcars dataset. We then show that the proposed Unsupervised approach\noutperforms the Weakly Supervised method in this particular dataset by\napproximately %6.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 07:41:40 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Bircanoglu", "Cenk", ""]]}, {"id": "2010.03834", "submitter": "Iztok Fister", "authors": "Iztok Fister Jr., Iztok Fister", "title": "Association rules over time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decisions made nowadays by Artificial Intelligence powered systems are\nusually hard for users to understand. One of the more important issues faced by\ndevelopers is exposed as how to create more explainable Machine Learning\nmodels. In line with this, more explainable techniques need to be developed,\nwhere visual explanation also plays a more important role. This technique could\nalso be applied successfully for explaining the results of Association Rule\nMining.This Chapter focuses on two issues: (1) How to discover the relevant\nassociation rules, and (2) How to express relations between more attributes\nvisually. For the solution of the first issue, the proposed method uses\nDifferential Evolution, while Sankey diagrams are adopted to solve the second\none. This method was applied to a transaction database containing data\ngenerated by an amateur cyclist in past seasons, using a mobile device worn\nduring the realization of training sessions that is divided into four time\nperiods. The results of visualization showed that a trend in improving\nperformance of an athlete can be indicated by changing the attributes appearing\nin the selected association rules in different time periods.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 08:31:34 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Fister", "Iztok", "Jr."], ["Fister", "Iztok", ""]]}, {"id": "2010.03848", "submitter": "Brendan Tidd", "authors": "Brendan Tidd, Nicolas Hudson, Akansel Cosgun", "title": "Guided Curriculum Learning for Walking Over Complex Terrain", "comments": "Submitted to Australasian Conference on Robotics and Automation\n  (ACRA) 2020", "journal-ref": "The proceedings of the Australasian Conference on Robotics and\n  Automation (ACRA) 2020", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable bipedal walking over complex terrain is a challenging problem, using\na curriculum can help learning. Curriculum learning is the idea of starting\nwith an achievable version of a task and increasing the difficulty as a success\ncriteria is met. We propose a 3-stage curriculum to train Deep Reinforcement\nLearning policies for bipedal walking over various challenging terrains. In the\nfirst stage, the agent starts on an easy terrain and the terrain difficulty is\ngradually increased, while forces derived from a target policy are applied to\nthe robot joints and the base. In the second stage, the guiding forces are\ngradually reduced to zero. Finally, in the third stage, random perturbations\nwith increasing magnitude are applied to the robot base, so the robustness of\nthe policies are improved. In simulation experiments, we show that our approach\nis effective in learning walking policies, separate from each other, for five\nterrain types: flat, hurdles, gaps, stairs, and steps. Moreover, we demonstrate\nthat in the absence of human demonstrations, a simple hand designed walking\ntrajectory is a sufficient prior to learn to traverse complex terrain types. In\nablation studies, we show that taking out any one of the three stages of the\ncurriculum degrades the learning performance.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 09:03:43 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 19:36:06 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Tidd", "Brendan", ""], ["Hudson", "Nicolas", ""], ["Cosgun", "Akansel", ""]]}, {"id": "2010.03855", "submitter": "Dong-Jin Kim", "authors": "Dong-Jin Kim, Tae-Hyun Oh, Jinsoo Choi, In So Kweon", "title": "Dense Relational Image Captioning via Multi-task Triple-Stream Networks", "comments": "Journal extension of our CVPR 2019 paper ( arXiv:1903.05942 ). Source\n  code : https://github.com/Dong-JinKim/DenseRelationalCaptioning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce dense relational captioning, a novel image captioning task which\naims to generate multiple captions with respect to relational information\nbetween objects in a visual scene. Relational captioning provides explicit\ndescriptions of each relationship between object combinations. This framework\nis advantageous in both diversity and amount of information, leading to a\ncomprehensive image understanding based on relationships, e.g., relational\nproposal generation. For relational understanding between objects, the\npart-of-speech (POS, i.e., subject-object-predicate categories) can be a\nvaluable prior information to guide the causal sequence of words in a caption.\nWe enforce our framework to not only learn to generate captions but also\npredict the POS of each word. To this end, we propose the multi-task\ntriple-stream network (MTTSNet) which consists of three recurrent units\nresponsible for each POS which is trained by jointly predicting the correct\ncaptions and POS for each word. In addition, we found that the performance of\nMTTSNet can be improved by modulating the object embeddings with an explicit\nrelational module. We demonstrate that our proposed model can generate more\ndiverse and richer captions, via extensive experimental analysis on large scale\ndatasets and several metrics. We additionally extend analysis to an ablation\nstudy, applications on holistic image captioning, scene graph generation, and\nretrieval tasks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 09:17:55 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 18:14:14 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Kim", "Dong-Jin", ""], ["Oh", "Tae-Hyun", ""], ["Choi", "Jinsoo", ""], ["Kweon", "In So", ""]]}, {"id": "2010.03863", "submitter": "Anna Rogers", "authors": "Anna Rogers, Isabelle Augenstein", "title": "What Can We Do to Improve Peer Review in NLP?", "comments": "To appear at Findings of EMNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer review is our best tool for judging the quality of conference\nsubmissions, but it is becoming increasingly spurious. We argue that a part of\nthe problem is that the reviewers and area chairs face a poorly defined task\nforcing apples-to-oranges comparisons. There are several potential ways\nforward, but the key difficulty is creating the incentives and mechanisms for\ntheir consistent implementation in the NLP community.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 09:32:21 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Rogers", "Anna", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2010.03920", "submitter": "Daniel Zeman", "authors": "Martin Vastl, Daniel Zeman, Rudolf Rosa", "title": "Predicting Typological Features in WALS using Language Embeddings and\n  Conditional Probabilities: \\'UFAL Submission to the SIGTYP 2020 Shared Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present our submission to the SIGTYP 2020 Shared Task on the prediction of\ntypological features. We submit a constrained system, predicting typological\nfeatures only based on the WALS database. We investigate two approaches. The\nsimpler of the two is a system based on estimating correlation of feature\nvalues within languages by computing conditional probabilities and mutual\ninformation. The second approach is to train a neural predictor operating on\nprecomputed language embeddings based on WALS features. Our submitted system\ncombines the two approaches based on their self-estimated confidence scores. We\nreach the accuracy of 70.7% on the test data and rank first in the shared task.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 12:05:48 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Vastl", "Martin", ""], ["Zeman", "Daniel", ""], ["Rosa", "Rudolf", ""]]}, {"id": "2010.03933", "submitter": "Debo Cheng", "authors": "Zhenlong Xu (1), Jixue Liu (1), Debo Cheng (1), Jiuyong Li (1), Lin\n  Liu (1), Ke Wang (2) ((1) STEM, Univsersity of South Austrlia, (2) Simon\n  Frasier University)", "title": "Assessing the Fairness of Classifiers with Collider Bias", "comments": "9pages,7figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing maturity of machine learning technologies and their\napplications to decisions relate to everyday decision making have brought\nconcerns about the fairness of the decisions. However, current fairness\nassessment systems often suffer from collider bias, which leads to a spurious\nassociation between the protected attribute and the outcomes. To achieve\nfairness evaluation on prediction models at the individual level, in this\npaper, we develop the causality-based theorems to support the use of direct\ncausal effect estimation for fairness assessment on a given a classifier\nwithout access to original training data. Based on the theorems, an unbiased\nsituation test method is presented to assess individual fairness of predictions\nby a classifier, through the elimination of the impact of collider bias of the\nclassifier on the fairness assessment. Extensive experiments have been\nperformed on synthetic and real-world data to evaluate the performance of the\nproposed method. The experimental results show that the proposed method reduces\nbias significantly.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 12:41:02 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Xu", "Zhenlong", ""], ["Liu", "Jixue", ""], ["Cheng", "Debo", ""], ["Li", "Jiuyong", ""], ["Liu", "Lin", ""], ["Wang", "Ke", ""]]}, {"id": "2010.03934", "submitter": "Minqi Jiang", "authors": "Minqi Jiang, Edward Grefenstette, Tim Rockt\\\"aschel", "title": "Prioritized Level Replay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Environments with procedurally generated content serve as important\nbenchmarks for testing systematic generalization in deep reinforcement\nlearning. In this setting, each level is an algorithmically created environment\ninstance with a unique configuration of its factors of variation. Training on a\nprespecified subset of levels allows for testing generalization to unseen\nlevels. What can be learned from a level depends on the current policy, yet\nprior work defaults to uniform sampling of training levels independently of the\npolicy. We introduce Prioritized Level Replay (PLR), a general framework for\nselectively sampling the next training level by prioritizing those with higher\nestimated learning potential when revisited in the future. We show TD-errors\neffectively estimate a level's future learning potential and, when used to\nguide the sampling procedure, induce an emergent curriculum of increasingly\ndifficult levels. By adapting the sampling of training levels, PLR\nsignificantly improves sample efficiency and generalization on Procgen\nBenchmark--matching the previous state-of-the-art in test return--and readily\ncombines with other methods. Combined with the previous leading method, PLR\nraises the state-of-the-art to over 76% improvement in test return relative to\nstandard RL baselines.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 12:46:57 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 18:40:45 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2021 19:45:12 GMT"}, {"version": "v4", "created": "Sat, 12 Jun 2021 10:50:10 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Jiang", "Minqi", ""], ["Grefenstette", "Edward", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "2010.03950", "submitter": "Rodrigo Toro Icarte", "authors": "Rodrigo Toro Icarte, Toryn Q. Klassen, Richard Valenzano, Sheila A.\n  McIlraith", "title": "Reward Machines: Exploiting Reward Function Structure in Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) methods usually treat reward functions as black\nboxes. As such, these methods must extensively interact with the environment in\norder to discover rewards and optimal policies. In most RL applications,\nhowever, users have to program the reward function and, hence, there is the\nopportunity to treat reward functions as white boxes instead -- to show the\nreward function's code to the RL agent so it can exploit its internal\nstructures to learn optimal policies faster. In this paper, we show how to\naccomplish this idea in two steps. First, we propose reward machines (RMs), a\ntype of finite state machine that supports the specification of reward\nfunctions while exposing reward function structure. We then describe different\nmethodologies to exploit such structures, including automated reward shaping,\ntask decomposition, and counterfactual reasoning for data augmentation.\nExperiments on tabular and continuous domains show the benefits of exploiting\nreward structure across different tasks and RL agents.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 00:10:16 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Icarte", "Rodrigo Toro", ""], ["Klassen", "Toryn Q.", ""], ["Valenzano", "Richard", ""], ["McIlraith", "Sheila A.", ""]]}, {"id": "2010.03962", "submitter": "Christopher Leung G", "authors": "Seung Gyu Hyun and Christopher Leung", "title": "Test-Cost Sensitive Methods for Identifying Nearby Points", "comments": "8 pages, 5 Figure, Submitted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world applications that involve missing values are often constrained by\nthe cost to obtain data. Test-cost sensitive, or costly feature, methods\nadditionally consider the cost of acquiring features. Such methods have been\nextensively studied in the problem of classification. In this paper, we study a\nrelated problem of test-cost sensitive methods to identify nearby points from a\nlarge set, given a new point with some unknown feature values. We present two\nmodels, one based on a tree and another based on Deep Reinforcement Learning.\nIn our simulations, we show that the models outperform random agents on a set\nof five real-world data sets.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 23:12:28 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Hyun", "Seung Gyu", ""], ["Leung", "Christopher", ""]]}, {"id": "2010.03986", "submitter": "James Hickey", "authors": "Gareth P. Jones, James M. Hickey, Pietro G. Di Stefano, Charanpal\n  Dhanjal, Laura C. Stoddart and Vlasios Vasileiou", "title": "Metrics and methods for a systematic comparison of fairness-aware\n  machine learning algorithms", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and removing bias from the decisions made by machine learning\nmodels is essential to avoid discrimination against unprivileged groups.\nDespite recent progress in algorithmic fairness, there is still no clear answer\nas to which bias-mitigation approaches are most effective. Evaluation\nstrategies are typically use-case specific, rely on data with unclear bias, and\nemploy a fixed policy to convert model outputs to decision outcomes. To address\nthese problems, we performed a systematic comparison of a number of popular\nfairness algorithms applicable to supervised classification. Our study is the\nmost comprehensive of its kind. It utilizes three real and four synthetic\ndatasets, and two different ways of converting model outputs to decisions. It\nconsiders fairness, predictive-performance, calibration quality, and speed of\n28 different modelling pipelines, corresponding to both fairness-unaware and\nfairness-aware algorithms. We found that fairness-unaware algorithms typically\nfail to produce adequately fair models and that the simplest algorithms are not\nnecessarily the fairest ones. We also found that fairness-aware algorithms can\ninduce fairness without material drops in predictive power. Finally, we found\nthat dataset idiosyncracies (e.g., degree of intrinsic unfairness, nature of\ncorrelations) do affect the performance of fairness-aware approaches. Our\nresults allow the practitioner to narrow down the approach(es) they would like\nto adopt without having to know in advance their fairness requirements.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 13:58:09 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Jones", "Gareth P.", ""], ["Hickey", "James M.", ""], ["Di Stefano", "Pietro G.", ""], ["Dhanjal", "Charanpal", ""], ["Stoddart", "Laura C.", ""], ["Vasileiou", "Vlasios", ""]]}, {"id": "2010.03990", "submitter": "Aman Kamboj", "authors": "Aman Kamboj, Rajneesh Rani, Aditya Nigam, Ranjeet Ranjan Jha", "title": "UESegNet: Context Aware Unconstrained ROI Segmentation Networks for Ear\n  Biometric", "comments": null, "journal-ref": null, "doi": "10.1007/s10044-020-00914-4", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biometric-based personal authentication systems have seen a strong demand\nmainly due to the increasing concern in various privacy and security\napplications. Although the use of each biometric trait is problem dependent,\nthe human ear has been found to have enough discriminating characteristics to\nallow its use as a strong biometric measure. To locate an ear in a 2D side face\nimage is a challenging task, numerous existing approaches have achieved\nsignificant performance, but the majority of studies are based on the\nconstrained environment. However, ear biometrics possess a great level of\ndifficulties in the unconstrained environment, where pose, scale, occlusion,\nilluminations, background clutter etc. varies to a great extent. To address the\nproblem of ear localization in the wild, we have proposed two high-performance\nregion of interest (ROI) segmentation models UESegNet-1 and UESegNet-2, which\nare fundamentally based on deep convolutional neural networks and primarily\nuses contextual information to localize ear in the unconstrained environment.\nAdditionally, we have applied state-of-the-art deep learning models viz; FRCNN\n(Faster Region Proposal Network) and SSD (Single Shot MultiBox Detecor) for ear\nlocalization task. To test the model's generalization, they are evaluated on\nsix different benchmark datasets viz; IITD, IITK, USTB-DB3, UND-E, UND-J2 and\nUBEAR, all of which contain challenging images. The performance of the models\nis compared on the basis of object detection performance measure parameters\nsuch as IOU (Intersection Over Union), Accuracy, Precision, Recall, and\nF1-Score. It has been observed that the proposed models UESegNet-1 and\nUESegNet-2 outperformed the FRCNN and SSD at higher values of IOUs i.e. an\naccuracy of 100\\% is achieved at IOU 0.5 on majority of the databases.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 14:05:15 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Kamboj", "Aman", ""], ["Rani", "Rajneesh", ""], ["Nigam", "Aditya", ""], ["Jha", "Ranjeet Ranjan", ""]]}, {"id": "2010.04003", "submitter": "Thang Doan", "authors": "Thang Doan, Mehdi Bennani, Bogdan Mazoure, Guillaume Rabusseau, Pierre\n  Alquier", "title": "A Theoretical Analysis of Catastrophic Forgetting through the NTK\n  Overlap Matrix", "comments": "Accepted to AISTATS 2021. Keywords: continual learning, catastrophic\n  forgetting, NTK regime, orthgonal gradient descent", "journal-ref": "Proceedings of the 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS 2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning (CL) is a setting in which an agent has to learn from an\nincoming stream of data during its entire lifetime. Although major advances\nhave been made in the field, one recurring problem which remains unsolved is\nthat of Catastrophic Forgetting (CF). While the issue has been extensively\nstudied empirically, little attention has been paid from a theoretical angle.\nIn this paper, we show that the impact of CF increases as two tasks\nincreasingly align. We introduce a measure of task similarity called the NTK\noverlap matrix which is at the core of CF. We analyze common projected gradient\nalgorithms and demonstrate how they mitigate forgetting. Then, we propose a\nvariant of Orthogonal Gradient Descent (OGD) which leverages structure of the\ndata through Principal Component Analysis (PCA). Experiments support our\ntheoretical findings and show how our method can help reduce CF on classical CL\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 17:35:31 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 15:31:16 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Doan", "Thang", ""], ["Bennani", "Mehdi", ""], ["Mazoure", "Bogdan", ""], ["Rabusseau", "Guillaume", ""], ["Alquier", "Pierre", ""]]}, {"id": "2010.04007", "submitter": "Jon Haitz Legarreta", "authors": "Jon Haitz Legarreta, Laurent Petit, Fran\\c{c}ois Rheault, Guillaume\n  Theaud, Carl Lemaire, Maxime Descoteaux and Pierre-Marc Jodoin", "title": "Tractography filtering using autoencoders", "comments": "Preprint. Paper under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG q-bio.NC q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Current brain white matter fiber tracking techniques show a number of\nproblems, including: generating large proportions of streamlines that do not\naccurately describe the underlying anatomy; extracting streamlines that are not\nsupported by the underlying diffusion signal; and under-representing some fiber\npopulations, among others. In this paper, we describe a novel unsupervised\nlearning method to filter streamlines from diffusion MRI tractography, and\nhence, to obtain more reliable tractograms.\n  We show that a convolutional neural network autoencoder provides a\nstraightforward and elegant way to learn a robust representation of brain\nstreamlines, which can be used to filter undesired samples with a nearest\nneighbor algorithm. Our method, dubbed FINTA (Filtering in Tractography using\nAutoencoders) comes with several key advantages: training does not need labeled\ndata, as it uses raw tractograms, it is fast and easily reproducible, it does\nnot rely on the input diffusion MRI data, and thus, does not suffer from domain\nadaptation issues. We demonstrate the ability of FINTA to discriminate between\n\"plausible\" and \"implausible\" streamlines as well as to recover individual\nstreamline group instances from a raw tractogram, from both synthetic and real\nhuman brain diffusion MRI tractography data, including partial tractograms.\nResults reveal that FINTA has a superior filtering performance compared to\nstate-of-the-art methods.\n  Together, this work brings forward a new deep learning framework in\ntractography based on autoencoders, and shows how it can be applied for\nfiltering purposes. It sets the foundations for opening up new prospects\ntowards more accurate and robust tractometry and connectivity diffusion MRI\nanalyses, which may ultimately lead to improve the imaging of the white matter\nanatomy.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 16:45:55 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Legarreta", "Jon Haitz", ""], ["Petit", "Laurent", ""], ["Rheault", "Fran\u00e7ois", ""], ["Theaud", "Guillaume", ""], ["Lemaire", "Carl", ""], ["Descoteaux", "Maxime", ""], ["Jodoin", "Pierre-Marc", ""]]}, {"id": "2010.04010", "submitter": "Mack Sweeney", "authors": "Mack Sweeney, Matthew van Adelsberg, Kathryn Laskey, Carlotta\n  Domeniconi", "title": "Effects of Model Misspecification on Bayesian Bandits: Case Studies in\n  UX Optimization", "comments": "10 pages, 4 figures, accepted at ICDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian bandits using Thompson Sampling have seen increasing success in\nrecent years. Yet existing value models (of rewards) are misspecified on many\nreal-world problem. We demonstrate this on the User Experience Optimization\n(UXO) problem, providing a novel formulation as a restless, sleeping bandit\nwith unobserved confounders plus optional stopping. Our case studies show how\ncommon misspecifications can lead to sub-optimal rewards, and we provide model\nextensions to address these, along with a scientific model building process\npractitioners can adopt or adapt to solve their own unique problems. To our\nknowledge, this is the first study showing the effects of overdispersion on\nbandit explore/exploit efficacy, tying the common notions of under- and\nover-confidence to over- and under-exploration, respectively. We also present\nthe first model to exploit cointegration in a restless bandit, demonstrating\nthat finite regret and fast and consistent optional stopping are possible by\nmoving beyond simpler windowing, discounting, and drift models.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 14:34:28 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Sweeney", "Mack", ""], ["van Adelsberg", "Matthew", ""], ["Laskey", "Kathryn", ""], ["Domeniconi", "Carlotta", ""]]}, {"id": "2010.04012", "submitter": "Siyuan Li", "authors": "Siyuan Li, Haitao Lin, Zelin Zang, Lirong Wu, Jun Xia, Stan Z. Li", "title": "Invertible Manifold Learning for Dimension Reduction", "comments": "ECML-PKDD 2021 camera-ready. 15 pages (main) with 10 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dimension reduction (DR) aims to learn low-dimensional representations of\nhigh-dimensional data with the preservation of essential information. In the\ncontext of manifold learning, we define that the representation after\ninformation-lossless DR preserves the topological and geometric properties of\ndata manifolds formally, and propose a novel two-stage DR method, called\ninvertible manifold learning (inv-ML) to bridge the gap between theoretical\ninformation-lossless and practical DR. The first stage includes a homeomorphic\nsparse coordinate transformation to learn low-dimensional representations\nwithout destroying topology and a local isometry constraint to preserve local\ngeometry. In the second stage, a linear compression is implemented for the\ntrade-off between the target dimension and the incurred information loss in\nexcessive DR scenarios. Experiments are conducted on seven datasets with a\nneural network implementation of inv-ML, called i-ML-Enc. Empirically, i-ML-Enc\nachieves invertible DR in comparison with typical existing methods as well as\nreveals the characteristics of the learned manifolds. Through latent space\ninterpolation on real-world datasets, we find that the reliability of tangent\nspace approximated by the local neighborhood is the key to the success of\nmanifold-based DR algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 14:22:51 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 15:32:57 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Li", "Siyuan", ""], ["Lin", "Haitao", ""], ["Zang", "Zelin", ""], ["Wu", "Lirong", ""], ["Xia", "Jun", ""], ["Li", "Stan Z.", ""]]}, {"id": "2010.04029", "submitter": "Meng Qu", "authors": "Meng Qu, Junkun Chen, Louis-Pascal Xhonneux, Yoshua Bengio, Jian Tang", "title": "RNNLogic: Learning Logic Rules for Reasoning on Knowledge Graphs", "comments": "iclr 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies learning logic rules for reasoning on knowledge graphs.\nLogic rules provide interpretable explanations when used for prediction as well\nas being able to generalize to other tasks, and hence are critical to learn.\nExisting methods either suffer from the problem of searching in a large search\nspace (e.g., neural logic programming) or ineffective optimization due to\nsparse rewards (e.g., techniques based on reinforcement learning). To address\nthese limitations, this paper proposes a probabilistic model called RNNLogic.\nRNNLogic treats logic rules as a latent variable, and simultaneously trains a\nrule generator as well as a reasoning predictor with logic rules. We develop an\nEM-based algorithm for optimization. In each iteration, the reasoning predictor\nis first updated to explore some generated logic rules for reasoning. Then in\nthe E-step, we select a set of high-quality rules from all generated rules with\nboth the rule generator and reasoning predictor via posterior inference; and in\nthe M-step, the rule generator is updated with the rules selected in the\nE-step. Experiments on four datasets prove the effectiveness of RNNLogic.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 14:47:02 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 02:52:53 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Qu", "Meng", ""], ["Chen", "Junkun", ""], ["Xhonneux", "Louis-Pascal", ""], ["Bengio", "Yoshua", ""], ["Tang", "Jian", ""]]}, {"id": "2010.04050", "submitter": "Amir-Hossein Karimi", "authors": "Amir-Hossein Karimi, Gilles Barthe, Bernhard Sch\\\"olkopf, Isabel\n  Valera", "title": "A survey of algorithmic recourse: definitions, formulations, solutions,\n  and prospects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is increasingly used to inform decision-making in sensitive\nsituations where decisions have consequential effects on individuals' lives. In\nthese settings, in addition to requiring models to be accurate and robust,\nsocially relevant values such as fairness, privacy, accountability, and\nexplainability play an important role for the adoption and impact of said\ntechnologies. In this work, we focus on algorithmic recourse, which is\nconcerned with providing explanations and recommendations to individuals who\nare unfavourably treated by automated decision-making systems. We first perform\nan extensive literature review, and align the efforts of many authors by\npresenting unified definitions, formulations, and solutions to recourse. Then,\nwe provide an overview of the prospective research directions towards which the\ncommunity may engage, challenging existing assumptions and making explicit\nconnections to other ethical challenges such as security, privacy, and\nfairness.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 15:15:34 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 18:44:36 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Karimi", "Amir-Hossein", ""], ["Barthe", "Gilles", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Valera", "Isabel", ""]]}, {"id": "2010.04055", "submitter": "Quanshi Zhang", "authors": "Xin Wang, Jie Ren, Shuyun Lin, Xiangming Zhu, Yisen Wang, Quanshi\n  Zhang", "title": "A Unified Approach to Interpreting and Boosting Adversarial\n  Transferability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use the interaction inside adversarial perturbations to\nexplain and boost the adversarial transferability. We discover and prove the\nnegative correlation between the adversarial transferability and the\ninteraction inside adversarial perturbations. The negative correlation is\nfurther verified through different DNNs with various inputs. Moreover, this\nnegative correlation can be regarded as a unified perspective to understand\ncurrent transferability-boosting methods. To this end, we prove that some\nclassic methods of enhancing the transferability essentially decease\ninteractions inside adversarial perturbations. Based on this, we propose to\ndirectly penalize interactions during the attacking process, which\nsignificantly improves the adversarial transferability.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 15:19:22 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Wang", "Xin", ""], ["Ren", "Jie", ""], ["Lin", "Shuyun", ""], ["Zhu", "Xiangming", ""], ["Wang", "Yisen", ""], ["Zhang", "Quanshi", ""]]}, {"id": "2010.04062", "submitter": "Jiancheng Yang", "authors": "Jiancheng Yang, Jiajun Chen, Kaiming Kuang, Tiancheng Lin, Junjun He,\n  Bingbing Ni", "title": "MIA-Prognosis: A Deep Learning Framework to Predict Therapy Response", "comments": "MICCAI 2020 (Early Accepted; Student Travel Award)", "journal-ref": null, "doi": "10.1007/978-3-030-59713-9_21", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predicting clinical outcome is remarkably important but challenging. Research\nefforts have been paid on seeking significant biomarkers associated with the\ntherapy response or/and patient survival. However, these biomarkers are\ngenerally costly and invasive, and possibly dissatifactory for novel therapy.\nOn the other hand, multi-modal, heterogeneous, unaligned temporal data is\ncontinuously generated in clinical practice. This paper aims at a unified deep\nlearning approach to predict patient prognosis and therapy response, with\neasily accessible data, e.g., radiographics, laboratory and clinical\ninformation. Prior arts focus on modeling single data modality, or ignore the\ntemporal changes. Importantly, the clinical time series is asynchronous in\npractice, i.e., recorded with irregular intervals. In this study, we formalize\nthe prognosis modeling as a multi-modal asynchronous time series classification\ntask, and propose a MIA-Prognosis framework with Measurement, Intervention and\nAssessment (MIA) information to predict therapy response, where a Simple\nTemporal Attention (SimTA) module is developed to process the asynchronous time\nseries. Experiments on synthetic dataset validate the superiory of SimTA over\nstandard RNN-based approaches. Furthermore, we experiment the proposed method\non an in-house, retrospective dataset of real-world non-small cell lung cancer\npatients under anti-PD-1 immunotherapy. The proposed method achieves promising\nperformance on predicting the immunotherapy response. Notably, our predictive\nmodel could further stratify low-risk and high-risk patients in terms of\nlong-term survival.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 15:30:17 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Yang", "Jiancheng", ""], ["Chen", "Jiajun", ""], ["Kuang", "Kaiming", ""], ["Lin", "Tiancheng", ""], ["He", "Junjun", ""], ["Ni", "Bingbing", ""]]}, {"id": "2010.04098", "submitter": "Varun Gangal", "authors": "Varun Gangal, Eduard Hovy", "title": "BERTering RAMS: What and How Much does BERT Already Know About Event\n  Arguments? -- A Study on the RAMS Dataset", "comments": "Accepted for the BlackBoxNLP 2020 Workshop @EMNLP 2020;\n  Pre-camera-ready copy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the attention map based probing frame-work from (Clark et al., 2019),\nwe observe that, on the RAMS dataset (Ebner et al., 2020), BERT's attention\nheads have modest but well above-chance ability to spot event arguments sans\nany training or domain finetuning, vary-ing from a low of 17.77% for Place to a\nhigh of 51.61% for Artifact. Next, we find that linear combinations of these\nheads, estimated with approx 11% of available total event argument detection\nsupervision, can push performance well-higher for some roles - highest two\nbeing Victim (68.29% Accuracy) and Artifact(58.82% Accuracy). Furthermore, we\ninvestigate how well our methods do for cross-sentence event arguments. We\npropose a procedure to isolate \"best heads\" for cross-sentence argument\ndetection separately of those for intra-sentence arguments. The heads thus\nestimated have superior cross-sentence performance compared to their jointly\nestimated equivalents, albeit only under the unrealistic assumption that we\nalready know the argument is present in an-other sentence. Lastly, we seek to\nisolate to what extent our numbers stem from lexical frequency based\nassociations between gold arguments and roles. We propose NONCE, a scheme to\ncreate adversarial test examples by replacing gold arguments with randomly\ngenerated \"nonce\" words. We find that learnt linear combinations are robust to\nNONCE, though individual best heads can be more sensitive.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 16:27:03 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 19:02:14 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Gangal", "Varun", ""], ["Hovy", "Eduard", ""]]}, {"id": "2010.04112", "submitter": "Abdulmajid Murad", "authors": "Abdulmajid Murad, Frank Alexander Kraemer, Kerstin Bach, Gavin Taylor", "title": "Information-Driven Adaptive Sensing Based on Deep Reinforcement Learning", "comments": "8 pages, 8 figures", "journal-ref": "10th International Conference on the Internet of Things (IoT20),\n  October 6-9, 2020, Malmo, Sweden", "doi": "10.1145/3410992.3411001", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to make better use of deep reinforcement learning in the creation of\nsensing policies for resource-constrained IoT devices, we present and study a\nnovel reward function based on the Fisher information value. This reward\nfunction enables IoT sensor devices to learn to spend available energy on\nmeasurements at otherwise unpredictable moments, while conserving energy at\ntimes when measurements would provide little new information. This is a highly\ngeneral approach, which allows for a wide range of use cases without\nsignificant human design effort or hyper-parameter tuning. We illustrate the\napproach in a scenario of workplace noise monitoring, where results show that\nthe learned behavior outperforms a uniform sampling strategy and comes close to\na near-optimal oracle solution.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 16:52:05 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Murad", "Abdulmajid", ""], ["Kraemer", "Frank Alexander", ""], ["Bach", "Kerstin", ""], ["Taylor", "Gavin", ""]]}, {"id": "2010.04116", "submitter": "Aidan N. Gomez", "authors": "Aidan N. Gomez, Oscar Key, Stephen Gou, Nick Frosst, Jeff Dean, Yarin\n  Gal", "title": "Interlocking Backpropagation: Improving depthwise model-parallelism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of parameters in state of the art neural networks has drastically\nincreased in recent years. This surge of interest in large scale neural\nnetworks has motivated the development of new distributed training strategies\nenabling such models. One such strategy is model-parallel distributed training.\nUnfortunately, model-parallelism suffers from poor resource utilisation, which\nleads to wasted resources. In this work, we improve upon recent developments in\nan idealised model-parallel optimisation setting: local learning. Motivated by\npoor resource utilisation, we introduce a class of intermediary strategies\nbetween local and global learning referred to as interlocking backpropagation.\nThese strategies preserve many of the compute-efficiency advantages of local\noptimisation, while recovering much of the task performance achieved by global\noptimisation. We assess our strategies on both image classification ResNets and\nTransformer language models, finding that our strategy consistently\nout-performs local learning in terms of task performance, and out-performs\nglobal learning in training efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 16:53:50 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Gomez", "Aidan N.", ""], ["Key", "Oscar", ""], ["Gou", "Stephen", ""], ["Frosst", "Nick", ""], ["Dean", "Jeff", ""], ["Gal", "Yarin", ""]]}, {"id": "2010.04119", "submitter": "Peter Hase", "authors": "Peter Hase, Shiyue Zhang, Harry Xie, Mohit Bansal", "title": "Leakage-Adjusted Simulatability: Can Models Generate Non-Trivial\n  Explanations of Their Behavior in Natural Language?", "comments": "EMNLP 2020 Findings (17 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data collection for natural language (NL) understanding tasks has\nincreasingly included human explanations alongside data points, allowing past\nworks to introduce models that both perform a task and generate NL explanations\nfor their outputs. Yet to date, model-generated explanations have been\nevaluated on the basis of surface-level similarities to human explanations,\nboth through automatic metrics like BLEU and human evaluations. We argue that\nthese evaluations are insufficient, since they fail to indicate whether\nexplanations support actual model behavior (faithfulness), rather than simply\nmatch what a human would say (plausibility). In this work, we address the\nproblem of evaluating explanations from the model simulatability perspective.\nOur contributions are as follows: (1) We introduce a leakage-adjusted\nsimulatability (LAS) metric for evaluating NL explanations, which measures how\nwell explanations help an observer predict a model's output, while controlling\nfor how explanations can directly leak the output. We use a model as a proxy\nfor a human observer, and validate this choice with two human subject\nexperiments. (2) Using the CoS-E and e-SNLI datasets, we evaluate two existing\ngenerative graphical models and two new approaches; one rationalizing method we\nintroduce achieves roughly human-level LAS scores. (3) Lastly, we frame\nexplanation generation as a multi-agent game and optimize explanations for\nsimulatability while penalizing label leakage, which can improve LAS scores. We\nprovide code for the experiments in this paper at\nhttps://github.com/peterbhase/LAS-NL-Explanations\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 16:59:07 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Hase", "Peter", ""], ["Zhang", "Shiyue", ""], ["Xie", "Harry", ""], ["Bansal", "Mohit", ""]]}, {"id": "2010.04124", "submitter": "Mehak Maniktala", "authors": "Mehak Maniktala, Christa Cody, Amy Isvik, Nicholas Lytle, Min Chi,\n  Tiffany Barnes", "title": "Extending the Hint Factory for the assistance dilemma: A novel,\n  data-driven HelpNeed Predictor for proactive problem-solving help", "comments": null, "journal-ref": "Journal of Educational Data Mining 12 (4), 24-65, 2020", "doi": "10.5281/zenodo.4399683", "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining when and whether to provide personalized support is a well-known\nchallenge called the assistance dilemma. A core problem in solving the\nassistance dilemma is the need to discover when students are unproductive so\nthat the tutor can intervene. Such a task is particularly challenging for\nopen-ended domains, even those that are well-structured with defined principles\nand goals. In this paper, we present a set of data-driven methods to classify,\npredict, and prevent unproductive problem-solving steps in the well-structured\nopen-ended domain of logic. This approach leverages and extends the Hint\nFactory, a set of methods that leverages prior student solution attempts to\nbuild data-driven intelligent tutors. We present a HelpNeed classification,\nthat uses prior student data to determine when students are likely to be\nunproductive and need help learning optimal problem-solving strategies. We\npresent a controlled study to determine the impact of an Adaptive pedagogical\npolicy that provides proactive hints at the start of each step based on the\noutcomes of our HelpNeed predictor: productive vs. unproductive. Our results\nshow that the students in the Adaptive condition exhibited better training\nbehaviors, with lower help avoidance, and higher help appropriateness (a higher\nchance of receiving help when it was likely to be needed), as measured using\nthe HelpNeed classifier, when compared to the Control. Furthermore, the results\nshow that the students who received Adaptive hints based on HelpNeed\npredictions during training significantly outperform their Control peers on the\nposttest, with the former producing shorter, more optimal solutions in less\ntime. We conclude with suggestions on how these HelpNeed methods could be\napplied in other well-structured open-ended domains.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 17:04:03 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Maniktala", "Mehak", ""], ["Cody", "Christa", ""], ["Isvik", "Amy", ""], ["Lytle", "Nicholas", ""], ["Chi", "Min", ""], ["Barnes", "Tiffany", ""]]}, {"id": "2010.04230", "submitter": "Will Grathwohl", "authors": "Will Grathwohl, Jacob Kelly, Milad Hashemi, Mohammad Norouzi, Kevin\n  Swersky, David Duvenaud", "title": "No MCMC for me: Amortized sampling for fast and stable training of\n  energy-based models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy-Based Models (EBMs) present a flexible and appealing way to represent\nuncertainty. Despite recent advances, training EBMs on high-dimensional data\nremains a challenging problem as the state-of-the-art approaches are costly,\nunstable, and require considerable tuning and domain expertise to apply\nsuccessfully. In this work, we present a simple method for training EBMs at\nscale which uses an entropy-regularized generator to amortize the MCMC sampling\ntypically used in EBM training. We improve upon prior MCMC-based entropy\nregularization methods with a fast variational approximation. We demonstrate\nthe effectiveness of our approach by using it to train tractable likelihood\nmodels. Next, we apply our estimator to the recently proposed Joint Energy\nModel (JEM), where we match the original performance with faster and stable\ntraining. This allows us to extend JEM models to semi-supervised classification\non tabular data from a variety of continuous domains.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 19:17:20 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 14:03:50 GMT"}, {"version": "v3", "created": "Sun, 6 Jun 2021 20:40:14 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Grathwohl", "Will", ""], ["Kelly", "Jacob", ""], ["Hashemi", "Milad", ""], ["Norouzi", "Mohammad", ""], ["Swersky", "Kevin", ""], ["Duvenaud", "David", ""]]}, {"id": "2010.04245", "submitter": "Prudhvi Raj Dachapally", "authors": "Alex Henry, Prudhvi Raj Dachapally, Shubham Pawar, Yuxuan Chen", "title": "Query-Key Normalization for Transformers", "comments": "8 pages, 2 figures, accepted at Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-resource language translation is a challenging but socially valuable NLP\ntask. Building on recent work adapting the Transformer's normalization to this\nsetting, we propose QKNorm, a normalization technique that modifies the\nattention mechanism to make the softmax function less prone to arbitrary\nsaturation without sacrificing expressivity. Specifically, we apply $\\ell_2$\nnormalization along the head dimension of each query and key matrix prior to\nmultiplying them and then scale up by a learnable parameter instead of dividing\nby the square root of the embedding dimension. We show improvements averaging\n0.928 BLEU over state-of-the-art bilingual benchmarks for 5 low-resource\ntranslation pairs from the TED Talks corpus and IWSLT'15.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 20:12:35 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Henry", "Alex", ""], ["Dachapally", "Prudhvi Raj", ""], ["Pawar", "Shubham", ""], ["Chen", "Yuxuan", ""]]}, {"id": "2010.04259", "submitter": "Leonardo Cotta", "authors": "Leonardo Cotta, Carlos H. C. Teixeira, Ananthram Swami, Bruno Ribeiro", "title": "Unsupervised Joint $k$-node Graph Representations with Compositional\n  Energy-Based Models", "comments": "accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Graph Neural Network (GNN) methods that learn inductive unsupervised\ngraph representations focus on learning node and edge representations by\npredicting observed edges in the graph. Although such approaches have shown\nadvances in downstream node classification tasks, they are ineffective in\njointly representing larger $k$-node sets, $k{>}2$. We propose MHM-GNN, an\ninductive unsupervised graph representation approach that combines joint\n$k$-node representations with energy-based models (hypergraph Markov networks)\nand GNNs. To address the intractability of the loss that arises from this\ncombination, we endow our optimization with a loss upper bound using a\nfinite-sample unbiased Markov Chain Monte Carlo estimator. Our experiments show\nthat the unsupervised MHM-GNN representations of MHM-GNN produce better\nunsupervised representations than existing approaches from the literature.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 21:13:37 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Cotta", "Leonardo", ""], ["Teixeira", "Carlos H. C.", ""], ["Swami", "Ananthram", ""], ["Ribeiro", "Bruno", ""]]}, {"id": "2010.04279", "submitter": "Christina Ji", "authors": "Christina X. Ji, Michael Oberst, Sanjat Kanjilal, David Sontag", "title": "Trajectory Inspection: A Method for Iterative Clinician-Driven Design of\n  Reinforcement Learning Studies", "comments": "To appear in AMIA 2021 virtual informatics summit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has the potential to significantly improve\nclinical decision making. However, treatment policies learned via RL from\nobservational data are sensitive to subtle choices in study design. We\nhighlight a simple approach, trajectory inspection, to bring clinicians into an\niterative design process for model-based RL studies. We identify where the\nmodel recommends unexpectedly aggressive treatments or expects surprisingly\npositive outcomes from its recommendations. Then, we examine clinical\ntrajectories simulated with the learned model and policy alongside the actual\nhospital course. Applying this approach to recent work on RL for sepsis\nmanagement, we uncover a model bias towards discharge, a preference for high\nvasopressor doses that may be linked to small sample sizes, and clinically\nimplausible expectations of discharge without weaning off vasopressors. We hope\nthat iterations of detecting and addressing the issues unearthed by our method\nwill result in RL policies that inspire more confidence in deployment.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 22:03:01 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 19:28:25 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Ji", "Christina X.", ""], ["Oberst", "Michael", ""], ["Kanjilal", "Sanjat", ""], ["Sontag", "David", ""]]}, {"id": "2010.04282", "submitter": "Patrick Rodler", "authors": "Patrick Rodler", "title": "Memory-Limited Model-Based Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various model-based diagnosis scenarios require the computation of most\npreferred fault explanations. Existing algorithms that are sound (i.e., output\nonly actual fault explanations) and complete (i.e., can return all\nexplanations), however, require exponential space to achieve this task. As a\nremedy, we propose two novel diagnostic search algorithms, called RBF-HS\n(Recursive Best-First Hitting Set Search) and HBF-HS (Hybrid Best-First Hitting\nSet Search), which build upon tried and tested techniques from the heuristic\nsearch domain. RBF-HS can enumerate an arbitrary predefined finite number of\nfault explanations in best-first order within linear space bounds, without\nsacrificing the desirable soundness or completeness properties. The idea of\nHBF-HS is to find a trade-off between runtime optimization and a restricted\nspace consumption that does not exceed the available memory.\n  In extensive experiments on real-world diagnosis cases we compared our\napproaches to Reiter's HS-Tree, a state-of-the-art method that gives the same\ntheoretical guarantees and is as general(ly applicable) as the suggested\nalgorithms. For the computation of minimum-cardinality fault explanations, we\nfind that (1) RBF-HS reduces memory requirements substantially in most cases by\nup to several orders of magnitude, (2) in more than a third of the cases, both\nmemory savings and runtime savings are achieved, and (3) given the runtime\noverhead is significant, using HBF-HS instead of RBF-HS reduces the runtime to\nvalues comparable with HS-Tree while keeping the used memory reasonably\nbounded. When computing most probable fault explanations, we observe that\nRBF-HS tends to trade memory savings more or less one-to-one for runtime\noverheads. Again, HBF-HS proves to be a reasonable remedy to cut down the\nruntime while complying with practicable memory bounds.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 22:09:39 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Rodler", "Patrick", ""]]}, {"id": "2010.04295", "submitter": "Yang Li", "authors": "Yang Li, Gang Li, Luheng He, Jingjie Zheng, Hong Li, Zhiwei Guan", "title": "Widget Captioning: Generating Natural Language Description for Mobile\n  User Interface Elements", "comments": "16 pages, EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language descriptions of user interface (UI) elements such as\nalternative text are crucial for accessibility and language-based interaction\nin general. Yet, these descriptions are constantly missing in mobile UIs. We\npropose widget captioning, a novel task for automatically generating language\ndescriptions for UI elements from multimodal input including both the image and\nthe structural representations of user interfaces. We collected a large-scale\ndataset for widget captioning with crowdsourcing. Our dataset contains 162,859\nlanguage phrases created by human workers for annotating 61,285 UI elements\nacross 21,750 unique UI screens. We thoroughly analyze the dataset, and train\nand evaluate a set of deep model configurations to investigate how each feature\nmodality as well as the choice of learning strategies impact the quality of\npredicted captions. The task formulation and the dataset as well as our\nbenchmark models contribute a solid basis for this novel multimodal captioning\ntask that connects language and user interfaces.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 22:56:03 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Li", "Yang", ""], ["Li", "Gang", ""], ["He", "Luheng", ""], ["Zheng", "Jingjie", ""], ["Li", "Hong", ""], ["Guan", "Zhiwei", ""]]}, {"id": "2010.04326", "submitter": "Richmond Addo Danquah", "authors": "Richmond Addo Danquah", "title": "Handling Imbalanced Data: A Case Study for Binary Class Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For several years till date, the major issues in terms of solving for\nclassification problems are the issues of Imbalanced data. Because majority of\nthe machine learning algorithms by default assumes all data are balanced, the\nalgorithms do not take into consideration the distribution of the data sample\nclass. The results tend to be unsatisfactory and skewed towards the majority\nsample class distribution. This implies that the consequences as a result of\nusing a model built using an Imbalanced data without handling for the Imbalance\nin the data could be misleading both in practice and theory. Most researchers\nhave focused on the application of Synthetic Minority Oversampling Technique\n(SMOTE) and Adaptive Synthetic (ADASYN) Sampling Approach in handling data\nImbalance independently in their works and have failed to better explain the\nalgorithms behind these techniques with computed examples. This paper focuses\non both synthetic oversampling techniques and manually computes synthetic data\npoints to enhance easy comprehension of the algorithms. We analyze the\napplication of these synthetic oversampling techniques on binary classification\nproblems with different Imbalanced ratios and sample sizes.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 02:04:14 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Danquah", "Richmond Addo", ""]]}, {"id": "2010.04327", "submitter": "Keyu Zhu", "authors": "Keyu Zhu, Pascal Van Hentenryck, Ferdinando Fioretto", "title": "Bias and Variance of Post-processing in Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-processing immunity is a fundamental property of differential privacy:\nit enables the application of arbitrary data-independent transformations to the\nresults of differentially private outputs without affecting their privacy\nguarantees. When query outputs must satisfy domain constraints, post-processing\ncan be used to project the privacy-preserving outputs onto the feasible region.\nMoreover, when the feasible region is convex, a widely adopted class of\npost-processing steps is also guaranteed to improve accuracy. Post-processing\nhas been applied successfully in many applications including census\ndata-release, energy systems, and mobility. However, its effects on the noise\ndistribution is poorly understood: It is often argued that post-processing may\nintroduce bias and increase variance. This paper takes a first step towards\nunderstanding the properties of post-processing. It considers the release of\ncensus data and examines, both theoretically and empirically, the behavior of a\nwidely adopted class of post-processing functions.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 02:12:54 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Zhu", "Keyu", ""], ["Van Hentenryck", "Pascal", ""], ["Fioretto", "Ferdinando", ""]]}, {"id": "2010.04328", "submitter": "Aishwarya Sarkar", "authors": "Aishwarya Sarkar, Jien Zhang, Chaoqun Lu, Ali Jannesari", "title": "HydroDeep -- A Knowledge Guided Deep Neural Network for\n  Geo-Spatiotemporal Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to limited evidence and complex causes of regional climate change, the\nconfidence in predicting fluvial floods remains low. Understanding the\nfundamental mechanisms intrinsic to geo-spatiotemporal information is crucial\nto improve the prediction accuracy. This paper demonstrates a hybrid neural\nnetwork architecture - HydroDeep, that couples a process-based hydro-ecological\nmodel with a combination of Deep Convolutional Neural Network (CNN) and Long\nShort-Term Memory (LSTM) Network. HydroDeep outperforms the independent CNN's\nand LSTM's performance by 1.6% and 10.5% respectively in Nash-Sutcliffe\nefficiency. Also, we show that HydroDeep pre-trained in one region is adept at\npassing on its knowledge to distant places via unique transfer learning\napproaches that minimize HydroDeep's training duration for a new region by\nlearning its regional geo-spatiotemporal features in a reduced number of\niterations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 02:20:59 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 20:47:24 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Sarkar", "Aishwarya", ""], ["Zhang", "Jien", ""], ["Lu", "Chaoqun", ""], ["Jannesari", "Ali", ""]]}, {"id": "2010.04344", "submitter": "Andrea Madotto Mr", "authors": "Andrea Madotto, Etsuko Ishii, Zhaojiang Lin, Sumanth Dathathri,\n  Pascale Fung", "title": "Plug-and-Play Conversational Models", "comments": "Accepted in EMNLP findings, and code available at\n  https://github.com/andreamad8/PPCM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been considerable progress made towards conversational models that\ngenerate coherent and fluent responses; however, this often involves training\nlarge language models on large dialogue datasets, such as Reddit. These large\nconversational models provide little control over the generated responses, and\nthis control is further limited in the absence of annotated conversational\ndatasets for attribute specific generation that can be used for fine-tuning the\nmodel. In this paper, we first propose and evaluate plug-and-play methods for\ncontrollable response generation, which does not require dialogue specific\ndatasets and does not rely on fine-tuning a large model. While effective, the\ndecoding procedure induces considerable computational overhead, rendering the\nconversational model unsuitable for interactive usage. To overcome this, we\nintroduce an approach that does not require further computation at decoding\ntime, while also does not require any fine-tuning of a large language model. We\ndemonstrate, through extensive automatic and human evaluation, a high degree of\ncontrol over the generated conversational responses with regard to multiple\ndesired attributes, while being fluent.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 03:17:51 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Madotto", "Andrea", ""], ["Ishii", "Etsuko", ""], ["Lin", "Zhaojiang", ""], ["Dathathri", "Sumanth", ""], ["Fung", "Pascale", ""]]}, {"id": "2010.04348", "submitter": "Hui Xu", "authors": "Hui Xu, Liyao Xiang, Youmin Le, Xiaoying Gan, Yuting Jia, Luoyi Fu,\n  Xinbing Wang", "title": "High-Order Relation Construction and Mining for Graph Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph matching pairs corresponding nodes across two or more graphs. The\nproblem is difficult as it is hard to capture the structural similarity across\ngraphs, especially on large graphs. We propose to incorporate high-order\ninformation for matching large-scale graphs. Iterated line graphs are\nintroduced for the first time to describe such high-order information, based on\nwhich we present a new graph matching method, called High-order Graph Matching\nNetwork (HGMN), to learn not only the local structural correspondence, but also\nthe hyperedge relations across graphs. We theoretically prove that iterated\nline graphs are more expressive than graph convolution networks in terms of\naligning nodes. By imposing practical constraints, HGMN is made scalable to\nlarge-scale graphs. Experimental results on a variety of settings have shown\nthat, HGMN acquires more accurate matching results than the state-of-the-art,\nverifying our method effectively captures the structural similarity across\ndifferent graphs.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 03:30:02 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Xu", "Hui", ""], ["Xiang", "Liyao", ""], ["Le", "Youmin", ""], ["Gan", "Xiaoying", ""], ["Jia", "Yuting", ""], ["Fu", "Luoyi", ""], ["Wang", "Xinbing", ""]]}, {"id": "2010.04351", "submitter": "Thao Nguyen", "authors": "Thao N.N. Nguyen, Bharadwaj Veeravalli, Xuanyao Fong", "title": "Connection Pruning for Deep Spiking Neural Networks with On-Chip\n  Learning", "comments": "14 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long training time hinders the potential of the deep Spiking Neural Network\n(SNN) with the online learning capability to be realized on the embedded\nsystems hardware. Our work proposes a novel connection pruning approach that\ncan be applied during the online Spike Timing Dependent Plasticity (STDP)-based\nlearning to optimize the learning time and the network connectivity of the SNN.\nOur connection pruning approach was evaluated on a deep SNN with the Time To\nFirst Spike (TTFS) coding and has successfully achieved 2.1x speed-up in the\nonline learning and reduced the network connectivity by 92.83%. The energy\nconsumption in the online learning was saved by 64%. Moreover, the connectivity\nreduction results in 2.83x speed-up and 78.24% energy saved in the inference.\nMeanwhile, the classification accuracy remains the same as our non-pruning\nbaseline on the Caltech 101 dataset. In addition, we developed an event-driven\nhardware architecture on the Field Programmable Gate Array (FPGA) platform that\nefficiently incorporates our proposed connection pruning approach while\nincurring as little as 0.56% power overhead. Moreover, we performed a\ncomparison between our work and the existing works on connection pruning for\nSNN to highlight the key features of each approach. To the best of our\nknowledge, our work is the first to propose a connection pruning algorithm that\ncan be applied during the online STDP-based learning for a deep SNN with the\nTTFS coding.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 03:44:42 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 12:44:47 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Nguyen", "Thao N. N.", ""], ["Veeravalli", "Bharadwaj", ""], ["Fong", "Xuanyao", ""]]}, {"id": "2010.04355", "submitter": "Shang-Wen Li", "authors": "Jin Cao, Jun Wang, Wael Hamza, Kelly Vanee, Shang-Wen Li", "title": "Style Attuned Pre-training and Parameter Efficient Fine-tuning for\n  Spoken Language Understanding", "comments": "Accepted at INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models have yielded state-of-the-art results in deciphering spoken\nlanguage understanding (SLU) problems; however, these models require a\nsignificant amount of domain-specific labeled examples for training, which is\nprohibitively expensive. While pre-trained language models like BERT have been\nshown to capture a massive amount of knowledge by learning from unlabeled\ncorpora and solve SLU using fewer labeled examples for adaption, the encoding\nof knowledge is implicit and agnostic to downstream tasks. Such encoding\nresults in model inefficiencies in parameter usage: an entirely new model is\nrequired for every domain. To address these challenges, we introduce a novel\nSLU framework, comprising a conversational language modeling (CLM) pre-training\ntask and a light encoder architecture. The CLM pre-training enables networks to\ncapture the representation of the language in conversation style with the\npresence of ASR errors. The light encoder architecture separates the shared\npre-trained networks from the mappings of generally encoded knowledge to\nspecific domains of SLU, allowing for the domain adaptation to be performed\nsolely at the light encoder and thus increasing efficiency. With the framework,\nwe match the performance of state-of-the-art SLU results on Alexa internal\ndatasets and on two public ones (ATIS, SNIPS), adding only 4.4% parameters per\ntask.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 03:53:37 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Cao", "Jin", ""], ["Wang", "Jun", ""], ["Hamza", "Wael", ""], ["Vanee", "Kelly", ""], ["Li", "Shang-Wen", ""]]}, {"id": "2010.04363", "submitter": "Zhiwei Xu", "authors": "Zhiwei Xu, Thalaiyasingam Ajanthan, Richard Hartley", "title": "Refining Semantic Segmentation with Superpixel by Transparent\n  Initialization and Sparse Encoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning greatly improves the performance of semantic\nsegmentation, its success mainly lies in object central areas without accurate\nedges. As superpixels are a popular and effective auxiliary to preserve object\nedges, in this paper, we jointly learn semantic segmentation with trainable\nsuperpixels. We achieve it with fully-connected layers with Transparent\nInitialization (TI) and efficient logit consistency using a sparse encoder. The\nproposed TI preserves the effects of learned parameters of pretrained networks.\nThis avoids a significant increase of the loss of pretrained networks, which\notherwise may be caused by inappropriate parameter initialization of the\nadditional layers. Meanwhile, consistent pixel labels in each superpixel are\nguaranteed by logit consistency. The sparse encoder with sparse matrix\noperations substantially reduces both the memory requirement and the\ncomputational complexity. We demonstrated the superiority of TI over other\nparameter initialization methods and tested its numerical stability. The\neffectiveness of our proposal was validated on PASCAL VOC 2012, ADE20K, and\nPASCAL Context showing enhanced semantic segmentation edges. With quantitative\nevaluations on segmentation edges using performance ratio and F-measure, our\nmethod outperforms the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 04:20:54 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 23:36:29 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 10:14:58 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Xu", "Zhiwei", ""], ["Ajanthan", "Thalaiyasingam", ""], ["Hartley", "Richard", ""]]}, {"id": "2010.04365", "submitter": "Zhou Fang", "authors": "Zhou Fang, Tianren Yang, Ying Jin", "title": "DeepStreet: A deep learning powered urban street network generation\n  module", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In countries experiencing unprecedented waves of urbanization, there is a\nneed for rapid and high quality urban street design. Our study presents a novel\ndeep learning powered approach, DeepStreet (DS), for automatic street network\ngeneration that can be applied to the urban street design with local\ncharacteristics. DS is driven by a Convolutional Neural Network (CNN) that\nenables the interpolation of streets based on the areas of immediate vicinity.\nSpecifically, the CNN is firstly trained to detect, recognize and capture the\nlocal features as well as the patterns of the existing street network sourced\nfrom the OpenStreetMap. With the trained CNN, DS is able to predict street\nnetworks' future expansion patterns within the predefined region conditioned on\nits surrounding street networks. To test the performance of DS, we apply it to\nan area in and around the Eixample area in the City of Barcelona, a well known\nexample in the fields of urban and transport planning with iconic grid like\nstreet networks in the centre and irregular road alignments farther afield. The\nresults show that DS can (1) detect and self cluster different types of complex\nstreet patterns in Barcelona; (2) predict both gridiron and irregular street\nand road networks. DS proves to have a great potential as a novel tool for\ndesigners to efficiently design the urban street network that well maintains\nthe consistency across the existing and newly generated urban street network.\nFurthermore, the generated networks can serve as a benchmark to guide the local\nplan-making especially in rapidly developing cities.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 04:27:41 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Fang", "Zhou", ""], ["Yang", "Tianren", ""], ["Jin", "Ying", ""]]}, {"id": "2010.04366", "submitter": "Honglu Zhou", "authors": "Honglu Zhou, Hareesh Ravi, Carlos M. Muniz, Vahid Azizi, Linda Ness,\n  Gerard de Melo, Mubbasir Kapadia", "title": "GitEvolve: Predicting the Evolution of GitHub Repositories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software development is becoming increasingly open and collaborative with the\nadvent of platforms such as GitHub. Given its crucial role, there is a need to\nbetter understand and model the dynamics of GitHub as a social platform.\nPrevious work has mostly considered the dynamics of traditional social\nnetworking sites like Twitter and Facebook. We propose GitEvolve, a system to\npredict the evolution of GitHub repositories and the different ways by which\nusers interact with them. To this end, we develop an end-to-end multi-task\nsequential deep neural network that given some seed events, simultaneously\npredicts which user-group is next going to interact with a given repository,\nwhat the type of the interaction is, and when it happens. To facilitate\nlearning, we use graph based representation learning to encode relationship\nbetween repositories. We map users to groups by modelling common interests to\nbetter predict popularity and to generalize to unseen users during inference.\nWe introduce an artificial event type to better model varying levels of\nactivity of repositories in the dataset. The proposed multi-task architecture\nis generic and can be extended to model information diffusion in other social\nnetworks. In a series of experiments, we demonstrate the effectiveness of the\nproposed model, using multiple metrics and baselines. Qualitative analysis of\nthe model's ability to predict popularity and forecast trends proves its\napplicability.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 04:32:15 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Zhou", "Honglu", ""], ["Ravi", "Hareesh", ""], ["Muniz", "Carlos M.", ""], ["Azizi", "Vahid", ""], ["Ness", "Linda", ""], ["de Melo", "Gerard", ""], ["Kapadia", "Mubbasir", ""]]}, {"id": "2010.04372", "submitter": "Zhengxuan Wu", "authors": "Zhengxuan Wu, Desmond C. Ong", "title": "Pragmatically Informative Color Generation by Grounding Contextual\n  Modifiers", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grounding language in contextual information is crucial for fine-grained\nnatural language understanding. One important task that involves grounding\ncontextual modifiers is color generation. Given a reference color \"green\", and\na modifier \"bluey\", how does one generate a color that could represent \"bluey\ngreen\"? We propose a computational pragmatics model that formulates this color\ngeneration task as a recursive game between speakers and listeners. In our\nmodel, a pragmatic speaker reasons about the inferences that a listener would\nmake, and thus generates a modified color that is maximally informative to help\nthe listener recover the original referents. In this paper, we show that\nincorporating pragmatic information provides significant improvements in\nperformance compared with other state-of-the-art deep learning models where\npragmatic inference and flexibility in representing colors from a large\ncontinuous space are lacking. Our model has an absolute 98% increase in\nperformance for the test cases where the reference colors are unseen during\ntraining, and an absolute 40% increase in performance for the test cases where\nboth the reference colors and the modifiers are unseen during training.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 04:54:54 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Wu", "Zhengxuan", ""], ["Ong", "Desmond C.", ""]]}, {"id": "2010.04384", "submitter": "Pengpeng Liu", "authors": "Pengpeng Liu, Xintong Han, Michael Lyu, Irwin King, Jia Xu", "title": "Learning 3D Face Reconstruction with a Pose Guidance Network", "comments": "ACCV 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a self-supervised learning approach to learning monocular 3D face\nreconstruction with a pose guidance network (PGN). First, we unveil the\nbottleneck of pose estimation in prior parametric 3D face learning methods, and\npropose to utilize 3D face landmarks for estimating pose parameters. With our\nspecially designed PGN, our model can learn from both faces with fully labeled\n3D landmarks and unlimited unlabeled in-the-wild face images. Our network is\nfurther augmented with a self-supervised learning scheme, which exploits face\ngeometry information embedded in multiple frames of the same person, to\nalleviate the ill-posed nature of regressing 3D face geometry from a single\nimage. These three insights yield a single approach that combines the\ncomplementary strengths of parametric model learning and data-driven learning\ntechniques. We conduct a rigorous evaluation on the challenging AFLW2000-3D,\nFlorence and FaceWarehouse datasets, and show that our method outperforms the\nstate-of-the-art for all metrics.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 06:11:17 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Liu", "Pengpeng", ""], ["Han", "Xintong", ""], ["Lyu", "Michael", ""], ["King", "Irwin", ""], ["Xu", "Jia", ""]]}, {"id": "2010.04389", "submitter": "Wenhao Yu", "authors": "Wenhao Yu, Chenguang Zhu, Zaitang Li, Zhiting Hu, Qingyun Wang, Heng\n  Ji, Meng Jiang", "title": "A Survey of Knowledge-Enhanced Text Generation", "comments": "42 pages, 12 tables, 8 figures; Under review at ACM CSUR (revised\n  manuscript)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of text generation is to make machines express in human language. It\nis one of the most important yet challenging tasks in natural language\nprocessing (NLP). Since 2014, various neural encoder-decoder models pioneered\nby Seq2Seq have been proposed to achieve the goal by learning to map input text\nto output text. However, the input text alone often provides limited knowledge\nto generate the desired output, so the performance of text generation is still\nfar from satisfaction in many real-world scenarios. To address this issue,\nresearchers have considered incorporating various forms of knowledge beyond the\ninput text into the generation models. This research direction is known as\nknowledge-enhanced text generation. In this survey, we present a comprehensive\nreview of the research on knowledge enhanced text generation over the past five\nyears. The main content includes two parts: (i) general methods and\narchitectures for integrating knowledge into text generation; (ii) specific\ntechniques and applications according to different forms of knowledge data.\nThis survey can have broad audiences, researchers and practitioners, in\nacademia and industry.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 06:46:46 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 07:09:57 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Yu", "Wenhao", ""], ["Zhu", "Chenguang", ""], ["Li", "Zaitang", ""], ["Hu", "Zhiting", ""], ["Wang", "Qingyun", ""], ["Ji", "Heng", ""], ["Jiang", "Meng", ""]]}, {"id": "2010.04402", "submitter": "Seung-Won Park", "authors": "Seung-won Park", "title": "Generating Novel Glyph without Human Data by Learning to Communicate", "comments": "To appear at 4th Workshop on Machine Learning for Creativity and\n  Design at NeurIPS 2020; 6 pages with 4 figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Neural Glyph, a system that generates novel glyph\nwithout any training data. The generator and the classifier are trained to\ncommunicate via visual symbols as a medium, which enforces the generator to\ncome up with a set of distinctive symbols. Our method results in glyphs that\nresemble the human-made glyphs, which may imply that the visual appearances of\nexisting glyphs can be attributed to constraints of communication via writing.\nImportant tricks that enable this framework are described and the code is made\navailable.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 07:18:36 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 12:57:16 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Park", "Seung-won", ""]]}, {"id": "2010.04434", "submitter": "Tielin Zhang", "authors": "Tielin Zhang and Shuncheng Jia and Xiang Cheng and Bo Xu", "title": "Tuning Convolutional Spiking Neural Network with Biologically-plausible\n  Reward Propagation", "comments": "Final Version. Accepted by IEEE Transactions on Neural Networks and\n  Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) contain more biologically realistic structures\nand biologically-inspired learning principles than those in standard Artificial\nNeural Networks (ANNs). SNNs are considered the third generation of ANNs,\npowerful on the robust computation with a low computational cost. The neurons\nin SNNs are non-differential, containing decayed historical states and\ngenerating event-based spikes after their states reaching the firing threshold.\nThese dynamic characteristics of SNNs make it difficult to be directly trained\nwith the standard backpropagation (BP), which is also considered not\nbiologically plausible. In this paper, a Biologically-plausible Reward\nPropagation (BRP) algorithm is proposed and applied to the SNN architecture\nwith both spiking-convolution (with both 1D and 2D convolutional kernels) and\nfull-connection layers. Unlike the standard BP that propagates error signals\nfrom post to presynaptic neurons layer by layer, the BRP propagates target\nlabels instead of errors directly from the output layer to all pre-hidden\nlayers. This effort is more consistent with the top-down reward-guiding\nlearning in cortical columns of the neocortex. Synaptic modifications with only\nlocal gradient differences are induced with pseudo-BP that might also be\nreplaced with the Spike-Timing Dependent Plasticity (STDP). The performance of\nthe proposed BRP-SNN is further verified on the spatial (including MNIST and\nCifar-10) and temporal (including TIDigits and DvsGesture) tasks, where the SNN\nusing BRP has reached a similar accuracy compared to other state-of-the-art\nBP-based SNNs and saved 50% more computational cost than ANNs. We think the\nintroduction of biologically plausible learning rules to the training procedure\nof biologically realistic SNNs will give us more hints and inspirations toward\na better understanding of the biological system's intelligent nature.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 08:42:13 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 06:06:27 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 13:50:56 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhang", "Tielin", ""], ["Jia", "Shuncheng", ""], ["Cheng", "Xiang", ""], ["Xu", "Bo", ""]]}, {"id": "2010.04440", "submitter": "Yannis Flet-Berliac", "authors": "Yannis Flet-Berliac, Reda Ouhamma, Odalric-Ambrym Maillard, Philippe\n  Preux", "title": "Learning Value Functions in Deep Policy Gradients using Residual\n  Variance", "comments": "Accepted at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Policy gradient algorithms have proven to be successful in diverse decision\nmaking and control tasks. However, these methods suffer from high sample\ncomplexity and instability issues. In this paper, we address these challenges\nby providing a different approach for training the critic in the actor-critic\nframework. Our work builds on recent studies indicating that traditional\nactor-critic algorithms do not succeed in fitting the true value function,\ncalling for the need to identify a better objective for the critic. In our\nmethod, the critic uses a new state-value (resp. state-action-value) function\napproximation that learns the value of the states (resp. state-action pairs)\nrelative to their mean value rather than the absolute value as in conventional\nactor-critic. We prove the theoretical consistency of the new gradient\nestimator and observe dramatic empirical improvement across a variety of\ncontinuous control tasks and algorithms. Furthermore, we validate our method in\ntasks with sparse rewards, where we provide experimental evidence and\ntheoretical insights.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 08:57:06 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 18:05:34 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 18:51:46 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Flet-Berliac", "Yannis", ""], ["Ouhamma", "Reda", ""], ["Maillard", "Odalric-Ambrym", ""], ["Preux", "Philippe", ""]]}, {"id": "2010.04444", "submitter": "Paul J. Pritz", "authors": "Paul J. Pritz and Liang Ma and Kin K. Leung", "title": "Jointly-Trained State-Action Embedding for Efficient Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While reinforcement learning has achieved considerable successes in recent\nyears, state-of-the-art models are often still limited by the size of state and\naction spaces. Model-free reinforcement learning approaches use some form of\nstate representations and the latest work has explored embedding techniques for\nactions, both with the aim of achieving better generalization and\napplicability. However, these approaches consider only states or actions,\nignoring the interaction between them when generating embedded representations.\nIn this work, we propose a new approach for jointly learning embeddings for\nstates and actions that combines aspects of model-free and model-based\nreinforcement learning, which can be applied in both discrete and continuous\ndomains. Specifically, we use a model of the environment to obtain embeddings\nfor states and actions and present a generic architecture that uses these to\nlearn a policy. In this way, the embedded representations obtained via our\napproach enable better generalization over both states and actions by capturing\nsimilarities in the embedding spaces. Evaluations of our approach on several\ngaming, robotic control, and recommender systems show it significantly\noutperforms state-of-the-art models in both discrete/continuous domains with\nlarge state/action spaces, thus confirming its efficacy and the overall\nsuperior performance.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 09:09:31 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 20:52:20 GMT"}, {"version": "v3", "created": "Fri, 4 Dec 2020 16:37:54 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Pritz", "Paul J.", ""], ["Ma", "Liang", ""], ["Leung", "Kin K.", ""]]}, {"id": "2010.04445", "submitter": "Mengjun Ming", "authors": "Mengjun Ming, Rui Wang, Tao Zhang", "title": "Investigating Constraint Relationship in Evolutionary Many-Constraint\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contributes to the treatment of extensive constraints in\nevolutionary many-constraint optimization through consideration of the\nrelationships between pair-wise constraints. In a conflicting relationship, the\nfunctional value of one constraint increases as the value in another constraint\ndecreases. In a harmonious relationship, the improvement in one constraint is\nrewarded with simultaneous improvement in the other constraint. In an\nindependent relationship, the adjustment to one constraint never affects the\nadjustment to the other. Based on the different features, methods for\nidentifying constraint relationships are discussed, helping to simplify\nmany-constraint optimization problems (MCOPs). Additionally, the transitivity\nof the relationships is further discussed at the aim of determining the\nrelationship in a new pair of constraints.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 09:15:08 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Ming", "Mengjun", ""], ["Wang", "Rui", ""], ["Zhang", "Tao", ""]]}, {"id": "2010.04456", "submitter": "Vincent Le-Guen", "authors": "Vincent Le Guen, Yuan Yin, J\\'er\\'emie Dona, Ibrahim Ayed, Emmanuel de\n  B\\'ezenac, Nicolas Thome, Patrick Gallinari", "title": "Augmenting Physical Models with Deep Networks for Complex Dynamics\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Forecasting complex dynamical phenomena in settings where only partial\nknowledge of their dynamics is available is a prevalent problem across various\nscientific fields. While purely data-driven approaches are arguably\ninsufficient in this context, standard physical modeling based approaches tend\nto be over-simplistic, inducing non-negligible errors. In this work, we\nintroduce the APHYNITY framework, a principled approach for augmenting\nincomplete physical dynamics described by differential equations with deep\ndata-driven models. It consists in decomposing the dynamics into two\ncomponents: a physical component accounting for the dynamics for which we have\nsome prior knowledge, and a data-driven component accounting for errors of the\nphysical model. The learning problem is carefully formulated such that the\nphysical model explains as much of the data as possible, while the data-driven\ncomponent only describes information that cannot be captured by the physical\nmodel, no more, no less. This not only provides the existence and uniqueness\nfor this decomposition, but also ensures interpretability and benefits\ngeneralization. Experiments made on three important use cases, each\nrepresentative of a different family of phenomena, i.e. reaction-diffusion\nequations, wave equations and the non-linear damped pendulum, show that\nAPHYNITY can efficiently leverage approximate physical models to accurately\nforecast the evolution of the system and correctly identify relevant physical\nparameters.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 09:31:03 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 08:49:33 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 18:18:27 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Guen", "Vincent Le", ""], ["Yin", "Yuan", ""], ["Dona", "J\u00e9r\u00e9mie", ""], ["Ayed", "Ibrahim", ""], ["de B\u00e9zenac", "Emmanuel", ""], ["Thome", "Nicolas", ""], ["Gallinari", "Patrick", ""]]}, {"id": "2010.04459", "submitter": "Yongmin Li", "authors": "Bolin Wei, Yongmin Li, Ge Li, Xin Xia, Zhi Jin", "title": "Retrieve and Refine: Exemplar-based Neural Comment Generation", "comments": "to be published in the 35th IEEE/ACM International Conference on\n  Automated Software Engineering (ASE 2020) (ASE'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code comment generation which aims to automatically generate natural language\ndescriptions for source code, is a crucial task in the field of automatic\nsoftware development. Traditional comment generation methods use\nmanually-crafted templates or information retrieval (IR) techniques to generate\nsummaries for source code. In recent years, neural network-based methods which\nleveraged acclaimed encoder-decoder deep learning framework to learn comment\ngeneration patterns from a large-scale parallel code corpus, have achieved\nimpressive results. However, these emerging methods only take code-related\ninformation as input. Software reuse is common in the process of software\ndevelopment, meaning that comments of similar code snippets are helpful for\ncomment generation. Inspired by the IR-based and template-based approaches, in\nthis paper, we propose a neural comment generation approach where we use the\nexisting comments of similar code snippets as exemplars to guide comment\ngeneration. Specifically, given a piece of code, we first use an IR technique\nto retrieve a similar code snippet and treat its comment as an exemplar. Then\nwe design a novel seq2seq neural network that takes the given code, its AST,\nits similar code, and its exemplar as input, and leverages the information from\nthe exemplar to assist in the target comment generation based on the semantic\nsimilarity between the source code and the similar code. We evaluate our\napproach on a large-scale Java corpus, which contains about 2M samples, and\nexperimental results demonstrate that our model outperforms the\nstate-of-the-art methods by a substantial margin.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 09:33:10 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Wei", "Bolin", ""], ["Li", "Yongmin", ""], ["Li", "Ge", ""], ["Xia", "Xin", ""], ["Jin", "Zhi", ""]]}, {"id": "2010.04463", "submitter": "Jingan Yang", "authors": "Jingan Yang, Yang Peng", "title": "Bioinspired Bipedal Locomotion Control for Humanoid Robotics Based on\n  EACO", "comments": "20 pages, 10 figures, 53 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To construct a robot that can walk as efficiently and steadily as humans or\nother legged animals, we develop an enhanced elitist-mutated ant colony\noptimization~(EACO) algorithm with genetic and crossover operators in real-time\napplications to humanoid robotics or other legged robots. This work presents\npromoting global search capability and convergence rate of the EACO applied to\nhumanoid robots in real-time by estimating the expected convergence rate using\nMarkov chain. Furthermore, we put a special focus on the EACO algorithm on a\nwide range of problems, from ACO, real-coded GAs, GAs with neural\nnetworks~(NNs), particle swarm optimization~(PSO) to complex robotics systems\nincluding gait synthesis, dynamic modeling of parameterizable trajectories and\ngait optimization of humanoid robotics. The experimental results illustrate the\ncapability of this method to discover the premature convergence probability,\ntackle successfully inherent stagnation, and promote the convergence rate of\nthe EACO-based humanoid robotics systems and demonstrated the applicability and\nthe effectiveness of our strategy for solving sophisticated optimization tasks.\nWe found reliable and fast walking gaits with a velocity of up to 0.47m/s using\nthe EACO optimization strategy. These findings have significant implications\nfor understanding and tackling inherent stagnation and poor convergence rate of\nthe EACO and provide new insight into the genetic architectures and control\noptimization of humanoid robotics.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 09:43:48 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Yang", "Jingan", ""], ["Peng", "Yang", ""]]}, {"id": "2010.04466", "submitter": "Robert Tjarko Lange", "authors": "Robert Tjarko Lange and Henning Sprekeler", "title": "Learning not to learn: Nature versus nurture in silico", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals are equipped with a rich innate repertoire of sensory, behavioral and\nmotor skills, which allows them to interact with the world immediately after\nbirth. At the same time, many behaviors are highly adaptive and can be tailored\nto specific environments by means of learning. In this work, we use\nmathematical analysis and the framework of meta-learning (or 'learning to\nlearn') to answer when it is beneficial to learn such an adaptive strategy and\nwhen to hard-code a heuristic behavior. We find that the interplay of\necological uncertainty, task complexity and the agents' lifetime has crucial\neffects on the meta-learned amortized Bayesian inference performed by an agent.\nThere exist two regimes: One in which meta-learning yields a learning algorithm\nthat implements task-dependent information-integration and a second regime in\nwhich meta-learning imprints a heuristic or 'hard-coded' behavior. Further\nanalysis reveals that non-adaptive behaviors are not only optimal for aspects\nof the environment that are stable across individuals, but also in situations\nwhere an adaptation to the environment would in fact be highly beneficial, but\ncould not be done quickly enough to be exploited within the remaining lifetime.\nHard-coded behaviors should hence not only be those that always work, but also\nthose that are too complex to be learned within a reasonable time frame.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 09:47:40 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 11:27:16 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Lange", "Robert Tjarko", ""], ["Sprekeler", "Henning", ""]]}, {"id": "2010.04495", "submitter": "Seyed Iman Mirzadeh", "authors": "Seyed Iman Mirzadeh, Mehrdad Farajtabar, Dilan Gorur, Razvan Pascanu,\n  Hassan Ghasemzadeh", "title": "Linear Mode Connectivity in Multitask and Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual (sequential) training and multitask (simultaneous) training are\noften attempting to solve the same overall objective: to find a solution that\nperforms well on all considered tasks. The main difference is in the training\nregimes, where continual learning can only have access to one task at a time,\nwhich for neural networks typically leads to catastrophic forgetting. That is,\nthe solution found for a subsequent task does not perform well on the previous\nones anymore. However, the relationship between the different minima that the\ntwo training regimes arrive at is not well understood. What sets them apart? Is\nthere a local structure that could explain the difference in performance\nachieved by the two different schemes? Motivated by recent work showing that\ndifferent minima of the same task are typically connected by very simple curves\nof low error, we investigate whether multitask and continual solutions are\nsimilarly connected. We empirically find that indeed such connectivity can be\nreliably achieved and, more interestingly, it can be done by a linear path,\nconditioned on having the same initialization for both. We thoroughly analyze\nthis observation and discuss its significance for the continual learning\nprocess. Furthermore, we exploit this finding to propose an effective algorithm\nthat constrains the sequentially learned minima to behave as the multitask\nsolution. We show that our method outperforms several state of the art\ncontinual learning algorithms on various vision benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 10:53:25 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Mirzadeh", "Seyed Iman", ""], ["Farajtabar", "Mehrdad", ""], ["Gorur", "Dilan", ""], ["Pascanu", "Razvan", ""], ["Ghasemzadeh", "Hassan", ""]]}, {"id": "2010.04536", "submitter": "Zhou Fang", "authors": "Zhou Fang, Ying Jin, Tianren Yang", "title": "Incorporating planning intelligence into deep learning: A planning\n  support tool for street network design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning applications in shaping ad hoc planning proposals are limited\nby the difficulty in integrating professional knowledge about cities with\nartificial intelligence. We propose a novel, complementary use of deep neural\nnetworks and planning guidance to automate street network generation that can\nbe context-aware, example-based and user-guided. The model tests suggest that\nthe incorporation of planning knowledge (e.g., road junctions and neighborhood\ntypes) in the model training leads to a more realistic prediction of street\nconfigurations. Furthermore, the new tool provides both professional and lay\nusers an opportunity to systematically and intuitively explore benchmark\nproposals for comparisons and further evaluations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 12:57:05 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Fang", "Zhou", ""], ["Jin", "Ying", ""], ["Yang", "Tianren", ""]]}, {"id": "2010.04548", "submitter": "Jialin Liu Ph.D", "authors": "Jialin Liu, Sam Snodgrass, Ahmed Khalifa, Sebastian Risi, Georgios N.\n  Yannakakis, Julian Togelius", "title": "Deep Learning for Procedural Content Generation", "comments": "This is a pre-print of an article published in Neural Computing and\n  Applications. The final authenticated version is available online at:\n  https://doi.org/10.1007/s00521-020-05383-8", "journal-ref": "Neural Computing and Applications 2020 (Early Access)", "doi": "10.1007/s00521-020-05383-8", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedural content generation in video games has a long history. Existing\nprocedural content generation methods, such as search-based, solver-based,\nrule-based and grammar-based methods have been applied to various content types\nsuch as levels, maps, character models, and textures. A research field centered\non content generation in games has existed for more than a decade. More\nrecently, deep learning has powered a remarkable range of inventions in content\nproduction, which are applicable to games. While some cutting-edge deep\nlearning methods are applied on their own, others are applied in combination\nwith more traditional methods, or in an interactive setting. This article\nsurveys the various deep learning methods that have been applied to generate\ngame content directly or indirectly, discusses deep learning methods that could\nbe used for content generation purposes but are rarely used today, and\nenvisages some limitations and potential future directions of deep learning for\nprocedural content generation.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 13:08:37 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Liu", "Jialin", ""], ["Snodgrass", "Sam", ""], ["Khalifa", "Ahmed", ""], ["Risi", "Sebastian", ""], ["Yannakakis", "Georgios N.", ""], ["Togelius", "Julian", ""]]}, {"id": "2010.04550", "submitter": "Maksim Tomic", "authors": "Maksim Tomic", "title": "Quantum Computational Psychoanalysis -- Quantum logic approach to\n  Bi-logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we are dealing with the fundamental concepts of Bi-logic\nproposed by Chilean psychoanalyst Ignacio Matte Blanco in the context of\nquantum logic, founded by Gareth Birkhoff and John Von Neumann. The main\npurpose of this paper is to present how a quantum-logical model, represented by\nthe lattice of a closed subspace of Hilbert space, can be used as a\ncomputational framework for concepts that are originally described by Sigmund\nFreud as the fundamental properties of the unconscious psyche.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 11:40:14 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Tomic", "Maksim", ""]]}, {"id": "2010.04551", "submitter": "Chen Feng", "authors": "Feng Chen", "title": "AI Centered on Scene Fitting and Dynamic Cognitive Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper briefly analyzes the advantages and problems of AI mainstream\ntechnology and puts forward: To achieve stronger Artificial Intelligence, the\nend-to-end function calculation must be changed and adopt the technology system\ncentered on scene fitting. It also discusses the concrete scheme named Dynamic\nCognitive Network model (DC Net). Discussions : The knowledge and data in the\ncomprehensive domain are uniformly represented by using the rich connection\nheterogeneous Dynamic Cognitive Network constructed by conceptualized elements;\nA network structure of two dimensions and multi layers is designed to achieve\nunified implementation of AI core processing such as combination and\ngeneralization; This paper analyzes the implementation differences of computer\nsystems in different scenes, such as open domain, closed domain, significant\nprobability and non-significant probability, and points out that the\nimplementation in open domain and significant probability scene is the key of\nAI, and a cognitive probability model combining bidirectional conditional\nprobability, probability passing and superposition, probability col-lapse is\ndesigned; An omnidirectional network matching-growth algorithm system driven by\ntarget and probability is designed to realize the integration of parsing,\ngenerating, reasoning, querying, learning and so on; The principle of cognitive\nnetwork optimization is proposed, and the basic framework of Cognitive Network\nLearning algorithm (CNL) is designed that structure learning is the primary\nmethod and parameter learning is the auxiliary. The logical similarity of\nimplementation between DC Net model and human intelligence is analyzed in this\npaper.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 06:13:41 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Chen", "Feng", ""]]}, {"id": "2010.04576", "submitter": "Cheng-Te Li", "authors": "Hsin-Yu Chen, Cheng-Te Li", "title": "HENIN: Learning Heterogeneous Neural Interaction Networks for\n  Explainable Cyberbullying Detection on Social Media", "comments": "EMNLP 2020 long paper. Code is available at\n  https://github.com/HsinYu7330/HENIN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the computational detection of cyberbullying, existing work largely\nfocused on building generic classifiers that rely exclusively on text analysis\nof social media sessions. Despite their empirical success, we argue that a\ncritical missing piece is the model explainability, i.e., why a particular\npiece of media session is detected as cyberbullying. In this paper, therefore,\nwe propose a novel deep model, HEterogeneous Neural Interaction Networks\n(HENIN), for explainable cyberbullying detection. HENIN contains the following\ncomponents: a comment encoder, a post-comment co-attention sub-network, and\nsession-session and post-post interaction extractors. Extensive experiments\nconducted on real datasets exhibit not only the promising performance of HENIN,\nbut also highlight evidential comments so that one can understand why a media\nsession is identified as cyberbullying.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 13:44:34 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Chen", "Hsin-Yu", ""], ["Li", "Cheng-Te", ""]]}, {"id": "2010.04586", "submitter": "Shilpa Mayannavar", "authors": "Shilpa Mayannavar, Uday Wali, and V M Aparanji", "title": "A Novel ANN Structure for Image Recognition", "comments": "9 pages, 10 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents Multi-layer Auto Resonance Networks (ARN), a new neural\nmodel, for image recognition. Neurons in ARN, called Nodes, latch on to an\nincoming pattern and resonate when the input is within its 'coverage.'\nResonance allows the neuron to be noise tolerant and tunable. Coverage of nodes\ngives them an ability to approximate the incoming pattern. Its latching\ncharacteristics allow it to respond to episodic events without disturbing the\nexisting trained network. These networks are capable of addressing problems in\nvaried fields but have not been sufficiently explored. Implementation of an\nimage classification and identification system using two-layer ARN is discussed\nin this paper. Recognition accuracy of 94% has been achieved for MNIST dataset\nwith only two layers of neurons and just 50 samples per numeral, making it\nuseful in computing at the edge of cloud infrastructure.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 14:07:29 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Mayannavar", "Shilpa", ""], ["Wali", "Uday", ""], ["Aparanji", "V M", ""]]}, {"id": "2010.04595", "submitter": "Bo Yang", "authors": "Alex Trevithick, Bo Yang", "title": "GRF: Learning a General Radiance Field for 3D Scene Representation and\n  Rendering", "comments": "Code and data are available at: https://github.com/alextrevithick/GRF", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple yet powerful implicit neural function that can represent\nand render arbitrarily complex 3D scenes in a single network only from 2D\nobservations. The function models 3D scenes as a general radiance field, which\ntakes a set of posed 2D images with camera poses and intrinsics as input,\nconstructs an internal representation for each 3D point of the scene, and\nrenders the corresponding appearance and geometry of any 3D point viewing from\nan arbitrary angle. The key to our approach is to explicitly integrate the\nprinciple of multi-view geometry to obtain the internal representations from\nobserved 2D views, such that the learned implicit representations empirically\nremain multi-view consistent. In addition, we introduce an effective neural\nmodule to learn general features for each pixel in 2D images, allowing the\nconstructed internal 3D representations to be general as well. Extensive\nexperiments demonstrate the superiority of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 14:21:43 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 06:33:25 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Trevithick", "Alex", ""], ["Yang", "Bo", ""]]}, {"id": "2010.04602", "submitter": "Tom Weber", "authors": "Tom Weber, Stefan Wermter", "title": "Integrating Intrinsic and Extrinsic Explainability: The Relevance of\n  Understanding Neural Networks for Human-Robot Interaction", "comments": "Fall Symposium AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable artificial intelligence (XAI) can help foster trust in and\nacceptance of intelligent and autonomous systems. Moreover, understanding the\nmotivation for an agent's behavior results in better and more successful\ncollaborations between robots and humans. However, not only can humans benefit\nfrom a robot's explanation but the robot itself can also benefit from\nexplanations given to him. Currently, most attention is paid to explaining deep\nneural networks and black-box models. However, a lot of these approaches are\nnot applicable to humanoid robots. Therefore, in this position paper, current\nproblems with adapting XAI methods to explainable neurorobotics are described.\nFurthermore, NICO, an open-source humanoid robot platform, is introduced and\nhow the interaction of intrinsic explanations by the robot itself and extrinsic\nexplanations provided by the environment enable efficient robotic behavior.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 14:28:48 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Weber", "Tom", ""], ["Wermter", "Stefan", ""]]}, {"id": "2010.04605", "submitter": "Zhi Wang", "authors": "Zhi Wang and Chunlin Chen and Daoyi Dong", "title": "Instance Weighted Incremental Evolution Strategies for Reinforcement\n  Learning in Dynamic Environments", "comments": "Under review, 18 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution strategies (ES), as a family of black-box optimization algorithms,\nrecently emerge as a scalable alternative to reinforcement learning (RL)\napproaches such as Q-learning or policy gradient, and are much faster when many\ncentral processing units (CPUs) are available due to better parallelization. In\nthis paper, we propose a systematic incremental learning method for ES in\ndynamic environments. The goal is to adjust previously learned policy to a new\none incrementally whenever the environment changes. We incorporate an instance\nweighting mechanism with ES to facilitate its learning adaptation, while\nretaining scalability of ES. During parameter updating, higher weights are\nassigned to instances that contain more new knowledge, thus encouraging the\nsearch distribution to move towards new promising areas of parameter space. We\npropose two easy-to-implement metrics to calculate the weights: instance\nnovelty and instance quality. Instance novelty measures an instance's\ndifference from the previous optimum in the original environment, while\ninstance quality corresponds to how well an instance performs in the new\nenvironment. The resulting algorithm, Instance Weighted Incremental Evolution\nStrategies (IW-IES), is verified to achieve significantly improved performance\non a suite of robot navigation tasks. This paper thus introduces a family of\nscalable ES algorithms for RL domains that enables rapid learning adaptation to\ndynamic environments.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 14:31:44 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Wang", "Zhi", ""], ["Chen", "Chunlin", ""], ["Dong", "Daoyi", ""]]}, {"id": "2010.04606", "submitter": "Gon\\c{c}alo Mordido", "authors": "Gon\\c{c}alo Mordido and Christoph Meinel", "title": "Mark-Evaluate: Assessing Language Generation using Population Estimation\n  Methods", "comments": "Accepted at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a family of metrics to assess language generation derived from\npopulation estimation methods widely used in ecology. More specifically, we use\nmark-recapture and maximum-likelihood methods that have been applied over the\npast several decades to estimate the size of closed populations in the wild. We\npropose three novel metrics: ME$_\\text{Petersen}$ and ME$_\\text{CAPTURE}$,\nwhich retrieve a single-valued assessment, and ME$_\\text{Schnabel}$ which\nreturns a double-valued metric to assess the evaluation set in terms of quality\nand diversity, separately. In synthetic experiments, our family of methods is\nsensitive to drops in quality and diversity. Moreover, our methods show a\nhigher correlation to human evaluation than existing metrics on several\nchallenging tasks, namely unconditional language generation, machine\ntranslation, and text summarization.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 14:31:53 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Mordido", "Gon\u00e7alo", ""], ["Meinel", "Christoph", ""]]}, {"id": "2010.04625", "submitter": "Omar Shaikh", "authors": "Omar Shaikh, Jiaao Chen, Jon Saad-Falcon, Duen Horng Chau and Diyi\n  Yang", "title": "Examining the Ordering of Rhetorical Strategies in Persuasive Requests", "comments": "Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpreting how persuasive language influences audiences has implications\nacross many domains like advertising, argumentation, and propaganda. Persuasion\nrelies on more than a message's content. Arranging the order of the message\nitself (i.e., ordering specific rhetorical strategies) also plays an important\nrole. To examine how strategy orderings contribute to persuasiveness, we first\nutilize a Variational Autoencoder model to disentangle content and rhetorical\nstrategies in textual requests from a large-scale loan request corpus. We then\nvisualize interplay between content and strategy through an attentional LSTM\nthat predicts the success of textual requests. We find that specific (orderings\nof) strategies interact uniquely with a request's content to impact success\nrate, and thus the persuasiveness of a request.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 15:10:44 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 00:37:11 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Shaikh", "Omar", ""], ["Chen", "Jiaao", ""], ["Saad-Falcon", "Jon", ""], ["Chau", "Duen Horng", ""], ["Yang", "Diyi", ""]]}, {"id": "2010.04627", "submitter": "Matthew Kusner", "authors": "Valentina Zantedeschi, Matt J. Kusner, Vlad Niculae", "title": "Learning Binary Decision Trees by Argmin Differentiation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning binary decision trees that partition data\nfor some downstream task. We propose to learn discrete parameters (i.e., for\ntree traversals and node pruning) and continuous parameters (i.e., for tree\nsplit functions and prediction functions) simultaneously using argmin\ndifferentiation. We do so by sparsely relaxing a mixed-integer program for the\ndiscrete parameters, to allow gradients to pass through the program to\ncontinuous parameters. We derive customized algorithms to efficiently compute\nthe forward and backward passes. This means that our tree learning procedure\ncan be used as an (implicit) layer in arbitrary deep networks, and can be\noptimized with arbitrary loss functions. We demonstrate that our approach\nproduces binary trees that are competitive with existing single tree and\nensemble approaches, in both supervised and unsupervised settings. Further,\napart from greedy approaches (which do not have competitive accuracies), our\nmethod is faster to train than all other tree-learning baselines we compare\nwith. The code for reproducing the results is available at\nhttps://github.com/vzantedeschi/LatentTrees.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 15:11:28 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 14:35:17 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zantedeschi", "Valentina", ""], ["Kusner", "Matt J.", ""], ["Niculae", "Vlad", ""]]}, {"id": "2010.04642", "submitter": "Loic Landrieu", "authors": "Thomas Chaton, Nicolas Chaulet, Sofiane Horache, Loic Landrieu", "title": "Torch-Points3D: A Modular Multi-Task Frameworkfor Reproducible Deep\n  Learning on 3D Point Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Torch-Points3D, an open-source framework designed to facilitate\nthe use of deep networks on3D data. Its modular design, efficient\nimplementation, and user-friendly interfaces make it a relevant tool for\nresearch and productization alike. Beyond multiple quality-of-life features,\nour goal is to standardize a higher level of transparency and reproducibility\nin 3D deep learning research, and to lower its barrier to entry. In this paper,\nwe present the design principles of Torch-Points3D, as well as extensive\nbenchmarks of multiple state-of-the-art algorithms and inference schemes across\nseveral datasets and tasks. The modularity of Torch-Points3D allows us to\ndesign fair and rigorous experimental protocols in which all methods are\nevaluated in the same conditions. The Torch-Points3D repository\n:https://github.com/nicolas-chaulet/torch-points3d\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 15:34:32 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Chaton", "Thomas", ""], ["Chaulet", "Nicolas", ""], ["Horache", "Sofiane", ""], ["Landrieu", "Loic", ""]]}, {"id": "2010.04646", "submitter": "Tyler Malloy", "authors": "Tyler Malloy, Chris R. Sims, Tim Klinger, Miao Liu, Matthew Riemer,\n  Gerald Tesauro", "title": "Deep RL With Information Constrained Policies: Generalization in\n  Continuous Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological agents learn and act intelligently in spite of a highly limited\ncapacity to process and store information. Many real-world problems involve\ncontinuous control, which represents a difficult task for artificial\nintelligence agents. In this paper we explore the potential learning advantages\na natural constraint on information flow might confer onto artificial agents in\ncontinuous control tasks. We focus on the model-free reinforcement learning\n(RL) setting and formalize our approach in terms of an information-theoretic\nconstraint on the complexity of learned policies. We show that our approach\nemerges in a principled fashion from the application of rate-distortion theory.\nWe implement a novel Capacity-Limited Actor-Critic (CLAC) algorithm and situate\nit within a broader family of RL algorithms such as the Soft Actor Critic (SAC)\nand Mutual Information Reinforcement Learning (MIRL) algorithm. Our experiments\nusing continuous control tasks show that compared to alternative approaches,\nCLAC offers improvements in generalization between training and modified test\nenvironments. This is achieved in the CLAC model while displaying the high\nsample efficiency of similar methods.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 15:42:21 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Malloy", "Tyler", ""], ["Sims", "Chris R.", ""], ["Klinger", "Tim", ""], ["Liu", "Miao", ""], ["Riemer", "Matthew", ""], ["Tesauro", "Gerald", ""]]}, {"id": "2010.04647", "submitter": "Bo Li", "authors": "Bo Li and Yezhen Wang, Shanghang Zhang, Dongsheng Li, Trevor Darrell,\n  Kurt Keutzer, Han Zhao", "title": "Learning Invariant Representations and Risks for Semi-supervised Domain\n  Adaptation", "comments": "Accepted to CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The success of supervised learning hinges on the assumption that the training\nand test data come from the same underlying distribution, which is often not\nvalid in practice due to potential distribution shift. In light of this, most\nexisting methods for unsupervised domain adaptation focus on achieving\ndomain-invariant representations and small source domain error. However, recent\nworks have shown that this is not sufficient to guarantee good generalization\non the target domain, and in fact, is provably detrimental under label\ndistribution shift. Furthermore, in many real-world applications it is often\nfeasible to obtain a small amount of labeled data from the target domain and\nuse them to facilitate model training with source data. Inspired by the above\nobservations, in this paper we propose the first method that aims to\nsimultaneously learn invariant representations and risks under the setting of\nsemi-supervised domain adaptation (Semi-DA). First, we provide a finite sample\nbound for both classification and regression problems under Semi-DA. The bound\nsuggests a principled way to obtain target generalization, i.e. by aligning\nboth the marginal and conditional distributions across domains in feature\nspace. Motivated by this, we then introduce the LIRR algorithm for jointly\n\\textbf{L}earning \\textbf{I}nvariant \\textbf{R}epresentations and\n\\textbf{R}isks. Finally, extensive experiments are conducted on both\nclassification and regression tasks, which demonstrates LIRR consistently\nachieves state-of-the-art performance and significant improvements compared\nwith the methods that only learn invariant representations or invariant risks.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 15:42:35 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 12:53:32 GMT"}, {"version": "v3", "created": "Sun, 4 Apr 2021 18:10:56 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Li", "Bo", ""], ["Wang", "Yezhen", ""], ["Zhang", "Shanghang", ""], ["Li", "Dongsheng", ""], ["Darrell", "Trevor", ""], ["Keutzer", "Kurt", ""], ["Zhao", "Han", ""]]}, {"id": "2010.04652", "submitter": "Mary Ellen Foster", "authors": "Mary Ellen Foster and Ronald P. A. Petrick", "title": "Towards Social HRI for Improving Children's Healthcare Experiences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a new research project that aims to develop a social\nrobot designed to help children cope with painful and distressing medical\nprocedures in a clinical setting. While robots have previously been trialled\nfor this task, with promising initial results, the systems have tended to be\nteleoperated, limiting their flexibility and robustness. This project will use\nepistemic planning techniques as a core component for action selection in the\nrobot system, in order to generate plans that include physical, sensory, and\nsocial actions for interacting with humans. The robot will operate in a task\nenvironment where appropriate and safe interaction with children,\nparents/caregivers, and healthcare professionals is required. In addition to\naddressing the core technical challenge of building an autonomous social robot,\nthe project will incorporate co-design techniques involving all participant\ngroups, and the final robot system will be evaluated in a two-site clinical\ntrial.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 15:49:54 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Foster", "Mary Ellen", ""], ["Petrick", "Ronald P. A.", ""]]}, {"id": "2010.04683", "submitter": "Jovita Lukasik", "authors": "Jovita Lukasik and David Friede and Arber Zela and Frank Hutter and\n  Margret Keuper", "title": "Smooth Variational Graph Embeddings for Efficient Neural Architecture\n  Search", "comments": "8 pages, 3 figures, 5 tables. Camera-Ready Version for IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) has recently been addressed from various\ndirections, including discrete, sampling-based methods and efficient\ndifferentiable approaches. While the former are notoriously expensive, the\nlatter suffer from imposing strong constraints on the search space.\nArchitecture optimization from a learned embedding space for example through\ngraph neural network based variational autoencoders builds a middle ground and\nleverages advantages from both sides. Such approaches have recently shown good\nperformance on several benchmarks. Yet, their stability and predictive power\nheavily depends on their capacity to reconstruct networks from the embedding\nspace. In this paper, we propose a two-sided variational graph autoencoder,\nwhich allows to smoothly encode and accurately reconstruct neural architectures\nfrom various search spaces. We evaluate the proposed approach on neural\narchitectures defined by the ENAS approach, the NAS-Bench-101 and the\nNAS-Bench-201 search space and show that our smooth embedding space allows to\ndirectly extrapolate the performance prediction to architectures outside the\nseen domain (e.g. with more operations). Thus, it facilitates to predict good\nnetwork architectures even without expensive Bayesian optimization or\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 17:05:41 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 14:50:56 GMT"}, {"version": "v3", "created": "Wed, 12 May 2021 12:44:54 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Lukasik", "Jovita", ""], ["Friede", "David", ""], ["Zela", "Arber", ""], ["Hutter", "Frank", ""], ["Keuper", "Margret", ""]]}, {"id": "2010.04687", "submitter": "Andrea Ferrario", "authors": "Andrea Ferrario, Michele Loi", "title": "A Series of Unfortunate Counterfactual Events: the Role of Time in\n  Counterfactual Explanations", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual explanations are a prominent example of post-hoc\ninterpretability methods in the explainable Artificial Intelligence research\ndomain. They provide individuals with alternative scenarios and a set of\nrecommendations to achieve a sought-after machine learning model outcome.\nRecently, the literature has identified desiderata of counterfactual\nexplanations, such as feasibility, actionability and sparsity that should\nsupport their applicability in real-world contexts. However, we show that the\nliterature has neglected the problem of the time dependency of counterfactual\nexplanations. We argue that, due to their time dependency and because of the\nprovision of recommendations, even feasible, actionable and sparse\ncounterfactual explanations may not be appropriate in real-world applications.\nThis is due to the possible emergence of what we call \"unfortunate\ncounterfactual events.\" These events may occur due to the retraining of machine\nlearning models whose outcomes have to be explained via counterfactual\nexplanation. Series of unfortunate counterfactual events frustrate the efforts\nof those individuals who successfully implemented the recommendations of\ncounterfactual explanations. This negatively affects people's trust in the\nability of institutions to provide machine learning-supported decisions\nconsistently. We introduce an approach to address the problem of the emergence\nof unfortunate counterfactual events that makes use of histories of\ncounterfactual explanations. In the final part of the paper we propose an\nethical analysis of two distinct strategies to cope with the challenge of\nunfortunate counterfactual events. We show that they respond to an ethically\nresponsible imperative to preserve the trustworthiness of credit lending\norganizations, the decision models they employ, and the social-economic\nfunction of credit lending.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 17:16:29 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 19:52:07 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Ferrario", "Andrea", ""], ["Loi", "Michele", ""]]}, {"id": "2010.04689", "submitter": "Gregory Kahn", "authors": "Gregory Kahn, Pieter Abbeel, Sergey Levine", "title": "LaND: Learning to Navigate from Disengagements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consistently testing autonomous mobile robots in real world scenarios is a\nnecessary aspect of developing autonomous navigation systems. Each time the\nhuman safety monitor disengages the robot's autonomy system due to the robot\nperforming an undesirable maneuver, the autonomy developers gain insight into\nhow to improve the autonomy system. However, we believe that these\ndisengagements not only show where the system fails, which is useful for\ntroubleshooting, but also provide a direct learning signal by which the robot\ncan learn to navigate. We present a reinforcement learning approach for\nlearning to navigate from disengagements, or LaND. LaND learns a neural network\nmodel that predicts which actions lead to disengagements given the current\nsensory observation, and then at test time plans and executes actions that\navoid disengagements. Our results demonstrate LaND can successfully learn to\nnavigate in diverse, real world sidewalk environments, outperforming both\nimitation learning and reinforcement learning approaches. Videos, code, and\nother material are available on our website\nhttps://sites.google.com/view/sidewalk-learning\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 17:21:42 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Kahn", "Gregory", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "2010.04736", "submitter": "Chenhao Tan", "authors": "Samuel Carton, Anirudh Rathore, Chenhao Tan", "title": "Evaluating and Characterizing Human Rationales", "comments": "14 pages, 15 figures, to appear in EMNLP 2020. Code is available at\n  https://github.com/BoulderDS/evaluating-human-rationales", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two main approaches for evaluating the quality of machine-generated\nrationales are: 1) using human rationales as a gold standard; and 2) automated\nmetrics based on how rationales affect model behavior. An open question,\nhowever, is how human rationales fare with these automatic metrics. Analyzing a\nvariety of datasets and models, we find that human rationales do not\nnecessarily perform well on these metrics. To unpack this finding, we propose\nimproved metrics to account for model-dependent baseline performance. We then\npropose two methods to further characterize rationale quality, one based on\nmodel retraining and one on using \"fidelity curves\" to reveal properties such\nas irrelevance and redundancy. Our work leads to actionable suggestions for\nevaluating and characterizing rationales.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 18:00:04 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Carton", "Samuel", ""], ["Rathore", "Anirudh", ""], ["Tan", "Chenhao", ""]]}, {"id": "2010.04791", "submitter": "Shiyue Zhang", "authors": "Shiyue Zhang, Benjamin Frey, Mohit Bansal", "title": "ChrEn: Cherokee-English Machine Translation for Endangered Language\n  Revitalization", "comments": "EMNLP 2020 (19 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cherokee is a highly endangered Native American language spoken by the\nCherokee people. The Cherokee culture is deeply embedded in its language.\nHowever, there are approximately only 2,000 fluent first language Cherokee\nspeakers remaining in the world, and the number is declining every year. To\nhelp save this endangered language, we introduce ChrEn, a Cherokee-English\nparallel dataset, to facilitate machine translation research between Cherokee\nand English. Compared to some popular machine translation language pairs, ChrEn\nis extremely low-resource, only containing 14k sentence pairs in total. We\nsplit our parallel data in ways that facilitate both in-domain and\nout-of-domain evaluation. We also collect 5k Cherokee monolingual data to\nenable semi-supervised learning. Besides these datasets, we propose several\nCherokee-English and English-Cherokee machine translation systems. We compare\nSMT (phrase-based) versus NMT (RNN-based and Transformer-based) systems;\nsupervised versus semi-supervised (via language model, back-translation, and\nBERT/Multilingual-BERT) methods; as well as transfer learning versus\nmultilingual joint training with 4 other languages. Our best results are\n15.8/12.7 BLEU for in-domain and 6.5/5.0 BLEU for out-of-domain Chr-En/EnChr\ntranslations, respectively, and we hope that our dataset and systems will\nencourage future work by the community for Cherokee language revitalization.\nOur data, code, and demo will be publicly available at\nhttps://github.com/ZhangShiyue/ChrEn\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 20:28:06 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Zhang", "Shiyue", ""], ["Frey", "Benjamin", ""], ["Bansal", "Mohit", ""]]}, {"id": "2010.04816", "submitter": "Michael Zhang", "authors": "Michael Zhang", "title": "Characterizing Policy Divergence for Personalized Meta-Reinforcement\n  Learning", "comments": "Deep Reinforcement Learning Workshop, NeurIPS 2019; Workshop on\n  Meta-Learning (Meta-Learn), NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite ample motivation from costly exploration and limited trajectory data,\nrapidly adapting to new environments with few-shot reinforcement learning (RL)\ncan remain a challenging task, especially with respect to personalized\nsettings. Here, we consider the problem of recommending optimal policies to a\nset of multiple entities each with potentially different characteristics, such\nthat individual entities may parameterize distinct environments with unique\ntransition dynamics. Inspired by existing literature in meta-learning, we\nextend previous work by focusing on the notion that certain environments are\nmore similar to each other than others in personalized settings, and propose a\nmodel-free meta-learning algorithm that prioritizes past experiences by\nrelevance during gradient-based adaptation. Our algorithm involves\ncharacterizing past policy divergence through methods in inverse reinforcement\nlearning, and we illustrate how such metrics are able to effectively\ndistinguish past policy parameters by the environment they were deployed in,\nleading to more effective fast adaptation during test time. To study\npersonalization more effectively we introduce a navigation testbed to\nspecifically incorporate environment diversity across training episodes, and\ndemonstrate that our approach outperforms meta-learning alternatives with\nrespect to few-shot reinforcement learning in personalized settings.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 21:31:53 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Zhang", "Michael", ""]]}, {"id": "2010.04821", "submitter": "Ziyuan Zhong", "authors": "Ziyuan Zhong, Yuchi Tian, Baishakhi Ray", "title": "Understanding Local Robustness of Deep Neural Networks under Natural\n  Variations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are being deployed in a wide range of settings\ntoday, from safety-critical applications like autonomous driving to commercial\napplications involving image classifications. However, recent research has\nshown that DNNs can be brittle to even slight variations of the input data.\nTherefore, rigorous testing of DNNs has gained widespread attention.\n  While DNN robustness under norm-bound perturbation got significant attention\nover the past few years, our knowledge is still limited when natural variants\nof the input images come. These natural variants, e.g. a rotated or a rainy\nversion of the original input, are especially concerning as they can occur\nnaturally in the field without any active adversary and may lead to undesirable\nconsequences. Thus, it is important to identify the inputs whose small\nvariations may lead to erroneous DNN behaviors. The very few studies that\nlooked at DNN's robustness under natural variants, however, focus on estimating\nthe overall robustness of DNNs across all the test data rather than localizing\nsuch error-producing points. This work aims to bridge this gap.\n  To this end, we study the local per-input robustness properties of the DNNs\nand leverage those properties to build a white-box (DeepRobust-W) and a\nblack-box (DeepRobust-B) tool to automatically identify the non-robust points.\nOur evaluation of these methods on three DNN models spanning three widely used\nimage classification datasets shows that they are effective in flagging points\nof poor robustness. In particular, DeepRobust-W and DeepRobust-B are able to\nachieve an F1 score of up to 91.4% and 99.1%, respectively. We further show\nthat DeepRobust-W can be applied to a regression problem in another domain. Our\nevaluation on three self-driving car models demonstrates that DeepRobust-W is\neffective in identifying points of poor robustness with F1 score up to 78.9%.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 21:42:16 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 02:46:18 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Zhong", "Ziyuan", ""], ["Tian", "Yuchi", ""], ["Ray", "Baishakhi", ""]]}, {"id": "2010.04826", "submitter": "Prasanna Parthasarathi", "authors": "Prasanna Parthasarathi and Arvind Neelakantan and Sharan Narang", "title": "On Task-Level Dialogue Composition of Generative Transformer Model", "comments": "8 pages; Accepted at Workshop on Insights from Negative Results in\n  NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented dialogue systems help users accomplish tasks such as booking a\nmovie ticket and ordering food via conversation. Generative models\nparameterized by a deep neural network are widely used for next turn response\ngeneration in such systems. It is natural for users of the system to want to\naccomplish multiple tasks within the same conversation, but the ability of\ngenerative models to compose multiple tasks is not well studied. In this work,\nwe begin by studying the effect of training human-human task-oriented dialogues\ntowards improving the ability to compose multiple tasks on Transformer\ngenerative models. To that end, we propose and explore two solutions: (1)\ncreating synthetic multiple task dialogue data for training from human-human\nsingle task dialogue and (2) forcing the encoder representation to be invariant\nto single and multiple task dialogues using an auxiliary loss. The results from\nour experiments highlight the difficulty of even the sophisticated variant of\ntransformer model in learning to compose multiple tasks from single task\ndialogues.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 22:10:03 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Parthasarathi", "Prasanna", ""], ["Neelakantan", "Arvind", ""], ["Narang", "Sharan", ""]]}, {"id": "2010.04827", "submitter": "Jiahao Chen", "authors": "Eren Kurshan and Hongda Shen and Jiahao Chen", "title": "Towards Self-Regulating AI: Challenges and Opportunities of AI Model\n  Governance in Financial Services", "comments": "8 pages, 7 figures", "journal-ref": "Proceedings of the 1st International Conference on AI in Finance\n  (ICAIF '20), October 15-16, 2020, New York", "doi": "10.1145/3383455.3422564", "report-no": null, "categories": "cs.LG cs.AI q-fin.GN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI systems have found a wide range of application areas in financial\nservices. Their involvement in broader and increasingly critical decisions has\nescalated the need for compliance and effective model governance. Current\ngovernance practices have evolved from more traditional financial applications\nand modeling frameworks. They often struggle with the fundamental differences\nin AI characteristics such as uncertainty in the assumptions, and the lack of\nexplicit programming. AI model governance frequently involves complex review\nflows and relies heavily on manual steps. As a result, it faces serious\nchallenges in effectiveness, cost, complexity, and speed. Furthermore, the\nunprecedented rate of growth in the AI model complexity raises questions on the\nsustainability of the current practices. This paper focuses on the challenges\nof AI model governance in the financial services industry. As a part of the\noutlook, we present a system-level framework towards increased self-regulation\nfor robustness and compliance. This approach aims to enable potential solution\nopportunities through increased automation and the integration of monitoring,\nmanagement, and mitigation capabilities. The proposed framework also provides\nmodel governance and risk management improved capabilities to manage model risk\nduring deployment.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 22:12:22 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Kurshan", "Eren", ""], ["Shen", "Hongda", ""], ["Chen", "Jiahao", ""]]}, {"id": "2010.04831", "submitter": "Shib Sankar Dasgupta", "authors": "Shib Sankar Dasgupta, Michael Boratko, Dongxu Zhang, Luke Vilnis,\n  Xiang Lorraine Li, Andrew McCallum", "title": "Improving Local Identifiability in Probabilistic Box Embeddings", "comments": "Accepted at NeurIPS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric embeddings have recently received attention for their natural\nability to represent transitive asymmetric relations via containment. Box\nembeddings, where objects are represented by n-dimensional hyperrectangles, are\na particularly promising example of such an embedding as they are closed under\nintersection and their volume can be calculated easily, allowing them to\nnaturally represent calibrated probability distributions. The benefits of\ngeometric embeddings also introduce a problem of local identifiability,\nhowever, where whole neighborhoods of parameters result in equivalent loss\nwhich impedes learning. Prior work addressed some of these issues by using an\napproximation to Gaussian convolution over the box parameters, however, this\nintersection operation also increases the sparsity of the gradient. In this\nwork, we model the box parameters with min and max Gumbel distributions, which\nwere chosen such that space is still closed under the operation of the\nintersection. The calculation of the expected intersection volume involves all\nparameters, and we demonstrate experimentally that this drastically improves\nthe ability of such models to learn.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 22:34:12 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 01:39:49 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Dasgupta", "Shib Sankar", ""], ["Boratko", "Michael", ""], ["Zhang", "Dongxu", ""], ["Vilnis", "Luke", ""], ["Li", "Xiang Lorraine", ""], ["McCallum", "Andrew", ""]]}, {"id": "2010.04836", "submitter": "Jiahao Chen", "authors": "Jiahao Chen and Manuela Veloso", "title": "Paying down metadata debt: learning the representation of concepts using\n  topic models", "comments": "8 pages, 4 figures. Data set available in paper source", "journal-ref": "Proceedings of the 1st ACM International Conference on AI in\n  Finance (ICAIF '20), October 15-16, 2020, New York, NY, USA", "doi": "10.1145/3383455.3422537", "report-no": null, "categories": "cs.LG cs.AI cs.DL cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a data management problem called metadata debt, to identify the\nmapping between data concepts and their logical representations. We describe\nhow this mapping can be learned using semisupervised topic models based on\nlow-rank matrix factorizations that account for missing and noisy labels,\ncoupled with sparsity penalties to improve localization and interpretability.\nWe introduce a gauge transformation approach that allows us to construct\nexplicit associations between topics and concept labels, and thus assign\nmeaning to topics. We also show how to use this topic model for semisupervised\nlearning tasks like extrapolating from known labels, evaluating possible errors\nin existing labels, and predicting missing features. We show results from this\ntopic model in predicting subject tags on over 25,000 datasets from Kaggle.com,\ndemonstrating the ability to learn semantically meaningful features.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 22:42:38 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Chen", "Jiahao", ""], ["Veloso", "Manuela", ""]]}, {"id": "2010.04837", "submitter": "Manoj Bhat", "authors": "Iljoo Baek, Tzu-Chieh Tai, Manoj Bhat, Karun Ellango, Tarang Shah,\n  Kamal Fuseini, Ragunathan (Raj) Rajkumar", "title": "CurbScan: Curb Detection and Tracking Using Multi-Sensor Fusion", "comments": "Accepted to IEEE ITSC-2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Reliable curb detection is critical for safe autonomous driving in urban\ncontexts. Curb detection and tracking are also useful in vehicle localization\nand path planning. Past work utilized a 3D LiDAR sensor to determine accurate\ndistance information and the geometric attributes of curbs. However, such an\napproach requires dense point cloud data and is also vulnerable to false\npositives from obstacles present on both road and off-road areas. In this\npaper, we propose an approach to detect and track curbs by fusing together data\nfrom multiple sensors: sparse LiDAR data, a mono camera and low-cost ultrasonic\nsensors. The detection algorithm is based on a single 3D LiDAR and a mono\ncamera sensor used to detect candidate curb features and it effectively removes\nfalse positives arising from surrounding static and moving obstacles. The\ndetection accuracy of the tracking algorithm is boosted by using Kalman\nfilter-based prediction and fusion with lateral distance information from\nlow-cost ultrasonic sensors. We next propose a line-fitting algorithm that\nyields robust results for curb locations. Finally, we demonstrate the practical\nfeasibility of our solution by testing in different road environments and\nevaluating our implementation in a real vehicle\\footnote{Demo video clips\ndemonstrating our algorithm have been uploaded to Youtube:\nhttps://www.youtube.com/watch?v=w5MwsdWhcy4,\nhttps://www.youtube.com/watch?v=Gd506RklfG8.}. Our algorithm maintains over\n90\\% accuracy within 4.5-22 meters and 0-14 meters for the KITTI dataset and\nour dataset respectively, and its average processing time per frame is\napproximately 10 ms on Intel i7 x86 and 100ms on NVIDIA Xavier board.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 22:48:20 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 00:28:21 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Baek", "Iljoo", "", "Raj"], ["Tai", "Tzu-Chieh", "", "Raj"], ["Bhat", "Manoj", "", "Raj"], ["Ellango", "Karun", "", "Raj"], ["Shah", "Tarang", "", "Raj"], ["Fuseini", "Kamal", "", "Raj"], ["Ragunathan", "", "", "Raj"], ["Rajkumar", "", ""]]}, {"id": "2010.04840", "submitter": "Jiahao Chen", "authors": "Leo de Castro and Jiahao Chen and Antigoni Polychroniadou", "title": "CryptoCredit: Securely Training Fair Models", "comments": "8 pages", "journal-ref": "Proceedings of the 1st ACM International Conference on AI in\n  Finance (ICAIF '20), October 15-16, 2020, New York, NY, USA", "doi": "10.1145/3383455.3422567", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When developing models for regulated decision making, sensitive features like\nage, race and gender cannot be used and must be obscured from model developers\nto prevent bias. However, the remaining features still need to be tested for\ncorrelation with sensitive features, which can only be done with the knowledge\nof those features. We resolve this dilemma using a fully homomorphic encryption\nscheme, allowing model developers to train linear regression and logistic\nregression models and test them for possible bias without ever revealing the\nsensitive features in the clear. We demonstrate how it can be applied to\nleave-one-out regression testing, and show using the adult income data set that\nour method is practical to run.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 23:05:37 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["de Castro", "Leo", ""], ["Chen", "Jiahao", ""], ["Polychroniadou", "Antigoni", ""]]}, {"id": "2010.04844", "submitter": "James Michaelov", "authors": "James A. Michaelov and Benjamin K. Bergen", "title": "How well does surprisal explain N400 amplitude under different\n  experimental conditions?", "comments": "To be presented at CoNLL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IT cs.LG math.IT q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the extent to which word surprisal can be used to predict a\nneural measure of human language processing difficulty - the N400. To do this,\nwe use recurrent neural networks to calculate the surprisal of stimuli from\npreviously published neurolinguistic studies of the N400. We find that\nsurprisal can predict N400 amplitude in a wide range of cases, and the cases\nwhere it cannot do so provide valuable insight into the neurocognitive\nprocesses underlying the response.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 23:18:23 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Michaelov", "James A.", ""], ["Bergen", "Benjamin K.", ""]]}, {"id": "2010.04849", "submitter": "James Boerkoel Jr.", "authors": "Maya Abo Dominguez, William La, James C. Boerkoel Jr", "title": "Modeling Human Temporal Uncertainty in Human-Agent Teams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automated scheduling is potentially a very useful tool for facilitating\nefficient, intuitive interactions between a robot and a human teammate.\nHowever, a current gapin automated scheduling is that it is not well understood\nhow to best represent the timing uncertainty that human teammates introduce.\nThis paper attempts to address this gap by designing an online human-robot\ncollaborative packaging game that we use to build a model of human timing\nuncertainty from a population of crowd-workers. We conclude that heavy-tailed\ndistributions are the best models of human temporal uncertainty, with a\nLog-Normal distribution achieving the best fit to our experimental data. We\ndiscuss how these results along with our collaborative online game will inform\nand facilitate future explorations into scheduling for improved human-robot\nfluency.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 23:43:59 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Dominguez", "Maya Abo", ""], ["La", "William", ""], ["Boerkoel", "James C.", "Jr"]]}, {"id": "2010.04862", "submitter": "Dong Wang", "authors": "Dong Wang", "title": "Remarks on Optimal Scores for Speaker Recognition", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MM cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we first establish the theory of optimal scores for speaker\nrecognition. Our analysis shows that the minimum Bayes risk (MBR) decisions for\nboth the speaker identification and speaker verification tasks can be based on\na normalized likelihood (NL). When the underlying generative model is a linear\nGaussian, the NL score is mathematically equivalent to the PLDA likelihood\nratio, and the empirical scores based on cosine distance and Euclidean distance\ncan be seen as approximations of this linear Gaussian NL score under some\nconditions. We discuss a number of properties of the NL score and perform a\nsimple simulation experiment to demonstrate the properties of the NL score.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 01:28:24 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 03:33:49 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Wang", "Dong", ""]]}, {"id": "2010.04863", "submitter": "Hao Huang", "authors": "Hao Huang, Guodong Long, Tao Shen, Jing Jiang, Chengqi Zhang", "title": "RatE: Relation-Adaptive Translating Embedding for Knowledge Graph\n  Completion", "comments": "Accepted to appear at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many graph embedding approaches have been proposed for knowledge graph\ncompletion via link prediction. Among those, translating embedding approaches\nenjoy the advantages of light-weight structure, high efficiency and great\ninterpretability. Especially when extended to complex vector space, they show\nthe capability in handling various relation patterns including symmetry,\nantisymmetry, inversion and composition. However, previous translating\nembedding approaches defined in complex vector space suffer from two main\nissues: 1) representing and modeling capacities of the model are limited by the\ntranslation function with rigorous multiplication of two complex numbers; and\n2) embedding ambiguity caused by one-to-many relations is not explicitly\nalleviated. In this paper, we propose a relation-adaptive translation function\nbuilt upon a novel weighted product in complex space, where the weights are\nlearnable, relation-specific and independent to embedding size. The translation\nfunction only requires eight more scalar parameters each relation, but improves\nexpressive power and alleviates embedding ambiguity problem. Based on the\nfunction, we then present our Relation-adaptive translating Embedding (RatE)\napproach to score each graph triple. Moreover, a novel negative sampling method\nis proposed to utilize both prior knowledge and self-adversarial learning for\neffective optimization. Experiments verify RatE achieves state-of-the-art\nperformance on four link prediction benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 01:30:30 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Huang", "Hao", ""], ["Long", "Guodong", ""], ["Shen", "Tao", ""], ["Jiang", "Jing", ""], ["Zhang", "Chengqi", ""]]}, {"id": "2010.04873", "submitter": "Yueming Yin", "authors": "Yueming Yin, Zhen Yang (Senior Member, IEEE), Xiaofu Wu, and Haifeng\n  Hu", "title": "Unveiling Class-Labeling Structure for Universal Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a more practical setting for unsupervised domain adaptation, Universal\nDomain Adaptation (UDA) is recently introduced, where the target label set is\nunknown. One of the big challenges in UDA is how to determine the common label\nset shared by source and target domains, as there is simply no labeling\navailable in the target domain. In this paper, we employ a probabilistic\napproach for locating the common label set, where each source class may come\nfrom the common label set with a probability. In particular, we propose a novel\napproach for evaluating the probability of each source class from the common\nlabel set, where this probability is computed by the prediction margin\naccumulated over the whole target domain. Then, we propose a simple universal\nadaptation network (S-UAN) by incorporating the probabilistic structure for the\ncommon label set. Finally, we analyse the generalization bound focusing on the\ncommon label set and explore the properties on the target risk for UDA.\nExtensive experiments indicate that S-UAN works well in different UDA settings\nand outperforms the state-of-the-art methods by large margins.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 02:13:02 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Yin", "Yueming", "", "Senior Member, IEEE"], ["Yang", "Zhen", "", "Senior Member, IEEE"], ["Wu", "Xiaofu", ""], ["Hu", "Haifeng", ""]]}, {"id": "2010.04883", "submitter": "Xinyin Ma", "authors": "Xinyin Ma, Yongliang Shen, Gongfan Fang, Chen Chen, Chenghao Jia,\n  Weiming Lu", "title": "Adversarial Self-Supervised Data-Free Distillation for Text\n  Classification", "comments": "11 pages, 5 figures, Accepted to EMNLP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large pre-trained transformer-based language models have achieved impressive\nresults on a wide range of NLP tasks. In the past few years, Knowledge\nDistillation(KD) has become a popular paradigm to compress a computationally\nexpensive model to a resource-efficient lightweight model. However, most KD\nalgorithms, especially in NLP, rely on the accessibility of the original\ntraining dataset, which may be unavailable due to privacy issues. To tackle\nthis problem, we propose a novel two-stage data-free distillation method, named\nAdversarial self-Supervised Data-Free Distillation (AS-DFD), which is designed\nfor compressing large-scale transformer-based models (e.g., BERT). To avoid\ntext generation in discrete space, we introduce a Plug & Play Embedding\nGuessing method to craft pseudo embeddings from the teacher's hidden knowledge.\nMeanwhile, with a self-supervised module to quantify the student's ability, we\nadapt the difficulty of pseudo embeddings in an adversarial training manner. To\nthe best of our knowledge, our framework is the first data-free distillation\nframework designed for NLP tasks. We verify the effectiveness of our method on\nseveral text classification datasets.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 02:46:06 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Ma", "Xinyin", ""], ["Shen", "Yongliang", ""], ["Fang", "Gongfan", ""], ["Chen", "Chen", ""], ["Jia", "Chenghao", ""], ["Lu", "Weiming", ""]]}, {"id": "2010.04894", "submitter": "Ahmad Esmaeili", "authors": "Ahmad Esmaeili and John C. Gallagher and John A. Springer and Eric T.\n  Matson", "title": "HAMLET: A Hierarchical Agent-based Machine Learning Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Multi-Agent Systems provide a convenient and relevant way to\nanalyze, model, and simulate complex systems in which a large number of\nentities are interacting at different levels of abstraction. In this paper, we\nintroduce HAMLET (Hierarchical Agent-based Machine LEarning plaTform), a\nplatform based on hierarchical multi-agent systems, to facilitate the research\nand democratization of machine learning entities distributed geographically or\nlocally. This is carried out by firstly modeling the machine learning solutions\nas a hypergraph and then autonomously setting up a multi-level structure\ncomposed of heterogeneous agents based on their innate capabilities and learned\nskills. HAMLET aids the design and management of machine learning systems and\nprovides analytical capabilities for the research communities to assess the\nexisting and/or new algorithms/datasets through flexible and customizable\nqueries. The proposed platform does not assume restrictions on the type of\nmachine learning algorithms/datasets and is theoretically proven to be sound\nand complete with polynomial computational requirements. Additionally, it is\nexamined empirically on 120 training and four generalized batch testing tasks\nperformed on 24 machine learning algorithms and 9 standard datasets. The\nexperimental results provided not only establish confidence in the platform's\nconsistency and correctness but also demonstrates its testing and analytical\ncapacity.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 03:46:59 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Esmaeili", "Ahmad", ""], ["Gallagher", "John C.", ""], ["Springer", "John A.", ""], ["Matson", "Eric T.", ""]]}, {"id": "2010.04899", "submitter": "Sarah Al-Hussaini", "authors": "Sarah Al-Hussaini, Shantanu Thakar, Hyojeong Kim, Pradeep Rajendran,\n  Brual C. Shah, Jeremy A. Marvel, Satyandra K. Gupta", "title": "Human-Supervised Semi-Autonomous Mobile Manipulators for Safely and\n  Efficiently Executing Machine Tending Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile manipulators can be used for machine tending and material handling\ntasks in small volume manufacturing applications. These applications usually\nhave semi-structured work environment. The use of a fully autonomous mobile\nmanipulator for such applications can be risky, as an inaccurate model of the\nworkspace may result in damage to expensive equipment. On the other hand, the\nuse of a fully teleoperated mobile manipulator may require a significant amount\nof operator time. In this paper, a semi-autonomous mobile manipulator is\ndeveloped for safely and efficiently carrying out machine tending tasks under\nhuman supervision. The robot is capable of generating motion plans from the\nhigh-level task description and presenting simulation results to the human for\napproval. The human operator can authorize the robot to execute the\nautomatically generated plan or provide additional input to the planner to\nrefine the plan. If the level of uncertainty in some parts of the workspace\nmodel is high, then the human can decide to perform teleoperation to safely\nexecute the task. Our preliminary user trials show that non-expert operators\ncan quickly learn to use the system and perform machine tending tasks.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 04:28:52 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 21:03:38 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Al-Hussaini", "Sarah", ""], ["Thakar", "Shantanu", ""], ["Kim", "Hyojeong", ""], ["Rajendran", "Pradeep", ""], ["Shah", "Brual C.", ""], ["Marvel", "Jeremy A.", ""], ["Gupta", "Satyandra K.", ""]]}, {"id": "2010.04900", "submitter": "Chiyu Zhang", "authors": "Muhammad Abdul-Mageed and Chiyu Zhang and AbdelRahim Elmadany and Lyle\n  Ungar", "title": "Toward Micro-Dialect Identification in Diaglossic and Code-Switched\n  Environments", "comments": "Accepted in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although the prediction of dialects is an important language processing task,\nwith a wide range of applications, existing work is largely limited to\ncoarse-grained varieties. Inspired by geolocation research, we propose the\nnovel task of Micro-Dialect Identification (MDI) and introduce MARBERT, a new\nlanguage model with striking abilities to predict a fine-grained variety (as\nsmall as that of a city) given a single, short message. For modeling, we offer\na range of novel spatially and linguistically-motivated multi-task learning\nmodels. To showcase the utility of our models, we introduce a new, large-scale\ndataset of Arabic micro-varieties (low-resource) suited to our tasks. MARBERT\npredicts micro-dialects with 9.9% F1, ~76X better than a majority class\nbaseline. Our new language model also establishes new state-of-the-art on\nseveral external tasks.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 04:35:16 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 07:55:03 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Abdul-Mageed", "Muhammad", ""], ["Zhang", "Chiyu", ""], ["Elmadany", "AbdelRahim", ""], ["Ungar", "Lyle", ""]]}, {"id": "2010.04903", "submitter": "Yu-An Wang", "authors": "Yu-An Wang, Yun-Nung Chen", "title": "What Do Position Embeddings Learn? An Empirical Study of Pre-Trained\n  Language Model Positional Encoding", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, pre-trained Transformers have dominated the majority of NLP\nbenchmark tasks. Many variants of pre-trained Transformers have kept breaking\nout, and most focus on designing different pre-training objectives or variants\nof self-attention. Embedding the position information in the self-attention\nmechanism is also an indispensable factor in Transformers however is often\ndiscussed at will. Therefore, this paper carries out an empirical study on\nposition embeddings of mainstream pre-trained Transformers, which mainly\nfocuses on two questions: 1) Do position embeddings really learn the meaning of\npositions? 2) How do these different learned position embeddings affect\nTransformers for NLP tasks? This paper focuses on providing a new insight of\npre-trained position embeddings through feature-level analysis and empirical\nexperiments on most of iconic NLP tasks. It is believed that our experimental\nresults can guide the future work to choose the suitable positional encoding\nfunction for specific tasks given the application property.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 05:03:14 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Wang", "Yu-An", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "2010.04904", "submitter": "Qifei Wang", "authors": "Qifei Wang, Junjie Ke, Joshua Greaves, Grace Chu, Gabriel Bender,\n  Luciano Sbaiz, Alec Go, Andrew Howard, Feng Yang, Ming-Hsuan Yang, Jeff\n  Gilbert, and Peyman Milanfar", "title": "Multi-path Neural Networks for On-device Multi-domain Visual\n  Classification", "comments": "WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning multiple domains/tasks with a single model is important for\nimproving data efficiency and lowering inference cost for numerous vision\ntasks, especially on resource-constrained mobile devices. However,\nhand-crafting a multi-domain/task model can be both tedious and challenging.\nThis paper proposes a novel approach to automatically learn a multi-path\nnetwork for multi-domain visual classification on mobile devices. The proposed\nmulti-path network is learned from neural architecture search by applying one\nreinforcement learning controller for each domain to select the best path in\nthe super-network created from a MobileNetV3-like search space. An adaptive\nbalanced domain prioritization algorithm is proposed to balance optimizing the\njoint model on multiple domains simultaneously. The determined multi-path model\nselectively shares parameters across domains in shared nodes while keeping\ndomain-specific parameters within non-shared nodes in individual domain paths.\nThis approach effectively reduces the total number of parameters and FLOPS,\nencouraging positive knowledge transfer while mitigating negative interference\nacross domains. Extensive evaluations on the Visual Decathlon dataset\ndemonstrate that the proposed multi-path model achieves state-of-the-art\nperformance in terms of accuracy, model size, and FLOPS against other\napproaches using MobileNetV3-like architectures. Furthermore, the proposed\nmethod improves average accuracy over learning single-domain models\nindividually, and reduces the total number of parameters and FLOPS by 78% and\n32% respectively, compared to the approach that simply bundles single-domain\nmodels for multi-domain learning.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 05:13:49 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 08:02:15 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Wang", "Qifei", ""], ["Ke", "Junjie", ""], ["Greaves", "Joshua", ""], ["Chu", "Grace", ""], ["Bender", "Gabriel", ""], ["Sbaiz", "Luciano", ""], ["Go", "Alec", ""], ["Howard", "Andrew", ""], ["Yang", "Feng", ""], ["Yang", "Ming-Hsuan", ""], ["Gilbert", "Jeff", ""], ["Milanfar", "Peyman", ""]]}, {"id": "2010.04914", "submitter": "Richard Freedman", "authors": "Richard G. Freedman, Steven J. Levine, Brian C. Williams, Shlomo\n  Zilberstein", "title": "Helpfulness as a Key Metric of Human-Robot Collaboration", "comments": "Accepted for presentation at the AAAI 2020 Fall Symposium Series, in\n  the symposium for Artificial Intelligence for Human-Robot Interaction: Trust\n  & Explainability in Artificial Intelligence for Human-Robot Interaction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As robotic teammates become more common in society, people will assess the\nrobots' roles in their interactions along many dimensions. One such dimension\nis effectiveness: people will ask whether their robotic partners are\ntrustworthy and effective collaborators. This begs a crucial question: how can\nwe quantitatively measure the helpfulness of a robotic partner for a given task\nat hand? This paper seeks to answer this question with regards to the\ninteractive robot's decision making. We describe a clear, concise, and\ntask-oriented metric applicable to many different planning and execution\nparadigms. The proposed helpfulness metric is fundamental to assessing the\nbenefit that a partner has on a team for a given task. In this paper, we define\nhelpfulness, illustrate it on concrete examples from a variety of domains,\ndiscuss its properties and ramifications for planning interactions with humans,\nand present preliminary results.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 06:00:36 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Freedman", "Richard G.", ""], ["Levine", "Steven J.", ""], ["Williams", "Brian C.", ""], ["Zilberstein", "Shlomo", ""]]}, {"id": "2010.04922", "submitter": "Zhengxuan Wu", "authors": "Zhengxuan Wu, Thanh-Son Nguyen, Desmond C. Ong", "title": "Structured Self-Attention Weights Encode Semantics in Sentiment Analysis", "comments": "10 pages", "journal-ref": "BlackBoxNLP Workshop at EMNLP 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural attention, especially the self-attention made popular by the\nTransformer, has become the workhorse of state-of-the-art natural language\nprocessing (NLP) models. Very recent work suggests that the self-attention in\nthe Transformer encodes syntactic information; Here, we show that\nself-attention scores encode semantics by considering sentiment analysis tasks.\nIn contrast to gradient-based feature attribution methods, we propose a simple\nand effective Layer-wise Attention Tracing (LAT) method to analyze structured\nattention weights. We apply our method to Transformer models trained on two\ntasks that have surface dissimilarities, but share common semantics---sentiment\nanalysis of movie reviews and time-series valence prediction in life story\nnarratives. Across both tasks, words with high aggregated attention weights\nwere rich in emotional semantics, as quantitatively validated by an emotion\nlexicon labeled by human annotators. Our results show that structured attention\nweights encode rich semantics in sentiment analysis, and match human\ninterpretations of semantics.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 06:49:25 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Wu", "Zhengxuan", ""], ["Nguyen", "Thanh-Son", ""], ["Ong", "Desmond C.", ""]]}, {"id": "2010.04924", "submitter": "Vikas Raunak", "authors": "Vikas Raunak, Siddharth Dalmia, Vivek Gupta and Florian Metze", "title": "On Long-Tailed Phenomena in Neural Machine Translation", "comments": "Accepted to Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  State-of-the-art Neural Machine Translation (NMT) models struggle with\ngenerating low-frequency tokens, tackling which remains a major challenge. The\nanalysis of long-tailed phenomena in the context of structured prediction tasks\nis further hindered by the added complexities of search during inference. In\nthis work, we quantitatively characterize such long-tailed phenomena at two\nlevels of abstraction, namely, token classification and sequence generation. We\npropose a new loss function, the Anti-Focal loss, to better adapt model\ntraining to the structural dependencies of conditional text generation by\nincorporating the inductive biases of beam search in the training process. We\nshow the efficacy of the proposed technique on a number of Machine Translation\n(MT) datasets, demonstrating that it leads to significant gains over\ncross-entropy across different language pairs, especially on the generation of\nlow-frequency words. We have released the code to reproduce our results.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 07:00:57 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Raunak", "Vikas", ""], ["Dalmia", "Siddharth", ""], ["Gupta", "Vivek", ""], ["Metze", "Florian", ""]]}, {"id": "2010.04925", "submitter": "Yaowei Zheng", "authors": "Yaowei Zheng, Richong Zhang, Yongyi Mao", "title": "Regularizing Neural Networks via Adversarial Model Perturbation", "comments": "16 pages, 13 figures, accepted to CVPR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective regularization techniques are highly desired in deep learning for\nalleviating overfitting and improving generalization. This work proposes a new\nregularization scheme, based on the understanding that the flat local minima of\nthe empirical risk cause the model to generalize better. This scheme is\nreferred to as adversarial model perturbation (AMP), where instead of directly\nminimizing the empirical risk, an alternative \"AMP loss\" is minimized via SGD.\nSpecifically, the AMP loss is obtained from the empirical risk by applying the\n\"worst\" norm-bounded perturbation on each point in the parameter space.\nComparing with most existing regularization schemes, AMP has strong theoretical\njustifications, in that minimizing the AMP loss can be shown theoretically to\nfavour flat local minima of the empirical risk. Extensive experiments on\nvarious modern deep architectures establish AMP as a new state of the art among\nregularization schemes. Our code is available at\nhttps://github.com/hiyouga/AMP-Regularizer.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 07:01:00 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 14:02:46 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 13:53:27 GMT"}, {"version": "v4", "created": "Fri, 7 May 2021 04:26:26 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Zheng", "Yaowei", ""], ["Zhang", "Richong", ""], ["Mao", "Yongyi", ""]]}, {"id": "2010.04927", "submitter": "Qiansheng Wang", "authors": "Qiansheng Wang, Yuxin Liu, Chengguo Lv, Zhen Wang and Guohong Fu", "title": "Cue-word Driven Neural Response Generation with a Shrinking Vocabulary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain response generation is the task of generating sensible and\ninformative re-sponses to the source sentence. However, neural models tend to\ngenerate safe and mean-ingless responses. While cue-word introducing approaches\nencourage responses with concrete semantics and have shown tremendous\npotential, they still fail to explore di-verse responses during decoding. In\nthis paper, we propose a novel but natural approach that can produce multiple\ncue-words during decoding, and then uses the produced cue-words to drive\ndecoding and shrinks the decoding vocabulary. Thus the neural genera-tion model\ncan explore the full space of responses and discover informative ones with\nefficiency. Experimental results show that our approach significantly\noutperforms several strong baseline models with much lower decoding complexity.\nEspecially, our approach can converge to concrete semantics more efficiently\nduring decoding.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 07:13:32 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Wang", "Qiansheng", ""], ["Liu", "Yuxin", ""], ["Lv", "Chengguo", ""], ["Wang", "Zhen", ""], ["Fu", "Guohong", ""]]}, {"id": "2010.04935", "submitter": "Jun Kong", "authors": "Jun Kong, Jin Wang and Xuejie Zhang", "title": "HPCC-YNU at SemEval-2020 Task 9: A Bilingual Vector Gating Mechanism for\n  Sentiment Analysis of Code-Mixed Text", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is fairly common to use code-mixing on a social media platform to express\nopinions and emotions in multilingual societies. The purpose of this task is to\ndetect the sentiment of code-mixed social media text. Code-mixed text poses a\ngreat challenge for the traditional NLP system, which currently uses\nmonolingual resources to deal with the problem of multilingual mixing. This\ntask has been solved in the past using lexicon lookup in respective sentiment\ndictionaries and using a long short-term memory (LSTM) neural network for\nmonolingual resources. In this paper, we (my codalab username is kongjun)\npresent a system that uses a bilingual vector gating mechanism for bilingual\nresources to complete the task. The model consists of two main parts: the\nvector gating mechanism, which combines the character and word levels, and the\nattention mechanism, which extracts the important emotional parts of the text.\nThe results show that the proposed system outperforms the baseline algorithm.\nWe achieved fifth place in Spanglish and 19th place in Hinglish.The code of\nthis paper is availabled at : https://github.com/JunKong5/Semveal2020-task9\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 08:02:15 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Kong", "Jun", ""], ["Wang", "Jin", ""], ["Zhang", "Xuejie", ""]]}, {"id": "2010.04949", "submitter": "Mingxiang Chen", "authors": "Mingxiang Chen, Zhecheng Wang", "title": "Image Generation With Neural Cellular Automatas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach to generate images (or other\nartworks) by using neural cellular automatas (NCAs). Rather than training NCAs\nbased on single images one by one, we combined the idea with variational\nautoencoders (VAEs), and hence explored some applications, such as image\nrestoration and style fusion. The code for model implementation is available\nonline.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 08:52:52 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 03:34:23 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Chen", "Mingxiang", ""], ["Wang", "Zhecheng", ""]]}, {"id": "2010.04965", "submitter": "Kiarash Mohammadi", "authors": "Kiarash Mohammadi, Amir-Hossein Karimi, Gilles Barthe, Isabel Valera", "title": "Scaling Guarantees for Nearest Counterfactual Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual explanations (CFE) are being widely used to explain\nalgorithmic decisions, especially in consequential decision-making contexts\n(e.g., loan approval or pretrial bail). In this context, CFEs aim to provide\nindividuals affected by an algorithmic decision with the most similar\nindividual (i.e., nearest individual) with a different outcome. However, while\nan increasing number of works propose algorithms to compute CFEs, such\napproaches either lack in optimality of distance (i.e., they do not return the\nnearest individual) and perfect coverage (i.e., they do not provide a CFE for\nall individuals); or they cannot handle complex models, such as neural\nnetworks. In this work, we provide a framework based on Mixed-Integer\nProgramming (MIP) to compute nearest counterfactual explanations with provable\nguarantees and with runtimes comparable to gradient-based approaches. Our\nexperiments on the Adult, COMPAS, and Credit datasets show that, in contrast\nwith previous methods, our approach allows for efficiently computing diverse\nCFEs with both distance guarantees and perfect coverage.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 10:05:50 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 07:15:30 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Mohammadi", "Kiarash", ""], ["Karimi", "Amir-Hossein", ""], ["Barthe", "Gilles", ""], ["Valera", "Isabel", ""]]}, {"id": "2010.04974", "submitter": "Xiangming Gu", "authors": "Xiangming Gu and Xiang Cheng", "title": "Distilling a Deep Neural Network into a Takagi-Sugeno-Kang Fuzzy\n  Inference System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) demonstrate great success in classification\ntasks. However, they act as black boxes and we don't know how they make\ndecisions in a particular classification task. To this end, we propose to\ndistill the knowledge from a DNN into a fuzzy inference system (FIS), which is\nTakagi-Sugeno-Kang (TSK)-type in this paper. The model has the capability to\nexpress the knowledge acquired by a DNN based on fuzzy rules, thus explaining a\nparticular decision much easier. Knowledge distillation (KD) is applied to\ncreate a TSK-type FIS that generalizes better than one directly from the\ntraining data, which is guaranteed through experiments in this paper. To\nfurther improve the performances, we modify the baseline method of KD and\nobtain good results.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 10:58:05 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Gu", "Xiangming", ""], ["Cheng", "Xiang", ""]]}, {"id": "2010.04990", "submitter": "Yassine Himeur", "authors": "Christos Sardianos and Iraklis Varlamis and Christos Chronis and\n  George Dimitrakopoulos and Abdullah Alsalemi and Yassine Himeur and Faycal\n  Bensaali and Abbes Amira", "title": "The emergence of Explainability of Intelligent Systems: Delivering\n  Explainable and Personalised Recommendations for Energy Efficiency", "comments": "19 pages, 8 figures, 1 table", "journal-ref": "International Journal of Intelligent Systems, 2020", "doi": "10.1002/int.22314", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in artificial intelligence namely in machine learning and\ndeep learning, have boosted the performance of intelligent systems in several\nways. This gave rise to human expectations, but also created the need for a\ndeeper understanding of how intelligent systems think and decide. The concept\nof explainability appeared, in the extent of explaining the internal system\nmechanics in human terms. Recommendation systems are intelligent systems that\nsupport human decision making, and as such, they have to be explainable in\norder to increase user trust and improve the acceptance of recommendations. In\nthis work, we focus on a context-aware recommendation system for energy\nefficiency and develop a mechanism for explainable and persuasive\nrecommendations, which are personalized to user preferences and habits. The\npersuasive facts either emphasize on the economical saving prospects (Econ) or\non a positive ecological impact (Eco) and explanations provide the reason for\nrecommending an energy saving action. Based on a study conducted using a\nTelegram bot, different scenarios have been validated with actual data and\nhuman feedback. Current results show a total increase of 19\\% on the\nrecommendation acceptance ratio when both economical and ecological persuasive\nfacts are employed. This revolutionary approach on recommendation systems,\ndemonstrates how intelligent recommendations can effectively encourage energy\nsaving behavior.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 13:11:43 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 11:25:18 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Sardianos", "Christos", ""], ["Varlamis", "Iraklis", ""], ["Chronis", "Christos", ""], ["Dimitrakopoulos", "George", ""], ["Alsalemi", "Abdullah", ""], ["Himeur", "Yassine", ""], ["Bensaali", "Faycal", ""], ["Amira", "Abbes", ""]]}, {"id": "2010.04992", "submitter": "Ehsan Mokhtarian", "authors": "Ehsan Mokhtarian, Sina Akbari, AmirEmad Ghassami, Negar Kiyavash", "title": "A Recursive Markov Boundary-Based Approach to Causal Structure Learning", "comments": "29 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint-based methods are one of the main approaches for causal structure\nlearning that are particularly valued as they are asymptotically guaranteed to\nfind a structure that is Markov equivalent to the causal graph of the system.\nOn the other hand, they may require an exponentially large number of\nconditional independence (CI) tests in the number of variables of the system.\nIn this paper, we propose a novel recursive constraint-based method for causal\nstructure learning that significantly reduces the required number of CI tests\ncompared to the existing literature. The idea of the proposed approach is to\nuse Markov boundary information to identify a specific variable that can be\nremoved from the set of variables without affecting the statistical\ndependencies among the other variables. Having identified such a variable, we\ndiscover its neighborhood, remove that variable from the set of variables, and\nrecursively learn the causal structure over the remaining variables. We further\nprovide a lower bound on the number of CI tests required by any\nconstraint-based method. Comparing this lower bound to our achievable bound\ndemonstrates the efficiency of the proposed approach. Our experimental results\nshow that the proposed algorithm outperforms state-of-the-art both on synthetic\nand real-world structures.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 13:26:22 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 23:05:04 GMT"}, {"version": "v3", "created": "Fri, 21 May 2021 02:37:14 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Mokhtarian", "Ehsan", ""], ["Akbari", "Sina", ""], ["Ghassami", "AmirEmad", ""], ["Kiyavash", "Negar", ""]]}, {"id": "2010.05001", "submitter": "Wanqing Cui", "authors": "Wanqing Cui, Yanyan Lan, Liang Pang, Jiafeng Guo, Xueqi Cheng", "title": "Beyond Language: Learning Commonsense from Images for Reasoning", "comments": "Accepted to EMNLP'20 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel approach to learn commonsense from images,\ninstead of limited raw texts or costly constructed knowledge bases, for the\ncommonsense reasoning problem in NLP. Our motivation comes from the fact that\nan image is worth a thousand words, where richer scene information could be\nleveraged to help distill the commonsense knowledge, which is often hidden in\nlanguages. Our approach, namely Loire, consists of two stages. In the first\nstage, a bi-modal sequence-to-sequence approach is utilized to conduct the\nscene layout generation task, based on a text representation model ViBERT. In\nthis way, the required visual scene knowledge, such as spatial relations, will\nbe encoded in ViBERT by the supervised learning process with some bi-modal data\nlike COCO. Then ViBERT is concatenated with a pre-trained language model to\nperform the downstream commonsense reasoning tasks. Experimental results on two\ncommonsense reasoning problems, i.e. commonsense question answering and pronoun\nresolution, demonstrate that Loire outperforms traditional language-based\nmethods. We also give some case studies to show what knowledge is learned from\nimages and explain how the generated scene layout helps the commonsense\nreasoning process.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 13:47:13 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Cui", "Wanqing", ""], ["Lan", "Yanyan", ""], ["Pang", "Liang", ""], ["Guo", "Jiafeng", ""], ["Cheng", "Xueqi", ""]]}, {"id": "2010.05006", "submitter": "Xinyu Wang", "authors": "Xinyu Wang, Yong Jiang, Nguyen Bach, Tao Wang, Zhongqiang Huang, Fei\n  Huang, Kewei Tu", "title": "Automated Concatenation of Embeddings for Structured Prediction", "comments": "Accepted to Proceedings of ACL-IJCNLP 2021. 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Pretrained contextualized embeddings are powerful word representations for\nstructured prediction tasks. Recent work found that better word representations\ncan be obtained by concatenating different types of embeddings. However, the\nselection of embeddings to form the best concatenated representation usually\nvaries depending on the task and the collection of candidate embeddings, and\nthe ever-increasing number of embedding types makes it a more difficult\nproblem. In this paper, we propose Automated Concatenation of Embeddings (ACE)\nto automate the process of finding better concatenations of embeddings for\nstructured prediction tasks, based on a formulation inspired by recent progress\non neural architecture search. Specifically, a controller alternately samples a\nconcatenation of embeddings, according to its current belief of the\neffectiveness of individual embedding types in consideration for a task, and\nupdates the belief based on a reward. We follow strategies in reinforcement\nlearning to optimize the parameters of the controller and compute the reward\nbased on the accuracy of a task model, which is fed with the sampled\nconcatenation as input and trained on a task dataset. Empirical results on 6\ntasks and 21 datasets show that our approach outperforms strong baselines and\nachieves state-of-the-art performance with fine-tuned embeddings in all the\nevaluations.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 14:03:20 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 06:30:35 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 11:15:40 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2021 13:23:25 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Wang", "Xinyu", ""], ["Jiang", "Yong", ""], ["Bach", "Nguyen", ""], ["Wang", "Tao", ""], ["Huang", "Zhongqiang", ""], ["Huang", "Fei", ""], ["Tu", "Kewei", ""]]}, {"id": "2010.05010", "submitter": "Xinyu Wang", "authors": "Xinyu Wang, Yong Jiang, Zhaohui Yan, Zixia Jia, Nguyen Bach, Tao Wang,\n  Zhongqiang Huang, Fei Huang, Kewei Tu", "title": "Structural Knowledge Distillation: Tractably Distilling Information for\n  Structured Predictor", "comments": "Accepted to Proceedings of ACL-IJCNLP 2021. 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge distillation is a critical technique to transfer knowledge between\nmodels, typically from a large model (the teacher) to a more fine-grained one\n(the student). The objective function of knowledge distillation is typically\nthe cross-entropy between the teacher and the student's output distributions.\nHowever, for structured prediction problems, the output space is exponential in\nsize; therefore, the cross-entropy objective becomes intractable to compute and\noptimize directly. In this paper, we derive a factorized form of the knowledge\ndistillation objective for structured prediction, which is tractable for many\ntypical choices of the teacher and student models. In particular, we show the\ntractability and empirical effectiveness of structural knowledge distillation\nbetween sequence labeling and dependency parsing models under four different\nscenarios: 1) the teacher and student share the same factorization form of the\noutput structure scoring function; 2) the student factorization produces more\nfine-grained substructures than the teacher factorization; 3) the teacher\nfactorization produces more fine-grained substructures than the student\nfactorization; 4) the factorization forms from the teacher and the student are\nincompatible.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 14:19:25 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 12:07:25 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 13:31:22 GMT"}, {"version": "v4", "created": "Wed, 2 Jun 2021 02:31:19 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Wang", "Xinyu", ""], ["Jiang", "Yong", ""], ["Yan", "Zhaohui", ""], ["Jia", "Zixia", ""], ["Bach", "Nguyen", ""], ["Wang", "Tao", ""], ["Huang", "Zhongqiang", ""], ["Huang", "Fei", ""], ["Tu", "Kewei", ""]]}, {"id": "2010.05013", "submitter": "Lidia Talavera-Martinez", "authors": "Lidia Talavera-Mart\\'inez, Pedro Bibiloni, Manuel Gonz\\'alez-Hidalgo", "title": "An Encoder-Decoder CNN for Hair Removal in Dermoscopic Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of removing occluding hair has a relevant role in the early and\naccurate diagnosis of skin cancer. It consists of detecting hairs and restore\nthe texture below them, which is sporadically occluded. In this work, we\npresent a model based on convolutional neural networks for hair removal in\ndermoscopic images. During the network's training, we use a combined loss\nfunction to improve the restoration ability of the proposed model. In order to\ntrain the CNN and to quantitatively validate their performance, we simulate the\npresence of skin hair in hairless images extracted from publicly known datasets\nsuch as the PH2, dermquest, dermis, EDRA2002, and the ISIC Data Archive. As far\nas we know, there is no other hair removal method based on deep learning. Thus,\nwe compare our results with six state-of-the-art algorithms based on\ntraditional computer vision techniques by means of similarity measures that\ncompare the reference hairless image and the one with hair simulated. Finally,\na statistical test is used to compare the methods. Both qualitative and\nquantitative results demonstrate the effectiveness of our network.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 14:28:10 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Talavera-Mart\u00ednez", "Lidia", ""], ["Bibiloni", "Pedro", ""], ["Gonz\u00e1lez-Hidalgo", "Manuel", ""]]}, {"id": "2010.05024", "submitter": "Mingming Liu", "authors": "Beiran Chen, Yi Zhang, George Iosifidis, Mingming Liu", "title": "Reinforcement Learning on Computational Resource Allocation of\n  Cloud-based Wireless Networks", "comments": "This paper has been accepted by the IEEE 6th World Forum on Internet\n  of Things conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Wireless networks used for Internet of Things (IoT) are expected to largely\ninvolve cloud-based computing and processing. Softwarised and centralised\nsignal processing and network switching in the cloud enables flexible network\ncontrol and management. In a cloud environment, dynamic computational resource\nallocation is essential to save energy while maintaining the performance of the\nprocesses. The stochastic features of the Central Processing Unit (CPU) load\nvariation as well as the possible complex parallelisation situations of the\ncloud processes makes the dynamic resource allocation an interesting research\nchallenge. This paper models this dynamic computational resource allocation\nproblem into a Markov Decision Process (MDP) and designs a model-based\nreinforcement-learning agent to optimise the dynamic resource allocation of the\nCPU usage. Value iteration method is used for the reinforcement-learning agent\nto pick up the optimal policy during the MDP. To evaluate our performance we\nanalyse two types of processes that can be used in the cloud-based IoT networks\nwith different levels of parallelisation capabilities, i.e., Software-Defined\nRadio (SDR) and Software-Defined Networking (SDN). The results show that our\nagent rapidly converges to the optimal policy, stably performs in different\nparameter settings, outperforms or at least equally performs compared to a\nbaseline algorithm in energy savings for different scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 15:16:26 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Chen", "Beiran", ""], ["Zhang", "Yi", ""], ["Iosifidis", "George", ""], ["Liu", "Mingming", ""]]}, {"id": "2010.05042", "submitter": "Daniel Foguelman", "authors": "Daniel J. Foguelman, Philipp Henning, Adelinde Uhrmacher, and Rodrigo\n  Castro", "title": "EB-DEVS: A Formal Framework for Modeling and Simulation of Emergent\n  Behavior in Dynamic Complex Systems", "comments": "38 page document with: original content 25 pages, references 3 pages,\n  appendices 10 pages", "journal-ref": "Journal of Computational Science Volume 53, July 2021, 101387", "doi": "10.1016/j.jocs.2021.101387", "report-no": null, "categories": "cs.MA cs.AI nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergent behavior is a key feature defining a system under study as a complex\nsystem. Simulation has been recognized as the only way to deal with the study\nof the emergency of properties (at a macroscopic level) among groups of system\ncomponents (at a microscopic level), for the manifestations of emergent\nstructures cannot be deduced from analysing components in isolation. A\nsystems-oriented generalisation must consider the presence of feedback loops\n(micro components react to macro properties), interaction among components of\ndifferent classes (modular composition) and layered interaction of subsystems\noperating at different spatio-temporal scales (hierarchical organisation). In\nthis work we introduce Emergent Behavior-DEVS (EB-DEVS) a Modeling and\nSimulation (M&S) formalism that permits reasoning about complex systems where\nemergent behavior is placed at the forefront of the analysis activity. EB-DEVS\nbuilds on the DEVS formalism, adding upward/downward communication channels to\nwell-established capabilities for modular and hierarchical M&S of heterogeneous\nmulti-formalism systems. EB-DEVS takes a minimalist stance on expressiveness,\nintroducing a small set of extensions on Classic DEVS that can cope with\nemergent behavior, and making both formalisms interoperable (the modeler\ndecides which subsystems deserve to be expressed via micro-macro dynamics). We\npresent three case studies: flocks of birds with learning, population epidemics\nwith vaccination and sub-cellular dynamics with homeostasis, through which we\nshowcase how EB-DEVS performs by placing emergent properties at the center of\nthe M&S process.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 16:39:41 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 22:54:20 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Foguelman", "Daniel J.", ""], ["Henning", "Philipp", ""], ["Uhrmacher", "Adelinde", ""], ["Castro", "Rodrigo", ""]]}, {"id": "2010.05045", "submitter": "Quanshi Zhang", "authors": "Hao Zhang, Yichen Xie, Longjie Zheng, Die Zhang, Quanshi Zhang", "title": "Interpreting Multivariate Shapley Interactions in DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to explain deep neural networks (DNNs) from the perspective\nof multivariate interactions. In this paper, we define and quantify the\nsignificance of interactions among multiple input variables of the DNN. Input\nvariables with strong interactions usually form a coalition and reflect\nprototype features, which are memorized and used by the DNN for inference. We\ndefine the significance of interactions based on the Shapley value, which is\ndesigned to assign the attribution value of each input variable to the\ninference. We have conducted experiments with various DNNs. Experimental\nresults have demonstrated the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 17:02:51 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 05:51:48 GMT"}, {"version": "v3", "created": "Sat, 16 Jan 2021 15:14:41 GMT"}, {"version": "v4", "created": "Wed, 3 Feb 2021 09:12:47 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Zhang", "Hao", ""], ["Xie", "Yichen", ""], ["Zheng", "Longjie", ""], ["Zhang", "Die", ""], ["Zhang", "Quanshi", ""]]}, {"id": "2010.05050", "submitter": "Yicheng Luo", "authors": "Yicheng Luo, Antonio Filieri, Yuan Zhou", "title": "Symbolic Parallel Adaptive Importance Sampling for Probabilistic Program\n  Analysis", "comments": "Extended pre-print version of ESEC/FSE '21 paper", "journal-ref": null, "doi": "10.1145/3468264.3468593", "report-no": null, "categories": "cs.LG cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic software analysis aims at quantifying the probability of a\ntarget event occurring during the execution of a program processing uncertain\nincoming data or written itself using probabilistic programming constructs.\nRecent techniques combine symbolic execution with model counting or solution\nspace quantification methods to obtain accurate estimates of the occurrence\nprobability of rare target events, such as failures in a mission-critical\nsystem. However, they face several scalability and applicability limitations\nwhen analyzing software processing with high-dimensional and correlated\nmultivariate input distributions. In this paper, we present SYMbolic Parallel\nAdaptive Importance Sampling (SYMPAIS), a new inference method tailored to\nanalyze path conditions generated from the symbolic execution of programs with\nhigh-dimensional, correlated input distributions. SYMPAIS combines results from\nimportance sampling and constraint solving to produce accurate estimates of the\nsatisfaction probability for a broad class of constraints that cannot be\nanalyzed by current solution space quantification methods. We demonstrate\nSYMPAIS's generality and performance compared with state-of-the-art\nalternatives on a set of problems from different application domains.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 17:39:12 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 19:32:14 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Luo", "Yicheng", ""], ["Filieri", "Antonio", ""], ["Zhou", "Yuan", ""]]}, {"id": "2010.05090", "submitter": "Kunal Chawla", "authors": "Kunal Chawla, Diyi Yang", "title": "Semi-supervised Formality Style Transfer using Language Model\n  Discriminator and Mutual Information Maximization", "comments": "EMNLP 2020 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formality style transfer is the task of converting informal sentences to\ngrammatically-correct formal sentences, which can be used to improve\nperformance of many downstream NLP tasks. In this work, we propose a\nsemi-supervised formality style transfer model that utilizes a language\nmodel-based discriminator to maximize the likelihood of the output sentence\nbeing formal, which allows us to use maximization of token-level conditional\nprobabilities for training. We further propose to maximize mutual information\nbetween source and target styles as our training objective instead of\nmaximizing the regular likelihood that often leads to repetitive and trivial\ngenerated responses. Experiments showed that our model outperformed previous\nstate-of-the-art baselines significantly in terms of both automated metrics and\nhuman judgement. We further generalized our model to unsupervised text style\ntransfer task, and achieved significant improvements on two benchmark sentiment\nstyle transfer datasets.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 21:05:56 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Chawla", "Kunal", ""], ["Yang", "Diyi", ""]]}, {"id": "2010.05115", "submitter": "Henry Chen", "authors": "Henry Chen, Robin Cohen, Kerstin Dautenhahn, Edith Law, Krzysztof\n  Czarnecki", "title": "Autonomous Vehicle Visual Signals for Pedestrians: Experiments and\n  Design Recommendations", "comments": "The 31st IEEE Intelligent Vehicles Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.MA cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous Vehicles (AV) will transform transportation, but also the\ninteraction between vehicles and pedestrians. In the absence of a driver, it is\nnot clear how an AV can communicate its intention to pedestrians. One option is\nto use visual signals. To advance their design, we conduct four\nhuman-participant experiments and evaluate six representative AV visual signals\nfor visibility, intuitiveness, persuasiveness, and usability at pedestrian\ncrossings. Based on the results, we distill twelve practical design\nrecommendations for AV visual signals, with focus on signal pattern design and\nplacement. Moreover, the paper advances the methodology for experimental\nevaluation of visual signals, including lab, closed-course, and public road\ntests using an autonomous vehicle. In addition, the paper also reports insights\non pedestrian crosswalk behaviours and the impacts of pedestrian trust towards\nAVs on the behaviors. We hope that this work will constitute valuable input to\nthe ongoing development of international standards for AV lamps, and thus help\nmature automated driving in general.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 22:56:46 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Chen", "Henry", ""], ["Cohen", "Robin", ""], ["Dautenhahn", "Kerstin", ""], ["Law", "Edith", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "2010.05123", "submitter": "Jatin Sharma", "authors": "Jatin Sharma and Jon Campbell and Pete Ansell and Jay Beavers and\n  Christopher O'Dowd", "title": "Towards Hardware-Agnostic Gaze-Trackers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaze-tracking is a novel way of interacting with computers which allows new\nscenarios, such as enabling people with motor-neuron disabilities to control\ntheir computers or doctors to interact with patient information without\ntouching screen or keyboard. Further, there are emerging applications of\ngaze-tracking in interactive gaming, user experience research, human attention\nanalysis and behavioral studies. Accurate estimation of the gaze may involve\naccounting for head-pose, head-position, eye rotation, distance from the object\nas well as operating conditions such as illumination, occlusion, background\nnoise and various biological aspects of the user. Commercially available\ngaze-trackers utilize specialized sensor assemblies that usually consist of an\ninfrared light source and camera. There are several challenges in the universal\nproliferation of gaze-tracking as accessibility technologies, specifically its\naffordability, reliability, and ease-of-use. In this paper, we try to address\nthese challenges through the development of a hardware-agnostic gaze-tracker.\nWe present a deep neural network architecture as an appearance-based method for\nconstrained gaze-tracking that utilizes facial imagery captured on an ordinary\nRGB camera ubiquitous in all modern computing devices. Our system achieved an\nerror of 1.8073cm on GazeCapture dataset without any calibration or device\nspecific fine-tuning. This research shows promise that one day soon any\ncomputer, tablet, or phone will be controllable using just your eyes due to the\nprediction capabilities of deep neutral networks.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 00:53:57 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Sharma", "Jatin", ""], ["Campbell", "Jon", ""], ["Ansell", "Pete", ""], ["Beavers", "Jay", ""], ["O'Dowd", "Christopher", ""]]}, {"id": "2010.05125", "submitter": "Keji Han", "authors": "Keji Han and Yun Li", "title": "Is It Time to Redefine the Classification Task for Deep Neural Networks?", "comments": "9 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) is demonstrated to be vulnerable to the\nadversarial example, which is generated by adding small adversarial\nperturbation into the original legitimate example to cause the wrong outputs of\nDNNs. Nowadays, most works focus on the robustness of the deep model, while few\nworks pay attention to the robustness of the learning task itself defined on\nDNNs. So we redefine this issue as the robustness of deep neural learning\nsystem. A deep neural learning system consists of the deep model and the\nlearning task defined on the deep model. Moreover, the deep model is usually a\ndeep neural network, involving the model architecture, data, training loss and\ntraining algorithm. We speculate that the vulnerability of the deep learning\nsystem also roots in the learning task itself. This paper defines the\ninterval-label classification task for the deep classification system, whose\nlabels are predefined non-overlapping intervals, instead of a fixed value (hard\nlabel) or probability vector (soft label). The experimental results demonstrate\nthat the interval-label classification task is more robust than the traditional\nclassification task while retaining accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 01:06:49 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Han", "Keji", ""], ["Li", "Yun", ""]]}, {"id": "2010.05134", "submitter": "Fan Xie", "authors": "Fan Xie, Alexander Chowdhury, M. Clara De Paolis Kaluza, Linfeng Zhao,\n  Lawson L.S. Wong, Rose Yu", "title": "Deep Imitation Learning for Bimanual Robotic Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep imitation learning framework for robotic bimanual\nmanipulation in a continuous state-action space. A core challenge is to\ngeneralize the manipulation skills to objects in different locations. We\nhypothesize that modeling the relational information in the environment can\nsignificantly improve generalization. To achieve this, we propose to (i)\ndecompose the multi-modal dynamics into elemental movement primitives, (ii)\nparameterize each primitive using a recurrent graph neural network to capture\ninteractions, and (iii) integrate a high-level planner that composes primitives\nsequentially and a low-level controller to combine primitive dynamics and\ninverse kinematics control. Our model is a deep, hierarchical, modular\narchitecture. Compared to baselines, our model generalizes better and achieves\nhigher success rates on several simulated bimanual robotic manipulation tasks.\nWe open source the code for simulation, data, and models at:\nhttps://github.com/Rose-STL-Lab/HDR-IL.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 01:40:03 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 21:16:36 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Xie", "Fan", ""], ["Chowdhury", "Alexander", ""], ["Kaluza", "M. Clara De Paolis", ""], ["Zhao", "Linfeng", ""], ["Wong", "Lawson L. S.", ""], ["Yu", "Rose", ""]]}, {"id": "2010.05150", "submitter": "Tsung-Yen Yang", "authors": "Tsung-Yen Yang and Michael Hu and Yinlam Chow and Peter J. Ramadge and\n  Karthik Narasimhan", "title": "Safe Reinforcement Learning with Natural Language Constraints", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle the problem of learning control policies for tasks\nwhen provided with constraints in natural language. In contrast to instruction\nfollowing, language here is used not to specify goals, but rather to describe\nsituations that an agent must avoid during its exploration of the environment.\nSpecifying constraints in natural language also differs from the predominant\nparadigm in safe reinforcement learning, where safety criteria are enforced by\nhand-defined cost functions. While natural language allows for easy and\nflexible specification of safety constraints and budget limitations, its\nambiguous nature presents a challenge when mapping these specifications into\nrepresentations that can be used by techniques for safe reinforcement learning.\nTo address this, we develop a model that contains two components: (1) a\nconstraint interpreter to encode natural language constraints into vector\nrepresentations capturing spatial and temporal information on forbidden states,\nand (2) a policy network that uses these representations to output a policy\nwith minimal constraint violations. Our model is end-to-end differentiable and\nwe train it using a recently proposed algorithm for constrained policy\noptimization. To empirically demonstrate the effectiveness of our approach, we\ncreate a new benchmark task for autonomous navigation with crowd-sourced\nfree-form text specifying three different types of constraints. Our method\noutperforms several baselines by achieving 6-7 times higher returns and 76%\nfewer constraint violations on average. Dataset and code to reproduce our\nexperiments are available at https://sites.google.com/view/polco-hazard-world/.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 03:41:56 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Yang", "Tsung-Yen", ""], ["Hu", "Michael", ""], ["Chow", "Yinlam", ""], ["Ramadge", "Peter J.", ""], ["Narasimhan", "Karthik", ""]]}, {"id": "2010.05154", "submitter": "Rohan Ramanath", "authors": "Rohan Ramanath, Konstantin Salomatin, Jeffrey D. Gee, Kirill Talanine,\n  Onkar Dalal, Gungor Polatkan, Sara Smoot, Deepak Kumar", "title": "Lambda Learner: Fast Incremental Learning on Data Streams", "comments": null, "journal-ref": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining, 2021", "doi": "10.1145/3447548.3467172", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the most well-established applications of machine learning is in\ndeciding what content to show website visitors. When observation data comes\nfrom high-velocity, user-generated data streams, machine learning methods\nperform a balancing act between model complexity, training time, and\ncomputational costs. Furthermore, when model freshness is critical, the\ntraining of models becomes time-constrained. Parallelized batch offline\ntraining, although horizontally scalable, is often not time-considerate or\ncost-effective. In this paper, we propose Lambda Learner, a new framework for\ntraining models by incremental updates in response to mini-batches from data\nstreams. We show that the resulting model of our framework closely estimates a\nperiodically updated model trained on offline data and outperforms it when\nmodel updates are time-sensitive. We provide theoretical proof that the\nincremental learning updates improve the loss-function over a stale batch\nmodel. We present a large-scale deployment on the sponsored content platform\nfor a large social network, serving hundreds of millions of users across\ndifferent channels (e.g., desktop, mobile). We address challenges and\ncomplexities from both algorithms and infrastructure perspectives, and\nillustrate the system details for computation, storage, and streaming\nproduction of training data.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 04:00:34 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 14:27:01 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ramanath", "Rohan", ""], ["Salomatin", "Konstantin", ""], ["Gee", "Jeffrey D.", ""], ["Talanine", "Kirill", ""], ["Dalal", "Onkar", ""], ["Polatkan", "Gungor", ""], ["Smoot", "Sara", ""], ["Kumar", "Deepak", ""]]}, {"id": "2010.05172", "submitter": "Yucheng Yang", "authors": "Yucheng Yang, Yue Pang, Guanhua Huang, Weinan E", "title": "The Knowledge Graph for Macroeconomic Analysis with Alternative Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.AI q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current knowledge system of macroeconomics is built on interactions among\na small number of variables, since traditional macroeconomic models can mostly\nhandle a handful of inputs. Recent work using big data suggests that a much\nlarger number of variables are active in driving the dynamics of the aggregate\neconomy. In this paper, we introduce a knowledge graph (KG) that consists of\nnot only linkages between traditional economic variables but also new\nalternative big data variables. We extract these new variables and the linkages\nby applying advanced natural language processing (NLP) tools on the massive\ntextual data of academic literature and research reports. As one example of the\npotential applications, we use it as the prior knowledge to select variables\nfor economic forecasting models in macroeconomics. Compared to statistical\nvariable selection methods, KG-based methods achieve significantly higher\nforecasting accuracy, especially for long run forecasts.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 05:40:22 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Yang", "Yucheng", ""], ["Pang", "Yue", ""], ["Huang", "Guanhua", ""], ["E", "Weinan", ""]]}, {"id": "2010.05176", "submitter": "Alexander Hadjiivanov", "authors": "Alexander Hadjiivanov and Alan Blair", "title": "Complexity-based speciation and genotype representation for\n  neuroevolution", "comments": null, "journal-ref": "2016 IEEE Congress on Evolutionary Computation (CEC), Vancouver,\n  BC, 2016, pp. 3092-3101", "doi": "10.1109/CEC.2016.7744180", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a speciation principle for neuroevolution where\nevolving networks are grouped into species based on the number of hidden\nneurons, which is indicative of the complexity of the search space. This\nspeciation principle is indivisibly coupled with a novel genotype\nrepresentation which is characterised by zero genome redundancy, high\nresilience to bloat, explicit marking of recurrent connections, as well as an\nefficient and reproducible stack-based evaluation procedure for networks with\narbitrary topology. Furthermore, the proposed speciation principle is employed\nin several techniques designed to promote and preserve diversity within species\nand in the ecosystem as a whole. The competitive performance of the proposed\nframework, named Cortex, is demonstrated through experiments. A highly\ncustomisable software platform which implements the concepts proposed in this\nstudy is also introduced in the hope that it will serve as a useful and\nreliable tool for experimentation in the field of neuroevolution.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 06:26:56 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Hadjiivanov", "Alexander", ""], ["Blair", "Alan", ""]]}, {"id": "2010.05180", "submitter": "Zhengxian Lin", "authors": "Zhengxian Lin, Kim-Ho Lam and Alan Fern", "title": "Contrastive Explanations for Reinforcement Learning via Embedded Self\n  Predictions", "comments": "Published (Oral) at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a deep reinforcement learning (RL) architecture that supports\nexplaining why a learned agent prefers one action over another. The key idea is\nto learn action-values that are directly represented via human-understandable\nproperties of expected futures. This is realized via the embedded\nself-prediction (ESP)model, which learns said properties in terms of human\nprovided features. Action preferences can then be explained by contrasting the\nfuture properties predicted for each action. To address cases where there are a\nlarge number of features, we develop a novel method for computing minimal\nsufficient explanations from anESP. Our case studies in three domains,\nincluding a complex strategy game, show that ESP models can be effectively\nlearned and support insightful explanations.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 07:02:20 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2021 08:53:22 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Lin", "Zhengxian", ""], ["Lam", "Kim-Ho", ""], ["Fern", "Alan", ""]]}, {"id": "2010.05185", "submitter": "Chenhui Chu", "authors": "Chenhui Chu, Yuto Takebayashi, Mishra Vipul, Yuta Nakashima", "title": "Constructing a Visual Relationship Authenticity Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A visual relationship denotes a relationship between two objects in an image,\nwhich can be represented as a triplet of (subject; predicate; object). Visual\nrelationship detection is crucial for scene understanding in images. Existing\nvisual relationship detection datasets only contain true relationships that\ncorrectly describe the content in an image. However, distinguishing false\nvisual relationships from true ones is also crucial for image understanding and\ngrounded natural language processing. In this paper, we construct a visual\nrelationship authenticity dataset, where both true and false relationships\namong all objects appeared in the captions in the Flickr30k entities image\ncaption dataset are annotated. The dataset is available at\nhttps://github.com/codecreator2053/VR_ClassifiedDataset. We hope that this\ndataset can promote the study on both vision and language understanding.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 07:38:33 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Chu", "Chenhui", ""], ["Takebayashi", "Yuto", ""], ["Vipul", "Mishra", ""], ["Nakashima", "Yuta", ""]]}, {"id": "2010.05190", "submitter": "Siddharth Karamcheti", "authors": "Siddharth Karamcheti, Dorsa Sadigh, Percy Liang", "title": "Learning Adaptive Language Interfaces through Decomposition", "comments": "Accepted at the 1st Workshop for Interactive and Executable Semantic\n  Parsing (IntEx-SemPar) @ EMNLP 2020. 11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to create an interactive natural language interface that\nefficiently and reliably learns from users to complete tasks in simulated\nrobotics settings. We introduce a neural semantic parsing system that learns\nnew high-level abstractions through decomposition: users interactively teach\nthe system by breaking down high-level utterances describing novel behavior\ninto low-level steps that it can understand. Unfortunately, existing methods\neither rely on grammars which parse sentences with limited flexibility, or\nneural sequence-to-sequence models that do not learn efficiently or reliably\nfrom individual examples. Our approach bridges this gap, demonstrating the\nflexibility of modern neural systems, as well as the one-shot reliable\ngeneralization of grammar-based methods. Our crowdsourced interactive\nexperiments suggest that over time, users complete complex tasks more\nefficiently while using our system by leveraging what they just taught. At the\nsame time, getting users to trust the system enough to be incentivized to teach\nhigh-level utterances is still an ongoing challenge. We end with a discussion\nof some of the obstacles we need to overcome to fully realize the potential of\nthe interactive paradigm.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 08:27:07 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Karamcheti", "Siddharth", ""], ["Sadigh", "Dorsa", ""], ["Liang", "Percy", ""]]}, {"id": "2010.05193", "submitter": "Chenhui Chu", "authors": "Vipul Mishra, Chenhui Chu and Yuki Arase", "title": "Lexically Cohesive Neural Machine Translation with Copy Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexically cohesive translations preserve consistency in word choices in\ndocument-level translation. We employ a copy mechanism into a context-aware\nneural machine translation model to allow copying words from previous\ntranslation outputs. Different from previous context-aware neural machine\ntranslation models that handle all the discourse phenomena implicitly, our\nmodel explicitly addresses the lexical cohesion problem by boosting the\nprobabilities to output words consistently. We conduct experiments on Japanese\nto English translation using an evaluation dataset for discourse translation.\nThe results showed that the proposed model significantly improved lexical\ncohesion compared to previous context-aware models.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 08:39:02 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Mishra", "Vipul", ""], ["Chu", "Chenhui", ""], ["Arase", "Yuki", ""]]}, {"id": "2010.05202", "submitter": "Wangchunshu Zhou", "authors": "Qifei Li and Wangchunshu Zhou", "title": "Connecting the Dots Between Fact Verification and Fake News Detection", "comments": "Accepted to COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact verification models have enjoyed a fast advancement in the last two\nyears with the development of pre-trained language models like BERT and the\nrelease of large scale datasets such as FEVER. However, the challenging problem\nof fake news detection has not benefited from the improvement of fact\nverification models, which is closely related to fake news detection. In this\npaper, we propose a simple yet effective approach to connect the dots between\nfact verification and fake news detection. Our approach first employs a text\nsummarization model pre-trained on news corpora to summarize the long news\narticle into a short claim. Then we use a fact verification model pre-trained\non the FEVER dataset to detect whether the input news article is real or fake.\nOur approach makes use of the recent success of fact verification models and\nenables zero-shot fake news detection, alleviating the need of large-scale\ntraining data to train fake news detection models. Experimental results on\nFakenewsNet, a benchmark dataset for fake news detection, demonstrate the\neffectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 09:28:52 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Li", "Qifei", ""], ["Zhou", "Wangchunshu", ""]]}, {"id": "2010.05213", "submitter": "Sarika Jain", "authors": "Sarika Jain", "title": "Exploiting Knowledge Graphs for Facilitating Product/Service Discovery", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing techniques to product discovery rely on syntactic\napproaches, thus ignoring valuable and specific semantic information of the\nunderlying standards during the process. The product data comes from different\nheterogeneous sources and formats giving rise to the problem of\ninteroperability. Above all, due to the continuously increasing influx of data,\nthe manual labeling is getting costlier. Integrating the descriptions of\ndifferent products into a single representation requires organizing all the\nproducts across vendors in a single taxonomy. Practically relevant and quality\nproduct categorization standards are still limited in number; and that too in\nacademic research projects where we can majorly see only prototypes as compared\nto industry. This work presents a cost-effective solution for e-commerce on the\nData Web by employing an unsupervised approach for data classification and\nexploiting the knowledge graphs for matching. The proposed architecture\ndescribes available products in web ontology language OWL and stores them in a\ntriple store. User input specifications for certain products are matched\nagainst the available product categories to generate a knowledge graph. This\nmullti-phased top-down approach to develop and improve existing, if any,\ntailored product recommendations will be able to connect users with the exact\nproduct/service of their choice.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 10:22:10 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Jain", "Sarika", ""]]}, {"id": "2010.05234", "submitter": "Isaac Ronald Ward", "authors": "Isaac Ronald Ward, Jack Joyner, Casey Lickfold, Stash Rowe, Yulan Guo\n  and Mohammed Bennamoun", "title": "A Practical Guide to Graph Neural Networks", "comments": "28 pages, 15 figures, currently under review at ACM CSUR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have recently grown in popularity in the field\nof artificial intelligence due to their unique ability to ingest relatively\nunstructured data types as input data. Although some elements of the GNN\narchitecture are conceptually similar in operation to traditional neural\nnetworks (and neural network variants), other elements represent a departure\nfrom traditional deep learning techniques. This tutorial exposes the power and\nnovelty of GNNs to the average deep learning enthusiast by collating and\npresenting details on the motivations, concepts, mathematics, and applications\nof the most common types of GNNs. Importantly, we present this tutorial\nconcisely, alongside worked code examples, and at an introductory pace, thus\nproviding a practical and accessible guide to understanding and using GNNs.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 12:36:17 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 02:14:03 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ward", "Isaac Ronald", ""], ["Joyner", "Jack", ""], ["Lickfold", "Casey", ""], ["Rowe", "Stash", ""], ["Guo", "Yulan", ""], ["Bennamoun", "Mohammed", ""]]}, {"id": "2010.05241", "submitter": "Alexander Gorban", "authors": "Bogdan Grechuk, Alexander N. Gorban, Ivan Y. Tyukin", "title": "General stochastic separation theorems with optimal bounds", "comments": "Numerical examples and illustrations are added, minor corrections\n  extended discussion and the bibliography", "journal-ref": "Neural Networks, Volume 138, 2021, Pages 33-56", "doi": "10.1016/j.neunet.2021.01.034", "report-no": null, "categories": "cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Phenomenon of stochastic separability was revealed and used in machine\nlearning to correct errors of Artificial Intelligence (AI) systems and analyze\nAI instabilities. In high-dimensional datasets under broad assumptions each\npoint can be separated from the rest of the set by simple and robust Fisher's\ndiscriminant (is Fisher separable). Errors or clusters of errors can be\nseparated from the rest of the data. The ability to correct an AI system also\nopens up the possibility of an attack on it, and the high dimensionality\ninduces vulnerabilities caused by the same stochastic separability that holds\nthe keys to understanding the fundamentals of robustness and adaptivity in\nhigh-dimensional data-driven AI. To manage errors and analyze vulnerabilities,\nthe stochastic separation theorems should evaluate the probability that the\ndataset will be Fisher separable in given dimensionality and for a given class\nof distributions. Explicit and optimal estimates of these separation\nprobabilities are required, and this problem is solved in present work. The\ngeneral stochastic separation theorems with optimal probability estimates are\nobtained for important classes of distributions: log-concave distribution,\ntheir convex combinations and product distributions. The standard i.i.d.\nassumption was significantly relaxed. These theorems and estimates can be used\nboth for correction of high-dimensional data driven AI systems and for analysis\nof their vulnerabilities. The third area of application is the emergence of\nmemories in ensembles of neurons, the phenomena of grandmother's cells and\nsparse coding in the brain, and explanation of unexpected effectiveness of\nsmall neural ensembles in high-dimensional brain.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 13:12:41 GMT"}, {"version": "v2", "created": "Sat, 9 Jan 2021 19:10:17 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Grechuk", "Bogdan", ""], ["Gorban", "Alexander N.", ""], ["Tyukin", "Ivan Y.", ""]]}, {"id": "2010.05243", "submitter": "Debaditya Pal", "authors": "Debaditya Pal, Harsh Sharma, Kaustubh Chaudhari", "title": "Data Agnostic RoBERTa-based Natural Language to SQL Query Generation", "comments": "8 Pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational databases are among the most widely used architectures to store\nmassive amounts of data in the modern world. However, there is a barrier\nbetween these databases and the average user. The user often lacks the\nknowledge of a query language such as SQL required to interact with the\ndatabase. The NL2SQL task aims at finding deep learning approaches to solve\nthis problem by converting natural language questions into valid SQL queries.\nGiven the sensitive nature of some databases and the growing need for data\nprivacy, we have presented an approach with data privacy at its core. We have\npassed RoBERTa embeddings and data-agnostic knowledge vectors into LSTM based\nsubmodels to predict the final query. Although we have not achieved state of\nthe art results, we have eliminated the need for the table data, right from the\ntraining of the model, and have achieved a test set execution accuracy of\n76.7%. By eliminating the table data dependency while training we have created\na model capable of zero shot learning based on the natural language question\nand table schema alone.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 13:18:46 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 06:29:58 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 05:55:10 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Pal", "Debaditya", ""], ["Sharma", "Harsh", ""], ["Chaudhari", "Kaustubh", ""]]}, {"id": "2010.05254", "submitter": "Alexander Berndt", "authors": "Alexander Berndt, Niels Van Duijkeren, Luigi Palmieri and Tamas\n  Keviczky", "title": "A Feedback Scheme to Reorder a Multi-Agent Execution Schedule by\n  Persistently Optimizing a Switchable Action Dependency Graph", "comments": "ICAPS 2020 DMAP workshop, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider multiple Automated Guided Vehicles (AGVs)\nnavigating a common workspace to fulfill various intralogistics tasks,\ntypically formulated as the Multi-Agent Path Finding (MAPF) problem. To keep\nplan execution deadlock-free, one approach is to construct an Action Dependency\nGraph (ADG) which encodes the ordering of AGVs as they proceed along their\nroutes. Using this method, delayed AGVs occasionally require others to wait for\nthem at intersections, thereby affecting the plan execution efficiency. If the\nworkspace is shared by dynamic obstacles such as humans or third party robots,\nAGVs can experience large delays. A common mitigation approach is to re-solve\nthe MAPF using the current, delayed AGV positions. However, solving the MAPF is\ntime-consuming, making this approach inefficient, especially for large AGV\nteams. In this work, we present an online method to repeatedly modify a given\nacyclic ADG to minimize route completion times of each AGV. Our approach\npersistently maintains an acyclic ADG, necessary for deadlock-free plan\nexecution. We evaluate the approach by considering simulations with random\ndisturbances on the execution and show faster route completion times compared\nto the baseline ADG-based execution management approach.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 14:39:50 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Berndt", "Alexander", ""], ["Van Duijkeren", "Niels", ""], ["Palmieri", "Luigi", ""], ["Keviczky", "Tamas", ""]]}, {"id": "2010.05256", "submitter": "Yutai Hou", "authors": "Yutai Hou, Yongkui Lai, Yushan Wu, Wanxiang Che, Ting Liu", "title": "Few-shot Learning for Multi-label Intent Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the few-shot multi-label classification for user\nintent detection. For multi-label intent detection, state-of-the-art work\nestimates label-instance relevance scores and uses a threshold to select\nmultiple associated intent labels. To determine appropriate thresholds with\nonly a few examples, we first learn universal thresholding experience on\ndata-rich domains, and then adapt the thresholds to certain few-shot domains\nwith a calibration based on nonparametric learning. For better calculation of\nlabel-instance relevance score, we introduce label name embedding as anchor\npoints in representation space, which refines representations of different\nclasses to be well-separated from each other. Experiments on two datasets show\nthat the proposed model significantly outperforms strong baselines in both\none-shot and five-shot settings.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 14:42:18 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Hou", "Yutai", ""], ["Lai", "Yongkui", ""], ["Wu", "Yushan", ""], ["Che", "Wanxiang", ""], ["Liu", "Ting", ""]]}, {"id": "2010.05273", "submitter": "Maruan Al-Shedivat", "authors": "Maruan Al-Shedivat, Jennifer Gillenwater, Eric Xing, Afshin\n  Rostamizadeh", "title": "Federated Learning via Posterior Averaging: A New Perspective and\n  Practical Algorithms", "comments": "ICLR 2021. Code: https://github.com/alshedivat/fedpa", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is typically approached as an optimization problem, where\nthe goal is to minimize a global loss function by distributing computation\nacross client devices that possess local data and specify different parts of\nthe global objective. We present an alternative perspective and formulate\nfederated learning as a posterior inference problem, where the goal is to infer\na global posterior distribution by having client devices each infer the\nposterior of their local data. While exact inference is often intractable, this\nperspective provides a principled way to search for global optima in federated\nsettings. Further, starting with the analysis of federated quadratic\nobjectives, we develop a computation- and communication-efficient approximate\nposterior inference algorithm -- federated posterior averaging (FedPA). Our\nalgorithm uses MCMC for approximate inference of local posteriors on the\nclients and efficiently communicates their statistics to the server, where the\nlatter uses them to refine a global estimate of the posterior mode. Finally, we\nshow that FedPA generalizes federated averaging (FedAvg), can similarly benefit\nfrom adaptive optimizers, and yields state-of-the-art results on four realistic\nand challenging benchmarks, converging faster, to better optima.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 15:55:45 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 04:09:49 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 05:44:11 GMT"}, {"version": "v4", "created": "Sat, 30 Jan 2021 01:50:00 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Al-Shedivat", "Maruan", ""], ["Gillenwater", "Jennifer", ""], ["Xing", "Eric", ""], ["Rostamizadeh", "Afshin", ""]]}, {"id": "2010.05293", "submitter": "Jared Millson", "authors": "Jared Millson", "title": "A Defeasible Calculus for Zetetic Agents", "comments": null, "journal-ref": null, "doi": "10.12775/LLP.2020.019", "report-no": null, "categories": "cs.AI cs.CL math.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The study of defeasible reasoning unites epistemologists with those working\nin AI, in part, because both are interested in epistemic rationality. While it\nis traditionally thought to govern the formation and (with)holding of beliefs,\nepistemic rationality may also apply to the interrogative attitudes associated\nwith our core epistemic practice of inquiry, such as wondering, investigating,\nand curiosity. Since generally intelligent systems should be capable of\nrational inquiry, AI researchers have a natural interest in the norms that\ngovern interrogative attitudes. Following its recent coinage, we use the term\n\"zetetic\" to refer to the properties and norms associated with the capacity to\ninquire. In this paper, we argue that zetetic norms can be modeled via\ndefeasible inferences to and from questions---a.k.a erotetic inferences---in a\nmanner similar to the way norms of epistemic rationality are represented by\ndefeasible inference rules. We offer a sequent calculus that accommodates the\nunique features of \"erotetic defeat\" and that exhibits the computational\nproperties needed to inform the design of zetetic agents. The calculus\npresented here is an improved version of the one presented in Millson (2019),\nextended to cover a new class of defeasible erotetic inferences.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 17:39:03 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Millson", "Jared", ""]]}, {"id": "2010.05300", "submitter": "Yulin Wang", "authors": "Yulin Wang, Kangchen Lv, Rui Huang, Shiji Song, Le Yang, Gao Huang", "title": "Glance and Focus: a Dynamic Approach to Reducing Spatial Redundancy in\n  Image Classification", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accuracy of deep convolutional neural networks (CNNs) generally improves\nwhen fueled with high resolution images. However, this often comes at a high\ncomputational cost and high memory footprint. Inspired by the fact that not all\nregions in an image are task-relevant, we propose a novel framework that\nperforms efficient image classification by processing a sequence of relatively\nsmall inputs, which are strategically selected from the original image with\nreinforcement learning. Such a dynamic decision process naturally facilitates\nadaptive inference at test time, i.e., it can be terminated once the model is\nsufficiently confident about its prediction and thus avoids further redundant\ncomputation. Notably, our framework is general and flexible as it is compatible\nwith most of the state-of-the-art light-weighted CNNs (such as MobileNets,\nEfficientNets and RegNets), which can be conveniently deployed as the backbone\nfeature extractor. Experiments on ImageNet show that our method consistently\nimproves the computational efficiency of a wide variety of deep models. For\nexample, it further reduces the average latency of the highly efficient\nMobileNet-V3 on an iPhone XS Max by 20% without sacrificing accuracy. Code and\npre-trained models are available at\nhttps://github.com/blackfeather-wang/GFNet-Pytorch.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 17:55:06 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Wang", "Yulin", ""], ["Lv", "Kangchen", ""], ["Huang", "Rui", ""], ["Song", "Shiji", ""], ["Yang", "Le", ""], ["Huang", "Gao", ""]]}, {"id": "2010.05309", "submitter": "Peri Akiva", "authors": "Peri Akiva, Matthew Purri, Kristin Dana, Beth Tellman, Tyler Anderson", "title": "H2O-Net: Self-Supervised Flood Segmentation via Adversarial Domain\n  Adaptation and Label Refinement", "comments": "Submitted to WACV2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate flood detection in near real time via high resolution, high latency\nsatellite imagery is essential to prevent loss of lives by providing quick and\nactionable information. Instruments and sensors useful for flood detection are\nonly available in low resolution, low latency satellites with region re-visit\nperiods of up to 16 days, making flood alerting systems that use such\nsatellites unreliable. This work presents H2O-Network, a self supervised deep\nlearning method to segment floods from satellites and aerial imagery by\nbridging domain gap between low and high latency satellite and coarse-to-fine\nlabel refinement. H2O-Net learns to synthesize signals highly correlative with\nwater presence as a domain adaptation step for semantic segmentation in high\nresolution satellite imagery. Our work also proposes a self-supervision\nmechanism, which does not require any hand annotation, used during training to\ngenerate high quality ground truth data. We demonstrate that H2O-Net\noutperforms the state-of-the-art semantic segmentation methods on satellite\nimagery by 10% and 12% pixel accuracy and mIoU respectively for the task of\nflood segmentation. We emphasize the generalizability of our model by\ntransferring model weights trained on satellite imagery to drone imagery, a\nhighly different sensor and domain.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 18:35:03 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Akiva", "Peri", ""], ["Purri", "Matthew", ""], ["Dana", "Kristin", ""], ["Tellman", "Beth", ""], ["Anderson", "Tyler", ""]]}, {"id": "2010.05311", "submitter": "Zhong Zheng", "authors": "Yucheng Yang, Zhong Zheng, Weinan E", "title": "Interpretable Neural Networks for Panel Data Analysis in Economics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.AI cs.LG econ.GN q-fin.EC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of interpretability and transparency are preventing economists from\nusing advanced tools like neural networks in their empirical research. In this\npaper, we propose a class of interpretable neural network models that can\nachieve both high prediction accuracy and interpretability. The model can be\nwritten as a simple function of a regularized number of interpretable features,\nwhich are outcomes of interpretable functions encoded in the neural network.\nResearchers can design different forms of interpretable functions based on the\nnature of their tasks. In particular, we encode a class of interpretable\nfunctions named persistent change filters in the neural network to study time\nseries cross-sectional data. We apply the model to predicting individual's\nmonthly employment status using high-dimensional administrative data. We\nachieve an accuracy of 94.5% in the test set, which is comparable to the best\nperformed conventional machine learning methods. Furthermore, the\ninterpretability of the model allows us to understand the mechanism that\nunderlies the prediction: an individual's employment status is closely related\nto whether she pays different types of insurances. Our work is a useful step\ntowards overcoming the black-box problem of neural networks, and provide a new\ntool for economists to study administrative and proprietary big data.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 18:40:22 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 10:49:54 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 14:57:43 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Yang", "Yucheng", ""], ["Zheng", "Zhong", ""], ["E", "Weinan", ""]]}, {"id": "2010.05352", "submitter": "Pranav Rajpurkar", "authors": "Hari Sowrirajan, Jingbo Yang, Andrew Y. Ng, Pranav Rajpurkar", "title": "MoCo-CXR: MoCo Pretraining Improves Representation and Transferability\n  of Chest X-ray Models", "comments": "Accepted at Medical Imaging with Deep Learning (MIDL) Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contrastive learning is a form of self-supervision that can leverage\nunlabeled data to produce pretrained models. While contrastive learning has\ndemonstrated promising results on natural image classification tasks, its\napplication to medical imaging tasks like chest X-ray interpretation has been\nlimited. In this work, we propose MoCo-CXR, which is an adaptation of the\ncontrastive learning method Momentum Contrast (MoCo), to produce models with\nbetter representations and initializations for the detection of pathologies in\nchest X-rays. In detecting pleural effusion, we find that linear models trained\non MoCo-CXR-pretrained representations outperform those without\nMoCo-CXR-pretrained representations, indicating that MoCo-CXR-pretrained\nrepresentations are of higher-quality. End-to-end fine-tuning experiments\nreveal that a model initialized via MoCo-CXR-pretraining outperforms its\nnon-MoCo-CXR-pretrained counterpart. We find that MoCo-CXR-pretraining provides\nthe most benefit with limited labeled training data. Finally, we demonstrate\nsimilar results on a target Tuberculosis dataset unseen during pretraining,\nindicating that MoCo-CXR-pretraining endows models with representations and\ntransferability that can be applied across chest X-ray datasets and tasks.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 21:42:10 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 02:54:06 GMT"}, {"version": "v3", "created": "Mon, 17 May 2021 20:39:42 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Sowrirajan", "Hari", ""], ["Yang", "Jingbo", ""], ["Ng", "Andrew Y.", ""], ["Rajpurkar", "Pranav", ""]]}, {"id": "2010.05353", "submitter": "Deepak P", "authors": "Deepak P", "title": "Local Connectivity in Centroid Clustering", "comments": "In 24th International Database Engineering & Applications Symposium\n  (IDEAS 2020), August 12--14, 2020, Seoul, Republic of Korea", "journal-ref": null, "doi": "10.1145/3410566.3410601", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a fundamental task in unsupervised learning, one that targets\nto group a dataset into clusters of similar objects. There has been recent\ninterest in embedding normative considerations around fairness within\nclustering formulations. In this paper, we propose 'local connectivity' as a\ncrucial factor in assessing membership desert in centroid clustering. We use\nlocal connectivity to refer to the support offered by the local neighborhood of\nan object towards supporting its membership to the cluster in question. We\nmotivate the need to consider local connectivity of objects in cluster\nassignment, and provide ways to quantify local connectivity in a given\nclustering. We then exploit concepts from density-based clustering and devise\nLOFKM, a clustering method that seeks to deepen local connectivity in\nclustering outputs, while staying within the framework of centroid clustering.\nThrough an empirical evaluation over real-world datasets, we illustrate that\nLOFKM achieves notable improvements in local connectivity at reasonable costs\nto clustering quality, illustrating the effectiveness of the method.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 21:56:42 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["P", "Deepak", ""]]}, {"id": "2010.05357", "submitter": "Jiahua Chen", "authors": "Jiahua Chen and Shuai Wang and Sahisnu Mazumder and Bing Liu", "title": "A Knowledge-Driven Approach to Classifying Object and Attribute\n  Coreferences in Opinion Mining", "comments": "Accepted to Proceedings of EMNLP 2020 (Findings)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifying and resolving coreferences of objects (e.g., product names) and\nattributes (e.g., product aspects) in opinionated reviews is crucial for\nimproving the opinion mining performance. However, the task is challenging as\none often needs to consider domain-specific knowledge (e.g., iPad is a tablet\nand has aspect resolution) to identify coreferences in opinionated reviews.\nAlso, compiling a handcrafted and curated domain-specific knowledge base for\neach domain is very time consuming and arduous. This paper proposes an approach\nto automatically mine and leverage domain-specific knowledge for classifying\nobjects and attribute coreferences. The approach extracts domain-specific\nknowledge from unlabeled review data and trains a knowledgeaware neural\ncoreference classification model to leverage (useful) domain knowledge together\nwith general commonsense knowledge for the task. Experimental evaluation on\nrealworld datasets involving five domains (product types) shows the\neffectiveness of the approach.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 22:08:43 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 13:03:15 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chen", "Jiahua", ""], ["Wang", "Shuai", ""], ["Mazumder", "Sahisnu", ""], ["Liu", "Bing", ""]]}, {"id": "2010.05384", "submitter": "Yao-Chung Fan", "authors": "Ho-Lam Chung, Ying-Hong Chan, Yao-Chung Fan", "title": "A BERT-based Distractor Generation Scheme with Multi-tasking and\n  Negative Answer Training Strategies", "comments": "Accepted by EMNLP2020 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we investigate the following two limitations for the existing\ndistractor generation (DG) methods. First, the quality of the existing DG\nmethods are still far from practical use. There is still room for DG quality\nimprovement. Second, the existing DG designs are mainly for single distractor\ngeneration. However, for practical MCQ preparation, multiple distractors are\ndesired. Aiming at these goals, in this paper, we present a new distractor\ngeneration scheme with multi-tasking and negative answer training strategies\nfor effectively generating \\textit{multiple} distractors. The experimental\nresults show that (1) our model advances the state-of-the-art result from 28.65\nto 39.81 (BLEU 1 score) and (2) the generated multiple distractors are diverse\nand show strong distracting power for multiple choice question.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 01:22:29 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Chung", "Ho-Lam", ""], ["Chan", "Ying-Hong", ""], ["Fan", "Yao-Chung", ""]]}, {"id": "2010.05391", "submitter": "William Beksi", "authors": "Mohammad Samiul Arshad and William J. Beksi", "title": "A Progressive Conditional Generative Adversarial Network for Generating\n  Dense and Colored 3D Point Clouds", "comments": "To be published in the 2020 International Conference on 3D Vision\n  (3DV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel conditional generative adversarial\nnetwork that creates dense 3D point clouds, with color, for assorted classes of\nobjects in an unsupervised manner. To overcome the difficulty of capturing\nintricate details at high resolutions, we propose a point transformer that\nprogressively grows the network through the use of graph convolutions. The\nnetwork is composed of a leaf output layer and an initial set of branches.\nEvery training iteration evolves a point vector into a point cloud of\nincreasing resolution. After a fixed number of iterations, the number of\nbranches is increased by replicating the last branch. Experimental results show\nthat our network is capable of learning and mimicking a 3D data distribution,\nand produces colored point clouds with fine details at multiple resolutions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 01:32:13 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Arshad", "Mohammad Samiul", ""], ["Beksi", "William J.", ""]]}, {"id": "2010.05394", "submitter": "Fred Glover", "authors": "Fred Glover", "title": "Exploiting Local Optimality in Metaheuristic Search", "comments": "60 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of strategies have been proposed for overcoming local optimality in\nmetaheuristic search. This paper examines characteristics of moves that can be\nexploited to make good decisions about steps that lead away from a local\noptimum and then lead toward a new local optimum. We introduce strategies to\nidentify and take advantage of useful features of solution history with an\nadaptive memory metaheuristic, to provide rules for selecting moves that offer\npromise for discovering improved local optima.\n  Our approach uses a new type of adaptive memory based on a construction\ncalled exponential extrapolation. The memory operates by means of threshold\ninequalities that ensure selected moves will not lead to a specified number of\nmost recently encountered local optima. Associated thresholds are embodied in\nchoice rule strategies that further exploit the exponential extrapolation\nconcept. Together these produce a threshold based Alternating Ascent (AA)\nalgorithm that opens a variety of research possibilities for exploration.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 01:51:09 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 13:59:58 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 13:45:42 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Glover", "Fred", ""]]}, {"id": "2010.05418", "submitter": "Stephen Casper", "authors": "Stephen Casper", "title": "Achilles Heels for AGI/ASI via Decision Theoretic Adversaries", "comments": "Contact info for author at stephencasper.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As progress in AI continues to advance, it is crucial to know how advanced\nsystems will make choices and in what ways they may fail. Machines can already\noutsmart humans in some domains, and understanding how to safely build ones\nwhich may have capabilities at or above the human level is of particular\nconcern. One might suspect that artificially generally intelligent (AGI) and\nartificially superintelligent (ASI) systems should be modeled as as something\nwhich humans, by definition, can't reliably outsmart. As a challenge to this\nassumption, this paper presents the Achilles Heel hypothesis which states that\neven a potentially superintelligent system may nonetheless have stable\ndecision-theoretic delusions which cause them to make obviously irrational\ndecisions in adversarial settings. In a survey of relevant dilemmas and\nparadoxes from the decision theory literature, a number of these potential\nAchilles Heels are discussed in context of this hypothesis. Several novel\ncontributions are made toward understanding the ways in which these weaknesses\nmight be implanted into a system.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 02:53:23 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 00:51:41 GMT"}, {"version": "v3", "created": "Mon, 26 Jul 2021 01:39:09 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Casper", "Stephen", ""]]}, {"id": "2010.05421", "submitter": "Yiding Yang", "authors": "Yiding Yang, Zunlei Feng, Mingli Song, Xinchao Wang", "title": "Factorizable Graph Convolutional Networks", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs have been widely adopted to denote structural connections between\nentities. The relations are in many cases heterogeneous, but entangled together\nand denoted merely as a single edge between a pair of nodes. For example, in a\nsocial network graph, users in different latent relationships like friends and\ncolleagues, are usually connected via a bare edge that conceals such intrinsic\nconnections. In this paper, we introduce a novel graph convolutional network\n(GCN), termed as factorizable graph convolutional network(FactorGCN), that\nexplicitly disentangles such intertwined relations encoded in a graph.\nFactorGCN takes a simple graph as input, and disentangles it into several\nfactorized graphs, each of which represents a latent and disentangled relation\namong nodes. The features of the nodes are then aggregated separately in each\nfactorized latent space to produce disentangled features, which further leads\nto better performances for downstream tasks. We evaluate the proposed FactorGCN\nboth qualitatively and quantitatively on the synthetic and real-world datasets,\nand demonstrate that it yields truly encouraging results in terms of both\ndisentangling and feature aggregation. Code is publicly available at\nhttps://github.com/ihollywhy/FactorGCN.PyTorch.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 03:01:40 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Yang", "Yiding", ""], ["Feng", "Zunlei", ""], ["Song", "Mingli", ""], ["Wang", "Xinchao", ""]]}, {"id": "2010.05427", "submitter": "Chengsheng Mao", "authors": "Chengsheng Mao, Liang Yao, Yuan Luo", "title": "Towards Expressive Graph Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Network (GNN) aggregates the neighborhood of each node into the\nnode embedding and shows its powerful capability for graph representation\nlearning. However, most existing GNN variants aggregate the neighborhood\ninformation in a fixed non-injective fashion, which may map different graphs or\nnodes to the same embedding, reducing the model expressiveness. We present a\ntheoretical framework to design a continuous injective set function for\nneighborhood aggregation in GNN. Using the framework, we propose expressive GNN\nthat aggregates the neighborhood of each node with a continuous injective set\nfunction, so that a GNN layer maps similar nodes with similar neighborhoods to\nsimilar embeddings, different nodes to different embeddings and the equivalent\nnodes or isomorphic graphs to the same embeddings. Moreover, the proposed\nexpressive GNN can naturally learn expressive representations for graphs with\ncontinuous node attributes. We validate the proposed expressive GNN (ExpGNN)\nfor graph classification on multiple benchmark datasets including simple graphs\nand attributed graphs. The experimental results demonstrate that our model\nachieves state-of-the-art performances on most of the benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 03:13:41 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Mao", "Chengsheng", ""], ["Yao", "Liang", ""], ["Luo", "Yuan", ""]]}, {"id": "2010.05432", "submitter": "Md Mosharaf Hossain", "authors": "Md Mosharaf Hossain, Antonios Anastasopoulos, Eduardo Blanco, and\n  Alexis Palmer", "title": "It's not a Non-Issue: Negation as a Source of Error in Machine\n  Translation", "comments": "Accepted at the Findings of EMNLP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine translation (MT) systems progress at a rapid pace, questions of\ntheir adequacy linger. In this study we focus on negation, a universal, core\nproperty of human language that significantly affects the semantics of an\nutterance. We investigate whether translating negation is an issue for modern\nMT systems using 17 translation directions as test bed. Through thorough\nanalysis, we find that indeed the presence of negation can significantly impact\ndownstream quality, in some cases resulting in quality reductions of more than\n60%. We also provide a linguistically motivated analysis that directly explains\nthe majority of our findings. We release our annotations and code to replicate\nour analysis here: https://github.com/mosharafhossain/negation-mt.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 03:34:44 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Hossain", "Md Mosharaf", ""], ["Anastasopoulos", "Antonios", ""], ["Blanco", "Eduardo", ""], ["Palmer", "Alexis", ""]]}, {"id": "2010.05437", "submitter": "Yujie Li", "authors": "Jiqian Dong, Sikai Chen, Paul Young Joun Ha, Yujie Li, Samuel Labi", "title": "A DRL-based Multiagent Cooperative Control Framework for CAV Networks: a\n  Graphic Convolution Q Network", "comments": "TRB 2021 Annual Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connected Autonomous Vehicle (CAV) Network can be defined as a collection of\nCAVs operating at different locations on a multilane corridor, which provides a\nplatform to facilitate the dissemination of operational information as well as\ncontrol instructions. Cooperation is crucial in CAV operating systems since it\ncan greatly enhance operation in terms of safety and mobility, and high-level\ncooperation between CAVs can be expected by jointly plan and control within CAV\nnetwork. However, due to the highly dynamic and combinatory nature such as\ndynamic number of agents (CAVs) and exponentially growing joint action space in\na multiagent driving task, achieving cooperative control is NP hard and cannot\nbe governed by any simple rule-based methods. In addition, existing literature\ncontains abundant information on autonomous driving's sensing technology and\ncontrol logic but relatively little guidance on how to fuse the information\nacquired from collaborative sensing and build decision processor on top of\nfused information. In this paper, a novel Deep Reinforcement Learning (DRL)\nbased approach combining Graphic Convolution Neural Network (GCN) and Deep Q\nNetwork (DQN), namely Graphic Convolution Q network (GCQ) is proposed as the\ninformation fusion module and decision processor. The proposed model can\naggregate the information acquired from collaborative sensing and output safe\nand cooperative lane changing decisions for multiple CAVs so that individual\nintention can be satisfied even under a highly dynamic and partially observed\nmixed traffic. The proposed algorithm can be deployed on centralized control\ninfrastructures such as road-side units (RSU) or cloud platforms to improve the\nCAV operation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 03:53:58 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Dong", "Jiqian", ""], ["Chen", "Sikai", ""], ["Ha", "Paul Young Joun", ""], ["Li", "Yujie", ""], ["Labi", "Samuel", ""]]}, {"id": "2010.05446", "submitter": "Bo Chen", "authors": "Jing Zhang, Bo Chen, Lingxi Zhang, Xirui Ke, Haipeng Ding", "title": "Neural, Symbolic and Neural-Symbolic Reasoning on Knowledge Graphs", "comments": "29 pages, AI Open Journal 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph reasoning is the fundamental component to support machine\nlearning applications such as information extraction, information retrieval,\nand recommendation. Since knowledge graphs can be viewed as the discrete\nsymbolic representations of knowledge, reasoning on knowledge graphs can\nnaturally leverage the symbolic techniques. However, symbolic reasoning is\nintolerant of the ambiguous and noisy data. On the contrary, the recent\nadvances of deep learning promote neural reasoning on knowledge graphs, which\nis robust to the ambiguous and noisy data, but lacks interpretability compared\nto symbolic reasoning. Considering the advantages and disadvantages of both\nmethodologies, recent efforts have been made on combining the two reasoning\nmethods. In this survey, we take a thorough look at the development of the\nsymbolic, neural and hybrid reasoning on knowledge graphs. We survey two\nspecific reasoning tasks, knowledge graph completion and question answering on\nknowledge graphs, and explain them in a unified reasoning framework. We also\nbriefly discuss the future directions for knowledge graph reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 04:28:57 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 06:47:45 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 04:49:30 GMT"}, {"version": "v4", "created": "Fri, 26 Mar 2021 06:46:16 GMT"}, {"version": "v5", "created": "Wed, 31 Mar 2021 02:53:48 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Zhang", "Jing", ""], ["Chen", "Bo", ""], ["Zhang", "Lingxi", ""], ["Ke", "Xirui", ""], ["Ding", "Haipeng", ""]]}, {"id": "2010.05453", "submitter": "Son-Il Kwak", "authors": "I.M. Son, S.I. Kwak, M.O. Choe", "title": "Fuzzy Approximate Reasoning Method based on Least Common Multiple and\n  its Property Analysis", "comments": "18 pages, 0 figures, 14 tables. arXiv admin note: substantial text\n  overlap with arXiv:2003.13450", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows a novel fuzzy approximate reasoning method based on the\nleast common multiple (LCM). Its fundamental idea is to obtain a new fuzzy\nreasoning result by the extended distance measure based on LCM between the\nantecedent fuzzy set and the consequent one in discrete SISO fuzzy system. The\nproposed method is called LCM one. And then this paper analyzes its some\nproperties, i.e., the reductive property, information loss occurred in\nreasoning process, and the convergence of fuzzy control. Theoretical and\nexperimental research results highlight that proposed method meaningfully\nimprove the reductive property and information loss and controllability than\nthe previous fuzzy reasoning methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 07:22:28 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Son", "I. M.", ""], ["Kwak", "S. I.", ""], ["Choe", "M. O.", ""]]}, {"id": "2010.05468", "submitter": "Dongxu Li", "authors": "Dongxu Li, Chenchen Xu, Xin Yu, Kaihao Zhang, Ben Swift, Hanna\n  Suominen, Hongdong Li", "title": "TSPNet: Hierarchical Feature Learning via Temporal Semantic Pyramid for\n  Sign Language Translation", "comments": "NeurIPS 2020 preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sign language translation (SLT) aims to interpret sign video sequences into\ntext-based natural language sentences. Sign videos consist of continuous\nsequences of sign gestures with no clear boundaries in between. Existing SLT\nmodels usually represent sign visual features in a frame-wise manner so as to\navoid needing to explicitly segmenting the videos into isolated signs. However,\nthese methods neglect the temporal information of signs and lead to substantial\nambiguity in translation. In this paper, we explore the temporal semantic\nstructures of signvideos to learn more discriminative features. To this end, we\nfirst present a novel sign video segment representation which takes into\naccount multiple temporal granularities, thus alleviating the need for accurate\nvideo segmentation. Taking advantage of the proposed segment representation, we\ndevelop a novel hierarchical sign video feature learning method via a temporal\nsemantic pyramid network, called TSPNet. Specifically, TSPNet introduces an\ninter-scale attention to evaluate and enhance local semantic consistency of\nsign segments and an intra-scale attention to resolve semantic ambiguity by\nusing non-local video context. Experiments show that our TSPNet outperforms the\nstate-of-the-art with significant improvements on the BLEU score (from 9.58 to\n13.41) and ROUGE score (from 31.80 to 34.96)on the largest commonly-used SLT\ndataset. Our implementation is available at\nhttps://github.com/verashira/TSPNet.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 05:58:09 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Li", "Dongxu", ""], ["Xu", "Chenchen", ""], ["Yu", "Xin", ""], ["Zhang", "Kaihao", ""], ["Swift", "Ben", ""], ["Suominen", "Hanna", ""], ["Li", "Hongdong", ""]]}, {"id": "2010.05470", "submitter": "Simone Raponi", "authors": "Gabriele Oligeri, Simone Raponi, Savio Sciancalepore, Roberto Di\n  Pietro", "title": "PAST-AI: Physical-layer Authentication of Satellite Transmitters via\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical-layer security is regaining traction in the research community, due\nto the performance boost introduced by deep learning classification algorithms.\nThis is particularly true for sender authentication in wireless communications\nvia radio fingerprinting. However, previous research efforts mainly focused on\nterrestrial wireless devices while, to the best of our knowledge, none of the\nprevious work took into consideration satellite transmitters. The satellite\nscenario is generally challenging because, among others, satellite radio\ntransducers feature non-standard electronics (usually aged and specifically\ndesigned for harsh conditions). Moreover, the fingerprinting task is\nspecifically difficult for Low-Earth Orbit (LEO) satellites (like the ones we\nfocus in this paper) since they orbit at about 800Km from the Earth, at a speed\nof around 25,000Km/h, thus making the receiver experiencing a down-link with\nunique attenuation and fading characteristics. In this paper, we propose\nPAST-AI, a methodology tailored to authenticate LEO satellites through\nfingerprinting of their IQ samples, using advanced AI solutions. Our\nmethodology is tested on real data -- more than 100M I/Q samples -- collected\nfrom an extensive measurements campaign on the IRIDIUM LEO satellites\nconstellation, lasting 589 hours. Results are striking: we prove that\nConvolutional Neural Networks (CNN) and autoencoders (if properly calibrated)\ncan be successfully adopted to authenticate the satellite transducers, with an\naccuracy spanning between 0.8 and 1, depending on prior assumptions. The\nproposed methodology, the achieved results, and the provided insights, other\nthan being interesting on their own, when associated to the dataset that we\nmade publicly available, will also pave the way for future research in the\narea.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 06:08:11 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Oligeri", "Gabriele", ""], ["Raponi", "Simone", ""], ["Sciancalepore", "Savio", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "2010.05471", "submitter": "Qiansheng Wang", "authors": "Zhen Wang, Qiansheng Wang, Chengguo Lv, Xue Cao and Guohong Fu", "title": "Unseen Target Stance Detection with Adversarial Domain Generalization", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9206635", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although stance detection has made great progress in the past few years, it\nis still facing the problem of unseen targets. In this study, we investigate\nthe domain difference between targets and thus incorporate attention-based\nconditional encoding with adversarial domain generalization to perform unseen\ntarget stance detection. Experimental results show that our approach achieves\nnew state-of-the-art performance on the SemEval-2016 dataset, demonstrating the\nimportance of domain difference between targets in unseen target stance\ndetection.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 06:12:18 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Wang", "Zhen", ""], ["Wang", "Qiansheng", ""], ["Lv", "Chengguo", ""], ["Cao", "Xue", ""], ["Fu", "Guohong", ""]]}, {"id": "2010.05480", "submitter": "Ildar Rakhmatulin", "authors": "Ildar Rakhmatulin", "title": "A review of the low-cost eye-tracking systems for 2010-2020", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The manuscript presented an analysis of the work in the field of eye-tracking\nover the past ten years in the low-cost filed. We researched in detail the\nmethods, algorithms, and developed hardware. To realization, this task we\nconsidered the commercial eye-tracking systems with hardware and software and\nFree software. Additionally, the manuscript considered advances in the neural\nnetwork fields for eye-tracking tasks and problems which hold back the\ndevelopment of the low-cost eye-tracking system. special attention in the\nmanuscript is given to recommendations for further research in the field of\neye-tracking devices in the low-cost field.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 06:54:27 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Rakhmatulin", "Ildar", ""]]}, {"id": "2010.05502", "submitter": "M. F. Mridha", "authors": "Abu Quwsar Ohi, M. F. Mridha, Md. Abdul Hamid, Muhammad Mostafa\n  Monowar, Dongsu Lee, Jinsul Kim", "title": "A Lightweight Speaker Recognition System Using Timbre Properties", "comments": "Accepted in Journal of Contents Computing", "journal-ref": "The Journal of Contents Computing 2, no. 1 (2020): 139-151", "doi": "10.9728/jcc.2020.06.2.1.139", "report-no": null, "categories": "cs.SD cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Speaker recognition is an active research area that contains notable usage in\nbiometric security and authentication system. Currently, there exist many\nwell-performing models in the speaker recognition domain. However, most of the\nadvanced models implement deep learning that requires GPU support for real-time\nspeech recognition, and it is not suitable for low-end devices. In this paper,\nwe propose a lightweight text-independent speaker recognition model based on\nrandom forest classifier. It also introduces new features that are used for\nboth speaker verification and identification tasks. The proposed model uses\nhuman speech based timbral properties as features that are classified using\nrandom forest. Timbre refers to the very basic properties of sound that allow\nlisteners to discriminate among them. The prototype uses seven most actively\nsearched timbre properties, boominess, brightness, depth, hardness, roughness,\nsharpness, and warmth as features of our speaker recognition model. The\nexperiment is carried out on speaker verification and speaker identification\ntasks and shows the achievements and drawbacks of the proposed model. In the\nspeaker identification phase, it achieves a maximum accuracy of 78%. On the\ncontrary, in the speaker verification phase, the model maintains an accuracy of\n80% having an equal error rate (ERR) of 0.24.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 07:56:03 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 05:58:43 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Ohi", "Abu Quwsar", ""], ["Mridha", "M. F.", ""], ["Hamid", "Md. Abdul", ""], ["Monowar", "Muhammad Mostafa", ""], ["Lee", "Dongsu", ""], ["Kim", "Jinsul", ""]]}, {"id": "2010.05516", "submitter": "Carolin Lawrence", "authors": "Carolin Lawrence, Timo Sztyler, Mathias Niepert", "title": "Explaining Neural Matrix Factorization with Gradient Rollback", "comments": "35th AAAI Conference on Artificial Intelligence, 2021. Includes\n  Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining the predictions of neural black-box models is an important\nproblem, especially when such models are used in applications where user trust\nis crucial. Estimating the influence of training examples on a learned neural\nmodel's behavior allows us to identify training examples most responsible for a\ngiven prediction and, therefore, to faithfully explain the output of a\nblack-box model. The most generally applicable existing method is based on\ninfluence functions, which scale poorly for larger sample sizes and models.\n  We propose gradient rollback, a general approach for influence estimation,\napplicable to neural models where each parameter update step during gradient\ndescent touches a smaller number of parameters, even if the overall number of\nparameters is large. Neural matrix factorization models trained with gradient\ndescent are part of this model class. These models are popular and have found a\nwide range of applications in industry. Especially knowledge graph embedding\nmethods, which belong to this class, are used extensively. We show that\ngradient rollback is highly efficient at both training and test time. Moreover,\nwe show theoretically that the difference between gradient rollback's influence\napproximation and the true influence on a model's behavior is smaller than\nknown bounds on the stability of stochastic gradient descent. This establishes\nthat gradient rollback is robustly estimating example influence. We also\nconduct experiments which show that gradient rollback provides faithful\nexplanations for knowledge base completion and recommender datasets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 08:15:54 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 07:27:32 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 08:50:56 GMT"}, {"version": "v4", "created": "Tue, 15 Dec 2020 07:01:30 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Lawrence", "Carolin", ""], ["Sztyler", "Timo", ""], ["Niepert", "Mathias", ""]]}, {"id": "2010.05523", "submitter": "Xiangru Tang", "authors": "Xiangru Tang, Alan Aw", "title": "FILM: A Fast, Interpretable, and Low-rank Metric Learning Approach for\n  Sentence Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of semantic similarity plays a vital role in sentence matching. It\nrequires to learn discriminative representations of natural language. Recently,\nowing to more and more sophisticated model architecture, impressive progress\nhas been made, along with a time-consuming training process and\nnot-interpretable inference. To alleviate this problem, we explore a metric\nlearning approach, named FILM (Fast, Interpretable, and Low-rank Metric\nlearning) to efficiently find a high discriminative projection of the\nhigh-dimensional data. We construct this metric learning problem as a manifold\noptimization problem and solve it with the Cayley transformation method with\nthe Barzilai-Borwein step size. In experiments, we apply FILM with triplet loss\nminimization objective to the Quora Challenge and Semantic Textual Similarity\n(STS) Task. The results demonstrate that the FILM method achieves superior\nperformance as well as the fastest computation speed, which is consistent with\nour theoretical analysis of time complexity.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 08:24:41 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 01:14:14 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Tang", "Xiangru", ""], ["Aw", "Alan", ""]]}, {"id": "2010.05545", "submitter": "Jost Tobias Springenberg", "authors": "Jost Tobias Springenberg, Nicolas Heess, Daniel Mankowitz, Josh Merel,\n  Arunkumar Byravan, Abbas Abdolmaleki, Jackie Kay, Jonas Degrave, Julian\n  Schrittwieser, Yuval Tassa, Jonas Buchli, Dan Belov, Martin Riedmiller", "title": "Local Search for Policy Iteration in Continuous Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for local, regularized, policy improvement in\nreinforcement learning (RL) that allows us to formulate model-based and\nmodel-free variants in a single framework. Our algorithm can be interpreted as\na natural extension of work on KL-regularized RL and introduces a form of tree\nsearch for continuous action spaces. We demonstrate that additional computation\nspent on model-based policy improvement during learning can improve data\nefficiency, and confirm that model-based policy improvement during action\nselection can also be beneficial. Quantitatively, our algorithm improves data\nefficiency on several continuous control benchmarks (when a model is learned in\nparallel), and it provides significant improvements in wall-clock time in\nhigh-dimensional domains (when a ground truth model is available). The unified\nframework also helps us to better understand the space of model-based and\nmodel-free algorithms. In particular, we demonstrate that some benefits\nattributed to model-based RL can be obtained without a model, simply by\nutilizing more computation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 09:02:48 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Springenberg", "Jost Tobias", ""], ["Heess", "Nicolas", ""], ["Mankowitz", "Daniel", ""], ["Merel", "Josh", ""], ["Byravan", "Arunkumar", ""], ["Abdolmaleki", "Abbas", ""], ["Kay", "Jackie", ""], ["Degrave", "Jonas", ""], ["Schrittwieser", "Julian", ""], ["Tassa", "Yuval", ""], ["Buchli", "Jonas", ""], ["Belov", "Dan", ""], ["Riedmiller", "Martin", ""]]}, {"id": "2010.05599", "submitter": "Lilang Lin", "authors": "Lilang Lin, Sijie Song, Wenhan Yan and Jiaying Liu", "title": "MS$^2$L: Multi-Task Self-Supervised Learning for Skeleton Based Action\n  Recognition", "comments": "Accepted by ACMMM 2020", "journal-ref": null, "doi": "10.1145/3394171.3413548", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address self-supervised representation learning from human\nskeletons for action recognition. Previous methods, which usually learn feature\npresentations from a single reconstruction task, may come across the\noverfitting problem, and the features are not generalizable for action\nrecognition. Instead, we propose to integrate multiple tasks to learn more\ngeneral representations in a self-supervised manner. To realize this goal, we\nintegrate motion prediction, jigsaw puzzle recognition, and contrastive\nlearning to learn skeleton features from different aspects. Skeleton dynamics\ncan be modeled through motion prediction by predicting the future sequence. And\ntemporal patterns, which are critical for action recognition, are learned\nthrough solving jigsaw puzzles. We further regularize the feature space by\ncontrastive learning. Besides, we explore different training strategies to\nutilize the knowledge from self-supervised tasks for action recognition. We\nevaluate our multi-task self-supervised learning approach with action\nclassifiers trained under different configurations, including unsupervised,\nsemi-supervised and fully-supervised settings. Our experiments on the NW-UCLA,\nNTU RGB+D, and PKUMMD datasets show remarkable performance for action\nrecognition, demonstrating the superiority of our method in learning more\ndiscriminative and general features. Our project website is available at\nhttps://langlandslin.github.io/projects/MSL/.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 11:09:44 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 07:07:05 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Lin", "Lilang", ""], ["Song", "Sijie", ""], ["Yan", "Wenhan", ""], ["Liu", "Jiaying", ""]]}, {"id": "2010.05609", "submitter": "Amine Abdaoui", "authors": "Amine Abdaoui, Camille Pradel and Gr\\'egoire Sigel", "title": "Load What You Need: Smaller Versions of Multilingual BERT", "comments": null, "journal-ref": "SustaiNLP / EMNLP 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained Transformer-based models are achieving state-of-the-art results\non a variety of Natural Language Processing data sets. However, the size of\nthese models is often a drawback for their deployment in real production\napplications. In the case of multilingual models, most of the parameters are\nlocated in the embeddings layer. Therefore, reducing the vocabulary size should\nhave an important impact on the total number of parameters. In this paper, we\npropose to generate smaller models that handle fewer number of languages\naccording to the targeted corpora. We present an evaluation of smaller versions\nof multilingual BERT on the XNLI data set, but we believe that this method may\nbe applied to other multilingual transformers. The obtained results confirm\nthat we can generate smaller models that keep comparable results, while\nreducing up to 45% of the total number of parameters. We compared our models\nwith DistilmBERT (a distilled version of multilingual BERT) and showed that\nunlike language reduction, distillation induced a 1.7% to 6% drop in the\noverall accuracy on the XNLI data set. The presented models and code are\npublicly available.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 11:29:06 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Abdaoui", "Amine", ""], ["Pradel", "Camille", ""], ["Sigel", "Gr\u00e9goire", ""]]}, {"id": "2010.05627", "submitter": "Pan Zhou", "authors": "Pan Zhou, Jiashi Feng, Chao Ma, Caiming Xiong, Steven HOI, Weinan E", "title": "Towards Theoretically Understanding Why SGD Generalizes Better Than ADAM\n  in Deep Learning", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is not clear yet why ADAM-alike adaptive gradient algorithms suffer from\nworse generalization performance than SGD despite their faster training speed.\nThis work aims to provide understandings on this generalization gap by\nanalyzing their local convergence behaviors. Specifically, we observe the heavy\ntails of gradient noise in these algorithms. This motivates us to analyze these\nalgorithms through their Levy-driven stochastic differential equations (SDEs)\nbecause of the similar convergence behaviors of an algorithm and its SDE. Then\nwe establish the escaping time of these SDEs from a local basin. The result\nshows that (1) the escaping time of both SGD and ADAM~depends on the Radon\nmeasure of the basin positively and the heaviness of gradient noise negatively;\n(2) for the same basin, SGD enjoys smaller escaping time than ADAM, mainly\nbecause (a) the geometry adaptation in ADAM~via adaptively scaling each\ngradient coordinate well diminishes the anisotropic structure in gradient noise\nand results in larger Radon measure of a basin; (b) the exponential gradient\naverage in ADAM~smooths its gradient and leads to lighter gradient noise tails\nthan SGD. So SGD is more locally unstable than ADAM~at sharp minima defined as\nthe minima whose local basins have small Radon measure, and can better escape\nfrom them to flatter ones with larger Radon measure. As flat minima here which\noften refer to the minima at flat or asymmetric basins/valleys often generalize\nbetter than sharp ones~\\cite{keskar2016large,he2019asymmetric}, our result\nexplains the better generalization performance of SGD over ADAM. Finally,\nexperimental results confirm our heavy-tailed gradient noise assumption and\ntheoretical affirmation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 12:00:26 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Zhou", "Pan", ""], ["Feng", "Jiashi", ""], ["Ma", "Chao", ""], ["Xiong", "Caiming", ""], ["HOI", "Steven", ""], ["E", "Weinan", ""]]}, {"id": "2010.05635", "submitter": "Nikolaos Nikolaou", "authors": "Nikolaos Nikolaou and Konstantinos Sechidis", "title": "Inferring Causal Direction from Observational Data: A Complexity\n  Approach", "comments": "9 Pages, 2 figures, Presented in Machine Learning for Pharma and\n  Healthcare Applications ECML PKDD 2020 Workshop (PharML 2020)", "journal-ref": "Machine Learning for Pharma and Healthcare Applications ECML PKDD\n  2020 Workshop (PharML 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the heart of causal structure learning from observational data lies a\ndeceivingly simple question: given two statistically dependent random\nvariables, which one has a causal effect on the other? This is impossible to\nanswer using statistical dependence testing alone and requires that we make\nadditional assumptions. We propose several fast and simple criteria for\ndistinguishing cause and effect in pairs of discrete or continuous random\nvariables. The intuition behind them is that predicting the effect variable\nusing the cause variable should be `simpler' than the reverse -- different\nnotions of `simplicity' giving rise to different criteria. We demonstrate the\naccuracy of the criteria on synthetic data generated under a broad family of\ncausal mechanisms and types of noise.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 12:10:37 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Nikolaou", "Nikolaos", ""], ["Sechidis", "Konstantinos", ""]]}, {"id": "2010.05649", "submitter": "Ziheng Duan", "authors": "Haoyan Xu, Ziheng Duan, Yunsheng Bai, Yida Huang, Anni Ren, Qianru Yu,\n  Qianru Zhang, Yueyang Wang, Xiaoqian Wang, Yizhou Sun, Wei Wang", "title": "Multivariate Time Series Classification with Hierarchical Variational\n  Graph Pooling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, multivariate time series classification (MTSC) has\nreceived great attention with the advance of sensing techniques. Current deep\nlearning methods for MTSC are based on convolutional and recurrent neural\nnetwork, with the assumption that time series variables have the same effect to\neach other. Thus they cannot model the pairwise dependencies among variables\nexplicitly. What's more, current spatial-temporal modeling methods based on\nGNNs are inherently flat and lack the capability of aggregating node\ninformation in a hierarchical manner. To address this limitation and attain\nexpressive global representation of MTS, we propose a graph pooling based\nframework MTPool and view MTSC task as graph classification task. With graph\nstructure learning and temporal convolution, MTS slices are converted to graphs\nand spatial-temporal features are extracted. Then, we propose a novel graph\npooling method, which uses an ``encoder-decoder'' mechanism to generate\nadaptive centroids for cluster assignments. GNNs and graph pooling layers are\nused for joint graph representation learning and graph coarsening. With\nmultiple graph pooling layers, the input graphs are hierachically coarsened to\none node. Finally, differentiable classifier takes this coarsened one-node\ngraph as input to get the final predicted class. Experiments on 10 benchmark\ndatasets demonstrate MTPool outperforms state-of-the-art methods in MTSC tasks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 12:36:47 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Xu", "Haoyan", ""], ["Duan", "Ziheng", ""], ["Bai", "Yunsheng", ""], ["Huang", "Yida", ""], ["Ren", "Anni", ""], ["Yu", "Qianru", ""], ["Zhang", "Qianru", ""], ["Wang", "Yueyang", ""], ["Wang", "Xiaoqian", ""], ["Sun", "Yizhou", ""], ["Wang", "Wei", ""]]}, {"id": "2010.05680", "submitter": "Jiarui Fang", "authors": "Jiarui Fang, Yang Yu, Chengduo Zhao, Jie Zhou", "title": "TurboTransformers: An Efficient GPU Serving System For Transformer\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transformer is the most critical algorithm innovation of the Nature\nLanguage Processing (NLP) field in recent years. Unlike the Recurrent Neural\nNetwork (RNN) models, Transformers can process on dimensions of sequence\nlengths in parallel, therefore leading to better accuracy on long sequences.\nHowever, efficient deployments of them for online services in data centers\nequipped with GPUs are not easy. First, more computation introduced by\ntransformer structures makes it more challenging to meet the latency and\nthroughput constraints of serving. Second, NLP tasks take in sentences of\nvariable length. The variability of input dimensions brings a severe problem to\nefficient memory management and serving optimization.\n  This paper designed a transformer serving system called TurboTransformers,\nwhich consists of a computing runtime and a serving framework to solve the\nabove challenges. Three innovative features make it stand out from other\nsimilar works. An efficient parallel algorithm is proposed for GPU-based batch\nreduction operations, like Softmax and LayerNorm, major hot spots besides BLAS\nroutines. A memory allocation algorithm, which better balances the memory\nfootprint and allocation/free efficiency, is designed for variable-length input\nsituations. A serving framework equipped with a new batch scheduler using\ndynamic programming achieves the optimal throughput on variable-length\nrequests. The system can achieve the state-of-the-art transformer model serving\nperformance on GPU platforms and can be seamlessly integrated into your PyTorch\ncode with a few lines of code.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 07:28:38 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 12:30:31 GMT"}, {"version": "v3", "created": "Sun, 3 Jan 2021 12:33:49 GMT"}, {"version": "v4", "created": "Sat, 20 Feb 2021 08:54:32 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Fang", "Jiarui", ""], ["Yu", "Yang", ""], ["Zhao", "Chengduo", ""], ["Zhou", "Jie", ""]]}, {"id": "2010.05694", "submitter": "EPTCS", "authors": "Viviana Mascardi (University of Genova, DIBRIS, Italy), Domenico\n  Pellegrini (Ministry of Justice, Tribunale di Genova, Italy)", "title": "Logical Judges Challenge Human Judges on the Strange Case of\n  B.C.-Valjean", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 268-275", "doi": "10.4204/EPTCS.325.32", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On May 12th, 2020, during the course entitled Artificial Intelligence and\nJurisdiction Practice organized by the Italian School of Magistracy, more than\n70 magistrates followed our demonstration of a Prolog logical judge reasoning\non an armed robbery case. Although the implemented logical judge is just an\nexercise of knowledge representation and simple deductive reasoning, a\npractical demonstration of an automated reasoning tool to such a large audience\nof potential end-users represents a first and unique attempt in Italy and, to\nthe best of our knowledge, in the international panorama. In this paper we\npresent the case addressed by the logical judge - a real case already addressed\nby a human judge in 2015 - and the feedback on the demonstration collected from\nthe attendees.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:51:27 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Mascardi", "Viviana", "", "University of Genova, DIBRIS, Italy"], ["Pellegrini", "Domenico", "", "Ministry of Justice, Tribunale di Genova, Italy"]]}, {"id": "2010.05732", "submitter": "Francis Ferraro", "authors": "Rajat Patel and Francis Ferraro", "title": "On the Complementary Nature of Knowledge Graph Embedding, Fine Grain\n  Entity Types, and Language Modeling", "comments": "To appear at the EMNLP 2020 Workshop on Deep Learning Inside Out", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the complementary natures of neural knowledge graph embedding,\nfine-grain entity type prediction, and neural language modeling. We show that a\nlanguage model-inspired knowledge graph embedding approach yields both improved\nknowledge graph embeddings and fine-grain entity type representations. Our work\nalso shows that jointly modeling both structured knowledge tuples and language\nimproves both.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 14:26:48 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Patel", "Rajat", ""], ["Ferraro", "Francis", ""]]}, {"id": "2010.05738", "submitter": "Sopan Khosla", "authors": "Sopan Khosla, Carolyn Rose", "title": "Using Type Information to Improve Entity Coreference Resolution", "comments": "Accepted as Long Paper at CODI workshop EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Coreference resolution (CR) is an essential part of discourse analysis. Most\nrecently, neural approaches have been proposed to improve over SOTA models from\nearlier paradigms. So far none of the published neural models leverage external\nsemantic knowledge such as type information. This paper offers the first such\nmodel and evaluation, demonstrating modest gains in accuracy by introducing\neither gold standard or predicted types. In the proposed approach, type\ninformation serves both to (1) improve mention representation and (2) create a\nsoft type consistency check between coreference candidate mentions. Our\nevaluation covers two different grain sizes of types over four different\nbenchmark corpora.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 14:32:39 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Khosla", "Sopan", ""], ["Rose", "Carolyn", ""]]}, {"id": "2010.05744", "submitter": "Federico Amato", "authors": "Federico Amato, Fabian Guignard, Philippe Jacquet and Mikhail Kanevski", "title": "On Feature Selection Using Anisotropic General Regression Neural Network", "comments": null, "journal-ref": "ESANN 2020 proceedings, European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning. Online event, 2-4\n  October 2020, i6doc.com publ., ISBN 978-2-87587-074-2. Available from\n  http://www.i6doc.com/en/", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of irrelevant features in the input dataset tends to reduce the\ninterpretability and predictive quality of machine learning models. Therefore,\nthe development of feature selection methods to recognize irrelevant features\nis a crucial topic in machine learning. Here we show how the General Regression\nNeural Network used with an anisotropic Gaussian Kernel can be used to perform\nfeature selection. A number of numerical experiments are conducted using\nsimulated data to study the robustness of the proposed methodology and its\nsensitivity to sample size. Finally, a comparison with four other feature\nselection methods is performed on several real world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 14:35:40 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Amato", "Federico", ""], ["Guignard", "Fabian", ""], ["Jacquet", "Philippe", ""], ["Kanevski", "Mikhail", ""]]}, {"id": "2010.05757", "submitter": "Carsten Eickhoff", "authors": "Aaron S. Eisman, Nishant R. Shah, Carsten Eickhoff, George Zerveas,\n  Elizabeth S. Chen, Wen-Chih Wu, Indra Neil Sarkar", "title": "Extracting Angina Symptoms from Clinical Notes Using Pre-Trained\n  Transformer Architectures", "comments": null, "journal-ref": "AMIA Annual Symposium 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anginal symptoms can connote increased cardiac risk and a need for change in\ncardiovascular management. This study evaluated the potential to extract these\nsymptoms from physician notes using the Bidirectional Encoder from Transformers\nlanguage model fine-tuned on a domain-specific corpus. The history of present\nillness section of 459 expert annotated primary care physician notes from\nconsecutive patients referred for cardiac testing without known atherosclerotic\ncardiovascular disease were included. Notes were annotated for positive and\nnegative mentions of chest pain and shortness of breath characterization. The\nresults demonstrate high sensitivity and specificity for the detection of chest\npain or discomfort, substernal chest pain, shortness of breath, and dyspnea on\nexertion. Small sample size limited extracting factors related to provocation\nand palliation of chest pain. This study provides a promising starting point\nfor the natural language processing of physician notes to characterize\nclinically actionable anginal symptoms.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 14:53:32 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Eisman", "Aaron S.", ""], ["Shah", "Nishant R.", ""], ["Eickhoff", "Carsten", ""], ["Zerveas", "George", ""], ["Chen", "Elizabeth S.", ""], ["Wu", "Wen-Chih", ""], ["Sarkar", "Indra Neil", ""]]}, {"id": "2010.05759", "submitter": "Alexander Katzmann", "authors": "Alexander Katzmann, Oliver Taubmann, Stephen Ahmad, Alexander\n  M\\\"uhlberg, Michael S\\\"uhling, Horst-Michael Gro{\\ss}", "title": "Explaining Clinical Decision Support Systems in Medical Imaging using\n  Cycle-Consistent Activation Maximization", "comments": "32 pages, 9 figures, 18 pages appendix, metadata typo corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical decision support using deep neural networks has become a topic of\nsteadily growing interest. While recent work has repeatedly demonstrated that\ndeep learning offers major advantages for medical image classification over\ntraditional methods, clinicians are often hesitant to adopt the technology\nbecause its underlying decision-making process is considered to be\nintransparent and difficult to comprehend. In recent years, this has been\naddressed by a variety of approaches that have successfully contributed to\nproviding deeper insight. Most notably, additive feature attribution methods\nare able to propagate decisions back into the input space by creating a\nsaliency map which allows the practitioner to \"see what the network sees.\"\nHowever, the quality of the generated maps can become poor and the images noisy\nif only limited data is available - a typical scenario in clinical contexts. We\npropose a novel decision explanation scheme based on CycleGAN activation\nmaximization which generates high-quality visualizations of classifier\ndecisions even in smaller data sets. We conducted a user study in which these\nvisualizations significantly outperformed existing methods on the LIDC dataset\nfor lung lesion malignancy classification. With our approach we make a\nsignificant contribution to a better understanding of clinical decision support\nsystems based on deep neural networks and thus aim to foster overall clinical\nacceptance.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 14:39:27 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 11:57:53 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Katzmann", "Alexander", ""], ["Taubmann", "Oliver", ""], ["Ahmad", "Stephen", ""], ["M\u00fchlberg", "Alexander", ""], ["S\u00fchling", "Michael", ""], ["Gro\u00df", "Horst-Michael", ""]]}, {"id": "2010.05761", "submitter": "Elan Rosenfeld", "authors": "Elan Rosenfeld, Pradeep Ravikumar, Andrej Risteski", "title": "The Risks of Invariant Risk Minimization", "comments": "ICLR 2021 Camera-Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invariant Causal Prediction (Peters et al., 2016) is a technique for\nout-of-distribution generalization which assumes that some aspects of the data\ndistribution vary across the training set but that the underlying causal\nmechanisms remain constant. Recently, Arjovsky et al. (2019) proposed Invariant\nRisk Minimization (IRM), an objective based on this idea for learning deep,\ninvariant features of data which are a complex function of latent variables;\nmany alternatives have subsequently been suggested. However, formal guarantees\nfor all of these works are severely lacking. In this paper, we present the\nfirst analysis of classification under the IRM objective--as well as these\nrecently proposed alternatives--under a fairly natural and general model. In\nthe linear case, we show simple conditions under which the optimal solution\nsucceeds or, more often, fails to recover the optimal invariant predictor. We\nfurthermore present the very first results in the non-linear regime: we\ndemonstrate that IRM can fail catastrophically unless the test data are\nsufficiently similar to the training distribution--this is precisely the issue\nthat it was intended to solve. Thus, in this setting we find that IRM and its\nalternatives fundamentally do not improve over standard Empirical Risk\nMinimization.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 14:54:32 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 16:23:24 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Rosenfeld", "Elan", ""], ["Ravikumar", "Pradeep", ""], ["Risteski", "Andrej", ""]]}, {"id": "2010.05767", "submitter": "Jan Robine", "authors": "Jan Robine, Tobias Uelwer, Stefan Harmeling", "title": "Smaller World Models for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sample efficiency remains a fundamental issue of reinforcement learning.\nModel-based algorithms try to make better use of data by simulating the\nenvironment with a model. We propose a new neural network architecture for\nworld models based on a vector quantized-variational autoencoder (VQ-VAE) to\nencode observations and a convolutional LSTM to predict the next embedding\nindices. A model-free PPO agent is trained purely on simulated experience from\nthe world model. We adopt the setup introduced by Kaiser et al. (2020), which\nonly allows 100K interactions with the real environment. We apply our method on\n36 Atari environments and show that we reach comparable performance to their\nSimPLe algorithm, while our model is significantly smaller.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 15:02:41 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 12:02:16 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Robine", "Jan", ""], ["Uelwer", "Tobias", ""], ["Harmeling", "Stefan", ""]]}, {"id": "2010.05769", "submitter": "Heribert Wankerl", "authors": "Heribert Wankerl and Maike L. Stern and Ali Mahdavi and Christoph\n  Eichler and Elmar W. Lang", "title": "Parameterized Reinforcement Learning for Optical System Optimization", "comments": "Presented as a poster at the workshop on machine learning for\n  engineering modeling, simulation and design @ NeurIPS 2020", "journal-ref": null, "doi": "10.1088/1361-6463/abfddb", "report-no": null, "categories": "cs.LG cs.AI physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing a multi-layer optical system with designated optical\ncharacteristics is an inverse design problem in which the resulting design is\ndetermined by several discrete and continuous parameters. In particular, we\nconsider three design parameters to describe a multi-layer stack: Each layer's\ndielectric material and thickness as well as the total number of layers. Such a\ncombination of both, discrete and continuous parameters is a challenging\noptimization problem that often requires a computationally expensive search for\nan optimal system design. Hence, most methods merely determine the optimal\nthicknesses of the system's layers. To incorporate layer material and the total\nnumber of layers as well, we propose a method that considers the stacking of\nconsecutive layers as parameterized actions in a Markov decision process. We\npropose an exponentially transformed reward signal that eases policy\noptimization and adapt a recent variant of Q-learning for inverse design\noptimization. We demonstrate that our method outperforms human experts and a\nnaive reinforcement learning algorithm concerning the achieved optical\ncharacteristics. Moreover, the learned Q-values contain information about the\noptical properties of multi-layer optical systems, thereby allowing physical\ninterpretation or what-if analysis.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 10:53:28 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 10:56:02 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Wankerl", "Heribert", ""], ["Stern", "Maike L.", ""], ["Mahdavi", "Ali", ""], ["Eichler", "Christoph", ""], ["Lang", "Elmar W.", ""]]}, {"id": "2010.05772", "submitter": "Afshin Oroojlooy", "authors": "Afshin Oroojlooy, Mohammadreza Nazari, Davood Hajinezhad, Jorge Silva", "title": "AttendLight: Universal Attention-Based Reinforcement Learning Model for\n  Traffic Signal Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose AttendLight, an end-to-end Reinforcement Learning (RL) algorithm\nfor the problem of traffic signal control. Previous approaches for this problem\nhave the shortcoming that they require training for each new intersection with\na different structure or traffic flow distribution. AttendLight solves this\nissue by training a single, universal model for intersections with any number\nof roads, lanes, phases (possible signals), and traffic flow. To this end, we\npropose a deep RL model which incorporates two attention models. The first\nattention model is introduced to handle different numbers of roads-lanes; and\nthe second attention model is intended for enabling decision-making with any\nnumber of phases in an intersection. As a result, our proposed model works for\nany intersection configuration, as long as a similar configuration is\nrepresented in the training set. Experiments were conducted with both synthetic\nand real-world standard benchmark data-sets. The results we show cover\nintersections with three or four approaching roads;\none-directional/bi-directional roads with one, two, and three lanes; different\nnumber of phases; and different traffic flows. We consider two regimes: (i)\nsingle-environment training, single-deployment, and (ii) multi-environment\ntraining, multi-deployment. AttendLight outperforms both classical and other\nRL-based approaches on all cases in both regimes.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 15:07:57 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Oroojlooy", "Afshin", ""], ["Nazari", "Mohammadreza", ""], ["Hajinezhad", "Davood", ""], ["Silva", "Jorge", ""]]}, {"id": "2010.05821", "submitter": "Yiming Li", "authors": "Yiming Li, Ziqi Zhang, Jiawang Bai, Baoyuan Wu, Yong Jiang, Shu-Tao\n  Xia", "title": "Open-sourced Dataset Protection via Backdoor Watermarking", "comments": "Accepted by the NeurIPS Workshop on Dataset Curation and Security,\n  2020. 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid development of deep learning has benefited from the release of some\nhigh-quality open-sourced datasets ($e.g.$, ImageNet), which allows researchers\nto easily verify the effectiveness of their algorithms. Almost all existing\nopen-sourced datasets require that they can only be adopted for academic or\neducational purposes rather than commercial purposes, whereas there is still no\ngood way to protect them. In this paper, we propose a \\emph{backdoor embedding\nbased dataset watermarking} method to protect an open-sourced\nimage-classification dataset by verifying whether it is used for training a\nthird-party model. Specifically, the proposed method contains two main\nprocesses, including \\emph{dataset watermarking} and \\emph{dataset\nverification}. We adopt classical poisoning-based backdoor attacks ($e.g.$,\nBadNets) for dataset watermarking, ie, generating some poisoned samples by\nadding a certain trigger ($e.g.$, a local patch) onto some benign samples,\nlabeled with a pre-defined target class. Based on the proposed backdoor-based\nwatermarking, we use a hypothesis test guided method for dataset verification\nbased on the posterior probability generated by the suspicious third-party\nmodel of the benign samples and their correspondingly watermarked samples\n($i.e.$, images with trigger) on the target class. Experiments on some\nbenchmark datasets are conducted, which verify the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 16:16:27 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 08:32:27 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 04:51:13 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Li", "Yiming", ""], ["Zhang", "Ziqi", ""], ["Bai", "Jiawang", ""], ["Wu", "Baoyuan", ""], ["Jiang", "Yong", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "2010.05867", "submitter": "David Byrd", "authors": "David Byrd and Antigoni Polychroniadou", "title": "Differentially Private Secure Multi-Party Computation for Federated\n  Learning in Financial Applications", "comments": "ACM ICAIF 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.MA q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning enables a population of clients, working with a trusted\nserver, to collaboratively learn a shared machine learning model while keeping\neach client's data within its own local systems. This reduces the risk of\nexposing sensitive data, but it is still possible to reverse engineer\ninformation about a client's private data set from communicated model\nparameters. Most federated learning systems therefore use differential privacy\nto introduce noise to the parameters. This adds uncertainty to any attempt to\nreveal private client data, but also reduces the accuracy of the shared model,\nlimiting the useful scale of privacy-preserving noise. A system can further\nreduce the coordinating server's ability to recover private client information,\nwithout additional accuracy loss, by also including secure multiparty\ncomputation. An approach combining both techniques is especially relevant to\nfinancial firms as it allows new possibilities for collaborative learning\nwithout exposing sensitive client data. This could produce more accurate models\nfor important tasks like optimal trade execution, credit origination, or fraud\ndetection. The key contributions of this paper are: We present a\nprivacy-preserving federated learning protocol to a non-specialist audience,\ndemonstrate it using logistic regression on a real-world credit card fraud data\nset, and evaluate it using an open-source simulation platform which we have\nadapted for the development of federated learning systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 17:16:27 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Byrd", "David", ""], ["Polychroniadou", "Antigoni", ""]]}, {"id": "2010.05880", "submitter": "Ahmad Berjaoui", "authors": "Ahmad Berjaoui", "title": "Continual learning using hash-routed convolutional neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning could shift the machine learning paradigm from data\ncentric to model centric. A continual learning model needs to scale efficiently\nto handle semantically different datasets, while avoiding unnecessary growth.\nWe introduce hash-routed convolutional neural networks: a group of\nconvolutional units where data flows dynamically. Feature maps are compared\nusing feature hashing and similar data is routed to the same units. A\nhash-routed network provides excellent plasticity thanks to its routed nature,\nwhile generating stable features through the use of orthogonal feature hashing.\nEach unit evolves separately and new units can be added (to be used only when\nnecessary). Hash-routed networks achieve excellent performance across a variety\nof typical continual learning benchmarks without storing raw data and train\nusing only gradient descent. Besides providing a continual learning framework\nfor supervised tasks with encouraging results, our model can be used for\nunsupervised or reinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 07:48:37 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Berjaoui", "Ahmad", ""]]}, {"id": "2010.05887", "submitter": "Farzan Masrour", "authors": "Farzan Masrour, Pang-Ning Tan, Abdol-Hossein Esfahanian", "title": "Fairness Perception from a Network-Centric Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic fairness is a major concern in recent years as the influence of\nmachine learning algorithms becomes more widespread. In this paper, we\ninvestigate the issue of algorithmic fairness from a network-centric\nperspective. Specifically, we introduce a novel yet intuitive function known as\nnetwork-centric fairness perception and provide an axiomatic approach to\nanalyze its properties. Using a peer-review network as case study, we also\nexamine its utility in terms of assessing the perception of fairness in paper\nacceptance decisions. We show how the function can be extended to a group\nfairness metric known as fairness visibility and demonstrate its relationship\nto demographic parity. We also illustrate a potential pitfall of the fairness\nvisibility measure that can be exploited to mislead individuals into perceiving\nthat the algorithmic decisions are fair. We demonstrate how the problem can be\nalleviated by increasing the local neighborhood size of the fairness perception\nfunction.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 06:35:03 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Masrour", "Farzan", ""], ["Tan", "Pang-Ning", ""], ["Esfahanian", "Abdol-Hossein", ""]]}, {"id": "2010.05894", "submitter": "Wenqi Jiang", "authors": "Wenqi Jiang, Zhenhao He, Shuai Zhang, Thomas B. Preu{\\ss}er, Kai Zeng,\n  Liang Feng, Jiansong Zhang, Tongxuan Liu, Yong Li, Jingren Zhou, Ce Zhang,\n  Gustavo Alonso", "title": "MicroRec: Efficient Recommendation Inference by Hardware and Data\n  Structure Solutions", "comments": "Accepted by MLSys'21 (the 4th Conference on Machine Learning and\n  Systems)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are widely used in personalized recommendation systems.\nUnlike regular DNN inference workloads, recommendation inference is\nmemory-bound due to the many random memory accesses needed to lookup the\nembedding tables. The inference is also heavily constrained in terms of latency\nbecause producing a recommendation for a user must be done in about tens of\nmilliseconds. In this paper, we propose MicroRec, a high-performance inference\nengine for recommendation systems. MicroRec accelerates recommendation\ninference by (1) redesigning the data structures involved in the embeddings to\nreduce the number of lookups needed and (2) taking advantage of the\navailability of High-Bandwidth Memory (HBM) in FPGA accelerators to tackle the\nlatency by enabling parallel lookups. We have implemented the resulting design\non an FPGA board including the embedding lookup step as well as the complete\ninference process. Compared to the optimized CPU baseline (16 vCPU,\nAVX2-enabled), MicroRec achieves 13.8~14.7x speedup on embedding lookup alone\nand 2.5$~5.4x speedup for the entire recommendation inference in terms of\nthroughput. As for latency, CPU-based engines needs milliseconds for inferring\na recommendation while MicroRec only takes microseconds, a significant\nadvantage in real-time recommendation systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 17:42:30 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 10:44:01 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Jiang", "Wenqi", ""], ["He", "Zhenhao", ""], ["Zhang", "Shuai", ""], ["Preu\u00dfer", "Thomas B.", ""], ["Zeng", "Kai", ""], ["Feng", "Liang", ""], ["Zhang", "Jiansong", ""], ["Liu", "Tongxuan", ""], ["Li", "Yong", ""], ["Zhou", "Jingren", ""], ["Zhang", "Ce", ""], ["Alonso", "Gustavo", ""]]}, {"id": "2010.05898", "submitter": "Maarten Bieshaar", "authors": "Maarten Bieshaar, Jens Schreiber, Stephan Vogt, Andr\\'e Gensler,\n  Bernhard Sick", "title": "Quantile Surfaces -- Generalizing Quantile Regression to Multivariate\n  Targets", "comments": "Submitted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI), currently under review, 15 page, 23 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we present a novel approach to multivariate probabilistic\nforecasting. Our approach is based on an extension of single-output quantile\nregression (QR) to multivariate-targets, called quantile surfaces (QS). QS uses\na simple yet compelling idea of indexing observations of a probabilistic\nforecast through direction and vector length to estimate a central tendency. We\nextend the single-output QR technique to multivariate probabilistic targets. QS\nefficiently models dependencies in multivariate target variables and represents\nprobability distributions through discrete quantile levels. Therefore, we\npresent a novel two-stage process. In the first stage, we perform a\ndeterministic point forecast (i.e., central tendency estimation). Subsequently,\nwe model the prediction uncertainty using QS involving neural networks called\nquantile surface regression neural networks (QSNN). Additionally, we introduce\nnew methods for efficient and straightforward evaluation of the reliability and\nsharpness of the issued probabilistic QS predictions. We complement this by the\ndirectional extension of the Continuous Ranked Probability Score (CRPS) score.\nFinally, we evaluate our novel approach on synthetic data and two currently\nresearched real-world challenges in two different domains: First, probabilistic\nforecasting for renewable energy power generation, second, short-term cyclists\ntrajectory forecasting for autonomously driving vehicles. Especially for the\nlatter, our empirical results show that even a simple one-layer QSNN\noutperforms traditional parametric multivariate forecasting techniques, thus\nimproving the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 16:35:37 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Bieshaar", "Maarten", ""], ["Schreiber", "Jens", ""], ["Vogt", "Stephan", ""], ["Gensler", "Andr\u00e9", ""], ["Sick", "Bernhard", ""]]}, {"id": "2010.05906", "submitter": "Lianhui Qin", "authors": "Lianhui Qin, Vered Shwartz, Peter West, Chandra Bhagavatula, Jena\n  Hwang, Ronan Le Bras, Antoine Bosselut, Yejin Choi", "title": "Back to the Future: Unsupervised Backprop-based Decoding for\n  Counterfactual and Abductive Commonsense Reasoning", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abductive and counterfactual reasoning, core abilities of everyday human\ncognition, require reasoning about what might have happened at time t, while\nconditioning on multiple contexts from the relative past and future. However,\nsimultaneous incorporation of past and future contexts using generative\nlanguage models (LMs) can be challenging, as they are trained either to\ncondition only on the past context or to perform narrowly scoped\ntext-infilling. In this paper, we propose DeLorean, a new unsupervised decoding\nalgorithm that can flexibly incorporate both the past and future contexts using\nonly off-the-shelf, left-to-right language models and no supervision. The key\nintuition of our algorithm is incorporating the future through\nback-propagation, during which, we only update the internal representation of\nthe output while fixing the model parameters. By alternating between forward\nand backward propagation, DeLorean can decode the output representation that\nreflects both the left and right contexts. We demonstrate that our approach is\ngeneral and applicable to two nonmonotonic reasoning tasks: abductive text\ngeneration and counterfactual story revision, where DeLorean outperforms a\nrange of unsupervised and some supervised methods, based on automatic and human\nevaluation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 17:58:43 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 05:39:07 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 07:59:45 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Qin", "Lianhui", ""], ["Shwartz", "Vered", ""], ["West", "Peter", ""], ["Bhagavatula", "Chandra", ""], ["Hwang", "Jena", ""], ["Bras", "Ronan Le", ""], ["Bosselut", "Antoine", ""], ["Choi", "Yejin", ""]]}, {"id": "2010.05909", "submitter": "Sahar Tavakoli", "authors": "Sahar Tavakoli", "title": "PhD dissertation to infer multiple networks from microbial data", "comments": "PhD dissertation, Univ Central Florida (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interactions among the constituent members of a microbial community play\na major role in determining the overall behavior of the community and the\nabundance levels of its members. These interactions can be modeled using a\nnetwork whose nodes represent microbial taxa and edges represent pairwise\ninteractions. A microbial network is a weighted graph that is constructed from\na sample-taxa count matrix, and can be used to model co-occurrences and/or\ninteractions of the constituent members of a microbial community. The nodes in\nthis graph represent microbial taxa and the edges represent pairwise\nassociations amongst these taxa. A microbial network is typically constructed\nfrom a sample-taxa count matrix that is obtained by sequencing multiple\nbiological samples and identifying taxa counts. From large-scale microbiome\nstudies, it is evident that microbial community compositions and interactions\nare impacted by environmental and/or host factors. Thus, it is not unreasonable\nto expect that a sample-taxa matrix generated as part of a large study\ninvolving multiple environmental or clinical parameters can be associated with\nmore than one microbial network. However, to our knowledge, microbial network\ninference methods proposed thus far assume that the sample-taxa matrix is\nassociated with a single network.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 19:16:26 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 19:51:56 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Tavakoli", "Sahar", ""]]}, {"id": "2010.05941", "submitter": "Noble Kennamer", "authors": "Noble Kennamer, Emille E. O. Ishida, Santiago Gonzalez-Gaitan, Rafael\n  S. de Souza, Alexander Ihler, Kara Ponder, Ricardo Vilalta, Anais Moller,\n  David O. Jones, Mi Dai, Alberto Krone-Martins, Bruno Quint, Sreevarsha\n  Sreejith, Alex I. Malz, Lluis Galbany (The LSST Dark Energy Science\n  Collaboration and the COIN collaboration)", "title": "Active learning with RESSPECT: Resource allocation for extragalactic\n  astronomical transients", "comments": "Accepted to the 2020 IEEE Symposium Series on Computational\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent increase in volume and complexity of available astronomical data\nhas led to a wide use of supervised machine learning techniques. Active\nlearning strategies have been proposed as an alternative to optimize the\ndistribution of scarce labeling resources. However, due to the specific\nconditions in which labels can be acquired, fundamental assumptions, such as\nsample representativeness and labeling cost stability cannot be fulfilled. The\nRecommendation System for Spectroscopic follow-up (RESSPECT) project aims to\nenable the construction of optimized training samples for the Rubin Observatory\nLegacy Survey of Space and Time (LSST), taking into account a realistic\ndescription of the astronomical data environment. In this work, we test the\nrobustness of active learning techniques in a realistic simulated astronomical\ndata scenario. Our experiment takes into account the evolution of training and\npool samples, different costs per object, and two different sources of budget.\nResults show that traditional active learning strategies significantly\noutperform random sampling. Nevertheless, more complex batch strategies are not\nable to significantly overcome simple uncertainty sampling techniques. Our\nfindings illustrate three important points: 1) active learning strategies are a\npowerful tool to optimize the label-acquisition task in astronomy, 2) for\nupcoming large surveys like LSST, such techniques allow us to tailor the\nconstruction of the training sample for the first day of the survey, and 3) the\npeculiar data environment related to the detection of astronomical transients\nis a fertile ground that calls for the development of tailored machine learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 18:04:04 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 21:05:03 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Kennamer", "Noble", "", "The LSST Dark Energy Science\n  Collaboration and the COIN collaboration"], ["Ishida", "Emille E. O.", "", "The LSST Dark Energy Science\n  Collaboration and the COIN collaboration"], ["Gonzalez-Gaitan", "Santiago", "", "The LSST Dark Energy Science\n  Collaboration and the COIN collaboration"], ["de Souza", "Rafael S.", "", "The LSST Dark Energy Science\n  Collaboration and the COIN collaboration"], ["Ihler", "Alexander", "", "The LSST Dark Energy Science\n  Collaboration and the COIN collaboration"], ["Ponder", "Kara", "", "The LSST Dark Energy Science\n  Collaboration and the COIN collaboration"], ["Vilalta", "Ricardo", "", "The LSST Dark Energy Science\n  Collaboration and the COIN collaboration"], ["Moller", "Anais", "", "The LSST Dark Energy Science\n  Collaboration and the COIN collaboration"], ["Jones", "David O.", "", "The LSST Dark Energy Science\n  Collaboration and the COIN collaboration"], ["Dai", "Mi", "", "The LSST Dark Energy Science\n  Collaboration and the COIN collaboration"], ["Krone-Martins", "Alberto", "", "The LSST Dark Energy Science\n  Collaboration and the COIN collaboration"], ["Quint", "Bruno", "", "The LSST Dark Energy Science\n  Collaboration and the COIN collaboration"], ["Sreejith", "Sreevarsha", "", "The LSST Dark Energy Science\n  Collaboration and the COIN collaboration"], ["Malz", "Alex I.", "", "The LSST Dark Energy Science\n  Collaboration and the COIN collaboration"], ["Galbany", "Lluis", "", "The LSST Dark Energy Science\n  Collaboration and the COIN collaboration"]]}, {"id": "2010.05961", "submitter": "Ewan Dunbar", "authors": "Juliette Millet and Ewan Dunbar", "title": "Perceptimatic: A human speech perception benchmark for unsupervised\n  subword modelling", "comments": null, "journal-ref": "Proceedings of Interspeech 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a data set and methods to compare speech processing\nmodels and human behaviour on a phone discrimination task. We provide\nPerceptimatic, an open data set which consists of French and English speech\nstimuli, as well as the results of 91 English- and 93 French-speaking\nlisteners. The stimuli test a wide range of French and English contrasts, and\nare extracted directly from corpora of natural running read speech, used for\nthe 2017 Zero Resource Speech Challenge. We provide a method to compare humans'\nperceptual space with models' representational space, and we apply it to models\npreviously submitted to the Challenge. We show that, unlike unsupervised models\nand supervised multilingual models, a standard supervised monolingual HMM-GMM\nphone recognition system, while good at discriminating phones, yields a\nrepresentational space very different from that of human native listeners.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 18:40:08 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Millet", "Juliette", ""], ["Dunbar", "Ewan", ""]]}, {"id": "2010.05967", "submitter": "Ewan Dunbar", "authors": "Ewan Dunbar and Julien Karadayi and Mathieu Bernard and Xuan-Nga Cao\n  and Robin Algayres and Lucas Ondel and Laurent Besacier and Sakriani Sakti\n  and Emmanuel Dupoux", "title": "The Zero Resource Speech Challenge 2020: Discovering discrete subword\n  and word units", "comments": null, "journal-ref": "Proceedings of Interspeech 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Zero Resource Speech Challenge 2020, which aims at learning\nspeech representations from raw audio signals without any labels. It combines\nthe data sets and metrics from two previous benchmarks (2017 and 2019) and\nfeatures two tasks which tap into two levels of speech representation. The\nfirst task is to discover low bit-rate subword representations that optimize\nthe quality of speech synthesis; the second one is to discover word-like units\nfrom unsegmented raw speech. We present the results of the twenty submitted\nmodels and discuss the implications of the main findings for unsupervised\nspeech learning.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 18:56:48 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Dunbar", "Ewan", ""], ["Karadayi", "Julien", ""], ["Bernard", "Mathieu", ""], ["Cao", "Xuan-Nga", ""], ["Algayres", "Robin", ""], ["Ondel", "Lucas", ""], ["Besacier", "Laurent", ""], ["Sakti", "Sakriani", ""], ["Dupoux", "Emmanuel", ""]]}, {"id": "2010.05970", "submitter": "Jonathan Hersh", "authors": "Hannes Mueller, Andre Groger, Jonathan Hersh, Andrea Matranga and Joan\n  Serrat", "title": "Monitoring War Destruction from Space: A Machine Learning Approach", "comments": null, "journal-ref": null, "doi": "10.1073/pnas.2025400118", "report-no": null, "categories": "econ.GN cs.AI cs.CV q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing data on building destruction in conflict zones rely on eyewitness\nreports or manual detection, which makes it generally scarce, incomplete and\npotentially biased. This lack of reliable data imposes severe limitations for\nmedia reporting, humanitarian relief efforts, human rights monitoring,\nreconstruction initiatives, and academic studies of violent conflict. This\narticle introduces an automated method of measuring destruction in\nhigh-resolution satellite images using deep learning techniques combined with\ndata augmentation to expand training samples. We apply this method to the\nSyrian civil war and reconstruct the evolution of damage in major cities across\nthe country. The approach allows generating destruction data with unprecedented\nscope, resolution, and frequency - only limited by the available satellite\nimagery - which can alleviate data limitations decisively.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 19:01:20 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 03:47:28 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Mueller", "Hannes", ""], ["Groger", "Andre", ""], ["Hersh", "Jonathan", ""], ["Matranga", "Andrea", ""], ["Serrat", "Joan", ""]]}, {"id": "2010.05979", "submitter": "Sahar Tavakoli", "authors": "Sahar Tavakoli", "title": "Signal classification using weighted orthogonal regression method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new classifier based on the intrinsic properties of the data\nis proposed. Classification is an essential task in data mining-based\napplications. The classification problem will be challenging when the size of\nthe training set is not sufficient to compare to the dimension of the problem.\nThis paper proposes a new classification method that exploits the intrinsic\nstructure of each class through the corresponding Eigen components. Each\ncomponent contributes to the learned span of each class by specific weight. The\nweight is determined by the associated eigenvalue. This approach results in\nreliable learning robust in the case of facing a classification problem with\nlimited training data. The proposed method involves the obtained Eigenvectors\nby SVD of data from each class to select the bases for each subspace. Moreover,\nit considers an efficient weighting for the decision-making criterion to\ndiscriminate two classes. In addition to high performance on artificial data,\nthis method has increased the best result of international competition.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 19:12:14 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Tavakoli", "Sahar", ""]]}, {"id": "2010.05983", "submitter": "Gaojie Jin", "authors": "Gaojie Jin, Xinping Yi, Liang Zhang, Lijun Zhang, Sven Schewe, Xiaowei\n  Huang", "title": "How does Weight Correlation Affect the Generalisation Ability of Deep\n  Neural Networks", "comments": "Accpeted by NeurIPS 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the novel concept of weight correlation in deep neural\nnetworks and discusses its impact on the networks' generalisation ability. For\nfully-connected layers, the weight correlation is defined as the average cosine\nsimilarity between weight vectors of neurons, and for convolutional layers, the\nweight correlation is defined as the cosine similarity between filter matrices.\nTheoretically, we show that, weight correlation can, and should, be\nincorporated into the PAC Bayesian framework for the generalisation of neural\nnetworks, and the resulting generalisation bound is monotonic with respect to\nthe weight correlation. We formulate a new complexity measure, which lifts the\nPAC Bayes measure with weight correlation, and experimentally confirm that it\nis able to rank the generalisation errors of a set of networks more precisely\nthan existing measures. More importantly, we develop a new regulariser for\ntraining, and provide extensive experiments that show that the generalisation\nerror can be greatly reduced with our novel approach.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 19:18:27 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 09:33:10 GMT"}, {"version": "v3", "created": "Sat, 17 Oct 2020 22:38:21 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Jin", "Gaojie", ""], ["Yi", "Xinping", ""], ["Zhang", "Liang", ""], ["Zhang", "Lijun", ""], ["Schewe", "Sven", ""], ["Huang", "Xiaowei", ""]]}, {"id": "2010.05985", "submitter": "Alexander Gutkin", "authors": "Alexander Gutkin and Richard Sproat", "title": "NEMO: Frequentist Inference Approach to Constrained Linguistic Typology\n  Feature Prediction in SIGTYP 2020 Shared Task", "comments": "To appear in Second Workshop on Computational Research in Linguistic\n  Typology (SIGTYP 2020) at 2020 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper describes the NEMO submission to SIGTYP 2020 shared task which\ndeals with prediction of linguistic typological features for multiple languages\nusing the data derived from World Atlas of Language Structures (WALS). We\nemploy frequentist inference to represent correlations between typological\nfeatures and use this representation to train simple multi-class estimators\nthat predict individual features. We describe two submitted ridge\nregression-based configurations which ranked second and third overall in the\nconstrained task. Our best configuration achieved the micro-averaged accuracy\nscore of 0.66 on 149 test languages.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 19:25:43 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Gutkin", "Alexander", ""], ["Sproat", "Richard", ""]]}, {"id": "2010.05990", "submitter": "Jordan J. Bird", "authors": "Jordan J. Bird, Anik\\'o Ek\\'art, Diego R. Faria", "title": "Chatbot Interaction with Artificial Intelligence: Human Data\n  Augmentation with T5 and Language Transformer Ensemble for Text\n  Classification", "comments": "18 pages, 10 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present the Chatbot Interaction with Artificial Intelligence\n(CI-AI) framework as an approach to the training of deep learning chatbots for\ntask classification. The intelligent system augments human-sourced data via\nartificial paraphrasing in order to generate a large set of training data for\nfurther classical, attention, and language transformation-based learning\napproaches for Natural Language Processing. Human beings are asked to\nparaphrase commands and questions for task identification for further execution\nof a machine. The commands and questions are split into training and validation\nsets. A total of 483 responses were recorded. Secondly, the training set is\nparaphrased by the T5 model in order to augment it with further data. Seven\nstate-of-the-art transformer-based text classification algorithms (BERT,\nDistilBERT, RoBERTa, DistilRoBERTa, XLM, XLM-RoBERTa, and XLNet) are\nbenchmarked for both sets after fine-tuning on the training data for two\nepochs. We find that all models are improved when training data is augmented by\nthe T5 model, with an average increase of classification accuracy by 4.01%. The\nbest result was the RoBERTa model trained on T5 augmented data which achieved\n98.96% classification accuracy. Finally, we found that an ensemble of the five\nbest-performing transformer models via Logistic Regression of output label\npredictions led to an accuracy of 99.59% on the dataset of human responses. A\nhighly-performing model allows the intelligent system to interpret human\ncommands at the social-interaction level through a chatbot-like interface (e.g.\n\"Robot, can we have a conversation?\") and allows for better accessibility to AI\nby non-technical users.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 19:37:18 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 14:33:08 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Bird", "Jordan J.", ""], ["Ek\u00e1rt", "Anik\u00f3", ""], ["Faria", "Diego R.", ""]]}, {"id": "2010.05993", "submitter": "Andrea Zugarini", "authors": "Andrea Zugarini and Matteo Tiezzi and Marco Maggini", "title": "Vulgaris: Analysis of a Corpus for Middle-Age Varieties of Italian\n  Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Italian is a Romance language that has its roots in Vulgar Latin. The birth\nof the modern Italian started in Tuscany around the 14th century, and it is\nmainly attributed to the works of Dante Alighieri, Francesco Petrarca and\nGiovanni Boccaccio, who are among the most acclaimed authors of the medieval\nage in Tuscany. However, Italy has been characterized by a high variety of\ndialects, which are often loosely related to each other, due to the past\nfragmentation of the territory. Italian has absorbed influences from many of\nthese dialects, as also from other languages due to dominion of portions of the\ncountry by other nations, such as Spain and France. In this work we present\nVulgaris, a project aimed at studying a corpus of Italian textual resources\nfrom authors of different regions, ranging in a time period between 1200 and\n1600. Each composition is associated to its author, and authors are also\ngrouped in families, i.e. sharing similar stylistic/chronological\ncharacteristics. Hence, the dataset is not only a valuable resource for\nstudying the diachronic evolution of Italian and the differences between its\ndialects, but it is also useful to investigate stylistic aspects between single\nauthors. We provide a detailed statistical analysis of the data, and a\ncorpus-driven study in dialectology and diachronic varieties.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 19:42:22 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Zugarini", "Andrea", ""], ["Tiezzi", "Matteo", ""], ["Maggini", "Marco", ""]]}, {"id": "2010.05995", "submitter": "Nesime Tatbul", "authors": "Akhilesh Gupta, Nesime Tatbul, Ryan Marcus, Shengtian Zhou, Insup Lee,\n  Justin Gottschlich", "title": "Class-Weighted Evaluation Metrics for Imbalanced Data Classification", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class distribution skews in imbalanced datasets may lead to models with\nprediction bias towards majority classes, making fair assessment of classifiers\na challenging task. Balanced Accuracy is a popular metric used to evaluate a\nclassifier's prediction performance under such scenarios. However, this metric\nfalls short when classes vary in importance, especially when class importance\nis skewed differently from class cardinality distributions. In this paper, we\npropose a simple and general-purpose evaluation framework for imbalanced data\nclassification that is sensitive to arbitrary skews in class cardinalities and\nimportances. Experiments with several state-of-the-art classifiers tested on\nreal-world datasets and benchmarks from two different domains show that our new\nframework is more effective than Balanced Accuracy -- not only in evaluating\nand ranking model predictions, but also in training the models themselves.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 19:47:09 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Gupta", "Akhilesh", ""], ["Tatbul", "Nesime", ""], ["Marcus", "Ryan", ""], ["Zhou", "Shengtian", ""], ["Lee", "Insup", ""], ["Gottschlich", "Justin", ""]]}, {"id": "2010.05997", "submitter": "Xing Jie Zhong", "authors": "Xing Jie Zhong, and David Chiang", "title": "Look It Up: Bilingual and Monolingual Dictionaries Improve Neural\n  Machine Translation", "comments": "Accepted for publication in Proceedings of WMT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite advances in neural machine translation (NMT) quality, rare words\ncontinue to be problematic. For humans, the solution to the rare-word problem\nhas long been dictionaries, but dictionaries cannot be straightforwardly\nincorporated into NMT. In this paper, we describe a new method for \"attaching\"\ndictionary definitions to rare words so that the network can learn the best way\nto use them. We demonstrate improvements of up to 3.1 BLEU using bilingual\ndictionaries and up to 0.7 BLEU using monolingual source-language dictionaries.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 19:53:08 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Zhong", "Xing Jie", ""], ["Chiang", "David", ""]]}, {"id": "2010.06002", "submitter": "Andrea Loreggia", "authors": "Grady Booch, Francesco Fabiano, Lior Horesh, Kiran Kate, Jon Lenchner,\n  Nick Linck, Andrea Loreggia, Keerthiram Murugesan, Nicholas Mattei, Francesca\n  Rossi, Biplav Srivastava", "title": "Thinking Fast and Slow in AI", "comments": null, "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence\n  2021, 35(17), 15042-15046", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a research direction to advance AI which draws\ninspiration from cognitive theories of human decision making. The premise is\nthat if we gain insights about the causes of some human capabilities that are\nstill lacking in AI (for instance, adaptability, generalizability, common\nsense, and causal reasoning), we may obtain similar capabilities in an AI\nsystem by embedding these causal components. We hope that the high-level\ndescription of our vision included in this paper, as well as the several\nresearch questions that we propose to consider, can stimulate the AI research\ncommunity to define, try and evaluate new methodologies, frameworks, and\nevaluation metrics, in the spirit of achieving a better understanding of both\nhuman and machine intelligence.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 20:10:05 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 21:12:08 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Booch", "Grady", ""], ["Fabiano", "Francesco", ""], ["Horesh", "Lior", ""], ["Kate", "Kiran", ""], ["Lenchner", "Jon", ""], ["Linck", "Nick", ""], ["Loreggia", "Andrea", ""], ["Murugesan", "Keerthiram", ""], ["Mattei", "Nicholas", ""], ["Rossi", "Francesca", ""], ["Srivastava", "Biplav", ""]]}, {"id": "2010.06007", "submitter": "Teerapat Jenrungrot", "authors": "Teerapat Jenrungrot, Vivek Jayaram, Steve Seitz, Ira\n  Kemelmacher-Shlizerman", "title": "The Cone of Silence: Speech Separation by Localization", "comments": "9 pages + references + supplementary. Oral presentation at NeurIPS\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a multi-microphone recording of an unknown number of speakers talking\nconcurrently, we simultaneously localize the sources and separate the\nindividual speakers. At the core of our method is a deep network, in the\nwaveform domain, which isolates sources within an angular region $\\theta \\pm\nw/2$, given an angle of interest $\\theta$ and angular window size $w$. By\nexponentially decreasing $w$, we can perform a binary search to localize and\nseparate all sources in logarithmic time. Our algorithm allows for an arbitrary\nnumber of potentially moving speakers at test time, including more speakers\nthan seen during training. Experiments demonstrate state-of-the-art performance\nfor both source separation and source localization, particularly in high levels\nof background noise.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 20:19:23 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Jenrungrot", "Teerapat", ""], ["Jayaram", "Vivek", ""], ["Seitz", "Steve", ""], ["Kemelmacher-Shlizerman", "Ira", ""]]}, {"id": "2010.06030", "submitter": "Jiahui Yu", "authors": "Jiahui Yu, Wei Han, Anmol Gulati, Chung-Cheng Chiu, Bo Li, Tara N.\n  Sainath, Yonghui Wu, Ruoming Pang", "title": "Dual-mode ASR: Unify and Improve Streaming ASR with Full-context\n  Modeling", "comments": "Accepted in ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Streaming automatic speech recognition (ASR) aims to emit each hypothesized\nword as quickly and accurately as possible, while full-context ASR waits for\nthe completion of a full speech utterance before emitting completed hypotheses.\nIn this work, we propose a unified framework, Dual-mode ASR, to train a single\nend-to-end ASR model with shared weights for both streaming and full-context\nspeech recognition. We show that the latency and accuracy of streaming ASR\nsignificantly benefit from weight sharing and joint training of full-context\nASR, especially with inplace knowledge distillation during the training. The\nDual-mode ASR framework can be applied to recent state-of-the-art\nconvolution-based and transformer-based ASR networks. We present extensive\nexperiments with two state-of-the-art ASR networks, ContextNet and Conformer,\non two datasets, a widely used public dataset LibriSpeech and a large-scale\ndataset MultiDomain. Experiments and ablation studies demonstrate that\nDual-mode ASR not only simplifies the workflow of training and deploying\nstreaming and full-context ASR models, but also significantly improves both\nemission latency and recognition accuracy of streaming ASR. With Dual-mode ASR,\nwe achieve new state-of-the-art streaming ASR results on both LibriSpeech and\nMultiDomain in terms of accuracy and latency.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 21:12:56 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 17:56:46 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Yu", "Jiahui", ""], ["Han", "Wei", ""], ["Gulati", "Anmol", ""], ["Chiu", "Chung-Cheng", ""], ["Li", "Bo", ""], ["Sainath", "Tara N.", ""], ["Wu", "Yonghui", ""], ["Pang", "Ruoming", ""]]}, {"id": "2010.06034", "submitter": "Sharib Ali Dr.", "authors": "Sharib Ali, Mariia Dmitrieva, Noha Ghatwary, Sophia Bano, Gorkem\n  Polat, Alptekin Temizel, Adrian Krenzer, Amar Hekalo, Yun Bo Guo, Bogdan\n  Matuszewski, Mourad Gridach, Irina Voiculescu, Vishnusai Yoganand, Arnav\n  Chavan, Aryan Raj, Nhan T. Nguyen, Dat Q. Tran, Le Duy Huynh, Nicolas Boutry,\n  Shahadate Rezvy, Haijian Chen, Yoon Ho Choi, Anand Subramanian, Velmurugan\n  Balasubramanian, Xiaohong W. Gao, Hongyu Hu, Yusheng Liao, Danail Stoyanov,\n  Christian Daul, Stefano Realdon, Renato Cannizzaro, Dominique Lamarque, Terry\n  Tran-Nguyen, Adam Bailey, Barbara Braden, James East and Jens Rittscher", "title": "Deep learning for detection and segmentation of artefact and disease\n  instances in gastrointestinal endoscopy", "comments": "32 pages", "journal-ref": null, "doi": "10.1016/j.media.2021.102002", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Endoscopy Computer Vision Challenge (EndoCV) is a crowd-sourcing\ninitiative to address eminent problems in developing reliable computer aided\ndetection and diagnosis endoscopy systems and suggest a pathway for clinical\ntranslation of technologies. Whilst endoscopy is a widely used diagnostic and\ntreatment tool for hollow-organs, there are several core challenges often faced\nby endoscopists, mainly: 1) presence of multi-class artefacts that hinder their\nvisual interpretation, and 2) difficulty in identifying subtle precancerous\nprecursors and cancer abnormalities. Artefacts often affect the robustness of\ndeep learning methods applied to the gastrointestinal tract organs as they can\nbe confused with tissue of interest. EndoCV2020 challenges are designed to\naddress research questions in these remits. In this paper, we present a summary\nof methods developed by the top 17 teams and provide an objective comparison of\nstate-of-the-art methods and methods designed by the participants for two\nsub-challenges: i) artefact detection and segmentation (EAD2020), and ii)\ndisease detection and segmentation (EDD2020). Multi-center, multi-organ,\nmulti-class, and multi-modal clinical endoscopy datasets were compiled for both\nEAD2020 and EDD2020 sub-challenges. The out-of-sample generalization ability of\ndetection algorithms was also evaluated. Whilst most teams focused on accuracy\nimprovements, only a few methods hold credibility for clinical usability. The\nbest performing teams provided solutions to tackle class imbalance, and\nvariabilities in size, origin, modality and occurrences by exploring data\naugmentation, data fusion, and optimal class thresholding techniques.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 21:22:37 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 17:49:32 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Ali", "Sharib", ""], ["Dmitrieva", "Mariia", ""], ["Ghatwary", "Noha", ""], ["Bano", "Sophia", ""], ["Polat", "Gorkem", ""], ["Temizel", "Alptekin", ""], ["Krenzer", "Adrian", ""], ["Hekalo", "Amar", ""], ["Guo", "Yun Bo", ""], ["Matuszewski", "Bogdan", ""], ["Gridach", "Mourad", ""], ["Voiculescu", "Irina", ""], ["Yoganand", "Vishnusai", ""], ["Chavan", "Arnav", ""], ["Raj", "Aryan", ""], ["Nguyen", "Nhan T.", ""], ["Tran", "Dat Q.", ""], ["Huynh", "Le Duy", ""], ["Boutry", "Nicolas", ""], ["Rezvy", "Shahadate", ""], ["Chen", "Haijian", ""], ["Choi", "Yoon Ho", ""], ["Subramanian", "Anand", ""], ["Balasubramanian", "Velmurugan", ""], ["Gao", "Xiaohong W.", ""], ["Hu", "Hongyu", ""], ["Liao", "Yusheng", ""], ["Stoyanov", "Danail", ""], ["Daul", "Christian", ""], ["Realdon", "Stefano", ""], ["Cannizzaro", "Renato", ""], ["Lamarque", "Dominique", ""], ["Tran-Nguyen", "Terry", ""], ["Bailey", "Adam", ""], ["Braden", "Barbara", ""], ["East", "James", ""], ["Rittscher", "Jens", ""]]}, {"id": "2010.06040", "submitter": "Dinghan Shen", "authors": "Mingzhi Zheng, Dinghan Shen, Yelong Shen, Weizhu Chen, Lin Xiao", "title": "Improving Self-supervised Pre-training via a Fully-Explored Masked\n  Language Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Masked Language Model (MLM) framework has been widely adopted for\nself-supervised language pre-training. In this paper, we argue that randomly\nsampled masks in MLM would lead to undesirably large gradient variance. Thus,\nwe theoretically quantify the gradient variance via correlating the gradient\ncovariance with the Hamming distance between two different masks (given a\ncertain text sequence). To reduce the variance due to the sampling of masks, we\npropose a fully-explored masking strategy, where a text sequence is divided\ninto a certain number of non-overlapping segments. Thereafter, the tokens\nwithin one segment are masked for training. We prove, from a theoretical\nperspective, that the gradients derived from this new masking schema have a\nsmaller variance and can lead to more efficient self-supervised training. We\nconduct extensive experiments on both continual pre-training and general\npre-training from scratch. Empirical results confirm that this new masking\nstrategy can consistently outperform standard random masking. Detailed\nefficiency analysis and ablation studies further validate the advantages of our\nfully-explored masking strategy under the MLM framework.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 21:28:14 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 04:45:59 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Zheng", "Mingzhi", ""], ["Shen", "Dinghan", ""], ["Shen", "Yelong", ""], ["Chen", "Weizhu", ""], ["Xiao", "Lin", ""]]}, {"id": "2010.06047", "submitter": "Saturnino Luz", "authors": "Sofia de la Fuente Garcia, Craig Ritchie and Saturnino Luz", "title": "Artificial Intelligence, speech and language processing approaches to\n  monitoring Alzheimer's Disease: a systematic review", "comments": "Pre-print submitted to the Journal of Alzheimer's Disease", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language is a valuable source of clinical information in Alzheimer's Disease,\nas it declines concurrently with neurodegeneration. Consequently, speech and\nlanguage data have been extensively studied in connection with its diagnosis.\nThis paper summarises current findings on the use of artificial intelligence,\nspeech and language processing to predict cognitive decline in the context of\nAlzheimer's Disease, detailing current research procedures, highlighting their\nlimitations and suggesting strategies to address them. We conducted a\nsystematic review of original research between 2000 and 2019, registered in\nPROSPERO (reference CRD42018116606). An interdisciplinary search covered six\ndatabases on engineering (ACM and IEEE), psychology (PsycINFO), medicine\n(PubMed and Embase) and Web of Science. Bibliographies of relevant papers were\nscreened until December 2019. From 3,654 search results 51 articles were\nselected against the eligibility criteria. Four tables summarise their\nfindings: study details (aim, population, interventions, comparisons, methods\nand outcomes), data details (size, type, modalities, annotation, balance,\navailability and language of study), methodology (pre-processing, feature\ngeneration, machine learning, evaluation and results) and clinical\napplicability (research implications, clinical potential, risk of bias and\nstrengths/limitations). While promising results are reported across nearly all\n51 studies, very few have been implemented in clinical research or practice. We\nconcluded that the main limitations of the field are poor standardisation,\nlimited comparability of results, and a degree of disconnect between study aims\nand clinical applications. Attempts to close these gaps should support\ntranslation of future research into clinical practice.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 21:43:04 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Garcia", "Sofia de la Fuente", ""], ["Ritchie", "Craig", ""], ["Luz", "Saturnino", ""]]}, {"id": "2010.06049", "submitter": "Alejandro Flores Mr", "authors": "A. Flores and G. Flores", "title": "Implementation of a neural network for non-linearities estimation in a\n  tail-sitter aircraft", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The control of a tail-sitter aircraft is a challenging task, especially\nduring transition maneuver where the lift and drag forces are highly nonlinear.\nIn this work, we implement a Neural Network (NN) capable of estimate such\nnonlinearities. Once they are estimated, one can propose a control scheme where\nthese forces can correctly feed-forwarded. Our implementation of the NN has\nbeen programmed in C++ on the PX4 Autopilot an open-source autopilot for\ndrones. To ensure that this implementation does not considerably affect the\nautopilot's performance, the coded NN must be of a light computational load.\nWith the aim to test our approach, we have carried out a series of realistic\nsimulations in the Software in The Loop (SITL) using the PX4 Autopilot. These\nexperiments demonstrate that the implemented NN can be used to estimate the\ntail-sitter aerodynamic forces, and can be used to improve the control\nalgorithms during all the flight phases of the tail-sitter aircraft: hover,\ncruise flight, and transition.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 21:46:16 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Flores", "A.", ""], ["Flores", "G.", ""]]}, {"id": "2010.06059", "submitter": "Sonia Baee", "authors": "Sonia Baee, Mark Rucker, Anna Baglione, Mawulolo K. Ameko, Laura\n  Barnes", "title": "A Framework for Addressing the Risks and Opportunities In AI-Supported\n  Virtual Health Coaches", "comments": "4 pages", "journal-ref": null, "doi": "10.1145/3421937.3421971", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual coaching has rapidly evolved into a foundational component of modern\nclinical practice. At a time when healthcare professionals are in short supply\nand the demand for low-cost treatments is ever-increasing, virtual health\ncoaches (VHCs) offer intervention-on-demand for those limited by finances or\ngeographic access to care. More recently, AI-powered virtual coaches have\nbecome a viable complement to human coaches. However, the push for AI-powered\ncoaching systems raises several important issues for researchers, designers,\nclinicians, and patients. In this paper, we present a novel framework to guide\nthe design and development of virtual coaching systems. This framework augments\na traditional data science pipeline with four key guiding goals: reliability,\nfairness, engagement, and ethics.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 22:41:35 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Baee", "Sonia", ""], ["Rucker", "Mark", ""], ["Baglione", "Anna", ""], ["Ameko", "Mawulolo K.", ""], ["Barnes", "Laura", ""]]}, {"id": "2010.06065", "submitter": "Zonghai Yao", "authors": "Zonghai Yao, Liangliang Cao and Huapu Pan", "title": "Zero-shot Entity Linking with Efficient Long Range Sequence Modeling", "comments": "6 pages, 6 figures, Findings of EMNLP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of zero-shot entity linking, in which a link\nin the test time may not present in training. Following the prevailing\nBERT-based research efforts, we find a simple yet effective way is to expand\nthe long-range sequence modeling. Unlike many previous methods, our method does\nnot require expensive pre-training of BERT with long position embedding.\nInstead, we propose an efficient position embeddings initialization method\ncalled Embedding-repeat, which initializes larger position embeddings based on\nBERT-Base. On Wikia's zero-shot EL dataset, our method improves the SOTA from\n76.06% to 79.08%, and for its long data, the corresponding improvement is from\n74.57% to 82.14%. Our experiments suggest the effectiveness of long-range\nsequence modeling without retraining the BERT model.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 22:59:18 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Yao", "Zonghai", ""], ["Cao", "Liangliang", ""], ["Pan", "Huapu", ""]]}, {"id": "2010.06076", "submitter": "George Monta\\~nez", "authors": "Daniel Bashir, George D. Montanez, Sonia Sehra, Pedro Sandoval Segura,\n  Julius Lauw", "title": "An Information-Theoretic Perspective on Overfitting and Underfitting", "comments": "Accepted for presentation at The 33rd Australasian Joint Conference\n  on Artificial Intelligence (AJCAI 2020), November 29-30, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an information-theoretic framework for understanding overfitting\nand underfitting in machine learning and prove the formal undecidability of\ndetermining whether an arbitrary classification algorithm will overfit a\ndataset. Measuring algorithm capacity via the information transferred from\ndatasets to models, we consider mismatches between algorithm capacities and\ndatasets to provide a signature for when a model can overfit or underfit a\ndataset. We present results upper-bounding algorithm capacity, establish its\nrelationship to quantities in the algorithmic search framework for machine\nlearning, and relate our work to recent information-theoretic approaches to\ngeneralization.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 23:24:47 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 19:22:53 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Bashir", "Daniel", ""], ["Montanez", "George D.", ""], ["Sehra", "Sonia", ""], ["Segura", "Pedro Sandoval", ""], ["Lauw", "Julius", ""]]}, {"id": "2010.06084", "submitter": "Sean Andrist", "authors": "Sean Andrist and Dan Bohus", "title": "Accelerating the Development of Multimodal, Integrative-AI Systems with\n  Platform for Situated Intelligence", "comments": "5 pages, 1 figure. Submitted to the 2020 AAAI Fall Symposium: Trust\n  and Explainability in Artificial Intelligence for Human-Robot Interaction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe Platform for Situated Intelligence, an open-source framework for\nmultimodal, integrative-AI systems. The framework provides infrastructure,\ntools, and components that enable and accelerate the development of\napplications that process multimodal streams of data and in which timing is\ncritical. The framework is particularly well-suited for developing physically\nsituated interactive systems that perceive and reason about their surroundings\nin order to better interact with people, such as social robots, virtual\nassistants, smart meeting rooms, etc. In this paper, we provide a brief,\nhigh-level overview of the framework and its main affordances, and discuss its\nimplications for HRI.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 23:53:12 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Andrist", "Sean", ""], ["Bohus", "Dan", ""]]}, {"id": "2010.06113", "submitter": "Shubham Sharma", "authors": "Shubham Sharma, Alan H. Gee, David Paydarfar, Joydeep Ghosh", "title": "FaiR-N: Fair and Robust Neural Networks for Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness in machine learning is crucial when individuals are subject to\nautomated decisions made by models in high-stake domains. Organizations that\nemploy these models may also need to satisfy regulations that promote\nresponsible and ethical A.I. While fairness metrics relying on comparing model\nerror rates across subpopulations have been widely investigated for the\ndetection and mitigation of bias, fairness in terms of the equalized ability to\nachieve recourse for different protected attribute groups has been relatively\nunexplored. We present a novel formulation for training neural networks that\nconsiders the distance of data points to the decision boundary such that the\nnew objective: (1) reduces the average distance to the decision boundary\nbetween two groups for individuals subject to a negative outcome in each group,\ni.e. the network is more fair with respect to the ability to obtain recourse,\nand (2) increases the average distance of data points to the boundary to\npromote adversarial robustness. We demonstrate that training with this loss\nyields more fair and robust neural networks with similar accuracies to models\ntrained without it. Moreover, we qualitatively motivate and empirically show\nthat reducing recourse disparity across groups also improves fairness measures\nthat rely on error rates. To the best of our knowledge, this is the first time\nthat recourse capabilities across groups are considered to train fairer neural\nnetworks, and a relation between error rates based fairness and recourse based\nfairness is investigated.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 01:53:15 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Sharma", "Shubham", ""], ["Gee", "Alan H.", ""], ["Paydarfar", "David", ""], ["Ghosh", "Joydeep", ""]]}, {"id": "2010.06119", "submitter": "Qingyun Wang", "authors": "Qingyun Wang, Qi Zeng, Lifu Huang, Kevin Knight, Heng Ji, Nazneen\n  Fatema Rajani", "title": "ReviewRobot: Explainable Paper Review Generation based on Knowledge\n  Synthesis", "comments": "14 pages. Accepted by The 14th International Conference on Natural\n  Language Generation (INLG 2020) Code and resource is available at\n  https://github.com/EagleW/ReviewRobot", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To assist human review process, we build a novel ReviewRobot to automatically\nassign a review score and write comments for multiple categories such as\nnovelty and meaningful comparison. A good review needs to be knowledgeable,\nnamely that the comments should be constructive and informative to help improve\nthe paper; and explainable by providing detailed evidence. ReviewRobot achieves\nthese goals via three steps: (1) We perform domain-specific Information\nExtraction to construct a knowledge graph (KG) from the target paper under\nreview, a related work KG from the papers cited by the target paper, and a\nbackground KG from a large collection of previous papers in the domain. (2) By\ncomparing these three KGs, we predict a review score and detailed structured\nknowledge as evidence for each review category. (3) We carefully select and\ngeneralize human review sentences into templates, and apply these templates to\ntransform the review scores and evidence into natural language comments.\nExperimental results show that our review score predictor reaches 71.4%-100%\naccuracy. Human assessment by domain experts shows that 41.7%-70.5% of the\ncomments generated by ReviewRobot are valid and constructive, and better than\nhuman-written ones for 20% of the time. Thus, ReviewRobot can serve as an\nassistant for paper reviewers, program chairs and authors.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 02:17:58 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 00:30:08 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 22:31:33 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Wang", "Qingyun", ""], ["Zeng", "Qi", ""], ["Huang", "Lifu", ""], ["Knight", "Kevin", ""], ["Ji", "Heng", ""], ["Rajani", "Nazneen Fatema", ""]]}, {"id": "2010.06164", "submitter": "Mauricio Gonzalez-Soto", "authors": "Mauricio Gonzalez-Soto, Ivan R. Feliciano-Avelino, L. Enrique Sucar,\n  Hugo J. Escalante Balderas", "title": "Causal Structure Learning: a Bayesian approach based on random graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Random Graph is a random object which take its values in the space of\ngraphs. We take advantage of the expressibility of graphs in order to model the\nuncertainty about the existence of causal relationships within a given set of\nvariables. We adopt a Bayesian point of view in order to capture a causal\nstructure via interaction and learning with a causal environment. We test our\nmethod over two different scenarios, and the experiments mainly confirm that\nour technique can learn a causal structure. Furthermore, the experiments and\nresults presented for the first test scenario demonstrate the usefulness of our\nmethod to learn a causal structure as well as the optimal action. On the other\nhand the second experiment, shows that our proposal manages to learn the\nunderlying causal structure of several tasks with different sizes and different\ncausal structures.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 04:13:06 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Gonzalez-Soto", "Mauricio", ""], ["Feliciano-Avelino", "Ivan R.", ""], ["Sucar", "L. Enrique", ""], ["Balderas", "Hugo J. Escalante", ""]]}, {"id": "2010.06187", "submitter": "Nahid Parvez Farazi", "authors": "Nahid Parvez Farazi, Tanvir Ahamed, Limon Barua, Bo Zou", "title": "Deep Reinforcement Learning and Transportation Research: A Comprehensive\n  Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) is an emerging methodology that is\ntransforming the way many complicated transportation decision-making problems\nare tackled. Researchers have been increasingly turning to this powerful\nlearning-based methodology to solve challenging problems across transportation\nfields. While many promising applications have been reported in the literature,\nthere remains a lack of comprehensive synthesis of the many DRL algorithms and\ntheir uses and adaptations. The objective of this paper is to fill this gap by\nconducting a comprehensive, synthesized review of DRL applications in\ntransportation. We start by offering an overview of the DRL mathematical\nbackground, popular and promising DRL algorithms, and some highly effective DRL\nextensions. Building on this overview, a systematic investigation of about 150\nDRL studies that have appeared in the transportation literature, divided into\nseven different categories, is performed. Building on this review, we continue\nto examine the applicability, strengths, shortcomings, and common and\napplication-specific issues of DRL techniques with regard to their applications\nin transportation. In the end, we recommend directions for future research and\npresent available resources for actually implementing DRL.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 05:23:11 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Farazi", "Nahid Parvez", ""], ["Ahamed", "Tanvir", ""], ["Barua", "Limon", ""], ["Zou", "Bo", ""]]}, {"id": "2010.06196", "submitter": "Zitao Liu", "authors": "Tianqiao Liu, Qian Fang, Wenbiao Ding, Zitao Liu", "title": "Mathematical Word Problem Generation from Commonsense Knowledge Graph\n  and Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing interest in the use of automatic mathematical word\nproblem (MWP) generation in educational assessment. Different from standard\nnatural question generation, MWP generation needs to maintain the underlying\nmathematical operations between quantities and variables, while at the same\ntime ensuring the relevance between the output and the given topic. To address\nabove problem, we develop an end-to-end neural model to generate diverse MWPs\nin real-world scenarios from commonsense knowledge graph and equations. The\nproposed model (1) learns both representations from edge-enhanced Levi graphs\nof symbolic equations and commonsense knowledge; (2) automatically fuses\nequation and commonsense knowledge information via a self-planning module when\ngenerating the MWPs. Experiments on an educational gold-standard set and a\nlarge-scale generated MWP set show that our approach is superior on the MWP\ngeneration task, and it outperforms the state-of-the-art models in terms of\nboth automatic evaluation metrics, i.e., BLEU-4, ROUGE-L, Self-BLEU, and human\nevaluation metrics, i.e., equation relevance, topic relevance, and language\ncoherence. To encourage reproducible results, we make our code and MWP dataset\npublic available at \\url{https://tinyurl.com/4ppldug7}.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 06:31:53 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 10:57:49 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Liu", "Tianqiao", ""], ["Fang", "Qian", ""], ["Ding", "Wenbiao", ""], ["Liu", "Zitao", ""]]}, {"id": "2010.06197", "submitter": "Kai Huang", "authors": "Luyang Wang, Kai Huang, Jiao Wang, Shengsheng Huang, Jason Dai, Yue\n  Zhuang", "title": "Context-Aware Drive-thru Recommendation Service at Fast Food Restaurants", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drive-thru is a popular sales channel in the fast food industry where\nconsumers can make food purchases without leaving their cars. Drive-thru\nrecommendation systems allow restaurants to display food recommendations on the\ndigital menu board as guests are making their orders. Popular recommendation\nmodels in eCommerce scenarios rely on user attributes (such as user profiles or\npurchase history) to generate recommendations, while such information is hard\nto obtain in the drive-thru use case. Thus, in this paper, we propose a new\nrecommendation model Transformer Cross Transformer (TxT), which exploits the\nguest order behavior and contextual features (such as location, time, and\nweather) using Transformer encoders for drive-thru recommendations. Empirical\nresults show that our TxT model achieves superior results in Burger King's\ndrive-thru production environment compared with existing recommendation\nsolutions. In addition, we implement a unified system to run end-to-end big\ndata analytics and deep learning workloads on the same cluster. We find that in\npractice, maintaining a single big data cluster for the entire pipeline is more\nefficient and cost-saving. Our recommendation system is not only beneficial for\ndrive-thru scenarios, and it can also be generalized to other customer\ninteraction channels.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 06:31:59 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Wang", "Luyang", ""], ["Huang", "Kai", ""], ["Wang", "Jiao", ""], ["Huang", "Shengsheng", ""], ["Dai", "Jason", ""], ["Zhuang", "Yue", ""]]}, {"id": "2010.06219", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge, Alexander Tschantz, Anil Seth, Christopher L Buckley", "title": "Investigating the Scalability and Biological Plausibility of the\n  Activation Relaxation Algorithm", "comments": "13/10/20 initial upload", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed Activation Relaxation (AR) algorithm provides a simple\nand robust approach for approximating the backpropagation of error algorithm\nusing only local learning rules. Unlike competing schemes, it converges to the\nexact backpropagation gradients, and utilises only a single type of\ncomputational unit and a single backwards relaxation phase. We have previously\nshown that the algorithm can be further simplified and made more biologically\nplausible by (i) introducing a learnable set of backwards weights, which\novercomes the weight-transport problem, and (ii) avoiding the computation of\nnonlinear derivatives at each neuron. However, tthe efficacy of these\nsimplifications has, so far, only been tested on simple multi-layer-perceptron\n(MLP) networks. Here, we show that these simplifications still maintain\nperformance using more complex CNN architectures and challenging datasets,\nwhich have proven difficult for other biologically-plausible schemes to scale\nto. We also investigate whether another biologically implausible assumption of\nthe original AR algorithm -- the frozen feedforward pass -- can be relaxed\nwithout damaging performance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 08:02:38 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Millidge", "Beren", ""], ["Tschantz", "Alexander", ""], ["Seth", "Anil", ""], ["Buckley", "Christopher L", ""]]}, {"id": "2010.06253", "submitter": "Peng Cui", "authors": "Peng Cui, Le Hu, and Yuanchao Liu", "title": "Enhancing Extractive Text Summarization with Topic-Aware Graph Neural\n  Networks", "comments": "Accepted by COLING(2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Text summarization aims to compress a textual document to a short summary\nwhile keeping salient information. Extractive approaches are widely used in\ntext summarization because of their fluency and efficiency. However, most of\nexisting extractive models hardly capture inter-sentence relationships,\nparticularly in long documents. They also often ignore the effect of topical\ninformation on capturing important contents. To address these issues, this\npaper proposes a graph neural network (GNN)-based extractive summarization\nmodel, enabling to capture inter-sentence relationships efficiently via\ngraph-structured document representation. Moreover, our model integrates a\njoint neural topic model (NTM) to discover latent topics, which can provide\ndocument-level features for sentence selection. The experimental results\ndemonstrate that our model not only substantially achieves state-of-the-art\nresults on CNN/DM and NYT datasets but also considerably outperforms existing\napproaches on scientific paper datasets consisting of much longer documents,\nindicating its better robustness in document genres and lengths. Further\ndiscussions show that topical information can help the model preselect salient\ncontents from an entire document, which interprets its effectiveness in long\ndocument summarization.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 09:30:04 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Cui", "Peng", ""], ["Hu", "Le", ""], ["Liu", "Yuanchao", ""]]}, {"id": "2010.06261", "submitter": "Asif Salim", "authors": "Asif Salim, Shiju. S. S, and Sumitra. S", "title": "Neighborhood Preserving Kernels for Attributed Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the design of a reproducing kernel suitable for attributed\ngraphs, in which the similarity between the two graphs is defined based on the\nneighborhood information of the graph nodes with the aid of a product graph\nformulation. We represent the proposed kernel as the weighted sum of two other\nkernels of which one is an R-convolution kernel that processes the attribute\ninformation of the graph and the other is an optimal assignment kernel that\nprocesses label information. They are formulated in such a way that the edges\nprocessed as part of the kernel computation have the same neighborhood\nproperties and hence the kernel proposed makes a well-defined correspondence\nbetween regions processed in graphs. These concepts are also extended to the\ncase of the shortest paths. We identified the state-of-the-art kernels that can\nbe mapped to such a neighborhood preserving framework. We found that the kernel\nvalue of the argument graphs in each iteration of the Weisfeiler-Lehman color\nrefinement algorithm can be obtained recursively from the product graph\nformulated in our method. By incorporating the proposed kernel on support\nvector machines we analyzed the real-world data sets and it has shown superior\nperformance in comparison with that of the other state-of-the-art graph\nkernels.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 09:58:50 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Salim", "Asif", ""], ["S", "Shiju. S.", ""], ["S", "Sumitra.", ""]]}, {"id": "2010.06269", "submitter": "Tharindu Ranasinghe Mr", "authors": "Hansi Hettiarachchi, Tharindu Ranasinghe", "title": "BRUMS at SemEval-2020 Task 3: Contextualised Embeddings for Predicting\n  the (Graded) Effect of Context in Word Similarity", "comments": "Accepted to SemEval-2020 (International Workshop on Semantic\n  Evaluation) at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents the team BRUMS submission to SemEval-2020 Task 3: Graded\nWord Similarity in Context. The system utilises state-of-the-art contextualised\nword embeddings, which have some task-specific adaptations, including stacked\nembeddings and average embeddings. Overall, the approach achieves good\nevaluation scores across all the languages, while maintaining simplicity.\nFollowing the final rankings, our approach is ranked within the top 5 solutions\nof each language while preserving the 1st position of Finnish subtask 2.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 10:25:18 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 14:44:16 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Hettiarachchi", "Hansi", ""], ["Ranasinghe", "Tharindu", ""]]}, {"id": "2010.06278", "submitter": "Tharindu Ranasinghe Mr", "authors": "Tharindu Ranasinghe, Hansi Hettiarachchi", "title": "BRUMS at SemEval-2020 Task 12 : Transformer based Multilingual Offensive\n  Language Identification in Social Media", "comments": "Accepted to SemEval-2020 (International Workshop on Semantic\n  Evaluation) at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we describe the team \\textit{BRUMS} entry to OffensEval 2:\nMultilingual Offensive Language Identification in Social Media in SemEval-2020.\nThe OffensEval organizers provided participants with annotated datasets\ncontaining posts from social media in Arabic, Danish, English, Greek and\nTurkish. We present a multilingual deep learning model to identify offensive\nlanguage in social media. Overall, the approach achieves acceptable evaluation\nscores, while maintaining flexibility between languages.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 10:39:14 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Ranasinghe", "Tharindu", ""], ["Hettiarachchi", "Hansi", ""]]}, {"id": "2010.06281", "submitter": "Tharindu Ranasinghe Mr", "authors": "Tharindu Ranasinghe, Alistair Plum, Constantin Orasan, Ruslan Mitkov", "title": "RGCL at SemEval-2020 Task 6: Neural Approaches to Definition Extraction", "comments": "Accepted to SemEval-2020 (International Workshop on Semantic\n  Evaluation) at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents the RGCL team submission to SemEval 2020 Task 6:\nDeftEval, subtasks 1 and 2. The system classifies definitions at the sentence\nand token levels. It utilises state-of-the-art neural network architectures,\nwhich have some task-specific adaptations, including an automatically extended\ntraining set. Overall, the approach achieves acceptable evaluation scores,\nwhile maintaining flexibility in architecture selection.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 10:48:15 GMT"}], "update_date": "2020-11-22", "authors_parsed": [["Ranasinghe", "Tharindu", ""], ["Plum", "Alistair", ""], ["Orasan", "Constantin", ""], ["Mitkov", "Ruslan", ""]]}, {"id": "2010.06307", "submitter": "Julia Dietlmeier", "authors": "Julia Dietlmeier, Joseph Antony, Kevin McGuinness, Noel E. O'Connor", "title": "How important are faces for person re-identification?", "comments": "25th International Conference on Pattern Recognition (ICPR2020),\n  Milan, Italy, 10-15 January 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the dependence of existing state-of-the-art person\nre-identification models on the presence and visibility of human faces. We\napply a face detection and blurring algorithm to create anonymized versions of\nseveral popular person re-identification datasets including Market1501,\nDukeMTMC-reID, CUHK03, Viper, and Airport. Using a cross-section of existing\nstate-of-the-art models that range in accuracy and computational efficiency, we\nevaluate the effect of this anonymization on re-identification performance\nusing standard metrics. Perhaps surprisingly, the effect on mAP is very small,\nand accuracy is recovered by simply training on the anonymized versions of the\ndata rather than the original data. These findings are consistent across\nmultiple models and datasets. These results indicate that datasets can be\nsafely anonymized by blurring faces without significantly impacting the\nperformance of person reidentification systems, and may allow for the release\nof new richer re-identification datasets where previously there were privacy or\ndata protection concerns.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 11:47:16 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Dietlmeier", "Julia", ""], ["Antony", "Joseph", ""], ["McGuinness", "Kevin", ""], ["O'Connor", "Noel E.", ""]]}, {"id": "2010.06324", "submitter": "Dan Andrei Calian", "authors": "Dan A. Calian and Daniel J. Mankowitz and Tom Zahavy and Zhongwen Xu\n  and Junhyuk Oh and Nir Levine and Timothy Mann", "title": "Balancing Constraints and Rewards with Meta-Gradient D4PG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying Reinforcement Learning (RL) agents to solve real-world applications\noften requires satisfying complex system constraints. Often the constraint\nthresholds are incorrectly set due to the complex nature of a system or the\ninability to verify the thresholds offline (e.g, no simulator or reasonable\noffline evaluation procedure exists). This results in solutions where a task\ncannot be solved without violating the constraints. However, in many real-world\ncases, constraint violations are undesirable yet they are not catastrophic,\nmotivating the need for soft-constrained RL approaches. We present a\nsoft-constrained RL approach that utilizes meta-gradients to find a good\ntrade-off between expected return and minimizing constraint violations. We\ndemonstrate the effectiveness of this approach by showing that it consistently\noutperforms the baselines across four different MuJoCo domains.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 12:15:23 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 17:27:30 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Calian", "Dan A.", ""], ["Mankowitz", "Daniel J.", ""], ["Zahavy", "Tom", ""], ["Xu", "Zhongwen", ""], ["Oh", "Junhyuk", ""], ["Levine", "Nir", ""], ["Mann", "Timothy", ""]]}, {"id": "2010.06371", "submitter": "Debjyoti Mukherjee", "authors": "Debjyoti Mukherjee, Alireza Ahmadi, Maryam Vahdat Pour, Joel Reardon", "title": "An Empirical Study on User Reviews Targeting Mobile Apps' Security &\n  Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Application markets provide a communication channel between app developers\nand their end-users in form of app reviews, which allow users to provide\nfeedback about the apps. Although security and privacy in mobile apps are one\nof the biggest issues, it is unclear how much people are aware of these or\ndiscuss them in reviews.\n  In this study, we explore the privacy and security concerns of users using\nreviews in the Google Play Store. For this, we conducted a study by analyzing\naround 2.2M reviews from the top 539 apps of this Android market. We found that\n0.5\\% of these reviews are related to the security and privacy concerns of the\nusers. We further investigated these apps by performing dynamic analysis which\nprovided us valuable insights into their actual behaviors. Based on the\ndifferent perspectives, we categorized the apps and evaluated how the different\nfactors influence the users' perception of the apps. It was evident from the\nresults that the number of permissions that the apps request plays a dominant\nrole in this matter. We also found that sending out the location can affect the\nusers' thoughts about the app. The other factors do not directly affect the\nprivacy and security concerns for the users.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 02:00:36 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Mukherjee", "Debjyoti", ""], ["Ahmadi", "Alireza", ""], ["Pour", "Maryam Vahdat", ""], ["Reardon", "Joel", ""]]}, {"id": "2010.06416", "submitter": "Hideyoshi Yanagisawa", "authors": "Chang Li and Hideyoshi Yanagisawa", "title": "Intrinsic motivation in virtual assistant interaction for fostering\n  spontaneous interactions", "comments": null, "journal-ref": "PLoS ONE, 16(4), e0250326 (2021)", "doi": "10.1371/journal.pone.0250326", "report-no": null, "categories": "cs.HC cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the growing utility of today's conversational virtual assistants, the\nimportance of user motivation in human-AI interaction is becoming more obvious.\nHowever, previous studies in this and related fields, such as human-computer\ninteraction and human-robot interaction, scarcely discussed intrinsic\nmotivation and its affecting factors. Those studies either treated motivation\nas an inseparable concept or focused on non-intrinsic motivation. The current\nstudy aims to cover intrinsic motivation by taking an affective-engineering\napproach. A novel motivation model is proposed, in which intrinsic motivation\nis affected by two factors that derive from user interactions with virtual\nassistants: expectation of capability and uncertainty. Experiments are\nconducted where these two factors are manipulated by making participants\nbelieve they are interacting with the smart speaker \"Amazon Echo\". Intrinsic\nmotivation is measured both by using questionnaires and by covertly monitoring\na five-minute free-choice period in the experimenter's absence, during which\nthe participants could decide for themselves whether to interact with the\nvirtual assistants. Results of the first experiment showed that high\nexpectation engenders more intrinsically motivated interaction compared with\nlow expectation. The results also suggested suppressive effects by uncertainty\non intrinsic motivation, though we had not hypothesized before experiments. We\nthen revised our hypothetical model of action selection accordingly and\nconducted a verification experiment of uncertainty's effects. Results of the\nverification experiment showed that reducing uncertainty encourages more\ninteractions and causes the motivation behind these interactions to shift from\nnon-intrinsic to intrinsic.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 14:23:57 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Li", "Chang", ""], ["Yanagisawa", "Hideyoshi", ""]]}, {"id": "2010.06425", "submitter": "Esther Rodrigo Bonet", "authors": "Esther Rodrigo Bonet, Duc Minh Nguyen and Nikos Deligiannis", "title": "Temporal Collaborative Filtering with Graph Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal collaborative filtering (TCF) methods aim at modelling non-static\naspects behind recommender systems, such as the dynamics in users' preferences\nand social trends around items. State-of-the-art TCF methods employ recurrent\nneural networks (RNNs) to model such aspects. These methods deploy\nmatrix-factorization-based (MF-based) approaches to learn the user and item\nrepresentations. Recently, graph-neural-network-based (GNN-based) approaches\nhave shown improved performance in providing accurate recommendations over\ntraditional MF-based approaches in non-temporal CF settings. Motivated by this,\nwe propose a novel TCF method that leverages GNNs to learn user and item\nrepresentations, and RNNs to model their temporal dynamics. A challenge with\nthis method lies in the increased data sparsity, which negatively impacts\nobtaining meaningful quality representations with GNNs. To overcome this\nchallenge, we train a GNN model at each time step using a set of observed\ninteractions accumulated time-wise. Comprehensive experiments on real-world\ndata show the improved performance obtained by our method over several\nstate-of-the-art temporal and non-temporal CF models.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 14:38:40 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Bonet", "Esther Rodrigo", ""], ["Nguyen", "Duc Minh", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "2010.06432", "submitter": "Matan Orbach", "authors": "Orith Toledo-Ronen, Matan Orbach, Yonatan Bilu, Artem Spector, Noam\n  Slonim", "title": "Multilingual Argument Mining: Datasets and Analysis", "comments": "Accepted to Findings of EMNLP 2020 (Long Paper). For the associated\n  multilingual arguments and evidence corpus, see\n  https://www.research.ibm.com/haifa/dept/vst/debating_data.shtml#Multilingual%20Argument%20Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing interest in argument mining and computational argumentation\nbrings with it a plethora of Natural Language Understanding (NLU) tasks and\ncorresponding datasets. However, as with many other NLU tasks, the dominant\nlanguage is English, with resources in other languages being few and far\nbetween. In this work, we explore the potential of transfer learning using the\nmultilingual BERT model to address argument mining tasks in non-English\nlanguages, based on English datasets and the use of machine translation. We\nshow that such methods are well suited for classifying the stance of arguments\nand detecting evidence, but less so for assessing the quality of arguments,\npresumably because quality is harder to preserve under translation. In\naddition, focusing on the translate-train approach, we show how the choice of\nlanguages for translation, and the relations among them, affect the accuracy of\nthe resultant model. Finally, to facilitate evaluation of transfer learning on\nargument mining tasks, we provide a human-generated dataset with more than 10k\narguments in multiple languages, as well as machine translation of the English\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 14:49:10 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Toledo-Ronen", "Orith", ""], ["Orbach", "Matan", ""], ["Bilu", "Yonatan", ""], ["Spector", "Artem", ""], ["Slonim", "Noam", ""]]}, {"id": "2010.06460", "submitter": "Gergely Hajgat\\'o", "authors": "Gergely Hajgat\\'o and Gy\\\"orgy Pa\\'al and B\\'alint Gyires-T\\'oth", "title": "Deep Reinforcement Learning for Real-Time Optimization of Pumps in Water\n  Distribution Systems", "comments": null, "journal-ref": "Journal of Water Resources Planning and Management, Volume 146,\n  Issue 11 (November 2020)", "doi": "10.1061/(ASCE)WR.1943-5452.0001287", "report-no": null, "categories": "cs.AI cs.LG physics.flu-dyn physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time control of pumps can be an infeasible task in water distribution\nsystems (WDSs) because the calculation to find the optimal pump speeds is\nresource-intensive. The computational need cannot be lowered even with the\ncapabilities of smart water networks when conventional optimization techniques\nare used. Deep reinforcement learning (DRL) is presented here as a controller\nof pumps in two WDSs. An agent based on a dueling deep q-network is trained to\nmaintain the pump speeds based on instantaneous nodal pressure data. General\noptimization techniques (e.g., Nelder-Mead method, differential evolution)\nserve as baselines. The total efficiency achieved by the DRL agent compared to\nthe best performing baseline is above 0.98, whereas the speedup is around 2x\ncompared to that. The main contribution of the presented approach is that the\nagent can run the pumps in real-time because it depends only on measurement\ndata. If the WDS is replaced with a hydraulic simulation, the agent still\noutperforms conventional techniques in search speed.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 15:13:49 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Hajgat\u00f3", "Gergely", ""], ["Pa\u00e1l", "Gy\u00f6rgy", ""], ["Gyires-T\u00f3th", "B\u00e1lint", ""]]}, {"id": "2010.06488", "submitter": "Michael Emmerich", "authors": "Michael Emmerich, Joost Nibbeling, Marios Kefalas, Aske Plaat", "title": "Multiple Node Immunisation for Preventing Epidemics on Networks by Exact\n  Multiobjective Optimisation of Cost and Shield-Value", "comments": "Based on the Master Thesis of Joost Nibbeling, LIACS, Leiden\n  University, The Netherlands", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The general problem in this paper is vertex (node) subset selection with the\ngoal to contain an infection that spreads in a network. Instead of selecting\nthe single most important node, this paper deals with the problem of selecting\nmultiple nodes for removal. As compared to previous work on multiple-node\nselection, the trade-off between cost and benefit is considered. The benefit is\nmeasured in terms of increasing the epidemic threshold which is a measure of\nhow difficult it is for an infection to spread in a network. The cost is\nmeasured in terms of the number and size of nodes to be removed or controlled.\nAlready in its single-objective instance with a fixed number of $k$ nodes to be\nremoved, the multiple vertex immunisation problems have been proven to be\nNP-hard. Several heuristics have been developed to approximate the problem. In\nthis work, we compare meta-heuristic techniques with exact methods on the\nShield-value, which is a sub-modular proxy for the maximal eigenvalue and used\nin the current state-of-the-art greedy node-removal strategies. We generalise\nit to the multi-objective case and replace the greedy algorithm by a quadratic\nprogram (QP), which then can be solved with exact QP solvers. The main\ncontribution of this paper is the insight that, if time permits, exact and\nproblem-specific methods approximation should be used, which are often far\nbetter than Pareto front approximations obtained by general meta-heuristics.\nBased on these, it will be more effective to develop strategies for controlling\nreal-world networks when the goal is to prevent or contain epidemic outbreaks.\nThis paper is supported by ready to use Python implementation of the\noptimization methods and datasets.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 15:49:00 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Emmerich", "Michael", ""], ["Nibbeling", "Joost", ""], ["Kefalas", "Marios", ""], ["Plaat", "Aske", ""]]}, {"id": "2010.06503", "submitter": "Pedro Ricardo Ariel Salvador Bassi Electrical Engineer", "authors": "Pedro R. A. S. Bassi, Willian Rampazzo and Romis Attux", "title": "Transfer Learning and SpecAugment applied to SSVEP Based BCI\n  Classification", "comments": null, "journal-ref": "Biomedical Signal Processing and Control 67 (2021) 102542", "doi": "10.1016/j.bspc.2021.102542", "report-no": null, "categories": "eess.SP cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Objective: We used deep convolutional neural networks (DCNNs) to classify\nelectroencephalography (EEG) signals in a steady-state visually evoked\npotentials (SSVEP) based single-channel brain-computer interface (BCI), which\ndoes not require calibration on the user.\n  Methods: EEG signals were converted to spectrograms and served as input to\ntrain DCNNs using the transfer learning technique. We also modified and applied\na data augmentation method, SpecAugment, generally employed for speech\nrecognition. Furthermore, for comparison purposes, we classified the SSVEP\ndataset using Support-vector machines (SVMs) and Filter Bank canonical\ncorrelation analysis (FBCCA).\n  Results: Excluding the evaluated user's data from the fine-tuning process, we\nreached 82.2% mean test accuracy and 0.825 mean F1-Score on 35 subjects from an\nopen dataset, using a small data length (0.5 s), only one electrode (Oz) and\nthe DCNN with transfer learning, window slicing (WS) and SpecAugment's time\nmasks.\n  Conclusion: The DCNN results surpassed SVM and FBCCA performances, using a\nsingle electrode and a small data length. Transfer learning provided minimal\naccuracy change, but made training faster. SpecAugment created a small\nperformance improvement and was successfully combined with WS, yielding higher\naccuracies.\n  Significance: We present a new methodology to solve the problem of SSVEP\nclassification using DCNNs. We also modified a speech recognition data\naugmentation technique and applied it to the context of BCIs. The presented\nmethodology surpassed performances obtained with FBCCA and SVMs (more\ntraditional SSVEP classification methods) in BCIs with small data lengths and\none electrode. This type of BCI can be used to develop small and fast systems.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 00:30:12 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 06:58:13 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Bassi", "Pedro R. A. S.", ""], ["Rampazzo", "Willian", ""], ["Attux", "Romis", ""]]}, {"id": "2010.06529", "submitter": "Julius von K\\\"ugelgen", "authors": "Julius von K\\\"ugelgen, Amir-Hossein Karimi, Umang Bhatt, Isabel\n  Valera, Adrian Weller, Bernhard Sch\\\"olkopf", "title": "On the Fairness of Causal Algorithmic Recourse", "comments": "v3 with additional experiments, new case study, new introduction, and\n  revised structure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic fairness is typically studied from the perspective of\npredictions. Instead, here we investigate fairness from the perspective of\nrecourse actions suggested to individuals to remedy an unfavourable\nclassification. We propose two new fairness criteria at the group and\nindividual level, which -- unlike prior work on equalising the average\ngroup-wise distance from the decision boundary -- explicitly account for causal\nrelationships between features, thereby capturing downstream effects of\nrecourse actions performed in the physical world. We explore how our criteria\nrelate to others, such as counterfactual fairness, and show that fairness of\nrecourse is complementary to fairness of prediction. We study theoretically and\nempirically how to enforce fair causal recourse by altering the classifier and\nperform a case study on the Adult dataset. Finally, we discuss whether fairness\nviolations in the data generating process revealed by our criteria may be\nbetter addressed by societal interventions as opposed to constraints on the\nclassifier.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 16:35:06 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 09:48:33 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 16:03:26 GMT"}, {"version": "v4", "created": "Tue, 8 Jun 2021 12:26:07 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["von K\u00fcgelgen", "Julius", ""], ["Karimi", "Amir-Hossein", ""], ["Bhatt", "Umang", ""], ["Valera", "Isabel", ""], ["Weller", "Adrian", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2010.06536", "submitter": "Sasan Tavakkol", "authors": "Sasan Tavakkol, Feng Han, Brandon Mayer, Mark Phillips, Cyrus Shahabi,\n  Yao-Yi Chiang and Raimondas Kiveris", "title": "Kartta Labs: Collaborative Time Travel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce the modular and scalable design of Kartta Labs, an open source,\nopen data, and scalable system for virtually reconstructing cities from\nhistorical maps and photos. Kartta Labs relies on crowdsourcing and artificial\nintelligence consisting of two major modules: Maps and 3D models. Each module,\nin turn, consists of sub-modules that enable the system to reconstruct a city\nfrom historical maps and photos. The result is a spatiotemporal reference that\ncan be used to integrate various collected data (curated, sensed, or\ncrowdsourced) for research, education, and entertainment purposes. The system\nempowers the users to experience collaborative time travel such that they work\ntogether to reconstruct the past and experience it on an open source and open\ndata platform.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 02:19:32 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Tavakkol", "Sasan", ""], ["Han", "Feng", ""], ["Mayer", "Brandon", ""], ["Phillips", "Mark", ""], ["Shahabi", "Cyrus", ""], ["Chiang", "Yao-Yi", ""], ["Kiveris", "Raimondas", ""]]}, {"id": "2010.06595", "submitter": "Dallas Card", "authors": "Dallas Card and Peter Henderson and Urvashi Khandelwal and Robin Jia\n  and Kyle Mahowald and Dan Jurafsky", "title": "With Little Power Comes Great Responsibility", "comments": "To appear at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its importance to experimental design, statistical power (the\nprobability that, given a real effect, an experiment will reject the null\nhypothesis) has largely been ignored by the NLP community. Underpowered\nexperiments make it more difficult to discern the difference between\nstatistical noise and meaningful model improvements, and increase the chances\nof exaggerated findings. By meta-analyzing a set of existing NLP papers and\ndatasets, we characterize typical power for a variety of settings and conclude\nthat underpowered experiments are common in the NLP literature. In particular,\nfor several tasks in the popular GLUE benchmark, small test sets mean that most\nattempted comparisons to state of the art models will not be adequately\npowered. Similarly, based on reasonable assumptions, we find that the most\ntypical experimental design for human rating studies will be underpowered to\ndetect small model differences, of the sort that are frequently studied. For\nmachine translation, we find that typical test sets of 2000 sentences have\napproximately 75% power to detect differences of 1 BLEU point. To improve the\nsituation going forward, we give an overview of best practices for power\nanalysis in NLP and release a series of notebooks to assist with future power\nanalyses.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 18:00:02 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Card", "Dallas", ""], ["Henderson", "Peter", ""], ["Khandelwal", "Urvashi", ""], ["Jia", "Robin", ""], ["Mahowald", "Kyle", ""], ["Jurafsky", "Dan", ""]]}, {"id": "2010.06627", "submitter": "Matthew Fontaine", "authors": "Hejia Zhang, Matthew C. Fontaine, Amy K. Hoover, Julian Togelius,\n  Bistra Dilkina, Stefanos Nikolaidis", "title": "Video Game Level Repair via Mixed Integer Linear Programming", "comments": "Accepted to AIIDE 2020 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in procedural content generation via machine learning\nenable the generation of video-game levels that are aesthetically similar to\nhuman-authored examples. However, the generated levels are often unplayable\nwithout additional editing. We propose a generate-then-repair framework for\nautomatic generation of playable levels adhering to specific styles. The\nframework constructs levels using a generative adversarial network (GAN)\ntrained with human-authored examples and repairs them using a mixed-integer\nlinear program (MIP) with playability constraints. A key component of the\nframework is computing minimum cost edits between the GAN generated level and\nthe solution of the MIP solver, which we cast as a minimum cost network flow\nproblem. Results show that the proposed framework generates a diverse range of\nplayable levels, that capture the spatial relationships between objects\nexhibited in the human-authored levels.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 18:37:58 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Zhang", "Hejia", ""], ["Fontaine", "Matthew C.", ""], ["Hoover", "Amy K.", ""], ["Togelius", "Julian", ""], ["Dilkina", "Bistra", ""], ["Nikolaidis", "Stefanos", ""]]}, {"id": "2010.06631", "submitter": "Jialu Zhang", "authors": "Jialu Zhang, Mark Santolucito and Ruzica Piskac", "title": "Succinct Explanations With Cascading Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classic decision tree learning is a binary classification algorithm that\nconstructs models with first-class transparency - every classification has a\ndirectly derivable explanation. However, learning decision trees on modern\ndatasets generates large trees, which in turn generate decision paths of\nexcessive depth, obscuring the explanation of classifications. To improve the\ncomprehensibility of classifications, we propose a new decision tree model that\nwe call Cascading Decision Trees. Cascading Decision Trees shorten the size of\nexplanations of classifications, without sacrificing model performance overall.\nOur key insight is to separate the notion of a decision path and an explanation\npath. Utilizing this insight, instead of having one monolithic decision tree,\nwe build several smaller decision subtrees and cascade them in sequence. Our\ncascading decision subtrees are designed to specifically target explanations\nfor positive classifications. This way each subtree identifies the smallest set\nof features that can classify as many positive samples as possible, without\nmisclassifying any negative samples. Applying cascading decision trees to new\nsamples results in a significantly shorter and succinct explanation, if one of\nthe subtrees detects a positive classification. In that case, we immediately\nstop and report the decision path of only the current subtree to the user as an\nexplanation for the classification. We evaluate our algorithm on standard\ndatasets, as well as new real-world applications and find that our model\nshortens the explanation depth by over 40.8% for positive classifications\ncompared to the classic decision tree model.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 18:48:39 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Zhang", "Jialu", ""], ["Santolucito", "Mark", ""], ["Piskac", "Ruzica", ""]]}, {"id": "2010.06671", "submitter": "Pedram Hosseini", "authors": "Lily Li, Or Levi, Pedram Hosseini, David A. Broniatowski", "title": "A Multi-Modal Method for Satire Detection using Textual and Visual Cues", "comments": "Accepted to the Third Workshop on NLP for Internet Freedom (NLP4IF):\n  Censorship, Disinformation, and Propaganda. Co-located with COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satire is a form of humorous critique, but it is sometimes misinterpreted by\nreaders as legitimate news, which can lead to harmful consequences. We observe\nthat the images used in satirical news articles often contain absurd or\nridiculous content and that image manipulation is used to create fictional\nscenarios. While previous work have studied text-based methods, in this work we\npropose a multi-modal approach based on state-of-the-art visiolinguistic model\nViLBERT. To this end, we create a new dataset consisting of images and\nheadlines of regular and satirical news for the task of satire detection. We\nfine-tune ViLBERT on the dataset and train a convolutional neural network that\nuses an image forensics technique. Evaluation on the dataset shows that our\nproposed multi-modal approach outperforms image-only, text-only, and simple\nfusion baselines.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 20:08:29 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Li", "Lily", ""], ["Levi", "Or", ""], ["Hosseini", "Pedram", ""], ["Broniatowski", "David A.", ""]]}, {"id": "2010.06684", "submitter": "Mojtaba Nayyeri", "authors": "Mojtaba Nayyeri, Chengjin Xu, Jens Lehmann, Sahar Vahdati", "title": "Motif Learning in Knowledge Graphs Using Trajectories Of Differential\n  Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge Graph Embeddings (KGEs) have shown promising performance on link\nprediction tasks by mapping the entities and relations from a knowledge graph\ninto a geometric space (usually a vector space). Ultimately, the plausibility\nof the predicted links is measured by using a scoring function over the learned\nembeddings (vectors). Therefore, the capability in preserving graph\ncharacteristics including structural aspects and semantics highly depends on\nthe design of the KGE, as well as the inherited abilities from the underlying\ngeometry. Many KGEs use the flat geometry which renders them incapable of\npreserving complex structures and consequently causes wrong inferences by the\nmodels. To address this problem, we propose a neuro differential KGE that\nembeds nodes of a KG on the trajectories of Ordinary Differential Equations\n(ODEs). To this end, we represent each relation (edge) in a KG as a vector\nfield on a smooth Riemannian manifold. We specifically parameterize ODEs by a\nneural network to represent various complex shape manifolds and more\nimportantly complex shape vector fields on the manifold. Therefore, the\nunderlying embedding space is capable of getting various geometric forms to\nencode complexity in subgraph structures with different motifs. Experiments on\nsynthetic and benchmark dataset as well as social network KGs justify the ODE\ntrajectories as a means to structure preservation and consequently avoiding\nwrong inferences over state-of-the-art KGE models.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 20:53:17 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 18:31:11 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Nayyeri", "Mojtaba", ""], ["Xu", "Chengjin", ""], ["Lehmann", "Jens", ""], ["Vahdati", "Sahar", ""]]}, {"id": "2010.06698", "submitter": "Joshua Hunte", "authors": "Joshua Hunte, Martin Neil, Norman Fenton", "title": "Product risk assessment: a Bayesian network approach", "comments": "32 pages, 12 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.AI stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Product risk assessment is the overall process of determining whether a\nproduct, which could be anything from a type of washing machine to a type of\nteddy bear, is judged safe for consumers to use. There are several methods used\nfor product risk assessment, including RAPEX, which is the primary method used\nby regulators in the UK and EU. However, despite its widespread use, we\nidentify several limitations of RAPEX including a limited approach to handling\nuncertainty and the inability to incorporate causal explanations for using and\ninterpreting test data. In contrast, Bayesian Networks (BNs) are a rigorous,\nnormative method for modelling uncertainty and causality which are already used\nfor risk assessment in domains such as medicine and finance, as well as\ncritical systems generally. This article proposes a BN model that provides an\nimproved systematic method for product risk assessment that resolves the\nidentified limitations with RAPEX. We use our proposed method to demonstrate\nrisk assessments for a teddy bear and a new uncertified kettle for which there\nis no testing data and the number of product instances is unknown. We show\nthat, while we can replicate the results of the RAPEX method, the BN approach\nis more powerful and flexible.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 16:40:03 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Hunte", "Joshua", ""], ["Neil", "Martin", ""], ["Fenton", "Norman", ""]]}, {"id": "2010.06724", "submitter": "Muhao Chen", "authors": "Muhao Chen, Hongming Zhang, Haoyu Wang, Dan Roth", "title": "\"What Are You Trying to Do?\" Semantic Typing of Event Processes", "comments": "CoNLL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a new cognitively motivated semantic typing task,\nmulti-axis event process typing, that, given an event process, attempts to\ninfer free-form type labels describing (i) the type of action made by the\nprocess and (ii) the type of object the process seeks to affect. This task is\ninspired by computational and cognitive studies of event understanding, which\nsuggest that understanding processes of events is often directed by recognizing\nthe goals, plans or intentions of the protagonist(s). We develop a large\ndataset containing over 60k event processes, featuring ultra fine-grained\ntyping on both the action and object type axes with very large ($10^3\\sim\n10^4$) label vocabularies. We then propose a hybrid learning framework, P2GT,\nwhich addresses the challenging typing problem with indirect supervision from\nglosses1and a joint learning-to-rank framework. As our experiments indicate,\nP2GT supports identifying the intent of processes, as well as the fine semantic\ntype of the affected object. It also demonstrates the capability of handling\nfew-shot cases, and strong generalizability on out-of-domain event processes.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 22:37:29 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Chen", "Muhao", ""], ["Zhang", "Hongming", ""], ["Wang", "Haoyu", ""], ["Roth", "Dan", ""]]}, {"id": "2010.06727", "submitter": "Haoyu Wang", "authors": "Haoyu Wang, Muhao Chen, Hongming Zhang, Dan Roth", "title": "Joint Constrained Learning for Event-Event Relation Extraction", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding natural language involves recognizing how multiple event\nmentions structurally and temporally interact with each other. In this process,\none can induce event complexes that organize multi-granular events with\ntemporal order and membership relations interweaving among them. Due to the\nlack of jointly labeled data for these relational phenomena and the restriction\non the structures they articulate, we propose a joint constrained learning\nframework for modeling event-event relations. Specifically, the framework\nenforces logical constraints within and across multiple temporal and subevent\nrelations by converting these constraints into differentiable learning\nobjectives. We show that our joint constrained learning approach effectively\ncompensates for the lack of jointly labeled data, and outperforms SOTA methods\non benchmarks for both temporal relation extraction and event hierarchy\nconstruction, replacing a commonly used but more expensive global inference\nprocess. We also present a promising case study showing the effectiveness of\nour approach in inducing event complexes on an external corpus.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 22:45:28 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 21:51:18 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Wang", "Haoyu", ""], ["Chen", "Muhao", ""], ["Zhang", "Hongming", ""], ["Roth", "Dan", ""]]}, {"id": "2010.06734", "submitter": "Pulkit Sharma", "authors": "Pulkit Sharma, Shezan Rohinton Mirzan, Apurva Bhandari, Anish Pimpley,\n  Abhiram Eswaran, Soundar Srinivasan and Liqun Shao", "title": "Evaluating Tree Explanation Methods for Anomaly Reasoning: A Case Study\n  of SHAP TreeExplainer and TreeInterpreter", "comments": "10 pages, 2 figures, 4 tables, CMAI workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding predictions made by Machine Learning models is critical in many\napplications. In this work, we investigate the performance of two methods for\nexplaining tree-based models- Tree Interpreter (TI) and SHapley Additive\nexPlanations TreeExplainer (SHAP-TE). Using a case study on detecting anomalies\nin job runtimes of applications that utilize cloud-computing platforms, we\ncompare these approaches using a variety of metrics, including computation\ntime, significance of attribution value, and explanation accuracy. We find\nthat, although the SHAP-TE offers consistency guarantees over TI, at the cost\nof increased computation, consistency does not necessarily improve the\nexplanation performance in our case study.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 23:18:26 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Sharma", "Pulkit", ""], ["Mirzan", "Shezan Rohinton", ""], ["Bhandari", "Apurva", ""], ["Pimpley", "Anish", ""], ["Eswaran", "Abhiram", ""], ["Srinivasan", "Soundar", ""], ["Shao", "Liqun", ""]]}, {"id": "2010.06740", "submitter": "Yanjun  Qi Dr.", "authors": "Jake Grigsby, Yanjun Qi", "title": "Measuring Visual Generalization in Continuous Control from Pixels", "comments": "A total of 20 pages, 8 pages as the main text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning and data augmentation have significantly reduced the\nperformance gap between state and image-based reinforcement learning agents in\ncontinuous control tasks. However, it is still unclear whether current\ntechniques can face a variety of visual conditions required by real-world\nenvironments. We propose a challenging benchmark that tests agents' visual\ngeneralization by adding graphical variety to existing continuous control\ndomains. Our empirical analysis shows that current methods struggle to\ngeneralize across a diverse set of visual changes, and we examine the specific\nfactors of variation that make these tasks difficult. We find that data\naugmentation techniques outperform self-supervised learning approaches and that\nmore significant image transformations provide better visual generalization\n\\footnote{The benchmark and our augmented actor-critic implementation are\nopen-sourced @ https://github.com/QData/dmc_remastered)\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 23:42:40 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 20:33:03 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Grigsby", "Jake", ""], ["Qi", "Yanjun", ""]]}, {"id": "2010.06746", "submitter": "Rollin Omari M", "authors": "Rollin Omari, R. I. McKay and Tom Gedeon", "title": "Analogical and Relational Reasoning with Spiking Neural Networks", "comments": "7 pages, 3 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Raven's Progressive Matrices have been widely used for measuring abstract\nreasoning and intelligence in humans. However for artificial learning systems,\nabstract reasoning remains a challenging problem. In this paper we investigate\nhow neural networks augmented with biologically inspired spiking modules gain a\nsignificant advantage in solving this problem. To illustrate this, we first\ninvestigate the performance of our networks with supervised learning, then with\nunsupervised learning. Experiments on the RAVEN dataset show that the overall\naccuracy of our supervised networks surpass human-level performance, while our\nunsupervised networks significantly outperform existing unsupervised methods.\nFinally, our results from both supervised and unsupervised learning illustrate\nthat, unlike their non-augmented counterparts, networks with spiking modules\nare able to extract and encode temporal features without any explicit\ninstruction, do not heavily rely on training data, and generalise more readily\nto new problems. In summary, the results reported here indicate that artificial\nneural networks with spiking modules are well suited to solving abstract\nreasoning.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 00:18:00 GMT"}], "update_date": "2020-12-28", "authors_parsed": [["Omari", "Rollin", ""], ["McKay", "R. I.", ""], ["Gedeon", "Tom", ""]]}, {"id": "2010.06775", "submitter": "Hao Tan", "authors": "Hao Tan, Mohit Bansal", "title": "Vokenization: Improving Language Understanding with Contextualized,\n  Visual-Grounded Supervision", "comments": "EMNLP 2020 (15 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans learn language by listening, speaking, writing, reading, and also, via\ninteraction with the multimodal real world. Existing language pre-training\nframeworks show the effectiveness of text-only self-supervision while we\nexplore the idea of a visually-supervised language model in this paper. We find\nthat the main reason hindering this exploration is the large divergence in\nmagnitude and distributions between the visually-grounded language datasets and\npure-language corpora. Therefore, we develop a technique named \"vokenization\"\nthat extrapolates multimodal alignments to language-only data by contextually\nmapping language tokens to their related images (which we call \"vokens\"). The\n\"vokenizer\" is trained on relatively small image captioning datasets and we\nthen apply it to generate vokens for large language corpora. Trained with these\ncontextually generated vokens, our visually-supervised language models show\nconsistent improvements over self-supervised alternatives on multiple\npure-language tasks such as GLUE, SQuAD, and SWAG. Code and pre-trained models\npublicly available at https://github.com/airsplay/vokenization\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 02:11:51 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Tan", "Hao", ""], ["Bansal", "Mohit", ""]]}, {"id": "2010.06797", "submitter": "Mingyu Cai", "authors": "Mingyu Cai, Shaoping Xiao, Baoluo Li, Zhiliang Li and Zhen Kan", "title": "Reinforcement Learning Based Temporal Logic Control with Maximum\n  Probabilistic Satisfaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.AI cs.RO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a model-free reinforcement learning (RL) algorithm to\nsynthesize a control policy that maximizes the satisfaction probability of\nlinear temporal logic (LTL) specifications. Due to the consideration of\nenvironment and motion uncertainties, we model the robot motion as a\nprobabilistic labeled Markov decision process with unknown transition\nprobabilities and unknown probabilistic label functions. The LTL task\nspecification is converted to a limit deterministic generalized B\\\"uchi\nautomaton (LDGBA) with several accepting sets to maintain dense rewards during\nlearning. The novelty of applying LDGBA is to construct an embedded LDGBA\n(E-LDGBA) by designing a synchronous tracking-frontier function, which enables\nthe record of non-visited accepting sets without increasing dimensional and\ncomputational complexity. With appropriate dependent reward and discount\nfunctions, rigorous analysis shows that any method that optimizes the expected\ndiscount return of the RL-based approach is guaranteed to find the optimal\npolicy that maximizes the satisfaction probability of the LTL specifications. A\nmodel-free RL-based motion planning strategy is developed to generate the\noptimal policy in this paper. The effectiveness of the RL-based control\nsynthesis is demonstrated via simulation and experimental results.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 03:49:16 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 04:45:16 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 20:51:11 GMT"}, {"version": "v4", "created": "Thu, 22 Jul 2021 01:36:30 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Cai", "Mingyu", ""], ["Xiao", "Shaoping", ""], ["Li", "Baoluo", ""], ["Li", "Zhiliang", ""], ["Kan", "Zhen", ""]]}, {"id": "2010.06801", "submitter": "Ming Gong", "authors": "Xingyao Zhang, Linjun Shou, Jian Pei, Ming Gong, Lijie Wen, Daxin\n  Jiang", "title": "A Graph Representation of Semi-structured Data for Web Question\n  Answering", "comments": "Accepted as long paper in COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abundant semi-structured data on the Web, such as HTML-based tables and\nlists, provide commercial search engines a rich information source for question\nanswering (QA). Different from plain text passages in Web documents, Web tables\nand lists have inherent structures, which carry semantic correlations among\nvarious elements in tables and lists. Many existing studies treat tables and\nlists as flat documents with pieces of text and do not make good use of\nsemantic information hidden in structures. In this paper, we propose a novel\ngraph representation of Web tables and lists based on a systematic\ncategorization of the components in semi-structured data as well as their\nrelations. We also develop pre-training and reasoning techniques on the graph\nmodel for the QA task. Extensive experiments on several real datasets collected\nfrom a commercial engine verify the effectiveness of our approach. Our method\nimproves F1 score by 3.90 points over the state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 04:01:54 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Zhang", "Xingyao", ""], ["Shou", "Linjun", ""], ["Pei", "Jian", ""], ["Gong", "Ming", ""], ["Wen", "Lijie", ""], ["Jiang", "Daxin", ""]]}, {"id": "2010.06820", "submitter": "James Foulds", "authors": "Kamrun Naher Keya, Rashidul Islam, Shimei Pan, Ian Stockwell, James R.\n  Foulds", "title": "Equitable Allocation of Healthcare Resources with Fair Cox Models", "comments": "AAAI Fall Symposium on AI in Government and Public Sector (AAAI\n  FSS-20), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healthcare programs such as Medicaid provide crucial services to vulnerable\npopulations, but due to limited resources, many of the individuals who need\nthese services the most languish on waiting lists. Survival models, e.g. the\nCox proportional hazards model, can potentially improve this situation by\npredicting individuals' levels of need, which can then be used to prioritize\nthe waiting lists. Providing care to those in need can prevent\ninstitutionalization for those individuals, which both improves quality of life\nand reduces overall costs. While the benefits of such an approach are clear,\ncare must be taken to ensure that the prioritization process is fair or\nindependent of demographic information-based harmful stereotypes. In this work,\nwe develop multiple fairness definitions for survival models and corresponding\nfair Cox proportional hazards models to ensure equitable allocation of\nhealthcare resources. We demonstrate the utility of our methods in terms of\nfairness and predictive accuracy on two publicly available survival datasets.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 06:08:15 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Keya", "Kamrun Naher", ""], ["Islam", "Rashidul", ""], ["Pan", "Shimei", ""], ["Stockwell", "Ian", ""], ["Foulds", "James R.", ""]]}, {"id": "2010.06822", "submitter": "Faeze Brahman", "authors": "Faeze Brahman, Snigdha Chaturvedi", "title": "Modeling Protagonist Emotions for Emotion-Aware Storytelling", "comments": "EMNLP 2020, update: Conference version of Weber et al. (2020) is\n  cited", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotions and their evolution play a central role in creating a captivating\nstory. In this paper, we present the first study on modeling the emotional\ntrajectory of the protagonist in neural storytelling. We design methods that\ngenerate stories that adhere to given story titles and desired emotion arcs for\nthe protagonist. Our models include Emotion Supervision (EmoSup) and two\nEmotion-Reinforced (EmoRL) models. The EmoRL models use special rewards\ndesigned to regularize the story generation process through reinforcement\nlearning. Our automatic and manual evaluations demonstrate that these models\nare significantly better at generating stories that follow the desired emotion\narcs compared to baseline methods, without sacrificing story quality.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 06:24:25 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 19:23:52 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Brahman", "Faeze", ""], ["Chaturvedi", "Snigdha", ""]]}, {"id": "2010.06854", "submitter": "Yuta Yajima", "authors": "Yuta Yajima and Akihiro Inokuchi", "title": "Refining Similarity Matrices to Cluster Attributed Networks Accurately", "comments": "9pages, 11 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a result of the recent popularity of social networks and the increase in\nthe number of research papers published across all fields, attributed networks\nconsisting of relationships between objects, such as humans and the papers,\nthat have attributes are becoming increasingly large. Therefore, various\nstudies for clustering attributed networks into sub-networks are being actively\nconducted. When clustering attributed networks using spectral clustering, the\nclustering accuracy is strongly affected by the quality of the similarity\nmatrices, which are input into spectral clustering and represent the\nsimilarities between pairs of objects. In this paper, we aim to increase the\naccuracy by refining the matrices before applying spectral clustering to them.\nWe verify the practicability of our proposed method by comparing the accuracy\nof spectral clustering with similarity matrices before and after refining them.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 07:43:36 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Yajima", "Yuta", ""], ["Inokuchi", "Akihiro", ""]]}, {"id": "2010.06962", "submitter": "Zhixin Chen", "authors": "Zhixin Chen, Mengxiang Lin", "title": "Self-Imitation Learning for Robot Tasks with Sparse and Delayed Rewards", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of reinforcement learning (RL) in robotic control is still\nlimited in the environments with sparse and delayed rewards. In this paper, we\npropose a practical self-imitation learning method named Self-Imitation\nLearning with Constant Reward (SILCR). Instead of requiring hand-defined\nimmediate rewards from environments, our method assigns the immediate rewards\nat each timestep with constant values according to their final episodic\nrewards. In this way, even if the dense rewards from environments are\nunavailable, every action taken by the agents would be guided properly. We\ndemonstrate the effectiveness of our method in some challenging continuous\nrobotics control tasks in MuJoCo simulation and the results show that our\nmethod significantly outperforms the alternative methods in tasks with sparse\nand delayed rewards. Even compared with alternatives with dense rewards\navailable, our method achieves competitive performance. The ablation\nexperiments also show the stability and reproducibility of our method.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 11:12:07 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 12:09:26 GMT"}, {"version": "v3", "created": "Tue, 25 May 2021 13:45:43 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Chen", "Zhixin", ""], ["Lin", "Mengxiang", ""]]}, {"id": "2010.06992", "submitter": "Stefan Postavaru", "authors": "\\c{S}tefan Post\\u{a}varu, Anton Tsitsulin, Filipe Miguel Gon\\c{c}alves\n  de Almeida, Yingtao Tian, Silvio Lattanzi, Bryan Perozzi", "title": "InstantEmbedding: Efficient Local Node Representations", "comments": "23 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce InstantEmbedding, an efficient method for\ngenerating single-node representations using local PageRank computations. We\ntheoretically prove that our approach produces globally consistent\nrepresentations in sublinear time. We demonstrate this empirically by\nconducting extensive experiments on real-world datasets with over a billion\nedges. Our experiments confirm that InstantEmbedding requires drastically less\ncomputation time (over 9,000 times faster) and less memory (by over 8,000\ntimes) to produce a single node's embedding than traditional methods including\nDeepWalk, node2vec, VERSE, and FastRP. We also show that our method produces\nhigh quality representations, demonstrating results that meet or exceed the\nstate of the art for unsupervised representation learning on tasks like node\nclassification and link prediction.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 12:08:45 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Post\u0103varu", "\u015etefan", ""], ["Tsitsulin", "Anton", ""], ["de Almeida", "Filipe Miguel Gon\u00e7alves", ""], ["Tian", "Yingtao", ""], ["Lattanzi", "Silvio", ""], ["Perozzi", "Bryan", ""]]}, {"id": "2010.07038", "submitter": "David Conal Higgins", "authors": "David Higgins", "title": "OnRAMP for Regulating AI in Medical Products", "comments": "46 pages, 3 tables, 1 figure. Published in Advanced Intelligent\n  Systems, July 2021. (See DOI link)", "journal-ref": null, "doi": "10.1002/aisy.202100042", "report-no": null, "categories": "cs.CY cs.AI stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Medical Artificial Intelligence (AI) involves the application of machine\nlearning algorithms to biomedical datasets in order to improve medical\npractices. Products incorporating medical AI require certification before\ndeployment in most jurisdictions. To date, clear pathways for regulating\nmedical AI are still under development. Below the level of formal pathways lies\nthe actual practice of developing a medical AI solution. This Perspective\nproposes best practice guidelines for development compatible with the\nproduction of a regulatory package which, regardless of the formal regulatory\npath, will form a core component of a certification process. The approach is\npredicated on a statistical risk perspective, typical of medical device\nregulators, and a deep understanding of machine learning methodologies. These\nguidelines will allow all parties to communicate more clearly in the\ndevelopment of a common Good Machine Learning Practice (GMLP), and thus lead to\nthe enhanced development of both medical AI products and regulations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 14:02:30 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 14:52:24 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 15:47:15 GMT"}, {"version": "v4", "created": "Mon, 30 Nov 2020 14:41:05 GMT"}, {"version": "v5", "created": "Mon, 1 Feb 2021 14:51:39 GMT"}, {"version": "v6", "created": "Mon, 26 Jul 2021 11:51:05 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Higgins", "David", ""]]}, {"id": "2010.07042", "submitter": "Avi Caciularu", "authors": "Oren Barkan, Yonatan Fuchs, Avi Caciularu, Noam Koenigstein", "title": "Explainable Recommendations via Attentive Multi-Persona Collaborative\n  Filtering", "comments": "Accepted to RecSys 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two main challenges in recommender systems are modeling users with\nheterogeneous taste, and providing explainable recommendations. In this paper,\nwe propose the neural Attentive Multi-Persona Collaborative Filtering (AMP-CF)\nmodel as a unified solution for both problems. AMP-CF breaks down the user to\nseveral latent 'personas' (profiles) that identify and discern the different\ntastes and inclinations of the user. Then, the revealed personas are used to\ngenerate and explain the final recommendation list for the user. AMP-CF models\nusers as an attentive mixture of personas, enabling a dynamic user\nrepresentation that changes based on the item under consideration. We\ndemonstrate AMP-CF on five collaborative filtering datasets from the domains of\nmovies, music, video games and social networks. As an additional contribution,\nwe propose a novel evaluation scheme for comparing the different items in a\nrecommendation list based on the distance from the underlying distribution of\n\"tastes\" in the user's historical items. Experimental results show that AMP-CF\nis competitive with other state-of-the-art models. Finally, we provide\nqualitative results to showcase the ability of AMP-CF to explain its\nrecommendations.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 11:52:57 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Barkan", "Oren", ""], ["Fuchs", "Yonatan", ""], ["Caciularu", "Avi", ""], ["Koenigstein", "Noam", ""]]}, {"id": "2010.07054", "submitter": "Deepak P", "authors": "Deepak P and Savitha Sam Abraham", "title": "Representativity Fairness in Clustering", "comments": "In 12th ACM Web Science Conference (WebSci 2020)", "journal-ref": null, "doi": "10.1145/3394231.3397910", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating fairness constructs into machine learning algorithms is a topic\nof much societal importance and recent interest. Clustering, a fundamental task\nin unsupervised learning that manifests across a number of web data scenarios,\nhas also been subject of attention within fair ML research. In this paper, we\ndevelop a novel notion of fairness in clustering, called representativity\nfairness. Representativity fairness is motivated by the need to alleviate\ndisparity across objects' proximity to their assigned cluster representatives,\nto aid fairer decision making. We illustrate the importance of representativity\nfairness in real-world decision making scenarios involving clustering and\nprovide ways of quantifying objects' representativity and fairness over it. We\ndevelop a new clustering formulation, RFKM, that targets to optimize for\nrepresentativity fairness along with clustering quality. Inspired by the\n$K$-Means framework, RFKM incorporates novel loss terms to formulate an\nobjective function. The RFKM objective and optimization approach guides it\ntowards clustering configurations that yield higher representativity fairness.\nThrough an empirical evaluation over a variety of public datasets, we establish\nthe effectiveness of our method. We illustrate that we are able to\nsignificantly improve representativity fairness at only marginal impact to\nclustering quality.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 21:50:06 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["P", "Deepak", ""], ["Abraham", "Savitha Sam", ""]]}, {"id": "2010.07070", "submitter": "Yuzhe Zhang", "authors": "Yuzhe Zhang and Davide Grossi", "title": "Power in Liquid Democracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper develops a theory of power for delegable proxy voting systems. We\ndefine a power index able to measure the influence of both voters and\ndelegators. Using this index, which we characterize axiomatically, we extend an\nearlier game-theoretic model by incorporating power-seeking behavior by agents.\nWe analytically study the existence of pure strategy Nash equilibria in such a\nmodel. Finally, by means of simulations, we study the effect of relevant\nparameters on the emergence of power inequalities in the model.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 13:17:06 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Zhang", "Yuzhe", ""], ["Grossi", "Davide", ""]]}, {"id": "2010.07079", "submitter": "Emily Dinan", "authors": "Jing Xu, Da Ju, Margaret Li, Y-Lan Boureau, Jason Weston, Emily Dinan", "title": "Recipes for Safety in Open-domain Chatbots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models trained on large unlabeled corpora of human interactions will learn\npatterns and mimic behaviors therein, which include offensive or otherwise\ntoxic behavior and unwanted biases. We investigate a variety of methods to\nmitigate these issues in the context of open-domain generative dialogue models.\nWe introduce a new human-and-model-in-the-loop framework for both training\nsafer models and for evaluating them, as well as a novel method to distill\nsafety considerations inside generative models without the use of an external\nclassifier at deployment time. We conduct experiments comparing these methods\nand find our new techniques are (i) safer than existing models as measured by\nautomatic and human evaluations while (ii) maintaining usability metrics such\nas engagingness relative to the state of the art. We then discuss the\nlimitations of this work by analyzing failure cases of our models.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 13:26:39 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 16:56:50 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Xu", "Jing", ""], ["Ju", "Da", ""], ["Li", "Margaret", ""], ["Boureau", "Y-Lan", ""], ["Weston", "Jason", ""], ["Dinan", "Emily", ""]]}, {"id": "2010.07095", "submitter": "Xu Zhao", "authors": "Xu Zhao, Zihao Wang, Hao Wu, Yong Zhang", "title": "A Relaxed Matching Procedure for Unsupervised BLI", "comments": "6 pages,1 figures, accepted as short paper by ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently unsupervised Bilingual Lexicon Induction (BLI) without any parallel\ncorpus has attracted much research interest. One of the crucial parts in\nmethods for the BLI task is the matching procedure. Previous works impose a too\nstrong constraint on the matching and lead to many counterintuitive translation\npairings. Thus, We propose a relaxed matching procedure to find a more precise\nmatching between two languages. We also find that aligning source and target\nlanguage embedding space bidirectionally will bring significant improvement. We\nfollow the previous iterative framework to conduct experiments. Results on\nstandard benchmark demonstrate the effectiveness of our proposed method, which\nsubstantially outperforms previous unsupervised methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 13:53:08 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Zhao", "Xu", ""], ["Wang", "Zihao", ""], ["Wu", "Hao", ""], ["Zhang", "Yong", ""]]}, {"id": "2010.07126", "submitter": "Lav Varshney", "authors": "Lav R. Varshney, Nazneen Fatema Rajani, and Richard Socher", "title": "Explaining Creative Artifacts", "comments": "2020 Workshop on Human Interpretability in Machine Learning (WHI), at\n  ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human creativity is often described as the mental process of combining\nassociative elements into a new form, but emerging computational creativity\nalgorithms may not operate in this manner. Here we develop an inverse problem\nformulation to deconstruct the products of combinatorial and compositional\ncreativity into associative chains as a form of post-hoc interpretation that\nmatches the human creative process. In particular, our formulation is\nstructured as solving a traveling salesman problem through a knowledge graph of\nassociative elements. We demonstrate our approach using an example in\nexplaining culinary computational creativity where there is an explicit\nsemantic structure, and two examples in language generation where we either\nextract explicit concepts that map to a knowledge graph or we consider\ndistances in a word embedding space. We close by casting the length of an\noptimal traveling salesman path as a measure of novelty in creativity.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 14:32:38 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Varshney", "Lav R.", ""], ["Rajani", "Nazneen Fatema", ""], ["Socher", "Richard", ""]]}, {"id": "2010.07152", "submitter": "Kai Wang", "authors": "Kai Wang, Yu Liu, Qian Ma, Quan Z. Sheng", "title": "MulDE: Multi-teacher Knowledge Distillation for Low-dimensional\n  Knowledge Graph Embeddings", "comments": "Accepted for publication at the Web Conference 2021", "journal-ref": null, "doi": "10.1145/3442381.3449898", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction based on knowledge graph embeddings (KGE) aims to predict new\ntriples to automatically construct knowledge graphs (KGs). However, recent KGE\nmodels achieve performance improvements by excessively increasing the embedding\ndimensions, which may cause enormous training costs and require more storage\nspace. In this paper, instead of training high-dimensional models, we propose\nMulDE, a novel knowledge distillation framework, which includes multiple\nlow-dimensional hyperbolic KGE models as teachers and two student components,\nnamely Junior and Senior. Under a novel iterative distillation strategy, the\nJunior component, a low-dimensional KGE model, asks teachers actively based on\nits preliminary prediction results, and the Senior component integrates\nteachers' knowledge adaptively to train the Junior component based on two\nmechanisms: relation-specific scaling and contrast attention. The experimental\nresults show that MulDE can effectively improve the performance and training\nspeed of low-dimensional KGE models. The distilled 32-dimensional model is\ncompetitive compared to the state-of-the-art high-dimensional methods on\nseveral widely-used datasets.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 15:09:27 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 09:33:41 GMT"}, {"version": "v3", "created": "Sat, 27 Mar 2021 14:29:34 GMT"}, {"version": "v4", "created": "Thu, 1 Apr 2021 08:09:33 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Wang", "Kai", ""], ["Liu", "Yu", ""], ["Ma", "Qian", ""], ["Sheng", "Quan Z.", ""]]}, {"id": "2010.07167", "submitter": "Jens M\\\"uller", "authors": "Jens M\\\"uller, Robert Schmier, Lynton Ardizzone, Carsten Rother and\n  Ullrich K\\\"othe", "title": "Learning Robust Models Using The Principle of Independent Causal\n  Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard supervised learning breaks down under data distribution shift.\nHowever, the principle of independent causal mechanisms (ICM, Peters et al.\n(2017)) can turn this weakness into an opportunity: one can take advantage of\ndistribution shift between different environments during training in order to\nobtain more robust models. We propose a new gradient-based learning framework\nwhose objective function is derived from the ICM principle. We show\ntheoretically and experimentally that neural networks trained in this framework\nfocus on relations remaining invariant across environments and ignore unstable\nones. Moreover, we prove that the recovered stable relations correspond to the\ntrue causal mechanisms under certain conditions. In both regression and\nclassification, the resulting models generalize well to unseen scenarios where\ntraditionally trained models fail.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 15:38:01 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 15:39:13 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["M\u00fcller", "Jens", ""], ["Schmier", "Robert", ""], ["Ardizzone", "Lynton", ""], ["Rother", "Carsten", ""], ["K\u00f6the", "Ullrich", ""]]}, {"id": "2010.07213", "submitter": "Manish Kesarwani", "authors": "Shazia Afzal, Rajmohan C, Manish Kesarwani, Sameep Mehta, Hima Patel", "title": "Data Readiness Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data exploration and quality analysis is an important yet tedious process in\nthe AI pipeline. Current practices of data cleaning and data readiness\nassessment for machine learning tasks are mostly conducted in an arbitrary\nmanner which limits their reuse and results in loss of productivity. We\nintroduce the concept of a Data Readiness Report as an accompanying\ndocumentation to a dataset that allows data consumers to get detailed insights\ninto the quality of input data. Data characteristics and challenges on various\nquality dimensions are identified and documented keeping in mind the principles\nof transparency and explainability. The Data Readiness Report also serves as a\nrecord of all data assessment operations including applied transformations.\nThis provides a detailed lineage for the purpose of data governance and\nmanagement. In effect, the report captures and documents the actions taken by\nvarious personas in a data readiness and assessment workflow. Overtime this\nbecomes a repository of best practices and can potentially drive a\nrecommendation system for building automated data readiness workflows on the\nlines of AutoML [8]. We anticipate that together with the Datasheets [9],\nDataset Nutrition Label [11], FactSheets [1] and Model Cards [15], the Data\nReadiness Report makes significant progress towards Data and AI lifecycle\ndocumentation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 16:26:29 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 13:30:05 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Afzal", "Shazia", ""], ["C", "Rajmohan", ""], ["Kesarwani", "Manish", ""], ["Mehta", "Sameep", ""], ["Patel", "Hima", ""]]}, {"id": "2010.07221", "submitter": "Nikhil Churamani", "authors": "Nikhil Churamani and Pablo Barros and Hatice Gunes and Stefan Wermter", "title": "Affect-Driven Modelling of Robot Personality for Collaborative\n  Human-Robot Interactions", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative interactions require social robots to adapt to the dynamics of\nhuman affective behaviour. Yet, current approaches for affective behaviour\ngeneration in robots focus on instantaneous perception to generate a one-to-one\nmapping between observed human expressions and static robot actions. In this\npaper, we propose a novel framework for personality-driven behaviour generation\nin social robots. The framework consists of (i) a hybrid neural model for\nevaluating facial expressions and speech, forming intrinsic affective\nrepresentations in the robot, (ii) an Affective Core, that employs\nself-organising neural models to embed robot personality traits like patience\nand emotional actuation, and (iii) a Reinforcement Learning model that uses the\nrobot's affective appraisal to learn interaction behaviour. For evaluation, we\nconduct a user study (n = 31) where the NICO robot acts as a proposer in the\nUltimatum Game. The effect of robot personality on its negotiation strategy is\nwitnessed by participants, who rank a patient robot with high emotional\nactuation higher on persistence, while an inert and impatient robot higher on\nits generosity and altruistic behaviour.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 16:34:14 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Churamani", "Nikhil", ""], ["Barros", "Pablo", ""], ["Gunes", "Hatice", ""], ["Wermter", "Stefan", ""]]}, {"id": "2010.07249", "submitter": "Elliot Creager", "authors": "Elliot Creager, J\\\"orn-Henrik Jacobsen, Richard Zemel", "title": "Environment Inference for Invariant Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning models that gracefully handle distribution shifts is central to\nresearch on domain generalization, robust optimization, and fairness. A\npromising formulation is domain-invariant learning, which identifies the key\nissue of learning which features are domain-specific versus domain-invariant.\nAn important assumption in this area is that the training examples are\npartitioned into \"domains\" or \"environments\". Our focus is on the more common\nsetting where such partitions are not provided. We propose EIIL, a general\nframework for domain-invariant learning that incorporates Environment Inference\nto directly infer partitions that are maximally informative for downstream\nInvariant Learning. We show that EIIL outperforms invariant learning methods on\nthe CMNIST benchmark without using environment labels, and significantly\noutperforms ERM on worst-group performance in the Waterbirds and CivilComments\ndatasets. Finally, we establish connections between EIIL and algorithmic\nfairness, which enables EIIL to improve accuracy and calibration in a fair\nprediction problem.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 17:11:46 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 04:28:19 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 17:34:14 GMT"}, {"version": "v4", "created": "Thu, 10 Jun 2021 20:41:37 GMT"}, {"version": "v5", "created": "Thu, 15 Jul 2021 17:21:57 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Creager", "Elliot", ""], ["Jacobsen", "J\u00f6rn-Henrik", ""], ["Zemel", "Richard", ""]]}, {"id": "2010.07261", "submitter": "Makesh Narsimhan Sreedhar", "authors": "Makesh Narsimhan Sreedhar, Kun Ni, Siva Reddy", "title": "Learning Improvised Chatbots from Adversarial Modifications of Natural\n  Language Feedback", "comments": "Accepted for publication at Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ubiquitous nature of chatbots and their interaction with users generate\nan enormous amount of data. Can we improve chatbots using this data? A\nself-feeding chatbot improves itself by asking natural language feedback when a\nuser is dissatisfied with its response and uses this feedback as an additional\ntraining sample. However, user feedback in most cases contains extraneous\nsequences hindering their usefulness as a training sample. In this work, we\npropose a generative adversarial model that converts noisy feedback into a\nplausible natural response in a conversation. The generator's goal is to\nconvert the feedback into a response that answers the user's previous utterance\nand to fool the discriminator which distinguishes feedback from natural\nresponses. We show that augmenting original training data with these modified\nfeedback responses improves the original chatbot performance from 69.94% to\n75.96% in ranking correct responses on the Personachat dataset, a large\nimprovement given that the original model is already trained on 131k samples.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 17:33:37 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 02:19:13 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Sreedhar", "Makesh Narsimhan", ""], ["Ni", "Kun", ""], ["Reddy", "Siva", ""]]}, {"id": "2010.07326", "submitter": "Andrea L\\'opez-Incera", "authors": "Andrea L\\'opez-Incera, Morgane Nouvian, Katja Ried, Thomas M\\\"uller\n  and Hans J. Briegel", "title": "Collective defense of honeybee colonies: experimental results and\n  theoretical modeling", "comments": null, "journal-ref": "BMC Biol 19, 106 (2021)", "doi": "10.1186/s12915-021-01028-x", "report-no": null, "categories": "q-bio.PE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social insect colonies routinely face large vertebrate predators, against\nwhich they need to mount a collective defense. To do so, honeybees use an alarm\npheromone that recruits nearby bees into mass stinging of the perceived threat.\nThis alarm pheromone is carried directly on the stinger, hence its\nconcentration builds up during the course of the attack. Here, we investigate\nhow individual bees react to different alarm pheromone concentrations, and how\nthis evolved response-pattern leads to better coordination at the group level.\nWe first present an individual dose-response curve to the alarm pheromone,\nobtained experimentally. Second, we apply Projective Simulation to model each\nbee as an artificial learning agent that relies on the pheromone concentration\nto decide whether to sting or not. If the emergent collective performance\nbenefits the colony, the individual reactions that led to it are enhanced via\nreinforcement learning, thus emulating natural selection. Predators are modeled\nin a realistic way so that the effect of factors such as their resistance,\ntheir killing rate or their frequency of attacks can be studied. We are able to\nreproduce the experimentally measured response-pattern of real bees, and to\nidentify the main selection pressures that shaped it. Finally, we apply the\nmodel to a case study: by tuning the parameters to represent the environmental\nconditions of European or African bees, we can predict the difference in\naggressiveness observed between these two subspecies.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 18:00:50 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["L\u00f3pez-Incera", "Andrea", ""], ["Nouvian", "Morgane", ""], ["Ried", "Katja", ""], ["M\u00fcller", "Thomas", ""], ["Briegel", "Hans J.", ""]]}, {"id": "2010.07344", "submitter": "Atish Agarwala", "authors": "Atish Agarwala, Jeffrey Pennington, Yann Dauphin, Sam Schoenholz", "title": "Temperature check: theory and practice for training models with\n  softmax-cross-entropy losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The softmax function combined with a cross-entropy loss is a principled\napproach to modeling probability distributions that has become ubiquitous in\ndeep learning. The softmax function is defined by a lone hyperparameter, the\ntemperature, that is commonly set to one or regarded as a way to tune model\nconfidence after training; however, less is known about how the temperature\nimpacts training dynamics or generalization performance. In this work we\ndevelop a theory of early learning for models trained with\nsoftmax-cross-entropy loss and show that the learning dynamics depend crucially\non the inverse-temperature $\\beta$ as well as the magnitude of the logits at\ninitialization, $||\\beta{\\bf z}||_{2}$. We follow up these analytic results\nwith a large-scale empirical study of a variety of model architectures trained\non CIFAR10, ImageNet, and IMDB sentiment analysis. We find that generalization\nperformance depends strongly on the temperature, but only weakly on the initial\nlogit magnitude. We provide evidence that the dependence of generalization on\n$\\beta$ is not due to changes in model confidence, but is a dynamical\nphenomenon. It follows that the addition of $\\beta$ as a tunable hyperparameter\nis key to maximizing model performance. Although we find the optimal $\\beta$ to\nbe sensitive to the architecture, our results suggest that tuning $\\beta$ over\nthe range $10^{-2}$ to $10^1$ improves performance over all architectures\nstudied. We find that smaller $\\beta$ may lead to better peak performance at\nthe cost of learning stability.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 18:26:23 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Agarwala", "Atish", ""], ["Pennington", "Jeffrey", ""], ["Dauphin", "Yann", ""], ["Schoenholz", "Sam", ""]]}, {"id": "2010.07349", "submitter": "Vincent Le-Guen", "authors": "Vincent Le Guen, Nicolas Thome", "title": "Probabilistic Time Series Forecasting with Structured Shape and Temporal\n  Diversity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Probabilistic forecasting consists in predicting a distribution of possible\nfuture outcomes. In this paper, we address this problem for non-stationary time\nseries, which is very challenging yet crucially important. We introduce the\nSTRIPE model for representing structured diversity based on shape and time\nfeatures, ensuring both probable predictions while being sharp and accurate.\nSTRIPE is agnostic to the forecasting model, and we equip it with a\ndiversification mechanism relying on determinantal point processes (DPP). We\nintroduce two DPP kernels for modeling diverse trajectories in terms of shape\nand time, which are both differentiable and proved to be positive\nsemi-definite. To have an explicit control on the diversity structure, we also\ndesign an iterative sampling mechanism to disentangle shape and time\nrepresentations in the latent space. Experiments carried out on synthetic\ndatasets show that STRIPE significantly outperforms baseline methods for\nrepresenting diversity, while maintaining accuracy of the forecasting model. We\nalso highlight the relevance of the iterative sampling scheme and the\nimportance to use different criteria for measuring quality and diversity.\nFinally, experiments on real datasets illustrate that STRIPE is able to\noutperform state-of-the-art probabilistic forecasting approaches in the best\nsample prediction.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 18:31:43 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 11:50:53 GMT"}, {"version": "v3", "created": "Sat, 10 Apr 2021 07:50:13 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Guen", "Vincent Le", ""], ["Thome", "Nicolas", ""]]}, {"id": "2010.07358", "submitter": "Ruta Desai", "authors": "Benjamin Newman, Kevin Carlberg and Ruta Desai", "title": "Optimal Assistance for Object-Rearrangement Tasks in Augmented Reality", "comments": "19 pages including supplementary. Under review for ACM IUI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Augmented-reality (AR) glasses that will have access to onboard sensors and\nan ability to display relevant information to the user present an opportunity\nto provide user assistance in quotidian tasks. Many such tasks can be\ncharacterized as object-rearrangement tasks. We introduce a novel framework for\ncomputing and displaying AR assistance that consists of (1) associating an\noptimal action sequence with the policy of an embodied agent and (2) presenting\nthis sequence to the user as suggestions in the AR system's heads-up display.\nThe embodied agent comprises a \"hybrid\" between the AR system and the user,\nwith the AR system's observation space (i.e., sensors) and the user's action\nspace (i.e., task-execution actions); its policy is learned by minimizing the\ntask-completion time. In this initial study, we assume that the AR system's\nobservations include the environment's map and localization of the objects and\nthe user. These choices allow us to formalize the problem of computing AR\nassistance for any object-rearrangement task as a planning problem,\nspecifically as a capacitated vehicle-routing problem. Further, we introduce a\nnovel AR simulator that can enable web-based evaluation of AR-like assistance\nand associated at-scale data collection via the Habitat simulator for embodied\nartificial intelligence. Finally, we perform a study that evaluates user\nresponse to the proposed form of AR assistance on a specific quotidian\nobject-rearrangement task, house cleaning, using our proposed AR simulator on\nmechanical turk. In particular, we study the effect of the proposed AR\nassistance on users' task performance and sense of agency over a range of task\ndifficulties. Our results indicate that providing users with such assistance\nimproves their overall performance and while users report a negative impact to\ntheir agency, they may still prefer the proposed assistance to having no\nassistance at all.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 18:46:07 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Newman", "Benjamin", ""], ["Carlberg", "Kevin", ""], ["Desai", "Ruta", ""]]}, {"id": "2010.07359", "submitter": "Nalinda Kulathunga", "authors": "Nalinda Kulathunga, Nishath Rajiv Ranasinghe, Daniel Vrinceanu,\n  Zackary Kinsman, Lei Huang, Yunjiao Wang", "title": "Effects of the Nonlinearity in Activation Functions on the Performance\n  of Deep Learning Models", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nonlinearity of activation functions used in deep learning models are\ncrucial for the success of predictive models. There are several commonly used\nsimple nonlinear functions, including Rectified Linear Unit (ReLU) and\nLeaky-ReLU (L-ReLU). In practice, these functions remarkably enhance the model\naccuracy. However, there is limited insight into the functionality of these\nnonlinear activation functions in terms of why certain models perform better\nthan others. Here, we investigate the model performance when using ReLU or\nL-ReLU as activation functions in different model architectures and data\ndomains. Interestingly, we found that the application of L-ReLU is mostly\neffective when the number of trainable parameters in a model is relatively\nsmall. Furthermore, we found that the image classification models seem to\nperform well with L-ReLU in fully connected layers, especially when pre-trained\nmodels such as the VGG-16 are used for the transfer learning.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 18:48:59 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Kulathunga", "Nalinda", ""], ["Ranasinghe", "Nishath Rajiv", ""], ["Vrinceanu", "Daniel", ""], ["Kinsman", "Zackary", ""], ["Huang", "Lei", ""], ["Wang", "Yunjiao", ""]]}, {"id": "2010.07384", "submitter": "Christopher Frye", "authors": "Damien de Mijolla, Christopher Frye, Markus Kunesch, John Mansir, Ilya\n  Feige", "title": "Human-interpretable model explainability on high-dimensional data", "comments": "8 pages, 6 figures, 1 appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of explainability in machine learning continues to grow, as\nboth neural-network architectures and the data they model become increasingly\ncomplex. Unique challenges arise when a model's input features become high\ndimensional: on one hand, principled model-agnostic approaches to\nexplainability become too computationally expensive; on the other, more\nefficient explainability algorithms lack natural interpretations for general\nusers. In this work, we introduce a framework for human-interpretable\nexplainability on high-dimensional data, consisting of two modules. First, we\napply a semantically meaningful latent representation, both to reduce the raw\ndimensionality of the data, and to ensure its human interpretability. These\nlatent features can be learnt, e.g. explicitly as disentangled representations\nor implicitly through image-to-image translation, or they can be based on any\ncomputable quantities the user chooses. Second, we adapt the Shapley paradigm\nfor model-agnostic explainability to operate on these latent features. This\nleads to interpretable model explanations that are both theoretically\ncontrolled and computationally tractable. We benchmark our approach on\nsynthetic data and demonstrate its effectiveness on several\nimage-classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 20:06:28 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["de Mijolla", "Damien", ""], ["Frye", "Christopher", ""], ["Kunesch", "Markus", ""], ["Mansir", "John", ""], ["Feige", "Ilya", ""]]}, {"id": "2010.07389", "submitter": "Christopher Frye", "authors": "Tom Begley, Tobias Schwedes, Christopher Frye, Ilya Feige", "title": "Explainability for fair machine learning", "comments": "8 pages, 3 figures, 2 tables, 1 appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the decisions made or influenced by machine learning models increasingly\nimpact our lives, it is crucial to detect, understand, and mitigate unfairness.\nBut even simply determining what \"unfairness\" should mean in a given context is\nnon-trivial: there are many competing definitions, and choosing between them\noften requires a deep understanding of the underlying task. It is thus tempting\nto use model explainability to gain insights into model fairness, however\nexisting explainability tools do not reliably indicate whether a model is\nindeed fair. In this work we present a new approach to explaining fairness in\nmachine learning, based on the Shapley value paradigm. Our fairness\nexplanations attribute a model's overall unfairness to individual input\nfeatures, even in cases where the model does not operate on sensitive\nattributes directly. Moreover, motivated by the linearity of Shapley\nexplainability, we propose a meta algorithm for applying existing training-time\nfairness interventions, wherein one trains a perturbation to the original\nmodel, rather than a new model entirely. By explaining the original model, the\nperturbation, and the fair-corrected model, we gain insight into the\naccuracy-fairness trade-off that is being made by the intervention. We further\nshow that this meta algorithm enjoys both flexibility and stability benefits\nwith no loss in performance.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 20:21:01 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Begley", "Tom", ""], ["Schwedes", "Tobias", ""], ["Frye", "Christopher", ""], ["Feige", "Ilya", ""]]}, {"id": "2010.07404", "submitter": "Qi Zhao", "authors": "Qi Zhao", "title": "A Deep Learning Framework for Predicting Digital Asset Price Movement\n  from Trade-by-trade Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.AI cs.LG q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a deep learning framework based on Long Short-term Memory\nNetwork(LSTM) that predicts price movement of cryptocurrencies from\ntrade-by-trade data. The main focus of this study is on predicting short-term\nprice changes in a fixed time horizon from a looking back period. By carefully\ndesigning features and detailed searching for best hyper-parameters, the model\nis trained to achieve high performance on nearly a year of trade-by-trade data.\nThe optimal model delivers stable high performance(over 60% accuracy) on\nout-of-sample test periods. In a realistic trading simulation setting, the\nprediction made by the model could be easily monetized. Moreover, this study\nshows that the LSTM model could extract universal features from trade-by-trade\ndata, as the learned parameters well maintain their high performance on other\ncryptocurrency instruments that were not included in training data. This study\nexceeds existing researches in term of the scale and precision of data used, as\nwell as the high prediction accuracy achieved.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 10:42:02 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Zhao", "Qi", ""]]}, {"id": "2010.07414", "submitter": "Isar Nejadgholi", "authors": "Isar Nejadgholi and Svetlana Kiritchenko", "title": "On Cross-Dataset Generalization in Automatic Detection of Online Abuse", "comments": "13 pages, 3 figures, published at WOAH-2020 (The 4th Workshop on\n  Online Abuse and Harms)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NLP research has attained high performances in abusive language detection as\na supervised classification task. While in research settings, training and test\ndatasets are usually obtained from similar data samples, in practice systems\nare often applied on data that are different from the training set in topic and\nclass distributions. Also, the ambiguity in class definitions inherited in this\ntask aggravates the discrepancies between source and target datasets. We\nexplore the topic bias and the task formulation bias in cross-dataset\ngeneralization. We show that the benign examples in the Wikipedia Detox dataset\nare biased towards platform-specific topics. We identify these examples using\nunsupervised topic modeling and manual inspection of topics' keywords. Removing\nthese topics increases cross-dataset generalization, without reducing in-domain\nclassification performance. For a robust dataset design, we suggest applying\ninexpensive unsupervised methods to inspect the collected data and downsize the\nnon-generalizable content before manually annotating for class labels.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 21:47:03 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 15:28:12 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 18:47:03 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Nejadgholi", "Isar", ""], ["Kiritchenko", "Svetlana", ""]]}, {"id": "2010.07422", "submitter": "HanQin Cai", "authors": "HanQin Cai, Keaton Hamm, Longxiu Huang, Jiaqi Li, Tao Wang", "title": "Rapid Robust Principal Component Analysis: CUR Accelerated Inexact Low\n  Rank Estimation", "comments": null, "journal-ref": "IEEE Signal Processing Letters, 28 (2021): 116-120", "doi": "10.1109/LSP.2020.3044130", "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG cs.NA math.IT math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust principal component analysis (RPCA) is a widely used tool for\ndimension reduction. In this work, we propose a novel non-convex algorithm,\ncoined Iterated Robust CUR (IRCUR), for solving RPCA problems, which\ndramatically improves the computational efficiency in comparison with the\nexisting algorithms. IRCUR achieves this acceleration by employing CUR\ndecomposition when updating the low rank component, which allows us to obtain\nan accurate low rank approximation via only three small submatrices.\nConsequently, IRCUR is able to process only the small submatrices and avoid\nexpensive computing on the full matrix through the entire algorithm. Numerical\nexperiments establish the computational advantage of IRCUR over the\nstate-of-art algorithms on both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 22:30:20 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 01:41:41 GMT"}, {"version": "v3", "created": "Sun, 7 Feb 2021 06:43:25 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Cai", "HanQin", ""], ["Hamm", "Keaton", ""], ["Huang", "Longxiu", ""], ["Li", "Jiaqi", ""], ["Wang", "Tao", ""]]}, {"id": "2010.07429", "submitter": "Zhefan Xu", "authors": "Zhefan Xu, Di Deng, Kenji Shimada", "title": "Autonomous UAV Exploration of Dynamic Environments via Incremental\n  Sampling and Probabilistic Roadmap", "comments": "8 Pages, 9 Figures, and 5 Tables. Video Link:\n  https://youtu.be/ileyP4DRBjU. Github Link: https://github.com/Zhefan-Xu/DEP", "journal-ref": "IEEE Robotics and Automation Letters, Volume: 6, Issue: 2, April\n  2021. Page(s): 2729 - 2736", "doi": "10.1109/LRA.2021.3062008", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous exploration requires robots to generate informative trajectories\niteratively. Although sampling-based methods are highly efficient in unmanned\naerial vehicle exploration, many of these methods do not effectively utilize\nthe sampled information from the previous planning iterations, leading to\nredundant computation and longer exploration time. Also, few have explicitly\nshown their exploration ability in dynamic environments even though they can\nrun real-time. To overcome these limitations, we propose a novel dynamic\nexploration planner (DEP) for exploring unknown environments using incremental\nsampling and Probabilistic Roadmap (PRM). In our sampling strategy, nodes are\nadded incrementally and distributed evenly in the explored region, yielding the\nbest viewpoints. To further shortening exploration time and ensuring safety,\nour planner optimizes paths locally and refine them based on the Euclidean\nSigned Distance Function (ESDF) map. Meanwhile, as the multi-query planner, PRM\nallows the proposed planner to quickly search alternative paths to avoid\ndynamic obstacles for safe exploration. Simulation experiments show that our\nmethod safely explores dynamic environments and outperforms the benchmark\nplanners in terms of exploration time, path length, and computational time.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 22:52:37 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 19:33:52 GMT"}, {"version": "v3", "created": "Sun, 21 Mar 2021 03:04:36 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Xu", "Zhefan", ""], ["Deng", "Di", ""], ["Shimada", "Kenji", ""]]}, {"id": "2010.07458", "submitter": "Razieh Nabi", "authors": "Razieh Nabi, Joel Pfeiffer, Murat Ali Bayir, Denis Charles, Emre\n  K{\\i}c{\\i}man", "title": "Causal Inference in the Presence of Interference in Sponsored Search\n  Advertising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classical causal inference, inferring cause-effect relations from data\nrelies on the assumption that units are independent and identically\ndistributed. This assumption is violated in settings where units are related\nthrough a network of dependencies. An example of such a setting is ad placement\nin sponsored search advertising, where the clickability of a particular ad is\npotentially influenced by where it is placed and where other ads are placed on\nthe search result page. In such scenarios, confounding arises due to not only\nthe individual ad-level covariates but also the placements and covariates of\nother ads in the system. In this paper, we leverage the language of causal\ninference in the presence of interference to model interactions among the ads.\nQuantification of such interactions allows us to better understand the click\nbehavior of users, which in turn impacts the revenue of the host search engine\nand enhances user satisfaction. We illustrate the utility of our formalization\nthrough experiments carried out on the ad placement system of the Bing search\nengine.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 01:13:14 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Nabi", "Razieh", ""], ["Pfeiffer", "Joel", ""], ["Bayir", "Murat Ali", ""], ["Charles", "Denis", ""], ["K\u0131c\u0131man", "Emre", ""]]}, {"id": "2010.07459", "submitter": "Lan Du", "authors": "Jueqing Lu, Lan Du, Ming Liu, Joanna Dipnall", "title": "Multi-label Few/Zero-shot Learning with Knowledge Aggregated from\n  Multiple Label Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few/Zero-shot learning is a big challenge of many classifications tasks,\nwhere a classifier is required to recognise instances of classes that have very\nfew or even no training samples. It becomes more difficult in multi-label\nclassification, where each instance is labelled with more than one class. In\nthis paper, we present a simple multi-graph aggregation model that fuses\nknowledge from multiple label graphs encoding different semantic label\nrelationships in order to study how the aggregated knowledge can benefit\nmulti-label zero/few-shot document classification. The model utilises three\nkinds of semantic information, i.e., the pre-trained word embeddings, label\ndescription, and pre-defined label relations. Experimental results derived on\ntwo large clinical datasets (i.e., MIMIC-II and MIMIC-III) and the EU\nlegislation dataset show that methods equipped with the multi-graph knowledge\naggregation achieve significant performance improvement across almost all the\nmeasures on few/zero-shot labels.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 01:15:43 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Lu", "Jueqing", ""], ["Du", "Lan", ""], ["Liu", "Ming", ""], ["Dipnall", "Joanna", ""]]}, {"id": "2010.07469", "submitter": "Xiangrui Li", "authors": "Yuan Zhou, Xiangrui Li", "title": "Unsupervised Self-training Algorithm Based on Deep Learning for Optical\n  Aerial Images Change Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical aerial images change detection is an important task in earth\nobservation and has been extensively investigated in the past few decades.\nGenerally, the supervised change detection methods with superior performance\nrequire a large amount of labeled training data which is obtained by manual\nannotation with high cost. In this paper, we present a novel unsupervised\nself-training algorithm (USTA) for optical aerial images change detection. The\ntraditional method such as change vector analysis is used to generate the\npseudo labels. We use these pseudo labels to train a well designed\nconvolutional neural network. The network is used as a teacher to classify the\noriginal multitemporal images to generate another set of pseudo labels. Then\ntwo set of pseudo labels are used to jointly train a student network with the\nsame structure as the teacher. The final change detection result can be\nobtained by the trained student network. Besides, we design an image filter to\ncontrol the usage of change information in the pseudo labels in the training\nprocess of the network. The whole process of the algorithm is an unsupervised\nprocess without manually marked labels. Experimental results on the real\ndatasets demonstrate competitive performance of our proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 01:51:46 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 07:28:12 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Zhou", "Yuan", ""], ["Li", "Xiangrui", ""]]}, {"id": "2010.07474", "submitter": "Chunnnan Wang", "authors": "Chunnan Wang, Kaixin Zhang, Hongzhi Wang, Bozhou Chen", "title": "Auto-STGCN: Autonomous Spatial-Temporal Graph Convolutional Network\n  Search Based on Reinforcement Learning and Existing Research Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, many spatial-temporal graph convolutional network (STGCN)\nmodels are proposed to deal with the spatial-temporal network data forecasting\nproblem. These STGCN models have their own advantages, i.e., each of them puts\nforward many effective operations and achieves good prediction results in the\nreal applications. If users can effectively utilize and combine these excellent\noperations integrating the advantages of existing models, then they may obtain\nmore effective STGCN models thus create greater value using existing work.\nHowever, they fail to do so due to the lack of domain knowledge, and there is\nlack of automated system to help users to achieve this goal. In this paper, we\nfill this gap and propose Auto-STGCN algorithm, which makes use of existing\nmodels to automatically explore high-performance STGCN model for specific\nscenarios. Specifically, we design Unified-STGCN framework, which summarizes\nthe operations of existing architectures, and use parameters to control the\nusage and characteristic attributes of each operation, so as to realize the\nparameterized representation of the STGCN architecture and the reorganization\nand fusion of advantages. Then, we present Auto-STGCN, an optimization method\nbased on reinforcement learning, to quickly search the parameter search space\nprovided by Unified-STGCN, and generate optimal STGCN models automatically.\nExtensive experiments on real-world benchmark datasets show that our Auto-STGCN\ncan find STGCN models superior to existing STGCN models with heuristic\nparameters, which demonstrates the effectiveness of our proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 02:33:11 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Wang", "Chunnan", ""], ["Zhang", "Kaixin", ""], ["Wang", "Hongzhi", ""], ["Chen", "Bozhou", ""]]}, {"id": "2010.07487", "submitter": "Alon Jacovi", "authors": "Alon Jacovi, Ana Marasovi\\'c, Tim Miller, Yoav Goldberg", "title": "Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and\n  Goals of Human Trust in AI", "comments": "Accepted to ACM FAccT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trust is a central component of the interaction between people and AI, in\nthat 'incorrect' levels of trust may cause misuse, abuse or disuse of the\ntechnology. But what, precisely, is the nature of trust in AI? What are the\nprerequisites and goals of the cognitive mechanism of trust, and how can we\npromote them, or assess whether they are being satisfied in a given\ninteraction? This work aims to answer these questions. We discuss a model of\ntrust inspired by, but not identical to, sociology's interpersonal trust (i.e.,\ntrust between people). This model rests on two key properties of the\nvulnerability of the user and the ability to anticipate the impact of the AI\nmodel's decisions. We incorporate a formalization of 'contractual trust', such\nthat trust between a user and an AI is trust that some implicit or explicit\ncontract will hold, and a formalization of 'trustworthiness' (which detaches\nfrom the notion of trustworthiness in sociology), and with it concepts of\n'warranted' and 'unwarranted' trust. We then present the possible causes of\nwarranted trust as intrinsic reasoning and extrinsic behavior, and discuss how\nto design trustworthy AI, how to evaluate whether trust has manifested, and\nwhether it is warranted. Finally, we elucidate the connection between trust and\nXAI using our formalization.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 03:07:23 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 21:14:17 GMT"}, {"version": "v3", "created": "Wed, 20 Jan 2021 12:24:26 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Jacovi", "Alon", ""], ["Marasovi\u0107", "Ana", ""], ["Miller", "Tim", ""], ["Goldberg", "Yoav", ""]]}, {"id": "2010.07494", "submitter": "Zhiyuan Xu", "authors": "Zhiyuan Xu, Kun Wu, Zhengping Che, Jian Tang, Jieping Ye", "title": "Knowledge Transfer in Multi-Task Deep Reinforcement Learning for\n  Continuous Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Deep Reinforcement Learning (DRL) has emerged as a promising approach\nto many complex tasks, it remains challenging to train a single DRL agent that\nis capable of undertaking multiple different continuous control tasks. In this\npaper, we present a Knowledge Transfer based Multi-task Deep Reinforcement\nLearning framework (KTM-DRL) for continuous control, which enables a single DRL\nagent to achieve expert-level performance in multiple different tasks by\nlearning from task-specific teachers. In KTM-DRL, the multi-task agent first\nleverages an offline knowledge transfer algorithm designed particularly for the\nactor-critic architecture to quickly learn a control policy from the experience\nof task-specific teachers, and then it employs an online learning algorithm to\nfurther improve itself by learning from new online transition samples under the\nguidance of those teachers. We perform a comprehensive empirical study with two\ncommonly-used benchmarks in the MuJoCo continuous control task suite. The\nexperimental results well justify the effectiveness of KTM-DRL and its\nknowledge transfer and online learning algorithms, as well as its superiority\nover the state-of-the-art by a large margin.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 03:26:47 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 14:34:32 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Xu", "Zhiyuan", ""], ["Wu", "Kun", ""], ["Che", "Zhengping", ""], ["Tang", "Jian", ""], ["Ye", "Jieping", ""]]}, {"id": "2010.07497", "submitter": "Jianheng Tang", "authors": "Wenge Liu, Jianheng Tang, Jinghui Qin, Lin Xu, Zhen Li, Xiaodan Liang", "title": "MedDG: A Large-scale Medical Consultation Dataset for Building Medical\n  Dialogue System", "comments": "Data and code are available at https://github.com/lwgkzl/MedDG", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing conversational agents to interact with patients and provide\nprimary clinical advice has attracted increasing attention due to its huge\napplication potential, especially in the time of COVID-19 Pandemic. However,\nthe training of end-to-end neural-based medical dialogue system is restricted\nby an insufficient quantity of medical dialogue corpus. In this work, we make\nthe first attempt to build and release a large-scale high-quality Medical\nDialogue dataset related to 12 types of common Gastrointestinal diseases named\nMedDG, with more than 17K conversations collected from the online health\nconsultation community. Five different categories of entities, including\ndiseases, symptoms, attributes, tests, and medicines, are annotated in each\nconversation of MedDG as additional labels. To push forward the future research\non building expert-sensitive medical dialogue system, we proposes two kinds of\nmedical dialogue tasks based on MedDG dataset. One is the next entity\nprediction and the other is the doctor response generation. To acquire a clear\ncomprehension on these two medical dialogue tasks, we implement several\nstate-of-the-art benchmarks, as well as design two dialogue models with a\nfurther consideration on the predicted entities. Experimental results show that\nthe pre-train language models and other baselines struggle on both tasks with\npoor performance in our dataset, and the response quality can be enhanced with\nthe help of auxiliary entity information. From human evaluation, the simple\nretrieval model outperforms several state-of-the-art generative models,\nindicating that there still remains a large room for improvement on generating\nmedically meaningful responses.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 03:34:33 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Liu", "Wenge", ""], ["Tang", "Jianheng", ""], ["Qin", "Jinghui", ""], ["Xu", "Lin", ""], ["Li", "Zhen", ""], ["Liang", "Xiaodan", ""]]}, {"id": "2010.07504", "submitter": "Ayan Mukhopadhyay", "authors": "Ayan Mukhopadhyay and Geoffrey Pettet and Mykel Kochenderfer and\n  Abhishek Dubey", "title": "Designing Emergency Response Pipelines : Lessons and Challenges", "comments": "Accepted at the AI for Social Good Workshop, AAAI Fall Symposium\n  Series 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergency response to incidents such as accidents, crimes, and fires is a\nmajor problem faced by communities. Emergency response management comprises of\nseveral stages and sub-problems like forecasting, resource allocation, and\ndispatch. The design of principled approaches to tackle each problem is\nnecessary to create efficient emergency response management (ERM) pipelines.\nOver the last six years, we have worked with several first responder\norganizations to design ERM pipelines. In this paper, we highlight some of the\nchallenges that we have identified and lessons that we have learned through our\nexperience in this domain. Such challenges are particularly relevant for\npractitioners and researchers, and are important considerations even in the\ndesign of response strategies to mitigate disasters like floods and\nearthquakes.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 04:04:15 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Mukhopadhyay", "Ayan", ""], ["Pettet", "Geoffrey", ""], ["Kochenderfer", "Mykel", ""], ["Dubey", "Abhishek", ""]]}, {"id": "2010.07514", "submitter": "Chi Chen", "authors": "Chi Chen, Xin Peng, Zhenchang Xing, Jun Sun, Xin Wang, Yifan Zhao, and\n  Wenyun Zhao", "title": "Holistic Combination of Structural and Textual Code Information for\n  Context based API Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context based API recommendation is an important way to help developers find\nthe needed APIs effectively and efficiently. For effective API recommendation,\nwe need not only a joint view of both structural and textual code information,\nbut also a holistic view of correlated API usage in control and data flow graph\nas a whole. Unfortunately, existing API recommendation methods exploit\nstructural or textual code information separately. In this work, we propose a\nnovel API recommendation approach called APIRec-CST (API Recommendation by\nCombining Structural and Textual code information). APIRec-CST is a deep\nlearning model that combines the API usage with the text information in the\nsource code based on an API Context Graph Network and a Code Token Network that\nsimultaneously learn structural and textual features for API recommendation. We\napply APIRec-CST to train a model for JDK library based on 1,914 open-source\nJava projects and evaluate the accuracy and MRR (Mean Reciprocal Rank) of API\nrecommendation with another 6 open-source projects. The results show that our\napproach achieves respectively a top-1, top-5, top-10 accuracy and MRR of\n60.3%, 81.5%, 87.7% and 69.4%, and significantly outperforms an existing\ngraph-based statistical approach and a tree-based deep learning approach for\nAPI recommendation. A further analysis shows that textual code information\nmakes sense and improves the accuracy and MRR. We also conduct a user study in\nwhich two groups of students are asked to finish 6 programming tasks with or\nwithout our APIRec-CST plugin. The results show that APIRec-CST can help the\nstudents to finish the tasks faster and more accurately and the feedback on the\nusability is overwhelmingly positive.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 04:40:42 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Chen", "Chi", ""], ["Peng", "Xin", ""], ["Xing", "Zhenchang", ""], ["Sun", "Jun", ""], ["Wang", "Xin", ""], ["Zhao", "Yifan", ""], ["Zhao", "Wenyun", ""]]}, {"id": "2010.07523", "submitter": "Zhengxuan Wu", "authors": "Zhengxuan Wu, Desmond C. Ong", "title": "Context-Guided BERT for Targeted Aspect-Based Sentiment Analysis", "comments": null, "journal-ref": "AAAI 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-based sentiment analysis (ABSA) and Targeted ASBA (TABSA) allow\nfiner-grained inferences about sentiment to be drawn from the same text,\ndepending on context. For example, a given text can have different targets\n(e.g., neighborhoods) and different aspects (e.g., price or safety), with\ndifferent sentiment associated with each target-aspect pair. In this paper, we\ninvestigate whether adding context to self-attention models improves\nperformance on (T)ABSA. We propose two variants of Context-Guided BERT\n(CG-BERT) that learn to distribute attention under different contexts. We first\nadapt a context-aware Transformer to produce a CG-BERT that uses context-guided\nsoftmax-attention. Next, we propose an improved Quasi-Attention CG-BERT model\nthat learns a compositional attention that supports subtractive attention. We\ntrain both models with pretrained BERT on two (T)ABSA datasets: SentiHood and\nSemEval-2014 (Task 4). Both models achieve new state-of-the-art results with\nour QACG-BERT model having the best performance. Furthermore, we provide\nanalyses of the impact of context in the our proposed models. Our work provides\nmore evidence for the utility of adding context-dependencies to pretrained\nself-attention-based language models for context-based natural language tasks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 05:01:20 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 18:33:19 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Wu", "Zhengxuan", ""], ["Ong", "Desmond C.", ""]]}, {"id": "2010.07533", "submitter": "Liang Li", "authors": "Bin-Bin Zhao and Liang Li and Hui-Dong Zhang", "title": "TDRE: A Tensor Decomposition Based Approach for Relation Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting entity pairs along with relation types from unstructured texts is\na fundamental subtask of information extraction. Most existing joint models\nrely on fine-grained labeling scheme or focus on shared embedding parameters.\nThese methods directly model the joint probability of multi-labeled triplets,\nwhich suffer from extracting redundant triplets with all relation types.\nHowever, each sentence may contain very few relation types. In this paper, we\nfirst model the final triplet extraction result as a three-order tensor of\nword-to-word pairs enriched with each relation type. And in order to obtain the\nsentence contained relations, we introduce an independent but joint training\nrelation classification module. The tensor decomposition strategy is finally\nutilized to decompose the triplet tensor with predicted relational components\nwhich omits the calculations for unpredicted relation types. According to\neffective decomposition methods, we propose the Tensor Decomposition based\nRelation Extraction (TDRE) approach which is able to extract overlapping\ntriplets and avoid detecting unnecessary entity pairs. Experiments on benchmark\ndatasets NYT, CoNLL04 and ADE datasets demonstrate that the proposed method\noutperforms existing strong baselines.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 05:29:34 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Zhao", "Bin-Bin", ""], ["Li", "Liang", ""], ["Zhang", "Hui-Dong", ""]]}, {"id": "2010.07553", "submitter": "Hyun-Jin Jeong", "authors": "Hyun-Jin Jeong, Yong-Jae Moon, Eunsu Park, Harim Lee", "title": "Solar Coronal Magnetic Field Extrapolation from Synchronic Data with\n  AI-generated Farside", "comments": "12 pages, 6 figures, 1 table, Accepted for publication in ApJL", "journal-ref": null, "doi": "10.3847/2041-8213/abc255", "report-no": null, "categories": "astro-ph.SR cs.AI physics.space-ph", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Solar magnetic fields play a key role in understanding the nature of the\ncoronal phenomena. Global coronal magnetic fields are usually extrapolated from\nphotospheric fields, for which farside data is taken when it was at the\nfrontside, about two weeks earlier. For the first time we have constructed the\nextrapolations of global magnetic fields using frontside and artificial\nintelligence (AI)-generated farside magnetic fields at a near-real time basis.\nWe generate the farside magnetograms from three channel farside observations of\nSolar Terrestrial Relations Observatory (STEREO) Ahead (A) and Behind (B) by\nour deep learning model trained with frontside Solar Dynamics Observatory\nextreme ultraviolet images and magnetograms. For frontside testing data sets,\nwe demonstrate that the generated magnetic field distributions are consistent\nwith the real ones; not only active regions (ARs), but also quiet regions of\nthe Sun. We make global magnetic field synchronic maps in which conventional\nfarside data are replaced by farside ones generated by our model. The\nsynchronic maps show much better not only the appearance of ARs but also the\ndisappearance of others on the solar surface than before. We use these\nsynchronized magnetic data to extrapolate the global coronal fields using\nPotential Field Source Surface (PFSS) model. We show that our results are much\nmore consistent with coronal observations than those of the conventional method\nin view of solar active regions and coronal holes. We present several positive\nprospects of our new methodology for the study of solar corona, heliosphere,\nand space weather.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 07:04:54 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 04:06:27 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 06:27:14 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Jeong", "Hyun-Jin", ""], ["Moon", "Yong-Jae", ""], ["Park", "Eunsu", ""], ["Lee", "Harim", ""]]}, {"id": "2010.07604", "submitter": "Dongjun Kim", "authors": "Dongjun Kim, Kyungwoo Song, YoonYeong Kim, Yongjin Shin, Wanmo Kang,\n  Il-Chul Moon", "title": "Sequential Likelihood-Free Inference with Implicit Surrogate Proposal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference without the access of likelihood, or likelihood-free\ninference, has been a key research topic in simulations, to yield a more\nrealistic generation result. Recent likelihood-free inference updates an\napproximate posterior sequentially with the dataset of the cumulative\nsimulation input-output pairs over inference rounds. Therefore, the dataset is\ngathered through the iterative simulations with sampled inputs from a proposal\ndistribution by MCMC, which becomes the key of inference quality in this\nsequential framework. This paper introduces a new proposal modeling, named as\nImplicit Surrogate Proposal (ISP), to generate a cumulated dataset with further\nsample efficiency. ISP constructs the cumulative dataset in the most diverse\nway by drawing i.i.d samples via a feed-forward fashion, so the posterior\ninference does not suffer from the disadvantages of MCMC caused by its\nnon-i.i.d nature, such as auto-correlation and slow mixing. We analyze the\nconvergence property of ISP in both theoretical and empirical aspects to\nguarantee that ISP provides an asymptotically exact sampler. We demonstrate\nthat ISP outperforms the baseline inference algorithms on simulations with\nmulti-modal posteriors.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 08:59:23 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 16:55:23 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Kim", "Dongjun", ""], ["Song", "Kyungwoo", ""], ["Kim", "YoonYeong", ""], ["Shin", "Yongjin", ""], ["Kang", "Wanmo", ""], ["Moon", "Il-Chul", ""]]}, {"id": "2010.07610", "submitter": "Fabrice Muhlenbach", "authors": "Fabrice Muhlenbach", "title": "A Methodology for Ethics-by-Design AI Systems: Dealing with Human Value\n  Conflicts", "comments": "Paper presented at the 2020 IEEE International Conference on Systems,\n  Man, and Cybernetics (SMC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The introduction of artificial intelligence into activities traditionally\ncarried out by human beings produces brutal changes. This is not without\nconsequences for human values. This paper is about designing and implementing\nmodels of ethical behaviors in AI-based systems, and more specifically it\npresents a methodology for designing systems that take ethical aspects into\naccount at an early stage while finding an innovative solution to prevent human\nvalues from being affected. Two case studies where AI-based innovations\ncomplement economic and social proposals with this methodology are presented:\none in the field of culture and operated by a private company, the other in the\nfield of scientific research and supported by a state organization.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 09:14:00 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Muhlenbach", "Fabrice", ""]]}, {"id": "2010.07615", "submitter": "George De Ath", "authors": "George De Ath, Richard M. Everson, Jonathan E. Fieldsend", "title": "Asynchronous \\epsilon-Greedy Bayesian Optimisation", "comments": "Accepted for the 37th conference on Uncertainty in Artificial\n  Intelligence (UAI 2021). 11 pages (main paper) + 22 pages (supplementary\n  material)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Bayesian optimisation (BO) is a successful technique for the\noptimisation of expensive black-box functions. Asynchronous BO can reduce\nwallclock time by starting a new evaluation as soon as another finishes, thus\nmaximising resource utilisation. To maximise resource allocation, we develop a\nnovel asynchronous BO method, AEGiS (Asynchronous $\\epsilon$-Greedy Global\nSearch) that combines greedy search, exploiting the surrogate's mean\nprediction, with Thompson sampling and random selection from the approximate\nPareto set describing the trade-off between exploitation (surrogate mean\nprediction) and exploration (surrogate posterior variance). We demonstrate\nempirically the efficacy of AEGiS on synthetic benchmark problems,\nmeta-surrogate hyperparameter tuning problems and real-world problems, showing\nthat AEGiS generally outperforms existing methods for asynchronous BO. When a\nsingle worker is available performance is no worse than BO using expected\nimprovement.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 09:21:02 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 11:10:00 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 16:06:56 GMT"}, {"version": "v4", "created": "Fri, 11 Jun 2021 11:15:36 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["De Ath", "George", ""], ["Everson", "Richard M.", ""], ["Fieldsend", "Jonathan E.", ""]]}, {"id": "2010.07620", "submitter": "Yao Zhang", "authors": "Yao Zhang, Xu Zhang, Jun Wang, Hongru Liang, Adam Jatowt, Wenqiang\n  Lei, Zhenglu Yang", "title": "GMH: A General Multi-hop Reasoning Model for KG Completion", "comments": "11 pages, 5 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs are essential for numerous downstream natural language\nprocessing applications, but are typically incomplete with many facts missing.\nThis results in research efforts on multi-hop reasoning task, which can be\nformulated as a search process and current models typically perform short\ndistance reasoning. However, the long-distance reasoning is also vital with the\nability to connect the superficially unrelated entities. To the best of our\nknowledge, there lacks a general framework that approaches multi-hop reasoning\nin both short and long scenarios. We argue that there are two key issues for\nlong distance reasoning: i) which edge to select, and ii) when to stop the\nsearch. In this work, we propose a general model which resolves the issues with\nthree modules: 1) the local-global knowledge module to estimate the possible\npaths, 2) the differentiated action dropout module to explore a diverse set of\npaths, and 3) the adaptive stopping search module to avoid over searching. The\ncomprehensive results on three datasets demonstrate the superiority of our\nmodel with significant improvements against baselines in both short and long\ndistance reasoning scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 09:30:46 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 13:48:28 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Zhang", "Yao", ""], ["Zhang", "Xu", ""], ["Wang", "Jun", ""], ["Liang", "Hongru", ""], ["Jatowt", "Adam", ""], ["Lei", "Wenqiang", ""], ["Yang", "Zhenglu", ""]]}, {"id": "2010.07628", "submitter": "Jingwei Ma", "authors": "Jiahui Wen and Jingwei Ma and Hongkui Tu and Wei Yin and Jian Fang", "title": "Hierarchical Text Interaction for Rating Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional recommender systems encounter several challenges such as data\nsparsity and unexplained recommendation. To address these challenges, many\nworks propose to exploit semantic information from review data. However, these\nmethods have two major limitations in terms of the way to model textual\nfeatures and capture textual interaction. For textual modeling, they simply\nconcatenate all the reviews of a user/item into a single review. However,\nfeature extraction at word/phrase level can violate the meaning of the original\nreviews. As for textual interaction, they defer the interactions to the\nprediction layer, making them fail to capture complex correlations between\nusers and items. To address those limitations, we propose a novel Hierarchical\nText Interaction model(HTI) for rating prediction. In HTI, we propose to model\nlow-level word semantics and high-level review representations hierarchically.\nThe hierarchy allows us to exploit textual features at different granularities.\nTo further capture complex user-item interactions, we propose to exploit\nsemantic correlations between each user-item pair at different hierarchies. At\nword level, we propose an attention mechanism specialized to each user-item\npair, and capture the important words for representing each review. At review\nlevel, we mutually propagate textual features between the user and item, and\ncapture the informative reviews. The aggregated review representations are\nintegrated into a collaborative filtering framework for rating prediction.\nExperiments on five real-world datasets demonstrate that HTI outperforms\nstate-of-the-art models by a large margin. Further case studies provide a deep\ninsight into HTI's ability to capture semantic correlations at different levels\nof granularities for rating prediction.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 09:52:40 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Wen", "Jiahui", ""], ["Ma", "Jingwei", ""], ["Tu", "Hongkui", ""], ["Yin", "Wei", ""], ["Fang", "Jian", ""]]}, {"id": "2010.07647", "submitter": "Shakshi Sharma", "authors": "Shakshi Sharma and Rajesh Sharma", "title": "Identifying Possible Rumor Spreaders on Twitter: A Weak Supervised\n  Learning Approach", "comments": "Published at The International Joint Conference on Neural Networks\n  2021 (IJCNN2021). Please cite the IJCNN version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Social Media (OSM) platforms such as Twitter, Facebook are extensively\nexploited by the users of these platforms for spreading the (mis)information to\na large audience effortlessly at a rapid pace. It has been observed that the\nmisinformation can cause panic, fear, and financial loss to society. Thus, it\nis important to detect and control the misinformation in such platforms before\nit spreads to the masses. In this work, we focus on rumors, which is one type\nof misinformation (other types are fake news, hoaxes, etc). One way to control\nthe spread of the rumors is by identifying users who are possibly the rumor\nspreaders, that is, users who are often involved in spreading the rumors. Due\nto the lack of availability of rumor spreaders labeled dataset (which is an\nexpensive task), we use publicly available PHEME dataset, which contains rumor\nand non-rumor tweets information, and then apply a weak supervised learning\napproach to transform the PHEME dataset into rumor spreaders dataset. We\nutilize three types of features, that is, user, text, and ego-network features,\nbefore applying various supervised learning approaches. In particular, to\nexploit the inherent network property in this dataset (user-user reply graph),\nwe explore Graph Convolutional Network (GCN), a type of Graph Neural Network\n(GNN) technique. We compare GCN results with the other approaches: SVM, RF, and\nLSTM. Extensive experiments performed on the rumor spreaders dataset, where we\nachieve up to 0.864 value for F1-Score and 0.720 value for AUC-ROC, shows the\neffectiveness of our methodology for identifying possible rumor spreaders using\nthe GCN technique.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 10:31:28 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 09:16:25 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Sharma", "Shakshi", ""], ["Sharma", "Rajesh", ""]]}, {"id": "2010.07650", "submitter": "Ioannis Mollas", "authors": "Ioannis Mollas, Nick Bassiliades, Grigorios Tsoumakas", "title": "Altruist: Argumentative Explanations through Local Interpretations of\n  Predictive Models", "comments": "9 Pages, 4 Figures, 3 Tables, Submitted to SDM21 by SIAM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable machine learning is an emerging field providing solutions on\nacquiring insights into machine learning models' rationale. It has been put in\nthe map of machine learning by suggesting ways to tackle key ethical and\nsocietal issues. However, existing techniques of interpretable machine learning\nare far from being comprehensible and explainable to the end user. Another key\nissue in this field is the lack of evaluation and selection criteria, making it\ndifficult for the end user to choose the most appropriate interpretation\ntechnique for its use. In this study, we introduce a meta-explanation\nmethodology that will provide truthful interpretations, in terms of feature\nimportance, to the end user through argumentation. At the same time, this\nmethodology can be used as an evaluation or selection tool for multiple\ninterpretation techniques based on feature importance.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 10:36:48 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Mollas", "Ioannis", ""], ["Bassiliades", "Nick", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "2010.07668", "submitter": "Peng Cui", "authors": "Peng Cui, Le Hu, Yuanchao Liu", "title": "Inducing Alignment Structure with Gated Graph Attention Networks for\n  Sentence Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence matching is a fundamental task of natural language processing with\nvarious applications. Most recent approaches adopt attention-based neural\nmodels to build word- or phrase-level alignment between two sentences. However,\nthese models usually ignore the inherent structure within the sentences and\nfail to consider various dependency relationships among text units. To address\nthese issues, this paper proposes a graph-based approach for sentence matching.\nFirst, we represent a sentence pair as a graph with several carefully design\nstrategies. We then employ a novel gated graph attention network to encode the\nconstructed graph for sentence matching. Experimental results demonstrate that\nour method substantially achieves state-of-the-art performance on two datasets\nacross tasks of natural language and paraphrase identification. Further\ndiscussions show that our model can learn meaningful graph structure,\nindicating its superiority on improved interpretability.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 11:25:54 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Cui", "Peng", ""], ["Hu", "Le", ""], ["Liu", "Yuanchao", ""]]}, {"id": "2010.07676", "submitter": "Guanhua Zhang", "authors": "Guanhua Zhang, Bing Bai, Jian Liang, Kun Bai, Conghui Zhu, Tiejun Zhao", "title": "Reliable Evaluations for Natural Language Inference based on a Unified\n  Cross-dataset Benchmark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies show that crowd-sourced Natural Language Inference (NLI)\ndatasets may suffer from significant biases like annotation artifacts. Models\nutilizing these superficial clues gain mirage advantages on the in-domain\ntesting set, which makes the evaluation results over-estimated. The lack of\ntrustworthy evaluation settings and benchmarks stalls the progress of NLI\nresearch. In this paper, we propose to assess a model's trustworthy\ngeneralization performance with cross-datasets evaluation. We present a new\nunified cross-datasets benchmark with 14 NLI datasets, and re-evaluate 9\nwidely-used neural network-based NLI models as well as 5 recently proposed\ndebiasing methods for annotation artifacts. Our proposed evaluation scheme and\nexperimental baselines could provide a basis to inspire future reliable NLI\nresearch.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 11:50:12 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Zhang", "Guanhua", ""], ["Bai", "Bing", ""], ["Liang", "Jian", ""], ["Bai", "Kun", ""], ["Zhu", "Conghui", ""], ["Zhao", "Tiejun", ""]]}, {"id": "2010.07693", "submitter": "Matthew Leavitt", "authors": "Matthew L. Leavitt, Ari Morcos", "title": "Linking average- and worst-case perturbation robustness via class\n  selectivity and dimensionality", "comments": "arXiv admin note: text overlap with arXiv:2007.04440", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representational sparsity is known to affect robustness to input\nperturbations in deep neural networks (DNNs), but less is known about how the\nsemantic content of representations affects robustness. Class selectivity-the\nvariability of a unit's responses across data classes or dimensions-is one way\nof quantifying the sparsity of semantic representations. Given recent evidence\nthat class selectivity may not be necessary for, and in some cases can impair\ngeneralization, we investigate whether it also confers robustness (or\nvulnerability) to perturbations of input data. We found that networks\nregularized to have lower levels of class selectivity were more robust to\naverage-case (naturalistic) perturbations, while networks with higher class\nselectivity are more vulnerable. In contrast, class selectivity increases\nrobustness to multiple types of worst-case (i.e. white box adversarial)\nperturbations, suggesting that while decreasing class selectivity is helpful\nfor average-case perturbations, it is harmful for worst-case perturbations. To\nexplain this difference, we studied the dimensionality of the networks'\nrepresentations: we found that the dimensionality of early-layer\nrepresentations is inversely proportional to a network's class selectivity, and\nthat adversarial samples cause a larger increase in early-layer dimensionality\nthan corrupted samples. Furthermore, the input-unit gradient is more variable\nacross samples and units in high-selectivity networks compared to\nlow-selectivity networks. These results lead to the conclusion that units\nparticipate more consistently in low-selectivity regimes compared to\nhigh-selectivity regimes, effectively creating a larger attack surface and\nhence vulnerability to worst-case perturbations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 00:45:29 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 22:49:58 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Leavitt", "Matthew L.", ""], ["Morcos", "Ari", ""]]}, {"id": "2010.07710", "submitter": "Mauro Vallati", "authors": "Mauro Vallati and Lukas Chrpa and Thomas L. McCluskey and Frank Hutter", "title": "On the Importance of Domain Model Configuration for Automated Planning\n  Engines", "comments": "Under consideration in Journal of Automated Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of domain-independent planners within the AI Planning\ncommunity is leading to \"off-the-shelf\" technology that can be used in a wide\nrange of applications. Moreover, it allows a modular approach --in which\nplanners and domain knowledge are modules of larger software applications--\nthat facilitates substitutions or improvements of individual modules without\nchanging the rest of the system. This approach also supports the use of\nreformulation and configuration techniques, which transform how a model is\nrepresented in order to improve the efficiency of plan generation.\n  In this article, we investigate how the performance of domain-independent\nplanners is affected by domain model configuration, i.e., the order in which\nelements are ordered in the model, particularly in the light of planner\ncomparisons. We then introduce techniques for the online and offline\nconfiguration of domain models, and we analyse the impact of domain model\nconfiguration on other reformulation approaches, such as macros.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 12:40:02 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Vallati", "Mauro", ""], ["Chrpa", "Lukas", ""], ["McCluskey", "Thomas L.", ""], ["Hutter", "Frank", ""]]}, {"id": "2010.07722", "submitter": "Pengfei Yang", "authors": "Pengfei Yang, Renjue Li, Jianlin Li, Cheng-Chao Huang, Jingyi Wang,\n  Jun Sun, Bai Xue, Lijun Zhang", "title": "Improving Neural Network Verification through Spurious Region Guided\n  Refinement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a spurious region guided refinement approach for robustness\nverification of deep neural networks. Our method starts with applying the\nDeepPoly abstract domain to analyze the network. If the robustness property\ncannot be verified, the result is inconclusive. Due to the over-approximation,\nthe computed region in the abstraction may be spurious in the sense that it\ndoes not contain any true counterexample. Our goal is to identify such spurious\nregions and use them to guide the abstraction refinement. The core idea is to\nmake use of the obtained constraints of the abstraction to infer new bounds for\nthe neurons. This is achieved by linear programming techniques. With the new\nbounds, we iteratively apply DeepPoly, aiming to eliminate spurious regions. We\nhave implemented our approach in a prototypical tool DeepSRGR. Experimental\nresults show that a large amount of regions can be identified as spurious, and\nas a result, the precision of DeepPoly can be significantly improved. As a side\ncontribution, we show that our approach can be applied to verify quantitative\nrobustness properties.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 13:03:15 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Yang", "Pengfei", ""], ["Li", "Renjue", ""], ["Li", "Jianlin", ""], ["Huang", "Cheng-Chao", ""], ["Wang", "Jingyi", ""], ["Sun", "Jun", ""], ["Xue", "Bai", ""], ["Zhang", "Lijun", ""]]}, {"id": "2010.07733", "submitter": "Junyi Zhu", "authors": "Junyi Zhu and Matthew Blaschko", "title": "R-GAP: Recursive Gradient Attack on Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning frameworks have been regarded as a promising approach to\nbreak the dilemma between demands on privacy and the promise of learning from\nlarge collections of distributed data. Many such frameworks only ask\ncollaborators to share their local update of a common model, i.e. gradients\nwith respect to locally stored data, instead of exposing their raw data to\nother collaborators. However, recent optimization-based gradient attacks show\nthat raw data can often be accurately recovered from gradients. It has been\nshown that minimizing the Euclidean distance between true gradients and those\ncalculated from estimated data is often effective in fully recovering private\ndata. However, there is a fundamental lack of theoretical understanding of how\nand when gradients can lead to unique recovery of original data. Our research\nfills this gap by providing a closed-form recursive procedure to recover data\nfrom gradients in deep neural networks. We name it Recursive Gradient Attack on\nPrivacy (R-GAP). Experimental results demonstrate that R-GAP works as well as\nor even better than optimization-based approaches at a fraction of the\ncomputation under certain conditions. Additionally, we propose a Rank Analysis\nmethod, which can be used to estimate the risk of gradient attacks inherent in\ncertain network architectures, regardless of whether an optimization-based or\nclosed-form-recursive attack is used. Experimental results demonstrate the\nutility of the rank analysis towards improving the network's security. Source\ncode is available for download from https://github.com/JunyiZhu-AI/R-GAP.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 13:22:40 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 14:10:53 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 11:16:25 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Zhu", "Junyi", ""], ["Blaschko", "Matthew", ""]]}, {"id": "2010.07734", "submitter": "Cheng Perng Phoo", "authors": "Cheng Perng Phoo, Bharath Hariharan", "title": "Self-training for Few-shot Transfer Across Extreme Task Differences", "comments": "Published as a conference paper at ICLR 2021(oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most few-shot learning techniques are pre-trained on a large, labeled \"base\ndataset\". In problem domains where such large labeled datasets are not\navailable for pre-training (e.g., X-ray, satellite images), one must resort to\npre-training in a different \"source\" problem domain (e.g., ImageNet), which can\nbe very different from the desired target task. Traditional few-shot and\ntransfer learning techniques fail in the presence of such extreme differences\nbetween the source and target tasks. In this paper, we present a simple and\neffective solution to tackle this extreme domain gap: self-training a source\ndomain representation on unlabeled data from the target domain. We show that\nthis improves one-shot performance on the target domain by 2.9 points on\naverage on the challenging BSCD-FSL benchmark consisting of datasets from\nmultiple domains. Our code is available at https://github.com/cpphoo/STARTUP.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 13:23:59 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 16:11:57 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Phoo", "Cheng Perng", ""], ["Hariharan", "Bharath", ""]]}, {"id": "2010.07738", "submitter": "Vinod Muthusamy", "authors": "Vinod Muthusamy, Merve Unuvar, Hagen V\\\"olzer, Justin D. Weisz", "title": "Do's and Don'ts for Human and Digital Worker Integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic process automation (RPA) and its next evolutionary stage, intelligent\nprocess automation, promise to drive improvements in efficiencies and process\noutcomes. However, how can business leaders evaluate how to integrate\nintelligent automation into business processes? What is an appropriate division\nof labor between humans and machines? How should combined human-AI teams be\nevaluated? For RPA, often the human labor cost and the robotic labor cost are\ndirectly compared to make an automation decision. In this position paper, we\nargue for a broader view that incorporates the potential for multiple levels of\nautonomy and human involvement, as well as a wider range of metrics beyond\nproductivity when integrating digital workers into a business process\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 13:30:23 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Muthusamy", "Vinod", ""], ["Unuvar", "Merve", ""], ["V\u00f6lzer", "Hagen", ""], ["Weisz", "Justin D.", ""]]}, {"id": "2010.07773", "submitter": "Shubhanker Banerjee", "authors": "Shubhanker Banerjee, Arun Jayapal and Sajeetha Thavareesan", "title": "NUIG-Shubhanker@Dravidian-CodeMix-FIRE2020: Sentiment Analysis of\n  Code-Mixed Dravidian text using XLNet", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Social media has penetrated into multilingual societies, however most of them\nuse English to be a preferred language for communication. So it looks natural\nfor them to mix their cultural language with English during conversations\nresulting in abundance of multilingual data, call this code-mixed data,\navailable in todays' world.Downstream NLP tasks using such data is challenging\ndue to the semantic nature of it being spread across multiple languages.One\nsuch Natural Language Processing task is sentiment analysis, for this we use an\nauto-regressive XLNet model to perform sentiment analysis on code-mixed\nTamil-English and Malayalam-English datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 14:09:02 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Banerjee", "Shubhanker", ""], ["Jayapal", "Arun", ""], ["Thavareesan", "Sajeetha", ""]]}, {"id": "2010.07785", "submitter": "Weishi Wang", "authors": "Weishi Wang, Shafiq Joty, Steven C.H. Hoi", "title": "Response Selection for Multi-Party Conversations with Dynamic Topic\n  Tracking", "comments": "9 pages, EMNLP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While participants in a multi-party multi-turn conversation simultaneously\nengage in multiple conversation topics, existing response selection methods are\ndeveloped mainly focusing on a two-party single-conversation scenario. Hence,\nthe prolongation and transition of conversation topics are ignored by current\nmethods. In this work, we frame response selection as a dynamic topic tracking\ntask to match the topic between the response and relevant conversation context.\nWith this new formulation, we propose a novel multi-task learning framework\nthat supports efficient encoding through large pretrained models with only two\nutterances at once to perform dynamic topic disentanglement and response\nselection. We also propose Topic-BERT an essential pretraining step to embed\ntopic information into BERT with self-supervised learning. Experimental results\non the DSTC-8 Ubuntu IRC dataset show state-of-the-art results in response\nselection and topic disentanglement tasks outperforming existing methods by a\ngood margin.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 14:21:38 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Wang", "Weishi", ""], ["Joty", "Shafiq", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "2010.07792", "submitter": "Yinuo Guo", "authors": "Yinuo Guo, Zeqi Lin, Jian-Guang Lou, Dongmei Zhang", "title": "Hierarchical Poset Decoding for Compositional Generalization in Language", "comments": "Accepted by Neurips 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize human language understanding as a structured prediction task\nwhere the output is a partially ordered set (poset). Current encoder-decoder\narchitectures do not take the poset structure of semantics into account\nproperly, thus suffering from poor compositional generalization ability. In\nthis paper, we propose a novel hierarchical poset decoding paradigm for\ncompositional generalization in language. Intuitively: (1) the proposed\nparadigm enforces partial permutation invariance in semantics, thus avoiding\noverfitting to bias ordering information; (2) the hierarchical mechanism allows\nto capture high-level structures of posets. We evaluate our proposed decoder on\nCompositional Freebase Questions (CFQ), a large and realistic natural language\nquestion answering dataset that is specifically designed to measure\ncompositional generalization. Results show that it outperforms current\ndecoders.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 14:34:26 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Guo", "Yinuo", ""], ["Lin", "Zeqi", ""], ["Lou", "Jian-Guang", ""], ["Zhang", "Dongmei", ""]]}, {"id": "2010.07805", "submitter": "Ziyao Xu", "authors": "Yang Deng, Ziyao Xu, Li Zhou, Huanping Liu, Anqi Huang", "title": "Research on AI Composition Recognition Based on Music Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of artificial intelligent composition has resulted in the\nincreasing popularity of machine-generated pieces, with frequent copyright\ndisputes consequently emerging. There is an insufficient amount of research on\nthe judgement of artificial and machine-generated works; the creation of a\nmethod to identify and distinguish these works is of particular importance.\nStarting from the essence of the music, the article constructs a\nmusic-rule-identifying algorithm through extracting modes, which will identify\nthe stability of the mode of machine-generated music, to judge whether it is\nartificial intelligent. The evaluation datasets used are provided by the\nConference on Sound and Music Technology(CSMT). Experimental results\ndemonstrate the algorithm to have a successful distinguishing ability between\ndatasets with different source distributions. The algorithm will also provide\nsome technological reference to the benign development of the music copyright\nand artificial intelligent music.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 14:51:24 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Deng", "Yang", ""], ["Xu", "Ziyao", ""], ["Zhou", "Li", ""], ["Liu", "Huanping", ""], ["Huang", "Anqi", ""]]}, {"id": "2010.07827", "submitter": "C\\'esar Soto-Valero", "authors": "Gustaf Halvardsson, Johanna Peterson, C\\'esar Soto-Valero, Benoit\n  Baudry", "title": "Interpretation of Swedish Sign Language using Convolutional Neural\n  Networks and Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic interpretation of sign languages is a challenging task, as it\nrequires the usage of high-level vision and high-level motion processing\nsystems for providing accurate image perception. In this paper, we use\nConvolutional Neural Networks (CNNs) and transfer learning in order to make\ncomputers able to interpret signs of the Swedish Sign Language (SSL) hand\nalphabet. Our model consist of the implementation of a pre-trained InceptionV3\nnetwork, and the usage of the mini-batch gradient descent optimization\nalgorithm. We rely on transfer learning during the pre-training of the model\nand its data. The final accuracy of the model, based on 8 study subjects and\n9,400 images, is 85%. Our results indicate that the usage of CNNs is a\npromising approach to interpret sign languages, and transfer learning can be\nused to achieve high testing accuracy despite using a small training dataset.\nFurthermore, we describe the implementation details of our model to interpret\nsigns as a user-friendly web application.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 15:34:09 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Halvardsson", "Gustaf", ""], ["Peterson", "Johanna", ""], ["Soto-Valero", "C\u00e9sar", ""], ["Baudry", "Benoit", ""]]}, {"id": "2010.07877", "submitter": "Victoria Krakovna", "authors": "Victoria Krakovna, Laurent Orseau, Richard Ngo, Miljan Martic, Shane\n  Legg", "title": "Avoiding Side Effects By Considering Future Tasks", "comments": "Published in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing reward functions is difficult: the designer has to specify what to\ndo (what it means to complete the task) as well as what not to do (side effects\nthat should be avoided while completing the task). To alleviate the burden on\nthe reward designer, we propose an algorithm to automatically generate an\nauxiliary reward function that penalizes side effects. This auxiliary objective\nrewards the ability to complete possible future tasks, which decreases if the\nagent causes side effects during the current task. The future task reward can\nalso give the agent an incentive to interfere with events in the environment\nthat make future tasks less achievable, such as irreversible actions by other\nagents. To avoid this interference incentive, we introduce a baseline policy\nthat represents a default course of action (such as doing nothing), and use it\nto filter out future tasks that are not achievable by default. We formally\ndefine interference incentives and show that the future task approach with a\nbaseline policy avoids these incentives in the deterministic case. Using\ngridworld environments that test for side effects and interference, we show\nthat our method avoids interference and is more effective for avoiding side\neffects than the common approach of penalizing irreversible actions.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 16:55:26 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Krakovna", "Victoria", ""], ["Orseau", "Laurent", ""], ["Ngo", "Richard", ""], ["Martic", "Miljan", ""], ["Legg", "Shane", ""]]}, {"id": "2010.07893", "submitter": "Stephen Chung", "authors": "Stephen Chung", "title": "An Alternative to Backpropagation in Deep Reinforcement Learning", "comments": "18 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art deep learning algorithms mostly rely on gradient\nbackpropagation to train a deep artificial neural network, which is generally\nregarded to be biologically implausible. For a network of stochastic units\ntrained on a reinforcement learning task or a supervised learning task, one\nbiologically plausible way of learning is to train each unit by REINFORCE. In\nthis case, only a global reward signal has to be broadcast to all units, and\nthe learning rule given is local, which can be interpreted as reward-modulated\nspike-timing-dependent plasticity (R-STDP) that is observed biologically.\nAlthough this learning rule follows the gradient of return in expectation, it\nsuffers from high variance and cannot be used to train a deep network in\npractice. In this paper, we propose an algorithm called MAP propagation that\ncan reduce this variance significantly while retaining the local property of\nlearning rule. Different from prior works on local learning rules (e.g.\nContrastive Divergence) which mostly applies to undirected models in\nunsupervised learning tasks, our proposed algorithm applies to directed models\nin reinforcement learning tasks. We show that the newly proposed algorithm can\nsolve common reinforcement learning tasks at a speed similar to that of\nbackpropagation when applied to an actor-critic network.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 17:17:39 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Chung", "Stephen", ""]]}, {"id": "2010.07915", "submitter": "Ayan Mukhopadhyay", "authors": "Tina Diao and Samriddhi Singla and Ayan Mukhopadhyay and Ahmed Eldawy\n  and Ross Shachter and Mykel Kochenderfer", "title": "Uncertainty Aware Wildfire Management", "comments": "Accepted at AI for Social Good Workshop, AAAI Fall Symposium Series\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent wildfires in the United States have resulted in loss of life and\nbillions of dollars, destroying countless structures and forests. Fighting\nwildfires is extremely complex. It is difficult to observe the true state of\nfires due to smoke and risk associated with ground surveillance. There are\nlimited resources to be deployed over a massive area and the spread of the fire\nis challenging to predict. This paper proposes a decision-theoretic approach to\ncombat wildfires. We model the resource allocation problem as a\npartially-observable Markov decision process. We also present a data-driven\nmodel that lets us simulate how fires spread as a function of relevant\ncovariates. A major problem in using data-driven models to combat wildfires is\nthe lack of comprehensive data sources that relate fires with relevant\ncovariates. We present an algorithmic approach based on large-scale raster and\nvector analysis that can be used to create such a dataset. Our data with over 2\nmillion data points is the first open-source dataset that combines existing\nfire databases with covariates extracted from satellite imagery. Through\nexperiments using real-world wildfire data, we demonstrate that our forecasting\nmodel can accurately model the spread of wildfires. Finally, we use simulations\nto demonstrate that our response strategy can significantly reduce response\ntimes compared to baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 17:47:31 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Diao", "Tina", ""], ["Singla", "Samriddhi", ""], ["Mukhopadhyay", "Ayan", ""], ["Eldawy", "Ahmed", ""], ["Shachter", "Ross", ""], ["Kochenderfer", "Mykel", ""]]}, {"id": "2010.07916", "submitter": "Hepeng Li", "authors": "Hepeng Li and Haibo He", "title": "Multi-Agent Trust Region Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend trust region policy optimization (TRPO) to multi-agent\nreinforcement learning (MARL) problems. We show that the policy update of TRPO\ncan be transformed into a distributed consensus optimization problem for\nmulti-agent cases. By making a series of approximations to the consensus\noptimization model, we propose a decentralized MARL algorithm, which we call\nmulti-agent TRPO (MATRPO). This algorithm can optimize distributed policies\nbased on local observations and private rewards. The agents do not need to know\nobservations, rewards, policies or value/action-value functions of other\nagents. The agents only share a likelihood ratio with their neighbors during\nthe training process. The algorithm is fully decentralized and\nprivacy-preserving. Our experiments on two cooperative games demonstrate its\nrobust performance on complicated MARL tasks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 17:49:47 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 14:41:40 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Li", "Hepeng", ""], ["He", "Haibo", ""]]}, {"id": "2010.07935", "submitter": "Kyongsik Yun", "authors": "Kyongsik Yun, Changrak Choi, Ryan Alimo, Anthony Davis, Linda Forster,\n  Amir Rahmani, Muhammad Adil, Ramtin Madani", "title": "Multi-Agent Motion Planning using Deep Learning for Space Applications", "comments": "2020 AIAA ASCEND", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art motion planners cannot scale to a large number of systems.\nMotion planning for multiple agents is an NP (non-deterministic\npolynomial-time) hard problem, so the computation time increases exponentially\nwith each addition of agents. This computational demand is a major stumbling\nblock to the motion planner's application to future NASA missions involving the\nswarm of space vehicles. We applied a deep neural network to transform\ncomputationally demanding mathematical motion planning problems into deep\nlearning-based numerical problems. We showed optimal motion trajectories can be\naccurately replicated using deep learning-based numerical models in several 2D\nand 3D systems with multiple agents. The deep learning-based numerical model\ndemonstrates superior computational efficiency with plans generated 1000 times\nfaster than the mathematical model counterpart.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 06:42:47 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Yun", "Kyongsik", ""], ["Choi", "Changrak", ""], ["Alimo", "Ryan", ""], ["Davis", "Anthony", ""], ["Forster", "Linda", ""], ["Rahmani", "Amir", ""], ["Adil", "Muhammad", ""], ["Madani", "Ramtin", ""]]}, {"id": "2010.07954", "submitter": "Alexander Ku", "authors": "Alexander Ku and Peter Anderson and Roma Patel and Eugene Ie and Jason\n  Baldridge", "title": "Room-Across-Room: Multilingual Vision-and-Language Navigation with Dense\n  Spatiotemporal Grounding", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Room-Across-Room (RxR), a new Vision-and-Language Navigation\n(VLN) dataset. RxR is multilingual (English, Hindi, and Telugu) and larger\n(more paths and instructions) than other VLN datasets. It emphasizes the role\nof language in VLN by addressing known biases in paths and eliciting more\nreferences to visible entities. Furthermore, each word in an instruction is\ntime-aligned to the virtual poses of instruction creators and validators. We\nestablish baseline scores for monolingual and multilingual settings and\nmultitask learning when including Room-to-Room annotations. We also provide\nresults for a model that learns from synchronized pose traces by focusing only\non portions of the panorama attended to in human demonstrations. The size,\nscope and detail of RxR dramatically expands the frontier for research on\nembodied language agents in simulated, photo-realistic environments.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 18:01:15 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Ku", "Alexander", ""], ["Anderson", "Peter", ""], ["Patel", "Roma", ""], ["Ie", "Eugene", ""], ["Baldridge", "Jason", ""]]}, {"id": "2010.07968", "submitter": "Zuxin Liu", "authors": "Zuxin Liu, Hongyi Zhou, Baiming Chen, Sicheng Zhong, Martial Hebert,\n  Ding Zhao", "title": "Constrained Model-based Reinforcement Learning with Robust Cross-Entropy\n  Method", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the constrained/safe reinforcement learning (RL) problem\nwith sparse indicator signals for constraint violations. We propose a\nmodel-based approach to enable RL agents to effectively explore the environment\nwith unknown system dynamics and environment constraints given a significantly\nsmall number of violation budgets. We employ the neural network ensemble model\nto estimate the prediction uncertainty and use model predictive control as the\nbasic control framework. We propose the robust cross-entropy method to optimize\nthe control sequence considering the model uncertainty and constraints. We\nevaluate our methods in the Safety Gym environment. The results show that our\napproach learns to complete the tasks with a much smaller number of constraint\nviolations than state-of-the-art baselines. Additionally, we are able to\nachieve several orders of magnitude better sample efficiency when compared with\nconstrained model-free RL approaches. The code is available at\n\\url{https://github.com/liuzuxin/safe-mbrl}.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 18:19:35 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2021 05:09:17 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Liu", "Zuxin", ""], ["Zhou", "Hongyi", ""], ["Chen", "Baiming", ""], ["Zhong", "Sicheng", ""], ["Hebert", "Martial", ""], ["Zhao", "Ding", ""]]}, {"id": "2010.07972", "submitter": "Junjie Hu", "authors": "Junjie Hu and Melvin Johnson and Orhan Firat and Aditya Siddhant and\n  Graham Neubig", "title": "Explicit Alignment Objectives for Multilingual Bidirectional Encoders", "comments": "published at NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained cross-lingual encoders such as mBERT (Devlin et al., 2019) and\nXLMR (Conneau et al., 2020) have proven to be impressively effective at\nenabling transfer-learning of NLP systems from high-resource languages to\nlow-resource languages. This success comes despite the fact that there is no\nexplicit objective to align the contextual embeddings of words/sentences with\nsimilar meanings across languages together in the same space. In this paper, we\npresent a new method for learning multilingual encoders, AMBER (Aligned\nMultilingual Bidirectional EncodeR). AMBER is trained on additional parallel\ndata using two explicit alignment objectives that align the multilingual\nrepresentations at different granularities. We conduct experiments on zero-shot\ncross-lingual transfer learning for different tasks including sequence tagging,\nsentence retrieval and sentence classification. Experimental results show that\nAMBER obtains gains of up to 1.1 average F1 score on sequence tagging and up to\n27.3 average accuracy on retrieval over the XLMR-large model which has 3.2x the\nparameters of AMBER. Our code and models are available at\nhttp://github.com/junjiehu/amber.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 18:34:13 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 01:57:42 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Hu", "Junjie", ""], ["Johnson", "Melvin", ""], ["Firat", "Orhan", ""], ["Siddhant", "Aditya", ""], ["Neubig", "Graham", ""]]}, {"id": "2010.07990", "submitter": "Adrian de Wynter", "authors": "Adrian de Wynter", "title": "An Algorithm for Learning Smaller Representations of Models With Scarce\n  Data", "comments": "Preprint. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a greedy algorithm for solving binary classification problems in\nsituations where the dataset is either too small or not fully representative of\nthe problem being solved, and obtaining more data is not possible. This\nalgorithm is of particular interest when training small models that have\ntrouble generalizing. It relies on a trained model with loose accuracy\nconstraints, an iterative hyperparameter pruning procedure, and a function used\nto generate new data. Analysis on correctness and runtime complexity under\nideal conditions and an extension to deep neural networks is provided. In the\nformer case we obtain an asymptotic bound of\n$O\\left(|\\Theta^2|\\left(\\log{|\\Theta|} + |\\theta^2| + T_f\\left(|\nD|\\right)\\right) + \\bar{S}|\\Theta||{E}|\\right)$, where $|{\\Theta}|$ is the\ncardinality of the set of hyperparameters $\\theta$ to be searched; $|{E}|$ and\n$|{D}|$ are the sizes of the evaluation and training datasets, respectively;\n$\\bar{S}$ and $\\bar{f}$ are the inference times for the trained model and the\ncandidate model; and $T_f({|{D}|})$ is a polynomial on $|{D}|$ and $\\bar{f}$.\nUnder these conditions, this algorithm returns a solution that is $1 \\leq r\n\\leq 2(1 - {2^{-|{\\Theta}|}})$ times better than simply enumerating and\ntraining with any $\\theta \\in \\Theta$. As part of our analysis of the\ngenerating function we also prove that, under certain assumptions, if an open\ncover of $D$ has the same homology as the manifold where the support of the\nunderlying probability distribution lies, then $D$ is learnable, and viceversa.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 19:17:51 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["de Wynter", "Adrian", ""]]}, {"id": "2010.07999", "submitter": "Jie Lei", "authors": "Jie Lei, Licheng Yu, Tamara L. Berg, Mohit Bansal", "title": "What is More Likely to Happen Next? Video-and-Language Future Event\n  Prediction", "comments": "EMNLP 2020 (17 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a video with aligned dialogue, people can often infer what is more\nlikely to happen next. Making such predictions requires not only a deep\nunderstanding of the rich dynamics underlying the video and dialogue, but also\na significant amount of commonsense knowledge. In this work, we explore whether\nAI models are able to learn to make such multimodal commonsense next-event\npredictions. To support research in this direction, we collect a new dataset,\nnamed Video-and-Language Event Prediction (VLEP), with 28,726 future event\nprediction examples (along with their rationales) from 10,234 diverse TV Show\nand YouTube Lifestyle Vlog video clips. In order to promote the collection of\nnon-trivial challenging examples, we employ an adversarial\nhuman-and-model-in-the-loop data collection procedure. We also present a strong\nbaseline incorporating information from video, dialogue, and commonsense\nknowledge. Experiments show that each type of information is useful for this\nchallenging task, and that compared to the high human performance on VLEP, our\nmodel provides a good starting point but leaves large room for future work. Our\ndataset and code are available at:\nhttps://github.com/jayleicn/VideoLanguageFuturePred\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 19:56:47 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Lei", "Jie", ""], ["Yu", "Licheng", ""], ["Berg", "Tamara L.", ""], ["Bansal", "Mohit", ""]]}, {"id": "2010.08034", "submitter": "Liyuan Liu", "authors": "Zichao Li and Liyuan Liu and Chengyu Dong and Jingbo Shang", "title": "Overfitting or Underfitting? Understand Robustness Drop in Adversarial\n  Training", "comments": "Work in Progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to understand why the robustness drops after conducting\nadversarial training for too long. Although this phenomenon is commonly\nexplained as overfitting, our analysis suggest that its primary cause is\nperturbation underfitting. We observe that after training for too long,\nFGSM-generated perturbations deteriorate into random noise. Intuitively, since\nno parameter updates are made to strengthen the perturbation generator, once\nthis process collapses, it could be trapped in such local optima. Also,\nsophisticating this process could mostly avoid the robustness drop, which\nsupports that this phenomenon is caused by underfitting instead of overfitting.\nIn the light of our analyses, we propose APART, an adaptive adversarial\ntraining framework, which parameterizes perturbation generation and\nprogressively strengthens them. Shielding perturbations from underfitting\nunleashes the potential of our framework. In our experiments, APART provides\ncomparable or even better robustness than PGD-10, with only about 1/4 of its\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 21:43:07 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Li", "Zichao", ""], ["Liu", "Liyuan", ""], ["Dong", "Chengyu", ""], ["Shang", "Jingbo", ""]]}, {"id": "2010.08052", "submitter": "Jieliang Luo", "authors": "Jieliang Luo and Hui Li", "title": "A Learning Approach to Robot-Agnostic Force-Guided High Precision\n  Assembly", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a learning approach to high-precision robotic\nassembly problems in the continuous action domain. Unlike many learning-based\napproaches that heavily rely on vision or spatial tracking, our approach takes\nforce/torque as the only observation. Each learned policy from our approach is\nrobot-agnostic, which can be applied to different robotic arms. These two\nfeatures can greatly reduce complexity and cost to perform robotic assembly in\nthe real world, especially in unstructured settings such as in architectural\nconstruction. To achieve it, we have developed a new distributed RL agent,\nnamed Recurrent Distributed DDPG (RD2), which extends Ape-X DDPG with\nrecurrency and makes two structural improvements on prioritized experience\nreplay. Our results show that RD2 is able to solve two fundamental\nhigh-precision assembly tasks, lap-joint and peg-in-hole, and outperforms two\nstate-of-the-art algorithms, Ape-X DDPG and PPO with LSTM. We have successfully\nevaluated our robot-agnostic policies on three robotic arms, Kuka KR60, Franka\nPanda, and UR10, in simulation. The video presenting our experiments is\navailable at https://sites.google.com/view/rd2-rl\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 22:33:43 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 23:53:45 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Luo", "Jieliang", ""], ["Li", "Hui", ""]]}, {"id": "2010.08056", "submitter": "Yudi Dong", "authors": "Yudi Dong and Yu-Dong Yao", "title": "IoT Platform for COVID-19 Prevention and Control: A Survey", "comments": "12 pages; Submitted to IEEE Internet of Things Journal", "journal-ref": "IEEE Access 2021", "doi": "10.1109/ACCESS.2021.3068276", "report-no": null, "categories": "cs.HC cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a result of the worldwide transmission of severe acute respiratory\nsyndrome coronavirus 2 (SARS-CoV-2), coronavirus disease 2019 (COVID-19) has\nevolved into an unprecedented pandemic. Currently, with unavailable\npharmaceutical treatments and vaccines, this novel coronavirus results in a\ngreat impact on public health, human society, and global economy, which is\nlikely to last for many years. One of the lessons learned from the COVID-19\npandemic is that a long-term system with non-pharmaceutical interventions for\npreventing and controlling new infectious diseases is desirable to be\nimplemented. Internet of things (IoT) platform is preferred to be utilized to\nachieve this goal, due to its ubiquitous sensing ability and seamless\nconnectivity. IoT technology is changing our lives through smart healthcare,\nsmart home, and smart city, which aims to build a more convenient and\nintelligent community. This paper presents how the IoT could be incorporated\ninto the epidemic prevention and control system. Specifically, we demonstrate a\npotential fog-cloud combined IoT platform that can be used in the systematic\nand intelligent COVID-19 prevention and control, which involves five\ninterventions including COVID-19 Symptom Diagnosis, Quarantine Monitoring,\nContact Tracing & Social Distancing, COVID-19 Outbreak Forecasting, and\nSARS-CoV-2 Mutation Tracking. We investigate and review the state-of-the-art\nliteratures of these five interventions to present the capabilities of IoT in\ncountering against the current COVID-19 pandemic or future infectious disease\nepidemics.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 22:43:03 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 18:04:14 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Dong", "Yudi", ""], ["Yao", "Yu-Dong", ""]]}, {"id": "2010.08065", "submitter": "Omar Mohamed Awad", "authors": "Omar Mohamed Awad, Mostafa Mahmoud, Isak Edo, Ali Hadi Zadeh, Ciaran\n  Bannon, Anand Jayarajan, Gennady Pekhimenko, Andreas Moshovos", "title": "FPRaker: A Processing Element For Accelerating Neural Network Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present FPRaker, a processing element for composing training accelerators.\nFPRaker processes several floating-point multiply-accumulation operations\nconcurrently and accumulates their result into a higher precision accumulator.\nFPRaker boosts performance and energy efficiency during training by taking\nadvantage of the values that naturally appear during training. Specifically, it\nprocesses the significand of the operands of each multiply-accumulate as a\nseries of signed powers of two. The conversion to this form is done on-the-fly.\nThis exposes ineffectual work that can be skipped: values when encoded have few\nterms and some of them can be discarded as they would fall outside the range of\nthe accumulator given the limited precision of floating-point. We demonstrate\nthat FPRaker can be used to compose an accelerator for training and that it can\nimprove performance and energy efficiency compared to using conventional\nfloating-point units under ISO-compute area constraints. We also demonstrate\nthat FPRaker delivers additional benefits when training incorporates pruning\nand quantization. Finally, we show that FPRaker naturally amplifies performance\nwith training methods that use a different precision per layer.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 23:24:10 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Awad", "Omar Mohamed", ""], ["Mahmoud", "Mostafa", ""], ["Edo", "Isak", ""], ["Zadeh", "Ali Hadi", ""], ["Bannon", "Ciaran", ""], ["Jayarajan", "Anand", ""], ["Pekhimenko", "Gennady", ""], ["Moshovos", "Andreas", ""]]}, {"id": "2010.08094", "submitter": "Navod Thilakarathne", "authors": "Navod Neranjan Thilakarathne, Mohan Krishna Kagita, Dr. Surekha Lanka,\n  Hussain Ahmad", "title": "Smart Grid: A Survey of Architectural Elements, Machine Learning and\n  Deep Learning Applications and Future Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Smart grid (SG), generally known as the next-generation power grid\nemerged as a replacement for ill-suited power systems in the 21st century. It\nis in-tegrated with advanced communication and computing capabilities, thus it\nis ex-pected to enhance the reliability and the efficiency of energy\ndistribution with minimum effects. With the massive infrastructure it holds and\nthe underlying communication network in the system, it introduced a large\nvolume of data that demands various techniques for proper analysis and decision\nmaking. Big data analytics, machine learning (ML), and deep learning (DL) plays\na key role when it comes to the analysis of this massive amount of data and\ngeneration of valuable insights. This paper explores and surveys the Smart grid\narchitectural elements, machine learning, and deep learning-based applications\nand approaches in the context of the Smart grid. In addition in terms of\nmachine learning-based data an-alytics, this paper highlights the limitations\nof the current research and highlights future directions as well.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 01:40:24 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Thilakarathne", "Navod Neranjan", ""], ["Kagita", "Mohan Krishna", ""], ["Lanka", "Dr. Surekha", ""], ["Ahmad", "Hussain", ""]]}, {"id": "2010.08101", "submitter": "Yilin Shen", "authors": "Yilin Shen, Wenhu Chen, Hongxia Jin", "title": "Modeling Token-level Uncertainty to Learn Unknown Concepts in SLU via\n  Calibrated Dirichlet Prior RNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One major task of spoken language understanding (SLU) in modern personal\nassistants is to extract semantic concepts from an utterance, called slot\nfilling. Although existing slot filling models attempted to improve extracting\nnew concepts that are not seen in training data, the performance in practice is\nstill not satisfied. Recent research collected question and answer annotated\ndata to learn what is unknown and should be asked, yet not practically scalable\ndue to the heavy data collection effort. In this paper, we incorporate\nsoftmax-based slot filling neural architectures to model the sequence\nuncertainty without question supervision. We design a Dirichlet Prior RNN to\nmodel high-order uncertainty by degenerating as softmax layer for RNN model\ntraining. To further enhance the uncertainty modeling robustness, we propose a\nnovel multi-task training to calibrate the Dirichlet concentration parameters.\nWe collect unseen concepts to create two test datasets from SLU benchmark\ndatasets Snips and ATIS. On these two and another existing Concept Learning\nbenchmark datasets, we show that our approach significantly outperforms\nstate-of-the-art approaches by up to 8.18%. Our method is generic and can be\napplied to any RNN or Transformer based slot filling models with a softmax\nlayer.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 02:12:30 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Shen", "Yilin", ""], ["Chen", "Wenhu", ""], ["Jin", "Hongxia", ""]]}, {"id": "2010.08114", "submitter": "Lingbing Guo", "authors": "Lingbing Guo, Weiqing Wang, Zequn Sun, Chenghao Liu, Wei Hu", "title": "Decentralized Knowledge Graph Representation Learning", "comments": "submitted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph (KG) representation learning methods have achieved\ncompetitive performance in many KG-oriented tasks, among which the best ones\nare usually based on graph neural networks (GNNs), a powerful family of\nnetworks that learns the representation of an entity by aggregating the\nfeatures of its neighbors and itself. However, many KG representation learning\nscenarios only provide the structure information that describes the\nrelationships among entities, causing that entities have no input features. In\nthis case, existing aggregation mechanisms are incapable of inducing embeddings\nof unseen entities as these entities have no pre-defined features for\naggregation. In this paper, we present a decentralized KG representation\nlearning approach, decentRL, which encodes each entity from and only from the\nembeddings of its neighbors. For optimization, we design an algorithm to\ndistill knowledge from the model itself such that the output embeddings can\ncontinuously gain knowledge from the corresponding original embeddings.\nExtensive experiments show that the proposed approach performed better than\nmany cutting-edge models on the entity alignment task, and achieved competitive\nperformance on the entity prediction task. Furthermore, under the inductive\nsetting, it significantly outperformed all baselines on both tasks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 02:31:22 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Guo", "Lingbing", ""], ["Wang", "Weiqing", ""], ["Sun", "Zequn", ""], ["Liu", "Chenghao", ""], ["Hu", "Wei", ""]]}, {"id": "2010.08119", "submitter": "Xinyu Huang", "authors": "Xinyu Huang, Lijun He, Xing Chen, Liejun Wang, Fan Li", "title": "Revenue and Energy Efficiency-Driven Delay Constrained Computing Task\n  Offloading and Resource Allocation in a Vehicular Edge Computing Network: A\n  Deep Reinforcement Learning Approach", "comments": "15 pages, 13 figures, submitted to IEEE Internet of Things", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For in-vehicle application,task type and vehicle state information, i.e.,\nvehicle speed, bear a significant impact on the task delay requirement.\nHowever, the joint impact of task type and vehicle speed on the task delay\nconstraint has not been studied, and this lack of study may cause a mismatch\nbetween the requirement of the task delay and allocated computation and\nwireless resources. In this paper, we propose a joint task type and vehicle\nspeed-aware task offloading and resource allocation strategy to decrease the\nvehicl's energy cost for executing tasks and increase the revenue of the\nvehicle for processing tasks within the delay constraint. First, we establish\nthe joint task type and vehicle speed-aware delay constraint model. Then, the\ndelay, energy cost and revenue for task execution in the vehicular edge\ncomputing (VEC) server, local terminal and terminals of other vehicles are\ncalculated. Based on the energy cost and revenue from task execution,the\nutility function of the vehicle is acquired. Next, we formulate a joint\noptimization of task offloading and resource allocation to maximize the utility\nlevel of the vehicles subject to the constraints of task delay, computation\nresources and wireless resources. To obtain a near-optimal solution of the\nformulated problem, a joint offloading and resource allocation based on the\nmulti-agent deep deterministic policy gradient (JORA-MADDPG) algorithm is\nproposed to maximize the utility level of vehicles. Simulation results show\nthat our algorithm can achieve superior performance in task completion delay,\nvehicles' energy cost and processing revenue.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 02:45:05 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Huang", "Xinyu", ""], ["He", "Lijun", ""], ["Chen", "Xing", ""], ["Wang", "Liejun", ""], ["Li", "Fan", ""]]}, {"id": "2010.08125", "submitter": "Mark Burgess", "authors": "Mark Burgess", "title": "Testing the Quantitative Spacetime Hypothesis using Artificial Narrative\n  Comprehension (II) : Establishing the Geometry of Invariant Concepts, Themes,\n  and Namespaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a pool of observations selected from a sensor stream, input data can be\nrobustly represented, via a multiscale process, in terms of invariant concepts,\nand themes. Applying this to episodic natural language data, one may obtain a\ngraph geometry associated with the decomposition, which is a direct encoding of\nspacetime relationships for the events. This study contributes to an ongoing\napplication of the Semantic Spacetime Hypothesis, and demonstrates the\nunsupervised analysis of narrative texts using inexpensive computational\nmethods without knowledge of linguistics. Data streams are parsed and\nfractionated into small constituents, by multiscale interferometry, in the\nmanner of bioinformatic analysis. Fragments may then be recombined to construct\noriginal sensory episodes---or form new narratives by a chemistry of\nassociation and pattern reconstruction, based only on the four fundamental\nspacetime relationships. There is a straightforward correspondence between\nbioinformatic processes and this cognitive representation of natural language.\nFeatures identifiable as `concepts' and `narrative themes' span three main\nscales (micro, meso, and macro). Fragments of the input act as symbols in a\nhierarchy of alphabets that define new effective languages at each scale.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 11:19:17 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Burgess", "Mark", ""]]}, {"id": "2010.08126", "submitter": "Mark Burgess", "authors": "Mark Burgess", "title": "Testing the Quantitative Spacetime Hypothesis using Artificial Narrative\n  Comprehension (I) : Bootstrapping Meaning from Episodic Narrative viewed as a\n  Feature Landscape", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of extracting important and meaningful parts of a sensory data\nstream, without prior training, is studied for symbolic sequences, by using\ntextual narrative as a test case. This is part of a larger study concerning the\nextraction of concepts from spacetime processes, and their knowledge\nrepresentations within hybrid symbolic-learning `Artificial Intelligence'. Most\napproaches to text analysis make extensive use of the evolved human sense of\nlanguage and semantics. In this work, streams are parsed without knowledge of\nsemantics, using only measurable patterns (size and time) within the changing\nstream of symbols -- as an event `landscape'. This is a form of interferometry.\nUsing lightweight procedures that can be run in just a few seconds on a single\nCPU, this work studies the validity of the Semantic Spacetime Hypothesis, for\nthe extraction of concepts as process invariants. This `semantic preprocessor'\nmay then act as a front-end for more sophisticated long-term graph-based\nlearning techniques. The results suggest that what we consider important and\ninteresting about sensory experience is not solely based on higher reasoning,\nbut on simple spacetime process cues, and this may be how cognitive processing\nis bootstrapped in the beginning.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 11:10:12 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Burgess", "Mark", ""]]}, {"id": "2010.08128", "submitter": "Jianfeng He", "authors": "Jianfeng He, Xuchao Zhang, Shuo Lei, Shuhui Wang, Qingming Huang,\n  Chang-Tien Lu, Bei Xiao", "title": "Semantic Editing On Segmentation Map Via Multi-Expansion Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic editing on segmentation map has been proposed as an intermediate\ninterface for image generation, because it provides flexible and strong\nassistance in various image generation tasks. This paper aims to improve\nquality of edited segmentation map conditioned on semantic inputs. Even though\nrecent studies apply global and local adversarial losses extensively to\ngenerate images for higher image quality, we find that they suffer from the\nmisalignment of the boundary area in the mask area. To address this, we propose\nMExGAN for semantic editing on segmentation map, which uses a novel\nMulti-Expansion (MEx) loss implemented by adversarial losses on MEx areas. Each\nMEx area has the mask area of the generation as the majority and the boundary\nof original context as the minority. To boost convenience and stability of MEx\nloss, we further propose an Approximated MEx (A-MEx) loss. Besides, in contrast\nto previous model that builds training data for semantic editing on\nsegmentation map with part of the whole image, which leads to model performance\ndegradation, MExGAN applies the whole image to build the training data.\nExtensive experiments on semantic editing on segmentation map and natural image\ninpainting show competitive results on four datasets.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 03:12:26 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["He", "Jianfeng", ""], ["Zhang", "Xuchao", ""], ["Lei", "Shuo", ""], ["Wang", "Shuhui", ""], ["Huang", "Qingming", ""], ["Lu", "Chang-Tien", ""], ["Xiao", "Bei", ""]]}, {"id": "2010.08140", "submitter": "Farhana Faruqe", "authors": "Farhana Faruqe, Ryan Watkins, and Larry Medsker", "title": "Monitoring Trust in Human-Machine Interactions for Public Sector\n  Applications", "comments": "Presented at AAAI FSS-20: Artificial Intelligence in Government and\n  Public Sector, Washington, DC, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The work reported here addresses the capacity of psychophysiological sensors\nand measures using Electroencephalogram (EEG) and Galvanic Skin Response (GSR)\nto detect levels of trust for humans using AI-supported Human-Machine\nInteraction (HMI). Improvements to the analysis of EEG and GSR data may create\nmodels that perform as well, or better than, traditional tools. A challenge to\nanalyzing the EEG and GSR data is the large amount of training data required\ndue to a large number of variables in the measurements. Researchers have\nroutinely used standard machine-learning classifiers like artificial neural\nnetworks (ANN), support vector machines (SVM), and K-nearest neighbors (KNN).\nTraditionally, these have provided few insights into which features of the EEG\nand GSR data facilitate the more and least accurate predictions - thus making\nit harder to improve the HMI and human-machine trust relationship. A key\ningredient to applying trust-sensor research results to practical situations\nand monitoring trust in work environments is the understanding of which key\nfeatures are contributing to trust and then reducing the amount of data needed\nfor practical applications. We used the Local Interpretable Model-agnostic\nExplanations (LIME) model as a process to reduce the volume of data required to\nmonitor and enhance trust in HMI systems - a technology that could be valuable\nfor governmental and public sector applications. Explainable AI can make HMI\nsystems transparent and promote trust. From customer service in government\nagencies and community-level non-profit public service organizations to\nnational military and cybersecurity institutions, many public sector\norganizations are increasingly concerned to have effective and ethical HMI with\nservices that are trustworthy, unbiased, and free of unintended negative\nconsequences.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 03:59:28 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Faruqe", "Farhana", ""], ["Watkins", "Ryan", ""], ["Medsker", "Larry", ""]]}, {"id": "2010.08141", "submitter": "Sunil Thulasidasan", "authors": "Xiaoying Pang, Sunil Thulasidasan, Larry Rybarcyk", "title": "Autonomous Control of a Particle Accelerator using Deep Reinforcement\n  Learning", "comments": "NeurIPS 2020 Workshop on Machine Learning for Engineering, Modeling,\n  Simulation and Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG physics.acc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an approach to learning optimal control policies for a large,\nlinear particle accelerator using deep reinforcement learning coupled with a\nhigh-fidelity physics engine. The framework consists of an AI controller that\nuses deep neural nets for state and action-space representation and learns\noptimal policies using reward signals that are provided by the physics\nsimulator. For this work, we only focus on controlling a small section of the\nentire accelerator. Nevertheless, initial results indicate that we can achieve\nbetter-than-human level performance in terms of particle beam current and\ndistribution. The ultimate goal of this line of work is to substantially reduce\nthe tuning time for such facilities by orders of magnitude, and achieve\nnear-autonomous control.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 04:02:01 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 00:42:39 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Pang", "Xiaoying", ""], ["Thulasidasan", "Sunil", ""], ["Rybarcyk", "Larry", ""]]}, {"id": "2010.08146", "submitter": "Wenbin Zhang", "authors": "Wenbin Zhang and Liang Zhao", "title": "Online Decision Trees with Fairness", "comments": "arXiv admin note: substantial text overlap with arXiv:1907.07237", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While artificial intelligence (AI)-based decision-making systems are\nincreasingly popular, significant concerns on the potential discrimination\nduring the AI decision-making process have been observed. For example, the\ndistribution of predictions is usually biased and dependents on the sensitive\nattributes (e.g., gender and ethnicity). Numerous approaches have therefore\nbeen proposed to develop decision-making systems that are\ndiscrimination-conscious by-design, which are typically batch-based and require\nthe simultaneous availability of all the training data for model learning.\nHowever, in the real-world, the data streams usually come on the fly which\nrequires the model to process each input data once \"on arrival\" and without the\nneed for storage and reprocessing. In addition, the data streams might also\nevolve over time, which further requires the model to be able to simultaneously\nadapt to non-stationary data distributions and time-evolving bias patterns,\nwith an effective and robust trade-off between accuracy and fairness. In this\npaper, we propose a novel framework of online decision tree with fairness in\nthe data stream with possible distribution drifting. Specifically, first, we\npropose two novel fairness splitting criteria that encode the data as well as\npossible, while simultaneously removing dependence on the sensitive attributes,\nand further adapts to non-stationary distribution with fine-grained control\nwhen needed. Second, we propose two fairness decision tree online growth\nalgorithms that fulfills different online fair decision-making requirements.\nOur experiments show that our algorithms are able to deal with discrimination\nin massive and non-stationary streaming environments, with a better trade-off\nbetween fairness and predictive performance.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 02:50:13 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Zhang", "Wenbin", ""], ["Zhao", "Liang", ""]]}, {"id": "2010.08158", "submitter": "Rakshitha Godahewa", "authors": "Rakshitha Godahewa, Christoph Bergmeir, Geoffrey I. Webb, Pablo\n  Montero-Manso", "title": "A Strong Baseline for Weekly Time Series Forecasting", "comments": "21 pages, 1 figure, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many businesses and industries require accurate forecasts for weekly time\nseries nowadays. The forecasting literature however does not currently provide\neasy-to-use, automatic, reproducible and accurate approaches dedicated to this\ntask. We propose a forecasting method that can be used as a strong baseline in\nthis domain, leveraging state-of-the-art forecasting techniques, forecast\ncombination, and global modelling. Our approach uses four base forecasting\nmodels specifically suitable for forecasting weekly data: a global Recurrent\nNeural Network model, Theta, Trigonometric Box-Cox ARMA Trend Seasonal (TBATS),\nand Dynamic Harmonic Regression ARIMA (DHR-ARIMA). Those are then optimally\ncombined using a lasso regression stacking approach. We evaluate the\nperformance of our method against a set of state-of-the-art weekly forecasting\nmodels on six datasets. Across four evaluation metrics, we show that our method\nconsistently outperforms the benchmark methods by a considerable margin with\nstatistical significance. In particular, our model can produce the most\naccurate forecasts, in terms of mean sMAPE, for the M4 weekly dataset.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 04:29:09 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Godahewa", "Rakshitha", ""], ["Bergmeir", "Christoph", ""], ["Webb", "Geoffrey I.", ""], ["Montero-Manso", "Pablo", ""]]}, {"id": "2010.08175", "submitter": "Xuanhong Chen", "authors": "Xuanhong Chen, Xirui Yan, Naiyuan Liu, Ting Qiu and Bingbing Ni", "title": "Anisotropic Stroke Control for Multiple Artists Style Transfer", "comments": "ACMMM2020", "journal-ref": "ACM Multimedia 2020", "doi": "10.1145/3394171.3413770", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Though significant progress has been made in artistic style transfer,\nsemantic information is usually difficult to be preserved in a fine-grained\nlocally consistent manner by most existing methods, especially when multiple\nartists styles are required to transfer within one single model. To circumvent\nthis issue, we propose a Stroke Control Multi-Artist Style Transfer framework.\nOn the one hand, we develop a multi-condition single-generator structure which\nfirst performs multi-artist style transfer. On the one hand, we design an\nAnisotropic Stroke Module (ASM) which realizes the dynamic adjustment of\nstyle-stroke between the non-trivial and the trivial regions. ASM endows the\nnetwork with the ability of adaptive semantic-consistency among various styles.\nOn the other hand, we present an novel Multi-Scale Projection Discriminator} to\nrealize the texture-level conditional generation. In contrast to the\nsingle-scale conditional discriminator, our discriminator is able to capture\nmulti-scale texture clue to effectively distinguish a wide range of artistic\nstyles. Extensive experimental results well demonstrate the feasibility and\neffectiveness of our approach. Our framework can transform a photograph into\ndifferent artistic style oil painting via only ONE single model. Furthermore,\nthe results are with distinctive artistic style and retain the anisotropic\nsemantic information. The code is already available on github:\nhttps://github.com/neuralchen/ASMAGAN.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 05:32:26 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 14:25:27 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Chen", "Xuanhong", ""], ["Yan", "Xirui", ""], ["Liu", "Naiyuan", ""], ["Qiu", "Ting", ""], ["Ni", "Bingbing", ""]]}, {"id": "2010.08178", "submitter": "Xuanfu Wu", "authors": "Xuanfu Wu, Yang Feng, Chenze Shao", "title": "Generating Diverse Translation from Model Distribution with Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the improvement of translation quality, neural machine translation\n(NMT) often suffers from the lack of diversity in its generation. In this\npaper, we propose to generate diverse translations by deriving a large number\nof possible models with Bayesian modelling and sampling models from them for\ninference. The possible models are obtained by applying concrete dropout to the\nNMT model and each of them has specific confidence for its prediction, which\ncorresponds to a posterior model distribution under specific training data in\nthe principle of Bayesian modeling. With variational inference, the posterior\nmodel distribution can be approximated with a variational distribution, from\nwhich the final models for inference are sampled. We conducted experiments on\nChinese-English and English-German translation tasks and the results shows that\nour method makes a better trade-off between diversity and accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 05:50:00 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Wu", "Xuanfu", ""], ["Feng", "Yang", ""], ["Shao", "Chenze", ""]]}, {"id": "2010.08185", "submitter": "Tanfang Chen", "authors": "Tanfang Chen, Weiwei Wang, Wenyang Wei, Xing Shi, Xiangang Li, Jieping\n  Ye, Kevin Knight", "title": "DiDi's Machine Translation System for WMT2020", "comments": "Accepted at WMT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes DiDi AI Labs' submission to the WMT2020 news translation\nshared task. We participate in the translation direction of Chinese->English.\nIn this direction, we use the Transformer as our baseline model, and integrate\nseveral techniques for model enhancement, including data filtering, data\nselection, back-translation, fine-tuning, model ensembling, and re-ranking. As\na result, our submission achieves a BLEU score of $36.6$ in Chinese->English.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 06:25:48 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Chen", "Tanfang", ""], ["Wang", "Weiwei", ""], ["Wei", "Wenyang", ""], ["Shi", "Xing", ""], ["Li", "Xiangang", ""], ["Ye", "Jieping", ""], ["Knight", "Kevin", ""]]}, {"id": "2010.08186", "submitter": "Saleh Shahinfar", "authors": "Saleh Shahinfar, Paul Meek, Greg Falzon", "title": "How many images do I need? Understanding how sample size per class\n  affects deep learning model performance metrics for balanced designs in\n  autonomous wildlife monitoring", "comments": null, "journal-ref": "Ecological Informatics, 2020, 57:101085", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) algorithms are the state of the art in automated\nclassification of wildlife camera trap images. The challenge is that the\necologist cannot know in advance how many images per species they need to\ncollect for model training in order to achieve their desired classification\naccuracy. In fact there is limited empirical evidence in the context of camera\ntrapping to demonstrate that increasing sample size will lead to improved\naccuracy. In this study we explore in depth the issues of deep learning model\nperformance for progressively increasing per class (species) sample sizes. We\nalso provide ecologists with an approximation formula to estimate how many\nimages per animal species they need for certain accuracy level a priori. This\nwill help ecologists for optimal allocation of resources, work and efficient\nstudy design. In order to investigate the effect of number of training images;\nseven training sets with 10, 20, 50, 150, 500, 1000 images per class were\ndesigned. Six deep learning architectures namely ResNet-18, ResNet-50,\nResNet-152, DnsNet-121, DnsNet-161, and DnsNet-201 were trained and tested on a\ncommon exclusive testing set of 250 images per class. The whole experiment was\nrepeated on three similar datasets from Australia, Africa and North America and\nthe results were compared. Simple regression equations for use by practitioners\nto approximate model performance metrics are provided. Generalized additive\nmodels (GAM) are shown to be effective in modelling DL performance metrics\nbased on the number of training images per class, tuning scheme and dataset.\n  Key-words: Camera Traps, Deep Learning, Ecological Informatics, Generalised\nAdditive Models, Learning Curves, Predictive Modelling, Wildlife.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 06:28:35 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Shahinfar", "Saleh", ""], ["Meek", "Paul", ""], ["Falzon", "Greg", ""]]}, {"id": "2010.08187", "submitter": "Guang-Neng Hu", "authors": "Guangneng Hu, Qiang Yang", "title": "PrivNet: Safeguarding Private Attributes in Transfer Learning for\n  Recommendation", "comments": "Findings of EMNLP 2020", "journal-ref": "Findings of ACL: EMNLP 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is an effective technique to improve a target recommender\nsystem with the knowledge from a source domain. Existing research focuses on\nthe recommendation performance of the target domain while ignores the privacy\nleakage of the source domain. The transferred knowledge, however, may\nunintendedly leak private information of the source domain. For example, an\nattacker can accurately infer user demographics from their historical purchase\nprovided by a source domain data owner. This paper addresses the above\nprivacy-preserving issue by learning a privacy-aware neural representation by\nimproving target performance while protecting source privacy. The key idea is\nto simulate the attacks during the training for protecting unseen users'\nprivacy in the future, modeled by an adversarial game, so that the transfer\nlearning model becomes robust to attacks. Experiments show that the proposed\nPrivNet model can successfully disentangle the knowledge benefitting the\ntransfer from leaking the privacy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 06:33:45 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Hu", "Guangneng", ""], ["Yang", "Qiang", ""]]}, {"id": "2010.08190", "submitter": "Yuang Shi", "authors": "Yuang Shi, Chen Zu, Mei Hong, Luping Zhou, Lei Wang, Xi Wu, Jiliu\n  Zhou, Daoqiang Zhang, Yan Wang", "title": "ASMFS: Adaptive-Similarity-based Multi-modality Feature Selection for\n  Classification of Alzheimer's Disease", "comments": "27 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing amounts of high-dimensional heterogeneous data to be\nprocessed, multi-modality feature selection has become an important research\ndirection in medical image analysis. Traditional methods usually depict the\ndata structure using fixed and predefined similarity matrix for each modality\nseparately, without considering the potential relationship structure across\ndifferent modalities. In this paper, we propose a novel multi-modality feature\nselection method, which performs feature selection and local similarity\nlearning simultaniously. Specially, a similarity matrix is learned by jointly\nconsidering different imaging modalities. And at the same time, feature\nselection is conducted by imposing sparse l_{2, 1} norm constraint. The\neffectiveness of our proposed joint learning method can be well demonstrated by\nthe experimental results on Alzheimer's Disease Neuroimaging Initiative (ADNI)\ndataset, which outperforms existing the state-of-the-art multi-modality\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 06:53:27 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Shi", "Yuang", ""], ["Zu", "Chen", ""], ["Hong", "Mei", ""], ["Zhou", "Luping", ""], ["Wang", "Lei", ""], ["Wu", "Xi", ""], ["Zhou", "Jiliu", ""], ["Zhang", "Daoqiang", ""], ["Wang", "Yan", ""]]}, {"id": "2010.08199", "submitter": "Chaitanya Manapragada", "authors": "Chaitanya Manapragada and Geoffrey I Webb and Mahsa Salehi and Albert\n  Bifet", "title": "Emergent and Unspecified Behaviors in Streaming Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hoeffding trees are the state-of-the-art methods in decision tree learning\nfor evolving data streams. These very fast decision trees are used in many real\napplications where data is created in real-time due to their efficiency. In\nthis work, we extricate explanations for why these streaming decision tree\nalgorithms for stationary and nonstationary streams (HoeffdingTree and\nHoeffdingAdaptiveTree) work as well as they do. In doing so, we identify\nthirteen unique unspecified design decisions in both the theoretical constructs\nand their implementations with substantial and consequential effects on\npredictive accuracy---design decisions that, without necessarily changing the\nessence of the algorithms, drive algorithm performance. We begin a larger\nconversation about explainability not just of the model but also of the\nprocesses responsible for an algorithm's success.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 07:02:30 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Manapragada", "Chaitanya", ""], ["Webb", "Geoffrey I", ""], ["Salehi", "Mahsa", ""], ["Bifet", "Albert", ""]]}, {"id": "2010.08200", "submitter": "Guangyu Zheng", "authors": "Wanyun Cui, Guangyu Zheng, Wei Wang", "title": "Unsupervised Natural Language Inference via Decoupled Multimodal\n  Contrastive Learning", "comments": "Published at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to solve the natural language inference problem without any\nsupervision from the inference labels via task-agnostic multimodal pretraining.\nAlthough recent studies of multimodal self-supervised learning also represent\nthe linguistic and visual context, their encoders for different modalities are\ncoupled. Thus they cannot incorporate visual information when encoding plain\ntext alone. In this paper, we propose Multimodal Aligned Contrastive Decoupled\nlearning (MACD) network. MACD forces the decoupled text encoder to represent\nthe visual information via contrastive learning. Therefore, it embeds visual\nknowledge even for plain text inference. We conducted comprehensive experiments\nover plain text inference datasets (i.e. SNLI and STS-B). The unsupervised MACD\neven outperforms the fully-supervised BiLSTM and BiLSTM+ELMO on STS-B.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 07:12:53 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Cui", "Wanyun", ""], ["Zheng", "Guangyu", ""], ["Wang", "Wei", ""]]}, {"id": "2010.08213", "submitter": "Yanghoon Kim", "authors": "Yanghoon Kim, Seungpil Won, Seunghyun Yoon and Kyomin Jung", "title": "Collaborative Training of GANs in Continuous and Discrete Spaces for\n  Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying generative adversarial networks (GANs) to text-related tasks is\nchallenging due to the discrete nature of language. One line of research\nresolves this issue by employing reinforcement learning (RL) and optimizing the\nnext-word sampling policy directly in a discrete action space. Such methods\ncompute the rewards from complete sentences and avoid error accumulation due to\nexposure bias. Other approaches employ approximation techniques that map the\ntext to continuous representation in order to circumvent the non-differentiable\ndiscrete process. Particularly, autoencoder-based methods effectively produce\nrobust representations that can model complex discrete structures. In this\npaper, we propose a novel text GAN architecture that promotes the collaborative\ntraining of the continuous-space and discrete-space methods. Our method employs\nan autoencoder to learn an implicit data manifold, providing a learning\nobjective for adversarial training in a continuous space. Furthermore, the\ncomplete textual output is directly evaluated and updated via RL in a discrete\nspace. The collaborative interplay between the two adversarial trainings\neffectively regularize the text representations in different spaces. The\nexperimental results on three standard benchmark datasets show that our model\nsubstantially outperforms state-of-the-art text GANs with respect to quality,\ndiversity, and global consistency.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 07:51:16 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 10:13:31 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Kim", "Yanghoon", ""], ["Won", "Seungpil", ""], ["Yoon", "Seunghyun", ""], ["Jung", "Kyomin", ""]]}, {"id": "2010.08218", "submitter": "Sunny Verma", "authors": "Sunny Verma, Jiwei Wang, Zhefeng Ge, Rujia Shen, Fan Jin, Yang Wang,\n  Fang Chen, and Wei Liu", "title": "Deep-HOSeq: Deep Higher Order Sequence Fusion for Multimodal Sentiment\n  Analysis", "comments": "Accepted at ICDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multimodal sentiment analysis utilizes multiple heterogeneous modalities for\nsentiment classification. The recent multimodal fusion schemes customize LSTMs\nto discover intra-modal dynamics and design sophisticated attention mechanisms\nto discover the inter-modal dynamics from multimodal sequences. Although\npowerful, these schemes completely rely on attention mechanisms which is\nproblematic due to two major drawbacks 1) deceptive attention masks, and 2)\ntraining dynamics. Nevertheless, strenuous efforts are required to optimize\nhyperparameters of these consolidate architectures, in particular their\ncustom-designed LSTMs constrained by attention schemes. In this research, we\nfirst propose a common network to discover both intra-modal and inter-modal\ndynamics by utilizing basic LSTMs and tensor based convolution networks. We\nthen propose unique networks to encapsulate temporal-granularity among the\nmodalities which is essential while extracting information within asynchronous\nsequences. We then integrate these two kinds of information via a fusion layer\nand call our novel multimodal fusion scheme as Deep-HOSeq (Deep network with\nhigher order Common and Unique Sequence information). The proposed Deep-HOSeq\nefficiently discovers all-important information from multimodal sequences and\nthe effectiveness of utilizing both types of information is empirically\ndemonstrated on CMU-MOSEI and CMU-MOSI benchmark datasets. The source code of\nour proposed Deep-HOSeq is and available at\nhttps://github.com/sverma88/Deep-HOSeq--ICDM-2020.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 08:02:11 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Verma", "Sunny", ""], ["Wang", "Jiwei", ""], ["Ge", "Zhefeng", ""], ["Shen", "Rujia", ""], ["Jin", "Fan", ""], ["Wang", "Yang", ""], ["Chen", "Fang", ""], ["Liu", "Wei", ""]]}, {"id": "2010.08234", "submitter": "Youngjin Park", "authors": "Youngjin Park, Deokjun Eom, Byoungki Seo, Jaesik Choi", "title": "Improved Predictive Deep Temporal Neural Networks with Trend Filtering", "comments": "8 pages, 4 figures, 3 tables, ICAIF 2020: ACM International\n  Conference on AI in Finance", "journal-ref": "ICAIF 2020: ACM International Conference on AI in Finance", "doi": "10.1145/3383455.3422565", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting with multivariate time series, which aims to predict future\nvalues given previous and current several univariate time series data, has been\nstudied for decades, with one example being ARIMA. Because it is difficult to\nmeasure the extent to which noise is mixed with informative signals within\nrapidly fluctuating financial time series data, designing a good predictive\nmodel is not a simple task. Recently, many researchers have become interested\nin recurrent neural networks and attention-based neural networks, applying them\nin financial forecasting. There have been many attempts to utilize these\nmethods for the capturing of long-term temporal dependencies and to select more\nimportant features in multivariate time series data in order to make accurate\npredictions. In this paper, we propose a new prediction framework based on deep\nneural networks and a trend filtering, which converts noisy time series data\ninto a piecewise linear fashion. We reveal that the predictive performance of\ndeep temporal neural networks improves when the training data is temporally\nprocessed by a trend filtering. To verify the effect of our framework, three\ndeep temporal neural networks, state of the art models for predictions in time\nseries finance data, are used and compared with models that contain trend\nfiltering as an input feature. Extensive experiments on real-world multivariate\ntime series data show that the proposed method is effective and significantly\nbetter than existing baseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 08:29:36 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Park", "Youngjin", ""], ["Eom", "Deokjun", ""], ["Seo", "Byoungki", ""], ["Choi", "Jaesik", ""]]}, {"id": "2010.08251", "submitter": "Andr\\'as Horv\\'ath", "authors": "Andras Horvath, Jalal Al-afandi", "title": "Filtered Batch Normalization", "comments": "Submitted to ICPR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a common assumption that the activation of different layers in neural\nnetworks follow Gaussian distribution. This distribution can be transformed\nusing normalization techniques, such as batch-normalization, increasing\nconvergence speed and improving accuracy. In this paper we would like to\ndemonstrate, that activations do not necessarily follow Gaussian distribution\nin all layers. Neurons in deeper layers are more selective and specific which\ncan result extremely large, out-of-distribution activations.\n  We will demonstrate that one can create more consistent mean and variance\nvalues for batch normalization during training by filtering out these\nactivations which can further improve convergence speed and yield higher\nvalidation accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 08:56:57 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Horvath", "Andras", ""], ["Al-afandi", "Jalal", ""]]}, {"id": "2010.08252", "submitter": "Jiancong Huang Jim", "authors": "Jiancong Huang, Juan Rojas, Matthieu Zimmer, Hongmin Wu, Yisheng Guan,\n  and Paul Weng", "title": "Hyperparameter Auto-tuning in Self-Supervised Robotic Learning", "comments": "8 pages, 6 figures, Published in IEEE Robotics and Automation\n  Letters; Presented at The 2021 International Conference on Robotics and\n  Automation (ICRA 2021); Presented at Deep RL Workshop, NeurIPS 2020", "journal-ref": "IEEE Robotics and Automation Letters, Volume:6, Issue:2, P.\n  3537-3544, April 2021", "doi": "10.1109/LRA.2021.3064509", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy optimization in reinforcement learning requires the selection of\nnumerous hyperparameters across different environments. Fixing them incorrectly\nmay negatively impact optimization performance leading notably to insufficient\nor redundant learning. Insufficient learning (due to convergence to local\noptima) results in under-performing policies whilst redundant learning wastes\ntime and resources. The effects are further exacerbated when using single\npolicies to solve multi-task learning problems. Observing that the Evidence\nLower Bound (ELBO) used in Variational Auto-Encoders correlates with the\ndiversity of image samples, we propose an auto-tuning technique based on the\nELBO for self-supervised reinforcement learning. Our approach can auto-tune\nthree hyperparameters: the replay buffer size, the number of policy gradient\nupdates during each epoch, and the number of exploration steps during each\nepoch. We use a state-of-the-art self-supervised robot learning framework\n(Reinforcement Learning with Imagined Goals (RIG) using Soft Actor-Critic) as\nbaseline for experimental verification. Experiments show that our method can\nauto-tune online and yields the best performance at a fraction of the time and\ncomputational resources. Code, video, and appendix for simulated and real-robot\nexperiments can be found at the project page \\url{www.JuanRojas.net/autotune}.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 08:58:24 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 06:43:06 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 14:18:56 GMT"}, {"version": "v4", "created": "Thu, 25 Mar 2021 03:30:59 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Huang", "Jiancong", ""], ["Rojas", "Juan", ""], ["Zimmer", "Matthieu", ""], ["Wu", "Hongmin", ""], ["Guan", "Yisheng", ""], ["Weng", "Paul", ""]]}, {"id": "2010.08262", "submitter": "Bernd Illing", "authors": "Bernd Illing, Jean Ventura, Guillaume Bellec, Wulfram Gerstner", "title": "Local plasticity rules can learn deep representations using\n  self-supervised contrastive predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in the brain is poorly understood and learning rules that respect\nbiological constraints, yet yield deep hierarchical representations, are still\nunknown. Here, we propose a learning rule that takes inspiration from\nneuroscience and recent advances in self-supervised deep learning. Learning\nminimizes a simple layer-specific loss function and does not need to\nback-propagate error signals within or between layers. Instead, weight updates\nfollow a local, Hebbian, learning rule that only depends on pre- and\npost-synaptic neuronal activity, predictive dendritic input and widely\nbroadcasted modulation factors which are identical for large groups of neurons.\nThe learning rule applies contrastive predictive learning to a causal,\nbiological setting using saccades (i.e. rapid shifts in gaze direction). We\nfind that networks trained with this self-supervised and local rule build deep\nhierarchical representations of images, speech and video.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 09:32:35 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 10:13:54 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2021 10:51:10 GMT"}, {"version": "v4", "created": "Wed, 16 Jun 2021 13:30:39 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Illing", "Bernd", ""], ["Ventura", "Jean", ""], ["Bellec", "Guillaume", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "2010.08269", "submitter": "Mark Berger", "authors": "Mark Berger, Jakub Zavrel, Paul Groth", "title": "Effective Distributed Representations for Academic Expert Search", "comments": "To be published in the Scholarly Document Processing 2020 Workshop @\n  EMNLP 2020 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expert search aims to find and rank experts based on a user's query. In\nacademia, retrieving experts is an efficient way to navigate through a large\namount of academic knowledge. Here, we study how different distributed\nrepresentations of academic papers (i.e. embeddings) impact academic expert\nretrieval. We use the Microsoft Academic Graph dataset and experiment with\ndifferent configurations of a document-centric voting model for retrieval. In\nparticular, we explore the impact of the use of contextualized embeddings on\nsearch performance. We also present results for paper embeddings that\nincorporate citation information through retrofitting. Additionally,\nexperiments are conducted using different techniques for assigning author\nweights based on author order. We observe that using contextual embeddings\nproduced by a transformer model trained for sentence similarity tasks produces\nthe most effective paper representations for document-centric expert retrieval.\nHowever, retrofitting the paper embeddings and using elaborate author\ncontribution weighting strategies did not improve retrieval performance.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 09:43:18 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Berger", "Mark", ""], ["Zavrel", "Jakub", ""], ["Groth", "Paul", ""]]}, {"id": "2010.08286", "submitter": "Pedro Casas Dr.", "authors": "Gast\\'on Garc\\'ia Gonz\\'alez, Pedro Casas, Alicia Fern\\'andez, and\n  Gabriel G\\'omez", "title": "On the Usage of Generative Models for Network Anomaly Detection in\n  Multivariate Time-Series", "comments": "To be published in ACM SIGMETRICS Performance Evaluation Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the many attempts and approaches for anomaly detection explored over\nthe years, the automatic detection of rare events in data communication\nnetworks remains a complex problem. In this paper we introduce Net-GAN, a novel\napproach to network anomaly detection in time-series, using recurrent neural\nnetworks (RNNs) and generative adversarial networks (GAN). Different from the\nstate of the art, which traditionally focuses on univariate measurements,\nNet-GAN detects anomalies in multivariate time-series, exploiting temporal\ndependencies through RNNs. Net-GAN discovers the underlying distribution of the\nbaseline, multivariate data, without making any assumptions on its nature,\noffering a powerful approach to detect anomalies in complex, difficult to model\nnetwork monitoring data. We further exploit the concepts behind generative\nmodels to conceive Net-VAE, a complementary approach to Net-GAN for network\nanomaly detection, based on variational auto-encoders (VAE). We evaluate\nNet-GAN and Net-VAE in different monitoring scenarios, including anomaly\ndetection in IoT sensor data, and intrusion detection in network measurements.\nGenerative models represent a promising approach for network anomaly detection,\nespecially when considering the complexity and ever-growing number of\ntime-series to monitor in operational networks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 10:22:25 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Gonz\u00e1lez", "Gast\u00f3n Garc\u00eda", ""], ["Casas", "Pedro", ""], ["Fern\u00e1ndez", "Alicia", ""], ["G\u00f3mez", "Gabriel", ""]]}, {"id": "2010.08300", "submitter": "Zhoujian Sun", "authors": "Zhoujian Sun, Wei Dong, Jinlong Shi and Zhengxing Huang", "title": "Interpretable Disease Prediction based on Reinforcement Path Reasoning\n  over Knowledge Graphs", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Objective: To combine medical knowledge and medical data to interpretably\npredict the risk of disease. Methods: We formulated the disease prediction task\nas a random walk along a knowledge graph (KG). Specifically, we build a KG to\nrecord relationships between diseases and risk factors according to validated\nmedical knowledge. Then, a mathematical object walks along the KG. It starts\nwalking at a patient entity, which connects the KG based on the patient current\ndiseases or risk factors and stops at a disease entity, which represents the\npredicted disease. The trajectory generated by the object represents an\ninterpretable disease progression path of the given patient. The dynamics of\nthe object are controlled by a policy-based reinforcement learning (RL) module,\nwhich is trained by electronic health records (EHRs). Experiments: We utilized\ntwo real-world EHR datasets to evaluate the performance of our model. In the\ndisease prediction task, our model achieves 0.743 and 0.639 in terms of macro\narea under the curve (AUC) in predicting 53 circulation system diseases in the\ntwo datasets, respectively. This performance is comparable to the commonly used\nmachine learning (ML) models in medical research. In qualitative analysis, our\nclinical collaborator reviewed the disease progression paths generated by our\nmodel and advocated their interpretability and reliability. Conclusion:\nExperimental results validate the proposed model in interpretably evaluating\nand optimizing disease prediction. Significance: Our work contributes to\nleveraging the potential of medical knowledge and medical data jointly for\ninterpretable prediction tasks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 10:46:28 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Sun", "Zhoujian", ""], ["Dong", "Wei", ""], ["Shi", "Jinlong", ""], ["Huang", "Zhengxing", ""]]}, {"id": "2010.08302", "submitter": "Xixi Lu", "authors": "Xixi Lu, Avigdor Gal, Hajo A. Reijers", "title": "Discovering Hierarchical Processes Using Flexible Activity Trees for\n  Event Abstraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processes, such as patient pathways, can be very complex, comprising of\nhundreds of activities and dozens of interleaved subprocesses. While existing\nprocess discovery algorithms have proven to construct models of high quality on\nclean logs of structured processes, it still remains a challenge when the\nalgorithms are being applied to logs of complex processes. The creation of a\nmulti-level, hierarchical representation of a process can help to manage this\ncomplexity. However, current approaches that pursue this idea suffer from a\nvariety of weaknesses. In particular, they do not deal well with interleaving\nsubprocesses. In this paper, we propose FlexHMiner, a three-step approach to\ndiscover processes with multi-level interleaved subprocesses. We implemented\nFlexHMiner in the open source Process Mining toolkit ProM. We used seven\nreal-life logs to compare the qualities of hierarchical models discovered using\ndomain knowledge, random clustering, and flat approaches. Our results indicate\nthat the hierarchical process models that the FlexHMiner generates compare\nfavorably to approaches that do not exploit hierarchy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 10:50:41 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Lu", "Xixi", ""], ["Gal", "Avigdor", ""], ["Reijers", "Hajo A.", ""]]}, {"id": "2010.08303", "submitter": "Boyi Liu", "authors": "Boyi Liu, Lujia Wang, Xinquan Chen, Lexiong Huang, Cheng-Zhong Xu", "title": "Peer-Assisted Robotic Learning: A Data-Driven Collaborative Learning\n  Approach for Cloud Robotic Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A technological revolution is occurring in the field of robotics with the\ndata-driven deep learning technology. However, building datasets for each local\nrobot is laborious. Meanwhile, data islands between local robots make data\nunable to be utilized collaboratively. To address this issue, the work presents\nPeer-Assisted Robotic Learning (PARL) in robotics, which is inspired by the\npeer-assisted learning in cognitive psychology and pedagogy. PARL implements\ndata collaboration with the framework of cloud robotic systems. Both data and\nmodels are shared by robots to the cloud after semantic computing and training\nlocally. The cloud converges the data and performs augmentation, integration,\nand transferring. Finally, fine tune this larger shared dataset in the cloud to\nlocal robots. Furthermore, we propose the DAT Network (Data Augmentation and\nTransferring Network) to implement the data processing in PARL. DAT Network can\nrealize the augmentation of data from multi-local robots. We conduct\nexperiments on a simplified self-driving task for robots (cars). DAT Network\nhas a significant improvement in the augmentation in self-driving scenarios.\nAlong with this, the self-driving experimental results also demonstrate that\nPARL is capable of improving learning effects with data collaboration of local\nrobots.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 10:52:54 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Liu", "Boyi", ""], ["Wang", "Lujia", ""], ["Chen", "Xinquan", ""], ["Huang", "Lexiong", ""], ["Xu", "Cheng-Zhong", ""]]}, {"id": "2010.08377", "submitter": "Robert Geirhos", "authors": "Robert Geirhos, Kantharaju Narayanappa, Benjamin Mitzkus, Matthias\n  Bethge, Felix A. Wichmann, Wieland Brendel", "title": "On the surprising similarities between supervised and self-supervised\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do humans learn to acquire a powerful, flexible and robust representation\nof objects? While much of this process remains unknown, it is clear that humans\ndo not require millions of object labels. Excitingly, recent algorithmic\nadvancements in self-supervised learning now enable convolutional neural\nnetworks (CNNs) to learn useful visual object representations without\nsupervised labels, too. In the light of this recent breakthrough, we here\ncompare self-supervised networks to supervised models and human behaviour. We\ntested models on 15 generalisation datasets for which large-scale human\nbehavioural data is available (130K highly controlled psychophysical trials).\nSurprisingly, current self-supervised CNNs share four key characteristics of\ntheir supervised counterparts: (1.) relatively poor noise robustness (with the\nnotable exception of SimCLR), (2.) non-human category-level error patterns,\n(3.) non-human image-level error patterns (yet high similarity to supervised\nmodel errors) and (4.) a bias towards texture. Taken together, these results\nsuggest that the strategies learned through today's supervised and\nself-supervised training objectives end up being surprisingly similar, but\ndistant from human-like behaviour. That being said, we are clearly just at the\nbeginning of what could be called a self-supervised revolution of machine\nvision, and we are hopeful that future self-supervised models behave\ndifferently from supervised ones, and---perhaps---more similar to robust human\nobject recognition.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 13:28:13 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Geirhos", "Robert", ""], ["Narayanappa", "Kantharaju", ""], ["Mitzkus", "Benjamin", ""], ["Bethge", "Matthias", ""], ["Wichmann", "Felix A.", ""], ["Brendel", "Wieland", ""]]}, {"id": "2010.08391", "submitter": "Zihui Zhang", "authors": "Cuican Yu, Zihui Zhang, Huibin Li", "title": "Reconstructing A Large Scale 3D Face Dataset for Deep 3D Face\n  Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods have brought many breakthroughs to computer vision,\nespecially in 2D face recognition. However, the bottleneck of deep learning\nbased 3D face recognition is that it is difficult to collect millions of 3D\nfaces, whether for industry or academia. In view of this situation, there are\nmany methods to generate more 3D faces from existing 3D faces through 3D face\ndata augmentation, which are used to train deep 3D face recognition models.\nHowever, to the best of our knowledge, there is no method to generate 3D faces\nfrom 2D face images for training deep 3D face recognition models. This letter\nfocuses on the role of reconstructed 3D facial surfaces in 3D face\nidentification and proposes a framework of 2D-aided deep 3D face\nidentification. In particular, we propose to reconstruct millions of 3D face\nscans from a large scale 2D face database (i.e.VGGFace2), using a deep learning\nbased 3D face reconstruction method (i.e.ExpNet). Then, we adopt a two-phase\ntraining approach: In the first phase, we use millions of face images to\npre-train the deep convolutional neural network (DCNN), and in the second\nphase, we use normal component images (NCI) of reconstructed 3D face scans to\ntrain the DCNN. Extensive experimental results illustrate that the proposed\napproach can greatly improve the rank-1 score of 3D face identification on the\nFRGC v2.0, the Bosphorus, and the BU-3DFE 3D face databases, compared to the\nmodel trained by 2D face images. Finally, our proposed approach achieves\nstate-of-the-art rank-1 scores on the FRGC v2.0 (97.6%), Bosphorus (98.4%), and\nBU-3DFE (98.8%) databases. The experimental results show that the reconstructed\n3D facial surfaces are useful and our 2D-aided deep 3D face identification\nframework is meaningful, facing the scarcity of 3D faces.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 13:48:38 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Yu", "Cuican", ""], ["Zhang", "Zihui", ""], ["Li", "Huibin", ""]]}, {"id": "2010.08473", "submitter": "Carlo Pinciroli", "authors": "Caleb Wagner, Neel Dhanaraj, Trevor Rizzo, Josue Contreras, Hannan\n  Liang, Gregory Lewin, Carlo Pinciroli", "title": "SMAC: Symbiotic Multi-Agent Construction", "comments": "8 pages, submitted to RAL-IROS2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel concept of a heterogeneous, distributed platform for\nautonomous 3D construction. The platform is composed of two types of robots\nacting in a coordinated and complementary fashion: (i) A collection of\ncommunicating smart construction blocks behaving as a form of growable smart\nmatter, and capable of planning and monitoring their own state and the\nconstruction progress; and (ii) A team of inchworm-shaped builder robots\ndesigned to navigate and modify the 3D structure, following the guidance of the\nsmart blocks. We describe the design of the hardware and introduce algorithms\nfor navigation and construction that support a wide class of 3D structures. We\ndemonstrate the capabilities of our concept and characterize its performance\nthrough simulations and real-robot experiments.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 16:19:02 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Wagner", "Caleb", ""], ["Dhanaraj", "Neel", ""], ["Rizzo", "Trevor", ""], ["Contreras", "Josue", ""], ["Liang", "Hannan", ""], ["Lewin", "Gregory", ""], ["Pinciroli", "Carlo", ""]]}, {"id": "2010.08497", "submitter": "Eric Benhamou", "authors": "Eric Benhamou and David Saltiel and Sandrine Ungari and Abhishek\n  Mukhopadhyay and Jamal Atif", "title": "AAMDRL: Augmented Asset Management with Deep Reinforcement Learning", "comments": "9 pages, 7 figures. arXiv admin note: substantial text overlap with\n  arXiv:2009.14136", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can an agent learn efficiently in a noisy and self adapting environment with\nsequential, non-stationary and non-homogeneous observations? Through trading\nbots, we illustrate how Deep Reinforcement Learning (DRL) can tackle this\nchallenge. Our contributions are threefold: (i) the use of contextual\ninformation also referred to as augmented state in DRL, (ii) the impact of a\none period lag between observations and actions that is more realistic for an\nasset management environment, (iii) the implementation of a new repetitive\ntrain test method called walk forward analysis, similar in spirit to cross\nvalidation for time series. Although our experiment is on trading bots, it can\neasily be translated to other bot environments that operate in sequential\nenvironment with regime changes and noisy data. Our experiment for an augmented\nasset manager interested in finding the best portfolio for hedging strategies\nshows that AAMDRL achieves superior returns and lower risk.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 03:55:47 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Benhamou", "Eric", ""], ["Saltiel", "David", ""], ["Ungari", "Sandrine", ""], ["Mukhopadhyay", "Abhishek", ""], ["Atif", "Jamal", ""]]}, {"id": "2010.08513", "submitter": "Shihua Zhang", "authors": "Penglong Zhai and Shihua Zhang", "title": "Learnable Graph-regularization for Matrix Decomposition", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank approximation models of data matrices have become important machine\nlearning and data mining tools in many fields including computer vision, text\nmining, bioinformatics and many others. They allow for embedding\nhigh-dimensional data into low-dimensional spaces, which mitigates the effects\nof noise and uncovers latent relations. In order to make the learned\nrepresentations inherit the structures in the original data,\ngraph-regularization terms are often added to the loss function. However, the\nprior graph construction often fails to reflect the true network connectivity\nand the intrinsic relationships. In addition, many graph-regularized methods\nfail to take the dual spaces into account. Probabilistic models are often used\nto model the distribution of the representations, but most of previous methods\noften assume that the hidden variables are independent and identically\ndistributed for simplicity. To this end, we propose a learnable\ngraph-regularization model for matrix decomposition (LGMD), which builds a\nbridge between graph-regularized methods and probabilistic matrix decomposition\nmodels. LGMD learns two graphical structures (i.e., two precision matrices) in\nreal-time in an iterative manner via sparse precision matrix estimation and is\nmore robust to noise and missing entries. Extensive numerical results and\ncomparison with competing methods demonstrate its effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 17:12:39 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Zhai", "Penglong", ""], ["Zhang", "Shihua", ""]]}, {"id": "2010.08525", "submitter": "Hongming Zhang", "authors": "Hongming Zhang, Muhao Chen, Haoyu Wang, Yangqiu Song, Dan Roth", "title": "Analogous Process Structure Induction for Sub-event Sequence Prediction", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational and cognitive studies of event understanding suggest that\nidentifying, comprehending, and predicting events depend on having structured\nrepresentations of a sequence of events and on conceptualizing (abstracting)\nits components into (soft) event categories. Thus, knowledge about a known\nprocess such as \"buying a car\" can be used in the context of a new but\nanalogous process such as \"buying a house\". Nevertheless, most event\nunderstanding work in NLP is still at the ground level and does not consider\nabstraction. In this paper, we propose an Analogous Process Structure Induction\nAPSI framework, which leverages analogies among processes and conceptualization\nof sub-event instances to predict the whole sub-event sequence of previously\nunseen open-domain processes. As our experiments and analysis indicate, APSI\nsupports the generation of meaningful sub-event sequences for unseen processes\nand can help predict missing events.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 17:35:40 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Zhang", "Hongming", ""], ["Chen", "Muhao", ""], ["Wang", "Haoyu", ""], ["Song", "Yangqiu", ""], ["Roth", "Dan", ""]]}, {"id": "2010.08531", "submitter": "Tianjun Zhang", "authors": "Tianjun Zhang, Huazhe Xu, Xiaolong Wang, Yi Wu, Kurt Keutzer, Joseph\n  E. Gonzalez, Yuandong Tian", "title": "Multi-Agent Collaboration via Reward Attribution Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in multi-agent reinforcement learning (MARL) have achieved\nsuper-human performance in games like Quake 3 and Dota 2. Unfortunately, these\ntechniques require orders-of-magnitude more training rounds than humans and\ndon't generalize to new agent configurations even on the same game. In this\nwork, we propose Collaborative Q-learning (CollaQ) that achieves\nstate-of-the-art performance in the StarCraft multi-agent challenge and\nsupports ad hoc team play. We first formulate multi-agent collaboration as a\njoint optimization on reward assignment and show that each agent has an\napproximately optimal policy that decomposes into two parts: one part that only\nrelies on the agent's own state, and the other part that is related to states\nof nearby agents. Following this novel finding, CollaQ decomposes the\nQ-function of each agent into a self term and an interactive term, with a\nMulti-Agent Reward Attribution (MARA) loss that regularizes the training.\nCollaQ is evaluated on various StarCraft maps and shows that it outperforms\nexisting state-of-the-art techniques (i.e., QMIX, QTRAN, and VDN) by improving\nthe win rate by 40% with the same number of samples. In the more challenging ad\nhoc team play setting (i.e., reweight/add/remove units without re-training or\nfinetuning), CollaQ outperforms previous SoTA by over 30%.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 17:42:11 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Zhang", "Tianjun", ""], ["Xu", "Huazhe", ""], ["Wang", "Xiaolong", ""], ["Wu", "Yi", ""], ["Keutzer", "Kurt", ""], ["Gonzalez", "Joseph E.", ""], ["Tian", "Yuandong", ""]]}, {"id": "2010.08532", "submitter": "Xingjian Li", "authors": "Xingjian Li, Di Hu, Xuhong Li, Haoyi Xiong, Zhi Ye, Zhipeng Wang,\n  Chengzhong Xu, Dejing Dou", "title": "Towards Accurate Knowledge Transfer via Target-awareness Representation\n  Disentanglement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning deep neural networks pre-trained on large scale datasets is one\nof the most practical transfer learning paradigm given limited quantity of\ntraining samples. To obtain better generalization, using the starting point as\nthe reference, either through weights or features, has been successfully\napplied to transfer learning as a regularizer. However, due to the domain\ndiscrepancy between the source and target tasks, there exists obvious risk of\nnegative transfer. In this paper, we propose a novel transfer learning\nalgorithm, introducing the idea of Target-awareness REpresentation\nDisentanglement (TRED), where the relevant knowledge with respect to the target\ntask is disentangled from the original source model and used as a regularizer\nduring fine-tuning the target model. Experiments on various real world datasets\nshow that our method stably improves the standard fine-tuning by more than 2%\nin average. TRED also outperforms other state-of-the-art transfer learning\nregularizers such as L2-SP, AT, DELTA and BSS.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 17:45:08 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Li", "Xingjian", ""], ["Hu", "Di", ""], ["Li", "Xuhong", ""], ["Xiong", "Haoyi", ""], ["Ye", "Zhi", ""], ["Wang", "Zhipeng", ""], ["Xu", "Chengzhong", ""], ["Dou", "Dejing", ""]]}, {"id": "2010.08534", "submitter": "Andrew Keyes", "authors": "Andrew Keyes, Nicky Bayat, Vahid Reza Khazaie, Yalda Mohsenzadeh", "title": "Latent Vector Recovery of Audio GANs", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced Generative Adversarial Networks (GANs) are remarkable in generating\nintelligible audio from a random latent vector. In this paper, we examine the\ntask of recovering the latent vector of both synthesized and real audio.\nPrevious works recovered latent vectors of given audio through an auto-encoder\ninspired technique that trains an encoder network either in parallel with the\nGAN or after the generator is trained. With our approach, we train a deep\nresidual neural network architecture to project audio synthesized by WaveGAN\ninto the corresponding latent space with near identical reconstruction\nperformance. To accommodate for the lack of an original latent vector for real\naudio, we optimize the residual network on the perceptual loss between the real\naudio samples and the reconstructed audio of the predicted latent vectors. In\nthe case of synthesized audio, the Mean Squared Error (MSE) between the ground\ntruth and recovered latent vector is minimized as well. We further investigated\nthe audio reconstruction performance when several gradient optimization steps\nare applied to the predicted latent vector. Through our deep neural network\nbased method of training on real and synthesized audio, we are able to predict\na latent vector that corresponds to a reasonable reconstruction of real audio.\nEven though we evaluated our method on WaveGAN, our proposed method is\nuniversal and can be applied to any other GANs.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 17:45:35 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Keyes", "Andrew", ""], ["Bayat", "Nicky", ""], ["Khazaie", "Vahid Reza", ""], ["Mohsenzadeh", "Yalda", ""]]}, {"id": "2010.08546", "submitter": "Ferhat Ozgur Catak", "authors": "erhat Ozgur Catak and Samed Sivaslioglu and Kevser Sahinbas", "title": "A Generative Model based Adversarial Security of Deep Learning and\n  Linear Classifier Models", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning algorithms have been applied widely in\nvarious fields such as health, transportation, and the autonomous car. With the\nrapid developments of deep learning techniques, it is critical to take the\nsecurity concern into account for the application of the algorithms. While\nmachine learning offers significant advantages in terms of the application of\nalgorithms, the issue of security is ignored. Since it has many applications in\nthe real world, security is a vital part of the algorithms. In this paper, we\nhave proposed a mitigation method for adversarial attacks against machine\nlearning models with an autoencoder model that is one of the generative ones.\nThe main idea behind adversarial attacks against machine learning models is to\nproduce erroneous results by manipulating trained models. We have also\npresented the performance of autoencoder models to various attack methods from\ndeep neural networks to traditional algorithms by using different methods such\nas non-targeted and targeted attacks to multi-class logistic regression, a fast\ngradient sign method, a targeted fast gradient sign method and a basic\niterative method attack to neural networks for the MNIST dataset.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 17:18:17 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Catak", "erhat Ozgur", ""], ["Sivaslioglu", "Samed", ""], ["Sahinbas", "Kevser", ""]]}, {"id": "2010.08547", "submitter": "Jingwei Ma", "authors": "Jingwei Ma and Jiahui Wen and Panpan Zhang and Guangda Zhang and Xue\n  Li", "title": "A Unified Model for Recommendation with Selective Neighborhood Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neighborhood-based recommenders are a major class of Collaborative Filtering\n(CF) models. The intuition is to exploit neighbors with similar preferences for\nbridging unseen user-item pairs and alleviating data sparseness. Many existing\nworks propose neural attention networks to aggregate neighbors and place higher\nweights on specific subsets of users for recommendation. However, the\nneighborhood information is not necessarily always informative, and the noises\nin the neighborhood can negatively affect the model performance. To address\nthis issue, we propose a novel neighborhood-based recommender, where a hybrid\ngated network is designed to automatically separate similar neighbors from\ndissimilar (noisy) ones, and aggregate those similar neighbors to comprise\nneighborhood representations. The confidence in the neighborhood is also\naddressed by putting higher weights on the neighborhood representations if we\nare confident with the neighborhood information, and vice versa. In addition, a\nuser-neighbor component is proposed to explicitly regularize user-neighbor\nproximity in the latent space. These two components are combined into a unified\nmodel to complement each other for the recommendation task. Extensive\nexperiments on three publicly available datasets show that the proposed model\nconsistently outperforms state-of-the-art neighborhood-based recommenders. We\nalso study different variants of the proposed model to justify the underlying\nintuition of the proposed hybrid gated network and user-neighbor modeling\ncomponents.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 08:06:16 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ma", "Jingwei", ""], ["Wen", "Jiahui", ""], ["Zhang", "Panpan", ""], ["Zhang", "Guangda", ""], ["Li", "Xue", ""]]}, {"id": "2010.08587", "submitter": "Rae Jeong", "authors": "Rae Jeong, Jost Tobias Springenberg, Jackie Kay, Daniel Zheng, Yuxiang\n  Zhou, Alexandre Galashov, Nicolas Heess, Francesco Nori", "title": "Learning Dexterous Manipulation from Suboptimal Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning dexterous manipulation in high-dimensional state-action spaces is an\nimportant open challenge with exploration presenting a major bottleneck.\nAlthough in many cases the learning process could be guided by demonstrations\nor other suboptimal experts, current RL algorithms for continuous action spaces\noften fail to effectively utilize combinations of highly off-policy expert data\nand on-policy exploration data. As a solution, we introduce Relative Entropy\nQ-Learning (REQ), a simple policy iteration algorithm that combines ideas from\nsuccessful offline and conventional RL algorithms. It represents the optimal\npolicy via importance sampling from a learned prior and is well-suited to take\nadvantage of mixed data distributions. We demonstrate experimentally that REQ\noutperforms several strong baselines on robotic manipulation tasks for which\nsuboptimal experts are available. We show how suboptimal experts can be\nconstructed effectively by composing simple waypoint tracking controllers, and\nwe also show how learned primitives can be combined with waypoint controllers\nto obtain reference behaviors to bootstrap a complex manipulation task on a\nsimulated bimanual robot with human-like hands. Finally, we show that REQ is\nalso effective for general off-policy RL, offline RL, and RL from\ndemonstrations. Videos and further materials are available at\nsites.google.com/view/rlfse.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 18:48:49 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 17:22:00 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Jeong", "Rae", ""], ["Springenberg", "Jost Tobias", ""], ["Kay", "Jackie", ""], ["Zheng", "Daniel", ""], ["Zhou", "Yuxiang", ""], ["Galashov", "Alexandre", ""], ["Heess", "Nicolas", ""], ["Nori", "Francesco", ""]]}, {"id": "2010.08591", "submitter": "Sumit Kumar", "authors": "Smita Pallavi, Raj Ratn Pranesh, Sumit Kumar", "title": "A Conglomerate of Multiple OCR Table Detection and Extraction", "comments": "For ICDAR proceedings, see https://panel.waset.org/abstracts/127575", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information representation as tables are compact and concise method that\neases searching, indexing, and storage requirements. Extracting and cloning\ntables from parsable documents is easier and widely used, however industry\nstill faces challenge in detecting and extracting tables from OCR documents or\nimages. This paper proposes an algorithm that detects and extracts multiple\ntables from OCR document. The algorithm uses a combination of image processing\ntechniques, text recognition and procedural coding to identify distinct tables\nin same image and map the text to appropriate corresponding cell in dataframe\nwhich can be stored as Comma-separated values, Database, Excel and multiple\nother usable formats.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 18:56:25 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Pallavi", "Smita", ""], ["Pranesh", "Raj Ratn", ""], ["Kumar", "Sumit", ""]]}, {"id": "2010.08596", "submitter": "Xin Ye", "authors": "Xin Ye and Yezhou Yang", "title": "Efficient Robotic Object Search via HIEM: Hierarchical Policy Learning\n  with Intrinsic-Extrinsic Modeling", "comments": "RA-L & ICRA21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the significant success at enabling robots with autonomous behaviors\nmakes deep reinforcement learning a promising approach for robotic object\nsearch task, the deep reinforcement learning approach severely suffers from the\nnature sparse reward setting of the task. To tackle this challenge, we present\na novel policy learning paradigm for the object search task, based on\nhierarchical and interpretable modeling with an intrinsic-extrinsic reward\nsetting. More specifically, we explore the environment efficiently through a\nproxy low-level policy which is driven by the intrinsic rewarding sub-goals. We\nfurther learn our hierarchical policy from the efficient exploration experience\nwhere we optimize both of our high-level and low-level policies towards the\nextrinsic rewarding goal to perform the object search task well. Experiments\nconducted on the House3D environment validate and show that the robot, trained\nwith our model, can perform the object search task in a more optimal and\ninterpretable way.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 19:21:38 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 19:45:02 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Ye", "Xin", ""], ["Yang", "Yezhou", ""]]}, {"id": "2010.08600", "submitter": "Claudia P\\'erez-D'Arpino", "authors": "Claudia P\\'erez-D'Arpino, Can Liu, Patrick Goebel, Roberto\n  Mart\\'in-Mart\\'in, Silvio Savarese", "title": "Robot Navigation in Constrained Pedestrian Environments using\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Navigating fluently around pedestrians is a necessary capability for mobile\nrobots deployed in human environments, such as buildings and homes. While\nresearch on social navigation has focused mainly on the scalability with the\nnumber of pedestrians in open spaces, typical indoor environments present the\nadditional challenge of constrained spaces such as corridors and doorways that\nlimit maneuverability and influence patterns of pedestrian interaction. We\npresent an approach based on reinforcement learning (RL) to learn policies\ncapable of dynamic adaptation to the presence of moving pedestrians while\nnavigating between desired locations in constrained environments. The policy\nnetwork receives guidance from a motion planner that provides waypoints to\nfollow a globally planned trajectory, whereas RL handles the local\ninteractions. We explore a compositional principle for multi-layout training\nand find that policies trained in a small set of geometrically simple layouts\nsuccessfully generalize to more complex unseen layouts that exhibit composition\nof the structural elements available during training. Going beyond walls-world\nlike domains, we show transfer of the learned policy to unseen 3D\nreconstructions of two real environments. These results support the\napplicability of the compositional principle to navigation in real-world\nbuildings and indicate promising usage of multi-agent simulation within\nreconstructed environments for tasks that involve interaction.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 19:40:08 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 06:26:16 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["P\u00e9rez-D'Arpino", "Claudia", ""], ["Liu", "Can", ""], ["Goebel", "Patrick", ""], ["Mart\u00edn-Mart\u00edn", "Roberto", ""], ["Savarese", "Silvio", ""]]}, {"id": "2010.08607", "submitter": "Mohit Sewak", "authors": "Mohit Sewak, Sanjay K. Sahay and Hemant Rathore", "title": "DeepIntent: ImplicitIntent based Android IDS with E2E Deep Learning\n  architecture", "comments": null, "journal-ref": null, "doi": "10.1109/PIMRC48278.2020.9217188", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Intent in Android plays an important role in inter-process and\nintra-process communications. The implicit Intent that an application could\naccept are declared in its manifest and are amongst the easiest feature to\nextract from an apk. Implicit Intents could even be extracted online and in\nreal-time. So far neither the feasibility of developing an Intrusion Detection\nSystem solely on implicit Intent has been explored, nor are any benchmarks\navailable of a malware classifier that is based on implicit Intent alone. We\ndemonstrate that despite Intent is implicit and well declared, it can provide\nvery intuitive insights to distinguish malicious from non-malicious\napplications. We conducted exhaustive experiments with over 40 different\nend-to-end Deep Learning configurations of Auto-Encoders and\nMulti-Layer-Perceptron to create a benchmark for a malware classifier that\nworks exclusively on implicit Intent. Using the results from the experiments we\ncreate an intrusion detection system using only the implicit Intents and\nend-to-end Deep Learning architecture. We obtained an area-under-curve\nstatistic of 0.81, and accuracy of 77.2% along with false-positive-rate of 0.11\non Drebin dataset.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 19:56:50 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Sewak", "Mohit", ""], ["Sahay", "Sanjay K.", ""], ["Rathore", "Hemant", ""]]}, {"id": "2010.08608", "submitter": "Mohit Sewak", "authors": "Mohit Sewak, Sanjay K. Sahay and Hemant Rathore", "title": "DOOM: A Novel Adversarial-DRL-Based Op-Code Level Metamorphic Malware\n  Obfuscator for the Enhancement of IDS", "comments": null, "journal-ref": null, "doi": "10.1145/3410530.3414411", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We designed and developed DOOM (Adversarial-DRL based Opcode level Obfuscator\nto generate Metamorphic malware), a novel system that uses adversarial deep\nreinforcement learning to obfuscate malware at the op-code level for the\nenhancement of IDS. The ultimate goal of DOOM is not to give a potent weapon in\nthe hands of cyber-attackers, but to create defensive-mechanisms against\nadvanced zero-day attacks. Experimental results indicate that the obfuscated\nmalware created by DOOM could effectively mimic multiple-simultaneous zero-day\nattacks. To the best of our knowledge, DOOM is the first system that could\ngenerate obfuscated malware detailed to individual op-code level. DOOM is also\nthe first-ever system to use efficient continuous action control based deep\nreinforcement learning in the area of malware generation and defense.\nExperimental results indicate that over 67% of the metamorphic malware\ngenerated by DOOM could easily evade detection from even the most potent IDS.\nThis achievement gains significance, as with this, even IDS augment with\nadvanced routing sub-system can be easily evaded by the malware generated by\nDOOM.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 19:57:06 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Sewak", "Mohit", ""], ["Sahay", "Sanjay K.", ""], ["Rathore", "Hemant", ""]]}, {"id": "2010.08615", "submitter": "Gangshan Jing", "authors": "Gangshan Jing, He Bai, Jemin George, Aranya Chakrabortty", "title": "Decomposability and Parallel Computation of Multi-Agent LQR", "comments": "This paper contains proofs of all the theorems in the conference\n  paper \"Decomposability and Parallel Computation of Multi-Agent LQR\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individual agents in a multi-agent system (MAS) may have decoupled open-loop\ndynamics, but a cooperative control objective usually results in coupled\nclosed-loop dynamics thereby making the control design computationally\nexpensive. The computation time becomes even higher when a learning strategy\nsuch as reinforcement learning (RL) needs to be applied to deal with the\nsituation when the agents dynamics are not known. To resolve this problem, we\npropose a parallel RL scheme for a linear quadratic regulator (LQR) design in a\ncontinuous-time linear MAS. The idea is to exploit the structural properties of\ntwo graphs embedded in the $Q$ and $R$ weighting matrices in the LQR objective\nto define an orthogonal transformation that can convert the original LQR design\nto multiple decoupled smaller-sized LQR designs. We show that if the MAS is\nhomogeneous then this decomposition retains closed-loop optimality. Conditions\nfor decomposability, an algorithm for constructing the transformation matrix, a\nparallel RL algorithm, and robustness analysis when the design is applied to\nnon-homogeneous MAS are presented. Simulations show that the proposed approach\ncan guarantee significant speed-up in learning without any loss in the\ncumulative value of the LQR cost.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 20:15:39 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 23:16:28 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Jing", "Gangshan", ""], ["Bai", "He", ""], ["George", "Jemin", ""], ["Chakrabortty", "Aranya", ""]]}, {"id": "2010.08652", "submitter": "Jian Ni", "authors": "Jian Ni and Taesun Moon and Parul Awasthy and Radu Florian", "title": "Cross-Lingual Relation Extraction with Transformers", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction (RE) is one of the most important tasks in information\nextraction, as it provides essential information for many NLP applications. In\nthis paper, we propose a cross-lingual RE approach that does not require any\nhuman annotation in a target language or any cross-lingual resources. Building\nupon unsupervised cross-lingual representation learning frameworks, we develop\nseveral deep Transformer based RE models with a novel encoding scheme that can\neffectively encode both entity location and entity type information. Our RE\nmodels, when trained with English data, outperform several deep neural network\nbased English RE models. More importantly, our models can be applied to perform\nzero-shot cross-lingual RE, achieving the state-of-the-art cross-lingual RE\nperformance on two datasets (68-89% of the accuracy of the supervised\ntarget-language RE model). The high cross-lingual transfer efficiency without\nrequiring additional training data or cross-lingual resources shows that our RE\nmodels are especially useful for low-resource languages.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 22:23:37 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ni", "Jian", ""], ["Moon", "Taesun", ""], ["Awasthy", "Parul", ""], ["Florian", "Radu", ""]]}, {"id": "2010.08657", "submitter": "Federico Pernici", "authors": "Federico Pernici, Matteo Bruni, Claudio Baecchi, Francesco Turchini,\n  Alberto Del Bimbo", "title": "Class-incremental Learning with Pre-allocated Fixed Classifiers", "comments": "ICPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In class-incremental learning, a learning agent faces a stream of data with\nthe goal of learning new classes while not forgetting previous ones. Neural\nnetworks are known to suffer under this setting, as they forget previously\nacquired knowledge. To address this problem, effective methods exploit past\ndata stored in an episodic memory while expanding the final classifier nodes to\naccommodate the new classes.\n  In this work, we substitute the expanding classifier with a novel fixed\nclassifier in which a number of pre-allocated output nodes are subject to the\nclassification loss right from the beginning of the learning phase. Contrarily\nto the standard expanding classifier, this allows: (a) the output nodes of\nfuture unseen classes to firstly see negative samples since the beginning of\nlearning together with the positive samples that incrementally arrive; (b) to\nlearn features that do not change their geometric configuration as novel\nclasses are incorporated in the learning model.\n  Experiments with public datasets show that the proposed approach is as\neffective as the expanding classifier while exhibiting novel intriguing\nproperties of the internal feature representation that are otherwise\nnot-existent. Our ablation study on pre-allocating a large number of classes\nfurther validates the approach.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 22:40:28 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Pernici", "Federico", ""], ["Bruni", "Matteo", ""], ["Baecchi", "Claudio", ""], ["Turchini", "Francesco", ""], ["Del Bimbo", "Alberto", ""]]}, {"id": "2010.08660", "submitter": "Manas Gaur", "authors": "Manas Gaur, Keyur Faldu, Amit Sheth", "title": "Semantics of the Black-Box: Can knowledge graphs help make deep learning\n  systems more interpretable and explainable?", "comments": "6 pages + references, 4 figures, Accepted to IEEE internet computing\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent series of innovations in deep learning (DL) have shown enormous\npotential to impact individuals and society, both positively and negatively.\nThe DL models utilizing massive computing power and enormous datasets have\nsignificantly outperformed prior historical benchmarks on increasingly\ndifficult, well-defined research tasks across technology domains such as\ncomputer vision, natural language processing, signal processing, and\nhuman-computer interactions. However, the Black-Box nature of DL models and\ntheir over-reliance on massive amounts of data condensed into labels and dense\nrepresentations poses challenges for interpretability and explainability of the\nsystem. Furthermore, DLs have not yet been proven in their ability to\neffectively utilize relevant domain knowledge and experience critical to human\nunderstanding. This aspect is missing in early data-focused approaches and\nnecessitated knowledge-infused learning and other strategies to incorporate\ncomputational knowledge. This article demonstrates how knowledge, provided as a\nknowledge graph, is incorporated into DL methods using knowledge-infused\nlearning, which is one of the strategies. We then discuss how this makes a\nfundamental difference in the interpretability and explainability of current\napproaches, and illustrate it with examples from natural language processing\nfor healthcare and education applications.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 22:55:23 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 02:28:43 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 15:52:55 GMT"}, {"version": "v4", "created": "Fri, 11 Dec 2020 23:03:11 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Gaur", "Manas", ""], ["Faldu", "Keyur", ""], ["Sheth", "Amit", ""]]}, {"id": "2010.08678", "submitter": "Vijay Janapa Reddi", "authors": "Robert David, Jared Duke, Advait Jain, Vijay Janapa Reddi, Nat\n  Jeffries, Jian Li, Nick Kreeger, Ian Nappier, Meghna Natraj, Shlomi Regev,\n  Rocky Rhodes, Tiezhen Wang, Pete Warden", "title": "TensorFlow Lite Micro: Embedded Machine Learning on TinyML Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning inference on embedded devices is a burgeoning field with myriad\napplications because tiny embedded devices are omnipresent. But we must\novercome major challenges before we can benefit from this opportunity. Embedded\nprocessors are severely resource constrained. Their nearest mobile counterparts\nexhibit at least a 100 -- 1,000x difference in compute capability, memory\navailability, and power consumption. As a result, the machine-learning (ML)\nmodels and associated ML inference framework must not only execute efficiently\nbut also operate in a few kilobytes of memory. Also, the embedded devices'\necosystem is heavily fragmented. To maximize efficiency, system vendors often\nomit many features that commonly appear in mainstream systems, including\ndynamic memory allocation and virtual memory, that allow for cross-platform\ninteroperability. The hardware comes in many flavors (e.g., instruction-set\narchitecture and FPU support, or lack thereof). We introduce TensorFlow Lite\nMicro (TF Micro), an open-source ML inference framework for running\ndeep-learning models on embedded systems. TF Micro tackles the efficiency\nrequirements imposed by embedded-system resource constraints and the\nfragmentation challenges that make cross-platform interoperability nearly\nimpossible. The framework adopts a unique interpreter-based approach that\nprovides flexibility while overcoming these challenges. This paper explains the\ndesign decisions behind TF Micro and describes its implementation details.\nAlso, we present an evaluation to demonstrate its low resource requirement and\nminimal run-time performance overhead.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 00:44:30 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 23:35:26 GMT"}, {"version": "v3", "created": "Sat, 13 Mar 2021 13:41:01 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["David", "Robert", ""], ["Duke", "Jared", ""], ["Jain", "Advait", ""], ["Reddi", "Vijay Janapa", ""], ["Jeffries", "Nat", ""], ["Li", "Jian", ""], ["Kreeger", "Nick", ""], ["Nappier", "Ian", ""], ["Natraj", "Meghna", ""], ["Regev", "Shlomi", ""], ["Rhodes", "Rocky", ""], ["Wang", "Tiezhen", ""], ["Warden", "Pete", ""]]}, {"id": "2010.08684", "submitter": "Mihail Eric", "authors": "Shikib Mehri and Mihail Eric", "title": "Example-Driven Intent Prediction with Observers", "comments": "NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A key challenge of dialog systems research is to effectively and efficiently\nadapt to new domains. A scalable paradigm for adaptation necessitates the\ndevelopment of generalizable models that perform well in few-shot settings. In\nthis paper, we focus on the intent classification problem which aims to\nidentify user intents given utterances addressed to the dialog system. We\npropose two approaches for improving the generalizability of utterance\nclassification models: (1) observers and (2) example-driven training. Prior\nwork has shown that BERT-like models tend to attribute a significant amount of\nattention to the [CLS] token, which we hypothesize results in diluted\nrepresentations. Observers are tokens that are not attended to, and are an\nalternative to the [CLS] token as a semantic representation of utterances.\nExample-driven training learns to classify utterances by comparing to examples,\nthereby using the underlying encoder as a sentence similarity model. These\nmethods are complementary; improving the representation through observers\nallows the example-driven model to better measure sentence similarities. When\ncombined, the proposed methods attain state-of-the-art results on three intent\nprediction datasets (\\textsc{banking77}, \\textsc{clinc150}, \\textsc{hwu64}) in\nboth the full data and few-shot (10 examples per intent) settings. Furthermore,\nwe demonstrate that the proposed approach can transfer to new intents and\nacross datasets without any additional training.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 01:03:06 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 02:09:16 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Mehri", "Shikib", ""], ["Eric", "Mihail", ""]]}, {"id": "2010.08690", "submitter": "Jeffrey Shainline", "authors": "Jeffrey M. Shainline", "title": "Optoelectronic Intelligence", "comments": "10 pages, five figures, perspective article", "journal-ref": null, "doi": "10.1063/5.0040567", "report-no": null, "categories": "cs.ET cs.AI cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To design and construct hardware for general intelligence, we must consider\nprinciples of both neuroscience and very-large-scale integration. For large\nneural systems capable of general intelligence, the attributes of photonics for\ncommunication and electronics for computation are complementary and\ninterdependent. Using light for communication enables high fan-out as well as\nlow-latency signaling across large systems with no traffic-dependent\nbottlenecks. For computation, the inherent nonlinearities, high speed, and low\npower consumption of Josephson circuits are conducive to complex neural\nfunctions. Operation at 4\\,K enables the use of single-photon detectors and\nsilicon light sources, two features that lead to efficiency and economical\nscalability. Here I sketch a concept for optoelectronic hardware, beginning\nwith synaptic circuits, continuing through wafer-scale integration, and\nextending to systems interconnected with fiber-optic white matter, potentially\nat the scale of the human brain and beyond.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 01:26:29 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Shainline", "Jeffrey M.", ""]]}, {"id": "2010.08707", "submitter": "Ahmed Qureshi", "authors": "Ahmed H. Qureshi, Jiangeng Dong, Asfiya Baig and Michael C. Yip", "title": "Constrained Motion Planning Networks X", "comments": "This is preprint version of a paper published in IEEE Transactions on\n  Robotics. The videos, code, dataset and trained models can be found here:\n  https://sites.google.com/view/compnetx/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained motion planning is a challenging field of research, aiming for\ncomputationally efficient methods that can find a collision-free path on the\nconstraint manifolds between a given start and goal configuration. These\nplanning problems come up surprisingly frequently, such as in robot\nmanipulation for performing daily life assistive tasks. However, few solutions\nto constrained motion planning are available, and those that exist struggle\nwith high computational time complexity in finding a path solution on the\nmanifolds. To address this challenge, we present Constrained Motion Planning\nNetworks X (CoMPNetX). It is a neural planning approach, comprising a\nconditional deep neural generator and discriminator with neural gradients-based\nfast projection operator. We also introduce neural task and scene\nrepresentations conditioned on which the CoMPNetX generates implicit manifold\nconfigurations to turbo-charge any underlying classical planner such as\nSampling-based Motion Planning methods for quickly solving complex constrained\nplanning tasks. We show that our method finds path solutions with high success\nrates and lower computation times than state-of-the-art traditional\npath-finding tools on various challenging scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 03:34:38 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 22:32:12 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Qureshi", "Ahmed H.", ""], ["Dong", "Jiangeng", ""], ["Baig", "Asfiya", ""], ["Yip", "Michael C.", ""]]}, {"id": "2010.08712", "submitter": "Meng Cao", "authors": "Meng Cao, Yue Dong, Jiapeng Wu, Jackie Chi Kit Cheung", "title": "Factual Error Correction for Abstractive Summarization Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural abstractive summarization systems have achieved promising progress,\nthanks to the availability of large-scale datasets and models pre-trained with\nself-supervised methods. However, ensuring the factual consistency of the\ngenerated summaries for abstractive summarization systems is a challenge. We\npropose a post-editing corrector module to address this issue by identifying\nand correcting factual errors in generated summaries. The neural corrector\nmodel is pre-trained on artificial examples that are created by applying a\nseries of heuristic transformations on reference summaries. These\ntransformations are inspired by an error analysis of state-of-the-art\nsummarization model outputs. Experimental results show that our model is able\nto correct factual errors in summaries generated by other neural summarization\nmodels and outperforms previous models on factual consistency evaluation on the\nCNN/DailyMail dataset. We also find that transferring from artificial error\ncorrection to downstream settings is still very challenging.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 04:24:16 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 22:56:36 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Cao", "Meng", ""], ["Dong", "Yue", ""], ["Wu", "Jiapeng", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "2010.08715", "submitter": "Ilya Kuzovkin", "authors": "Ilya Kuzovkin", "title": "Understanding Information Processing in Human Brain by Interpreting\n  Machine Learning Models", "comments": "Defended on September 22, 2020 (video recording at\n  https://www.uttv.ee/naita?id=30480). Supervisor: Dr. Raul Vicente Zafra\n  (Computational Neuroscience Lab, University of Tarty, Estonia). Opponents:\n  Dr. Fabian Sinz (IRG Neuronal Intelligence, University of T\\\"ubingen,\n  Germany), Dr. Tim C Kietzmann (Donders Institute for Brain, Cognition and\n  Behaviour, Radboud University, Netherlands)", "journal-ref": null, "doi": null, "report-no": "Dissertationes Informaticae Universitatis Tartuensis 19", "categories": "q-bio.NC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The thesis explores the role machine learning methods play in creating\nintuitive computational models of neural processing. Combined with\ninterpretability techniques, machine learning could replace human modeler and\nshift the focus of human effort to extracting the knowledge from the ready-made\nmodels and articulating that knowledge into intuitive descroptions of reality.\nThis perspective makes the case in favor of the larger role that exploratory\nand data-driven approach to computational neuroscience could play while\ncoexisting alongside the traditional hypothesis-driven approach.\n  We exemplify the proposed approach in the context of the knowledge\nrepresentation taxonomy with three research projects that employ\ninterpretability techniques on top of machine learning methods at three\ndifferent levels of neural organization. The first study (Chapter 3) explores\nfeature importance analysis of a random forest decoder trained on intracerebral\nrecordings from 100 human subjects to identify spectrotemporal signatures that\ncharacterize local neural activity during the task of visual categorization.\nThe second study (Chapter 4) employs representation similarity analysis to\ncompare the neural responses of the areas along the ventral stream with the\nactivations of the layers of a deep convolutional neural network. The third\nstudy (Chapter 5) proposes a method that allows test subjects to visually\nexplore the state representation of their neural signal in real time. This is\nachieved by using a topology-preserving dimensionality reduction technique that\nallows to transform the neural data from the multidimensional representation\nused by the computer into a two-dimensional representation a human can grasp.\n  The approach, the taxonomy, and the examples, present a strong case for the\napplicability of machine learning methods to automatic knowledge discovery in\nneuroscience.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 04:37:26 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Kuzovkin", "Ilya", ""]]}, {"id": "2010.08719", "submitter": "Xiaogang Wang", "authors": "Xiaogang Wang, Marcelo H Ang Jr, Gim Hee Lee", "title": "A Self-supervised Cascaded Refinement Network for Point Cloud Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point clouds are often sparse and incomplete, which imposes difficulties for\nreal-world applications, such as 3D object classification, detection and\nsegmentation. Existing shape completion methods tend to generate coarse shapes\nof objects without fine-grained details. Moreover, current approaches require\nfully-complete ground truth, which are difficult to obtain in real-world\napplications. In view of these, we propose a self-supervised object completion\nmethod, which optimizes the training procedure solely on the partial input\nwithout utilizing the fully-complete ground truth. In order to generate\nhigh-quality objects with detailed geometric structures, we propose a cascaded\nrefinement network (CRN) with a coarse-to-fine strategy to synthesize the\ncomplete objects. Considering the local details of partial input together with\nthe adversarial training, we are able to learn the complicated distributions of\npoint clouds and generate the object details as realistic as possible. We\nverify our self-supervised method on both unsupervised and supervised\nexperimental settings and show superior performances. Quantitative and\nqualitative experiments on different datasets demonstrate that our method\nachieves more realistic outputs compared to existing state-of-the-art\napproaches on the 3D point cloud completion task.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 04:56:22 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Wang", "Xiaogang", ""], ["Ang", "Marcelo H", "Jr"], ["Lee", "Gim Hee", ""]]}, {"id": "2010.08725", "submitter": "Chenhui Chu", "authors": "Andrew Merritt, Chenhui Chu, Yuki Arase", "title": "A Corpus for English-Japanese Multimodal Neural Machine Translation with\n  Comparable Sentences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal neural machine translation (NMT) has become an increasingly\nimportant area of research over the years because additional modalities, such\nas image data, can provide more context to textual data. Furthermore, the\nviability of training multimodal NMT models without a large parallel corpus\ncontinues to be investigated due to low availability of parallel sentences with\nimages, particularly for English-Japanese data. However, this void can be\nfilled with comparable sentences that contain bilingual terms and parallel\nphrases, which are naturally created through media such as social network posts\nand e-commerce product descriptions. In this paper, we propose a new multimodal\nEnglish-Japanese corpus with comparable sentences that are compiled from\nexisting image captioning datasets. In addition, we supplement our comparable\nsentences with a smaller parallel corpus for validation and test purposes. To\ntest the performance of this comparable sentence translation scenario, we train\nseveral baseline NMT models with our comparable corpus and evaluate their\nEnglish-Japanese translation performance. Due to low translation scores in our\nbaseline experiments, we believe that current multimodal NMT models are not\ndesigned to effectively utilize comparable sentence data. Despite this, we hope\nfor our corpus to be used to further research into multimodal NMT with\ncomparable sentences.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 06:12:25 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Merritt", "Andrew", ""], ["Chu", "Chenhui", ""], ["Arase", "Yuki", ""]]}, {"id": "2010.08760", "submitter": "Orsolya Csisz\\'ar", "authors": "Daniel Zeltner, Benedikt Schmid, Gabor Csiszar, Orsolya Csiszar", "title": "Squashing activation functions in benchmark tests: towards eXplainable\n  Artificial Intelligence using continuous-valued logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, deep neural networks have shown excellent results in\nmultiple tasks, however, there is still an increasing need to address the\nproblem of interpretability to improve model transparency, performance, and\nsafety. Achieving eXplainable Artificial Intelligence (XAI) by combining neural\nnetworks with continuous logic and multi-criteria decision-making tools is one\nof the most promising ways to approach this problem: by this combination, the\nblack-box nature of neural models can be reduced. The continuous logic-based\nneural model uses so-called Squashing activation functions, a parametric family\nof functions that satisfy natural invariance requirements and contain rectified\nlinear units as a particular case. This work demonstrates the first benchmark\ntests that measure the performance of Squashing functions in neural networks.\nThree experiments were carried out to examine their usability and a comparison\nwith the most popular activation functions was made for five different network\ntypes. The performance was determined by measuring the accuracy, loss, and time\nper epoch. These experiments and the conducted benchmarks have proven that the\nuse of Squashing functions is possible and similar in performance to\nconventional activation functions. Moreover, a further experiment was conducted\nby implementing nilpotent logical gates to demonstrate how simple\nclassification tasks can be solved successfully and with high performance. The\nresults indicate that due to the embedded nilpotent logical operators and the\ndifferentiability of the Squashing function, it is possible to solve\nclassification problems, where other commonly used activation functions fail.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 10:42:40 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Zeltner", "Daniel", ""], ["Schmid", "Benedikt", ""], ["Csiszar", "Gabor", ""], ["Csiszar", "Orsolya", ""]]}, {"id": "2010.08762", "submitter": "Fan Mo", "authors": "Fan Mo, Anastasia Borovykh, Mohammad Malekzadeh, Hamed Haddadi,\n  Soteris Demetriou", "title": "Layer-wise Characterization of Latent Information Leakage in Federated\n  Learning", "comments": "9 pages, at ICLR workshop (Distributed and Private Machine Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks via federated learning allows clients to share,\ninstead of the original data, only the model trained on their data. Prior work\nhas demonstrated that in practice a client's private information, unrelated to\nthe main learning task, can be discovered from the model's gradients, which\ncompromises the promised privacy protection. However, there is still no formal\napproach for quantifying the leakage of private information via the shared\nupdated model or gradients. In this work, we analyze property inference attacks\nand define two metrics based on (i) an adaptation of the empirical\n$\\mathcal{V}$-information, and (ii) a sensitivity analysis using Jacobian\nmatrices allowing us to measure changes in the gradients with respect to latent\ninformation. We show the applicability of our proposed metrics in localizing\nprivate latent information in a layer-wise manner and in two settings where (i)\nwe have or (ii) we do not have knowledge of the attackers' capabilities. We\nevaluate the proposed metrics for quantifying information leakage on three\nreal-world datasets using three benchmark models.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 10:49:14 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 11:49:14 GMT"}, {"version": "v3", "created": "Wed, 20 Jan 2021 20:35:58 GMT"}, {"version": "v4", "created": "Sat, 29 May 2021 11:10:58 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Mo", "Fan", ""], ["Borovykh", "Anastasia", ""], ["Malekzadeh", "Mohammad", ""], ["Haddadi", "Hamed", ""], ["Demetriou", "Soteris", ""]]}, {"id": "2010.08776", "submitter": "Urs Muller", "authors": "Mariusz Bojarski, Chenyi Chen, Joyjit Daw, Alperen De\\u{g}irmenci,\n  Joya Deri, Bernhard Firner, Beat Flepp, Sachin Gogri, Jesse Hong, Lawrence\n  Jackel, Zhenhua Jia, BJ Lee, Bo Liu, Fei Liu, Urs Muller, Samuel Payne,\n  Nischal Kota Nagendra Prasad, Artem Provodin, John Roach, Timur Rvachov, Neha\n  Tadimeti, Jesper van Engelen, Haiguang Wen, Eric Yang, and Zongyi Yang", "title": "The NVIDIA PilotNet Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Four years ago, an experimental system known as PilotNet became the first\nNVIDIA system to steer an autonomous car along a roadway. This system\nrepresents a departure from the classical approach for self-driving in which\nthe process is manually decomposed into a series of modules, each performing a\ndifferent task. In PilotNet, on the other hand, a single deep neural network\n(DNN) takes pixels as input and produces a desired vehicle trajectory as\noutput; there are no distinct internal modules connected by human-designed\ninterfaces. We believe that handcrafted interfaces ultimately limit performance\nby restricting information flow through the system and that a learned approach,\nin combination with other artificial intelligence systems that add redundancy,\nwill lead to better overall performing systems. We continue to conduct research\ntoward that goal.\n  This document describes the PilotNet lane-keeping effort, carried out over\nthe past five years by our NVIDIA PilotNet group in Holmdel, New Jersey. Here\nwe present a snapshot of system status in mid-2020 and highlight some of the\nwork done by the PilotNet group.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 12:25:18 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Bojarski", "Mariusz", ""], ["Chen", "Chenyi", ""], ["Daw", "Joyjit", ""], ["De\u011firmenci", "Alperen", ""], ["Deri", "Joya", ""], ["Firner", "Bernhard", ""], ["Flepp", "Beat", ""], ["Gogri", "Sachin", ""], ["Hong", "Jesse", ""], ["Jackel", "Lawrence", ""], ["Jia", "Zhenhua", ""], ["Lee", "BJ", ""], ["Liu", "Bo", ""], ["Liu", "Fei", ""], ["Muller", "Urs", ""], ["Payne", "Samuel", ""], ["Prasad", "Nischal Kota Nagendra", ""], ["Provodin", "Artem", ""], ["Roach", "John", ""], ["Rvachov", "Timur", ""], ["Tadimeti", "Neha", ""], ["van Engelen", "Jesper", ""], ["Wen", "Haiguang", ""], ["Yang", "Eric", ""], ["Yang", "Zongyi", ""]]}, {"id": "2010.08830", "submitter": "Zhining Liu", "authors": "Zhining Liu, Pengfei Wei, Jing Jiang, Wei Cao, Jiang Bian, Yi Chang", "title": "MESA: Boost Ensemble Imbalanced Learning with MEta-SAmpler", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Imbalanced learning (IL), i.e., learning unbiased models from\nclass-imbalanced data, is a challenging problem. Typical IL methods including\nresampling and reweighting were designed based on some heuristic assumptions.\nThey often suffer from unstable performance, poor applicability, and high\ncomputational cost in complex tasks where their assumptions do not hold. In\nthis paper, we introduce a novel ensemble IL framework named MESA. It\nadaptively resamples the training set in iterations to get multiple classifiers\nand forms a cascade ensemble model. MESA directly learns the sampling strategy\nfrom data to optimize the final metric beyond following random heuristics.\nMoreover, unlike prevailing meta-learning-based IL solutions, we decouple the\nmodel-training and meta-training in MESA by independently train the\nmeta-sampler over task-agnostic meta-data. This makes MESA generally applicable\nto most of the existing learning models and the meta-sampler can be efficiently\napplied to new tasks. Extensive experiments on both synthetic and real-world\ntasks demonstrate the effectiveness, robustness, and transferability of MESA.\nOur code is available at https://github.com/ZhiningLiu1998/mesa.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 17:29:27 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Liu", "Zhining", ""], ["Wei", "Pengfei", ""], ["Jiang", "Jing", ""], ["Cao", "Wei", ""], ["Bian", "Jiang", ""], ["Chang", "Yi", ""]]}, {"id": "2010.08844", "submitter": "Jinghan Yang", "authors": "Jinghan Yang, Adith Boloor, Ayan Chakrabarti, Xuan Zhang, Yevgeniy\n  Vorobeychik", "title": "Finding Physical Adversarial Examples for Autonomous Driving with Fast\n  and Differentiable Image Compositing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is considerable evidence that deep neural networks are vulnerable to\nadversarial perturbations applied directly to their digital inputs. However, it\nremains an open question whether this translates to vulnerabilities in real\nsystems. For example, an attack on self-driving cars would in practice entail\nmodifying the driving environment, which then impacts the video inputs to the\ncar's controller, thereby indirectly leading to incorrect driving decisions.\nSuch attacks require accounting for system dynamics and tracking viewpoint\nchanges. We propose a scalable approach for finding adversarial modifications\nof a simulated autonomous driving environment using a differentiable\napproximation for the mapping from environmental modifications (rectangles on\nthe road) to the corresponding video inputs to the controller neural network.\nGiven the parameters of the rectangles, our proposed differentiable mapping\ncomposites them onto pre-recorded video streams of the original environment,\naccounting for geometric and color variations. Moreover, we propose a multiple\ntrajectory sampling approach that enables our attacks to be robust to a car's\nself-correcting behavior. When combined with a neural network-based controller,\nour approach allows the design of adversarial modifications through end-to-end\ngradient-based optimization. Using the Carla autonomous driving simulator, we\nshow that our approach is significantly more scalable and far more effective at\nidentifying autonomous vehicle vulnerabilities in simulation experiments than a\nstate-of-the-art approach based on Bayesian Optimization.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 18:35:32 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 00:42:30 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Yang", "Jinghan", ""], ["Boloor", "Adith", ""], ["Chakrabarti", "Ayan", ""], ["Zhang", "Xuan", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "2010.08846", "submitter": "Manjunath Narayana", "authors": "Manjunath Narayana and Andreas Kolling and Lucio Nardelli and Phil\n  Fong", "title": "Lifelong update of semantic maps in dynamic environments", "comments": "To appear in IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robot understands its world through the raw information it senses from its\nsurroundings. This raw information is not suitable as a shared representation\nbetween the robot and its user. A semantic map, containing high-level\ninformation that both the robot and user understand, is better suited to be a\nshared representation. We use the semantic map as the user-facing interface on\nour fleet of floor-cleaning robots. Jitter in the robot's sensed raw map,\ndynamic objects in the environment, and exploration of new space by the robot\nare common challenges for robots. Solving these challenges effectively in the\ncontext of semantic maps is key to enabling semantic maps for lifelong mapping.\nFirst, as a robot senses new changes and alters its raw map in successive runs,\nthe semantics must be updated appropriately. We update the map using a spatial\ntransfer of semantics. Second, it is important to keep semantics and their\nrelative constraints consistent even in the presence of dynamic objects.\nInconsistencies are automatically determined and resolved through the\nintroduction of a map layer of meta-semantics. Finally, a discovery phase\nallows the semantic map to be updated with new semantics whenever the robot\nuncovers new information. Deployed commercially on thousands of floor-cleaning\nrobots in real homes, our user-facing semantic maps provide a intuitive user\nexperience through a lifelong mapping robot.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 18:44:33 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Narayana", "Manjunath", ""], ["Kolling", "Andreas", ""], ["Nardelli", "Lucio", ""], ["Fong", "Phil", ""]]}, {"id": "2010.08865", "submitter": "Thanh Tran", "authors": "Thanh Tran, Yifan Hu, Changwei Hu, Kevin Yen, Fei Tan, Kyumin Lee,\n  Serim Park", "title": "HABERTOR: An Efficient and Effective Deep Hatespeech Detector", "comments": null, "journal-ref": "EMNLP 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our HABERTOR model for detecting hatespeech in large scale\nuser-generated content. Inspired by the recent success of the BERT model, we\npropose several modifications to BERT to enhance the performance on the\ndownstream hatespeech classification task. HABERTOR inherits BERT's\narchitecture, but is different in four aspects: (i) it generates its own\nvocabularies and is pre-trained from the scratch using the largest scale\nhatespeech dataset; (ii) it consists of Quaternion-based factorized components,\nresulting in a much smaller number of parameters, faster training and\ninferencing, as well as less memory usage; (iii) it uses our proposed\nmulti-source ensemble heads with a pooling layer for separate input sources, to\nfurther enhance its effectiveness; and (iv) it uses a regularized adversarial\ntraining with our proposed fine-grained and adaptive noise magnitude to enhance\nits robustness. Through experiments on the large-scale real-world hatespeech\ndataset with 1.4M annotated comments, we show that HABERTOR works better than\n15 state-of-the-art hatespeech detection methods, including fine-tuning\nLanguage Models. In particular, comparing with BERT, our HABERTOR is 4~5 times\nfaster in the training/inferencing phase, uses less than 1/3 of the memory, and\nhas better performance, even though we pre-train it by using less than 1% of\nthe number of words. Our generalizability analysis shows that HABERTOR\ntransfers well to other unseen hatespeech datasets and is a more efficient and\neffective alternative to BERT for the hatespeech classification.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 21:10:08 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Tran", "Thanh", ""], ["Hu", "Yifan", ""], ["Hu", "Changwei", ""], ["Yen", "Kevin", ""], ["Tan", "Fei", ""], ["Lee", "Kyumin", ""], ["Park", "Serim", ""]]}, {"id": "2010.08869", "submitter": "Nishanth Kumar", "authors": "Nishanth Kumar, Michael Fishman, Natasha Danas, Michael Littman,\n  Stefanie Tellex, George Konidaris", "title": "Task Scoping: Generating Task-Specific Abstractions for Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generally intelligent agent requires an open-scope world model: one rich\nenough to tackle any of the wide range of tasks it may be asked to solve over\nits operational lifetime. Unfortunately, planning to solve any specific task\nusing such a rich model is computationally intractable - even for\nstate-of-the-art methods - due to the many states and actions that are\nnecessarily present in the model but irrelevant to that problem. We propose\ntask scoping: a method that exploits knowledge of the initial condition, goal\ncondition, and transition-dynamics structure of a task to automatically and\nefficiently prune provably irrelevant factors and actions from a planning\nproblem, which can dramatically decrease planning time. We prove that task\nscoping never deletes relevant factors or actions, characterize its\ncomputational complexity, and characterize the planning problems for which it\nis especially useful. Finally, we empirically evaluate task scoping on a\nvariety of domains and demonstrate that using it as a pre-planning step can\nreduce the state-action space of various planning problems by orders of\nmagnitude and speed up planning. When applied to a complex Minecraft domain,\nour approach speeds up a state-of-the-art planner by 30 times, including the\ntime required for task scoping itself.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 21:19:25 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 02:44:38 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Kumar", "Nishanth", ""], ["Fishman", "Michael", ""], ["Danas", "Natasha", ""], ["Littman", "Michael", ""], ["Tellex", "Stefanie", ""], ["Konidaris", "George", ""]]}, {"id": "2010.08885", "submitter": "Rui Prada", "authors": "Ana Salta and Rui Prada and Francisco S. Melo", "title": "A Game AI Competition to foster Collaborative AI research and\n  development", "comments": null, "journal-ref": "IEEE Transactions on Games, pp. 1-12, 2020", "doi": "10.1109/TG.2020.3024160", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game AI competitions are important to foster research and development on Game\nAI and AI in general. These competitions supply different challenging problems\nthat can be translated into other contexts, virtual or real. They provide\nframeworks and tools to facilitate the research on their core topics and\nprovide means for comparing and sharing results. A competition is also a way to\nmotivate new researchers to study these challenges. In this document, we\npresent the Geometry Friends Game AI Competition. Geometry Friends is a\ntwo-player cooperative physics-based puzzle platformer computer game. The\nconcept of the game is simple, though its solving has proven to be difficult.\nWhile the main and apparent focus of the game is cooperation, it also relies on\nother AI-related problems such as planning, plan execution, and motion control,\nall connected to situational awareness. All of these must be solved in\nreal-time. In this paper, we discuss the competition and the challenges it\nbrings, and present an overview of the current solutions.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 23:03:06 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Salta", "Ana", ""], ["Prada", "Rui", ""], ["Melo", "Francisco S.", ""]]}, {"id": "2010.08891", "submitter": "Aayam Shrestha", "authors": "Aayam Shrestha, Stefan Lee, Prasad Tadepalli, Alan Fern", "title": "DeepAveragers: Offline Reinforcement Learning by Solving Derived\n  Non-Parametric MDPs", "comments": "Preprint. Under review at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an approach to offline reinforcement learning (RL) based on\noptimally solving finitely-represented MDPs derived from a static dataset of\nexperience. This approach can be applied on top of any learned representation\nand has the potential to easily support multiple solution objectives as well as\nzero-shot adjustment to changing environments and goals. Our main contribution\nis to introduce the Deep Averagers with Costs MDP (DAC-MDP) and to investigate\nits solutions for offline RL. DAC-MDPs are a non-parametric model that can\nleverage deep representations and account for limited data by introducing costs\nfor exploiting under-represented parts of the model. In theory, we show\nconditions that allow for lower-bounding the performance of DAC-MDP solutions.\nWe also investigate the empirical behavior in a number of environments,\nincluding those with image-based observations. Overall, the experiments\ndemonstrate that the framework can work in practice and scale to large complex\noffline RL problems.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 00:11:45 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Shrestha", "Aayam", ""], ["Lee", "Stefan", ""], ["Tadepalli", "Prasad", ""], ["Fern", "Alan", ""]]}, {"id": "2010.08920", "submitter": "Vektor Dewanto", "authors": "Vektor Dewanto, George Dunn, Ali Eshragh, Marcus Gallagher, Fred\n  Roosta", "title": "Average-reward model-free reinforcement learning: a systematic review\n  and literature mapping", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning (RL) has been an active area of research\nand provides a fundamental framework for agent-based learning and\ndecision-making in artificial intelligence. In this paper, we review a specific\nsubset of this literature, namely work that utilizes optimization criteria\nbased on average rewards, in the infinite horizon setting. Average reward RL\nhas the advantage of being the most selective criterion in recurrent (ergodic)\nMarkov decision processes. In comparison to widely-used discounted reward\ncriterion, it also requires no discount factor, which is a critical\nhyperparameter, and properly aligns the optimization and performance metrics.\nMotivated by the solo survey by Mahadevan (1996a), we provide an updated review\nof work in this area and extend it to cover policy-iteration and function\napproximation methods (in addition to the value-iteration and tabular\ncounterparts). We also identify and discuss opportunities for future work.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 05:06:01 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Dewanto", "Vektor", ""], ["Dunn", "George", ""], ["Eshragh", "Ali", ""], ["Gallagher", "Marcus", ""], ["Roosta", "Fred", ""]]}, {"id": "2010.08923", "submitter": "Chenyu You", "authors": "Chenyu You, Nuo Chen, Fenglin Liu, Dongchao Yang, Yuexian Zou", "title": "Towards Data Distillation for End-to-end Spoken Conversational Question\n  Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI eess.AS eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spoken question answering, QA systems are designed to answer questions\nfrom contiguous text spans within the related speech transcripts. However, the\nmost natural way that human seek or test their knowledge is via human\nconversations. Therefore, we propose a new Spoken Conversational Question\nAnswering task (SCQA), aiming at enabling QA systems to model complex dialogues\nflow given the speech utterances and text corpora. In this task, our main\nobjective is to build a QA system to deal with conversational questions both in\nspoken and text forms, and to explore the plausibility of providing more cues\nin spoken documents with systems in information gathering. To this end, instead\nof adopting automatically generated speech transcripts with highly noisy data,\nwe propose a novel unified data distillation approach, DDNet, which directly\nfuse audio-text features to reduce the misalignment between automatic speech\nrecognition hypotheses and the reference transcriptions. In addition, to\nevaluate the capacity of QA systems in a dialogue-style interaction, we\nassemble a Spoken Conversational Question Answering (Spoken-CoQA) dataset with\nmore than 120k question-answer pairs. Experiments demonstrate that our proposed\nmethod achieves superior performance in spoken conversational question\nanswering.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 05:53:39 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["You", "Chenyu", ""], ["Chen", "Nuo", ""], ["Liu", "Fenglin", ""], ["Yang", "Dongchao", ""], ["Zou", "Yuexian", ""]]}, {"id": "2010.08924", "submitter": "Shinwoo Park", "authors": "Shin-woo Park, Byung Jun Bae, Jinyoung Yeo, Seung-won Hwang", "title": "Meta-path Free Semi-supervised Learning for Heterogeneous Networks", "comments": "The technical description of [Proposed Models] section has an error.\n  Especially, the training process", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have been widely used in representation learning\non graphs and achieved superior performance in tasks such as node\nclassification. However, analyzing heterogeneous graph of different types of\nnodes and links still brings great challenges for injecting the heterogeneity\ninto a graph neural network. A general remedy is to manually or automatically\ndesign meta-paths to transform a heterogeneous graph into a homogeneous graph,\nbut this is suboptimal since the features from the first-order neighbors are\nnot fully leveraged for training and inference. In this paper, we propose\nsimple and effective graph neural networks for heterogeneous graph, excluding\nthe use of meta-paths. Specifically, our models focus on relaxing the\nheterogeneity stress for model parameters by expanding model capacity of\ngeneral GNNs in an effective way. Extensive experimental results on six\nreal-world graphs not only show the superior performance of our proposed models\nover the state-of-the-arts, but also demonstrate the potentially good balance\nbetween reducing the heterogeneity stress and increasing the parameter size.\nOur code is freely available for reproducing our results.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 06:01:58 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 23:54:30 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Park", "Shin-woo", ""], ["Bae", "Byung Jun", ""], ["Yeo", "Jinyoung", ""], ["Hwang", "Seung-won", ""]]}, {"id": "2010.08925", "submitter": "Keehang Kwon", "authors": "Keehang Kwon", "title": "Implementing Agent-Based Systems via Computability Logic CL2", "comments": "11 pages. This is a revised version and some errors are fixed. arXiv\n  admin note: substantial text overlap with arXiv:1909.07036", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computability logic(CoL) is a powerful computational model. In this paper, we\nshow that CoL naturally supports multi-agent programming models where resources\n(coffee for example) are involved. To be specific, we discuss an implementation\nof the Starbucks based on CoL (CL2 to be exact).\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 06:07:32 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 11:15:41 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Kwon", "Keehang", ""]]}, {"id": "2010.08973", "submitter": "Ke Chen", "authors": "Maksymilian Wojtas and Ke Chen", "title": "Feature Importance Ranking for Deep Learning", "comments": "Accepted by NeurIPS 2020, 5 Figures and 1 Table in Main text, 10\n  Figures and 5 Tables in Supplementary Materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature importance ranking has become a powerful tool for explainable AI.\nHowever, its nature of combinatorial optimization poses a great challenge for\ndeep learning. In this paper, we propose a novel dual-net architecture\nconsisting of operator and selector for discovery of an optimal feature subset\nof a fixed size and ranking the importance of those features in the optimal\nsubset simultaneously. During learning, the operator is trained for a\nsupervised learning task via optimal feature subset candidates generated by the\nselector that learns predicting the learning performance of the operator\nworking on different optimal subset candidates. We develop an alternate\nlearning algorithm that trains two nets jointly and incorporates a stochastic\nlocal search procedure into learning to address the combinatorial optimization\nchallenge. In deployment, the selector generates an optimal feature subset and\nranks feature importance, while the operator makes predictions based on the\noptimal subset for test data. A thorough evaluation on synthetic, benchmark and\nreal data sets suggests that our approach outperforms several state-of-the-art\nfeature importance ranking and supervised feature selection methods. (Our\nsource code is available: https://github.com/maksym33/FeatureImportanceDL)\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 12:20:27 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Wojtas", "Maksymilian", ""], ["Chen", "Ke", ""]]}, {"id": "2010.08982", "submitter": "Fengda Zhang", "authors": "Fengda Zhang, Kun Kuang, Zhaoyang You, Tao Shen, Jun Xiao, Yin Zhang,\n  Chao Wu, Yueting Zhuang, Xiaolin Li", "title": "Federated Unsupervised Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To leverage enormous unlabeled data on distributed edge devices, we formulate\na new problem in federated learning called Federated Unsupervised\nRepresentation Learning (FURL) to learn a common representation model without\nsupervision while preserving data privacy. FURL poses two new challenges: (1)\ndata distribution shift (Non-IID distribution) among clients would make local\nmodels focus on different categories, leading to the inconsistency of\nrepresentation spaces. (2) without the unified information among clients in\nFURL, the representations across clients would be misaligned. To address these\nchallenges, we propose Federated Constrastive Averaging with dictionary and\nalignment (FedCA) algorithm. FedCA is composed of two key modules: (1)\ndictionary module to aggregate the representations of samples from each client\nand share with all clients for consistency of representation space and (2)\nalignment module to align the representation of each client on a base model\ntrained on a public data. We adopt the contrastive loss for local model\ntraining. Through extensive experiments with three evaluation protocols in IID\nand Non-IID settings, we demonstrate that FedCA outperforms all baselines with\nsignificant margins.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 13:28:30 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Zhang", "Fengda", ""], ["Kuang", "Kun", ""], ["You", "Zhaoyang", ""], ["Shen", "Tao", ""], ["Xiao", "Jun", ""], ["Zhang", "Yin", ""], ["Wu", "Chao", ""], ["Zhuang", "Yueting", ""], ["Li", "Xiaolin", ""]]}, {"id": "2010.08983", "submitter": "Sahana Ramnath", "authors": "Sahana Ramnath, Preksha Nema, Deep Sahni, Mitesh M. Khapra", "title": "Towards Interpreting BERT for Reading Comprehension Based QA", "comments": "7 pages including references and appendix. Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BERT and its variants have achieved state-of-the-art performance in various\nNLP tasks. Since then, various works have been proposed to analyze the\nlinguistic information being captured in BERT. However, the current works do\nnot provide an insight into how BERT is able to achieve near human-level\nperformance on the task of Reading Comprehension based Question Answering. In\nthis work, we attempt to interpret BERT for RCQA. Since BERT layers do not have\npredefined roles, we define a layer's role or functionality using Integrated\nGradients. Based on the defined roles, we perform a preliminary analysis across\nall layers. We observed that the initial layers focus on query-passage\ninteraction, whereas later layers focus more on contextual understanding and\nenhancing the answer prediction. Specifically for quantifier questions (how\nmuch/how many), we notice that BERT focuses on confusing words (i.e., on other\nnumerical quantities in the passage) in the later layers, but still manages to\npredict the answer correctly. The fine-tuning and analysis scripts will be\npublicly available at https://github.com/iitmnlp/BERT-Analysis-RCQA .\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 13:33:49 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ramnath", "Sahana", ""], ["Nema", "Preksha", ""], ["Sahni", "Deep", ""], ["Khapra", "Mitesh M.", ""]]}, {"id": "2010.08995", "submitter": "Jinta Weng", "authors": "Jinta Weng, Ying Gao, Jing Qiu, Guozhu Ding, Huanqin Zheng", "title": "Construction and Application of Teaching System Based on Crowdsourcing\n  Knowledge Graph", "comments": "Number of references:15 Classification code:903.3 Information\n  Retrieval and Use Conference code: 235759", "journal-ref": "4th China Conference on Knowledge Graph and Semantic Computing,\n  CCKS 2019", "doi": "10.1007/978-981-15-1956-7_3", "report-no": null, "categories": "cs.DB cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through the combination of crowdsourcing knowledge graph and teaching system,\nresearch methods to generate knowledge graph and its applications. Using two\ncrowdsourcing approaches, crowdsourcing task distribution and reverse captcha\ngeneration, to construct knowledge graph in the field of teaching system.\nGenerating a complete hierarchical knowledge graph of the teaching domain by\nnodes of school, student, teacher, course, knowledge point and exercise type.\nThe knowledge graph constructed in a crowdsourcing manner requires many users\nto participate collaboratively with fully consideration of teachers' guidance\nand users' mobilization issues. Based on the three subgraphs of knowledge\ngraph, prominent teacher, student learning situation and suitable learning\nroute could be visualized. Personalized exercises recommendation model is used\nto formulate the personalized exercise by algorithm based on the knowledge\ngraph. Collaborative creation model is developed to realize the crowdsourcing\nconstruction mechanism. Though unfamiliarity with the learning mode of\nknowledge graph and learners' less attention to the knowledge structure, system\nbased on Crowdsourcing Knowledge Graph can still get high acceptance around\nstudents and teachers\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 14:26:10 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Weng", "Jinta", ""], ["Gao", "Ying", ""], ["Qiu", "Jing", ""], ["Ding", "Guozhu", ""], ["Zheng", "Huanqin", ""]]}, {"id": "2010.09001", "submitter": "Louis Ly", "authors": "Louis Ly and Yen-Hsi Richard Tsai", "title": "Visibility Optimization for Surveillance-Evasion Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider surveillance-evasion differential games, where a pursuer must try\nto constantly maintain visibility of a moving evader. The pursuer loses as soon\nas the evader becomes occluded. Optimal controls for game can be formulated as\na Hamilton-Jacobi-Isaac equation. We use an upwind scheme to compute the\nfeedback value function, corresponding to the end-game time of the differential\ngame. Although the value function enables optimal controls, it is prohibitively\nexpensive to compute, even for a single pursuer and single evader on a small\ngrid. We consider a discrete variant of the surveillance-game. We propose two\nlocally optimal strategies based on the static value function for the\nsurveillance-evasion game with multiple pursuers and evaders. We show that\nMonte Carlo tree search and self-play reinforcement learning can train a deep\nneural network to generate reasonable strategies for on-line game play. Given\nenough computational resources and offline training time, the proposed model\ncan continue to improve its policies and efficiently scale to higher\nresolutions.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 15:02:41 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ly", "Louis", ""], ["Tsai", "Yen-Hsi Richard", ""]]}, {"id": "2010.09042", "submitter": "Anand Joshi", "authors": "Haleh Akrami, Anand A. Joshi, Sergul Aydore and Richard M. Leahy", "title": "Addressing Variance Shrinkage in Variational Autoencoders using Quantile\n  Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.IV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of uncertainty in deep learning models is of vital importance,\nespecially in medical imaging, where reliance on inference without taking into\naccount uncertainty could lead to misdiagnosis. Recently, the probabilistic\nVariational AutoEncoder (VAE) has become a popular model for anomaly detection\nin applications such as lesion detection in medical images. The VAE is a\ngenerative graphical model that is used to learn the data distribution from\nsamples and then generate new samples from this distribution. By training on\nnormal samples, the VAE can be used to detect inputs that deviate from this\nlearned distribution. The VAE models the output as a conditionally independent\nGaussian characterized by means and variances for each output dimension. VAEs\ncan therefore use reconstruction probability instead of reconstruction error\nfor anomaly detection. Unfortunately, joint optimization of both mean and\nvariance in the VAE leads to the well-known problem of shrinkage or\nunderestimation of variance. We describe an alternative approach that avoids\nthis variance shrinkage problem by using quantile regression. Using estimated\nquantiles to compute mean and variance under the Gaussian assumption, we\ncompute reconstruction probability as a principled approach to outlier or\nanomaly detection. Results on simulated and Fashion MNIST data demonstrate the\neffectiveness of our approach. We also show how our approach can be used for\nprincipled heterogeneous thresholding for lesion detection in brain images.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 17:37:39 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Akrami", "Haleh", ""], ["Joshi", "Anand A.", ""], ["Aydore", "Sergul", ""], ["Leahy", "Richard M.", ""]]}, {"id": "2010.09046", "submitter": "Cheonbok  Park", "authors": "Cheonbok Park, Yunwon Tae, Taehee Kim, Soyoung Yang, Mohammad Azam\n  Khan, Eunjeong Park and Jaegul Choo", "title": "Unsupervised Neural Machine Translation for Low-Resource Domains via\n  Meta-Learning", "comments": "to be published in ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised machine translation, which utilizes unpaired monolingual corpora\nas training data, has achieved comparable performance against supervised\nmachine translation. However, it still suffers from data-scarce domains. To\naddress this issue, this paper presents a novel meta-learning algorithm for\nunsupervised neural machine translation (UNMT) that trains the model to adapt\nto another domain by utilizing only a small amount of training data. We assume\nthat domain-general knowledge is a significant factor in handling data-scarce\ndomains. Hence, we extend the meta-learning algorithm, which utilizes knowledge\nlearned from high-resource domains, to boost the performance of low-resource\nUNMT. Our model surpasses a transfer learning-based approach by up to 2-4 BLEU\nscores. Extensive experimental results show that our proposed algorithm is\npertinent for fast adaptation and consistently outperforms other baseline\nmodels.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 17:54:13 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 14:14:06 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Park", "Cheonbok", ""], ["Tae", "Yunwon", ""], ["Kim", "Taehee", ""], ["Yang", "Soyoung", ""], ["Khan", "Mohammad Azam", ""], ["Park", "Eunjeong", ""], ["Choo", "Jaegul", ""]]}, {"id": "2010.09079", "submitter": "Mahdi Saleh", "authors": "Mahdi Saleh, Shervin Dehghani, Benjamin Busam, Nassir Navab, Federico\n  Tombari", "title": "Graphite: GRAPH-Induced feaTure Extraction for Point Cloud Registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D Point clouds are a rich source of information that enjoy growing\npopularity in the vision community. However, due to the sparsity of their\nrepresentation, learning models based on large point clouds is still a\nchallenge. In this work, we introduce Graphite, a GRAPH-Induced feaTure\nExtraction pipeline, a simple yet powerful feature transform and keypoint\ndetector. Graphite enables intensive down-sampling of point clouds with\nkeypoint detection accompanied by a descriptor. We construct a generic\ngraph-based learning scheme to describe point cloud regions and extract salient\npoints. To this end, we take advantage of 6D pose information and metric\nlearning to learn robust descriptions and keypoints across different scans. We\nReformulate the 3D keypoint pipeline with graph neural networks which allow\nefficient processing of the point set while boosting its descriptive power\nwhich ultimately results in more accurate 3D registrations. We demonstrate our\nlightweight descriptor on common 3D descriptor matching and point cloud\nregistration benchmarks and achieve comparable results with the state of the\nart. Describing 100 patches of a point cloud and detecting their keypoints\ntakes only ~0.018 seconds with our proposed network.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 19:41:09 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Saleh", "Mahdi", ""], ["Dehghani", "Shervin", ""], ["Busam", "Benjamin", ""], ["Navab", "Nassir", ""], ["Tombari", "Federico", ""]]}, {"id": "2010.09089", "submitter": "Tianlong Chen", "authors": "Tianlong Chen, Weiyi Zhang, Jingyang Zhou, Shiyu Chang, Sijia Liu,\n  Lisa Amini, Zhangyang Wang", "title": "Training Stronger Baselines for Learning to Optimize", "comments": "NeurIPS 2020 Spotlight Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to optimize (L2O) has gained increasing attention since classical\noptimizers require laborious problem-specific design and hyperparameter tuning.\nHowever, there is a gap between the practical demand and the achievable\nperformance of existing L2O models. Specifically, those learned optimizers are\napplicable to only a limited class of problems, and often exhibit instability.\nWith many efforts devoted to designing more sophisticated L2O models, we argue\nfor another orthogonal, under-explored theme: the training techniques for those\nL2O models. We show that even the simplest L2O model could have been trained\nmuch better. We first present a progressive training scheme to gradually\nincrease the optimizer unroll length, to mitigate a well-known L2O dilemma of\ntruncation bias (shorter unrolling) versus gradient explosion (longer\nunrolling). We further leverage off-policy imitation learning to guide the L2O\nlearning, by taking reference to the behavior of analytical optimizers. Our\nimproved training techniques are plugged into a variety of state-of-the-art L2O\nmodels, and immediately boost their performance, without making any change to\ntheir model structures. Especially, by our proposed techniques, an earliest and\nsimplest L2O model can be trained to outperform the latest complicated L2O\nmodels on a number of tasks. Our results demonstrate a greater potential of L2O\nyet to be unleashed, and urge to rethink the recent progress. Our codes are\npublicly available at: https://github.com/VITA-Group/L2O-Training-Techniques.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 20:05:48 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Chen", "Tianlong", ""], ["Zhang", "Weiyi", ""], ["Zhou", "Jingyang", ""], ["Chang", "Shiyu", ""], ["Liu", "Sijia", ""], ["Amini", "Lisa", ""], ["Wang", "Zhangyang", ""]]}, {"id": "2010.09101", "submitter": "David Mumford", "authors": "David Mumford", "title": "The Convergence of AI code and Cortical Functioning -- a Commentary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural nets, one of the oldest architectures for AI programming, are loosely\nbased on biological neurons and their properties. Recent work on language\napplications has made the AI code closer to biological reality in several ways.\nThis commentary examines this convergence and, in light of what is known of\nneocortical structure, addresses the question of whether ``general AI'' looks\nattainable with these tools.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 20:50:45 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Mumford", "David", ""]]}, {"id": "2010.09108", "submitter": "Eric Benhamou", "authors": "Eric Benhamou, David Saltiel, Sandrine Ungari, Abhishek Mukhopadhyay", "title": "Bridging the gap between Markowitz planning and deep reinforcement\n  learning", "comments": "10 pages, ICAPS PRL. arXiv admin note: substantial text overlap with\n  arXiv:2009.14136, arXiv:2010.08497", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While researchers in the asset management industry have mostly focused on\ntechniques based on financial and risk planning techniques like Markowitz\nefficient frontier, minimum variance, maximum diversification or equal risk\nparity, in parallel, another community in machine learning has started working\non reinforcement learning and more particularly deep reinforcement learning to\nsolve other decision making problems for challenging task like autonomous\ndriving, robot learning, and on a more conceptual side games solving like Go.\nThis paper aims to bridge the gap between these two approaches by showing Deep\nReinforcement Learning (DRL) techniques can shed new lights on portfolio\nallocation thanks to a more general optimization setting that casts portfolio\nallocation as an optimal control problem that is not just a one-step\noptimization, but rather a continuous control optimization with a delayed\nreward. The advantages are numerous: (i) DRL maps directly market conditions to\nactions by design and hence should adapt to changing environment, (ii) DRL does\nnot rely on any traditional financial risk assumptions like that risk is\nrepresented by variance, (iii) DRL can incorporate additional data and be a\nmulti inputs method as opposed to more traditional optimization methods. We\npresent on an experiment some encouraging results using convolution networks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 04:03:27 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Benhamou", "Eric", ""], ["Saltiel", "David", ""], ["Ungari", "Sandrine", ""], ["Mukhopadhyay", "Abhishek", ""]]}, {"id": "2010.09128", "submitter": "Manxi Wu", "authors": "Manxi Wu, Saurabh Amin, and Asuman Ozdaglar", "title": "Multi-agent Bayesian Learning with Adaptive Strategies: Convergence and\n  Stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study learning dynamics induced by strategic agents who repeatedly play a\ngame with an unknown payoff-relevant parameter. In each step, an information\nsystem estimates a belief distribution of the parameter based on the players'\nstrategies and realized payoffs using Bayes' rule. Players adjust their\nstrategies by accounting for an equilibrium strategy or a best response\nstrategy based on the updated belief. We prove that beliefs and strategies\nconverge to a fixed point with probability 1. We also provide conditions that\nguarantee local and global stability of fixed points. Any fixed point belief\nconsistently estimates the payoff distribution given the fixed point strategy\nprofile. However, convergence to a complete information Nash equilibrium is not\nalways guaranteed. We provide a sufficient and necessary condition under which\nfixed point belief recovers the unknown parameter. We also provide a sufficient\ncondition for convergence to complete information equilibrium even when\nparameter learning is incomplete.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 22:37:26 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Wu", "Manxi", ""], ["Amin", "Saurabh", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "2010.09142", "submitter": "Enamul Hoque", "authors": "Jason Obeid and Enamul Hoque", "title": "Chart-to-Text: Generating Natural Language Descriptions for Charts by\n  Adapting the Transformer Model", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information visualizations such as bar charts and line charts are very\npopular for exploring data and communicating insights. Interpreting and making\nsense of such visualizations can be challenging for some people, such as those\nwho are visually impaired or have low visualization literacy. In this work, we\nintroduce a new dataset and present a neural model for automatically generating\nnatural language summaries for charts. The generated summaries provide an\ninterpretation of the chart and convey the key insights found within that\nchart. Our neural model is developed by extending the state-of-the-art model\nfor the data-to-text generation task, which utilizes a transformer-based\nencoder-decoder architecture. We found that our approach outperforms the base\nmodel on a content selection metric by a wide margin (55.42% vs. 8.49%) and\ngenerates more informative, concise, and coherent summaries.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 23:57:33 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 21:17:49 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Obeid", "Jason", ""], ["Hoque", "Enamul", ""]]}, {"id": "2010.09164", "submitter": "Masha Itkina", "authors": "Masha Itkina, Boris Ivanovic, Ransalu Senanayake, Mykel J.\n  Kochenderfer, and Marco Pavone", "title": "Evidential Sparsification of Multimodal Latent Spaces in Conditional\n  Variational Autoencoders", "comments": "21 pages, 15 figures, 34th Conference on Neural Information\n  Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete latent spaces in variational autoencoders have been shown to\neffectively capture the data distribution for many real-world problems such as\nnatural language understanding, human intent prediction, and visual scene\nrepresentation. However, discrete latent spaces need to be sufficiently large\nto capture the complexities of real-world data, rendering downstream tasks\ncomputationally challenging. For instance, performing motion planning in a\nhigh-dimensional latent representation of the environment could be intractable.\nWe consider the problem of sparsifying the discrete latent space of a trained\nconditional variational autoencoder, while preserving its learned\nmultimodality. As a post hoc latent space reduction technique, we use\nevidential theory to identify the latent classes that receive direct evidence\nfrom a particular input condition and filter out those that do not. Experiments\non diverse tasks, such as image generation and human behavior prediction,\ndemonstrate the effectiveness of our proposed technique at reducing the\ndiscrete latent sample space size of a model while maintaining its learned\nmultimodality.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 01:27:21 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 22:28:54 GMT"}, {"version": "v3", "created": "Mon, 18 Jan 2021 18:34:32 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Itkina", "Masha", ""], ["Ivanovic", "Boris", ""], ["Senanayake", "Ransalu", ""], ["Kochenderfer", "Mykel J.", ""], ["Pavone", "Marco", ""]]}, {"id": "2010.09170", "submitter": "Hai Nguyen", "authors": "Hai Nguyen, Brett Daley, Xinchao Song, Christopher Amato, Robert Platt", "title": "Belief-Grounded Networks for Accelerated Robot Learning under Partial\n  Observability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important robotics problems are partially observable in the sense that a\nsingle visual or force-feedback measurement is insufficient to reconstruct the\nstate. Standard approaches involve learning a policy over beliefs or\nobservation-action histories. However, both of these have drawbacks; it is\nexpensive to track the belief online, and it is hard to learn policies directly\nover histories. We propose a method for policy learning under partial\nobservability called the Belief-Grounded Network (BGN) in which an auxiliary\nbelief-reconstruction loss incentivizes a neural network to concisely summarize\nits input history. Since the resulting policy is a function of the history\nrather than the belief, it can be executed easily at runtime. We compare BGN\nagainst several baselines on classic benchmark tasks as well as three novel\nrobotic touch-sensing tasks. BGN outperforms all other tested methods and its\nlearned policies work well when transferred onto a physical robot.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 02:02:21 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 03:19:40 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 14:25:40 GMT"}, {"version": "v4", "created": "Thu, 5 Nov 2020 23:33:48 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Nguyen", "Hai", ""], ["Daley", "Brett", ""], ["Song", "Xinchao", ""], ["Amato", "Christopher", ""], ["Platt", "Robert", ""]]}, {"id": "2010.09185", "submitter": "Vinit Chunilal Sarode", "authors": "Vinit Sarode, Animesh Dhagat, Rangaprasad Arun Srivatsan, Nicolas\n  Zevallos, Simon Lucey, Howie Choset", "title": "MaskNet: A Fully-Convolutional Network to Estimate Inlier Points", "comments": "Accepted at International Conference on 3D Vision (3DV, 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point clouds have grown in importance in the way computers perceive the\nworld. From LIDAR sensors in autonomous cars and drones to the time of flight\nand stereo vision systems in our phones, point clouds are everywhere. Despite\ntheir ubiquity, point clouds in the real world are often missing points because\nof sensor limitations or occlusions, or contain extraneous points from sensor\nnoise or artifacts. These problems challenge algorithms that require computing\ncorrespondences between a pair of point clouds. Therefore, this paper presents\na fully-convolutional neural network that identifies which points in one point\ncloud are most similar (inliers) to the points in another. We show improvements\nin learning-based and classical point cloud registration approaches when\nretrofitted with our network. We demonstrate these improvements on synthetic\nand real-world datasets. Finally, our network produces impressive results on\ntest datasets that were unseen during training, thus exhibiting\ngeneralizability. Code and videos are available at\nhttps://github.com/vinits5/masknet\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 03:18:35 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Sarode", "Vinit", ""], ["Dhagat", "Animesh", ""], ["Srivatsan", "Rangaprasad Arun", ""], ["Zevallos", "Nicolas", ""], ["Lucey", "Simon", ""], ["Choset", "Howie", ""]]}, {"id": "2010.09212", "submitter": "Jiangnan Li", "authors": "Jiangnan Li, Yingyuan Yang, Jinyuan Stella Sun", "title": "Exploiting Vulnerabilities of Deep Learning-based Energy Theft Detection\n  in AMI through Adversarial Attacks", "comments": "arXiv admin note: text overlap with arXiv:2006.03504", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective detection of energy theft can prevent revenue losses of utility\ncompanies and is also important for smart grid security. In recent years,\nenabled by the massive fine-grained smart meter data, deep learning (DL)\napproaches are becoming popular in the literature to detect energy theft in the\nadvanced metering infrastructure (AMI). However, as neural networks are shown\nto be vulnerable to adversarial examples, the security of the DL models is of\nconcern.\n  In this work, we study the vulnerabilities of DL-based energy theft detection\nthrough adversarial attacks, including single-step attacks and iterative\nattacks. From the attacker's point of view, we design the\n\\textit{SearchFromFree} framework that consists of 1) a randomly adversarial\nmeasurement initialization approach to maximize the stolen profit and 2) a\nstep-size searching scheme to increase the performance of black-box iterative\nattacks. The evaluation based on three types of neural networks shows that the\nadversarial attacker can report extremely low consumption measurements to the\nutility without being detected by the DL models. We finally discuss the\npotential defense mechanisms against adversarial attacks in energy theft\ndetection.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 02:25:40 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Li", "Jiangnan", ""], ["Yang", "Yingyuan", ""], ["Sun", "Jinyuan Stella", ""]]}, {"id": "2010.09231", "submitter": "Shalabh Gupta", "authors": "Zongyuan Shen and Junnan Song and Khushboo Mittal and Shalabh Gupta", "title": "CT-CPP: 3D Coverage Path Planning for Unknown Terrain Reconstruction\n  using Coverage Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter addresses the 3D coverage path planning (CPP) problem for terrain\nreconstruction of unknown obstacle rich environments. Due to sensing\nlimitations, the proposed method, called CT-CPP, performs layered scanning of\nthe 3D region to collect terrain data, where the traveling sequence is\noptimized using the concept of a coverage tree (CT). A modified TSP-based tree\ntraversal strategy is proposed. The CT-CPP method is validated on a\nhigh-fidelity underwater simulator and the results are evaluated in comparison\nto an existing terrain following CPP method (TF-CPP). The CT-CPP with TSP\noptimizer yields significant improvements in trajectory length, energy\nconsumption, and reconstruction error.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 05:34:13 GMT"}, {"version": "v2", "created": "Sat, 8 May 2021 16:54:12 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Shen", "Zongyuan", ""], ["Song", "Junnan", ""], ["Mittal", "Khushboo", ""], ["Gupta", "Shalabh", ""]]}, {"id": "2010.09240", "submitter": "Dan Su", "authors": "Dan Su, Yan Xu, Wenliang Dai, Ziwei Ji, Tiezheng Yu, Pascale Fung", "title": "Multi-hop Question Generation with Graph Convolutional Network", "comments": "Findings of EMNLP 2020", "journal-ref": null, "doi": "10.18653/v1/2020.findings-emnlp.416", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop Question Generation (QG) aims to generate answer-related questions\nby aggregating and reasoning over multiple scattered evidence from different\nparagraphs. It is a more challenging yet under-explored task compared to\nconventional single-hop QG, where the questions are generated from the sentence\ncontaining the answer or nearby sentences in the same paragraph without complex\nreasoning. To address the additional challenges in multi-hop QG, we propose\nMulti-Hop Encoding Fusion Network for Question Generation (MulQG), which does\ncontext encoding in multiple hops with Graph Convolutional Network and encoding\nfusion via an Encoder Reasoning Gate. To the best of our knowledge, we are the\nfirst to tackle the challenge of multi-hop reasoning over paragraphs without\nany sentence-level information. Empirical results on HotpotQA dataset\ndemonstrate the effectiveness of our method, in comparison with baselines on\nautomatic evaluation metrics. Moreover, from the human evaluation, our proposed\nmodel is able to generate fluent questions with high completeness and\noutperforms the strongest baseline by 20.8% in the multi-hop evaluation. The\ncode is publicly available at\nhttps://github.com/HLTCHKUST/MulQG}{https://github.com/HLTCHKUST/MulQG .\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 06:15:36 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 08:59:23 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Su", "Dan", ""], ["Xu", "Yan", ""], ["Dai", "Wenliang", ""], ["Ji", "Ziwei", ""], ["Yu", "Tiezheng", ""], ["Fung", "Pascale", ""]]}, {"id": "2010.09254", "submitter": "Jingang Wang", "authors": "Yang Yang, Junmei Hao, Canjia Li, Zili Wang, Jingang Wang, Fuzheng\n  Zhang, Rao Fu, Peixu Hou, Gong Zhang, Zhongyuan Wang", "title": "Query-aware Tip Generation for Vertical Search", "comments": "Accepted By CIKM 2020 Applied Research Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a concise form of user reviews, tips have unique advantages to explain the\nsearch results, assist users' decision making, and further improve user\nexperience in vertical search scenarios. Existing work on tip generation does\nnot take query into consideration, which limits the impact of tips in search\nscenarios. To address this issue, this paper proposes a query-aware tip\ngeneration framework, integrating query information into encoding and\nsubsequent decoding processes. Two specific adaptations of Transformer and\nRecurrent Neural Network (RNN) are proposed. For Transformer, the query impact\nis incorporated into the self-attention computation of both the encoder and the\ndecoder. As for RNN, the query-aware encoder adopts a selective network to\ndistill query-relevant information from the review, while the query-aware\ndecoder integrates the query information into the attention computation during\ndecoding. The framework consistently outperforms the competing methods on both\npublic and real-world industrial datasets. Last but not least, online\ndeployment experiments on Dianping demonstrate the advantage of the proposed\nframework for tip generation as well as its online business values.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 06:48:40 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Yang", "Yang", ""], ["Hao", "Junmei", ""], ["Li", "Canjia", ""], ["Wang", "Zili", ""], ["Wang", "Jingang", ""], ["Zhang", "Fuzheng", ""], ["Fu", "Rao", ""], ["Hou", "Peixu", ""], ["Zhang", "Gong", ""], ["Wang", "Zhongyuan", ""]]}, {"id": "2010.09269", "submitter": "Mayank Shekhar Jha", "authors": "Mayank Shekhar Jha (CRAN), Philippe Weber, Didier Theilliol,\n  Jean-Christophe Ponsart, Didier Maquin", "title": "A Reinforcement Learning Approach to Health Aware Control Strategy", "comments": null, "journal-ref": "Mediterranean Conference on Control and Automation (MED). IEEE,\n  2019, Jul 2019, Akko, Israel", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health-aware control (HAC) has emerged as one of the domains where control\nsynthesis is sought based upon the failure prognostics of system/component or\nthe Remaining Useful Life (RUL) predictions of critical components. The fact\nthat mathematical dynamic (transition) models of RUL are rarely available,\nmakes it difficult for RUL information to be incorporated into the control\nparadigm. A novel framework for health aware control is presented in this paper\nwhere reinforcement learning based approach is used to learn an optimal control\npolicy in face of component degradation by integrating global system transition\ndata (generated by an analytical model that mimics the real system) and RUL\npredictions. The RUL predictions generated at each step, is tracked to a\ndesired value of RUL. The latter is integrated within a cost function which is\nmaximized to learn the optimal control. The proposed method is studied using\nsimulation of a DC motor and shaft wear.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 07:25:54 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Jha", "Mayank Shekhar", "", "CRAN"], ["Weber", "Philippe", ""], ["Theilliol", "Didier", ""], ["Ponsart", "Jean-Christophe", ""], ["Maquin", "Didier", ""]]}, {"id": "2010.09270", "submitter": "Boliang Zhang", "authors": "Boliang Zhang, Spencer Whitehead, Lifu Huang and Heng Ji", "title": "Global Attention for Name Tagging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many name tagging approaches use local contextual information with much\nsuccess, but fail when the local context is ambiguous or limited. We present a\nnew framework to improve name tagging by utilizing local, document-level, and\ncorpus-level contextual information. We retrieve document-level context from\nother sentences within the same document and corpus-level context from\nsentences in other topically related documents. We propose a model that learns\nto incorporate document-level and corpus-level contextual information alongside\nlocal contextual information via global attentions, which dynamically weight\ntheir respective contextual information, and gating mechanisms, which determine\nthe influence of this information. Extensive experiments on benchmark datasets\nshow the effectiveness of our approach, which achieves state-of-the-art results\nfor Dutch, German, and Spanish on the CoNLL-2002 and CoNLL-2003 datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 07:27:15 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Zhang", "Boliang", ""], ["Whitehead", "Spencer", ""], ["Huang", "Lifu", ""], ["Ji", "Heng", ""]]}, {"id": "2010.09273", "submitter": "Fabian Timm", "authors": "Michael Ulrich and Claudius Gl\\\"aser and Fabian Timm", "title": "DeepReflecs: Deep Learning for Automotive Object Classification with\n  Radar Reflections", "comments": "preprint, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an novel object type classification method for automotive\napplications which uses deep learning with radar reflections. The method\nprovides object class information such as pedestrian, cyclist, car, or\nnon-obstacle. The method is both powerful and efficient, by using a\nlight-weight deep learning approach on reflection level radar data. It fills\nthe gap between low-performant methods of handcrafted features and\nhigh-performant methods with convolutional neural networks. The proposed\nnetwork exploits the specific characteristics of radar reflection data: It\nhandles unordered lists of arbitrary length as input and it combines both\nextraction of local and global features. In experiments with real data the\nproposed network outperforms existing methods of handcrafted or learned\nfeatures. An ablation study analyzes the impact of the proposed global context\nlayer.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 07:35:51 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ulrich", "Michael", ""], ["Gl\u00e4ser", "Claudius", ""], ["Timm", "Fabian", ""]]}, {"id": "2010.09278", "submitter": "Wen Fei", "authors": "Wen Fei, Wenrui Dai, Chenglin Li, Junni Zou, Hongkai Xiong", "title": "MimicNorm: Weight Mean and Last BN Layer Mimic the Dynamic of Batch\n  Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Substantial experiments have validated the success of Batch Normalization\n(BN) Layer in benefiting convergence and generalization. However, BN requires\nextra memory and float-point calculation. Moreover, BN would be inaccurate on\nmicro-batch, as it depends on batch statistics. In this paper, we address these\nproblems by simplifying BN regularization while keeping two fundamental impacts\nof BN layers, i.e., data decorrelation and adaptive learning rate. We propose a\nnovel normalization method, named MimicNorm, to improve the convergence and\nefficiency in network training. MimicNorm consists of only two light\noperations, including modified weight mean operations (subtract mean values\nfrom weight parameter tensor) and one BN layer before loss function (last BN\nlayer). We leverage the neural tangent kernel (NTK) theory to prove that our\nweight mean operation whitens activations and transits network into the chaotic\nregime like BN layer, and consequently, leads to an enhanced convergence. The\nlast BN layer provides autotuned learning rates and also improves accuracy.\nExperimental results show that MimicNorm achieves similar accuracy for various\nnetwork structures, including ResNets and lightweight networks like ShuffleNet,\nwith a reduction of about 20% memory consumption. The code is publicly\navailable at https://github.com/Kid-key/MimicNorm.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 07:42:41 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 01:50:11 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Fei", "Wen", ""], ["Dai", "Wenrui", ""], ["Li", "Chenglin", ""], ["Zou", "Junni", ""], ["Xiong", "Hongkai", ""]]}, {"id": "2010.09291", "submitter": "Salman Khan Dr.", "authors": "Jathushan Rajasegaran, Salman Khan, Munawar Hayat, Fahad Shahbaz Khan,\n  Mubarak Shah", "title": "Meta-learning the Learning Trends Shared Across Tasks", "comments": "Code will be released at https://github.com/brjathu/PAMELA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning stands for 'learning to learn' such that generalization to new\ntasks is achieved. Among these methods, Gradient-based meta-learning algorithms\nare a specific sub-class that excel at quick adaptation to new tasks with\nlimited data. This demonstrates their ability to acquire transferable\nknowledge, a capability that is central to human learning. However, the\nexisting meta-learning approaches only depend on the current task information\nduring the adaptation, and do not share the meta-knowledge of how a similar\ntask has been adapted before. To address this gap, we propose a 'Path-aware'\nmodel-agnostic meta-learning approach. Specifically, our approach not only\nlearns a good initialization for adaptation, it also learns an optimal way to\nadapt these parameters to a set of task-specific parameters, with learnable\nupdate directions, learning rates and, most importantly, the way updates evolve\nover different time-steps. Compared to the existing meta-learning methods, our\napproach offers: (a) The ability to learn gradient-preconditioning at different\ntime-steps of the inner-loop, thereby modeling the dynamic learning behavior\nshared across tasks, and (b) The capability of aggregating the learning context\nthrough the provision of direct gradient-skip connections from the old\ntime-steps, thus avoiding overfitting and improving generalization. In essence,\nour approach not only learns a transferable initialization, but also models the\noptimal update directions, learning rates, and task-specific learning trends.\nSpecifically, in terms of learning trends, our approach determines the way\nupdate directions shape up as the task-specific learning progresses and how the\nprevious update history helps in the current update. Our approach is simple to\nimplement and demonstrates faster convergence. We report significant\nperformance improvements on a number of FSL datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 08:06:47 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Rajasegaran", "Jathushan", ""], ["Khan", "Salman", ""], ["Hayat", "Munawar", ""], ["Khan", "Fahad Shahbaz", ""], ["Shah", "Mubarak", ""]]}, {"id": "2010.09309", "submitter": "Thanh Pham Dinh", "authors": "Phan Thi Hong Hanh, Pham Dinh Thanh and Huynh Thi Thanh Binh", "title": "Evolutionary Algorithm and Multifactorial Evolutionary Algorithm on\n  Clustered Shortest-Path Tree problem", "comments": "10 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In literature, Clustered Shortest-Path Tree Problem (CluSPT) is an NP-hard\nproblem. Previous studies often search for an optimal solution in relatively\nlarge space. To enhance the performance of the search process, two approaches\nare proposed: the first approach seeks for solutions as a set of edges. From\nthe original graph, we generate a new graph whose vertex set's cardinality is\nmuch smaller than that of the original one. Consequently, an effective\nEvolutionary Algorithm (EA) is proposed for solving CluSPT. The second approach\nlooks for vertex-based solutions. The search space of the CluSPT is transformed\ninto 2 nested search spaces (NSS). With every candidate in the high-level\noptimization, the search engine in the lower level will find a corresponding\ncandidate to combine with it to create the best solution for CluSPT.\nAccordingly, Nested Local Search EA (N-LSEA) is introduced to search for the\noptimal solution on the NSS. When solving this model in lower level by N-LSEA,\nvariety of similar tasks are handled. Thus, Multifactorial Evolutionary\nAlgorithm applied in order to enhance the implicit genetic transfer across\nthese optimizations. Proposed algorithms are conducted on a series of datasets\nand the obtained results demonstrate superior efficiency in comparison to\nprevious scientific works.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 08:37:18 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Hanh", "Phan Thi Hong", ""], ["Thanh", "Pham Dinh", ""], ["Binh", "Huynh Thi Thanh", ""]]}, {"id": "2010.09317", "submitter": "Qingqing Wu", "authors": "Qingqing Wu, Jie Xu, Yong Zeng, Derrick Wing Kwan Ng, Naofal\n  Al-Dhahir, Robert Schober, A. Lee Swindlehurst", "title": "A Comprehensive Overview on 5G-and-Beyond Networks with UAVs: From\n  Communications to Sensing and Intelligence", "comments": "Accepted by IEEE JSAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the advancements in cellular technologies and the dense deployment of\ncellular infrastructure, integrating unmanned aerial vehicles (UAVs) into the\nfifth-generation (5G) and beyond cellular networks is a promising solution to\nachieve safe UAV operation as well as enabling diversified applications with\nmission-specific payload data delivery. In particular, 5G networks need to\nsupport three typical usage scenarios, namely, enhanced mobile broadband\n(eMBB), ultra-reliable low-latency communications (URLLC), and massive\nmachine-type communications (mMTC). On the one hand, UAVs can be leveraged as\ncost-effective aerial platforms to provide ground users with enhanced\ncommunication services by exploiting their high cruising altitude and\ncontrollable maneuverability in three-dimensional (3D) space. On the other\nhand, providing such communication services simultaneously for both UAV and\nground users poses new challenges due to the need for ubiquitous 3D signal\ncoverage as well as the strong air-ground network interference. Besides the\nrequirement of high-performance wireless communications, the ability to support\neffective and efficient sensing as well as network intelligence is also\nessential for 5G-and-beyond 3D heterogeneous wireless networks with coexisting\naerial and ground users. In this paper, we provide a comprehensive overview of\nthe latest research efforts on integrating UAVs into cellular networks, with an\nemphasis on how to exploit advanced techniques (e.g., intelligent reflecting\nsurface, short packet transmission, energy harvesting, joint communication and\nradar sensing, and edge intelligence) to meet the diversified service\nrequirements of next-generation wireless systems. Moreover, we highlight\nimportant directions for further investigation in future work.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 08:56:04 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 11:13:32 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Wu", "Qingqing", ""], ["Xu", "Jie", ""], ["Zeng", "Yong", ""], ["Ng", "Derrick Wing Kwan", ""], ["Al-Dhahir", "Naofal", ""], ["Schober", "Robert", ""], ["Swindlehurst", "A. Lee", ""]]}, {"id": "2010.09322", "submitter": "Anuj Diwan", "authors": "Anuj Diwan, Preethi Jyothi", "title": "Reduce and Reconstruct: ASR for Low-Resource Phonetic Languages", "comments": "5 pages, 1 figure. Accepted at INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a seemingly simple but effective technique to improve\nlow-resource ASR systems for phonetic languages. By identifying sets of\nacoustically similar graphemes in these languages, we first reduce the output\nalphabet of the ASR system using linguistically meaningful reductions and then\nreconstruct the original alphabet using a standalone module. We demonstrate\nthat this lessens the burden and improves the performance of low-resource\nend-to-end ASR systems (because only reduced-alphabet predictions are needed)\nand that it is possible to design a very simple but effective reconstruction\nmodule that recovers sequences in the original alphabet from sequences in the\nreduced alphabet. We present a finite state transducer-based reconstruction\nmodule that operates on the 1-best ASR hypothesis in the reduced alphabet. We\ndemonstrate the efficacy of our proposed technique using ASR systems for two\nIndian languages, Gujarati and Telugu. With access to only 10 hrs of speech\ndata, we obtain relative WER reductions of up to 7% compared to systems that do\nnot use any reduction.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 08:59:58 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 10:11:49 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Diwan", "Anuj", ""], ["Jyothi", "Preethi", ""]]}, {"id": "2010.09325", "submitter": "Matej Hoffmann", "authors": "Matej Hoffmann", "title": "Body models in humans, animals, and robots", "comments": "27 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans and animals excel in combining information from multiple sensory\nmodalities, controlling their complex bodies, adapting to growth, failures, or\nusing tools. These capabilities are also highly desirable in robots. They are\ndisplayed by machines to some extent - yet, as is so often the case, the\nartificial creatures are lagging behind. The key foundation is an internal\nrepresentation of the body that the agent - human, animal, or robot - has\ndeveloped. In the biological realm, evidence has been accumulated by diverse\ndisciplines giving rise to the concepts of body image, body schema, and others.\nIn robotics, a model of the robot is an indispensable component that enables to\ncontrol the machine. In this article I compare the character of body\nrepresentations in biology with their robotic counterparts and relate that to\nthe differences in performance that we observe. I put forth a number of axes\nregarding the nature of such body models: fixed vs. plastic, amodal vs. modal,\nexplicit vs. implicit, serial vs. parallel, modular vs. holistic, and\ncentralized vs. distributed. An interesting trend emerges: on many of the axes,\nthere is a sequence from robot body models, over body image, body schema, to\nthe body representation in lower animals like the octopus. In some sense,\nrobots have a lot in common with Ian Waterman - \"the man who lost his body\" -\nin that they rely on an explicit, veridical body model (body image taken to the\nextreme) and lack any implicit, multimodal representation (like the body\nschema) of their bodies. I will then detail how robots can inform the\nbiological sciences dealing with body representations and finally, I will study\nwhich of the features of the \"body in the brain\" should be transferred to\nrobots, giving rise to more adaptive and resilient, self-calibrating machines.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 09:07:11 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Hoffmann", "Matej", ""]]}, {"id": "2010.09342", "submitter": "Jiateng Liu", "authors": "Jiateng Liu, Wenming Zheng, Yuan Zong", "title": "SMA-STN: Segmented Movement-Attending Spatiotemporal Network\n  forMicro-Expression Recognition", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correctly perceiving micro-expression is difficult since micro-expression is\nan involuntary, repressed, and subtle facial expression, and efficiently\nrevealing the subtle movement changes and capturing the significant segments in\na micro-expression sequence is the key to micro-expression recognition (MER).\nTo handle the crucial issue, in this paper, we firstly propose a dynamic\nsegmented sparse imaging module (DSSI) to compute dynamic images as\nlocal-global spatiotemporal descriptors under a unique sampling protocol, which\nreveals the subtle movement changes visually in an efficient way. Secondly, a\nsegmented movement-attending spatiotemporal network (SMA-STN) is proposed to\nfurther unveil imperceptible small movement changes, which utilizes a\nspatiotemporal movement-attending module (STMA) to capture long-distance\nspatial relation for facial expression and weigh temporal segments. Besides, a\ndeviation enhancement loss (DE-Loss) is embedded in the SMA-STN to enhance the\nrobustness of SMA-STN to subtle movement changes in feature level. Extensive\nexperiments on three widely used benchmarks, i.e., CASME II, SAMM, and SHIC,\nshow that the proposed SMA-STN achieves better MER performance than other\nstate-of-the-art methods, which proves that the proposed method is effective to\nhandle the challenging MER problem.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 09:23:24 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Liu", "Jiateng", ""], ["Zheng", "Wenming", ""], ["Zong", "Yuan", ""]]}, {"id": "2010.09366", "submitter": "Xiaoyu Guo", "authors": "Xiao-Yu Guo and Yuan-Fang Li and Gholamreza Haffari", "title": "Understanding Unnatural Questions Improves Reasoning over Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex question answering (CQA) over raw text is a challenging task. A\nprominent approach to this task is based on the programmer-interpreter\nframework, where the programmer maps the question into a sequence of reasoning\nactions which is then executed on the raw text by the interpreter. Learning an\neffective CQA model requires large amounts of human-annotated data,consisting\nof the ground-truth sequence of reasoning actions, which is time-consuming and\nexpensive to collect at scale. In this paper, we address the challenge of\nlearning a high-quality programmer (parser) by projecting natural\nhuman-generated questions into unnatural machine-generated questions which are\nmore convenient to parse. We firstly generate synthetic (question,action\nsequence) pairs by a data generator, and train a semantic parser that\nassociates synthetic questions with their corresponding action sequences. To\ncapture the diversity when applied tonatural questions, we learn a projection\nmodel to map natural questions into their most similar unnatural questions for\nwhich the parser can work well. Without any natural training data, our\nprojection model provides high-quality action sequences for the CQA task.\nExperimental results show that the QA model trained exclusively with synthetic\ndata generated by our method outperforms its state-of-the-art counterpart\ntrained on human-labeled data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 10:22:16 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Guo", "Xiao-Yu", ""], ["Li", "Yuan-Fang", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "2010.09387", "submitter": "Davide Corsi", "authors": "Davide Corsi, Enrico Marchesini, Alessandro Farinelli", "title": "Evaluating the Safety of Deep Reinforcement Learning Models using\n  Semi-Formal Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Groundbreaking successes have been achieved by Deep Reinforcement Learning\n(DRL) in solving practical decision-making problems. Robotics, in particular,\ncan involve high-cost hardware and human interactions. Hence, scrupulous\nevaluations of trained models are required to avoid unsafe behaviours in the\noperational environment. However, designing metrics to measure the safety of a\nneural network is an open problem, since standard evaluation parameters (e.g.,\ntotal reward) are not informative enough. In this paper, we present a\nsemi-formal verification approach for decision-making tasks, based on interval\nanalysis, that addresses the computational demanding of previous verification\nframeworks and design metrics to measure the safety of the models. Our method\nobtains comparable results over standard benchmarks with respect to formal\nverifiers, while drastically reducing the computation time. Moreover, our\napproach allows to efficiently evaluate safety properties for decision-making\nmodels in practical applications such as mapless navigation for mobile robots\nand trajectory generation for manipulators.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 11:18:06 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Corsi", "Davide", ""], ["Marchesini", "Enrico", ""], ["Farinelli", "Alessandro", ""]]}, {"id": "2010.09394", "submitter": "Junwoo Park", "authors": "Junwoo Park, Youngwoo Cho, Haneol Lee, Jaegul Choo, Edward Choi", "title": "Knowledge Graph-based Question Answering with Electronic Health Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Answering (QA) on Electronic Health Records (EHR), namely EHR QA,\ncan work as a crucial milestone towards developing an intelligent agent in\nhealthcare. EHR data are typically stored in a relational database, which can\nalso be converted to a Directed Acyclic Graph (DAG), allowing two approaches\nfor EHR QA: Table-based QA and Knowledge Graph-based QA. We hypothesize that\nthe graph-based approach is more suitable for EHR QA as graphs can represent\nrelations between entities and values more naturally compared to tables, which\nessentially require JOIN operations. To validate our hypothesis, we first\nconstruct EHR QA datasets based on MIMIC-III, where the same question-answer\npairs are represented in SQL (table-based) and SPARQL (graph-based),\nrespectively. We then test a state-of-the-art EHR QA model on both datasets\nwhere the model demonstrated superior QA performance on the SPARQL version.\nFinally, we open-source both MIMICSQL* and MIMIC-SPARQL* to encourage further\nEHR QA research in both direction\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 11:31:20 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Park", "Junwoo", ""], ["Cho", "Youngwoo", ""], ["Lee", "Haneol", ""], ["Choo", "Jaegul", ""], ["Choi", "Edward", ""]]}, {"id": "2010.09452", "submitter": "Joe Townsend Dr", "authors": "Joe Townsend, Theodoros Kasioumis and Hiroya Inakoshi", "title": "ERIC: Extracting Relations Inferred from Convolutions", "comments": "Accepted for poster presentation at ACCV (Asian Conference on\n  Computer Vision) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our main contribution is to show that the behaviour of kernels across\nmultiple layers of a convolutional neural network can be approximated using a\nlogic program. The extracted logic programs yield accuracies that correlate\nwith those of the original model, though with some information loss in\nparticular as approximations of multiple layers are chained together or as\nlower layers are quantised. We also show that an extracted program can be used\nas a framework for further understanding the behaviour of CNNs. Specifically,\nit can be used to identify key kernels worthy of deeper inspection and also\nidentify relationships with other kernels in the form of the logical rules.\nFinally, we make a preliminary, qualitative assessment of rules we extract from\nthe last convolutional layer and show that kernels identified are symbolic in\nthat they react strongly to sets of similar images that effectively divide\noutput classes into sub-classes with distinct characteristics.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 13:04:21 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Townsend", "Joe", ""], ["Kasioumis", "Theodoros", ""], ["Inakoshi", "Hiroya", ""]]}, {"id": "2010.09468", "submitter": "Alesssandro Giuseppi", "authors": "Alessandro Giuseppi, Antonio Pietrabissa", "title": "Chance-Constrained Control with Lexicographic Deep Reinforcement\n  Learning", "comments": "published version at: https://doi.org/10.1109/LCSYS.2020.2979635 in\n  this version we fixed a typo in (9)", "journal-ref": "IEEE Control Systems Letters, vol. 4, no. 3, pp. 755-760, July\n  2020", "doi": "10.1109/LCSYS.2020.2979635", "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a lexicographic Deep Reinforcement Learning\n(DeepRL)-based approach to chance-constrained Markov Decision Processes, in\nwhich the controller seeks to ensure that the probability of satisfying the\nconstraint is above a given threshold. Standard DeepRL approaches require i)\nthe constraints to be included as additional weighted terms in the cost\nfunction, in a multi-objective fashion, and ii) the tuning of the introduced\nweights during the training phase of the Deep Neural Network (DNN) according to\nthe probability thresholds. The proposed approach, instead, requires to\nseparately train one constraint-free DNN and one DNN associated to each\nconstraint and then, at each time-step, to select which DNN to use depending on\nthe system observed state. The presented solution does not require any\nhyper-parameter tuning besides the standard DNN ones, even if the probability\nthresholds changes. A lexicographic version of the well-known DeepRL algorithm\nDQN is also proposed and validated via simulations.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 13:09:14 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Giuseppi", "Alessandro", ""], ["Pietrabissa", "Antonio", ""]]}, {"id": "2010.09473", "submitter": "Djallel Bouneffouf", "authors": "Djallel Bouneffouf, Rapha\\\"el F\\'eraud, Sohini Upadhyay, Yasaman\n  Khazaeni and Irina Rish", "title": "Double-Linear Thompson Sampling for Context-Attentive Bandits", "comments": "arXiv admin note: text overlap with arXiv:1906.09384", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze and extend an online learning framework known as\nContext-Attentive Bandit, motivated by various practical applications, from\nmedical diagnosis to dialog systems, where due to observation costs only a\nsmall subset of a potentially large number of context variables can be observed\nat each iteration;however, the agent has a freedom to choose which variables to\nobserve. We derive a novel algorithm, called Context-Attentive Thompson\nSampling (CATS), which builds upon the Linear Thompson Sampling approach,\nadapting it to Context-Attentive Bandit setting. We provide a theoretical\nregret analysis and an extensive empirical evaluation demonstrating advantages\nof the proposed approach over several baseline methods on a variety of\nreal-life datasets\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 13:01:19 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Bouneffouf", "Djallel", ""], ["F\u00e9raud", "Rapha\u00ebl", ""], ["Upadhyay", "Sohini", ""], ["Khazaeni", "Yasaman", ""], ["Rish", "Irina", ""]]}, {"id": "2010.09475", "submitter": "Liwei Hu", "authors": "Liwei Hu, Yu Xiang, Jun Zhan, Zifang Shi and Wenzheng Wang", "title": "Aerodynamic Data Predictions Based on Multi-task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of datasets is one of the key factors that affect the accuracy of\naerodynamic data models. For example, in the uniformly sampled Burgers'\ndataset, the insufficient high-speed data is overwhelmed by massive low-speed\ndata. Predicting high-speed data is more difficult than predicting low-speed\ndata, owing to that the number of high-speed data is limited, i.e. the quality\nof the Burgers' dataset is not satisfactory. To improve the quality of\ndatasets, traditional methods usually employ the data resampling technology to\nproduce enough data for the insufficient parts in the original datasets before\nmodeling, which increases computational costs. Recently, the mixtures of\nexperts have been used in natural language processing to deal with different\nparts of sentences, which provides a solution for eliminating the need for data\nresampling in aerodynamic data modeling. Motivated by this, we propose the\nmulti-task learning (MTL), a datasets quality-adaptive learning scheme, which\ncombines task allocation and aerodynamic characteristics learning together to\ndisperse the pressure of the entire learning task. The task allocation divides\na whole learning task into several independent subtasks, while the aerodynamic\ncharacteristics learning learns these subtasks simultaneously to achieve better\nprecision. Two experiments with poor quality datasets are conducted to verify\nthe data quality-adaptivity of the MTL to datasets. The results show than the\nMTL is more accurate than FCNs and GANs in poor quality datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 01:39:27 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Hu", "Liwei", ""], ["Xiang", "Yu", ""], ["Zhan", "Jun", ""], ["Shi", "Zifang", ""], ["Wang", "Wenzheng", ""]]}, {"id": "2010.09482", "submitter": "Shahram Khadivi", "authors": "Jingjing Huo, Christian Herold, Yingbo Gao, Leonard Dahlmann, Shahram\n  Khadivi, and Hermann Ney", "title": "Diving Deep into Context-Aware Neural Machine Translation", "comments": "Accepted at 5th Conference on Machine Translation (WMT20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context-aware neural machine translation (NMT) is a promising direction to\nimprove the translation quality by making use of the additional context, e.g.,\ndocument-level translation, or having meta-information. Although there exist\nvarious architectures and analyses, the effectiveness of different\ncontext-aware NMT models is not well explored yet. This paper analyzes the\nperformance of document-level NMT models on four diverse domains with a varied\namount of parallel document-level bilingual data. We conduct a comprehensive\nset of experiments to investigate the impact of document-level NMT. We find\nthat there is no single best approach to document-level NMT, but rather that\ndifferent architectures come out on top on different tasks. Looking at\ntask-specific problems, such as pronoun resolution or headline translation, we\nfind improvements in the context-aware systems, even in cases where the\ncorpus-level metrics like BLEU show no significant improvement. We also show\nthat document-level back-translation significantly helps to compensate for the\nlack of document-level bi-texts.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 13:23:12 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Huo", "Jingjing", ""], ["Herold", "Christian", ""], ["Gao", "Yingbo", ""], ["Dahlmann", "Leonard", ""], ["Khadivi", "Shahram", ""], ["Ney", "Hermann", ""]]}, {"id": "2010.09498", "submitter": "Linhang Cai", "authors": "Linhang Cai, Zhulin An, Chuanguang Yang and Yongjun Xu", "title": "Softer Pruning, Incremental Regularization", "comments": "7 pages, ICPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network pruning is widely used to compress Deep Neural Networks (DNNs). The\nSoft Filter Pruning (SFP) method zeroizes the pruned filters during training\nwhile updating them in the next training epoch. Thus the trained information of\nthe pruned filters is completely dropped. To utilize the trained pruned\nfilters, we proposed a SofteR Filter Pruning (SRFP) method and its variant,\nAsymptotic SofteR Filter Pruning (ASRFP), simply decaying the pruned weights\nwith a monotonic decreasing parameter. Our methods perform well across various\nnetworks, datasets and pruning rates, also transferable to weight pruning. On\nILSVRC-2012, ASRFP prunes 40% of the parameters on ResNet-34 with 1.63% top-1\nand 0.68% top-5 accuracy improvement. In theory, SRFP and ASRFP are an\nincremental regularization of the pruned filters. Besides, We note that SRFP\nand ASRFP pursue better results while slowing down the speed of convergence.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 13:37:19 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Cai", "Linhang", ""], ["An", "Zhulin", ""], ["Yang", "Chuanguang", ""], ["Xu", "Yongjun", ""]]}, {"id": "2010.09515", "submitter": "Adam Foster", "authors": "Adam Foster, Rattana Pukdee, Tom Rainforth", "title": "Improving Transformation Invariance in Contrastive Representation\n  Learning", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose methods to strengthen the invariance properties of representations\nobtained by contrastive learning. While existing approaches implicitly induce a\ndegree of invariance as representations are learned, we look to more directly\nenforce invariance in the encoding process. To this end, we first introduce a\ntraining objective for contrastive learning that uses a novel regularizer to\ncontrol how the representation changes under transformation. We show that\nrepresentations trained with this objective perform better on downstream tasks\nand are more robust to the introduction of nuisance transformations at test\ntime. Second, we propose a change to how test time representations are\ngenerated by introducing a feature averaging approach that combines encodings\nfrom multiple transformations of the original input, finding that this leads to\nacross the board performance gains. Finally, we introduce the novel Spirograph\ndataset to explore our ideas in the context of a differentiable generative\nprocess with multiple downstream tasks, showing that our techniques for\nlearning invariance are highly beneficial.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 13:49:29 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 14:20:51 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Foster", "Adam", ""], ["Pukdee", "Rattana", ""], ["Rainforth", "Tom", ""]]}, {"id": "2010.09520", "submitter": "Hao Wang", "authors": "Hao Wang, Jia Zhang, Yingce Xia, Jiang Bian, Chao Zhang, Tie-Yan Liu", "title": "COSEA: Convolutional Code Search with Layer-wise Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic code search, which aims to retrieve code snippets relevant to a\ngiven natural language query, has attracted many research efforts with the\npurpose of accelerating software development. The huge amount of online\npublicly available code repositories has prompted the employment of deep\nlearning techniques to build state-of-the-art code search models. Particularly,\nthey leverage deep neural networks to embed codes and queries into a unified\nsemantic vector space and then use the similarity between code's and query's\nvectors to approximate the semantic correlation between code and the query.\nHowever, most existing studies overlook the code's intrinsic structural logic,\nwhich indeed contains a wealth of semantic information, and fails to capture\nintrinsic features of codes. In this paper, we propose a new deep learning\narchitecture, COSEA, which leverages convolutional neural networks with\nlayer-wise attention to capture the valuable code's intrinsic structural logic.\nTo further increase the learning efficiency of COSEA, we propose a variant of\ncontrastive loss for training the code search model, where the ground-truth\ncode should be distinguished from the most similar negative sample. We have\nimplemented a prototype of COSEA. Extensive experiments over existing public\ndatasets of Python and SQL have demonstrated that COSEA can achieve significant\nimprovements over state-of-the-art methods on code search tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 13:53:38 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Wang", "Hao", ""], ["Zhang", "Jia", ""], ["Xia", "Yingce", ""], ["Bian", "Jiang", ""], ["Zhang", "Chao", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2010.09531", "submitter": "Gongjin Lan", "authors": "Gongjin Lan, Maarten van Hooft, Matteo De Carlo, Jakub M. Tomczak,\n  A.E. Eiben", "title": "Learning Locomotion Skills in Evolvable Robots", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The challenge of robotic reproduction -- making of new robots by recombining\ntwo existing ones -- has been recently cracked and physically evolving robot\nsystems have come within reach. Here we address the next big hurdle: producing\nan adequate brain for a newborn robot. In particular, we address the task of\ntargeted locomotion which is arguably a fundamental skill in any practical\nimplementation. We introduce a controller architecture and a generic learning\nmethod to allow a modular robot with an arbitrary shape to learn to walk\ntowards a target and follow this target if it moves. Our approach is validated\non three robots, a spider, a gecko, and their offspring, in three real-world\nscenarios.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 14:01:50 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Lan", "Gongjin", ""], ["van Hooft", "Maarten", ""], ["De Carlo", "Matteo", ""], ["Tomczak", "Jakub M.", ""], ["Eiben", "A. E.", ""]]}, {"id": "2010.09536", "submitter": "Hongyao Tang", "authors": "Hongyao Tang, Zhaopeng Meng, Jianye Hao, Chen Chen, Daniel Graves,\n  Dong Li, Hangyu Mao, Wulong Liu, Yaodong Yang, Changmin Yu", "title": "Represent Your Own Policies: Reinforcement Learning with Policy-extended\n  Value Function Approximator", "comments": "Preprint version, 33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Policy-extended Value Function Approximator (PeVFA) in Reinforcement\nLearning (RL), which extends conventional value function approximator (VFA) to\ntake as input not only the state (and action) but also an explicit policy\nrepresentation. Such an extension enables PeVFA to preserve values of multiple\npolicies at the same time and brings an appealing characteristic, i.e.,\n\\emph{value generalization among policies}. We formally analyze the value\ngeneralization under Generalized Policy Iteration (GPI). From theoretical and\nempirical lens, we show that generalized value estimates offered by PeVFA may\nhave lower initial approximation error to true values of successive policies,\nwhich is expected to improve consecutive value approximation during GPI. Based\non above clues, we introduce a new form of GPI with PeVFA which leverages the\nvalue generalization along policy improvement path. Moreover, we propose a\nrepresentation learning framework for RL policy, providing several approaches\nto learn effective policy embeddings from policy network parameters or\nstate-action pairs. In our experiments, we evaluate the efficacy of value\ngeneralization offered by PeVFA and policy representation learning in several\nOpenAI Gym continuous control tasks. For a representative instance of algorithm\nimplementation, Proximal Policy Optimization (PPO) re-implemented under the\nparadigm of GPI with PeVFA achieves about 40\\% performance improvement on its\nvanilla counterpart in most environments.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 14:09:18 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 02:11:39 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 03:19:30 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Tang", "Hongyao", ""], ["Meng", "Zhaopeng", ""], ["Hao", "Jianye", ""], ["Chen", "Chen", ""], ["Graves", "Daniel", ""], ["Li", "Dong", ""], ["Mao", "Hangyu", ""], ["Liu", "Wulong", ""], ["Yang", "Yaodong", ""], ["Yu", "Changmin", ""]]}, {"id": "2010.09546", "submitter": "Jian Shen", "authors": "Jian Shen, Han Zhao, Weinan Zhang, Yong Yu", "title": "Model-based Policy Optimization with Unsupervised Model Adaptation", "comments": "Thirty-fourth Conference on Neural Information Processing Systems\n  (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning methods learn a dynamics model with real\ndata sampled from the environment and leverage it to generate simulated data to\nderive an agent. However, due to the potential distribution mismatch between\nsimulated data and real data, this could lead to degraded performance. Despite\nmuch effort being devoted to reducing this distribution mismatch, existing\nmethods fail to solve it explicitly. In this paper, we investigate how to\nbridge the gap between real and simulated data due to inaccurate model\nestimation for better policy optimization. To begin with, we first derive a\nlower bound of the expected return, which naturally inspires a bound\nmaximization algorithm by aligning the simulated and real data distributions.\nTo this end, we propose a novel model-based reinforcement learning framework\nAMPO, which introduces unsupervised model adaptation to minimize the integral\nprobability metric (IPM) between feature distributions from real and simulated\ndata. Instantiating our framework with Wasserstein-1 distance gives a practical\nmodel-based approach. Empirically, our approach achieves state-of-the-art\nperformance in terms of sample efficiency on a range of continuous control\nbenchmark tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 14:19:42 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 07:00:55 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Shen", "Jian", ""], ["Zhao", "Han", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "2010.09568", "submitter": "Vince Grolmusz", "authors": "Laszlo Keresztes and Evelin Szogi and Balint Varga and Vince Grolmusz", "title": "Introducing and Applying Newtonian Blurring: An Augmented Dataset of\n  126,000 Human Connectomes at braingraph.org", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian blurring is a well-established method for image data augmentation:\nit may generate a large set of images from a small set of pictures for training\nand testing purposes for Artificial Intelligence (AI) applications. When we\napply AI for non-imagelike biological data, hardly any related method exists.\nHere we introduce the \"Newtonian blurring\" in human braingraph (or connectome)\naugmentation: Started from a dataset of 1053 subjects, we first repeat a\nprobabilistic weighted braingraph construction algorithm 10 times for\ndescribing the connections of distinct cerebral areas, then take 7 repetitions\nin every possible way, delete the lower and upper extremes, and average the\nremaining 7-2=5 edge-weights for the data of each subject. This way we augment\nthe 1053 graph-set to 120 x 1053 = 126,360 graphs. In augmentation techniques,\nit is an important requirement that no artificial additions should be\nintroduced into the dataset. Gaussian blurring and also this Newtonian blurring\nsatisfy this goal. The resulting dataset of 126,360 graphs, each in 5\nresolutions (i.e., 631,800 graphs in total), is freely available at the site\nhttps://braingraph.org/cms/download-pit-group-connectomes/. Augmenting with\nNewtonian blurring may also be applicable in other non-image related fields,\nwhere probabilistic processing and data averaging are implemented.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 14:51:59 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 07:36:01 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 16:31:26 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Keresztes", "Laszlo", ""], ["Szogi", "Evelin", ""], ["Varga", "Balint", ""], ["Grolmusz", "Vince", ""]]}, {"id": "2010.09624", "submitter": "Guillermo Ortiz-Jimenez", "authors": "Guillermo Ortiz-Jimenez, Apostolos Modas, Seyed-Mohsen\n  Moosavi-Dezfooli, Pascal Frossard", "title": "Optimism in the Face of Adversity: Understanding and Improving Deep\n  Learning through Adversarial Robustness", "comments": "24 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by massive amounts of data and important advances in computational\nresources, new deep learning systems have achieved outstanding results in a\nlarge spectrum of applications. Nevertheless, our current theoretical\nunderstanding on the mathematical foundations of deep learning lags far behind\nits empirical success. Towards solving the vulnerability of neural networks,\nhowever, the field of adversarial robustness has recently become one of the\nmain sources of explanations of our deep models. In this article, we provide an\nin-depth review of the field of adversarial robustness in deep learning, and\ngive a self-contained introduction to its main notions. But, in contrast to the\nmainstream pessimistic perspective of adversarial robustness, we focus on the\nmain positive aspects that it entails. We highlight the intuitive connection\nbetween adversarial examples and the geometry of deep neural networks, and\neventually explore how the geometric study of adversarial examples can serve as\na powerful tool to understand deep learning. Furthermore, we demonstrate the\nbroad applicability of adversarial robustness, providing an overview of the\nmain emerging applications of adversarial robustness beyond security. The goal\nof this article is to provide readers with a set of new perspectives to\nunderstand deep learning, and to supply them with intuitive tools and insights\non how to use adversarial robustness to improve it.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 16:03:46 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 17:47:48 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Ortiz-Jimenez", "Guillermo", ""], ["Modas", "Apostolos", ""], ["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Frossard", "Pascal", ""]]}, {"id": "2010.09641", "submitter": "Tony Zhao", "authors": "Tony Zhao, Jaeyoung Choi, Gerald Friedland", "title": "DIME: An Online Tool for the Visual Comparison of Cross-Modal Retrieval\n  Models", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-37734-2_61", "report-no": null, "categories": "cs.MM cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cross-modal retrieval relies on accurate models to retrieve relevant results\nfor queries across modalities such as image, text, and video. In this paper, we\nbuild upon previous work by tackling the difficulty of evaluating models both\nquantitatively and qualitatively quickly. We present DIME (Dataset, Index,\nModel, Embedding), a modality-agnostic tool that handles multimodal datasets,\ntrained models, and data preprocessors to support straightforward model\ncomparison with a web browser graphical user interface. DIME inherently\nsupports building modality-agnostic queryable indexes and extraction of\nrelevant feature embeddings, and thus effectively doubles as an efficient\ncross-modal tool to explore and search through datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 16:35:30 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Zhao", "Tony", ""], ["Choi", "Jaeyoung", ""], ["Friedland", "Gerald", ""]]}, {"id": "2010.09657", "submitter": "Nipun Sadvilkar", "authors": "Nipun Sadvilkar and Mark Neumann", "title": "PySBD: Pragmatic Sentence Boundary Disambiguation", "comments": "'PySBD: Pragmatic Sentence Boundary Disambiguation' is a short paper\n  (5 Pages with references) accepted into 2nd Workshop for Natural Language\n  Processing Open Source Software (NLP-OSS) at EMNLP 2020 happening on 19 Nov\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a rule-based sentence boundary disambiguation\nPython package that works out-of-the-box for 22 languages. We aim to provide a\nrealistic segmenter which can provide logical sentences even when the format\nand domain of the input text is unknown. In our work, we adapt the Golden Rules\nSet (a language-specific set of sentence boundary exemplars) originally\nimplemented as a ruby gem - pragmatic_segmenter - which we ported to Python\nwith additional improvements and functionality. PySBD passes 97.92% of the\nGolden Rule Set exemplars for English, an improvement of 25% over the next best\nopen-source Python tool.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 16:56:03 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Sadvilkar", "Nipun", ""], ["Neumann", "Mark", ""]]}, {"id": "2010.09662", "submitter": "Bernard Lange", "authors": "Bernard Lange, Masha Itkina and Mykel J. Kochenderfer", "title": "Attention Augmented ConvLSTM for Environment Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safe and proactive planning in robotic systems generally requires accurate\npredictions of the environment. Prior work on environment prediction applied\nvideo frame prediction techniques to bird's-eye view environment\nrepresentations, such as occupancy grids. ConvLSTM-based frameworks used\npreviously often result in significant blurring and vanishing of moving\nobjects, thus hindering their applicability for use in safety-critical\napplications. In this work, we propose two extensions to the ConvLSTM to\naddress these issues. We present the Temporal Attention Augmented ConvLSTM\n(TAAConvLSTM) and Self-Attention Augmented ConvLSTM (SAAConvLSTM) frameworks\nfor spatiotemporal occupancy prediction, and demonstrate improved performance\nover baseline architectures on the real-world KITTI and Waymo datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 16:57:24 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 01:10:47 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Lange", "Bernard", ""], ["Itkina", "Masha", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2010.09680", "submitter": "Ehsan Nowroozi", "authors": "Ehsan Nowroozi, Ali Dehghantanha, Reza M. Parizi, Kim-Kwang Raymond\n  Choo", "title": "A Survey of Machine Learning Techniques in Adversarial Image Forensics", "comments": "37 pages, 24 figures, Accepted to the Journal Computer and Security\n  (Elsevier)", "journal-ref": "2020", "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image forensic plays a crucial role in both criminal investigations (e.g.,\ndissemination of fake images to spread racial hate or false narratives about\nspecific ethnicity groups) and civil litigation (e.g., defamation).\nIncreasingly, machine learning approaches are also utilized in image forensics.\nHowever, there are also a number of limitations and vulnerabilities associated\nwith machine learning-based approaches, for example how to detect adversarial\n(image) examples, with real-world consequences (e.g., inadmissible evidence, or\nwrongful conviction). Therefore, with a focus on image forensics, this paper\nsurveys techniques that can be used to enhance the robustness of machine\nlearning-based binary manipulation detectors in various adversarial scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 17:16:38 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Nowroozi", "Ehsan", ""], ["Dehghantanha", "Ali", ""], ["Parizi", "Reza M.", ""], ["Choo", "Kim-Kwang Raymond", ""]]}, {"id": "2010.09687", "submitter": "Pankesh Patel", "authors": "Vatsal Patel and Sarth Kanani and Tapan Pathak and Pankesh Patel and\n  Muhammad Intizar Ali and John Breslin", "title": "A Demonstration of Smart Doorbell Design Using Federated Deep Learning", "comments": "6", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Smart doorbells have been playing an important role in protecting our modern\nhomes. Existing approaches of sending video streams to a centralized server (or\nCloud) for video analytics have been facing many challenges such as latency,\nbandwidth cost and more importantly users' privacy concerns. To address these\nchallenges, this paper showcases the ability of an intelligent smart doorbell\nbased on Federated Deep Learning, which can deploy and manage video analytics\napplications such as a smart doorbell across Edge and Cloud resources. This\nplatform can scale, work with multiple devices, seamlessly manage online\norchestration of the application components. The proposed framework is\nimplemented using state-of-the-art technology. We implement the Federated\nServer using the Flask framework, containerized using Nginx and Gunicorn, which\nis deployed on AWS EC2 and AWS Serverless architecture.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 17:22:34 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Patel", "Vatsal", ""], ["Kanani", "Sarth", ""], ["Pathak", "Tapan", ""], ["Patel", "Pankesh", ""], ["Ali", "Muhammad Intizar", ""], ["Breslin", "John", ""]]}, {"id": "2010.09770", "submitter": "Stephen Chung", "authors": "Stephen Chung", "title": "Every Hidden Unit Maximizing Output Weights Maximizes The Global Reward", "comments": "16 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a network of stochastic units trained on a reinforcement learning task,\none biologically plausible way of learning is to treat each unit as a\nreinforcement learning unit and train each unit by REINFORCE using the same\nglobal reward signal. In this case, only a global reward signal has to be\nbroadcast to all units, and the learning rule given is local. Although this\nlearning rule follows the gradient of return in expectation, it suffers from\nhigh variance and cannot be used to train a deep network in practice. In this\npaper, we propose an algorithm called Weight Maximization, which can\nsignificantly improve the speed of applying REINFORCE to all units.\nEssentially, we replace the global reward to each hidden unit with the change\nin the norm of output weights, such that each hidden unit in the network is\ntrying to maximize the norm of output weights instead of the global reward. We\nfound that the new algorithm can solve simple reinforcement learning tasks\nsignificantly faster than the baseline model. We also prove that the resulting\nlearning rule is approximately following gradient ascent on the reward in\nexpectation when applied to a multi-layer network of Bernoulli logistic unit.\nIt illustrates an example of intelligent behavior arising from a population of\nself-interested hedonistic neurons, which corresponds to Klopf's hedonistic\nneuron hypothesis.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 18:18:53 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Chung", "Stephen", ""]]}, {"id": "2010.09776", "submitter": "Weinan Zhang", "authors": "Ming Zhou, Jun Luo, Julian Villella, Yaodong Yang, David Rusu, Jiayu\n  Miao, Weinan Zhang, Montgomery Alban, Iman Fadakar, Zheng Chen, Aurora\n  Chongxi Huang, Ying Wen, Kimia Hassanzadeh, Daniel Graves, Dong Chen,\n  Zhengbang Zhu, Nhat Nguyen, Mohamed Elsayed, Kun Shao, Sanjeevan Ahilan,\n  Baokuan Zhang, Jiannan Wu, Zhengang Fu, Kasra Rezaee, Peyman Yadmellat,\n  Mohsen Rohani, Nicolas Perez Nieves, Yihan Ni, Seyedershad Banijamali,\n  Alexander Cowen Rivers, Zheng Tian, Daniel Palenicek, Haitham bou Ammar,\n  Hongbo Zhang, Wulong Liu, Jianye Hao, Jun Wang", "title": "SMARTS: Scalable Multi-Agent Reinforcement Learning Training School for\n  Autonomous Driving", "comments": "20 pages, 11 figures. Paper accepted to CoRL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-agent interaction is a fundamental aspect of autonomous driving in the\nreal world. Despite more than a decade of research and development, the problem\nof how to competently interact with diverse road users in diverse scenarios\nremains largely unsolved. Learning methods have much to offer towards solving\nthis problem. But they require a realistic multi-agent simulator that generates\ndiverse and competent driving interactions. To meet this need, we develop a\ndedicated simulation platform called SMARTS (Scalable Multi-Agent RL Training\nSchool). SMARTS supports the training, accumulation, and use of diverse\nbehavior models of road users. These are in turn used to create increasingly\nmore realistic and diverse interactions that enable deeper and broader research\non multi-agent interaction. In this paper, we describe the design goals of\nSMARTS, explain its basic architecture and its key features, and illustrate its\nuse through concrete multi-agent experiments on interactive scenarios. We\nopen-source the SMARTS platform and the associated benchmark tasks and\nevaluation metrics to encourage and empower research on multi-agent learning\nfor autonomous driving. Our code is available at\nhttps://github.com/huawei-noah/SMARTS.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 18:26:10 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 01:32:36 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhou", "Ming", ""], ["Luo", "Jun", ""], ["Villella", "Julian", ""], ["Yang", "Yaodong", ""], ["Rusu", "David", ""], ["Miao", "Jiayu", ""], ["Zhang", "Weinan", ""], ["Alban", "Montgomery", ""], ["Fadakar", "Iman", ""], ["Chen", "Zheng", ""], ["Huang", "Aurora Chongxi", ""], ["Wen", "Ying", ""], ["Hassanzadeh", "Kimia", ""], ["Graves", "Daniel", ""], ["Chen", "Dong", ""], ["Zhu", "Zhengbang", ""], ["Nguyen", "Nhat", ""], ["Elsayed", "Mohamed", ""], ["Shao", "Kun", ""], ["Ahilan", "Sanjeevan", ""], ["Zhang", "Baokuan", ""], ["Wu", "Jiannan", ""], ["Fu", "Zhengang", ""], ["Rezaee", "Kasra", ""], ["Yadmellat", "Peyman", ""], ["Rohani", "Mohsen", ""], ["Nieves", "Nicolas Perez", ""], ["Ni", "Yihan", ""], ["Banijamali", "Seyedershad", ""], ["Rivers", "Alexander Cowen", ""], ["Tian", "Zheng", ""], ["Palenicek", "Daniel", ""], ["Ammar", "Haitham bou", ""], ["Zhang", "Hongbo", ""], ["Liu", "Wulong", ""], ["Hao", "Jianye", ""], ["Wang", "Jun", ""]]}, {"id": "2010.09780", "submitter": "Wenhao Yu", "authors": "Wenhao Yu, Lingfei Wu, Yu Deng, Qingkai Zeng, Ruchi Mahindru, Sinem\n  Guven, Meng Jiang", "title": "Technical Question Answering across Tasks and Domains", "comments": "NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Building automatic technical support system is an important yet challenge\ntask. Conceptually, to answer a user question on a technical forum, a human\nexpert has to first retrieve relevant documents, and then read them carefully\nto identify the answer snippet. Despite huge success the researchers have\nachieved in coping with general domain question answering (QA), much less\nattentions have been paid for investigating technical QA. Specifically,\nexisting methods suffer from several unique challenges (i) the question and\nanswer rarely overlaps substantially and (ii) very limited data size. In this\npaper, we propose a novel framework of deep transfer learning to effectively\naddress technical QA across tasks and domains. To this end, we present an\nadjustable joint learning approach for document retrieval and reading\ncomprehension tasks. Our experiments on the TechQA demonstrates superior\nperformance compared with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 18:39:30 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 05:00:18 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Yu", "Wenhao", ""], ["Wu", "Lingfei", ""], ["Deng", "Yu", ""], ["Zeng", "Qingkai", ""], ["Mahindru", "Ruchi", ""], ["Guven", "Sinem", ""], ["Jiang", "Meng", ""]]}, {"id": "2010.09788", "submitter": "Yufei Feng", "authors": "Mo Yu, Xiaoxiao Guo, Yufei Feng, Xiaodan Zhu, Michael Greenspan,\n  Murray Campbell", "title": "Deriving Commonsense Inference Tasks from Interactive Fictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense reasoning simulates the human ability to make presumptions about\nour physical world, and it is an indispensable cornerstone in building general\nAI systems. We propose a new commonsense reasoning dataset based on human's\ninteractive fiction game playings as human players demonstrate plentiful and\ndiverse commonsense reasoning. The new dataset mitigates several limitations of\nthe prior art. Experiments show that our task is solvable to human experts with\nsufficient commonsense knowledge but poses challenges to existing machine\nreading models, with a big performance gap of more than 30%.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 19:02:34 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Yu", "Mo", ""], ["Guo", "Xiaoxiao", ""], ["Feng", "Yufei", ""], ["Zhu", "Xiaodan", ""], ["Greenspan", "Michael", ""], ["Campbell", "Murray", ""]]}, {"id": "2010.09803", "submitter": "Jie Zhao", "authors": "Jie Zhao, Huan Sun", "title": "Adversarial Training for Code Retrieval with Question-Description\n  Relevance Regularization", "comments": "Accepted to Findings of EMNLP 2020. 11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Code retrieval is a key task aiming to match natural and programming\nlanguages. In this work, we propose adversarial learning for code retrieval,\nthat is regularized by question-description relevance. First, we adapt a simple\nadversarial learning technique to generate difficult code snippets given the\ninput question, which can help the learning of code retrieval that faces\nbi-modal and data-scarce challenges. Second, we propose to leverage\nquestion-description relevance to regularize adversarial learning, such that a\ngenerated code snippet should contribute more to the code retrieval training\nloss, only if its paired natural language description is predicted to be less\nrelevant to the user given question. Experiments on large-scale code retrieval\ndatasets of two programming languages show that our adversarial learning method\nis able to improve the performance of state-of-the-art models. Moreover, using\nan additional duplicate question prediction model to regularize adversarial\nlearning further improves the performance, and this is more effective than\nusing the duplicated questions in strong multi-task learning baselines\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 19:32:03 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 05:49:02 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Zhao", "Jie", ""], ["Sun", "Huan", ""]]}, {"id": "2010.09808", "submitter": "Kuno Kim", "authors": "Kuno Kim, Akshat Jindal, Yang Song, Jiaming Song, Yanan Sui, Stefano\n  Ermon", "title": "Imitation with Neural Density Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for Imitation Learning (IL) via density estimation\nof the expert's occupancy measure followed by Maximum Occupancy Entropy\nReinforcement Learning (RL) using the density as a reward. Our approach\nmaximizes a non-adversarial model-free RL objective that provably lower bounds\nreverse Kullback-Leibler divergence between occupancy measures of the expert\nand imitator. We present a practical IL algorithm, Neural Density Imitation\n(NDI), which obtains state-of-the-art demonstration efficiency on benchmark\ncontrol tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 19:38:36 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Kim", "Kuno", ""], ["Jindal", "Akshat", ""], ["Song", "Yang", ""], ["Song", "Jiaming", ""], ["Sui", "Yanan", ""], ["Ermon", "Stefano", ""]]}, {"id": "2010.09832", "submitter": "Anurag Koul", "authors": "Anurag Koul, Varun V. Kumar, Alan Fern, Somdeb Majumdar", "title": "Dream and Search to Control: Latent Space Planning for Continuous\n  Control", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning and planning with latent space dynamics has been shown to be useful\nfor sample efficiency in model-based reinforcement learning (MBRL) for discrete\nand continuous control tasks. In particular, recent work, for discrete action\nspaces, demonstrated the effectiveness of latent-space planning via Monte-Carlo\nTree Search (MCTS) for bootstrapping MBRL during learning and at test time.\nHowever, the potential gains from latent-space tree search have not yet been\ndemonstrated for environments with continuous action spaces. In this work, we\npropose and explore an MBRL approach for continuous action spaces based on\ntree-based planning over learned latent dynamics. We show that it is possible\nto demonstrate the types of bootstrapping benefits as previously shown for\ndiscrete spaces. In particular, the approach achieves improved sample\nefficiency and performance on a majority of challenging continuous-control\nbenchmarks compared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 20:10:51 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Koul", "Anurag", ""], ["Kumar", "Varun V.", ""], ["Fern", "Alan", ""], ["Majumdar", "Somdeb", ""]]}, {"id": "2010.09839", "submitter": "Alexander D'yakonov", "authors": "Dmitry Medvedev, Alexander D'yakonov", "title": "New Properties of the Data Distillation Method When Working With Tabular\n  Data", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data distillation is the problem of reducing the volume oftraining data while\nkeeping only the necessary information. With thispaper, we deeper explore the\nnew data distillation algorithm, previouslydesigned for image data. Our\nexperiments with tabular data show thatthe model trained on distilled samples\ncan outperform the model trainedon the original dataset. One of the problems of\nthe considered algorithmis that produced data has poor generalization on models\nwith differenthyperparameters. We show that using multiple architectures during\ndistillation can help overcome this problem.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 20:27:58 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Medvedev", "Dmitry", ""], ["D'yakonov", "Alexander", ""]]}, {"id": "2010.09842", "submitter": "Sanjai Narain", "authors": "Sanjai Narain, Emily Mak, Dana Chee, Todd Huster, Jeremy Cohen,\n  Kishore Pochiraju, Brendan Englot, Niraj K. Jha, Karthik Narayan", "title": "Robot Design With Neural Networks, MILP Solvers and Active Learning", "comments": "22 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Central to the design of many robot systems and their controllers is solving\na constrained blackbox optimization problem. This paper presents CNMA, a new\nmethod of solving this problem that is conservative in the number of\npotentially expensive blackbox function evaluations; allows specifying complex,\neven recursive constraints directly rather than as hard-to-design penalty or\nbarrier functions; and is resilient to the non-termination of function\nevaluations. CNMA leverages the ability of neural networks to approximate any\ncontinuous function, their transformation into equivalent mixed integer linear\nprograms (MILPs) and their optimization subject to constraints with industrial\nstrength MILP solvers. A new learning-from-failure step guides the learning to\nbe relevant to solving the constrained optimization problem. Thus, the amount\nof learning is orders of magnitude smaller than that needed to learn functions\nover their entire domains. CNMA is illustrated with the design of several\nrobotic systems: wave-energy propelled boat, lunar lander, hexapod, cartpole,\nacrobot and parallel parking. These range from 6 real-valued dimensions to 36.\nWe show that CNMA surpasses the Nelder-Mead, Gaussian and Random Search\noptimization methods against the metric of number of function evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 20:33:46 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 00:27:50 GMT"}, {"version": "v3", "created": "Sat, 16 Jan 2021 07:25:39 GMT"}, {"version": "v4", "created": "Mon, 8 Feb 2021 16:15:55 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Narain", "Sanjai", ""], ["Mak", "Emily", ""], ["Chee", "Dana", ""], ["Huster", "Todd", ""], ["Cohen", "Jeremy", ""], ["Pochiraju", "Kishore", ""], ["Englot", "Brendan", ""], ["Jha", "Niraj K.", ""], ["Narayan", "Karthik", ""]]}, {"id": "2010.09851", "submitter": "Disi Ji", "authors": "Disi Ji, Padhraic Smyth, Mark Steyvers", "title": "Can I Trust My Fairness Metric? Assessing Fairness with Unlabeled Data\n  and Bayesian Inference", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of reliably assessing group fairness when labeled\nexamples are few but unlabeled examples are plentiful. We propose a general\nBayesian framework that can augment labeled data with unlabeled data to produce\nmore accurate and lower-variance estimates compared to methods based on labeled\ndata alone. Our approach estimates calibrated scores for unlabeled examples in\neach group using a hierarchical latent variable model conditioned on labeled\nexamples. This in turn allows for inference of posterior distributions with\nassociated notions of uncertainty for a variety of group fairness metrics. We\ndemonstrate that our approach leads to significant and consistent reductions in\nestimation error across multiple well-known fairness datasets, sensitive\nattributes, and predictive models. The results show the benefits of using both\nunlabeled data and Bayesian inference in terms of assessing whether a\nprediction model is fair or not.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 20:42:18 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Ji", "Disi", ""], ["Smyth", "Padhraic", ""], ["Steyvers", "Mark", ""]]}, {"id": "2010.09890", "submitter": "Xavier Puig", "authors": "Xavier Puig, Tianmin Shu, Shuang Li, Zilin Wang, Yuan-Hong Liao,\n  Joshua B. Tenenbaum, Sanja Fidler, Antonio Torralba", "title": "Watch-And-Help: A Challenge for Social Perception and Human-AI\n  Collaboration", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we introduce Watch-And-Help (WAH), a challenge for testing\nsocial intelligence in agents. In WAH, an AI agent needs to help a human-like\nagent perform a complex household task efficiently. To succeed, the AI agent\nneeds to i) understand the underlying goal of the task by watching a single\ndemonstration of the human-like agent performing the same task (social\nperception), and ii) coordinate with the human-like agent to solve the task in\nan unseen environment as fast as possible (human-AI collaboration). For this\nchallenge, we build VirtualHome-Social, a multi-agent household environment,\nand provide a benchmark including both planning and learning based baselines.\nWe evaluate the performance of AI agents with the human-like agent as well as\nwith real humans using objective metrics and subjective user ratings.\nExperimental results demonstrate that the proposed challenge and virtual\nenvironment enable a systematic evaluation on the important aspects of machine\nsocial intelligence at scale.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 21:48:31 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 13:08:55 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Puig", "Xavier", ""], ["Shu", "Tianmin", ""], ["Li", "Shuang", ""], ["Wang", "Zilin", ""], ["Liao", "Yuan-Hong", ""], ["Tenenbaum", "Joshua B.", ""], ["Fidler", "Sanja", ""], ["Torralba", "Antonio", ""]]}, {"id": "2010.09895", "submitter": "Sarala Padi Dr", "authors": "Sarala Padi, Dinesh Manocha, Ram D.Sriram", "title": "Multi-Window Data Augmentation Approach for Speech Emotion Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Multi-Window Data Augmentation (MWA-SER) approach for speech\nemotion recognition. MWA-SER is a unimodal approach that focuses on two key\nconcepts; designing the speech augmentation method and building the deep\nlearning model to recognize the underlying emotion of an audio signal. Our\nproposed multi-window augmentation approach generates additional data samples\nfrom the speech signal by employing multiple window sizes in the audio feature\nextraction process. We show that our augmentation method, combined with a deep\nlearning model, improves speech emotion recognition performance. We evaluate\nthe performance of our approach on three benchmark datasets: IEMOCAP, SAVEE,\nand RAVDESS. We show that the multi-window model improves the SER performance\nand outperforms a single-window model. The notion of finding the best window\nsize is an essential step in audio feature extraction. We perform extensive\nexperimental evaluations to find the best window choice and explore the\nwindowing effect for SER analysis.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 22:15:03 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 00:13:07 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 18:17:46 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Padi", "Sarala", ""], ["Manocha", "Dinesh", ""], ["Sriram", "Ram D.", ""]]}, {"id": "2010.09916", "submitter": "Almuthanna Nassar", "authors": "Almuthanna Nassar, and Yasin Yilmaz", "title": "Deep Reinforcement Learning for Adaptive Network Slicing in 5G for\n  Intelligent Vehicular Systems and Smart Cities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent vehicular systems and smart city applications are the fastest\ngrowing Internet of things (IoT) implementations at a compound annual growth\nrate of 30%. In view of the recent advances in IoT devices and the emerging new\nbreed of IoT applications driven by artificial intelligence (AI), fog radio\naccess network (F-RAN) has been recently introduced for the fifth generation\n(5G) wireless communications to overcome the latency limitations of cloud-RAN\n(C-RAN). We consider the network slicing problem of allocating the limited\nresources at the network edge (fog nodes) to vehicular and smart city users\nwith heterogeneous latency and computing demands in dynamic environments. We\ndevelop a network slicing model based on a cluster of fog nodes (FNs)\ncoordinated with an edge controller (EC) to efficiently utilize the limited\nresources at the network edge. For each service request in a cluster, the EC\ndecides which FN to execute the task, i.e., locally serve the request at the\nedge, or to reject the task and refer it to the cloud. We formulate the problem\nas infinite-horizon Markov decision process (MDP) and propose a deep\nreinforcement learning (DRL) solution to adaptively learn the optimal slicing\npolicy. The performance of the proposed DRL-based slicing method is evaluated\nby comparing it with other slicing approaches in dynamic environments and for\ndifferent scenarios of design objectives. Comprehensive simulation results\ncorroborate that the proposed DRL-based EC quickly learns the optimal policy\nthrough interaction with the environment, which enables adaptive and automated\nnetwork slicing for efficient resource allocation in dynamic vehicular and\nsmart city environments.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 23:30:08 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Nassar", "Almuthanna", ""], ["Yilmaz", "Yasin", ""]]}, {"id": "2010.09919", "submitter": "Alexey Ignatiev", "authors": "Jinqiang Yu, Alexey Ignatiev, Pierre Le Bodic, Peter J. Stuckey", "title": "Optimal Decision Lists using SAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision lists are one of the most easily explainable machine learning\nmodels. Given the renewed emphasis on explainable machine learning decisions,\nthis machine learning model is increasingly attractive, combining small size\nand clear explainability. In this paper, we show for the first time how to\nconstruct optimal \"perfect\" decision lists which are perfectly accurate on the\ntraining data, and minimal in size, making use of modern SAT solving\ntechnology. We also give a new method for determining optimal sparse decision\nlists, which trade off size and accuracy. We contrast the size and test\naccuracy of optimal decisions lists versus optimal decision sets, as well as\nother state-of-the-art methods for determining optimal decision lists. We also\nexamine the size of average explanations generated by decision sets and\ndecision lists.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 23:33:42 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Yu", "Jinqiang", ""], ["Ignatiev", "Alexey", ""], ["Bodic", "Pierre Le", ""], ["Stuckey", "Peter J.", ""]]}, {"id": "2010.09926", "submitter": "Neema Kotonya", "authors": "Neema Kotonya and Francesca Toni", "title": "Explainable Automated Fact-Checking for Public Health Claims", "comments": "Accepted to EMNLP 2020. 15 pages, 7 figures, 9 tables. The dataset is\n  available at https://github.com/neemakot/Health-Fact-Checking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact-checking is the task of verifying the veracity of claims by assessing\ntheir assertions against credible evidence. The vast majority of fact-checking\nstudies focus exclusively on political claims. Very little research explores\nfact-checking for other topics, specifically subject matters for which\nexpertise is required. We present the first study of explainable fact-checking\nfor claims which require specific expertise. For our case study we choose the\nsetting of public health. To support this case study we construct a new dataset\nPUBHEALTH of 11.8K claims accompanied by journalist crafted, gold standard\nexplanations (i.e., judgments) to support the fact-check labels for claims. We\nexplore two tasks: veracity prediction and explanation generation. We also\ndefine and evaluate, with humans and computationally, three coherence\nproperties of explanation quality. Our results indicate that, by training on\nin-domain data, gains can be made in explainable, automated fact-checking for\nclaims which require specific expertise.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 23:51:33 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Kotonya", "Neema", ""], ["Toni", "Francesca", ""]]}, {"id": "2010.09927", "submitter": "Arvind Srikantan", "authors": "Karthik Radhakrishnan, Arvind Srikantan, Xi Victoria Lin", "title": "ColloQL: Robust Cross-Domain Text-to-SQL Over Search Queries", "comments": "IntEx-SemPar Workshop at EMNLP 2020, 12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translating natural language utterances to executable queries is a helpful\ntechnique in making the vast amount of data stored in relational databases\naccessible to a wider range of non-tech-savvy end users. Prior work in this\narea has largely focused on textual input that is linguistically correct and\nsemantically unambiguous. However, real-world user queries are often succinct,\ncolloquial, and noisy, resembling the input of a search engine. In this work,\nwe introduce data augmentation techniques and a sampling-based content-aware\nBERT model (ColloQL) to achieve robust text-to-SQL modeling over natural\nlanguage search (NLS) questions. Due to the lack of evaluation data, we curate\na new dataset of NLS questions and demonstrate the efficacy of our approach.\nColloQL's superior performance extends to well-formed text, achieving 84.9%\n(logical) and 90.7% (execution) accuracy on the WikiSQL dataset, making it, to\nthe best of our knowledge, the highest performing model that does not use\nexecution guided decoding.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 23:53:17 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Radhakrishnan", "Karthik", ""], ["Srikantan", "Arvind", ""], ["Lin", "Xi Victoria", ""]]}, {"id": "2010.09933", "submitter": "Ju-Seung Byun", "authors": "Ju-Seung Byun, Byungmoon Kim, Huamin Wang", "title": "Proximal Policy Gradient: PPO with Policy Gradient", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new algorithm PPG (Proximal Policy Gradient),\nwhich is close to both VPG (vanilla policy gradient) and PPO (proximal policy\noptimization). The PPG objective is a partial variation of the VPG objective\nand the gradient of the PPG objective is exactly same as the gradient of the\nVPG objective. To increase the number of policy update iterations, we introduce\nthe advantage-policy plane and design a new clipping strategy. We perform\nexperiments in OpenAI Gym and Bullet robotics environments for ten random\nseeds. The performance of PPG is comparable to PPO, and the entropy decays\nslower than PPG. Thus we show that performance similar to PPO can be obtained\nby using the gradient formula from the original policy gradient theorem.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 00:14:57 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Byun", "Ju-Seung", ""], ["Kim", "Byungmoon", ""], ["Wang", "Huamin", ""]]}, {"id": "2010.09954", "submitter": "Runzhe Yang", "authors": "Runzhe Yang, Jingxiao Chen, Karthik Narasimhan", "title": "Improving Dialog Systems for Negotiation with Personality Modeling", "comments": "ACL 2021. 12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the ability to model and infer personality types of\nopponents, predict their responses, and use this information to adapt a dialog\nagent's high-level strategy in negotiation tasks. Inspired by the idea of\nincorporating a theory of mind (ToM) into machines, we introduce a\nprobabilistic formulation to encapsulate the opponent's personality type during\nboth learning and inference. We test our approach on the CraigslistBargain\ndataset and show that our method using ToM inference achieves a 20% higher\ndialog agreement rate compared to baselines on a mixed population of opponents.\nWe also find that our model displays diverse negotiation behavior with\ndifferent types of opponents.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 01:46:03 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 06:28:57 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Yang", "Runzhe", ""], ["Chen", "Jingxiao", ""], ["Narasimhan", "Karthik", ""]]}, {"id": "2010.09964", "submitter": "Sayyed Jaffar Ali Raza", "authors": "Sayyed Jaffar Ali Raza, Apan Dastider, Mingjie Lin", "title": "Survivable Hyper-Redundant Robotic Arm with Bayesian Policy Morphing", "comments": null, "journal-ref": "2020 IEEE 16th International Conference on Automation Science and\n  Engineering (CASE)", "doi": "10.1109/CASE48305.2020.9216963", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a Bayesian reinforcement learning framework that\nallows robotic manipulators to adaptively recover from random mechanical\nfailures autonomously, hence being survivable. To this end, we formulate the\nframework of Bayesian Policy Morphing (BPM) that enables a robot agent to\nself-modify its learned policy after the diminution of its maneuvering\ndimensionality. We build upon existing actor-critic framework, and extend it to\nperform policy gradient updates as posterior learning, taking past policy\nupdates as prior distributions. We show that policy search, in the direction\nbiased by prior experience, significantly improves learning efficiency in terms\nof sampling requirements. We demonstrate our results on an 8-DOF robotic arm\nwith our algorithm of BPM, while intentionally disabling random joints with\ndifferent damage types like unresponsive joints, constant offset errors and\nangular imprecision. Our results have shown that, even with physical damages,\nthe robotic arm can still successfully maintain its functionality to accurately\nlocate and grasp a given target object.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 02:14:22 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Raza", "Sayyed Jaffar Ali", ""], ["Dastider", "Apan", ""], ["Lin", "Mingjie", ""]]}, {"id": "2010.09997", "submitter": "Haohan Wang", "authors": "Haohan Wang, Peiyan Zhang, Eric P. Xing", "title": "Word Shape Matters: Robust Machine Translation with Visual Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation has achieved remarkable empirical performance over\nstandard benchmark datasets, yet recent evidence suggests that the models can\nstill fail easily dealing with substandard inputs such as misspelled words, To\novercome this issue, we introduce a new encoding heuristic of the input symbols\nfor character-level NLP models: it encodes the shape of each character through\nthe images depicting the letters when printed. We name this new strategy visual\nembedding and it is expected to improve the robustness of NLP models because\nhumans also process the corpus visually through printed letters, instead of\nmachinery one-hot vectors. Empirically, our method improves models' robustness\nagainst substandard inputs, even in the test scenario where the models are\ntested with the noises that are beyond what is available during the training\nphase.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 04:08:03 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Wang", "Haohan", ""], ["Zhang", "Peiyan", ""], ["Xing", "Eric P.", ""]]}, {"id": "2010.10004", "submitter": "Luis Leal", "authors": "Luis Leal, Marvin Castillo, Fernando Juarez, Erick Ramirez, Mildred\n  Aspuac, Diana Letona", "title": "Convolutional-LSTM for Multi-Image to Single Output Medical Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical head CT-scan imaging has been successfully combined with deep\nlearning for medical diagnostics of head diseases and lesions[1]. State of the\nart classification models and algorithms for this task usually are based on 3d\nconvolution layers for volumetric data on a supervised learning setting (1\ninput volume, 1 prediction per patient) or 2d convolution layers in a\nsupervised setting (1 input image, 1 prediction per image). However a very\ncommon scenario in developing countries is to have the volume metadata lost due\nmultiple reasons for example formatting conversion in images (for example\n.dicom to jpg), in this scenario the doctor analyses the collection of images\nand then emits a single diagnostic for the patient (with possibly an unfixed\nand variable number of images per patient) , this prevents it from being\npossible to use state of the art 3d models, but also is not possible to convert\nit to a supervised problem in a (1 image,1 diagnostic) setting because\ndifferent angles or positions of the images for a single patient may not\ncontain the disease or lesion. In this study we propose a solution for this\nscenario by combining 2d convolutional[2] models with sequence models which\ngenerate a prediction only after all images have been processed by the model\nfor a given patient \\(i\\), this creates a multi-image to single-diagnostic\nsetting \\(y^i=f(x_1,x_2,..,x_n)\\) where \\(n\\) may be different between\npatients. The experimental results demonstrate that it is possible to get a\nmulti-image to single diagnostic model which mimics human doctor diagnostic\nprocess: evaluate the collection of patient images and then use important\ninformation in memory to decide a single diagnostic for the patient.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 04:30:09 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Leal", "Luis", ""], ["Castillo", "Marvin", ""], ["Juarez", "Fernando", ""], ["Ramirez", "Erick", ""], ["Aspuac", "Mildred", ""], ["Letona", "Diana", ""]]}, {"id": "2010.10019", "submitter": "Thao Minh Le", "authors": "Thao Minh Le, Vuong Le, Svetha Venkatesh, Truyen Tran", "title": "Hierarchical Conditional Relation Networks for Multimodal Video Question\n  Answering", "comments": "Major extension of our CVPR'20 paper to handle long video with text.\n  arXiv admin note: substantial text overlap with arXiv:2002.10698", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video QA challenges modelers in multiple fronts. Modeling video necessitates\nbuilding not only spatio-temporal models for the dynamic visual channel but\nalso multimodal structures for associated information channels such as\nsubtitles or audio. Video QA adds at least two more layers of complexity -\nselecting relevant content for each channel in the context of the linguistic\nquery, and composing spatio-temporal concepts and relations in response to the\nquery. To address these requirements, we start with two insights: (a) content\nselection and relation construction can be jointly encapsulated into a\nconditional computational structure, and (b) video-length structures can be\ncomposed hierarchically. For (a) this paper introduces a general-reusable\nneural unit dubbed Conditional Relation Network (CRN) taking as input a set of\ntensorial objects and translating into a new set of objects that encode\nrelations of the inputs. The generic design of CRN helps ease the common\ncomplex model building process of Video QA by simple block stacking with\nflexibility in accommodating input modalities and conditioning features across\nboth different domains. As a result, we realize insight (b) by introducing\nHierarchical Conditional Relation Networks (HCRN) for Video QA. The HCRN\nprimarily aims at exploiting intrinsic properties of the visual content of a\nvideo and its accompanying channels in terms of compositionality, hierarchy,\nand near and far-term relation. HCRN is then applied for Video QA in two forms,\nshort-form where answers are reasoned solely from the visual content, and\nlong-form where associated information, such as subtitles, presented. Our\nrigorous evaluations show consistent improvements over SOTAs on well-studied\nbenchmarks including large-scale real-world datasets such as TGIF-QA and TVQA,\ndemonstrating the strong capabilities of our CRN unit and the HCRN for complex\ndomains such as Video QA.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 02:31:06 GMT"}, {"version": "v2", "created": "Sun, 3 Jan 2021 07:11:23 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Le", "Thao Minh", ""], ["Le", "Vuong", ""], ["Venkatesh", "Svetha", ""], ["Tran", "Truyen", ""]]}, {"id": "2010.10028", "submitter": "David Pastor-Escuredo", "authors": "David Pastor-Escuredo and Ricardo Vinuesa", "title": "Towards and Ethical Framework in the Complex Digital Era", "comments": "arXiv admin note: text overlap with arXiv:2003.06530", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Since modernity, ethic has been progressively fragmented into specific\ncommunities of practice. The digital revolution enabled by AI and Data is\nbringing ethical wicked problems in the crossroads of technology and behavior.\nHowever, the need of a comprehensive and constructive ethical framework is\nemerging as digital platforms connect us globally. The unequal structure of the\nglobal system makes that dynamic changes and systemic problems impact more on\nthose that are most vulnerable. Ethical frameworks based only on the\nindividual-level are not longer sufficient. A new ethical vision must comprise\nthe understanding of the scales and complex interconnections of social systems.\nMany of these systems are internally fragile and very sensitive to external\nfactors and threats, which turns into unethical situations that require\nsystemic solutions. The high scale nature of digital technology that expands\nglobally has also an impact at the individual level having the risk to make\nhumans beings more homogeneous, predictable and ultimately controllable. To\npreserve the core of humanity ethic must take a stand to preserve and keep\npromoting individual rights and uniqueness and cultural heterogeneity tackling\nthe negative trends and impact of digitalization. Only combining human-centered\nand collectiveness-oriented digital development it will be possible to\nconstruct new social models and human-machine interactions that are ethical.\nThis vision requires science to enhance ethical frameworks and principles with\nthe actionable insights of relationships and properties of the social systems\nthat may not be evident and need to be quantified and understood to be solved.\nArtificial Intelligence is both a risk and and opportunity for an ethical\ndevelopment, thus we need a conceptual construct that drives towards a better\ndigitalizated world.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 15:28:04 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Pastor-Escuredo", "David", ""], ["Vinuesa", "Ricardo", ""]]}, {"id": "2010.10038", "submitter": "Sameer Dharur", "authors": "Sameer Dharur, Purva Tendulkar, Dhruv Batra, Devi Parikh, Ramprasaath\n  R. Selvaraju", "title": "SOrT-ing VQA Models : Contrastive Gradient Learning for Improved\n  Consistency", "comments": "Accepted to the NeurIPS 2020 workshop on Interpretable Inductive\n  Biases and Physically Structured Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in Visual Question Answering (VQA) has revealed\nstate-of-the-art models to be inconsistent in their understanding of the world\n-- they answer seemingly difficult questions requiring reasoning correctly but\nget simpler associated sub-questions wrong. These sub-questions pertain to\nlower level visual concepts in the image that models ideally should understand\nto be able to answer the higher level question correctly. To address this, we\nfirst present a gradient-based interpretability approach to determine the\nquestions most strongly correlated with the reasoning question on an image, and\nuse this to evaluate VQA models on their ability to identify the relevant\nsub-questions needed to answer a reasoning question. Next, we propose a\ncontrastive gradient learning based approach called Sub-question Oriented\nTuning (SOrT) which encourages models to rank relevant sub-questions higher\nthan irrelevant questions for an <image, reasoning-question> pair. We show that\nSOrT improves model consistency by upto 6.5% points over existing baselines,\nwhile also improving visual grounding.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 05:15:48 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 02:11:13 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Dharur", "Sameer", ""], ["Tendulkar", "Purva", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Selvaraju", "Ramprasaath R.", ""]]}, {"id": "2010.10041", "submitter": "Chi-Liang Liu", "authors": "Chi-Liang Liu and Tsung-Yuan Hsu and Yung-Sung Chuang and Chung-Yi Li\n  and Hung-yi Lee", "title": "Language Representation in Multilingual BERT and its applications to\n  improve Cross-lingual Generalization", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A token embedding in multilingual BERT (m-BERT) contains both language and\nsemantic information. We find that representation of a language can be obtained\nby simply averaging the embeddings of the tokens of the language. With the\nlanguage representation, we can control the output languages of multilingual\nBERT by manipulating the token embeddings and achieve unsupervised token\ntranslation. We further propose a computationally cheap but effective approach\nto improve the cross-lingual ability of m-BERT based on the observation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 05:41:35 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 07:26:02 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 05:47:46 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Liu", "Chi-Liang", ""], ["Hsu", "Tsung-Yuan", ""], ["Chuang", "Yung-Sung", ""], ["Li", "Chung-Yi", ""], ["Lee", "Hung-yi", ""]]}, {"id": "2010.10048", "submitter": "Renjie Zheng", "authors": "Renjie Zheng, Mingbo Ma, Baigong Zheng, Kaibo Liu, Jiahong Yuan,\n  Kenneth Church, Liang Huang", "title": "Fluent and Low-latency Simultaneous Speech-to-Speech Translation with\n  Self-adaptive Training", "comments": "10 pages, accepted by Findings of EMNLP 2020", "journal-ref": "Findings of EMNLP 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous speech-to-speech translation is widely useful but extremely\nchallenging, since it needs to generate target-language speech concurrently\nwith the source-language speech, with only a few seconds delay. In addition, it\nneeds to continuously translate a stream of sentences, but all recent solutions\nmerely focus on the single-sentence scenario. As a result, current approaches\naccumulate latencies progressively when the speaker talks faster, and introduce\nunnatural pauses when the speaker talks slower. To overcome these issues, we\npropose Self-Adaptive Translation (SAT) which flexibly adjusts the length of\ntranslations to accommodate different source speech rates. At similar levels of\ntranslation quality (as measured by BLEU), our method generates more fluent\ntarget speech (as measured by the naturalness metric MOS) with substantially\nlower latency than the baseline, in both Zh <-> En directions.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 06:02:15 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 19:12:17 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Zheng", "Renjie", ""], ["Ma", "Mingbo", ""], ["Zheng", "Baigong", ""], ["Liu", "Kaibo", ""], ["Yuan", "Jiahong", ""], ["Church", "Kenneth", ""], ["Huang", "Liang", ""]]}, {"id": "2010.10051", "submitter": "Jieqi Shi", "authors": "Jieqi Shi, Peiliang Li, Shaojie Shen", "title": "Tracking from Patterns: Learning Corresponding Patterns in Point Clouds\n  for 3D Object Tracking", "comments": "4 pages, ECCV2020 Workshop on Perception for Autonomous\n  Driving(PAD2020)", "journal-ref": "ECCV2020 Workshop on Perception for Autonomous Driving(PAD2020)", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robust 3D object tracker which continuously tracks surrounding objects and\nestimates their trajectories is key for self-driving vehicles. Most existing\ntracking methods employ a tracking-by-detection strategy, which usually\nrequires complex pair-wise similarity computation and neglects the nature of\ncontinuous object motion. In this paper, we propose to directly learn 3D object\ncorrespondences from temporal point cloud data and infer the motion information\nfrom correspondence patterns. We modify the standard 3D object detector to\nprocess two lidar frames at the same time and predict bounding box pairs for\nthe association and motion estimation tasks. We also equip our pipeline with a\nsimple yet effective velocity smoothing module to estimate consistent object\nmotion. Benifiting from the learned correspondences and motion refinement, our\nmethod exceeds the existing 3D tracking methods on both the KITTI and larger\nscale Nuscenes dataset.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 06:07:20 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Shi", "Jieqi", ""], ["Li", "Peiliang", ""], ["Shen", "Shaojie", ""]]}, {"id": "2010.10079", "submitter": "Dinghuai Zhang", "authors": "Yanzhi Chen, Dinghuai Zhang, Michael Gutmann, Aaron Courville,\n  Zhanxing Zhu", "title": "Neural Approximate Sufficient Statistics for Implicit Models", "comments": "ICLR2021 spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the fundamental problem of how to automatically construct summary\nstatistics for implicit generative models where the evaluation of the\nlikelihood function is intractable, but sampling data from the model is\npossible. The idea is to frame the task of constructing sufficient statistics\nas learning mutual information maximizing representations of the data with the\nhelp of deep neural networks. The infomax learning procedure does not need to\nestimate any density or density ratio. We apply our approach to both\ntraditional approximate Bayesian computation and recent neural likelihood\nmethods, boosting their performance on a range of tasks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 07:11:40 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 13:35:14 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Chen", "Yanzhi", ""], ["Zhang", "Dinghuai", ""], ["Gutmann", "Michael", ""], ["Courville", "Aaron", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "2010.10090", "submitter": "Guangda Ji", "authors": "Guangda Ji, Zhanxing Zhu", "title": "Knowledge Distillation in Wide Neural Networks: Risk Bound, Data\n  Efficiency and Imperfect Teacher", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation is a strategy of training a student network with guide\nof the soft output from a teacher network. It has been a successful method of\nmodel compression and knowledge transfer. However, currently knowledge\ndistillation lacks a convincing theoretical understanding. On the other hand,\nrecent finding on neural tangent kernel enables us to approximate a wide neural\nnetwork with a linear model of the network's random features. In this paper, we\ntheoretically analyze the knowledge distillation of a wide neural network.\nFirst we provide a transfer risk bound for the linearized model of the network.\nThen we propose a metric of the task's training difficulty, called data\ninefficiency. Based on this metric, we show that for a perfect teacher, a high\nratio of teacher's soft labels can be beneficial. Finally, for the case of\nimperfect teacher, we find that hard labels can correct teacher's wrong\nprediction, which explains the practice of mixing hard and soft labels.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 07:33:21 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Ji", "Guangda", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "2010.10103", "submitter": "Sungho Suh", "authors": "Sungho Suh, Jihun Kim, Paul Lukowicz and Yong Oh Lee", "title": "Two-stage generative adversarial networks for document image\n  binarization with color noise and background removal", "comments": "Submitted to Pattern Recognition, Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document image enhancement and binarization methods are often used to improve\nthe accuracy and efficiency of document image analysis tasks such as text\nrecognition. Traditional non-machine-learning methods are constructed on\nlow-level features in an unsupervised manner but have difficulty with\nbinarization on documents with severely degraded backgrounds. Convolutional\nneural network-based methods focus only on grayscale images and on local\ntextual features. In this paper, we propose a two-stage color document image\nenhancement and binarization method using generative adversarial neural\nnetworks. In the first stage, four color-independent adversarial networks are\ntrained to extract color foreground information from an input image for\ndocument image enhancement. In the second stage, two independent adversarial\nnetworks with global and local features are trained for image binarization of\ndocuments of variable size. For the adversarial neural networks, we formulate\nloss functions between a discriminator and generators having an encoder-decoder\nstructure. Experimental results show that the proposed method achieves better\nperformance than many classical and state-of-the-art algorithms over the\nDocument Image Binarization Contest (DIBCO) datasets, the LRDE Document\nBinarization Dataset (LRDE DBD), and our shipping label image dataset. We plan\nto release the shipping label dataset as well as our implementation code at\ngithub.com/opensuh/DocumentBinarization/.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 07:51:50 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 16:50:09 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 08:17:44 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Suh", "Sungho", ""], ["Kim", "Jihun", ""], ["Lukowicz", "Paul", ""], ["Lee", "Yong Oh", ""]]}, {"id": "2010.10131", "submitter": "Chao Yang", "authors": "Min Li and Chuanfu Xiao and Chao Yang", "title": "a-Tucker: Input-Adaptive and Matricization-Free Tucker Decomposition for\n  Dense Tensors on CPUs and GPUs", "comments": "10pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tucker decomposition is one of the most popular models for analyzing and\ncompressing large-scale tensorial data. Existing Tucker decomposition\nalgorithms usually rely on a single solver to compute the factor matrices and\ncore tensor, and are not flexible enough to adapt with the diversities of the\ninput data and the hardware. Moreover, to exploit highly efficient GEMM\nkernels, most Tucker decomposition implementations make use of explicit\nmatricizations, which could introduce extra costs in terms of data conversion\nand memory usage. In this paper, we present a-Tucker, a new framework for\ninput-adaptive and matricization-free Tucker decomposition of dense tensors. A\nmode-wise flexible Tucker decomposition algorithm is proposed to enable the\nswitch of different solvers for the factor matrices and core tensor, and a\nmachine-learning adaptive solver selector is applied to automatically cope with\nthe variations of both the input data and the hardware. To further improve the\nperformance and enhance the memory efficiency, we implement a-Tucker in a fully\nmatricization-free manner without any conversion between tensors and matrices.\nExperiments with a variety of synthetic and real-world tensors show that\na-Tucker can substantially outperform existing works on both CPUs and GPUs.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 08:52:14 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Li", "Min", ""], ["Xiao", "Chuanfu", ""], ["Yang", "Chao", ""]]}, {"id": "2010.10150", "submitter": "Wei Ping", "authors": "Sashank Santhanam, Wei Ping, Raul Puri, Mohammad Shoeybi, Mostofa\n  Patwary, Bryan Catanzaro", "title": "Local Knowledge Powered Conversational Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art conversational agents have advanced significantly in\nconjunction with the use of large transformer-based language models. However,\neven with these advancements, conversational agents still lack the ability to\nproduce responses that are informative and coherent with the local context. In\nthis work, we propose a dialog framework that incorporates both local knowledge\nas well as users' past dialogues to generate high quality conversations. We\nintroduce an approach to build a dataset based on Reddit conversations, where\noutbound URL links are widely available in the conversations and the\nhyperlinked documents can be naturally included as local external knowledge.\nUsing our framework and dataset, we demonstrate that incorporating local\nknowledge can largely improve informativeness, coherency and realisticness\nmeasures using human evaluations. In particular, our approach consistently\noutperforms the state-of-the-art conversational model on the Reddit dataset\nacross all three measures. We also find that scaling the size of our models\nfrom 117M to 8.3B parameters yields consistent improvement of validation\nperplexity as well as human evaluated metrics. Our model with 8.3B parameters\ncan generate human-like responses as rated by various human evaluations in a\nsingle-turn dialog setting.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 09:34:40 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Santhanam", "Sashank", ""], ["Ping", "Wei", ""], ["Puri", "Raul", ""], ["Shoeybi", "Mohammad", ""], ["Patwary", "Mostofa", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "2010.10154", "submitter": "Zhongxiang Dai", "authors": "Zhongxiang Dai, Kian Hsiang Low and Patrick Jaillet", "title": "Federated Bayesian Optimization via Thompson Sampling", "comments": "Accepted to 34th Conference on Neural Information Processing Systems\n  (NeurIPS 2020), Extended version with proofs and additional experimental\n  details and results, 25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a prominent approach to optimizing\nexpensive-to-evaluate black-box functions. The massive computational capability\nof edge devices such as mobile phones, coupled with privacy concerns, has led\nto a surging interest in federated learning (FL) which focuses on collaborative\ntraining of deep neural networks (DNNs) via first-order optimization\ntechniques. However, some common machine learning tasks such as hyperparameter\ntuning of DNNs lack access to gradients and thus require zeroth-order/black-box\noptimization. This hints at the possibility of extending BO to the FL setting\n(FBO) for agents to collaborate in these black-box optimization tasks. This\npaper presents federated Thompson sampling (FTS) which overcomes a number of\nkey challenges of FBO and FL in a principled way: We (a) use random Fourier\nfeatures to approximate the Gaussian process surrogate model used in BO, which\nnaturally produces the parameters to be exchanged between agents, (b) design\nFTS based on Thompson sampling, which significantly reduces the number of\nparameters to be exchanged, and (c) provide a theoretical convergence guarantee\nthat is robust against heterogeneous agents, which is a major challenge in FL\nand FBO. We empirically demonstrate the effectiveness of FTS in terms of\ncommunication efficiency, computational efficiency, and practical performance.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 09:42:17 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 14:47:27 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 15:07:17 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Dai", "Zhongxiang", ""], ["Low", "Kian Hsiang", ""], ["Jaillet", "Patrick", ""]]}, {"id": "2010.10156", "submitter": "Shivali Agarwal", "authors": "Shivali Agarwal, Shubham Atreja, Vikas Agarwal", "title": "Extracting Procedural Knowledge from Technical Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedures are an important knowledge component of documents that can be\nleveraged by cognitive assistants for automation, question-answering or driving\na conversation. It is a challenging problem to parse big dense documents like\nproduct manuals, user guides to automatically understand which parts are\ntalking about procedures and subsequently extract them. Most of the existing\nresearch has focused on extracting flows in given procedures or understanding\nthe procedures in order to answer conceptual questions. Identifying and\nextracting multiple procedures automatically from documents of diverse formats\nremains a relatively less addressed problem. In this work, we cover some of\nthis ground by -- 1) Providing insights on how structural and linguistic\nproperties of documents can be grouped to define types of procedures, 2)\nAnalyzing documents to extract the relevant linguistic and structural\nproperties, and 3) Formulating procedure identification as a classification\nproblem that leverages the features of the document derived from the above\nanalysis. We first implemented and deployed unsupervised techniques which were\nused in different use cases. Based on the evaluation in different use cases, we\nfigured out the weaknesses of the unsupervised approach. We then designed an\nimproved version which was supervised. We demonstrate that our technique is\neffective in identifying procedures from big and complex documents alike by\nachieving accuracy of 89%.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 09:47:52 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Agarwal", "Shivali", ""], ["Atreja", "Shubham", ""], ["Agarwal", "Vikas", ""]]}, {"id": "2010.10181", "submitter": "Voot Tangkaratt", "authors": "Voot Tangkaratt, Nontawat Charoenphakdee, and Masashi Sugiyama", "title": "Robust Imitation Learning from Noisy Demonstrations", "comments": "16 pages, 9 figures. Accepted to AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust learning from noisy demonstrations is a practical but highly\nchallenging problem in imitation learning. In this paper, we first\ntheoretically show that robust imitation learning can be achieved by optimizing\na classification risk with a symmetric loss. Based on this theoretical finding,\nwe then propose a new imitation learning method that optimizes the\nclassification risk by effectively combining pseudo-labeling with co-training.\nUnlike existing methods, our method does not require additional labels or\nstrict assumptions about noise distributions. Experimental results on\ncontinuous-control benchmarks show that our method is more robust compared to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 10:41:37 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 05:34:29 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 13:38:24 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Tangkaratt", "Voot", ""], ["Charoenphakdee", "Nontawat", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2010.10192", "submitter": "Moumita Choudhury", "authors": "Moumita Choudhury, Amit Sarker, Md. Mosaddek Khan, William Yeoh", "title": "A Particle Swarm Inspired Approach for Continuous Distributed Constraint\n  Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Constraint Optimization Problems (DCOPs) are a widely studied\nframework for coordinating interactions in cooperative multi-agent systems. In\nclassical DCOPs, variables owned by agents are assumed to be discrete. However,\nin many applications, such as target tracking or sleep scheduling in sensor\nnetworks, continuous-valued variables are more suitable than discrete ones. To\nbetter model such applications, researchers have proposed Continuous DCOPs\n(C-DCOPs), an extension of DCOPs, that can explicitly model problems with\ncontinuous variables. The state-of-the-art approaches for solving C-DCOPs\nexperience either onerous memory or computation overhead and unsuitable for\nnon-differentiable optimization problems. To address this issue, we propose a\nnew C-DCOP algorithm, namely Particle Swarm Optimization Based C-DCOP (PCD),\nwhich is inspired by Particle Swarm Optimization (PSO), a well-known\ncentralized population-based approach for solving continuous optimization\nproblems. In recent years, population-based algorithms have gained significant\nattention in classical DCOPs due to their ability in producing high-quality\nsolutions. Nonetheless, to the best of our knowledge, this class of algorithms\nhas not been utilized to solve C-DCOPs and there has been no work evaluating\nthe potential of PSO in solving classical DCOPs or C-DCOPs. In light of this\nobservation, we adapted PSO, a centralized algorithm, to solve C-DCOPs in a\ndecentralized manner. The resulting PCD algorithm not only produces\ngood-quality solutions but also finds solutions without any requirement for\nderivative calculations. Moreover, we design a crossover operator that can be\nused by PCD to further improve the quality of solutions found. Finally, we\ntheoretically prove that PCD is an anytime algorithm and empirically evaluate\nPCD against the state-of-the-art C-DCOP algorithms in a wide variety of\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 11:04:47 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Choudhury", "Moumita", ""], ["Sarker", "Amit", ""], ["Khan", "Md. Mosaddek", ""], ["Yeoh", "William", ""]]}, {"id": "2010.10209", "submitter": "Wei Zhang", "authors": "Wei Zhang, Ning Liu, and Yunfeng Zhang", "title": "Learn to Navigate Maplessly with Varied LiDAR Configurations: A Support\n  Point-Based Approach", "comments": "\\c{opyright} 20XX IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": "10.1109/LRA.2021.3061305", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) demonstrates great potential in mapless\nnavigation domain. However, such a navigation model is normally restricted to a\nfixed configuration of the range sensor because its input format is fixed. In\nthis paper, we propose a DRL model that can address range data obtained from\ndifferent range sensors with different installation positions. Our model first\nextracts the goal-directed features from each obstacle point. Subsequently, it\nchooses global obstacle features from all point-feature candidates and uses\nthese features for the final decision. As only a few points are used to support\nthe final decision, we refer to these points as support points and our approach\nas support point-based navigation (SPN). Our model can handle data from\ndifferent LiDAR setups and demonstrates good performance in simulation and\nreal-world experiments. Moreover, it shows great potential in crowded scenarios\nwith small obstacles when using a high-resolution LiDAR.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 11:46:27 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 02:51:02 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Zhang", "Wei", ""], ["Liu", "Ning", ""], ["Zhang", "Yunfeng", ""]]}, {"id": "2010.10216", "submitter": "Danish Contractor", "authors": "Biswesh Mohapatra, Gaurav Pandey, Danish Contractor, Sachindra Joshi", "title": "Simulated Chats for Task-oriented Dialog: Learning to Generate\n  Conversations from Instructions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular task-oriented dialog data sets such as MultiWOZ (Budzianowski et al.\n2018) are created by providing crowd-sourced workers a goal instruction,\nexpressed in natural language, that describes the task to be accomplished.\nCrowd-sourced workers play the role of a user and an agent to generate dialogs\nto accomplish tasks involving booking restaurant tables, making train\nreservations, calling a taxi etc. However, creating large crowd-sourced\ndatasets can be time consuming and expensive. To reduce the cost associated\nwith generating such dialog datasets, recent work has explored methods to\nautomatically create larger datasets from small samples.In this paper, we\npresent a data creation strategy that uses the pre-trained language model, GPT2\n(Radford et al. 2018), to simulate the interaction between crowd-sourced\nworkers by creating a user bot and an agent bot. We train the simulators using\na smaller percentage of actual crowd-generated conversations and their\ncorresponding goal instructions. We demonstrate that by using the simulated\ndata, we achieve significant improvements in both low-resource setting as well\nas in over-all task performance. To the best of our knowledge we are the first\nto present a model for generating entire conversations by simulating the\ncrowd-sourced data collection process\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 12:04:19 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Mohapatra", "Biswesh", ""], ["Pandey", "Gaurav", ""], ["Contractor", "Danish", ""], ["Joshi", "Sachindra", ""]]}, {"id": "2010.10218", "submitter": "Anant Raj", "authors": "Anant Raj and Cameron Musco and Lester Mackey and Nicolo Fusi", "title": "Model-specific Data Subsampling with Influence Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model selection requires repeatedly evaluating models on a given dataset and\nmeasuring their relative performances. In modern applications of machine\nlearning, the models being considered are increasingly more expensive to\nevaluate and the datasets of interest are increasing in size. As a result, the\nprocess of model selection is time-consuming and computationally inefficient.\nIn this work, we develop a model-specific data subsampling strategy that\nimproves over random sampling whenever training points have varying influence.\nSpecifically, we leverage influence functions to guide our selection strategy,\nproving theoretically, and demonstrating empirically that our approach quickly\nselects high-quality models.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 12:10:28 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Raj", "Anant", ""], ["Musco", "Cameron", ""], ["Mackey", "Lester", ""], ["Fusi", "Nicolo", ""]]}, {"id": "2010.10261", "submitter": "Zhao Zhong", "authors": "Yikang Zhang, Jian Zhang, Zhao Zhong", "title": "AutoBSS: An Efficient Algorithm for Block Stacking Style Search", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network architecture design mostly focuses on the new convolutional\noperator or special topological structure of network block, little attention is\ndrawn to the configuration of stacking each block, called Block Stacking Style\n(BSS). Recent studies show that BSS may also have an unneglectable impact on\nnetworks, thus we design an efficient algorithm to search it automatically. The\nproposed method, AutoBSS, is a novel AutoML algorithm based on Bayesian\noptimization by iteratively refining and clustering Block Stacking Style Code\n(BSSC), which can find optimal BSS in a few trials without biased evaluation.\nOn ImageNet classification task, ResNet50/MobileNetV2/EfficientNet-B0 with our\nsearched BSS achieve 79.29%/74.5%/77.79%, which outperform the original\nbaselines by a large margin. More importantly, experimental results on model\ncompression, object detection and instance segmentation show the strong\ngeneralizability of the proposed AutoBSS, and further verify the unneglectable\nimpact of BSS on neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 13:32:10 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 05:08:52 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Zhang", "Yikang", ""], ["Zhang", "Jian", ""], ["Zhong", "Zhao", ""]]}, {"id": "2010.10274", "submitter": "A. Ben Hamza", "authors": "Mahsa Mesgaran and A. Ben Hamza", "title": "Graph Fairing Convolutional Networks for Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolution is a fundamental building block for many deep neural\nnetworks on graph-structured data. In this paper, we introduce a simple, yet\nvery effective graph convolutional network with skip connections for\nsemi-supervised anomaly detection. The proposed multi-layer network\narchitecture is theoretically motivated by the concept of implicit fairing in\ngeometry processing, and comprises a graph convolution module for aggregating\ninformation from immediate node neighbors and a skip connection module for\ncombining layer-wise neighborhood representations. In addition to capturing\ninformation from distant graph nodes through skip connections between the\nnetwork's layers, our approach exploits both the graph structure and node\nfeatures for learning discriminative node representations. The effectiveness of\nour model is demonstrated through extensive experiments on five benchmark\ndatasets, achieving better or comparable anomaly detection results against\nstrong baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 13:45:47 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Mesgaran", "Mahsa", ""], ["Hamza", "A. Ben", ""]]}, {"id": "2010.10289", "submitter": "Jerry Lonlac", "authors": "Jerry Lonlac, Arnaud Doniec, Marin Lujak, Stephane Lecoeuche", "title": "Extracting Seasonal Gradual Patterns from Temporal Sequence Data Using\n  Periodic Patterns Mining", "comments": "30 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining frequent episodes aims at recovering sequential patterns from temporal\ndata sequences, which can then be used to predict the occurrence of related\nevents in advance. On the other hand, gradual patterns that capture\nco-variation of complex attributes in the form of \" when X increases/decreases,\nY increases/decreases\" play an important role in many real world applications\nwhere huge volumes of complex numerical data must be handled. Recently, these\npatterns have received attention from the data mining community exploring\ntemporal data who proposed methods to automatically extract gradual patterns\nfrom temporal data. However, to the best of our knowledge, no method has been\nproposed to extract gradual patterns that regularly appear at identical time\nintervals in many sequences of temporal data, despite the fact that such\npatterns may add knowledge to certain applications, such as e-commerce. In this\npaper, we propose to extract co-variations of periodically repeating attributes\nfrom the sequences of temporal data that we call seasonal gradual patterns. For\nthis purpose, we formulate the task of mining seasonal gradual patterns as the\nproblem of mining periodic patterns in multiple sequences and then we exploit\nperiodic pattern mining algorithms to extract seasonal gradual patterns. We\ndiscuss specific features of these patterns and propose an approach for their\nextraction based on mining periodic frequent patterns common to multiple\nsequences. We also propose a new anti-monotonous support definition associated\nto these seasonal gradual patterns. The illustrative results obtained from some\nreal world data sets show that the proposed approach is efficient and that it\ncan extract small sets of patterns by filtering numerous nonseasonal patterns\nto identify the seasonal ones.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 14:03:37 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Lonlac", "Jerry", ""], ["Doniec", "Arnaud", ""], ["Lujak", "Marin", ""], ["Lecoeuche", "Stephane", ""]]}, {"id": "2010.10296", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima", "title": "SeLFiE: Modular Semantic Reasoning for Induction in Isabelle/HOL", "comments": "under review at the 23rd International Symposium on Practical Aspects\n  of Declarative Languages (PADL) 2021. arXiv admin note: substantial text\n  overlap with arXiv:2009.09215", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof assistants offer tactics to apply proof by induction, but these tactics\nrely on inputs given by human engineers. We address this problem withSeLFiE, a\ndomain-specific language to encode experienced users' expertise on how to apply\nthe induct tactic in Isabelle/HOL: when we apply an induction heuristic written\nin SeLFiE to an inductive problem and arguments to the induct tactic, the\nSeLFiE interpreter examines both the syntactic structure of the problem and\nsemantics of the relevant constants to judge whether the arguments to the\ninduct tactic are plausible for that problem according to the heuristic. SeLFiE\nfacilitates the intricate interaction between syntactic and semantic analyses\nusing semantic constructs while maintaining the modularity of each analysis.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 09:05:09 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Nagashima", "Yutaka", ""]]}, {"id": "2010.10343", "submitter": "David Kohan Marzag\\~ao", "authors": "David Kohan Marzag\\~ao, Trung Dong Huynh, Ayah Helal, Luc Moreau", "title": "Provenance Graph Kernel", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Provenance is a record that describes how entities, activities, and agents\nhave influenced a piece of data. Such provenance information is commonly\nrepresented in graphs with relevant labels on both their nodes and edges. With\nthe growing adoption of provenance in a wide range of application domains,\nincreasingly, users are confronted with an abundance of graph data, which may\nprove challenging to analyse. Graph kernels, on the other hand, have been\nconsistently and successfully used to efficiently classify graphs. In this\npaper, we introduce a novel graph kernel called \\emph{provenance kernel}, which\nis inspired by and tailored for provenance data. It decomposes a provenance\ngraph into tree-patterns rooted at a given node and considers the labels of\nedges and nodes up to a certain distance from the root. We employ provenance\nkernels to classify provenance graphs from three application domains. Our\nevaluation shows that they perform well in terms of classification accuracy and\nyield competitive results when compared against standard graph kernel methods\nand the provenance network analytics method while taking significantly less\ntime.Moreover, we illustrate how the provenance types used in provenance\nkernels help improve the explainability of predictive models.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 15:07:30 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Marzag\u00e3o", "David Kohan", ""], ["Huynh", "Trung Dong", ""], ["Helal", "Ayah", ""], ["Moreau", "Luc", ""]]}, {"id": "2010.10344", "submitter": "Miriam Enzi", "authors": "Miriam Enzi, Sophie N. Parragh, Jakob Puchinger", "title": "The bi-objective multimodal car-sharing problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the bi-objective multimodal car-sharing problem (BiO-MMCP) is to\ndetermine the optimal mode of transport assignment for trips and to schedule\nthe routes of available cars and users whilst minimizing cost and maximizing\nuser satisfaction. We investigate the BiO-MMCP from a user-centred point of\nview. As user satisfaction is a crucial aspect in shared mobility systems, we\nconsider user preferences in a second objective. Users may choose and rank\ntheir preferred modes of transport for different times of the day. In this way\nwe account for, e.g., different traffic conditions throughout the planning\nhorizon.\n  We study different variants of the problem. In the base problem, the sequence\nof tasks a user has to fulfill is fixed in advance and travel times as well as\npreferences are constant over the planning horizon. In variant 2,\ntime-dependent travel times and preferences are introduced. In variant 3, we\nexamine the challenges when allowing additional routing decisions. Variant 4\nintegrates variants 2 and 3. For this last variant, we develop a branch-and-cut\nalgorithm which is embedded in two bi-objective frameworks, namely the\n$\\epsilon$-constraint method and a weighting binary search method.\nComputational experiments show that the branch-and cut algorithm outperforms\nthe MIP formulation and we discuss changing solutions along the Pareto\nfrontier.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 13:48:17 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Enzi", "Miriam", ""], ["Parragh", "Sophie N.", ""], ["Puchinger", "Jakob", ""]]}, {"id": "2010.10359", "submitter": "Aleksandar Miladinovic", "authors": "Aleksandar Miladinovi\\'c, Milo\\v{s} Aj\\v{c}evi\\'c, Agostino Accardo", "title": "Performance of Dual-Augmented Lagrangian Method and Common Spatial\n  Patterns applied in classification of Motor-Imagery BCI", "comments": null, "journal-ref": "GNB2020, June 10th-12th 2020, Trieste, Italy", "doi": "10.6084/m9.figshare.13087376.v1", "report-no": null, "categories": "eess.SP cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motor-imagery based brain-computer interfaces (MI-BCI) have the potential to\nbecome ground-breaking technologies for neurorehabilitation, the\nreestablishment of non-muscular communication and commands for patients\nsuffering from neuronal disorders and disabilities, but also outside of\nclinical practice, for video game control and other entertainment purposes.\nHowever, due to the noisy nature of the used EEG signal, reliable BCI systems\nrequire specialized procedures for features optimization and extraction. This\npaper compares the two approaches, the Common Spatial Patterns with Linear\nDiscriminant Analysis classifier (CSP-LDA), widely used in BCI for extracting\nfeatures in Motor Imagery (MI) tasks, and the Dual-Augmented Lagrangian (DAL)\nframework with three different regularization methods: group sparsity with row\ngroups (DAL-GLR), dual-spectrum (DAL-DS) and l1-norm regularization (DAL-L1).\nThe test has been performed on 7 healthy subjects performing 5 BCI-MI sessions\neach. The preliminary results show that DAL-GLR method outperforms standard\nCSP-LDA, presenting 6.9% lower misclassification error (p-value = 0.008) and\ndemonstrate the advantage of DAL framework for MI-BCI.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 20:50:13 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Miladinovi\u0107", "Aleksandar", ""], ["Aj\u010devi\u0107", "Milo\u0161", ""], ["Accardo", "Agostino", ""]]}, {"id": "2010.10363", "submitter": "Laurel Orr", "authors": "Laurel Orr, Megan Leszczynski, Simran Arora, Sen Wu, Neel Guha, Xiao\n  Ling, Christopher Re", "title": "Bootleg: Chasing the Tail with Self-Supervised Named Entity\n  Disambiguation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A challenge for named entity disambiguation (NED), the task of mapping\ntextual mentions to entities in a knowledge base, is how to disambiguate\nentities that appear rarely in the training data, termed tail entities. Humans\nuse subtle reasoning patterns based on knowledge of entity facts, relations,\nand types to disambiguate unfamiliar entities. Inspired by these patterns, we\nintroduce Bootleg, a self-supervised NED system that is explicitly grounded in\nreasoning patterns for disambiguation. We define core reasoning patterns for\ndisambiguation, create a learning procedure to encourage the self-supervised\nmodel to learn the patterns, and show how to use weak supervision to enhance\nthe signals in the training data. Encoding the reasoning patterns in a simple\nTransformer architecture, Bootleg meets or exceeds state-of-the-art on three\nNED benchmarks. We further show that the learned representations from Bootleg\nsuccessfully transfer to other non-disambiguation tasks that require\nentity-based knowledge: we set a new state-of-the-art in the popular TACRED\nrelation extraction task by 1.0 F1 points and demonstrate up to 8% performance\nlift in highly optimized production search and assistant tasks at a major\ntechnology company\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 15:17:49 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 02:19:08 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 16:21:13 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Orr", "Laurel", ""], ["Leszczynski", "Megan", ""], ["Arora", "Simran", ""], ["Wu", "Sen", ""], ["Guha", "Neel", ""], ["Ling", "Xiao", ""], ["Re", "Christopher", ""]]}, {"id": "2010.10368", "submitter": "Ali Akbari", "authors": "Ali Akbari, Muhammad Awais, Zhen-Hua Feng, Ammarah Farooq and Josef\n  Kittler", "title": "A Flatter Loss for Bias Mitigation in Cross-dataset Facial Age\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most existing studies in the facial age estimation assume training and\ntest images are captured under similar shooting conditions. However, this is\nrarely valid in real-world applications, where training and test sets usually\nhave different characteristics. In this paper, we advocate a cross-dataset\nprotocol for age estimation benchmarking. In order to improve the cross-dataset\nage estimation performance, we mitigate the inherent bias caused by the\nlearning algorithm itself. To this end, we propose a novel loss function that\nis more effective for neural network training. The relative smoothness of the\nproposed loss function is its advantage with regards to the optimisation\nprocess performed by stochastic gradient descent (SGD). Compared with existing\nloss functions, the lower gradient of the proposed loss function leads to the\nconvergence of SGD to a better optimum point, and consequently a better\ngeneralisation. The cross-dataset experimental results demonstrate the\nsuperiority of the proposed method over the state-of-the-art algorithms in\nterms of accuracy and generalisation capability.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 15:22:29 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 19:29:06 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Akbari", "Ali", ""], ["Awais", "Muhammad", ""], ["Feng", "Zhen-Hua", ""], ["Farooq", "Ammarah", ""], ["Kittler", "Josef", ""]]}, {"id": "2010.10380", "submitter": "Yoram Bachrach", "authors": "Yoram Bachrach, Richard Everett, Edward Hughes, Angeliki Lazaridou,\n  Joel Z. Leibo, Marc Lanctot, Michael Johanson, Wojciech M. Czarnecki, Thore\n  Graepel", "title": "Negotiating Team Formation Using Deep Reinforcement Learning", "comments": null, "journal-ref": "Artificial Intelligence 288 (2020): 103356", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When autonomous agents interact in the same environment, they must often\ncooperate to achieve their goals. One way for agents to cooperate effectively\nis to form a team, make a binding agreement on a joint plan, and execute it.\nHowever, when agents are self-interested, the gains from team formation must be\nallocated appropriately to incentivize agreement. Various approaches for\nmulti-agent negotiation have been proposed, but typically only work for\nparticular negotiation protocols. More general methods usually require human\ninput or domain-specific data, and so do not scale. To address this, we propose\na framework for training agents to negotiate and form teams using deep\nreinforcement learning. Importantly, our method makes no assumptions about the\nspecific negotiation protocol, and is instead completely experience driven. We\nevaluate our approach on both non-spatial and spatially extended team-formation\nnegotiation environments, demonstrating that our agents beat hand-crafted bots\nand reach negotiation outcomes consistent with fair solutions predicted by\ncooperative game theory. Additionally, we investigate how the physical location\nof agents influences negotiation outcomes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 15:41:23 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Bachrach", "Yoram", ""], ["Everett", "Richard", ""], ["Hughes", "Edward", ""], ["Lazaridou", "Angeliki", ""], ["Leibo", "Joel Z.", ""], ["Lanctot", "Marc", ""], ["Johanson", "Michael", ""], ["Czarnecki", "Wojciech M.", ""], ["Graepel", "Thore", ""]]}, {"id": "2010.10391", "submitter": "Georgios Michalopoulos", "authors": "George Michalopoulos, Yuanxin Wang, Hussam Kaka, Helen Chen and\n  Alexander Wong", "title": "UmlsBERT: Clinical Domain Knowledge Augmentation of Contextual\n  Embeddings Using the Unified Medical Language System Metathesaurus", "comments": "10 pages, 3 figures, accepted in NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual word embedding models, such as BioBERT and Bio_ClinicalBERT, have\nachieved state-of-the-art results in biomedical natural language processing\ntasks by focusing their pre-training process on domain-specific corpora.\nHowever, such models do not take into consideration expert domain knowledge.\n  In this work, we introduced UmlsBERT, a contextual embedding model that\nintegrates domain knowledge during the pre-training process via a novel\nknowledge augmentation strategy. More specifically, the augmentation on\nUmlsBERT with the Unified Medical Language System (UMLS) Metathesaurus was\nperformed in two ways: i) connecting words that have the same underlying\n`concept' in UMLS, and ii) leveraging semantic group knowledge in UMLS to\ncreate clinically meaningful input embeddings. By applying these two\nstrategies, UmlsBERT can encode clinical domain knowledge into word embeddings\nand outperform existing domain-specific models on common named-entity\nrecognition (NER) and clinical natural language inference clinical NLP tasks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 15:56:31 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 07:21:08 GMT"}, {"version": "v3", "created": "Wed, 28 Apr 2021 21:30:38 GMT"}, {"version": "v4", "created": "Wed, 19 May 2021 19:59:23 GMT"}, {"version": "v5", "created": "Thu, 3 Jun 2021 15:07:58 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Michalopoulos", "George", ""], ["Wang", "Yuanxin", ""], ["Kaka", "Hussam", ""], ["Chen", "Helen", ""], ["Wong", "Alexander", ""]]}, {"id": "2010.10407", "submitter": "A. Feder Cooper", "authors": "A. Feder Cooper", "title": "Where Is the Normative Proof? Assumptions and Contradictions in ML\n  Fairness Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Across machine learning (ML) sub-disciplines researchers make mathematical\nassumptions to facilitate proof-writing. While such assumptions are necessary\nfor providing mathematical guarantees for how algorithms behave, they also\nnecessarily limit the applicability of these algorithms to different problem\nsettings. This practice is known--in fact, obvious--and accepted in ML\nresearch. However, similar attention is not paid to the normative assumptions\nthat ground this work. I argue such assumptions are equally as important,\nespecially in areas of ML with clear social impact, such as fairness. This is\nbecause, similar to how mathematical assumptions constrain applicability,\nnormative assumptions also limit algorithm applicability to certain problem\ndomains. I show that, in existing papers published in top venues, once\nnormative assumptions are clarified, it is often possible to get unclear or\ncontradictory results. While the mathematical assumptions and results are\nsound, the implicit normative assumptions and accompanying normative results\ncontraindicate using these methods in practical fairness applications.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 16:13:46 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 19:30:59 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 22:08:04 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Cooper", "A. Feder", ""]]}, {"id": "2010.10418", "submitter": "Swarnadeep Saha", "authors": "Swarnadeep Saha, Yixin Nie, Mohit Bansal", "title": "ConjNLI: Natural Language Inference Over Conjunctive Sentences", "comments": "EMNLP 2020 (14 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning about conjuncts in conjunctive sentences is important for a deeper\nunderstanding of conjunctions in English and also how their usages and\nsemantics differ from conjunctive and disjunctive boolean logic. Existing NLI\nstress tests do not consider non-boolean usages of conjunctions and use\ntemplates for testing such model knowledge. Hence, we introduce ConjNLI, a\nchallenge stress-test for natural language inference over conjunctive\nsentences, where the premise differs from the hypothesis by conjuncts removed,\nadded, or replaced. These sentences contain single and multiple instances of\ncoordinating conjunctions (\"and\", \"or\", \"but\", \"nor\") with quantifiers,\nnegations, and requiring diverse boolean and non-boolean inferences over\nconjuncts. We find that large-scale pre-trained language models like RoBERTa do\nnot understand conjunctive semantics well and resort to shallow heuristics to\nmake inferences over such sentences. As some initial solutions, we first\npresent an iterative adversarial fine-tuning method that uses synthetically\ncreated training data based on boolean and non-boolean heuristics. We also\npropose a direct model advancement by making RoBERTa aware of predicate\nsemantic roles. While we observe some performance gains, ConjNLI is still\nchallenging for current methods, thus encouraging interesting future work for\nbetter understanding of conjunctions. Our data and code are publicly available\nat: https://github.com/swarnaHub/ConjNLI\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 16:29:13 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 21:49:00 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Saha", "Swarnadeep", ""], ["Nie", "Yixin", ""], ["Bansal", "Mohit", ""]]}, {"id": "2010.10439", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Ming-Wei Chang, Eva Schlinger, William Wang, William W.\n  Cohen", "title": "Open Question Answering over Tables and Text", "comments": "Accepted to ICLR 2021. Main paper has 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In open question answering (QA), the answer to a question is produced by\nretrieving and then analyzing documents that might contain answers to the\nquestion. Most open QA systems have considered only retrieving information from\nunstructured text. Here we consider for the first time open QA over both\ntabular and textual data and present a new large-scale dataset Open\nTable-and-Text Question Answering (OTT-QA) to evaluate performance on this\ntask. Most questions in OTT-QA require multi-hop inference across tabular data\nand unstructured text, and the evidence required to answer a question can be\ndistributed in different ways over these two types of input, making evidence\nretrieval challenging -- our baseline model using an iterative retriever and\nBERT-based reader achieves an exact match score less than 10%. We then propose\ntwo novel techniques to address the challenge of retrieving and aggregating\nevidence for OTT-QA. The first technique is to use \"early fusion\" to group\nmultiple highly relevant tabular and textual units into a fused block, which\nprovides more context for the retriever to search for. The second technique is\nto use a cross-block reader to model the cross-dependency between multiple\nretrieved evidence with global-local sparse attention. Combining these two\ntechniques improves the score significantly, to above 27%.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 16:48:14 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 08:21:18 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Chen", "Wenhu", ""], ["Chang", "Ming-Wei", ""], ["Schlinger", "Eva", ""], ["Wang", "William", ""], ["Cohen", "William W.", ""]]}, {"id": "2010.10442", "submitter": "Yue Shang", "authors": "Yunjiang Jiang, Yue Shang, Ziyang Liu, Hongwei Shen, Yun Xiao, Wei\n  Xiong, Sulong Xu, Weipeng Yan and Di Jin", "title": "BERT2DNN: BERT Distillation with Massive Unlabeled Data for Online\n  E-Commerce Search", "comments": "10 pages, 7 figures, to appear in ICDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relevance has significant impact on user experience and business profit for\ne-commerce search platform. In this work, we propose a data-driven framework\nfor search relevance prediction, by distilling knowledge from BERT and related\nmulti-layer Transformer teacher models into simple feed-forward networks with\nlarge amount of unlabeled data. The distillation process produces a student\nmodel that recovers more than 97\\% test accuracy of teacher models on new\nqueries, at a serving cost that's several magnitude lower (latency 150x lower\nthan BERT-Base and 15x lower than the most efficient BERT variant, TinyBERT).\nThe applications of temperature rescaling and teacher model stacking further\nboost model accuracy, without increasing the student model complexity.\n  We present experimental results on both in-house e-commerce search relevance\ndata as well as a public data set on sentiment analysis from the GLUE\nbenchmark. The latter takes advantage of another related public data set of\nmuch larger scale, while disregarding its potentially noisy labels. Embedding\nanalysis and case study on the in-house data further highlight the strength of\nthe resulting model. By making the data processing and model training source\ncode public, we hope the techniques presented here can help reduce energy\nconsumption of the state of the art Transformer models and also level the\nplaying field for small organizations lacking access to cutting edge machine\nlearning hardwares.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 16:56:04 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Jiang", "Yunjiang", ""], ["Shang", "Yue", ""], ["Liu", "Ziyang", ""], ["Shen", "Hongwei", ""], ["Xiao", "Yun", ""], ["Xiong", "Wei", ""], ["Xu", "Sulong", ""], ["Yan", "Weipeng", ""], ["Jin", "Di", ""]]}, {"id": "2010.10453", "submitter": "Maria Leonor Pacheco", "authors": "Maria Leonor Pacheco and Dan Goldwasser", "title": "Modeling Content and Context with Deep Relational Learning", "comments": "TACL pre-MIT Press version", "journal-ref": "Transactions of the Association for Computational Linguistics,\n  2021", "doi": "10.1162/tacl_a_00357", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building models for realistic natural language tasks requires dealing with\nlong texts and accounting for complicated structural dependencies.\nNeural-symbolic representations have emerged as a way to combine the reasoning\ncapabilities of symbolic methods, with the expressiveness of neural networks.\nHowever, most of the existing frameworks for combining neural and symbolic\nrepresentations have been designed for classic relational learning tasks that\nwork over a universe of symbolic entities and relations. In this paper, we\npresent DRaiL, an open-source declarative framework for specifying deep\nrelational models, designed to support a variety of NLP scenarios. Our\nframework supports easy integration with expressive language encoders, and\nprovides an interface to study the interactions between representation,\ninference and learning.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 17:09:35 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Pacheco", "Maria Leonor", ""], ["Goldwasser", "Dan", ""]]}, {"id": "2010.10458", "submitter": "Shaohuai Shi", "authors": "Shaohuai Shi, Xianhao Zhou, Shutao Song, Xingyao Wang, Zilin Zhu, Xue\n  Huang, Xinan Jiang, Feihu Zhou, Zhenyu Guo, Liqiang Xie, Rui Lan, Xianbin\n  Ouyang, Yan Zhang, Jieqian Wei, Jing Gong, Weiliang Lin, Ping Gao, Peng Meng,\n  Xiaomin Xu, Chenyang Guo, Bo Yang, Zhibo Chen, Yongjian Wu and Xiaowen Chu", "title": "Towards Scalable Distributed Training of Deep Learning on Public Cloud\n  Clusters", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed training techniques have been widely deployed in large-scale deep\nneural networks (DNNs) training on dense-GPU clusters. However, on public cloud\nclusters, due to the moderate inter-connection bandwidth between instances,\ntraditional state-of-the-art distributed training systems cannot scale well in\ntraining large-scale models. In this paper, we propose a new computing and\ncommunication efficient top-k sparsification communication library for\ndistributed training. To further improve the system scalability, we optimize\nI/O by proposing a simple yet efficient multi-level data caching mechanism and\noptimize the update operation by introducing a novel parallel tensor operator.\nExperimental results on a 16-node Tencent Cloud cluster (each node with 8\nNvidia Tesla V100 GPUs) show that our system achieves 25%-40% faster than\nexisting state-of-the-art systems on CNNs and Transformer. We finally break the\nrecord on DAWNBench on training ResNet-50 to 93% top-5 accuracy on ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 17:16:29 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Shi", "Shaohuai", ""], ["Zhou", "Xianhao", ""], ["Song", "Shutao", ""], ["Wang", "Xingyao", ""], ["Zhu", "Zilin", ""], ["Huang", "Xue", ""], ["Jiang", "Xinan", ""], ["Zhou", "Feihu", ""], ["Guo", "Zhenyu", ""], ["Xie", "Liqiang", ""], ["Lan", "Rui", ""], ["Ouyang", "Xianbin", ""], ["Zhang", "Yan", ""], ["Wei", "Jieqian", ""], ["Gong", "Jing", ""], ["Lin", "Weiliang", ""], ["Gao", "Ping", ""], ["Meng", "Peng", ""], ["Xu", "Xiaomin", ""], ["Guo", "Chenyang", ""], ["Yang", "Bo", ""], ["Chen", "Zhibo", ""], ["Wu", "Yongjian", ""], ["Chu", "Xiaowen", ""]]}, {"id": "2010.10474", "submitter": "Jay Nandy", "authors": "Jay Nandy and Wynne Hsu and Mong Li Lee", "title": "Towards Maximizing the Representation Gap between In-Domain &\n  Out-of-Distribution Examples", "comments": "Accepted at NeurIPS 2020 Workshop version: ICML UDL 2020, Link:\n  http://www.gatsby.ucl.ac.uk/~balaji/udl2020/accepted-papers/UDL2020-paper-134.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among existing uncertainty estimation approaches, Dirichlet Prior Network\n(DPN) distinctly models different predictive uncertainty types. However, for\nin-domain examples with high data uncertainties among multiple classes, even a\nDPN model often produces indistinguishable representations from the\nout-of-distribution (OOD) examples, compromising their OOD detection\nperformance. We address this shortcoming by proposing a novel loss function for\nDPN to maximize the \\textit{representation gap} between in-domain and OOD\nexamples. Experimental results demonstrate that our proposed approach\nconsistently improves OOD detection performance.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 17:34:26 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 13:42:26 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Nandy", "Jay", ""], ["Hsu", "Wynne", ""], ["Lee", "Mong Li", ""]]}, {"id": "2010.10505", "submitter": "Chen-Hsuan Lin", "authors": "Chen-Hsuan Lin, Chaoyang Wang, Simon Lucey", "title": "SDF-SRN: Learning Signed Distance 3D Object Reconstruction from Static\n  Images", "comments": "Accepted to NeurIPS 2020. Project page & code:\n  https://chenhsuanlin.bitbucket.io/signed-distance-SRN/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense 3D object reconstruction from a single image has recently witnessed\nremarkable advances, but supervising neural networks with ground-truth 3D\nshapes is impractical due to the laborious process of creating paired\nimage-shape datasets. Recent efforts have turned to learning 3D reconstruction\nwithout 3D supervision from RGB images with annotated 2D silhouettes,\ndramatically reducing the cost and effort of annotation. These techniques,\nhowever, remain impractical as they still require multi-view annotations of the\nsame object instance during training. As a result, most experimental efforts to\ndate have been limited to synthetic datasets. In this paper, we address this\nissue and propose SDF-SRN, an approach that requires only a single view of\nobjects at training time, offering greater utility for real-world scenarios.\nSDF-SRN learns implicit 3D shape representations to handle arbitrary shape\ntopologies that may exist in the datasets. To this end, we derive a novel\ndifferentiable rendering formulation for learning signed distance functions\n(SDF) from 2D silhouettes. Our method outperforms the state of the art under\nchallenging single-view supervision settings on both synthetic and real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 17:59:47 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Lin", "Chen-Hsuan", ""], ["Wang", "Chaoyang", ""], ["Lucey", "Simon", ""]]}, {"id": "2010.10560", "submitter": "Varun Raj Kompella", "authors": "Varun Kompella, Roberto Capobianco, Stacy Jong, Jonathan Browne,\n  Spencer Fox, Lauren Meyers, Peter Wurman, Peter Stone", "title": "Reinforcement Learning for Optimization of COVID-19 Mitigation policies", "comments": "*Joint First Authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The year 2020 has seen the COVID-19 virus lead to one of the worst global\npandemics in history. As a result, governments around the world are faced with\nthe challenge of protecting public health, while keeping the economy running to\nthe greatest extent possible. Epidemiological models provide insight into the\nspread of these types of diseases and predict the effects of possible\nintervention policies. However, to date,the even the most data-driven\nintervention policies rely on heuristics. In this paper, we study how\nreinforcement learning (RL) can be used to optimize mitigation policies that\nminimize the economic impact without overwhelming the hospital capacity. Our\nmain contributions are (1) a novel agent-based pandemic simulator which, unlike\ntraditional models, is able to model fine-grained interactions among people at\nspecific locations in a community; and (2) an RL-based methodology for\noptimizing fine-grained mitigation policies within this simulator. Our results\nvalidate both the overall simulator behavior and the learned policies under\nrealistic conditions.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 18:40:15 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Kompella", "Varun", ""], ["Capobianco", "Roberto", ""], ["Jong", "Stacy", ""], ["Browne", "Jonathan", ""], ["Fox", "Spencer", ""], ["Meyers", "Lauren", ""], ["Wurman", "Peter", ""], ["Stone", "Peter", ""]]}, {"id": "2010.10563", "submitter": "Pablo Messina", "authors": "Pablo Messina, Pablo Pino, Denis Parra, Alvaro Soto, Cecilia Besa,\n  Sergio Uribe, Marcelo and\\'ia, Cristian Tejos, Claudia Prieto and Daniel\n  Capurro", "title": "A Survey on Deep Learning and Explainability for Automatic Image-based\n  Medical Report Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every year physicians face an increasing demand of image-based diagnosis from\npatients, a problem that can be addressed with recent artificial intelligence\nmethods. In this context, we survey works in the area of automatic report\ngeneration from medical images, with emphasis on methods using deep neural\nnetworks, with respect to: (1) Datasets, (2) Architecture Design, (3)\nExplainability and (4) Evaluation Metrics. Our survey identifies interesting\ndevelopments, but also remaining challenges. Among them, the current evaluation\nof generated reports is especially weak, since it mostly relies on traditional\nNatural Language Processing (NLP) metrics, which do not accurately capture\nmedical correctness.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 18:48:37 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Messina", "Pablo", ""], ["Pino", "Pablo", ""], ["Parra", "Denis", ""], ["Soto", "Alvaro", ""], ["Besa", "Cecilia", ""], ["Uribe", "Sergio", ""], ["and\u00eda", "Marcelo", ""], ["Tejos", "Cristian", ""], ["Prieto", "Claudia", ""], ["Capurro", "Daniel", ""]]}, {"id": "2010.10590", "submitter": "Puru Malhotra", "authors": "Yugam Bajaj and Puru Malhotra", "title": "American Sign Language Identification Using Hand Trackpoint Analysis", "comments": "12 Pages, 6 Images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sign Language helps people with Speaking and Hearing Disabilities communicate\nwith others efficiently. Sign Language identification is a challenging area in\nthe field of computer vision and recent developments have been able to achieve\nnear perfect results for the task, though some challenges are yet to be solved.\nIn this paper we propose a novel machine learning based pipeline for American\nSign Language identification using hand track points. We convert a hand gesture\ninto a series of hand track point coordinates that serve as an input to our\nsystem. In order to make the solution more efficient, we experimented with 28\ndifferent combinations of pre-processing techniques, each run on three\ndifferent machine learning algorithms namely k-Nearest Neighbours, Random\nForests and a Neural Network. Their performance was contrasted to determine the\nbest pre-processing scheme and algorithm pair. Our system achieved an Accuracy\nof 95.66% to identify American sign language gestures.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 19:59:16 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 21:11:27 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2021 21:11:21 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Bajaj", "Yugam", ""], ["Malhotra", "Puru", ""]]}, {"id": "2010.10593", "submitter": "Tristan Sylvain", "authors": "Tristan Sylvain, Francis Dutil, Tess Berthier, Lisa Di Jorio, Margaux\n  Luck, Devon Hjelm, Yoshua Bengio", "title": "Cross-Modal Information Maximization for Medical Imaging: CMIM", "comments": "ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In hospitals, data are siloed to specific information systems that make the\nsame information available under different modalities such as the different\nmedical imaging exams the patient undergoes (CT scans, MRI, PET, Ultrasound,\netc.) and their associated radiology reports. This offers unique opportunities\nto obtain and use at train-time those multiple views of the same information\nthat might not always be available at test-time.\n  In this paper, we propose an innovative framework that makes the most of\navailable data by learning good representations of a multi-modal input that are\nresilient to modality dropping at test-time, using recent advances in mutual\ninformation maximization. By maximizing cross-modal information at train time,\nwe are able to outperform several state-of-the-art baselines in two different\nsettings, medical image classification, and segmentation. In particular, our\nmethod is shown to have a strong impact on the inference-time performance of\nweaker modalities.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 20:05:35 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 17:08:34 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 21:10:37 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Sylvain", "Tristan", ""], ["Dutil", "Francis", ""], ["Berthier", "Tess", ""], ["Di Jorio", "Lisa", ""], ["Luck", "Margaux", ""], ["Hjelm", "Devon", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2010.10596", "submitter": "Sahil Verma", "authors": "Sahil Verma and John Dickerson and Keegan Hines", "title": "Counterfactual Explanations for Machine Learning: A Review", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning plays a role in many deployed decision systems, often in\nways that are difficult or impossible to understand by human stakeholders.\nExplaining, in a human-understandable way, the relationship between the input\nand output of machine learning models is essential to the development of\ntrustworthy machine-learning-based systems. A burgeoning body of research seeks\nto define the goals and methods of explainability in machine learning. In this\npaper, we seek to review and categorize research on counterfactual\nexplanations, a specific class of explanation that provides a link between what\ncould have happened had input to a model been changed in a particular way.\nModern approaches to counterfactual explainability in machine learning draw\nconnections to the established legal doctrine in many countries, making them\nappealing to fielded systems in high-impact areas such as finance and\nhealthcare. Thus, we design a rubric with desirable properties of\ncounterfactual explanation algorithms and comprehensively evaluate all\ncurrently-proposed algorithms against that rubric. Our rubric provides easy\ncomparison and comprehension of the advantages and disadvantages of different\napproaches and serves as an introduction to major research themes in this\nfield. We also identify gaps and discuss promising research directions in the\nspace of counterfactual explainability.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 20:08:42 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Verma", "Sahil", ""], ["Dickerson", "John", ""], ["Hines", "Keegan", ""]]}, {"id": "2010.10618", "submitter": "Christopher Lazarus", "authors": "Christopher Lazarus, James G. Lopez, Mykel J. Kochenderfer", "title": "Runtime Safety Assurance Using Reinforcement Learning", "comments": null, "journal-ref": "2020 IEEE/AIAA 39th Digital Avionics Systems Conference (DASC)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The airworthiness and safety of a non-pedigreed autopilot must be verified,\nbut the cost to formally do so can be prohibitive. We can bypass formal\nverification of non-pedigreed components by incorporating Runtime Safety\nAssurance (RTSA) as mechanism to ensure safety. RTSA consists of a\nmeta-controller that observes the inputs and outputs of a non-pedigreed\ncomponent and verifies formally specified behavior as the system operates. When\nthe system is triggered, a verified recovery controller is deployed. Recovery\ncontrollers are designed to be safe but very likely disruptive to the\noperational objective of the system, and thus RTSA systems must balance safety\nand efficiency. The objective of this paper is to design a meta-controller\ncapable of identifying unsafe situations with high accuracy. High dimensional\nand non-linear dynamics in which modern controllers are deployed along with the\nblack-box nature of the nominal controllers make this a difficult problem.\nCurrent approaches rely heavily on domain expertise and human engineering. We\nframe the design of RTSA with the Markov decision process (MDP) framework and\nuse reinforcement learning (RL) to solve it. Our learned meta-controller\nconsistently exhibits superior performance in our experiments compared to our\nbaseline, human engineered approach.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 20:54:46 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Lazarus", "Christopher", ""], ["Lopez", "James G.", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2010.10637", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, Linghao Jin, Xu Han, Jane You", "title": "Mutual Information Regularized Identity-aware Facial\n  ExpressionRecognition in Compressed Video", "comments": "Published in Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to extract effective expression representations that invariant to the\nidentity-specific attributes is a long-lasting problem for facial expression\nrecognition (FER). Most of the previous methods process the RGB images of a\nsequence, while we argue that the off-the-shelf and valuable expression-related\nmuscle movement is already embedded in the compression format. In this paper,\nwe target to explore the inter-subject variations eliminated facial expression\nrepresentation in the compressed video domain. In the up to two orders of\nmagnitude compressed domain, we can explicitly infer the expression from the\nresidual frames and possibly extract identity factors from the I frame with a\npre-trained face recognition network. By enforcing the marginal independence of\nthem, the expression feature is expected to be purer for the expression and be\nrobust to identity shifts. Specifically, we propose a novel collaborative\nmin-min game for mutual information (MI) minimization in latent space. We do\nnot need the identity label or multiple expression samples from the same person\nfor identity elimination. Moreover, when the apex frame is annotated in the\ndataset, the complementary constraint can be further added to regularize the\nfeature-level game. In testing, only the compressed residual frames are\nrequired to achieve expression prediction. Our solution can achieve comparable\nor better performance than the recent decoded image-based methods on the\ntypical FER benchmarks with about 3 times faster inference.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 21:42:18 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 15:09:55 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Jin", "Linghao", ""], ["Han", "Xu", ""], ["You", "Jane", ""]]}, {"id": "2010.10644", "submitter": "Daniel J. Mankowitz", "authors": "Daniel J. Mankowitz and Dan A. Calian and Rae Jeong and Cosmin\n  Paduraru and Nicolas Heess and Sumanth Dathathri and Martin Riedmiller and\n  Timothy Mann", "title": "Robust Constrained Reinforcement Learning for Continuous Control with\n  Model Misspecification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world physical control systems are required to satisfy constraints\nupon deployment. Furthermore, real-world systems are often subject to effects\nsuch as non-stationarity, wear-and-tear, uncalibrated sensors and so on. Such\neffects effectively perturb the system dynamics and can cause a policy trained\nsuccessfully in one domain to perform poorly when deployed to a perturbed\nversion of the same domain. This can affect a policy's ability to maximize\nfuture rewards as well as the extent to which it satisfies constraints. We\nrefer to this as constrained model misspecification. We present an algorithm\nthat mitigates this form of misspecification, and showcase its performance in\nmultiple simulated Mujoco tasks from the Real World Reinforcement Learning\n(RWRL) suite.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 22:05:37 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 20:51:18 GMT"}, {"version": "v3", "created": "Tue, 1 Dec 2020 10:32:32 GMT"}, {"version": "v4", "created": "Wed, 3 Mar 2021 09:54:49 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Mankowitz", "Daniel J.", ""], ["Calian", "Dan A.", ""], ["Jeong", "Rae", ""], ["Paduraru", "Cosmin", ""], ["Heess", "Nicolas", ""], ["Dathathri", "Sumanth", ""], ["Riedmiller", "Martin", ""], ["Mann", "Timothy", ""]]}, {"id": "2010.10645", "submitter": "Mohan Sridharan", "authors": "Tiago Mota, Mohan Sridharan", "title": "Axiom Learning and Belief Tracing for Transparent Decision Making in\n  Robotics", "comments": "10 pages, 5 figures, AAAI Fall Symposium on Artificial Intelligence\n  for Human-Robot Interaction: Trust & Explainability in Artificial\n  Intelligence for Human-Robot Interaction (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robot's ability to provide descriptions of its decisions and beliefs\npromotes effective collaboration with humans. Providing such transparency is\nparticularly challenging in integrated robot systems that include\nknowledge-based reasoning methods and data-driven learning algorithms. Towards\naddressing this challenge, our architecture couples the complementary strengths\nof non-monotonic logical reasoning, deep learning, and decision-tree induction.\nDuring reasoning and learning, the architecture enables a robot to provide\non-demand relational descriptions of its decisions, beliefs, and the outcomes\nof hypothetical actions. These capabilities are grounded and evaluated in the\ncontext of scene understanding tasks and planning tasks performed using\nsimulated images and images from a physical robot manipulating tabletop\nobjects.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 22:09:17 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Mota", "Tiago", ""], ["Sridharan", "Mohan", ""]]}, {"id": "2010.10699", "submitter": "Zhao Xinyan", "authors": "Xinyan Zhao, Liangwei Chen, Huanhuan Chen", "title": "A Weighted Heterogeneous Graph Based Dialogue System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge based dialogue systems have attracted increasing research interest\nin diverse applications. However, for disease diagnosis, the widely used\nknowledge graph is hard to represent the symptom-symptom relations and\nsymptom-disease relations since the edges of traditional knowledge graph are\nunweighted. Most research on disease diagnosis dialogue systems highly rely on\ndata-driven methods and statistical features, lacking profound comprehension of\nsymptom-disease relations and symptom-symptom relations. To tackle this issue,\nthis work presents a weighted heterogeneous graph based dialogue system for\ndisease diagnosis. Specifically, we build a weighted heterogeneous graph based\non symptom co-occurrence and a proposed symptom frequency-inverse disease\nfrequency. Then this work proposes a graph based deep Q-network (Graph-DQN) for\ndialogue management. By combining Graph Convolutional Network (GCN) with DQN to\nlearn the embeddings of diseases and symptoms from both the structural and\nattribute information in the weighted heterogeneous graph, Graph-DQN could\ncapture the symptom-disease relations and symptom-symptom relations better.\nExperimental results show that the proposed dialogue system rivals the\nstate-of-the-art models. More importantly, the proposed dialogue system can\ncomplete the task with less dialogue turns and possess a better distinguishing\ncapability on diseases with similar symptoms.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 01:22:37 GMT"}, {"version": "v2", "created": "Sat, 26 Dec 2020 02:09:25 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Zhao", "Xinyan", ""], ["Chen", "Liangwei", ""], ["Chen", "Huanhuan", ""]]}, {"id": "2010.10724", "submitter": "Jeffrey M. Dudek", "authors": "Jeffrey M. Dudek, Dror Fried, Kuldeep S. Meel", "title": "Taming Discrete Integration via the Boon of Dimensionality", "comments": "To be published at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete integration is a fundamental problem in computer science that\nconcerns the computation of discrete sums over exponentially large sets.\nDespite intense interest from researchers for over three decades, the design of\nscalable techniques for computing estimates with rigorous guarantees for\ndiscrete integration remains the holy grail. The key contribution of this work\naddresses this scalability challenge via an efficient reduction of discrete\nintegration to model counting. The proposed reduction is achieved via a\nsignificant increase in the dimensionality that, contrary to conventional\nwisdom, leads to solving an instance of the relatively simpler problem of model\ncounting.\n  Building on the promising approach proposed by Chakraborty et al, our work\novercomes the key weakness of their approach: a restriction to dyadic weights.\nWe augment our proposed reduction, called DeWeight, with a state of the art\nefficient approximate model counter and perform detailed empirical analysis\nover benchmarks arising from neural network verification domains, an emerging\napplication area of critical importance. DeWeight, to the best of our\nknowledge, is the first technique to compute estimates with provable guarantees\nfor this class of benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 02:32:51 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Dudek", "Jeffrey M.", ""], ["Fried", "Dror", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "2010.10763", "submitter": "Hrithwik Shalu", "authors": "Joseph N Stember, Hrithwik Shalu", "title": "Reinforcement learning using Deep Q Networks and Q learning accurately\n  localizes brain tumors on MRI with very small training sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose Supervised deep learning in radiology suffers from notorious inherent\nlimitations: 1) It requires large, hand-annotated data sets, 2) It is\nnon-generalizable, and 3) It lacks explainability and intuition. We have\nrecently proposed Reinforcement Learning to address all threes. However, we\napplied it to images with radiologist eye tracking points, which limits the\nstate-action space. Here we generalize the Deep-Q Learning to a gridworld-based\nenvironment, so that only the images and image masks are required.\n  Materials and Methods We trained a Deep Q network on 30 two-dimensional image\nslices from the BraTS brain tumor database. Each image contained one lesion. We\nthen tested the trained Deep Q network on a separate set of 30 testing set\nimages. For comparison, we also trained and tested a keypoint detection\nsupervised deep learning network for the same set of training / testing images.\n  Results Whereas the supervised approach quickly overfit the training data,\nand predicably performed poorly on the testing set (11\\% accuracy), the Deep-Q\nlearning approach showed progressive improved generalizability to the testing\nset over training time, reaching 70\\% accuracy.\n  Conclusion We have shown a proof-of-principle application of reinforcement\nlearning to radiological images, here using 2D contrast-enhanced MRI brain\nimages with the goal of localizing brain tumors. This represents a\ngeneralization of recent work to a gridworld setting, naturally suitable for\nanalyzing medical images.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 05:00:04 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 05:23:10 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Stember", "Joseph N", ""], ["Shalu", "Hrithwik", ""]]}, {"id": "2010.10771", "submitter": "Boris Ba\\v{c}i\\'c Dr.", "authors": "Boris Ba\\v{c}i\\'c and Jason Zhang", "title": "Towards Real-time Drowsiness Detection for Elderly Care", "comments": "This unpublished paper was accepted by the Conference on Innovative\n  Technologies in Intelligent Systems & Industrial Applications (CITISIA 2020)\n  [https://ieee-citisia.org] and uploaded to ArXiv.org preprint server. The\n  camera-ready copy with DOI should be available in IEEE Xplore sometimes after\n  the conference presentation and copyright transfer to IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The primary focus of this paper is to produce a proof of concept for\nextracting drowsiness information from videos to help elderly living on their\nown. To quantify yawning, eyelid and head movement over time, we extracted 3000\nimages from captured videos for training and testing of deep learning models\nintegrated with OpenCV library. The achieved classification accuracy for eyelid\nand mouth open/close status were between 94.3%-97.2%. Visual inspection of head\nmovement from videos with generated 3D coordinate overlays, indicated clear\nspatiotemporal patterns in collected data (yaw, roll and pitch). Extraction\nmethodology of the drowsiness information as timeseries is applicable to other\ncontexts including support for prior work in privacy-preserving augmented\ncoaching, sport rehabilitation, and integration with big data platform in\nhealthcare.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 05:48:59 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Ba\u010di\u0107", "Boris", ""], ["Zhang", "Jason", ""]]}, {"id": "2010.10777", "submitter": "Shubhra Kanti Karmaker Santu", "authors": "Shubhra Kanti Karmaker Santu, Md. Mahadi Hassan, Micah J. Smith, Lei\n  Xu, ChengXiang Zhai, Kalyan Veeramachaneni", "title": "AutoML to Date and Beyond: Challenges and Opportunities", "comments": "35 pages, survey article, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As big data becomes ubiquitous across domains, and more and more stakeholders\naspire to make the most of their data, demand for machine learning tools has\nspurred researchers to explore the possibilities of automated machine learning\n(AutoML). AutoML tools aim to make machine learning accessible for non-machine\nlearning experts (domain experts), to improve the efficiency of machine\nlearning, and to accelerate machine learning research. But although automation\nand efficiency are among AutoML's main selling points, the process still\nrequires human involvement at a number of vital steps, including understanding\nthe attributes of domain-specific data, defining prediction problems, creating\na suitable training data set, and selecting a promising machine learning\ntechnique. These steps often require a prolonged back-and-forth that makes this\nprocess inefficient for domain experts and data scientists alike, and keeps\nso-called AutoML systems from being truly automatic. In this review article, we\nintroduce a new classification system for AutoML systems, using a seven-tiered\nschematic to distinguish these systems based on their level of autonomy. We\nbegin by describing what an end-to-end machine learning pipeline actually looks\nlike, and which subtasks of the machine learning pipeline have been automated\nso far. We highlight those subtasks which are still done manually - generally\nby a data scientist - and explain how this limits domain experts' access to\nmachine learning. Next, we introduce our novel level-based taxonomy for AutoML\nsystems and define each level according to the scope of automation support\nprovided. Finally, we lay out a roadmap for the future, pinpointing the\nresearch required to further automate the end-to-end machine learning pipeline\nand discussing important challenges that stand in the way of this ambitious\ngoal.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 06:08:21 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 03:16:30 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 07:22:44 GMT"}, {"version": "v4", "created": "Wed, 19 May 2021 20:32:33 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Santu", "Shubhra Kanti Karmaker", ""], ["Hassan", "Md. Mahadi", ""], ["Smith", "Micah J.", ""], ["Xu", "Lei", ""], ["Zhai", "ChengXiang", ""], ["Veeramachaneni", "Kalyan", ""]]}, {"id": "2010.10804", "submitter": "Zhongzheng Ren", "authors": "Zhongzheng Ren, Zhiding Yu, Xiaodong Yang, Ming-Yu Liu, Alexander G.\n  Schwing, Jan Kautz", "title": "UFO$^2$: A Unified Framework towards Omni-supervised Object Detection", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing work on object detection often relies on a single form of\nannotation: the model is trained using either accurate yet costly bounding\nboxes or cheaper but less expressive image-level tags. However, real-world\nannotations are often diverse in form, which challenges these existing works.\nIn this paper, we present UFO$^2$, a unified object detection framework that\ncan handle different forms of supervision simultaneously. Specifically, UFO$^2$\nincorporates strong supervision (e.g., boxes), various forms of partial\nsupervision (e.g., class tags, points, and scribbles), and unlabeled data.\nThrough rigorous evaluations, we demonstrate that each form of label can be\nutilized to either train a model from scratch or to further improve a\npre-trained model. We also use UFO$^2$ to investigate budget-aware\nomni-supervised learning, i.e., various annotation policies are studied under a\nfixed annotation budget: we show that competitive performance needs no strong\nlabels for all data. Finally, we demonstrate the generalization of UFO$^2$,\ndetecting more than 1,000 different objects without bounding box annotations.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 07:46:30 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Ren", "Zhongzheng", ""], ["Yu", "Zhiding", ""], ["Yang", "Xiaodong", ""], ["Liu", "Ming-Yu", ""], ["Schwing", "Alexander G.", ""], ["Kautz", "Jan", ""]]}, {"id": "2010.10814", "submitter": "Kaixin Wang", "authors": "Kaixin Wang, Bingyi Kang, Jie Shao, Jiashi Feng", "title": "Improving Generalization in Reinforcement Learning with Mixture\n  Regularization", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) agents trained in a limited set of\nenvironments tend to suffer overfitting and fail to generalize to unseen\ntesting environments. To improve their generalizability, data augmentation\napproaches (e.g. cutout and random convolution) are previously explored to\nincrease the data diversity. However, we find these approaches only locally\nperturb the observations regardless of the training environments, showing\nlimited effectiveness on enhancing the data diversity and the generalization\nperformance. In this work, we introduce a simple approach, named mixreg, which\ntrains agents on a mixture of observations from different training environments\nand imposes linearity constraints on the observation interpolations and the\nsupervision (e.g. associated reward) interpolations. Mixreg increases the data\ndiversity more effectively and helps learn smoother policies. We verify its\neffectiveness on improving generalization by conducting extensive experiments\non the large-scale Procgen benchmark. Results show mixreg outperforms the\nwell-established baselines on unseen testing environments by a large margin.\nMixreg is simple, effective and general. It can be applied to both policy-based\nand value-based RL algorithms. Code is available at\nhttps://github.com/kaixin96/mixreg .\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 08:12:03 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Wang", "Kaixin", ""], ["Kang", "Bingyi", ""], ["Shao", "Jie", ""], ["Feng", "Jiashi", ""]]}, {"id": "2010.10836", "submitter": "Deepak P", "authors": "Soumya Suvra Ghosal, Deepak P, Anna Jurek-Loughrey", "title": "ReSCo-CC: Unsupervised Identification of Key Disinformation Sentences", "comments": "The 22nd International Conference on Information Integration and\n  Web-based Applications & Services (iiWAS '20), Chiang Mai, Thailand", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disinformation is often presented in long textual articles, especially when\nit relates to domains such as health, often seen in relation to COVID-19. These\narticles are typically observed to have a number of trustworthy sentences among\nwhich core disinformation sentences are scattered. In this paper, we propose a\nnovel unsupervised task of identifying sentences containing key disinformation\nwithin a document that is known to be untrustworthy. We design a three-phase\nstatistical NLP solution for the task which starts with embedding sentences\nwithin a bespoke feature space designed for the task. Sentences represented\nusing those features are then clustered, following which the key sentences are\nidentified through proximity scoring. We also curate a new dataset with\nsentence level disinformation scorings to aid evaluation for this task; the\ndataset is being made publicly available to facilitate further research. Based\non a comprehensive empirical evaluation against techniques from related tasks\nsuch as claim detection and summarization, as well as against simplified\nvariants of our proposed approach, we illustrate that our method is able to\nidentify core disinformation effectively.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 08:53:36 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Ghosal", "Soumya Suvra", ""], ["P", "Deepak", ""], ["Jurek-Loughrey", "Anna", ""]]}, {"id": "2010.10873", "submitter": "Milad Moradi", "authors": "Milad Moradi, Matthias Samwald", "title": "Explaining black-box text classifiers for disease-treatment information\n  extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks and other intricate Artificial Intelligence (AI) models\nhave reached high levels of accuracy on many biomedical natural language\nprocessing tasks. However, their applicability in real-world use cases may be\nlimited due to their vague inner working and decision logic. A post-hoc\nexplanation method can approximate the behavior of a black-box AI model by\nextracting relationships between feature values and outcomes. In this paper, we\nintroduce a post-hoc explanation method that utilizes confident itemsets to\napproximate the behavior of black-box classifiers for medical information\nextraction. Incorporating medical concepts and semantics into the explanation\nprocess, our explanator finds semantic relations between inputs and outputs in\ndifferent parts of the decision space of a black-box classifier. The\nexperimental results show that our explanation method can outperform\nperturbation and decision set based explanators in terms of fidelity and\ninterpretability of explanations produced for predictions on a\ndisease-treatment information extraction task.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 09:58:00 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Moradi", "Milad", ""], ["Samwald", "Matthias", ""]]}, {"id": "2010.10874", "submitter": "Erik Ekstedt", "authors": "Erik Ekstedt and Gabriel Skantze", "title": "TurnGPT: a Transformer-based Language Model for Predicting Turn-taking\n  in Spoken Dialog", "comments": "Accepted to Findings of ACL: EMNLP 2020", "journal-ref": null, "doi": "10.18653/v1/2020.findings-emnlp.268", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntactic and pragmatic completeness is known to be important for turn-taking\nprediction, but so far machine learning models of turn-taking have used such\nlinguistic information in a limited way. In this paper, we introduce TurnGPT, a\ntransformer-based language model for predicting turn-shifts in spoken dialog.\nThe model has been trained and evaluated on a variety of written and spoken\ndialog datasets. We show that the model outperforms two baselines used in prior\nwork. We also report on an ablation study, as well as attention and gradient\nanalyses, which show that the model is able to utilize the dialog context and\npragmatic completeness for turn-taking prediction. Finally, we explore the\nmodel's potential in not only detecting, but also projecting, turn-completions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 09:58:39 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Ekstedt", "Erik", ""], ["Skantze", "Gabriel", ""]]}, {"id": "2010.10885", "submitter": "Frank Neumann", "authors": "Frank Neumann and Mojgan Pourhassan and Carsten Witt", "title": "Improved Runtime Results for Simple Randomised Search Heuristics on\n  Linear Functions with a Uniform Constraint", "comments": "Journal version to appear in Algorithmica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade remarkable progress has been made in development of\nsuitable proof techniques for analysing randomised search heuristics. The\ntheoretical investigation of these algorithms on classes of functions is\nessential to the understanding of the underlying stochastic process. Linear\nfunctions have been traditionally studied in this area resulting in tight\nbounds on the expected optimisation time of simple randomised search algorithms\nfor this class of problems. Recently, the constrained version of this problem\nhas gained attention and some theoretical results have also been obtained on\nthis class of problems. In this paper we study the class of linear functions\nunder uniform constraint and investigate the expected optimisation time of\nRandomised Local Search (RLS) and a simple evolutionary algorithm called (1+1)\nEA. We prove a tight bound of $\\Theta(n^2)$ for RLS and improve the previously\nbest known upper bound of (1+1) EA from $O(n^2 \\log (Bw_{\\max}))$ to $O(n^2\\log\nB)$ in expectation and to $O(n^2 \\log n)$ with high probability, where\n$w_{\\max}$ and $B$ are the maximum weight of the linear objective function and\nthe bound of the uniform constraint, respectively. Also, we obtain a tight\nbound of $O(n^2)$ for the (1+1) EA on a special class of instances. We\ncomplement our theoretical studies by experimental investigations that consider\ndifferent values of $B$ and also higher mutation rates that reflect the fact\nthat $2$-bit flips are crucial for dealing with the uniform constraint.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 10:42:39 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Neumann", "Frank", ""], ["Pourhassan", "Mojgan", ""], ["Witt", "Carsten", ""]]}, {"id": "2010.10900", "submitter": "Tommaso Soru", "authors": "Anand Panchbhai and Tommaso Soru and Edgard Marx", "title": "Exploring Sequence-to-Sequence Models for SPARQL Pattern Composition", "comments": "Proceedings of the First Indo-American Knowledge Graph and Semantic\n  Web Conference (KGSWC-India 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A booming amount of information is continuously added to the Internet as\nstructured and unstructured data, feeding knowledge bases such as DBpedia and\nWikidata with billions of statements describing millions of entities. The aim\nof Question Answering systems is to allow lay users to access such data using\nnatural language without needing to write formal queries. However, users often\nsubmit questions that are complex and require a certain level of abstraction\nand reasoning to decompose them into basic graph patterns. In this short paper,\nwe explore the use of architectures based on Neural Machine Translation called\nNeural SPARQL Machines to learn pattern compositions. We show that\nsequence-to-sequence models are a viable and promising option to transform long\nutterances into complex SPARQL queries.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 11:12:01 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Panchbhai", "Anand", ""], ["Soru", "Tommaso", ""], ["Marx", "Edgard", ""]]}, {"id": "2010.10903", "submitter": "Jon\\'a\\v{s} Kulh\\'anek", "authors": "Jon\\'a\\v{s} Kulh\\'anek and Erik Derner and Robert Babu\\v{s}ka", "title": "Visual Navigation in Real-World Indoor Environments Using End-to-End\n  Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual navigation is essential for many applications in robotics, from\nmanipulation, through mobile robotics to automated driving. Deep reinforcement\nlearning (DRL) provides an elegant map-free approach integrating image\nprocessing, localization, and planning in one module, which can be trained and\ntherefore optimized for a given environment. However, to date, DRL-based visual\nnavigation was validated exclusively in simulation, where the simulator\nprovides information that is not available in the real world, e.g., the robot's\nposition or image segmentation masks. This precludes the use of the learned\npolicy on a real robot. Therefore, we propose a novel approach that enables a\ndirect deployment of the trained policy on real robots. We have designed visual\nauxiliary tasks, a tailored reward scheme, and a new powerful simulator to\nfacilitate domain randomization. The policy is fine-tuned on images collected\nfrom real-world environments. We have evaluated the method on a mobile robot in\na real office environment. The training took ~30 hours on a single GPU. In 30\nnavigation experiments, the robot reached a 0.3-meter neighborhood of the goal\nin more than 86.7% of cases. This result makes the proposed method directly\napplicable to tasks like mobile manipulation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 11:22:30 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Kulh\u00e1nek", "Jon\u00e1\u0161", ""], ["Derner", "Erik", ""], ["Babu\u0161ka", "Robert", ""]]}, {"id": "2010.10932", "submitter": "Sungchul Choi", "authors": "Jaewoong Choi, Sion Jang, Jaeyoung Kim, Jiho Lee, Janghyeok Yoona,\n  Sungchul Choi", "title": "Deep learning-based citation recommendation system for patents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this study, we address the challenges in developing a deep learning-based\nautomatic patent citation recommendation system. Although deep learning-based\nrecommendation systems have exhibited outstanding performance in various\ndomains (such as movies, products, and paper citations), their validity in\npatent citations has not been investigated, owing to the lack of a freely\navailable high-quality dataset and relevant benchmark model. To solve these\nproblems, we present a novel dataset called PatentNet that includes textual\ninformation and metadata for approximately 110,000 patents from the Google Big\nQuery service. Further, we propose strong benchmark models considering the\nsimilarity of textual information and metadata (such as cooperative patent\nclassification code). Compared with existing recommendation methods, the\nproposed benchmark method achieved a mean reciprocal rank of 0.2377 on the test\nset, whereas the existing state-of-the-art recommendation method achieved\n0.2073.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 12:18:21 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Choi", "Jaewoong", ""], ["Jang", "Sion", ""], ["Kim", "Jaeyoung", ""], ["Lee", "Jiho", ""], ["Yoona", "Janghyeok", ""], ["Choi", "Sungchul", ""]]}, {"id": "2010.10981", "submitter": "Laura Graves", "authors": "Laura Graves, Vineel Nagisetty, Vijay Ganesh", "title": "Amnesiac Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Right to be Forgotten is part of the recently enacted General Data\nProtection Regulation (GDPR) law that affects any data holder that has data on\nEuropean Union residents. It gives EU residents the ability to request deletion\nof their personal data, including training records used to train machine\nlearning models. Unfortunately, Deep Neural Network models are vulnerable to\ninformation leaking attacks such as model inversion attacks which extract class\ninformation from a trained model and membership inference attacks which\ndetermine the presence of an example in a model's training data. If a malicious\nparty can mount an attack and learn private information that was meant to be\nremoved, then it implies that the model owner has not properly protected their\nuser's rights and their models may not be compliant with the GDPR law. In this\npaper, we present two efficient methods that address this question of how a\nmodel owner or data holder may delete personal data from models in such a way\nthat they may not be vulnerable to model inversion and membership inference\nattacks while maintaining model efficacy. We start by presenting a real-world\nthreat model that shows that simply removing training data is insufficient to\nprotect users. We follow that up with two data removal methods, namely\nUnlearning and Amnesiac Unlearning, that enable model owners to protect\nthemselves against such attacks while being compliant with regulations. We\nprovide extensive empirical analysis that show that these methods are indeed\nefficient, safe to apply, effectively remove learned information about\nsensitive data from trained models while maintaining model efficacy.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 13:14:17 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Graves", "Laura", ""], ["Nagisetty", "Vineel", ""], ["Ganesh", "Vijay", ""]]}, {"id": "2010.10992", "submitter": "Anay Mehrotra", "authors": "L. Elisa Celis, Chris Hays, Anay Mehrotra, Nisheeth K. Vishnoi", "title": "The Effect of the Rooney Rule on Implicit Bias in the Long Term", "comments": "Abstract shortened to satisfy the 1920 character limit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robust body of evidence demonstrates the adverse effects of implicit bias\nin various contexts--from hiring to health care. The Rooney Rule is an\nintervention developed to counter implicit bias and has been implemented in the\nprivate and public sectors. The Rooney Rule requires that a selection panel\ninclude at least one candidate from an underrepresented group in their\nshortlist of candidates. Recently, Kleinberg and Raghavan proposed a model of\nimplicit bias and studied the effectiveness of the Rooney Rule when applied to\na single selection decision. However, selection decisions often occur\nrepeatedly over time. Further, it has been observed that, given consistent\ncounterstereotypical feedback, implicit biases against underrepresented\ncandidates can change.\n  We consider a model of how a selection panel's implicit bias changes over\ntime given their hiring decisions either with or without the Rooney Rule in\nplace. Our main result is that, when the panel is constrained by the Rooney\nRule, their implicit bias roughly reduces at a rate that is the inverse of the\nsize of the shortlist--independent of the number of candidates, whereas without\nthe Rooney Rule, the rate is inversely proportional to the number of\ncandidates. Thus, when the number of candidates is much larger than the size of\nthe shortlist, the Rooney Rule enables a faster reduction in implicit bias,\nproviding an additional reason in favor of using it as a strategy to mitigate\nimplicit bias. Towards empirically evaluating the long-term effect of the\nRooney Rule in repeated selection decisions, we conduct an iterative candidate\nselection experiment on Amazon MTurk. We observe that, indeed, decision-makers\nsubject to the Rooney Rule select more minority candidates in addition to those\nrequired by the rule itself than they would if no rule is in effect, and do so\nwithout considerably decreasing the utility of candidates selected.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 13:33:00 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Celis", "L. Elisa", ""], ["Hays", "Chris", ""], ["Mehrotra", "Anay", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "2010.10998", "submitter": "Aditya Kalyanpur", "authors": "Aditya Kalyanpur, Or Biran, Tom Breloff, Jennifer Chu-Carroll, Ariel\n  Diertani, Owen Rambow, Mark Sammons", "title": "Open-Domain Frame Semantic Parsing Using Transformers", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frame semantic parsing is a complex problem which includes multiple\nunderlying subtasks. Recent approaches have employed joint learning of subtasks\n(such as predicate and argument detection), and multi-task learning of related\ntasks (such as syntactic and semantic parsing). In this paper, we explore\nmulti-task learning of all subtasks with transformer-based models. We show that\na purely generative encoder-decoder architecture handily beats the previous\nstate of the art in FrameNet 1.7 parsing, and that a mixed decoding multi-task\napproach achieves even better performance. Finally, we show that the multi-task\nmodel also outperforms recent state of the art systems for PropBank SRL parsing\non the CoNLL 2012 benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 13:38:04 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 23:37:12 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Kalyanpur", "Aditya", ""], ["Biran", "Or", ""], ["Breloff", "Tom", ""], ["Chu-Carroll", "Jennifer", ""], ["Diertani", "Ariel", ""], ["Rambow", "Owen", ""], ["Sammons", "Mark", ""]]}, {"id": "2010.11003", "submitter": "Chi-Liang Liu", "authors": "Chi-Liang Liu and Hung-yi Lee", "title": "Unsupervised Deep Learning based Multiple Choices Question Answering:\n  Start Learning from Basic Knowledge", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the possibility of almost unsupervised Multiple\nChoices Question Answering (MCQA). Starting from very basic knowledge, MCQA\nmodel knows that some choices have higher probabilities of being correct than\nthe others. The information, though very noisy, guides the training of an MCQA\nmodel. The proposed method is shown to outperform the baseline approaches on\nRACE and even comparable with some supervised learning approaches on MC500.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 13:44:35 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Liu", "Chi-Liang", ""], ["Lee", "Hung-yi", ""]]}, {"id": "2010.11025", "submitter": "Ammar Malik", "authors": "Ammar Malik, Hugo Lhachemi, and Robert Shorten", "title": "I-nteract 2.0: A Cyber-Physical System to Design 3D Models using Mixed\n  Reality Technologies and Deep Learning for Additive Manufacturing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I-nteract is a cyber-physical system that enables real-time interaction with\nboth virtual and real artifacts to design 3D models for additive manufacturing\nby leveraging on mixed reality technologies. This paper presents novel advances\nin the development of the interaction platform I-nteract to generate 3D models\nusing both constructive solid geometry and artificial intelligence. The system\nalso enables the user to adjust the dimensions of the 3D models with respect to\ntheir physical workspace. The effectiveness of the system is demonstrated by\ngenerating 3D models of furniture (e.g., chairs and tables) and fitting them\ninto the physical space in a mixed reality environment.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 14:13:21 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Malik", "Ammar", ""], ["Lhachemi", "Hugo", ""], ["Shorten", "Robert", ""]]}, {"id": "2010.11034", "submitter": "Joao Marques-Silva", "authors": "Yacine Izza, Alexey Ignatiev, and Joao Marques-Silva", "title": "On Explaining Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision trees (DTs) epitomize what have become to be known as interpretable\nmachine learning (ML) models. This is informally motivated by paths in DTs\nbeing often much smaller than the total number of features. This paper shows\nthat in some settings DTs can hardly be deemed interpretable, with paths in a\nDT being arbitrarily larger than a PI-explanation, i.e. a subset-minimal set of\nfeature values that entails the prediction. As a result, the paper proposes a\nnovel model for computing PI-explanations of DTs, which enables computing one\nPI-explanation in polynomial time. Moreover, it is shown that enumeration of\nPI-explanations can be reduced to the enumeration of minimal hitting sets.\nExperimental results were obtained on a wide range of publicly available\ndatasets with well-known DT-learning tools, and confirm that in most cases DTs\nhave paths that are proper supersets of PI-explanations.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 14:33:53 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Izza", "Yacine", ""], ["Ignatiev", "Alexey", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "2010.11038", "submitter": "Jinke He", "authors": "Jinke He and Miguel Suau and Frans A. Oliehoek", "title": "Influence-Augmented Online Planning for Complex Environments", "comments": "NeurIPS2020 - results have been updated after fixing minor bugs in\n  the code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we plan efficiently in real time to control an agent in a complex\nenvironment that may involve many other agents? While existing sample-based\nplanners have enjoyed empirical success in large POMDPs, their performance\nheavily relies on a fast simulator. However, real-world scenarios are complex\nin nature and their simulators are often computationally demanding, which\nseverely limits the performance of online planners. In this work, we propose\ninfluence-augmented online planning, a principled method to transform a\nfactored simulator of the entire environment into a local simulator that\nsamples only the state variables that are most relevant to the observation and\nreward of the planning agent and captures the incoming influence from the rest\nof the environment using machine learning methods. Our main experimental\nresults show that planning on this less accurate but much faster local\nsimulator with POMCP leads to higher real-time planning performance than\nplanning on the simulator that models the entire environment.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 14:39:26 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 15:28:23 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["He", "Jinke", ""], ["Suau", "Miguel", ""], ["Oliehoek", "Frans A.", ""]]}, {"id": "2010.11062", "submitter": "Hongda Shen", "authors": "Hongda Shen, Eren Kurshan", "title": "Deep Q-Network-based Adaptive Alert Threshold Selection Policy for\n  Payment Fraud Systems in Retail Banking", "comments": null, "journal-ref": null, "doi": "10.1145/3383455.3422563", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have widely been used in fraud detection systems.\nMost of the research and development efforts have been concentrated on\nimproving the performance of the fraud scoring models. Yet, the downstream\nfraud alert systems still have limited to no model adoption and rely on manual\nsteps. Alert systems are pervasively used across all payment channels in retail\nbanking and play an important role in the overall fraud detection process.\nCurrent fraud detection systems end up with large numbers of dropped alerts due\nto their inability to account for the alert processing capacity. Ideally, alert\nthreshold selection enables the system to maximize the fraud detection while\nbalancing the upstream fraud scores and the available bandwidth of the alert\nprocessing teams. However, in practice, fixed thresholds that are used for\ntheir simplicity do not have this ability. In this paper, we propose an\nenhanced threshold selection policy for fraud alert systems. The proposed\napproach formulates the threshold selection as a sequential decision making\nproblem and uses Deep Q-Network based reinforcement learning. Experimental\nresults show that this adaptive approach outperforms the current static\nsolutions by reducing the fraud losses as well as improving the operational\nefficiency of the alert system.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 15:10:57 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Shen", "Hongda", ""], ["Kurshan", "Eren", ""]]}, {"id": "2010.11066", "submitter": "Chenyu You", "authors": "Chenyu You, Nuo Chen, Yuexian Zou", "title": "Contextualized Attention-based Knowledge Transfer for Spoken\n  Conversational Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken conversational question answering (SCQA) requires machines to model\ncomplex dialogue flow given the speech utterances and text corpora. Different\nfrom traditional text question answering (QA) tasks, SCQA involves audio signal\nprocessing, passage comprehension, and contextual understanding. However, ASR\nsystems introduce unexpected noisy signals to the transcriptions, which result\nin performance degradation on SCQA. To overcome the problem, we propose CADNet,\na novel contextualized attention-based distillation approach, which applies\nboth cross-attention and self-attention to obtain ASR-robust contextualized\nembedding representations of the passage and dialogue history for performance\nimprovements. We also introduce the spoken conventional knowledge distillation\nframework to distill the ASR-robust knowledge from the estimated probabilities\nof the teacher model to the student. We conduct extensive experiments on the\nSpoken-CoQA dataset and demonstrate that our approach achieves remarkable\nperformance in this task.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 15:17:18 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 02:17:26 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 20:04:11 GMT"}, {"version": "v4", "created": "Thu, 24 Jun 2021 16:32:18 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["You", "Chenyu", ""], ["Chen", "Nuo", ""], ["Zou", "Yuexian", ""]]}, {"id": "2010.11067", "submitter": "Chenyu You", "authors": "Chenyu You, Nuo Chen, Yuexian Zou", "title": "Knowledge Distillation for Improved Accuracy in Spoken Question\n  Answering", "comments": "To appear in ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken question answering (SQA) is a challenging task that requires the\nmachine to fully understand the complex spoken documents. Automatic speech\nrecognition (ASR) plays a significant role in the development of QA systems.\nHowever, the recent work shows that ASR systems generate highly noisy\ntranscripts, which critically limit the capability of machine comprehension on\nthe SQA task. To address the issue, we present a novel distillation framework.\nSpecifically, we devise a training strategy to perform knowledge distillation\n(KD) from spoken documents and written counterparts. Our work makes a step\ntowards distilling knowledge from the language model as a supervision signal to\nlead to better student accuracy by reducing the misalignment between automatic\nand manual transcriptions. Experiments demonstrate that our approach\noutperforms several state-of-the-art language models on the Spoken-SQuAD\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 15:18:01 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 02:16:42 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 02:26:27 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["You", "Chenyu", ""], ["Chen", "Nuo", ""], ["Zou", "Yuexian", ""]]}, {"id": "2010.11123", "submitter": "Daniel Ajisafe", "authors": "Daniel Ajisafe, Oluwabukola Adegboro, Esther Oduntan, Tayo Arulogun", "title": "Towards End-to-End Training of Automatic Speech Recognition for Nigerian\n  Pidgin", "comments": "To appear in ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nigerian Pidgin remains one of the most popular languages in West Africa.\nWith at least 75 million speakers along the West African coast, the language\nhas spread to diasporic communities through Nigerian immigrants in England,\nCanada, and America, amongst others. In contrast, the language remains an\nunder-resourced one in the field of natural language processing, particularly\non speech recognition and translation tasks. In this work, we present the first\nparallel (speech-to-text) data on Nigerian pidgin. We also trained the first\nend-to-end speech recognition system (QuartzNet and Jasper model) on this\nlanguage which were both optimized using Connectionist Temporal Classification\n(CTC) loss. With baseline results, we were able to achieve a low word error\nrate (WER) of 0.77% using a greedy decoder on our dataset. Finally, we\nopen-source the data and code along with this publication in order to encourage\nfuture research in this direction.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 16:32:58 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Ajisafe", "Daniel", ""], ["Adegboro", "Oluwabukola", ""], ["Oduntan", "Esther", ""], ["Arulogun", "Tayo", ""]]}, {"id": "2010.11137", "submitter": "Yan Zeng", "authors": "Yan Zeng and Jian-Yun Nie", "title": "Multi-Domain Dialogue State Tracking based on State Graph", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of multi-domain Dialogue State Tracking (DST) with\nopen vocabulary, which aims to extract the state from the dialogue. Existing\napproaches usually concatenate previous dialogue state with dialogue history as\nthe input to a bi-directional Transformer encoder. They rely on the\nself-attention mechanism of Transformer to connect tokens in them. However,\nattention may be paid to spurious connections, leading to wrong inference. In\nthis paper, we propose to construct a dialogue state graph in which domains,\nslots and values from the previous dialogue state are connected properly.\nThrough training, the graph node and edge embeddings can encode co-occurrence\nrelations between domain-domain, slot-slot and domain-slot, reflecting the\nstrong transition paths in general dialogue. The state graph, encoded with\nrelational-GCN, is fused into the Transformer encoder. Experimental results\nshow that our approach achieves a new state of the art on the task while\nremaining efficient. It outperforms existing open-vocabulary DST approaches.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 16:55:18 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Zeng", "Yan", ""], ["Nie", "Jian-Yun", ""]]}, {"id": "2010.11140", "submitter": "Yan Zeng", "authors": "Yan Zeng and Jian-Yun Nie", "title": "A Simple and Efficient Multi-Task Learning Approach for Conditioned\n  Dialogue Generation", "comments": "Accepted as NAACL 2021 Long Paper (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Conditioned dialogue generation suffers from the scarcity of labeled\nresponses. In this work, we exploit labeled non-dialogue text data related to\nthe condition, which are much easier to collect. We propose a multi-task\nlearning approach to leverage both labeled dialogue and text data. The 3 tasks\njointly optimize the same pre-trained Transformer -- conditioned dialogue\ngeneration task on the labeled dialogue data, conditioned language encoding\ntask and conditioned language generation task on the labeled text data.\nExperimental results show that our approach outperforms the state-of-the-art\nmodels by leveraging the labeled texts, and it also obtains larger improvement\nin performance comparing to the previous methods to leverage text data.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 16:56:49 GMT"}, {"version": "v2", "created": "Sat, 24 Apr 2021 14:51:24 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zeng", "Yan", ""], ["Nie", "Jian-Yun", ""]]}, {"id": "2010.11143", "submitter": "Zejian Luo", "authors": "Ling Wang, Cheng Zhang, Zejian Luo, Chenguang Liu, Jie Liu, Xi Zheng,\n  and Athanasios Vasilakos", "title": "Progressive Defense Against Adversarial Attacks for Deep Learning as a\n  Service in Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, Deep Learning as a service can be deployed in Internet of Things\n(IoT) to provide smart services and sensor data processing. However, recent\nresearch has revealed that some Deep Neural Networks (DNN) can be easily misled\nby adding relatively small but adversarial perturbations to the input (e.g.,\npixel mutation in input images). One challenge in defending DNN against these\nattacks is to efficiently identifying and filtering out the adversarial pixels.\nThe state-of-the-art defense strategies with good robustness often require\nadditional model training for specific attacks. To reduce the computational\ncost without loss of generality, we present a defense strategy called a\nprogressive defense against adversarial attacks (PDAAA) for efficiently and\neffectively filtering out the adversarial pixel mutations, which could mislead\nthe neural network towards erroneous outputs, without a-priori knowledge about\nthe attack type. We evaluated our progressive defense strategy against various\nattack methods on two well-known datasets. The result shows it outperforms the\nstate-of-the-art while reducing the cost of model training by 50% on average.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 06:40:53 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Wang", "Ling", ""], ["Zhang", "Cheng", ""], ["Luo", "Zejian", ""], ["Liu", "Chenguang", ""], ["Liu", "Jie", ""], ["Zheng", "Xi", ""], ["Vasilakos", "Athanasios", ""]]}, {"id": "2010.11148", "submitter": "Jiahui Yu", "authors": "Jiahui Yu, Chung-Cheng Chiu, Bo Li, Shuo-yiin Chang, Tara N. Sainath,\n  Yanzhang He, Arun Narayanan, Wei Han, Anmol Gulati, Yonghui Wu, Ruoming Pang", "title": "FastEmit: Low-latency Streaming ASR with Sequence-level Emission\n  Regularization", "comments": "Accepted in ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Streaming automatic speech recognition (ASR) aims to emit each hypothesized\nword as quickly and accurately as possible. However, emitting fast without\ndegrading quality, as measured by word error rate (WER), is highly challenging.\nExisting approaches including Early and Late Penalties and Constrained\nAlignments penalize emission delay by manipulating per-token or per-frame\nprobability prediction in sequence transducer models. While being successful in\nreducing delay, these approaches suffer from significant accuracy regression\nand also require additional word alignment information from an existing model.\nIn this work, we propose a sequence-level emission regularization method, named\nFastEmit, that applies latency regularization directly on per-sequence\nprobability in training transducer models, and does not require any alignment.\nWe demonstrate that FastEmit is more suitable to the sequence-level\noptimization of transducer models for streaming ASR by applying it on various\nend-to-end streaming ASR networks including RNN-Transducer,\nTransformer-Transducer, ConvNet-Transducer and Conformer-Transducer. We achieve\n150-300 ms latency reduction with significantly better accuracy over previous\ntechniques on a Voice Search test set. FastEmit also improves streaming ASR\naccuracy from 4.4%/8.9% to 3.1%/7.5% WER, meanwhile reduces 90th percentile\nlatency from 210 ms to only 30 ms on LibriSpeech.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 17:05:01 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 20:59:05 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Yu", "Jiahui", ""], ["Chiu", "Chung-Cheng", ""], ["Li", "Bo", ""], ["Chang", "Shuo-yiin", ""], ["Sainath", "Tara N.", ""], ["He", "Yanzhang", ""], ["Narayanan", "Arun", ""], ["Han", "Wei", ""], ["Gulati", "Anmol", ""], ["Wu", "Yonghui", ""], ["Pang", "Ruoming", ""]]}, {"id": "2010.11151", "submitter": "Gergely Neu", "authors": "Joan Bas-Serrano, Sebastian Curi, Andreas Krause, Gergely Neu", "title": "Logistic Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new reinforcement learning algorithm derived from a regularized\nlinear-programming formulation of optimal control in MDPs. The method is\nclosely related to the classic Relative Entropy Policy Search (REPS) algorithm\nof Peters et al. (2010), with the key difference that our method introduces a\nQ-function that enables efficient exact model-free implementation. The main\nfeature of our algorithm (called QREPS) is a convex loss function for policy\nevaluation that serves as a theoretically sound alternative to the widely used\nsquared Bellman error. We provide a practical saddle-point optimization method\nfor minimizing this loss function and provide an error-propagation analysis\nthat relates the quality of the individual updates to the performance of the\noutput policy. Finally, we demonstrate the effectiveness of our method on a\nrange of benchmark problems.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 17:14:31 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 21:34:03 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Bas-Serrano", "Joan", ""], ["Curi", "Sebastian", ""], ["Krause", "Andreas", ""], ["Neu", "Gergely", ""]]}, {"id": "2010.11170", "submitter": "Ozan \\.Irsoy", "authors": "Tianze Shi, Igor Malioutov, Ozan \\.Irsoy", "title": "Semantic Role Labeling as Syntactic Dependency Parsing", "comments": "Appeared in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reduce the task of (span-based) PropBank-style semantic role labeling\n(SRL) to syntactic dependency parsing. Our approach is motivated by our\nempirical analysis that shows three common syntactic patterns account for over\n98% of the SRL annotations for both English and Chinese data. Based on this\nobservation, we present a conversion scheme that packs SRL annotations into\ndependency tree representations through joint labels that permit highly\naccurate recovery back to the original format. This representation allows us to\ntrain statistical dependency parsers to tackle SRL and achieve competitive\nperformance with the current state of the art. Our findings show the promise of\nsyntactic dependency trees in encoding semantic role relations within their\nsyntactic domain of locality, and point to potential further integration of\nsyntactic methods into semantic role labeling in the future.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 17:46:11 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Shi", "Tianze", ""], ["Malioutov", "Igor", ""], ["\u0130rsoy", "Ozan", ""]]}, {"id": "2010.11223", "submitter": "Tim Genewein", "authors": "Vladimir Mikulik, Gr\\'egoire Del\\'etang, Tom McGrath, Tim Genewein,\n  Miljan Martic, Shane Legg, Pedro A. Ortega", "title": "Meta-trained agents implement Bayes-optimal agents", "comments": "Published at 34th Conference on Neural Information Processing Systems\n  (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory-based meta-learning is a powerful technique to build agents that adapt\nfast to any task within a target distribution. A previous theoretical study has\nargued that this remarkable performance is because the meta-training protocol\nincentivises agents to behave Bayes-optimally. We empirically investigate this\nclaim on a number of prediction and bandit tasks. Inspired by ideas from\ntheoretical computer science, we show that meta-learned and Bayes-optimal\nagents not only behave alike, but they even share a similar computational\nstructure, in the sense that one agent system can approximately simulate the\nother. Furthermore, we show that Bayes-optimal agents are fixed points of the\nmeta-learning dynamics. Our results suggest that memory-based meta-learning\nmight serve as a general technique for numerically approximating Bayes-optimal\nagents - that is, even for task distributions for which we currently don't\npossess tractable models.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 18:05:21 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Mikulik", "Vladimir", ""], ["Del\u00e9tang", "Gr\u00e9goire", ""], ["McGrath", "Tom", ""], ["Genewein", "Tim", ""], ["Martic", "Miljan", ""], ["Legg", "Shane", ""], ["Ortega", "Pedro A.", ""]]}, {"id": "2010.11246", "submitter": "Tianze Shi", "authors": "Tianze Shi, Chen Zhao, Jordan Boyd-Graber, Hal Daum\\'e III and Lillian\n  Lee", "title": "On the Potential of Lexico-logical Alignments for Semantic Parsing to\n  SQL Queries", "comments": "Findings of ACL: EMNLP 2020", "journal-ref": "Findings of ACL: EMNLP 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale semantic parsing datasets annotated with logical forms have\nenabled major advances in supervised approaches. But can richer supervision\nhelp even more? To explore the utility of fine-grained, lexical-level\nsupervision, we introduce Squall, a dataset that enriches 11,276\nWikiTableQuestions English-language questions with manually created SQL\nequivalents plus alignments between SQL and question fragments. Our annotation\nenables new training possibilities for encoder-decoder models, including\napproaches from machine translation previously precluded by the absence of\nalignments. We propose and test two methods: (1) supervised attention; (2)\nadopting an auxiliary objective of disambiguating references in the input\nqueries to table columns. In 5-fold cross validation, these strategies improve\nover strong baselines by 4.4% execution accuracy. Oracle experiments suggest\nthat annotated alignments can support further accuracy gains of up to 23.9%.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 19:01:00 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Shi", "Tianze", ""], ["Zhao", "Chen", ""], ["Boyd-Graber", "Jordan", ""], ["Daum\u00e9", "Hal", "III"], ["Lee", "Lillian", ""]]}, {"id": "2010.11270", "submitter": "Roger M\\\"uller A", "authors": "Roger Alexander M\\\"uller, Jonathan Laflamme-Janssen, Jaime Camacaro,\n  Carolina Bessega", "title": "Learning second order coupled differential equations that are subject to\n  non-conservative forces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we address the question whether it is possible to learn the\ndifferential equations describing the physical properties of a dynamical\nsystem, subject to non-conservative forces, from observations of its realspace\ntrajectory(ies) only. We introduce a network that incorporates a difference\napproximation for the second order derivative in terms of residual connections\nbetween convolutional blocks, whose shared weights represent the coefficients\nof a second order ordinary differential equation. We further combine this\nsolver-like architecture with a convolutional network, capable of learning the\nrelation between trajectories of coupled oscillators and therefore allows us to\nmake a stable forecast even if the system is only partially observed. We\noptimize this map together with the solver network, while sharing their\nweights, to form a powerful framework capable of learning the complex physical\nproperties of a dissipative dynamical system.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 23:31:31 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 11:33:52 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["M\u00fcller", "Roger Alexander", ""], ["Laflamme-Janssen", "Jonathan", ""], ["Camacaro", "Jaime", ""], ["Bessega", "Carolina", ""]]}, {"id": "2010.11273", "submitter": "Adel Rahimi", "authors": "Othman Benchekroun, Adel Rahimi, Qini Zhang, Tetiana Kodliuk", "title": "The Need for Standardized Explainability", "comments": "Accepted in 2nd ICML 2020 Workshop on Human in the Loop Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable AI (XAI) is paramount in industry-grade AI; however existing\nmethods fail to address this necessity, in part due to a lack of\nstandardisation of explainability methods. The purpose of this paper is to\noffer a perspective on the current state of the area of explainability, and to\nprovide novel definitions for Explainability and Interpretability to begin\nstandardising this area of research. To do so, we provide an overview of the\nliterature on explainability, and of the existing methods that are already\nimplemented. Finally, we offer a tentative taxonomy of the different\nexplainability methods, opening the door to future research.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 08:40:20 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 02:19:36 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Benchekroun", "Othman", ""], ["Rahimi", "Adel", ""], ["Zhang", "Qini", ""], ["Kodliuk", "Tetiana", ""]]}, {"id": "2010.11289", "submitter": "Wolfgang Kratsch", "authors": "Wolfgang Kratsch, Fabian K\\\"onig, Maximilian R\\\"oglinger", "title": "Shedding Light on Blind Spots: Developing a Reference Architecture to\n  Leverage Video Data for Process Mining", "comments": "Submitted to Information Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process mining is one of the most active research streams in business process\nmanagement. In recent years, numerous methods have been proposed for analyzing\nstructured process data. Yet, in many cases, it is only the digitized parts of\nprocesses that are directly captured from process-aware information systems,\nand manual activities often result in blind spots. While the use of video\ncameras to observe these activities could help to fill this gap, a standardized\napproach to extracting event logs from unstructured video data remains lacking.\nHere, we propose a reference architecture to bridge the gap between computer\nvision and process mining. Various evaluation activities (i.e., competing\nartifact analysis, prototyping, and real-world application) ensured that the\nproposed reference architecture allows flexible, use-case-driven, and\ncontext-specific instantiations. Our results also show that an exemplary\nsoftware prototype instantiation of the proposed reference architecture is\ncapable of automatically extracting most of the process-relevant events from\nunstructured video data.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 20:01:52 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Kratsch", "Wolfgang", ""], ["K\u00f6nig", "Fabian", ""], ["R\u00f6glinger", "Maximilian", ""]]}, {"id": "2010.11305", "submitter": "Jie Yang", "authors": "Jie Amy Yang, Jianyu Huang, Jongsoo Park, Ping Tak Peter Tang, Andrew\n  Tulloch", "title": "Mixed-Precision Embedding Using a Cache", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recommendation systems, practitioners observed that increase in the number\nof embedding tables and their sizes often leads to significant improvement in\nmodel performances. Given this and the business importance of these models to\nmajor internet companies, embedding tables for personalization tasks have grown\nto terabyte scale and continue to grow at a significant rate. Meanwhile, these\nlarge-scale models are often trained with GPUs where high-performance memory is\na scarce resource, thus motivating numerous work on embedding table compression\nduring training. We propose a novel change to embedding tables using a cache\nmemory architecture, where the majority of rows in an embedding is trained in\nlow precision, and the most frequently or recently accessed rows cached and\ntrained in full precision. The proposed architectural change works in\nconjunction with standard precision reduction and computer arithmetic\ntechniques such as quantization and stochastic rounding. For an open source\ndeep learning recommendation model (DLRM) running with Criteo-Kaggle dataset,\nwe achieve 3x memory reduction with INT8 precision embedding tables and\nfull-precision cache whose size are 5% of the embedding tables, while\nmaintaining accuracy. For an industrial scale model and dataset, we achieve\neven higher >7x memory reduction with INT4 precision and cache size 1% of\nembedding tables, while maintaining accuracy, and 16% end-to-end training\nspeedup by reducing GPU-to-host data transfers.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 20:49:54 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 01:37:34 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Yang", "Jie Amy", ""], ["Huang", "Jianyu", ""], ["Park", "Jongsoo", ""], ["Tang", "Ping Tak Peter", ""], ["Tulloch", "Andrew", ""]]}, {"id": "2010.11328", "submitter": "Dhananjay Ashok", "authors": "Dhananjay Ashok, Joseph Scott, Sebastian Wetzel, Maysum Panju and\n  Vijay Ganesh", "title": "Logic Guided Genetic Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel Auxiliary Truth enhanced Genetic Algorithm (GA) that uses\nlogical or mathematical constraints as a means of data augmentation as well as\nto compute loss (in conjunction with the traditional MSE), with the aim of\nincreasing both data efficiency and accuracy of symbolic regression (SR)\nalgorithms. Our method, logic-guided genetic algorithm (LGGA), takes as input a\nset of labelled data points and auxiliary truths (ATs) (mathematical facts\nknown a priori about the unknown function the regressor aims to learn) and\noutputs a specially generated and curated dataset that can be used with any SR\nmethod. Three key insights underpin our method: first, SR users often know\nsimple ATs about the function they are trying to learn. Second, whenever an SR\nsystem produces a candidate equation inconsistent with these ATs, we can\ncompute a counterexample to prove the inconsistency, and further, this\ncounterexample may be used to augment the dataset and fed back to the SR system\nin a corrective feedback loop. Third, the value addition of these ATs is that\ntheir use in both the loss function and the data augmentation process leads to\nbetter rates of convergence, accuracy, and data efficiency. We evaluate LGGA\nagainst state-of-the-art SR tools, namely, Eureqa and TuringBot on 16 physics\nequations from \"The Feynman Lectures on Physics\" book. We find that using these\nSR tools in conjunction with LGGA results in them solving up to 30.0% more\nequations, needing only a fraction of the amount of data compared to the same\ntool without LGGA, i.e., resulting in up to a 61.9% improvement in data\nefficiency.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 21:57:12 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Ashok", "Dhananjay", ""], ["Scott", "Joseph", ""], ["Wetzel", "Sebastian", ""], ["Panju", "Maysum", ""], ["Ganesh", "Vijay", ""]]}, {"id": "2010.11334", "submitter": "Chiyu Zhang", "authors": "Muhammad Abdul-Mageed, Chiyu Zhang, Houda Bouamor and Nizar Habash", "title": "NADI 2020: The First Nuanced Arabic Dialect Identification Shared Task", "comments": "Accepted in The Fifth Arabic Natural Language Processing Workshop\n  (WANLP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the results and findings of the First Nuanced Arabic Dialect\nIdentification Shared Task (NADI). This Shared Task includes two subtasks:\ncountry-level dialect identification (Subtask 1) and province-level sub-dialect\nidentification (Subtask 2). The data for the shared task covers a total of 100\nprovinces from 21 Arab countries and are collected from the Twitter domain. As\nsuch, NADI is the first shared task to target naturally-occurring fine-grained\ndialectal text at the sub-country level. A total of 61 teams from 25 countries\nregistered to participate in the tasks, thus reflecting the interest of the\ncommunity in this area. We received 47 submissions for Subtask 1 from 18 teams\nand 9 submissions for Subtask 2 from 9 teams.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 22:14:28 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 04:53:19 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 19:18:33 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Abdul-Mageed", "Muhammad", ""], ["Zhang", "Chiyu", ""], ["Bouamor", "Houda", ""], ["Habash", "Nizar", ""]]}, {"id": "2010.11344", "submitter": "Jinxi Li", "authors": "Robin Walters, Jinxi Li, Rose Yu", "title": "Trajectory Prediction using Equivariant Continuous Convolution", "comments": "Accepted to ICLR 2021, 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory prediction is a critical part of many AI applications, for\nexample, the safe operation of autonomous vehicles. However, current methods\nare prone to making inconsistent and physically unrealistic predictions. We\nleverage insights from fluid dynamics to overcome this limitation by\nconsidering internal symmetry in real-world trajectories. We propose a novel\nmodel, Equivariant Continous COnvolution (ECCO) for improved trajectory\nprediction. ECCO uses rotationally-equivariant continuous convolutions to embed\nthe symmetries of the system. On both vehicle and pedestrian trajectory\ndatasets, ECCO attains competitive accuracy with significantly fewer\nparameters. It is also more sample efficient, generalizing automatically from\nfew data points in any orientation. Lastly, ECCO improves generalization with\nequivariance, resulting in more physically consistent predictions. Our method\nprovides a fresh perspective towards increasing trust and transparency in deep\nlearning models.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 23:18:42 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 22:07:18 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Walters", "Robin", ""], ["Li", "Jinxi", ""], ["Yu", "Rose", ""]]}, {"id": "2010.11362", "submitter": "Rithesh Kumar", "authors": "Rithesh Kumar, Kundan Kumar, Vicki Anand, Yoshua Bengio, Aaron\n  Courville", "title": "NU-GAN: High resolution neural upsampling with GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose NU-GAN, a new method for resampling audio from\nlower to higher sampling rates (upsampling). Audio upsampling is an important\nproblem since productionizing generative speech technology requires operating\nat high sampling rates. Such applications use audio at a resolution of 44.1 kHz\nor 48 kHz, whereas current speech synthesis methods are equipped to handle a\nmaximum of 24 kHz resolution. NU-GAN takes a leap towards solving audio\nupsampling as a separate component in the text-to-speech (TTS) pipeline by\nleveraging techniques for audio generation using GANs. ABX preference tests\nindicate that our NU-GAN resampler is capable of resampling 22 kHz to 44.1 kHz\naudio that is distinguishable from original audio only 7.4% higher than random\nchance for single speaker dataset, and 10.8% higher than chance for\nmulti-speaker dataset.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 01:00:23 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Kumar", "Rithesh", ""], ["Kumar", "Kundan", ""], ["Anand", "Vicki", ""], ["Bengio", "Yoshua", ""], ["Courville", "Aaron", ""]]}, {"id": "2010.11370", "submitter": "Gelareh Mohammadi", "authors": "Gelareh Mohammadi and Patrik Vuilleumier", "title": "A Multi-Componential Approach to Emotion Recognition and the Effect of\n  Personality", "comments": "13 pages", "journal-ref": "IEEE Transactions on Affective Computing, 2020", "doi": "10.1109/TAFFC.2020.3028109", "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotions are an inseparable part of human nature affecting our behavior in\nresponse to the outside world. Although most empirical studies have been\ndominated by two theoretical models including discrete categories of emotion\nand dichotomous dimensions, results from neuroscience approaches suggest a\nmulti-processes mechanism underpinning emotional experience with a large\noverlap across different emotions. While these findings are consistent with the\ninfluential theories of emotion in psychology that emphasize a role for\nmultiple component processes to generate emotion episodes, few studies have\nsystematically investigated the relationship between discrete emotions and a\nfull componential view. This paper applies a componential framework with a\ndata-driven approach to characterize emotional experiences evoked during movie\nwatching. The results suggest that differences between various emotions can be\ncaptured by a few (at least 6) latent dimensions, each defined by features\nassociated with component processes, including appraisal, expression,\nphysiology, motivation, and feeling. In addition, the link between discrete\nemotions and component model is explored and results show that a componential\nmodel with a limited number of descriptors is still able to predict the level\nof experienced discrete emotion(s) to a satisfactory level. Finally, as\nappraisals may vary according to individual dispositions and biases, we also\nstudy the relationship between personality traits and emotions in our\ncomputational framework and show that the role of personality on discrete\nemotion differences can be better justified using the component model.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 01:27:23 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Mohammadi", "Gelareh", ""], ["Vuilleumier", "Patrik", ""]]}, {"id": "2010.11387", "submitter": "George Boateng", "authors": "George Boateng", "title": "Kwame: A Bilingual AI Teaching Assistant for Online SuaCode Courses", "comments": "6 pages. Accepted and presented at NeurIPS 2020 workshop (Black in\n  AI) and AIED 2021 (international conference on AI in Education)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Introductory hands-on courses such as our smartphone-based coding course,\nSuaCode require a lot of support for students to accomplish learning goals.\nOnline environments make it even more difficult to get assistance especially\nmore recently because of COVID-19. Given the multilingual context of SuaCode\nstudents - learners across 42 African countries that are mostly Anglophone or\nFrancophone - in this work, we developed a bilingual Artificial Intelligence\n(AI) Teaching Assistant (TA) - Kwame - that provides answers to students'\ncoding questions from SuaCode courses in English and French. Kwame is a\nSentence-BERT (SBERT)-based question-answering (QA) system that we trained and\nevaluated offline using question-answer pairs created from the course's\nquizzes, lesson notes and students' questions in past cohorts. Kwame finds the\nparagraph most semantically similar to the question via cosine similarity. We\ncompared the system with TF-IDF and Universal Sentence Encoder. Our results\nshowed that fine-tuning on the course data and returning the top 3 and 5\nanswers improved the accuracy results. Kwame will make it easy for students to\nget quick and accurate answers to questions in SuaCode courses.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 02:26:12 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 00:12:46 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Boateng", "George", ""]]}, {"id": "2010.11401", "submitter": "Chenghao Liu", "authors": "Jianwen Yin, Chenghao Liu, Weiqing Wang, Jianling Sun, Steven C.H. Hoi", "title": "Learning Transferrable Parameters for Long-tailed Sequential User\n  Behavior Modeling", "comments": "Accepted by KDD2020", "journal-ref": null, "doi": "10.1145/3394486.3403078", "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential user behavior modeling plays a crucial role in online\nuser-oriented services, such as product purchasing, news feed consumption, and\nonline advertising. The performance of sequential modeling heavily depends on\nthe scale and quality of historical behaviors. However, the number of user\nbehaviors inherently follows a long-tailed distribution, which has been seldom\nexplored. In this work, we argue that focusing on tail users could bring more\nbenefits and address the long tails issue by learning transferrable parameters\nfrom both optimization and feature perspectives. Specifically, we propose a\ngradient alignment optimizer and adopt an adversarial training scheme to\nfacilitate knowledge transfer from the head to the tail. Such methods can also\ndeal with the cold-start problem of new users. Moreover, it could be directly\nadaptive to various well-established sequential models. Extensive experiments\non four real-world datasets verify the superiority of our framework compared\nwith the state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 03:12:02 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 13:36:51 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Yin", "Jianwen", ""], ["Liu", "Chenghao", ""], ["Wang", "Weiqing", ""], ["Sun", "Jianling", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "2010.11413", "submitter": "Baihan Lin", "authors": "Baihan Lin, Djallel Bouneffouf, Guillermo Cecchi", "title": "Predicting Human Decision Making in Psychological Tasks with Recurrent\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike traditional time series, the action sequences of human decision making\nusually involve many cognitive processes such as beliefs, desires, intentions\nand theory of mind, i.e. what others are thinking. This makes predicting human\ndecision making challenging to be treated agnostically to the underlying\npsychological mechanisms. We propose to use a recurrent neural network\narchitecture based on long short-term memory networks (LSTM) to predict the\ntime series of the actions taken by the human subjects at each step of their\ndecision making, the first application of such methods in this research domain.\nWe trained our prediction networks on the behavioral data from several\npublished psychological experiments of human decision making, and demonstrated\na clear advantage over the state-of-the-art methods in predicting human\ndecision making trajectories in both single-agent scenarios such as Iowa\nGambling Task and multi-agent scenarios such as Iterated Prisoner's Dilemma.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 03:36:03 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Lin", "Baihan", ""], ["Bouneffouf", "Djallel", ""], ["Cecchi", "Guillermo", ""]]}, {"id": "2010.11418", "submitter": "Amauri Souza", "authors": "Diego Mesquita, Amauri H. Souza, Samuel Kaski", "title": "Rethinking pooling in graph neural networks", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph pooling is a central component of a myriad of graph neural network\n(GNN) architectures. As an inheritance from traditional CNNs, most approaches\nformulate graph pooling as a cluster assignment problem, extending the idea of\nlocal patches in regular grids to graphs. Despite the wide adherence to this\ndesign choice, no work has rigorously evaluated its influence on the success of\nGNNs. In this paper, we build upon representative GNNs and introduce variants\nthat challenge the need for locality-preserving representations, either using\nrandomization or clustering on the complement graph. Strikingly, our\nexperiments demonstrate that using these variants does not result in any\ndecrease in performance. To understand this phenomenon, we study the interplay\nbetween convolutional layers and the subsequent pooling ones. We show that the\nconvolutions play a leading role in the learned representations. In contrast to\nthe common belief, local pooling is not responsible for the success of GNNs on\nrelevant and widely-used benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 03:48:56 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Mesquita", "Diego", ""], ["Souza", "Amauri H.", ""], ["Kaski", "Samuel", ""]]}, {"id": "2010.11419", "submitter": "Zhiwei Liu", "authors": "Zhiwei Liu, Xiaohan Li, Ziwei Fan, Stephen Guo, Kannan Achan, and\n  Philip S. Yu", "title": "Basket Recommendation with Multi-Intent Translation Graph Neural Network", "comments": "Accepted to IEEE Bigdata 2020. Code is available online at\n  https://github.com/JimLiu96/MITGNN", "journal-ref": "978-1-7281-6251-5/20/\\$31.00~\\copyright2020 IEEE", "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of basket recommendation~(BR) is to recommend a ranking list of\nitems to the current basket. Existing methods solve this problem by assuming\nthe items within the same basket are correlated by one semantic relation, thus\noptimizing the item embeddings. However, this assumption breaks when there\nexist multiple intents within a basket. For example, assuming a basket contains\n\\{\\textit{bread, cereal, yogurt, soap, detergent}\\} where \\{\\textit{bread,\ncereal, yogurt}\\} are correlated through the \"breakfast\" intent, while\n\\{\\textit{soap, detergent}\\} are of \"cleaning\" intent, ignoring multiple\nrelations among the items spoils the ability of the model to learn the\nembeddings. To resolve this issue, it is required to discover the intents\nwithin the basket. However, retrieving a multi-intent pattern is rather\nchallenging, as intents are latent within the basket. Additionally, intents\nwithin the basket may also be correlated. Moreover, discovering a multi-intent\npattern requires modeling high-order interactions, as the intents across\ndifferent baskets are also correlated. To this end, we propose a new framework\nnamed as \\textbf{M}ulti-\\textbf{I}ntent \\textbf{T}ranslation \\textbf{G}raph\n\\textbf{N}eural \\textbf{N}etwork~({\\textbf{MITGNN}}). MITGNN models $T$ intents\nas tail entities translated from one corresponding basket embedding via $T$\nrelation vectors. The relation vectors are learned through multi-head\naggregators to handle user and item information. Additionally, MITGNN\npropagates multiple intents across our defined basket graph to learn the\nembeddings of users and items by aggregating neighbors. Extensive experiments\non two real-world datasets prove the effectiveness of our proposed model on\nboth transductive and inductive BR. The code is available online at\nhttps://github.com/JimLiu96/MITGNN.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 03:52:00 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Liu", "Zhiwei", ""], ["Li", "Xiaohan", ""], ["Fan", "Ziwei", ""], ["Guo", "Stephen", ""], ["Achan", "Kannan", ""], ["Yu", "Philip S.", ""]]}, {"id": "2010.11422", "submitter": "Ildoo Kim", "authors": "Ildoo Kim, Younghoon Kim, Sungwoong Kim", "title": "Learning Loss for Test-Time Augmentation", "comments": "Accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation has been actively studied for robust neural networks. Most\nof the recent data augmentation methods focus on augmenting datasets during the\ntraining phase. At the testing phase, simple transformations are still widely\nused for test-time augmentation. This paper proposes a novel instance-level\ntest-time augmentation that efficiently selects suitable transformations for a\ntest input. Our proposed method involves an auxiliary module to predict the\nloss of each possible transformation given the input. Then, the transformations\nhaving lower predicted losses are applied to the input. The network obtains the\nresults by averaging the prediction results of augmented inputs. Experimental\nresults on several image classification benchmarks show that the proposed\ninstance-aware test-time augmentation improves the model's robustness against\nvarious corruptions.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 03:56:34 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Kim", "Ildoo", ""], ["Kim", "Younghoon", ""], ["Kim", "Sungwoong", ""]]}, {"id": "2010.11426", "submitter": "Xianzhi Du", "authors": "Xianzhi Du, Tsung-Yi Lin, Pengchong Jin, Yin Cui, Mingxing Tan, Quoc\n  Le, and Xiaodan Song", "title": "Efficient Scale-Permuted Backbone with Learned Resource Distribution", "comments": "ECCV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, SpineNet has demonstrated promising results on object detection and\nimage classification over ResNet model. However, it is unclear if the\nimprovement adds up when combining scale-permuted backbone with advanced\nefficient operations and compound scaling. Furthermore, SpineNet is built with\na uniform resource distribution over operations. While this strategy seems to\nbe prevalent for scale-decreased models, it may not be an optimal design for\nscale-permuted models. In this work, we propose a simple technique to combine\nefficient operations and compound scaling with a previously learned\nscale-permuted architecture. We demonstrate the efficiency of scale-permuted\nmodel can be further improved by learning a resource distribution over the\nentire network. The resulting efficient scale-permuted models outperform\nstate-of-the-art EfficientNet-based models on object detection and achieve\ncompetitive performance on image classification and semantic segmentation. Code\nand models will be open-sourced soon.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 03:59:51 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Du", "Xianzhi", ""], ["Lin", "Tsung-Yi", ""], ["Jin", "Pengchong", ""], ["Cui", "Yin", ""], ["Tan", "Mingxing", ""], ["Le", "Quoc", ""], ["Song", "Xiaodan", ""]]}, {"id": "2010.11437", "submitter": "Jun Seo", "authors": "Jun Seo, Young-Hyun Park, Sung-Whan Yoon, Jaekyun Moon", "title": "Task-Adaptive Feature Transformer for Few-Shot Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning allows machines to classify novel classes using only a few\nlabeled samples. Recently, few-shot segmentation aiming at semantic\nsegmentation on low sample data has also seen great interest. In this paper, we\npropose a learnable module for few-shot segmentation, the task-adaptive feature\ntransformer (TAFT). TAFT linearly transforms task-specific high-level features\nto a set of task-agnostic features well-suited to the segmentation job. Using\nthis task-conditioned feature transformation, the model is shown to effectively\nutilize the semantic information in novel classes to generate tight\nsegmentation masks. The proposed TAFT module can be easily plugged into\nexisting semantic segmentation algorithms to achieve few-shot segmentation\ncapability with only a few added parameters. We combine TAFT with Deeplab V3+,\na well-known segmentation architecture; experiments on the PASCAL-$5^i$ dataset\nconfirm that this combination successfully adds few-shot learning capability to\nthe segmentation algorithm, achieving the state-of-the-art few-shot\nsegmentation performance in some key representative cases.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 04:35:37 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Seo", "Jun", ""], ["Park", "Young-Hyun", ""], ["Yoon", "Sung-Whan", ""], ["Moon", "Jaekyun", ""]]}, {"id": "2010.11446", "submitter": "Andy Shih", "authors": "Andy Shih, Stefano Ermon", "title": "Probabilistic Circuits for Variational Inference in Discrete Graphical\n  Models", "comments": "In Advances in Neural Information Processing Systems 34 (NeurIPS),\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference in discrete graphical models with variational methods is difficult\nbecause of the inability to re-parameterize gradients of the Evidence Lower\nBound (ELBO). Many sampling-based methods have been proposed for estimating\nthese gradients, but they suffer from high bias or variance. In this paper, we\npropose a new approach that leverages the tractability of probabilistic circuit\nmodels, such as Sum Product Networks (SPN), to compute ELBO gradients exactly\n(without sampling) for a certain class of densities. In particular, we show\nthat selective-SPNs are suitable as an expressive variational distribution, and\nprove that when the log-density of the target model is a polynomial the\ncorresponding ELBO can be computed analytically. To scale to graphical models\nwith thousands of variables, we develop an efficient and effective construction\nof selective-SPNs with size $O(kn)$, where $n$ is the number of variables and\n$k$ is an adjustable hyperparameter. We demonstrate our approach on three types\nof graphical models -- Ising models, Latent Dirichlet Allocation, and factor\ngraphs from the UAI Inference Competition. Selective-SPNs give a better lower\nbound than mean-field and structured mean-field, and is competitive with\napproximations that do not provide a lower bound, such as Loopy Belief\nPropagation and Tree-Reweighted Belief Propagation. Our results show that\nprobabilistic circuits are promising tools for variational inference in\ndiscrete graphical models as they combine tractability and expressivity.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 05:04:38 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Shih", "Andy", ""], ["Ermon", "Stefano", ""]]}, {"id": "2010.11465", "submitter": "Hongyu Ren", "authors": "Hongyu Ren, Jure Leskovec", "title": "Beta Embeddings for Multi-Hop Logical Reasoning in Knowledge Graphs", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the fundamental problems in Artificial Intelligence is to perform\ncomplex multi-hop logical reasoning over the facts captured by a knowledge\ngraph (KG). This problem is challenging, because KGs can be massive and\nincomplete. Recent approaches embed KG entities in a low dimensional space and\nthen use these embeddings to find the answer entities. However, it has been an\noutstanding challenge of how to handle arbitrary first-order logic (FOL)\nqueries as present methods are limited to only a subset of FOL operators. In\nparticular, the negation operator is not supported. An additional limitation of\npresent methods is also that they cannot naturally model uncertainty. Here, we\npresent BetaE, a probabilistic embedding framework for answering arbitrary FOL\nqueries over KGs. BetaE is the first method that can handle a complete set of\nfirst-order logical operations: conjunction ($\\wedge$), disjunction ($\\vee$),\nand negation ($\\neg$). A key insight of BetaE is to use probabilistic\ndistributions with bounded support, specifically the Beta distribution, and\nembed queries/entities as distributions, which as a consequence allows us to\nalso faithfully model uncertainty. Logical operations are performed in the\nembedding space by neural operators over the probabilistic embeddings. We\ndemonstrate the performance of BetaE on answering arbitrary FOL queries on\nthree large, incomplete KGs. While being more general, BetaE also increases\nrelative performance by up to 25.4% over the current state-of-the-art KG\nreasoning methods that can only handle conjunctive queries without negation.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 06:11:39 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Ren", "Hongyu", ""], ["Leskovec", "Jure", ""]]}, {"id": "2010.11486", "submitter": "Aneta Neumann", "authors": "Aneta Neumann, Jakob Bossek, Frank Neumann", "title": "Computing Diverse Sets of Solutions for Monotone Submodular Optimisation\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular functions allow to model many real-world optimisation problems.\nThis paper introduces approaches for computing diverse sets of high quality\nsolutions for submodular optimisation problems. We first present diversifying\ngreedy sampling approaches and analyse them with respect to the diversity\nmeasured by entropy and the approximation quality of the obtained solutions.\nAfterwards, we introduce an evolutionary diversity optimisation approach to\nfurther improve diversity of the set of solutions. We carry out experimental\ninvestigations on popular submodular benchmark functions that show that the\ncombined approaches achieve high quality solutions of large diversity.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 07:11:34 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Neumann", "Aneta", ""], ["Bossek", "Jakob", ""], ["Neumann", "Frank", ""]]}, {"id": "2010.11503", "submitter": "Jean Christoph Jung", "authors": "Thomas Gogacz, V\\'ictor Guti\\'errez-Basulto, Yazm\\'in\n  Ib\\'a\\~nez-Garc\\'ia, Jean Christoph Jung, Filip Murlak", "title": "On Finite and Unrestricted Query Entailment beyond SQ with Number\n  Restrictions on Transitive Roles", "comments": "Full version of a paper accepted at IJCAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the description logic SQ with number restrictions applicable to\ntransitive roles, extended with either nominals or inverse roles. We show tight\n2EXPTIME upper bounds for unrestricted entailment of regular path queries for\nboth extensions and finite entailment of positive existential queries for\nnominals. For inverses, we establish 2EXPTIME-completeness for unrestricted and\nfinite entailment of instance queries (the latter under restriction to a\nsingle, transitive role).\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 07:44:00 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Gogacz", "Thomas", ""], ["Guti\u00e9rrez-Basulto", "V\u00edctor", ""], ["Ib\u00e1\u00f1ez-Garc\u00eda", "Yazm\u00edn", ""], ["Jung", "Jean Christoph", ""], ["Murlak", "Filip", ""]]}, {"id": "2010.11506", "submitter": "Lingkai Kong", "authors": "Lingkai Kong, Haoming Jiang, Yuchen Zhuang, Jie Lyu, Tuo Zhao, Chao\n  Zhang", "title": "Calibrated Language Model Fine-Tuning for In- and Out-of-Distribution\n  Data", "comments": "EMNLP2020 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuned pre-trained language models can suffer from severe miscalibration\nfor both in-distribution and out-of-distribution (OOD) data due to\nover-parameterization. To mitigate this issue, we propose a regularized\nfine-tuning method. Our method introduces two types of regularization for\nbetter calibration: (1) On-manifold regularization, which generates pseudo\non-manifold samples through interpolation within the data manifold. Augmented\ntraining with these pseudo samples imposes a smoothness regularization to\nimprove in-distribution calibration. (2) Off-manifold regularization, which\nencourages the model to output uniform distributions for pseudo off-manifold\nsamples to address the over-confidence issue for OOD data. Our experiments\ndemonstrate that the proposed method outperforms existing calibration methods\nfor text classification in terms of expectation calibration error,\nmisclassification detection, and OOD detection on six datasets. Our code can be\nfound at https://github.com/Lingkai-Kong/Calibrated-BERT-Fine-Tuning.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 07:48:38 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Kong", "Lingkai", ""], ["Jiang", "Haoming", ""], ["Zhuang", "Yuchen", ""], ["Lyu", "Jie", ""], ["Zhao", "Tuo", ""], ["Zhang", "Chao", ""]]}, {"id": "2010.11522", "submitter": "Jiaoyan Chen", "authors": "Ziheng Zhang and Jiaoyan Chen and Xi Chen and Hualuo Liu and Yuejia\n  Xiang and Bo Liu and Yefeng Zheng", "title": "An Industry Evaluation of Embedding-based Entity Alignment", "comments": "accepted by COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding-based entity alignment has been widely investigated in recent\nyears, but most proposed methods still rely on an ideal supervised learning\nsetting with a large number of unbiased seed mappings for training and\nvalidation, which significantly limits their usage. In this study, we evaluate\nthose state-of-the-art methods in an industrial context, where the impact of\nseed mappings with different sizes and different biases is explored. Besides\nthe popular benchmarks from DBpedia and Wikidata, we contribute and evaluate a\nnew industrial benchmark that is extracted from two heterogeneous knowledge\ngraphs (KGs) under deployment for medical applications. The experimental\nresults enable the analysis of the advantages and disadvantages of these\nalignment methods and the further discussion of suitable strategies for their\nindustrial deployment.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 08:33:58 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 12:25:10 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Zhang", "Ziheng", ""], ["Chen", "Jiaoyan", ""], ["Chen", "Xi", ""], ["Liu", "Hualuo", ""], ["Xiang", "Yuejia", ""], ["Liu", "Bo", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2010.11523", "submitter": "Jorik Jooken", "authors": "Jorik Jooken, Pieter Leyman, Patrick De Causmaecker, Tony Wauters", "title": "Exploring search space trees using an adapted version of Monte Carlo\n  tree search for combinatorial optimization problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, a novel approach to solve combinatorial optimization\nproblems is proposed. This approach makes use of a heuristic algorithm to\nexplore the search space tree of a problem instance. The algorithm is based on\nMonte Carlo tree search, a popular algorithm in game playing that is used to\nexplore game trees. By leveraging the combinatorial structure of a problem,\nseveral enhancements to the algorithm are proposed. These enhancements aim to\nefficiently explore the search space tree by pruning subtrees, using a\nheuristic simulation policy, reducing the domains of variables by eliminating\ndominated value assignments and using a beam width. They are demonstrated for\ntwo specific combinatorial optimization problems: the quay crane scheduling\nproblem with non-crossing constraints and the 0-1 knapsack problem.\nComputational results show that the algorithm achieves promising results for\nboth problems and eight new best solutions for a benchmark set of instances are\nfound for the former problem. These results indicate that the algorithm is\ncompetitive with the state-of-the-art. Apart from this, the results also show\nevidence that the algorithm is able to learn to correct the incorrect choices\nmade by constructive heuristics.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 08:33:58 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 08:54:29 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Jooken", "Jorik", ""], ["Leyman", "Pieter", ""], ["De Causmaecker", "Patrick", ""], ["Wauters", "Tony", ""]]}, {"id": "2010.11533", "submitter": "Qinyuan Wu", "authors": "Qinyuan Wu, Yong Deng and Neal Xiong", "title": "Exponential Negation of a Probability Distribution", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negation operation is important in intelligent information processing.\nDifferent with existing arithmetic negation, an exponential negation is\npresented in this paper. The new negation can be seen as a kind of geometry\nnegation. Some basic properties of the proposed negation is investigated, we\nfind that the fix point is the uniform probability distribution. The negation\nis an entropy increase operation and all the probability distributions will\nconverge to the uniform distribution after multiple negation iterations. The\nnumber of iterations of convergence is inversely proportional to the number of\nelements in the distribution. Some numerical examples are used to illustrate\nthe efficiency of the proposed negation.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 08:46:51 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 14:05:56 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Wu", "Qinyuan", ""], ["Deng", "Yong", ""], ["Xiong", "Neal", ""]]}, {"id": "2010.11566", "submitter": "Ali Aroudi", "authors": "Ali Aroudi and Sebastian Braun", "title": "DBNET: DOA-driven beamforming network for end-to-end farfield sound\n  source separation", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many deep learning techniques are available to perform source separation and\nreduce background noise. However, designing an end-to-end multi-channel source\nseparation method using deep learning and conventional acoustic signal\nprocessing techniques still remains challenging. In this paper we propose a\ndirection-of-arrival-driven beamforming network (DBnet) consisting of\ndirection-of-arrival (DOA) estimation and beamforming layers for end-to-end\nsource separation. We propose to train DBnet using loss functions that are\nsolely based on the distances between the separated speech signals and the\ntarget speech signals, without a need for the ground-truth DOAs of speakers. To\nimprove the source separation performance, we also propose end-to-end\nextensions of DBnet which incorporate post masking networks. We evaluate the\nproposed DBnet and its extensions on a very challenging dataset, targeting\nrealistic far-field sound source separation in reverberant and noisy\nenvironments. The experimental results show that the proposed extended DBnet\nusing a convolutional-recurrent post masking network outperforms\nstate-of-the-art source separation methods.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 09:52:05 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Aroudi", "Ali", ""], ["Braun", "Sebastian", ""]]}, {"id": "2010.11593", "submitter": "Hari Krishna Vydana Mr", "authors": "Hari Krishna Vydana, Lukas Burget, Jan Cernocky", "title": "A Technical Report: BUT Speech Translation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes the BUT's speech translation systems. The systems are\nEnglish$\\longrightarrow$German offline speech translation systems. The systems\nare based on our previous works \\cite{Jointly_trained_transformers}. Though\nEnd-to-End and cascade~(ASR-MT) spoken language translation~(SLT) systems are\nreaching comparable performances, a large degradation is observed when\ntranslating ASR hypothesis compared to the oracle input text. To reduce this\nperformance degradation, we have jointly-trained ASR and MT modules with ASR\nobjective as an auxiliary loss. Both the networks are connected through the\nneural hidden representations. This model has an End-to-End differentiable path\nwith respect to the final objective function and also utilizes the ASR\nobjective for better optimization. During the inference both the modules(i.e.,\nASR and MT) are connected through the hidden representations corresponding to\nthe n-best hypotheses. Ensembling with independently trained ASR and MT models\nhave further improved the performance of the system.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 10:52:31 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Vydana", "Hari Krishna", ""], ["Burget", "Lukas", ""], ["Cernocky", "Jan", ""]]}, {"id": "2010.11600", "submitter": "Junghoon Seo", "authors": "Junghoon Seo, Joon Suk Huh", "title": "On the Power of Deep but Naive Partial Label Learning", "comments": null, "journal-ref": "2021 IEEE ICASSP International Conference on Acoustics, Speech,\n  and Signal Processing", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial label learning (PLL) is a class of weakly supervised learning where\neach training instance consists of a data and a set of candidate labels\ncontaining a unique ground truth label. To tackle this problem, a majority of\ncurrent state-of-the-art methods employs either label disambiguation or\naveraging strategies. So far, PLL methods without such techniques have been\nconsidered impractical. In this paper, we challenge this view by revealing the\nhidden power of the oldest and naivest PLL method when it is instantiated with\ndeep neural networks. Specifically, we show that, with deep neural networks,\nthe naive model can achieve competitive performances against the other\nstate-of-the-art methods, suggesting it as a strong baseline for PLL. We also\naddress the question of how and why such a naive model works well with deep\nneural networks. Our empirical results indicate that deep neural networks\ntrained on partially labeled examples generalize very well even in the\nover-parametrized regime and without label disambiguations or regularizations.\nWe point out that existing learning theories on PLL are vacuous in the\nover-parametrized regime. Hence they cannot explain why the deep naive method\nworks. We propose an alternative theory on how deep learning generalize in PLL\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 11:02:56 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 07:32:23 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Seo", "Junghoon", ""], ["Huh", "Joon Suk", ""]]}, {"id": "2010.11619", "submitter": "Florin-Alexandru Vasluianu", "authors": "Florin-Alexandru Vasluianu and Andres Romero and Luc Van Gool and Radu\n  Timofte", "title": "Self-Supervised Shadow Removal", "comments": "10 pages, 4 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shadow removal is an important computer vision task aiming at the detection\nand successful removal of the shadow produced by an occluded light source and a\nphoto-realistic restoration of the image contents. Decades of re-search\nproduced a multitude of hand-crafted restoration techniques and, more recently,\nlearned solutions from shad-owed and shadow-free training image pairs. In this\nwork,we propose an unsupervised single image shadow removal solution via\nself-supervised learning by using a conditioned mask. In contrast to existing\nliterature, we do not require paired shadowed and shadow-free images, instead\nwe rely on self-supervision and jointly learn deep models to remove and add\nshadows to images. We validate our approach on the recently introduced ISTD and\nUSR datasets. We largely improve quantitatively and qualitatively over the\ncompared methods and set a new state-of-the-art performance in single image\nshadow removal.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 11:33:41 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Vasluianu", "Florin-Alexandru", ""], ["Romero", "Andres", ""], ["Van Gool", "Luc", ""], ["Timofte", "Radu", ""]]}, {"id": "2010.11645", "submitter": "Jonathan Uesato", "authors": "Sumanth Dathathri, Krishnamurthy Dvijotham, Alexey Kurakin, Aditi\n  Raghunathan, Jonathan Uesato, Rudy Bunel, Shreya Shankar, Jacob Steinhardt,\n  Ian Goodfellow, Percy Liang, Pushmeet Kohli", "title": "Enabling certification of verification-agnostic networks via\n  memory-efficient semidefinite programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convex relaxations have emerged as a promising approach for verifying\ndesirable properties of neural networks like robustness to adversarial\nperturbations. Widely used Linear Programming (LP) relaxations only work well\nwhen networks are trained to facilitate verification. This precludes\napplications that involve verification-agnostic networks, i.e., networks not\nspecially trained for verification. On the other hand, semidefinite programming\n(SDP) relaxations have successfully be applied to verification-agnostic\nnetworks, but do not currently scale beyond small networks due to poor time and\nspace asymptotics. In this work, we propose a first-order dual SDP algorithm\nthat (1) requires memory only linear in the total number of network\nactivations, (2) only requires a fixed number of forward/backward passes\nthrough the network per iteration. By exploiting iterative eigenvector methods,\nwe express all solver operations in terms of forward and backward passes\nthrough the network, enabling efficient use of hardware like GPUs/TPUs. For two\nverification-agnostic networks on MNIST and CIFAR-10, we significantly improve\nL-inf verified robust accuracy from 1% to 88% and 6% to 40% respectively. We\nalso demonstrate tight verification of a quadratic stability specification for\nthe decoder of a variational autoencoder.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 12:32:29 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 17:48:49 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Dathathri", "Sumanth", ""], ["Dvijotham", "Krishnamurthy", ""], ["Kurakin", "Alexey", ""], ["Raghunathan", "Aditi", ""], ["Uesato", "Jonathan", ""], ["Bunel", "Rudy", ""], ["Shankar", "Shreya", ""], ["Steinhardt", "Jacob", ""], ["Goodfellow", "Ian", ""], ["Liang", "Percy", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "2010.11655", "submitter": "Yunqiu Xu", "authors": "Yunqiu Xu, Meng Fang, Ling Chen, Yali Du, Joey Tianyi Zhou, Chengqi\n  Zhang", "title": "Deep Reinforcement Learning with Stacked Hierarchical Attention for\n  Text-based Games", "comments": "Accepted by NeurIPS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study reinforcement learning (RL) for text-based games, which are\ninteractive simulations in the context of natural language. While different\nmethods have been developed to represent the environment information and\nlanguage actions, existing RL agents are not empowered with any reasoning\ncapabilities to deal with textual games. In this work, we aim to conduct\nexplicit reasoning with knowledge graphs for decision making, so that the\nactions of an agent are generated and supported by an interpretable inference\nprocedure. We propose a stacked hierarchical attention mechanism to construct\nan explicit representation of the reasoning process by exploiting the structure\nof the knowledge graph. We extensively evaluate our method on a number of\nman-made benchmark games, and the experimental results demonstrate that our\nmethod performs better than existing text-based agents.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 12:40:22 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 12:27:59 GMT"}, {"version": "v3", "created": "Fri, 25 Dec 2020 06:38:23 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Xu", "Yunqiu", ""], ["Fang", "Meng", ""], ["Chen", "Ling", ""], ["Du", "Yali", ""], ["Zhou", "Joey Tianyi", ""], ["Zhang", "Chengqi", ""]]}, {"id": "2010.11666", "submitter": "Pavel Kalaidin", "authors": "Nadezhda Zueva, Madina Kabirova, Pavel Kalaidin", "title": "Reducing Unintended Identity Bias in Russian Hate Speech Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Toxicity has become a grave problem for many online communities and has been\ngrowing across many languages, including Russian. Hate speech creates an\nenvironment of intimidation, discrimination, and may even incite some\nreal-world violence. Both researchers and social platforms have been focused on\ndeveloping models to detect toxicity in online communication for a while now. A\ncommon problem of these models is the presence of bias towards some words (e.g.\nwoman, black, jew) that are not toxic, but serve as triggers for the classifier\ndue to model caveats. In this paper, we describe our efforts towards\nclassifying hate speech in Russian, and propose simple techniques of reducing\nunintended bias, such as generating training data with language models using\nterms and words related to protected identities as context and applying word\ndropout to such words.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 12:54:14 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Zueva", "Nadezhda", ""], ["Kabirova", "Madina", ""], ["Kalaidin", "Pavel", ""]]}, {"id": "2010.11679", "submitter": "Shudeng Wu", "authors": "Shudeng Wu, Tao Dai, Shu-Tao Xia", "title": "DPAttack: Diffused Patch Attacks against Universal Object Detection", "comments": "4 pages, 2 figures, CIKM Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep neural networks (DNNs) have been widely and successfully used\nin Object Detection, e.g. Faster RCNN, YOLO, CenterNet. However, recent studies\nhave shown that DNNs are vulnerable to adversarial attacks. Adversarial attacks\nagainst object detection can be divided into two categories, whole-pixel\nattacks and patch attacks. While these attacks add perturbations to a large\nnumber of pixels in images, we proposed a diffused patch attack\n(\\textbf{DPAttack}) to successfully fool object detectors by diffused patches\nof asteroid-shaped or grid-shape, which only change a small number of pixels.\nExperiments show that our DPAttack can successfully fool most object detectors\nwith diffused patches and we get the second place in the Alibaba Tianchi\ncompetition: Alibaba-Tsinghua Adversarial Challenge on Object Detection. Our\ncode can be obtained from https://github.com/Wu-Shudeng/DPAttack.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 04:48:24 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Wu", "Shudeng", ""], ["Dai", "Tao", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "2010.11685", "submitter": "Zilong Wang", "authors": "Zilong Wang, Mingjie Zhan, Xuebo Liu, Ding Liang", "title": "DocStruct: A Multimodal Method to Extract Hierarchy Structure in\n  Document for General Form Understanding", "comments": "Accepted to EMNLP 2020 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Form understanding depends on both textual contents and organizational\nstructure. Although modern OCR performs well, it is still challenging to\nrealize general form understanding because forms are commonly used and of\nvarious formats. The table detection and handcrafted features in previous works\ncannot apply to all forms because of their requirements on formats. Therefore,\nwe concentrate on the most elementary components, the key-value pairs, and\nadopt multimodal methods to extract features. We consider the form structure as\na tree-like or graph-like hierarchy of text fragments. The parent-child\nrelation corresponds to the key-value pairs in forms. We utilize the\nstate-of-the-art models and design targeted extraction modules to extract\nmultimodal features from semantic contents, layout information, and visual\nimages. A hybrid fusion method of concatenation and feature shifting is\ndesigned to fuse the heterogeneous features and provide an informative joint\nrepresentation. We adopt an asymmetric algorithm and negative sampling in our\nmodel as well. We validate our method on two benchmarks, MedForm and FUNSD, and\nextensive experiments demonstrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 08:54:17 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Wang", "Zilong", ""], ["Zhan", "Mingjie", ""], ["Liu", "Xuebo", ""], ["Liang", "Ding", ""]]}, {"id": "2010.11692", "submitter": "Mihir Rao", "authors": "Mihir Rao, Michelle Zhu, Tianyang Wang", "title": "Conversion and Implementation of State-of-the-Art Deep Learning\n  Algorithms for the Classification of Diabetic Retinopathy", "comments": "Pre-print version (in-review)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diabetic retinopathy (DR) is a retinal microvascular condition that emerges\nin diabetic patients. DR will continue to be a leading cause of blindness\nworldwide, with a predicted 191.0 million globally diagnosed patients in 2030.\nMicroaneurysms, hemorrhages, exudates, and cotton wool spots are common signs\nof DR. However, they can be small and hard for human eyes to detect. Early\ndetection of DR is crucial for effective clinical treatment. Existing methods\nto classify images require much time for feature extraction and selection, and\nare limited in their performance. Convolutional Neural Networks (CNNs), as an\nemerging deep learning (DL) method, have proven their potential in image\nclassification tasks. In this paper, comprehensive experimental studies of\nimplementing state-of-the-art CNNs for the detection and classification of DR\nare conducted in order to determine the top performing classifiers for the\ntask. Five CNN classifiers, namely Inception-V3, VGG19, VGG16, ResNet50, and\nInceptionResNetV2, are evaluated through experiments. They categorize medical\nimages into five different classes based on DR severity. Data augmentation and\ntransfer learning techniques are applied since annotated medical images are\nlimited and imbalanced. Experimental results indicate that the ResNet50\nclassifier has top performance for binary classification and that the\nInceptionResNetV2 classifier has top performance for multi-class DR\nclassification.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 20:42:14 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Rao", "Mihir", ""], ["Zhu", "Michelle", ""], ["Wang", "Tianyang", ""]]}, {"id": "2010.11704", "submitter": "Neil Sachdeva", "authors": "Neil Sachdeva, Misha Klopukh, Rachel St. Clair, William Hahn", "title": "Using Conditional Generative Adversarial Networks to Reduce the Effects\n  of Latency in Robotic Telesurgery", "comments": "6 pages with 5 figures and 1 table. J Robotic Surg (2020)", "journal-ref": null, "doi": "10.1007/s11701-020-01149-5", "report-no": null, "categories": "cs.CV cs.AI cs.RO eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The introduction of surgical robots brought about advancements in surgical\nprocedures. The applications of remote telesurgery range from building medical\nclinics in underprivileged areas, to placing robots abroad in military\nhot-spots where accessibility and diversity of medical experience may be\nlimited. Poor wireless connectivity may result in a prolonged delay, referred\nto as latency, between a surgeon's input and action a robot takes. In surgery,\nany micro-delay can injure a patient severely and in some cases, result in\nfatality. One was to increase safety is to mitigate the effects of latency\nusing deep learning aided computer vision. While the current surgical robots\nuse calibrated sensors to measure the position of the arms and tools, in this\nwork we present a purely optical approach that provides a measurement of the\ntool position in relation to the patient's tissues. This research aimed to\nproduce a neural network that allowed a robot to detect its own mechanical\nmanipulator arms. A conditional generative adversarial networks (cGAN) was\ntrained on 1107 frames of mock gastrointestinal robotic surgery data from the\n2015 EndoVis Instrument Challenge and corresponding hand-drawn labels for each\nframe. When run on new testing data, the network generated near-perfect labels\nof the input images which were visually consistent with the hand-drawn labels\nand was able to do this in 299 milliseconds. These accurately generated labels\ncan then be used as simplified identifiers for the robot to track its own\ncontrolled tools. These results show potential for conditional GANs as a\nreaction mechanism such that the robot can detect when its arms move outside\nthe operating area within a patient. This system allows for more accurate\nmonitoring of the position of surgical instruments in relation to the patient's\ntissue, increasing safety measures that are integral to successful telesurgery\nsystems.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 13:40:44 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Sachdeva", "Neil", ""], ["Klopukh", "Misha", ""], ["Clair", "Rachel St.", ""], ["Hahn", "William", ""]]}, {"id": "2010.11711", "submitter": "Yingheng Wang", "authors": "Yingheng Wang, Yaosen Min, Xin Chen, Ji Wu", "title": "Multi-view Graph Contrastive Representation Learning for Drug-Drug\n  Interaction Prediction", "comments": "In Proceedings of the Web Conference 2021 (WWW '21)", "journal-ref": null, "doi": "10.1145/3442381.3449786", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug-drug interaction(DDI) prediction is an important task in the medical\nhealth machine learning community. This study presents a new method, multi-view\ngraph contrastive representation learning for drug-drug interaction prediction,\nMIRACLE for brevity, to capture inter-view molecule structure and intra-view\ninteractions between molecules simultaneously. MIRACLE treats a DDI network as\na multi-view graph where each node in the interaction graph itself is a drug\nmolecular graph instance. We use GCNs and bond-aware attentive message passing\nnetworks to encode DDI relationships and drug molecular graphs in the MIRACLE\nlearning stage, respectively. Also, we propose a novel unsupervised contrastive\nlearning component to balance and integrate the multi-view information.\nComprehensive experiments on multiple real datasets show that MIRACLE\noutperforms the state-of-the-art DDI prediction models consistently.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 13:37:19 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 11:28:24 GMT"}, {"version": "v3", "created": "Sat, 10 Apr 2021 08:30:57 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wang", "Yingheng", ""], ["Min", "Yaosen", ""], ["Chen", "Xin", ""], ["Wu", "Ji", ""]]}, {"id": "2010.11714", "submitter": "Yukuan Yang", "authors": "Yukuan Yang, Fangyun Wei, Miaojing Shi, Guoqi Li", "title": "Restoring Negative Information in Few-Shot Object Detection", "comments": "To appear in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Few-shot learning has recently emerged as a new challenge in the deep\nlearning field: unlike conventional methods that train the deep neural networks\n(DNNs) with a large number of labeled data, it asks for the generalization of\nDNNs on new classes with few annotated samples. Recent advances in few-shot\nlearning mainly focus on image classification while in this paper we focus on\nobject detection. The initial explorations in few-shot object detection tend to\nsimulate a classification scenario by using the positive proposals in images\nwith respect to certain object class while discarding the negative proposals of\nthat class. Negatives, especially hard negatives, however, are essential to the\nembedding space learning in few-shot object detection. In this paper, we\nrestore the negative information in few-shot object detection by introducing a\nnew negative- and positive-representative based metric learning framework and a\nnew inference scheme with negative and positive representatives. We build our\nwork on a recent few-shot pipeline RepMet with several new modules to encode\nnegative information for both training and testing. Extensive experiments on\nImageNet-LOC and PASCAL VOC show our method substantially improves the\nstate-of-the-art few-shot object detection solutions. Our code is available at\nhttps://github.com/yang-yk/NP-RepMet.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 13:39:48 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 03:33:08 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Yang", "Yukuan", ""], ["Wei", "Fangyun", ""], ["Shi", "Miaojing", ""], ["Li", "Guoqi", ""]]}, {"id": "2010.11719", "submitter": "An Nguyen", "authors": "An Nguyen, Wenyu Zhang, Leo Schwinn, and Bjoern Eskofier", "title": "Conformance Checking for a Medical Training Process Using Petri net\n  Simulation and Sequence Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process Mining has recently gained popularity in healthcare due to its\npotential to provide a transparent, objective and data-based view on processes.\nConformance checking is a sub-discipline of process mining that has the\npotential to answer how the actual process executions deviate from existing\nguidelines. In this work, we analyze a medical training process for a surgical\nprocedure. Ten students were trained to install a Central Venous Catheters\n(CVC) with ultrasound. Event log data was collected directly after instruction\nby the supervisors during a first test run and additionally after a subsequent\nindividual training phase. In order to provide objective performance measures,\nwe formulate an optimal, global sequence alignment problem inspired by\napproaches in bioinformatics. Therefore, we use the Petri net model\nrepresentation of the medical process guideline to simulate a representative\nset of guideline conform sequences. Next, we calculate the optimal, global\nsequence alignment of the recorded and simulated event logs. Finally, the\noutput measures and visualization of aligned sequences are provided for\nobjective feedback.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 16:29:09 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Nguyen", "An", ""], ["Zhang", "Wenyu", ""], ["Schwinn", "Leo", ""], ["Eskofier", "Bjoern", ""]]}, {"id": "2010.11720", "submitter": "Betania Campello Ms.", "authors": "Betania S. C. Campello, Leonardo T. Duarte, Jo\\~ao M. T. Romano", "title": "A study of the Multicriteria decision analysis based on the time-series\n  features and a TOPSIS method proposal for a tensorial approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of Multiple Criteria Decision Analysis (MCDA) methods have been\ndeveloped to rank alternatives based on several decision criteria. Usually,\nMCDA methods deal with the criteria value at the time the decision is made\nwithout considering their evolution over time. However, it may be relevant to\nconsider the criteria' time series since providing essential information for\ndecision-making (e.g., an improvement of the criteria). To deal with this\nissue, we propose a new approach to rank the alternatives based on the criteria\ntime-series features (tendency, variance, etc.). In this novel approach, the\ndata is structured in three dimensions, which require a more complex data\nstructure, as the \\textit{tensors}, instead of the classical matrix\nrepresentation used in MCDA. Consequently, we propose an extension for the\nTOPSIS method to handle a tensor rather than a matrix. Computational results\nreveal that it is possible to rank the alternatives from a new perspective by\nconsidering meaningful decision-making information.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 14:37:02 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Campello", "Betania S. C.", ""], ["Duarte", "Leonardo T.", ""], ["Romano", "Jo\u00e3o M. T.", ""]]}, {"id": "2010.11721", "submitter": "Arvind Agarwal", "authors": "Vivek Iyer, Arvind Agarwal, Harshit Kumar", "title": "Multifaceted Context Representation using Dual Attention for Ontology\n  Alignment", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology Alignment is an important research problem that finds application in\nvarious fields such as data integration, data transfer, data preparation etc.\nState-of-the-art (SOTA) architectures in Ontology Alignment typically use naive\ndomain-dependent approaches with handcrafted rules and manually assigned\nvalues, making them unscalable and inefficient. Deep Learning approaches for\nontology alignment use domain-specific architectures that are not only\nin-extensible to other datasets and domains, but also typically perform worse\nthan rule-based approaches due to various limitations including over-fitting of\nmodels, sparsity of datasets etc. In this work, we propose VeeAlign, a Deep\nLearning based model that uses a dual-attention mechanism to compute the\ncontextualized representation of a concept in order to learn alignments. By\ndoing so, not only does our approach exploit both syntactic and semantic\nstructure of ontologies, it is also, by design, flexible and scalable to\ndifferent domains with minimal effort. We validate our approach on various\ndatasets from different domains and in multilingual settings, and show its\nsuperior performance over SOTA methods.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 18:28:38 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 11:31:42 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Iyer", "Vivek", ""], ["Agarwal", "Arvind", ""], ["Kumar", "Harshit", ""]]}, {"id": "2010.11732", "submitter": "Paulo Renato Conceicao Mendes", "authors": "Paulo R C Mendes, Antonio J G Busson, S\\'ergio Colcher, Daniel\n  Schwabe, \\'Alan L V Guedes, Carlos Laufer", "title": "A Cluster-Matching-Based Method for Video Face Recognition", "comments": "13 pages", "journal-ref": null, "doi": "10.1145/3428658.3430967", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition systems are present in many modern solutions and thousands\nof applications in our daily lives. However, current solutions are not easily\nscalable, especially when it comes to the addition of new targeted people. We\npropose a cluster-matching-based approach for face recognition in video. In our\napproach, we use unsupervised learning to cluster the faces present in both the\ndataset and targeted videos selected for face recognition. Moreover, we design\na cluster matching heuristic to associate clusters in both sets that is also\ncapable of identifying when a face belongs to a non-registered person. Our\nmethod has achieved a recall of 99.435% and a precision of 99.131% in the task\nof video face recognition. Besides performing face recognition, it can also be\nused to determine the video segments where each person is present.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 00:44:54 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Mendes", "Paulo R C", ""], ["Busson", "Antonio J G", ""], ["Colcher", "S\u00e9rgio", ""], ["Schwabe", "Daniel", ""], ["Guedes", "\u00c1lan L V", ""], ["Laufer", "Carlos", ""]]}, {"id": "2010.11733", "submitter": "Cedric Buron", "authors": "Nouredine Nour, Reda Belhaj-Soullami, C\\'edric Buron, Alain Peres,\n  Fr\\'ed\\'eric Barbaresco", "title": "Multi-Radar Tracking Optimization for Collaborative Combat", "comments": "Conference On Artificial Intelligence in Defense (CAID'2020), Nov\n  2020, Rennes, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart Grids of collaborative netted radars accelerate kill chains through\nmore efficient cross-cueing over centralized command and control. In this\npaper, we propose two novel reward-based learning approaches to decentralized\nnetted radar coordination based on black-box optimization and Reinforcement\nLearning (RL). To make the RL approach tractable, we use a simplification of\nthe problem that we proved to be equivalent to the initial formulation. We\napply these techniques on a simulation where radars can follow multiple targets\nat the same time and show they can learn implicit cooperation by comparing them\nto a greedy baseline.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 07:42:58 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Nour", "Nouredine", ""], ["Belhaj-Soullami", "Reda", ""], ["Buron", "C\u00e9dric", ""], ["Peres", "Alain", ""], ["Barbaresco", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "2010.11742", "submitter": "Jiancheng Yang", "authors": "Jiancheng Yang, Yangzhou Jiang, Xiaoyang Huang, Bingbing Ni, Chenglong\n  Zhao", "title": "Learning Black-Box Attackers with Transferable Priors and Query Feedback", "comments": "NeurIPS 2020. Code is available at\n  https://github.com/TrustworthyDL/LeBA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses the challenging black-box adversarial attack problem,\nwhere only classification confidence of a victim model is available. Inspired\nby consistency of visual saliency between different vision models, a surrogate\nmodel is expected to improve the attack performance via transferability. By\ncombining transferability-based and query-based black-box attack, we propose a\nsurprisingly simple baseline approach (named SimBA++) using the surrogate\nmodel, which significantly outperforms several state-of-the-art methods.\nMoreover, to efficiently utilize the query feedback, we update the surrogate\nmodel in a novel learning scheme, named High-Order Gradient Approximation\n(HOGA). By constructing a high-order gradient computation graph, we update the\nsurrogate model to approximate the victim model in both forward and backward\npass. The SimBA++ and HOGA result in Learnable Black-Box Attack (LeBA), which\nsurpasses previous state of the art by considerable margins: the proposed LeBA\nsignificantly reduces queries, while keeping higher attack success rates close\nto 100% in extensive ImageNet experiments, including attacking vision\nbenchmarks and defensive models. Code is open source at\nhttps://github.com/TrustworthyDL/LeBA.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 05:43:11 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Yang", "Jiancheng", ""], ["Jiang", "Yangzhou", ""], ["Huang", "Xiaoyang", ""], ["Ni", "Bingbing", ""], ["Zhao", "Chenglong", ""]]}, {"id": "2010.11773", "submitter": "Wolfgang Roth", "authors": "Wolfgang Roth, G\\\"unther Schindler, Holger Fr\\\"oning, Franz Pernkopf", "title": "On Resource-Efficient Bayesian Network Classifiers and Deep Neural\n  Networks", "comments": "Accepted at ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two methods to reduce the complexity of Bayesian network (BN)\nclassifiers. First, we introduce quantization-aware training using the\nstraight-through gradient estimator to quantize the parameters of BNs to few\nbits. Second, we extend a recently proposed differentiable tree-augmented naive\nBayes (TAN) structure learning approach by also considering the model size.\nBoth methods are motivated by recent developments in the deep learning\ncommunity, and they provide effective means to trade off between model size and\nprediction accuracy, which is demonstrated in extensive experiments.\nFurthermore, we contrast quantized BN classifiers with quantized deep neural\nnetworks (DNNs) for small-scale scenarios which have hardly been investigated\nin the literature. We show Pareto optimal models with respect to model size,\nnumber of operations, and test error and find that both model classes are\nviable options.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 14:47:55 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Roth", "Wolfgang", ""], ["Schindler", "G\u00fcnther", ""], ["Fr\u00f6ning", "Holger", ""], ["Pernkopf", "Franz", ""]]}, {"id": "2010.11784", "submitter": "Fangyu Liu", "authors": "Fangyu Liu, Ehsan Shareghi, Zaiqiao Meng, Marco Basaldella, Nigel\n  Collier", "title": "Self-Alignment Pretraining for Biomedical Entity Representations", "comments": "NAACL 2021 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the widespread success of self-supervised learning via masked\nlanguage models (MLM), accurately capturing fine-grained semantic relationships\nin the biomedical domain remains a challenge. This is of paramount importance\nfor entity-level tasks such as entity linking where the ability to model entity\nrelations (especially synonymy) is pivotal. To address this challenge, we\npropose SapBERT, a pretraining scheme that self-aligns the representation space\nof biomedical entities. We design a scalable metric learning framework that can\nleverage UMLS, a massive collection of biomedical ontologies with 4M+ concepts.\nIn contrast with previous pipeline-based hybrid systems, SapBERT offers an\nelegant one-model-for-all solution to the problem of medical entity linking\n(MEL), achieving a new state-of-the-art (SOTA) on six MEL benchmarking\ndatasets. In the scientific domain, we achieve SOTA even without task-specific\nsupervision. With substantial improvement over various domain-specific\npretrained MLMs such as BioBERT, SciBERTand and PubMedBERT, our pretraining\nscheme proves to be both effective and robust.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 14:59:57 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 11:01:50 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Liu", "Fangyu", ""], ["Shareghi", "Ehsan", ""], ["Meng", "Zaiqiao", ""], ["Basaldella", "Marco", ""], ["Collier", "Nigel", ""]]}, {"id": "2010.11793", "submitter": "Muhammad Umer Anwaar", "authors": "Muhammad Umer Anwaar, Zhiwei Han, Shyam Arumugaswamy, Rayyan Ahmad\n  Khan, Thomas Weber, Tianming Qiu, Hao Shen, Yuanting Liu, Martin Kleinsteuber", "title": "Metapath- and Entity-aware Graph Neural Network for Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In graph neural networks (GNNs), message passing iteratively aggregates\nnodes' information from their direct neighbors while neglecting the sequential\nnature of multi-hop node connections. Such sequential node connections e.g.,\nmetapaths, capture critical insights for downstream tasks. Concretely, in\nrecommender systems (RSs), disregarding these insights leads to inadequate\ndistillation of collaborative signals. In this paper, we employ collaborative\nsubgraphs (CSGs) and metapaths to form metapath-aware subgraphs, which\nexplicitly capture sequential semantics in graph structures. We propose\nmeta\\textbf{P}ath and \\textbf{E}ntity-\\textbf{A}ware \\textbf{G}raph\n\\textbf{N}eural \\textbf{N}etwork (PEAGNN), which trains multilayer GNNs to\nperform metapath-aware information aggregation on such subgraphs. This\naggregated information from different metapaths is then fused using attention\nmechanism. Finally, PEAGNN gives us the representations for node and subgraph,\nwhich can be used to train MLP for predicting score for target user-item pairs.\nTo leverage the local structure of CSGs, we present entity-awareness that acts\nas a contrastive regularizer on node embedding. Moreover, PEAGNN can be\ncombined with prominent layers such as GAT, GCN and GraphSage. Our empirical\nevaluation shows that our proposed technique outperforms competitive baselines\non several datasets for recommendation tasks. Further analysis demonstrates\nthat PEAGNN also learns meaningful metapath combinations from a given set of\nmetapaths.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 15:14:30 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 11:41:00 GMT"}, {"version": "v3", "created": "Fri, 2 Apr 2021 02:14:56 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Anwaar", "Muhammad Umer", ""], ["Han", "Zhiwei", ""], ["Arumugaswamy", "Shyam", ""], ["Khan", "Rayyan Ahmad", ""], ["Weber", "Thomas", ""], ["Qiu", "Tianming", ""], ["Shen", "Hao", ""], ["Liu", "Yuanting", ""], ["Kleinsteuber", "Martin", ""]]}, {"id": "2010.11796", "submitter": "Bo Feng", "authors": "Bo Feng, Qian Lou, Lei Jiang, and Geoffrey C. Fox", "title": "CryptoGRU: Low Latency Privacy-Preserving Text Analysis With GRU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Billions of text analysis requests containing private emails, personal text\nmessages, and sensitive online reviews, are processed by recurrent neural\nnetworks (RNNs) deployed on public clouds every day. Although prior secure\nnetworks combine homomorphic encryption (HE) and garbled circuit (GC) to\npreserve users' privacy, naively adopting the HE and GC hybrid technique to\nimplement RNNs suffers from long inference latency due to slow activation\nfunctions. In this paper, we present a HE and GC hybrid gated recurrent unit\n(GRU) network, CryptoGRU, for low-latency secure inferences. CryptoGRU replaces\ncomputationally expensive GC-based $tanh$ with fast GC-based $ReLU$, and then\nquantizes $sigmoid$ and $ReLU$ with a smaller bit length to accelerate\nactivations in a GRU. We evaluate CryptoGRU with multiple GRU models trained on\n4 public datasets. Experimental results show CryptoGRU achieves top-notch\naccuracy and improves the secure inference latency by up to $138\\times$ over\none of state-of-the-art secure networks on the Penn Treebank dataset.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 15:20:54 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Feng", "Bo", ""], ["Lou", "Qian", ""], ["Jiang", "Lei", ""], ["Fox", "Geoffrey C.", ""]]}, {"id": "2010.11835", "submitter": "Mikko Lauri", "authors": "Mikko Lauri and Frans A. Oliehoek", "title": "Multi-agent active perception with prediction rewards", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent active perception is a task where a team of agents cooperatively\ngathers observations to compute a joint estimate of a hidden variable. The task\nis decentralized and the joint estimate can only be computed after the task\nends by fusing observations of all agents. The objective is to maximize the\naccuracy of the estimate. The accuracy is quantified by a centralized\nprediction reward determined by a centralized decision-maker who perceives the\nobservations gathered by all agents after the task ends. In this paper, we\nmodel multi-agent active perception as a decentralized partially observable\nMarkov decision process (Dec-POMDP) with a convex centralized prediction\nreward. We prove that by introducing individual prediction actions for each\nagent, the problem is converted into a standard Dec-POMDP with a decentralized\nprediction reward. The loss due to decentralization is bounded, and we give a\nsufficient condition for when it is zero. Our results allow application of any\nDec-POMDP solution algorithm to multi-agent active perception problems, and\nenable planning to reduce uncertainty without explicit computation of joint\nestimates. We demonstrate the empirical usefulness of our results by applying a\nstandard Dec-POMDP algorithm to multi-agent active perception problems, showing\nincreased scalability in the planning horizon.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 16:10:15 GMT"}], "update_date": "2020-10-24", "authors_parsed": [["Lauri", "Mikko", ""], ["Oliehoek", "Frans A.", ""]]}, {"id": "2010.11842", "submitter": "Carsten Lutz", "authors": "Pierre Bourhis and Carsten Lutz", "title": "Containment in Monadic Disjunctive Datalog, MMSNP, and Expressive\n  Description Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study query containment in three closely related formalisms: monadic\ndisjunctive Datalog (MDDLog), MMSNP (a logical generalization of constraint\nsatisfaction problems), and ontology-mediated queries (OMQs) based on\nexpressive description logics and unions of conjunctive queries. Containment in\nMMSNP was known to be decidable due to a result by Feder and Vardi, but its\nexact complexity has remained open. We prove 2NEXPTIME-completeness and extend\nthis result to monadic disjunctive Datalog and to OMQs.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 16:25:00 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Bourhis", "Pierre", ""], ["Lutz", "Carsten", ""]]}, {"id": "2010.11848", "submitter": "Carsten Lutz", "authors": "Cristina Feier, Carsten Lutz, Frank Wolter", "title": "From Conjunctive Queries to Instance Queries in Ontology-Mediated\n  Querying", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider ontology-mediated queries (OMQs) based on expressive description\nlogics of the ALC family and (unions) of conjunctive queries, studying the\nrewritability into OMQs based on instance queries (IQs). Our results include\nexact characterizations of when such a rewriting is possible and tight\ncomplexity bounds for deciding rewritability. We also give a tight complexity\nbound for the related problem of deciding whether a given MMSNP sentence is\nequivalent to a CSP.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 16:40:59 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Feier", "Cristina", ""], ["Lutz", "Carsten", ""], ["Wolter", "Frank", ""]]}, {"id": "2010.11855", "submitter": "Michael Wick", "authors": "Michael L. Wick, Kate Silverstein, Jean-Baptiste Tristan, Adam Pocock,\n  Mark Johnson", "title": "Detecting and Exorcising Statistical Demons from Language Models with\n  Anti-Models of Negative Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It's been said that \"Language Models are Unsupervised Multitask Learners.\"\nIndeed, self-supervised language models trained on \"positive\" examples of\nEnglish text generalize in desirable ways to many natural language tasks. But\nif such models can stray so far from an initial self-supervision objective, a\nwayward model might generalize in undesirable ways too, say to nonsensical\n\"negative\" examples of unnatural language. A key question in this work is: do\nlanguage models trained on (positive) training data also generalize to\n(negative) test data? We use this question as a contrivance to assess the\nextent to which language models learn undesirable properties of text, such as\nn-grams, that might interfere with the learning of more desirable properties of\ntext, such as syntax. We find that within a model family, as the number of\nparameters, training epochs, and data set size increase, so does a model's\nability to generalize to negative n-gram data, indicating standard\nself-supervision generalizes too far. We propose a form of inductive bias that\nattenuates such undesirable signals with negative data distributions\nautomatically learned from positive data. We apply the method to remove n-gram\nsignals from LSTMs and find that doing so causes them to favor syntactic\nsignals, as demonstrated by large error reductions (up to 46% on the hardest\ncases) on a syntactic subject-verb agreement task.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 16:45:32 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Wick", "Michael L.", ""], ["Silverstein", "Kate", ""], ["Tristan", "Jean-Baptiste", ""], ["Pocock", "Adam", ""], ["Johnson", "Mark", ""]]}, {"id": "2010.11863", "submitter": "Ruosong Wang", "authors": "Ruosong Wang, Hanrui Zhang, Devendra Singh Chaplot, Denis Garagi\\'c,\n  Ruslan Salakhutdinov", "title": "Planning with Submodular Objective Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study planning with submodular objective functions, where instead of\nmaximizing the cumulative reward, the goal is to maximize the objective value\ninduced by a submodular function. Our framework subsumes standard planning and\nsubmodular maximization with cardinality constraints as special cases, and thus\nmany practical applications can be naturally formulated within our framework.\nBased on the notion of multilinear extension, we propose a novel and\ntheoretically principled algorithmic framework for planning with submodular\nobjective functions, which recovers classical algorithms when applied to the\ntwo special cases mentioned above. Empirically, our approach significantly\noutperforms baseline algorithms on synthetic environments and navigation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 16:55:12 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Wang", "Ruosong", ""], ["Zhang", "Hanrui", ""], ["Chaplot", "Devendra Singh", ""], ["Garagi\u0107", "Denis", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2010.11869", "submitter": "Lei Xu", "authors": "Lei Xu, Ivan Ramirez, Kalyan Veeramachaneni", "title": "Rewriting Meaningful Sentences via Conditional BERT Sampling and an\n  application on fooling text classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most adversarial attack methods that are designed to deceive a text\nclassifier change the text classifier's prediction by modifying a few words or\ncharacters. Few try to attack classifiers by rewriting a whole sentence, due to\nthe difficulties inherent in sentence-level rephrasing as well as the problem\nof setting the criteria for legitimate rewriting.\n  In this paper, we explore the problem of creating adversarial examples with\nsentence-level rewriting. We design a new sampling method, named\nParaphraseSampler, to efficiently rewrite the original sentence in multiple\nways. Then we propose a new criteria for modification, called a sentence-level\nthreaten model. This criteria allows for both word- and sentence-level changes,\nand can be adjusted independently in two dimensions: semantic similarity and\ngrammatical quality. Experimental results show that many of these rewritten\nsentences are misclassified by the classifier. On all 6 datasets, our\nParaphraseSampler achieves a better attack success rate than our baseline.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 17:03:13 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Xu", "Lei", ""], ["Ramirez", "Ivan", ""], ["Veeramachaneni", "Kalyan", ""]]}, {"id": "2010.11895", "submitter": "Ruosong Wang", "authors": "Ruosong Wang, Dean P. Foster, Sham M. Kakade", "title": "What are the Statistical Limits of Offline RL with Linear Function\n  Approximation?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline reinforcement learning seeks to utilize offline (observational) data\nto guide the learning of (causal) sequential decision making strategies. The\nhope is that offline reinforcement learning coupled with function approximation\nmethods (to deal with the curse of dimensionality) can provide a means to help\nalleviate the excessive sample complexity burden in modern sequential decision\nmaking problems. However, the extent to which this broader approach can be\neffective is not well understood, where the literature largely consists of\nsufficient conditions.\n  This work focuses on the basic question of what are necessary\nrepresentational and distributional conditions that permit provable\nsample-efficient offline reinforcement learning. Perhaps surprisingly, our main\nresult shows that even if: i) we have realizability in that the true value\nfunction of \\emph{every} policy is linear in a given set of features and 2) our\noff-policy data has good coverage over all features (under a strong spectral\ncondition), then any algorithm still (information-theoretically) requires a\nnumber of offline samples that is exponential in the problem horizon in order\nto non-trivially estimate the value of \\emph{any} given policy. Our results\nhighlight that sample-efficient offline policy evaluation is simply not\npossible unless significantly stronger conditions hold; such conditions include\neither having low distribution shift (where the offline data distribution is\nclose to the distribution of the policy to be evaluated) or significantly\nstronger representational conditions (beyond realizability).\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 17:32:13 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Wang", "Ruosong", ""], ["Foster", "Dean P.", ""], ["Kakade", "Sham M.", ""]]}, {"id": "2010.11917", "submitter": "Suraj Nair", "authors": "Annie S. Chen, HyunJi Nam, Suraj Nair, Chelsea Finn", "title": "Batch Exploration with Examples for Scalable Robotic Reinforcement\n  Learning", "comments": "11 Pages, 11 Figures", "journal-ref": "IEEE Robotics and Automation Letters ( Volume: 6, Issue: 3, July\n  2021)", "doi": "10.1109/LRA.2021.3068655", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from diverse offline datasets is a promising path towards learning\ngeneral purpose robotic agents. However, a core challenge in this paradigm lies\nin collecting large amounts of meaningful data, while not depending on a human\nin the loop for data collection. One way to address this challenge is through\ntask-agnostic exploration, where an agent attempts to explore without a\ntask-specific reward function, and collect data that can be useful for any\ndownstream task. While these approaches have shown some promise in simple\ndomains, they often struggle to explore the relevant regions of the state space\nin more challenging settings, such as vision based robotic manipulation. This\nchallenge stems from an objective that encourages exploring everything in a\npotentially vast state space. To mitigate this challenge, we propose to focus\nexploration on the important parts of the state space using weak human\nsupervision. Concretely, we propose an exploration technique, Batch Exploration\nwith Examples (BEE), that explores relevant regions of the state-space, guided\nby a modest number of human provided images of important states. These human\nprovided images only need to be collected once at the beginning of data\ncollection and can be collected in a matter of minutes, allowing us to scalably\ncollect diverse datasets, which can then be combined with any batch RL\nalgorithm. We find that BEE is able to tackle challenging vision-based\nmanipulation tasks both in simulation and on a real Franka robot, and observe\nthat compared to task-agnostic and weakly-supervised exploration techniques, it\n(1) interacts more than twice as often with relevant objects, and (2) improves\ndownstream task performance when used in conjunction with offline RL.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 17:49:25 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 18:27:28 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Chen", "Annie S.", ""], ["Nam", "HyunJi", ""], ["Nair", "Suraj", ""], ["Finn", "Chelsea", ""]]}, {"id": "2010.11926", "submitter": "Loizos Michael", "authors": "Efthymia Tsamoura, Loizos Michael", "title": "Neural-Symbolic Integration: A Compositional Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant progress in the development of neural-symbolic\nframeworks, the question of how to integrate a neural and a symbolic system in\na \\emph{compositional} manner remains open. Our work seeks to fill this gap by\ntreating these two systems as black boxes to be integrated as modules into a\nsingle architecture, without making assumptions on their internal structure and\nsemantics. Instead, we expect only that each module exposes certain methods for\naccessing the functions that the module implements: the symbolic module exposes\na deduction method for computing the function's output on a given input, and an\nabduction method for computing the function's inputs for a given output; the\nneural module exposes a deduction method for computing the function's output on\na given input, and an induction method for updating the function given\ninput-output training instances. We are, then, able to show that a symbolic\nmodule -- with any choice for syntax and semantics, as long as the deduction\nand abduction methods are exposed -- can be cleanly integrated with a neural\nmodule, and facilitate the latter's efficient training, achieving empirical\nperformance that exceeds that of previous work.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 17:55:44 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Tsamoura", "Efthymia", ""], ["Michael", "Loizos", ""]]}, {"id": "2010.11929", "submitter": "Alexey Dosovitskiy", "authors": "Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk\n  Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias\n  Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit and Neil Houlsby", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at\n  Scale", "comments": "Fine-tuning code and pre-trained models are available at\n  https://github.com/google-research/vision_transformer. ICLR camera-ready\n  version with 2 small modifications: 1) Added a discussion of CLS vs GAP\n  classifier in the appendix, 2) Fixed an error in exaFLOPs computation in\n  Figure 5 and Table 6 (relative performance of models is basically not\n  affected)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the Transformer architecture has become the de-facto standard for\nnatural language processing tasks, its applications to computer vision remain\nlimited. In vision, attention is either applied in conjunction with\nconvolutional networks, or used to replace certain components of convolutional\nnetworks while keeping their overall structure in place. We show that this\nreliance on CNNs is not necessary and a pure transformer applied directly to\nsequences of image patches can perform very well on image classification tasks.\nWhen pre-trained on large amounts of data and transferred to multiple mid-sized\nor small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision\nTransformer (ViT) attains excellent results compared to state-of-the-art\nconvolutional networks while requiring substantially fewer computational\nresources to train.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 17:55:59 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 13:08:56 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Dosovitskiy", "Alexey", ""], ["Beyer", "Lucas", ""], ["Kolesnikov", "Alexander", ""], ["Weissenborn", "Dirk", ""], ["Zhai", "Xiaohua", ""], ["Unterthiner", "Thomas", ""], ["Dehghani", "Mostafa", ""], ["Minderer", "Matthias", ""], ["Heigold", "Georg", ""], ["Gelly", "Sylvain", ""], ["Uszkoreit", "Jakob", ""], ["Houlsby", "Neil", ""]]}, {"id": "2010.11936", "submitter": "Tomasz Stanis{\\l}awek", "authors": "Rafal Powalski and Tomasz Stanislawek", "title": "UniCase -- Rethinking Casing in Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new approach to dealing with the problem of\ncase-sensitiveness in Language Modelling (LM). We propose simple architecture\nmodification to the RoBERTa language model, accompanied by a new tokenization\nstrategy, which we named Unified Case LM (UniCase). We tested our solution on\nthe GLUE benchmark, which led to increased performance by 0.42 points.\nMoreover, we prove that the UniCase model works much better when we have to\ndeal with text data, where all tokens are uppercased (+5.88 point).\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 17:58:44 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Powalski", "Rafal", ""], ["Stanislawek", "Tomasz", ""]]}, {"id": "2010.11940", "submitter": "Youngwoon Lee", "authors": "Jun Yamada, Youngwoon Lee, Gautam Salhotra, Karl Pertsch, Max\n  Pflueger, Gaurav S. Sukhatme, Joseph J. Lim, Peter Englert", "title": "Motion Planner Augmented Reinforcement Learning for Robot Manipulation\n  in Obstructed Environments", "comments": "Published at the Conference on Robot Learning (CoRL) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) agents are able to learn contact-rich\nmanipulation tasks by maximizing a reward signal, but require large amounts of\nexperience, especially in environments with many obstacles that complicate\nexploration. In contrast, motion planners use explicit models of the agent and\nenvironment to plan collision-free paths to faraway goals, but suffer from\ninaccurate models in tasks that require contacts with the environment. To\ncombine the benefits of both approaches, we propose motion planner augmented RL\n(MoPA-RL) which augments the action space of an RL agent with the long-horizon\nplanning capabilities of motion planners. Based on the magnitude of the action,\nour approach smoothly transitions between directly executing the action and\ninvoking a motion planner. We evaluate our approach on various simulated\nmanipulation tasks and compare it to alternative action spaces in terms of\nlearning efficiency and safety. The experiments demonstrate that MoPA-RL\nincreases learning efficiency, leads to a faster exploration, and results in\nsafer policies that avoid collisions with the environment. Videos and code are\navailable at https://clvrai.com/mopa-rl .\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 17:59:09 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Yamada", "Jun", ""], ["Lee", "Youngwoon", ""], ["Salhotra", "Gautam", ""], ["Pertsch", "Karl", ""], ["Pflueger", "Max", ""], ["Sukhatme", "Gaurav S.", ""], ["Lim", "Joseph J.", ""], ["Englert", "Peter", ""]]}, {"id": "2010.11944", "submitter": "Karl Pertsch", "authors": "Karl Pertsch, Youngwoon Lee, Joseph J. Lim", "title": "Accelerating Reinforcement Learning with Learned Skill Priors", "comments": "4th Conference on Robot Learning (CoRL), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent agents rely heavily on prior experience when learning a new task,\nyet most modern reinforcement learning (RL) approaches learn every task from\nscratch. One approach for leveraging prior knowledge is to transfer skills\nlearned on prior tasks to the new task. However, as the amount of prior\nexperience increases, the number of transferable skills grows too, making it\nchallenging to explore the full set of available skills during downstream\nlearning. Yet, intuitively, not all skills should be explored with equal\nprobability; for example information about the current state can hint which\nskills are promising to explore. In this work, we propose to implement this\nintuition by learning a prior over skills. We propose a deep latent variable\nmodel that jointly learns an embedding space of skills and the skill prior from\noffline agent experience. We then extend common maximum-entropy RL approaches\nto use skill priors to guide downstream learning. We validate our approach,\nSPiRL (Skill-Prior RL), on complex navigation and robotic manipulation tasks\nand show that learned skill priors are essential for effective skill transfer\nfrom rich datasets. Videos and code are available at https://clvrai.com/spirl.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 17:59:51 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Pertsch", "Karl", ""], ["Lee", "Youngwoon", ""], ["Lim", "Joseph J.", ""]]}, {"id": "2010.11967", "submitter": "Chenguang Wang", "authors": "Chenguang Wang, Xiao Liu, Dawn Song", "title": "Language Models are Open Knowledge Graphs", "comments": "30 pages, 32 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows how to construct knowledge graphs (KGs) from pre-trained\nlanguage models (e.g., BERT, GPT-2/3), without human supervision. Popular KGs\n(e.g, Wikidata, NELL) are built in either a supervised or semi-supervised\nmanner, requiring humans to create knowledge. Recent deep language models\nautomatically acquire knowledge from large-scale corpora via pre-training. The\nstored knowledge has enabled the language models to improve downstream NLP\ntasks, e.g., answering questions, and writing code and articles. In this paper,\nwe propose an unsupervised method to cast the knowledge contained within\nlanguage models into KGs. We show that KGs are constructed with a single\nforward pass of the pre-trained language models (without fine-tuning) over the\ncorpora. We demonstrate the quality of the constructed KGs by comparing to two\nKGs (Wikidata, TAC KBP) created by humans. Our KGs also provide open factual\nknowledge that is new in the existing KGs. Our code and KGs will be made\npublicly available.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 18:01:56 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Wang", "Chenguang", ""], ["Liu", "Xiao", ""], ["Song", "Dawn", ""]]}, {"id": "2010.11982", "submitter": "Avia Efrat", "authors": "Avia Efrat and Omer Levy", "title": "The Turking Test: Can Language Models Understand Instructions?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised machine learning provides the learner with a set of input-output\nexamples of the target task. Humans, however, can also learn to perform new\ntasks from instructions in natural language. Can machines learn to understand\ninstructions as well? We present the Turking Test, which examines a model's\nability to follow natural language instructions of varying complexity. These\nrange from simple tasks, like retrieving the nth word of a sentence, to ones\nthat require creativity, such as generating examples for SNLI and SQuAD in\nplace of human intelligence workers (\"turkers\"). Despite our lenient evaluation\nmethodology, we observe that a large pretrained language model performs poorly\nacross all tasks. Analyzing the model's error patterns reveals that the model\ntends to ignore explicit instructions and often generates outputs that cannot\nbe construed as an attempt to solve the task. While it is not yet clear whether\ninstruction understanding can be captured by traditional language models, the\nsheer expressivity of instruction understanding makes it an appealing\nalternative to the rising few-shot inference paradigm.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 18:44:16 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Efrat", "Avia", ""], ["Levy", "Omer", ""]]}, {"id": "2010.12001", "submitter": "Arthur Delarue", "authors": "Arthur Delarue, Ross Anderson, Christian Tjandraatmadja", "title": "Reinforcement Learning with Combinatorial Actions: An Application to\n  Vehicle Routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value-function-based methods have long played an important role in\nreinforcement learning. However, finding the best next action given a value\nfunction of arbitrary complexity is nontrivial when the action space is too\nlarge for enumeration. We develop a framework for value-function-based deep\nreinforcement learning with a combinatorial action space, in which the action\nselection problem is explicitly formulated as a mixed-integer optimization\nproblem. As a motivating example, we present an application of this framework\nto the capacitated vehicle routing problem (CVRP), a combinatorial optimization\nproblem in which a set of locations must be covered by a single vehicle with\nlimited capacity. On each instance, we model an action as the construction of a\nsingle route, and consider a deterministic policy which is improved through a\nsimple policy iteration algorithm. Our approach is competitive with other\nreinforcement learning methods and achieves an average gap of 1.7% with\nstate-of-the-art OR methods on standard library instances of medium size.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 19:32:21 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Delarue", "Arthur", ""], ["Anderson", "Ross", ""], ["Tjandraatmadja", "Christian", ""]]}, {"id": "2010.12008", "submitter": "Siamak Shakeri", "authors": "Siamak Shakeri, Noah Constant, Mihir Sanjay Kale, Linting Xue", "title": "Towards Zero-Shot Multilingual Synthetic Question and Answer Generation\n  for Cross-Lingual Reading Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple method to generate multilingual question and answer pairs\non a large scale through the use of a single generative model. These synthetic\nsamples can be used to improve the zero-shot performance of multilingual QA\nmodels on target languages. Our proposed multi-task training of the generative\nmodel only requires the labeled training samples in English, thus removing the\nneed for such samples in the target languages, making it applicable to far more\nlanguages than those with labeled data. Human evaluations indicate the majority\nof such samples are grammatically correct and sensible. Experimental results\nshow our proposed approach can achieve large gains on the XQuAD dataset,\nreducing the gap between zero-shot and supervised performance of smaller QA\nmodels on various languages.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 19:59:37 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 21:24:02 GMT"}, {"version": "v3", "created": "Fri, 28 May 2021 21:07:33 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Shakeri", "Siamak", ""], ["Constant", "Noah", ""], ["Kale", "Mihir Sanjay", ""], ["Xue", "Linting", ""]]}, {"id": "2010.12016", "submitter": "Matthew Leavitt", "authors": "Matthew L. Leavitt, Ari Morcos", "title": "Towards falsifiable interpretability research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for understanding the decisions of and mechanisms underlying deep\nneural networks (DNNs) typically rely on building intuition by emphasizing\nsensory or semantic features of individual examples. For instance, methods aim\nto visualize the components of an input which are \"important\" to a network's\ndecision, or to measure the semantic properties of single neurons. Here, we\nargue that interpretability research suffers from an over-reliance on\nintuition-based approaches that risk-and in some cases have caused-illusory\nprogress and misleading conclusions. We identify a set of limitations that we\nargue impede meaningful progress in interpretability research, and examine two\npopular classes of interpretability methods-saliency and single-neuron-based\napproaches-that serve as case studies for how overreliance on intuition and\nlack of falsifiability can undermine interpretability research. To address\nthese concerns, we propose a strategy to address these impediments in the form\nof a framework for strongly falsifiable interpretability research. We encourage\nresearchers to use their intuitions as a starting point to develop and test\nclear, falsifiable hypotheses, and hope that our framework yields robust,\nevidence-based interpretability methods that generate meaningful advances in\nour understanding of DNNs.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 22:03:41 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Leavitt", "Matthew L.", ""], ["Morcos", "Ari", ""]]}, {"id": "2010.12042", "submitter": "Byungsoo Kim", "authors": "Dongmin Shin, Yugeun Shim, Hangyeol Yu, Seewoo Lee, Byungsoo Kim,\n  Youngduck Choi", "title": "SAINT+: Integrating Temporal Features for EdNet Correctness Prediction", "comments": "LAK 2021", "journal-ref": null, "doi": "10.1145/3448139.3448188", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose SAINT+, a successor of SAINT which is a Transformer based\nknowledge tracing model that separately processes exercise information and\nstudent response information. Following the architecture of SAINT, SAINT+ has\nan encoder-decoder structure where the encoder applies self-attention layers to\na stream of exercise embeddings, and the decoder alternately applies\nself-attention layers and encoder-decoder attention layers to streams of\nresponse embeddings and encoder output. Moreover, SAINT+ incorporates two\ntemporal feature embeddings into the response embeddings: elapsed time, the\ntime taken for a student to answer, and lag time, the time interval between\nadjacent learning activities. We empirically evaluate the effectiveness of\nSAINT+ on EdNet, the largest publicly available benchmark dataset in the\neducation domain. Experimental results show that SAINT+ achieves\nstate-of-the-art performance in knowledge tracing with an improvement of 1.25%\nin area under receiver operating characteristic curve compared to SAINT, the\ncurrent state-of-the-art model in EdNet dataset.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 01:49:31 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 02:31:42 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Shin", "Dongmin", ""], ["Shim", "Yugeun", ""], ["Yu", "Hangyeol", ""], ["Lee", "Seewoo", ""], ["Kim", "Byungsoo", ""], ["Choi", "Youngduck", ""]]}, {"id": "2010.12069", "submitter": "Duncan McElfresh", "authors": "Duncan C McElfresh, Michael Curry, Tuomas Sandholm, John P Dickerson", "title": "Improving Policy-Constrained Kidney Exchange via Pre-Screening", "comments": "Appears at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In barter exchanges, participants swap goods with one another without\nexchanging money; exchanges are often facilitated by a central clearinghouse,\nwith the goal of maximizing the aggregate quality (or number) of swaps. Barter\nexchanges are subject to many forms of uncertainty--in participant preferences,\nthe feasibility and quality of various swaps, and so on. Our work is motivated\nby kidney exchange, a real-world barter market in which patients in need of a\nkidney transplant swap their willing living donors, in order to find a better\nmatch. Modern exchanges include 2- and 3-way swaps, making the kidney exchange\nclearing problem NP-hard. Planned transplants often fail for a variety of\nreasons--if the donor organ is refused by the recipient's medical team, or if\nthe donor and recipient are found to be medically incompatible. Due to 2- and\n3-way swaps, failed transplants can \"cascade\" through an exchange; one US-based\nexchange estimated that about 85% of planned transplants failed in 2019. Many\noptimization-based approaches have been designed to avoid these failures;\nhowever most exchanges cannot implement these methods due to legal and policy\nconstraints. Instead we consider a setting where exchanges can query the\npreferences of certain donors and recipients--asking whether they would accept\na particular transplant. We characterize this as a two-stage decision problem,\nin which the exchange program (a) queries a small number of transplants before\ncommitting to a matching, and (b) constructs a matching according to fixed\npolicy. We show that selecting these edges is a challenging combinatorial\nproblem, which is non-monotonic and non-submodular, in addition to being\nNP-hard. We propose both a greedy heuristic and a Monte Carlo tree search,\nwhich outperforms previous approaches, using experiments on both synthetic data\nand real kidney exchange data from the United Network for Organ Sharing.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 21:07:36 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["McElfresh", "Duncan C", ""], ["Curry", "Michael", ""], ["Sandholm", "Tuomas", ""], ["Dickerson", "John P", ""]]}, {"id": "2010.12091", "submitter": "Ravi Tejwani", "authors": "Ravi Tejwani, Boris Katz, Cynthia Breazeal", "title": "Migratable AI: Personalizing Dialog Conversations with migration context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The migration of conversational AI agents across different embodiments in\norder to maintain the continuity of the task has been recently explored to\nfurther improve user experience. However, these migratable agents lack\ncontextual understanding of the user information and the migrated device during\nthe dialog conversations with the user. This opens the question of how an agent\nmight behave when migrated into an embodiment for contextually predicting the\nnext utterance. We collected a dataset from the dialog conversations between\ncrowdsourced workers with the migration context involving personal and\nnon-personal utterances in different settings (public or private) of embodiment\ninto which the agent migrated. We trained the generative and information\nretrieval models on the dataset using with and without migration context and\nreport the results of both qualitative metrics and human evaluation. We believe\nthat the migration dataset would be useful for training future migratable AI\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 22:23:03 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Tejwani", "Ravi", ""], ["Katz", "Boris", ""], ["Breazeal", "Cynthia", ""]]}, {"id": "2010.12102", "submitter": "Xintao Wu", "authors": "Wen Huang and Kevin Labille and Xintao Wu and Dongwon Lee and Neil\n  Heffernan", "title": "Achieving User-Side Fairness in Contextual Bandits", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized recommendation based on multi-arm bandit (MAB) algorithms has\nshown to lead to high utility and efficiency as it can dynamically adapt the\nrecommendation strategy based on feedback. However, unfairness could incur in\npersonalized recommendation. In this paper, we study how to achieve user-side\nfairness in personalized recommendation. We formulate our fair personalized\nrecommendation as a modified contextual bandit and focus on achieving fairness\non the individual whom is being recommended an item as opposed to achieving\nfairness on the items that are being recommended. We introduce and define a\nmetric that captures the fairness in terms of rewards received for both the\nprivileged and protected groups. We develop a fair contextual bandit algorithm,\nFair-LinUCB, that improves upon the traditional LinUCB algorithm to achieve\ngroup-level fairness of users. Our algorithm detects and monitors unfairness\nwhile it learns to recommend personalized videos to students to achieve high\nefficiency. We provide a theoretical regret analysis and show that our\nalgorithm has a slightly higher regret bound than LinUCB. We conduct numerous\nexperimental evaluations to compare the performances of our fair contextual\nbandit to that of LinUCB and show that our approach achieves group-level\nfairness while maintaining a high utility.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 22:58:25 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Huang", "Wen", ""], ["Labille", "Kevin", ""], ["Wu", "Xintao", ""], ["Lee", "Dongwon", ""], ["Heffernan", "Neil", ""]]}, {"id": "2010.12121", "submitter": "Feiliang Ren", "authors": "Feiliang Ren, Juchen Li, Huihui Zhang, Shilei Liu, Bochao Li, Ruicheng\n  Ming, Yujia Bai", "title": "Knowledge Graph Embedding with Atrous Convolution and Residual Learning", "comments": "Accepted by COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding is an important task and it will benefit lots of\ndownstream applications. Currently, deep neural networks based methods achieve\nstate-of-the-art performance. However, most of these existing methods are very\ncomplex and need much time for training and inference. To address this issue,\nwe propose a simple but effective atrous convolution based knowledge graph\nembedding method. Compared with existing state-of-the-art methods, our method\nhas following main characteristics. First, it effectively increases feature\ninteractions by using atrous convolutions. Second, to address the original\ninformation forgotten issue and vanishing/exploding gradient issue, it uses the\nresidual learning method. Third, it has simpler structure but much higher\nparameter efficiency. We evaluate our method on six benchmark datasets with\ndifferent evaluation metrics. Extensive experiments show that our model is very\neffective. On these diverse datasets, it achieves better results than the\ncompared state-of-the-art methods on most of evaluation metrics. The source\ncodes of our model could be found at https://github.com/neukg/AcrE.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 00:57:23 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 06:07:38 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Ren", "Feiliang", ""], ["Li", "Juchen", ""], ["Zhang", "Huihui", ""], ["Liu", "Shilei", ""], ["Li", "Bochao", ""], ["Ming", "Ruicheng", ""], ["Bai", "Yujia", ""]]}, {"id": "2010.12144", "submitter": "Mehrnoosh Mirtaheri", "authors": "Mehrnoosh Mirtaheri, Mohammad Rostami, Xiang Ren, Fred Morstatter,\n  Aram Galstyan", "title": "One-shot Learning for Temporal Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most real-world knowledge graphs are characterized by a long-tail relation\nfrequency distribution where a significant fraction of relations occurs only a\nhandful of times. This observation has given rise to recent interest in\nlow-shot learning methods that are able to generalize from only a few examples.\nThe existing approaches, however, are tailored to static knowledge graphs and\nnot easily generalized to temporal settings, where data scarcity poses even\nbigger problems, e.g., due to occurrence of new, previously unseen relations.\nWe address this shortcoming by proposing a one-shot learning framework for link\nprediction in temporal knowledge graphs. Our proposed method employs a\nself-attention mechanism to effectively encode temporal interactions between\nentities, and a network to compute a similarity score between a given query and\na (one-shot) example. Our experiments show that the proposed algorithm\noutperforms the state of the art baselines for two well-studied benchmarks\nwhile achieving significantly better performance for sparse relations.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 03:24:44 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Mirtaheri", "Mehrnoosh", ""], ["Rostami", "Mohammad", ""], ["Ren", "Xiang", ""], ["Morstatter", "Fred", ""], ["Galstyan", "Aram", ""]]}, {"id": "2010.12214", "submitter": "Nasrin Sultana", "authors": "Nasrin Sultana, Jeffrey Chan, A. K. Qin, Tabinda Sarwar", "title": "Learning to Optimise General TSP Instances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Travelling Salesman Problem (TSP) is a classical combinatorial\noptimisation problem. Deep learning has been successfully extended to\nmeta-learning, where previous solving efforts assist in learning how to\noptimise future optimisation instances. In recent years, learning to optimise\napproaches have shown success in solving TSP problems. However, they focus on\none type of TSP problem, namely ones where the points are uniformly distributed\nin Euclidean spaces and have issues in generalising to other embedding spaces,\ne.g., spherical distance spaces, and to TSP instances where the points are\ndistributed in a non-uniform manner. An aim of learning to optimise is to train\nonce and solve across a broad spectrum of (TSP) problems. Although supervised\nlearning approaches have shown to achieve more optimal solutions than\nunsupervised approaches, they do require the generation of training data and\nrunning a solver to obtain solutions to learn from, which can be time-consuming\nand difficult to find reasonable solutions for harder TSP instances. Hence this\npaper introduces a new learning-based approach to solve a variety of different\nand common TSP problems that are trained on easier instances which are faster\nto train and are easier to obtain better solutions. We name this approach the\nnon-Euclidean TSP network (NETSP-Net). The approach is evaluated on various TSP\ninstances using the benchmark TSPLIB dataset and popular instance generator\nused in the literature. We performed extensive experiments that indicate our\napproach generalises across many types of instances and scales to instances\nthat are larger than what was used during training.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 07:37:16 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 11:51:57 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Sultana", "Nasrin", ""], ["Chan", "Jeffrey", ""], ["Qin", "A. K.", ""], ["Sarwar", "Tabinda", ""]]}, {"id": "2010.12237", "submitter": "Pedro Alejandro Ortega", "authors": "Tim Genewein, Tom McGrath, Gr\\'egoire D\\'eletang, Vladimir Mikulik,\n  Miljan Martic, Shane Legg, Pedro A. Ortega", "title": "Algorithms for Causal Reasoning in Probability Trees", "comments": "(2nd version with correction to algorithm) 11 pages, 8 figures, 5\n  algorithms. A companion Colaboratory tutorial is available at\n  https://github.com/deepmind/deepmind-research/tree/master/causal_reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probability trees are one of the simplest models of causal generative\nprocesses. They possess clean semantics and -- unlike causal Bayesian networks\n-- they can represent context-specific causal dependencies, which are necessary\nfor e.g. causal induction. Yet, they have received little attention from the AI\nand ML community. Here we present concrete algorithms for causal reasoning in\ndiscrete probability trees that cover the entire causal hierarchy (association,\nintervention, and counterfactuals), and operate on arbitrary propositional and\ncausal events. Our work expands the domain of causal reasoning to a very\ngeneral class of discrete stochastic processes.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 08:51:52 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 00:49:06 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Genewein", "Tim", ""], ["McGrath", "Tom", ""], ["D\u00e9letang", "Gr\u00e9goire", ""], ["Mikulik", "Vladimir", ""], ["Martic", "Miljan", ""], ["Legg", "Shane", ""], ["Ortega", "Pedro A.", ""]]}, {"id": "2010.12265", "submitter": "Bernardo Anibal Subercaseaux Roa", "authors": "Pablo Barcel\\'o, Mika\\\"el Monet, Jorge P\\'erez, Bernardo Subercaseaux", "title": "Model Interpretability through the Lens of Computational Complexity", "comments": "36 pages, including 9 pages of main text. This is the arXiv version\n  of the NeurIPS'2020 paper. Except from minor differences that could be\n  introduced by the publisher, the only difference should be the addition of\n  the appendix, which contains all the proofs that do not appear in the main\n  text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of several claims stating that some models are more interpretable\nthan others -- e.g., \"linear models are more interpretable than deep neural\nnetworks\" -- we still lack a principled notion of interpretability to formally\ncompare among different classes of models. We make a step towards such a notion\nby studying whether folklore interpretability claims have a correlate in terms\nof computational complexity theory. We focus on local post-hoc explainability\nqueries that, intuitively, attempt to answer why individual inputs are\nclassified in a certain way by a given model. In a nutshell, we say that a\nclass $\\mathcal{C}_1$ of models is more interpretable than another class\n$\\mathcal{C}_2$, if the computational complexity of answering post-hoc queries\nfor models in $\\mathcal{C}_2$ is higher than for those in $\\mathcal{C}_1$. We\nprove that this notion provides a good theoretical counterpart to current\nbeliefs on the interpretability of models; in particular, we show that under\nour definition and assuming standard complexity-theoretical assumptions (such\nas P$\\neq$NP), both linear and tree-based models are strictly more\ninterpretable than neural networks. Our complexity analysis, however, does not\nprovide a clear-cut difference between linear and tree-based models, as we\nobtain different results depending on the particular post-hoc explanations\nconsidered. Finally, by applying a finer complexity analysis based on\nparameterized complexity, we are able to prove a theoretical result suggesting\nthat shallow neural networks are more interpretable than deeper ones.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 09:50:40 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 21:57:06 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Barcel\u00f3", "Pablo", ""], ["Monet", "Mika\u00ebl", ""], ["P\u00e9rez", "Jorge", ""], ["Subercaseaux", "Bernardo", ""]]}, {"id": "2010.12290", "submitter": "Hanshuang Tong", "authors": "Zhen Wang, Ben Teng, Yun Zhou, Hanshuang Tong and Guangtong Liu", "title": "Exploring Common and Individual Characteristics of Students via Matrix\n  Recovering", "comments": "8 pages, 9 figures, Submitted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balancing group teaching and individual mentoring is an important issue in\neducation area. The nature behind this issue is to explore common\ncharacteristics shared by multiple students and individual characteristics for\neach student. Biclustering methods have been proved successful for detecting\nmeaningful patterns with the goal of driving group instructions based on\nstudents' characteristics. However, these methods ignore the individual\ncharacteristics of students as they only focus on common characteristics of\nstudents. In this article, we propose a framework to detect both group\ncharacteristics and individual characteristics of students simultaneously. We\nassume that the characteristics matrix of students' is composed of two parts:\none is a low-rank matrix representing the common characteristics of students;\nthe other is a sparse matrix representing individual characteristics of\nstudents. Thus, we treat the balancing issue as a matrix recovering problem.\nThe experiment results show the effectiveness of our method. Firstly, it can\ndetect meaningful biclusters that are comparable with the state-of-the-art\nbiclutering algorithms. Secondly, it can identify individual characteristics\nfor each student simultaneously. Both the source code of our algorithm and the\nreal datasets are available upon request.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 10:42:17 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Wang", "Zhen", ""], ["Teng", "Ben", ""], ["Zhou", "Yun", ""], ["Tong", "Hanshuang", ""], ["Liu", "Guangtong", ""]]}, {"id": "2010.12324", "submitter": "Janet Rafner", "authors": "Janet Rafner, Lotte Philipsen, Sebastian Risi, Joel Simon, Jacob\n  Sherson", "title": "The power of pictures: using ML assisted image generation to engage the\n  crowd in complex socioscientific problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-computer image generation using Generative Adversarial Networks (GANs)\nis becoming a well-established methodology for casual entertainment and open\nartistic exploration. Here, we take the interaction a step further by weaving\nin carefully structured design elements to transform the activity of\nML-assisted imaged generation into a catalyst for large-scale popular dialogue\non complex socioscientific problems such as the United Nations Sustainable\nDevelopment Goals (SDGs) and as a gateway for public participation in research.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 12:09:53 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 16:31:36 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Rafner", "Janet", ""], ["Philipsen", "Lotte", ""], ["Risi", "Sebastian", ""], ["Simon", "Joel", ""], ["Sherson", "Jacob", ""]]}, {"id": "2010.12327", "submitter": "Dave Braines Mr", "authors": "Dave Braines, Federico Cerutti, Marc Roig Vilamala, Mani Srivastava,\n  Lance Kaplan Alun Preece, Gavin Pearson", "title": "Towards human-agent knowledge fusion (HAKF) in support of distributed\n  coalition teams", "comments": "Presented at AAAI FSS-20: Artificial Intelligence in Government and\n  Public Sector, Washington, DC, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future coalition operations can be substantially augmented through agile\nteaming between human and machine agents, but in a coalition context these\nagents may be unfamiliar to the human users and expected to operate in a broad\nset of scenarios rather than being narrowly defined for particular purposes. In\nsuch a setting it is essential that the human agents can rapidly build trust in\nthe machine agents through appropriate transparency of their behaviour, e.g.,\nthrough explanations. The human agents are also able to bring their local\nknowledge to the team, observing the situation unfolding and deciding which key\ninformation should be communicated to the machine agents to enable them to\nbetter account for the particular environment. In this paper we describe the\ninitial steps towards this human-agent knowledge fusion (HAKF) environment\nthrough a recap of the key requirements, and an explanation of how these can be\nfulfilled for an example situation. We show how HAKF has the potential to bring\nvalue to both human and machine agents working as part of a distributed\ncoalition team in a complex event processing setting with uncertain sources.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 12:10:40 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Braines", "Dave", ""], ["Cerutti", "Federico", ""], ["Vilamala", "Marc Roig", ""], ["Srivastava", "Mani", ""], ["Preece", "Lance Kaplan Alun", ""], ["Pearson", "Gavin", ""]]}, {"id": "2010.12367", "submitter": "Cong Zhang", "authors": "Cong Zhang, Wen Song, Zhiguang Cao, Jie Zhang, Puay Siew Tan, Chi Xu", "title": "Learning to Dispatch for Job Shop Scheduling via Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Priority dispatching rule (PDR) is widely used for solving real-world\nJob-shop scheduling problem (JSSP). However, the design of effective PDRs is a\ntedious task, requiring a myriad of specialized knowledge and often delivering\nlimited performance. In this paper, we propose to automatically learn PDRs via\nan end-to-end deep reinforcement learning agent. We exploit the disjunctive\ngraph representation of JSSP, and propose a Graph Neural Network based scheme\nto embed the states encountered during solving. The resulting policy network is\nsize-agnostic, effectively enabling generalization on large-scale instances.\nExperiments show that the agent can learn high-quality PDRs from scratch with\nelementary raw features, and demonstrates strong performance against the best\nexisting PDRs. The learned policies also perform well on much larger instances\nthat are unseen in training.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 12:53:36 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Zhang", "Cong", ""], ["Song", "Wen", ""], ["Cao", "Zhiguang", ""], ["Zhang", "Jie", ""], ["Tan", "Puay Siew", ""], ["Xu", "Chi", ""]]}, {"id": "2010.12512", "submitter": "Linyi Yang", "authors": "Linyi Yang, Eoin M. Kenny, Tin Lok James Ng, Yi Yang, Barry Smyth, and\n  Ruihai Dong", "title": "Generating Plausible Counterfactual Explanations for Deep Transformers\n  in Financial Text Classification", "comments": "Accepted by COLING-20 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Corporate mergers and acquisitions (M&A) account for billions of dollars of\ninvestment globally every year, and offer an interesting and challenging domain\nfor artificial intelligence. However, in these highly sensitive domains, it is\ncrucial to not only have a highly robust and accurate model, but be able to\ngenerate useful explanations to garner a user's trust in the automated system.\nRegrettably, the recent research regarding eXplainable AI (XAI) in financial\ntext classification has received little to no attention, and many current\nmethods for generating textual-based explanations result in highly implausible\nexplanations, which damage a user's trust in the system. To address these\nissues, this paper proposes a novel methodology for producing plausible\ncounterfactual explanations, whilst exploring the regularization benefits of\nadversarial training on language models in the domain of FinTech. Exhaustive\nquantitative experiments demonstrate that not only does this approach improve\nthe model accuracy when compared to the current state-of-the-art and human\nperformance, but it also generates counterfactual explanations which are\nsignificantly more plausible based on human trials.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 16:29:26 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Yang", "Linyi", ""], ["Kenny", "Eoin M.", ""], ["Ng", "Tin Lok James", ""], ["Yang", "Yi", ""], ["Smyth", "Barry", ""], ["Dong", "Ruihai", ""]]}, {"id": "2010.12536", "submitter": "Nasim Rahaman", "authors": "Yoshua Bengio, Prateek Gupta, Tegan Maharaj, Nasim Rahaman, Martin\n  Weiss, Tristan Deleu, Eilif Muller, Meng Qu, Victor Schmidt, Pierre-Luc\n  St-Charles, Hannah Alsdurf, Olexa Bilanuik, David Buckeridge, G\\'aetan\n  Marceau Caron, Pierre-Luc Carrier, Joumana Ghosn, Satya Ortiz-Gagne, Chris\n  Pal, Irina Rish, Bernhard Sch\\\"olkopf, Abhinav Sharma, Jian Tang, Andrew\n  Williams", "title": "Predicting Infectiousness for Proactive Contact Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has spread rapidly worldwide, overwhelming manual\ncontact tracing in many countries and resulting in widespread lockdowns for\nemergency containment. Large-scale digital contact tracing (DCT) has emerged as\na potential solution to resume economic and social activity while minimizing\nspread of the virus. Various DCT methods have been proposed, each making\ntrade-offs between privacy, mobility restrictions, and public health. The most\ncommon approach, binary contact tracing (BCT), models infection as a binary\nevent, informed only by an individual's test results, with corresponding binary\nrecommendations that either all or none of the individual's contacts\nquarantine. BCT ignores the inherent uncertainty in contacts and the infection\nprocess, which could be used to tailor messaging to high-risk individuals, and\nprompt proactive testing or earlier warnings. It also does not make use of\nobservations such as symptoms or pre-existing medical conditions, which could\nbe used to make more accurate infectiousness predictions. In this paper, we use\na recently-proposed COVID-19 epidemiological simulator to develop and test\nmethods that can be deployed to a smartphone to locally and proactively predict\nan individual's infectiousness (risk of infecting others) based on their\ncontact history and other information, while respecting strong privacy\nconstraints. Predictions are used to provide personalized recommendations to\nthe individual via an app, as well as to send anonymized messages to the\nindividual's contacts, who use this information to better predict their own\ninfectiousness, an approach we call proactive contact tracing (PCT). We find a\ndeep-learning based PCT method which improves over BCT for equivalent average\nmobility, suggesting PCT could help in safe re-opening and second-wave\nprevention.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 17:06:07 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Bengio", "Yoshua", ""], ["Gupta", "Prateek", ""], ["Maharaj", "Tegan", ""], ["Rahaman", "Nasim", ""], ["Weiss", "Martin", ""], ["Deleu", "Tristan", ""], ["Muller", "Eilif", ""], ["Qu", "Meng", ""], ["Schmidt", "Victor", ""], ["St-Charles", "Pierre-Luc", ""], ["Alsdurf", "Hannah", ""], ["Bilanuik", "Olexa", ""], ["Buckeridge", "David", ""], ["Caron", "G\u00e1etan Marceau", ""], ["Carrier", "Pierre-Luc", ""], ["Ghosn", "Joumana", ""], ["Ortiz-Gagne", "Satya", ""], ["Pal", "Chris", ""], ["Rish", "Irina", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Sharma", "Abhinav", ""], ["Tang", "Jian", ""], ["Williams", "Andrew", ""]]}, {"id": "2010.12537", "submitter": "Haoyu Dong", "authors": "Zhiruo Wang, Haoyu Dong, Ran Jia, Jia Li, Zhiyi Fu, Shi Han, Dongmei\n  Zhang", "title": "TUTA: Tree-based Transformers for Generally Structured Table\n  Pre-training", "comments": "KDD'21", "journal-ref": null, "doi": "10.1145/3447548.3467434", "report-no": null, "categories": "cs.IR cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tables are widely used with various structures to organize and present data.\nRecent attempts on table understanding mainly focus on relational tables, yet\noverlook to other common table structures. In this paper, we propose TUTA, a\nunified pre-training architecture for understanding generally structured\ntables. Noticing that understanding a table requires spatial, hierarchical, and\nsemantic information, we enhance transformers with three novel structure-aware\nmechanisms. First, we devise a unified tree-based structure, called a\nbi-dimensional coordinate tree, to describe both the spatial and hierarchical\ninformation of generally structured tables. Upon this, we propose tree-based\nattention and position embedding to better capture the spatial and hierarchical\ninformation. Moreover, we devise three progressive pre-training objectives to\nenable representations at the token, cell, and table levels. We pre-train TUTA\non a wide range of unlabeled web and spreadsheet tables and fine-tune it on two\ncritical tasks in the field of table structure understanding: cell type\nclassification and table type classification. Experiments show that TUTA is\nhighly effective, achieving state-of-the-art on five widely-studied datasets.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 13:22:31 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 06:56:14 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 13:20:11 GMT"}, {"version": "v4", "created": "Tue, 20 Jul 2021 01:18:05 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Wang", "Zhiruo", ""], ["Dong", "Haoyu", ""], ["Jia", "Ran", ""], ["Li", "Jia", ""], ["Fu", "Zhiyi", ""], ["Han", "Shi", ""], ["Zhang", "Dongmei", ""]]}, {"id": "2010.12539", "submitter": "Kunal Sawarkar", "authors": "Kunal Sawarkar, Sanket Jain", "title": "Dynamically Tie the Right Offer to the Right Customer in\n  Telecommunications Industry", "comments": "Published in 2011 RESEARCH COUNCIL JOURNAL, An Annual Publication\n  From The Direct Marketing Association Research Council-\n  https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwiitNPbyr7sAhXyct8KHfSpDsEQFjABegQIAxAC&url=https%3A%2F%2Fthedma.org%2Fwp-content%2Fuploads%2F2011-Analytics-Journal.pdf&usg=AOvVaw1XhGZBELMr3-_HAPhysVPp", "journal-ref": "Published in 2011 RESEARCH COUNCIL JOURNAL, An Annual Publication\n  From The Direct Marketing Association Research Council", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a successful business, engaging in an effective campaign is a key task\nfor marketers. Most previous studies used various mathematical models to\nsegment customers without considering the correlation between customer\nsegmentation and a campaign. This work presents a conceptual model by studying\nthe significant campaign-dependent variables of customer targeting in customer\nsegmentation context. In this way, the processes of customer segmentation and\ntargeting thus can be linked and solved together. The outcomes of customer\nsegmentation of this study could be more meaningful and relevant for marketers.\nThis investigation applies a customer life time value (LTV) model to assess the\nfitness between targeted customer groups and marketing strategies. To integrate\ncustomer segmentation and customer targeting, this work uses the genetic\nalgorithm (GA) to determine the optimized marketing strategy. Later, we suggest\nusing C&RT (Classification and Regression Tree) in SPSS PASW Modeler as the\nreplacement to Genetic Algorithm technique to accomplish these results. We also\nsuggest using LOSSYCOUNTING and Counting Bloom Filter to dynamically design the\nright and up-to-date offer to the right customer.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 16:44:51 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Sawarkar", "Kunal", ""], ["Jain", "Sanket", ""]]}, {"id": "2010.12598", "submitter": "Luis Rosero", "authors": "Luis Alberto Rosero, Iago Pacheco Gomes, J\\'unior Anderson Rodrigues\n  da Silva, Tiago Cesar dos Santos, Angelica Tiemi Mizuno Nakamura, Jean Amaro,\n  Denis Fernando Wolf and Fernando Santos Os\\'orio", "title": "A Software Architecture for Autonomous Vehicles: Team LRM-B Entry in the\n  First CARLA Autonomous Driving Challenge", "comments": "16 pages, 12 figures, preprint submitted to Journal of Systems\n  Architecture", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of the first CARLA autonomous driving challenge was to deploy\nautonomous driving systems to lead with complex traffic scenarios where all\nparticipants faced the same challenging traffic situations. According to the\norganizers, this competition emerges as a way to democratize and to accelerate\nthe research and development of autonomous vehicles around the world using the\nCARLA simulator contributing to the development of the autonomous vehicle area.\nTherefore, this paper presents the architecture design for the navigation of an\nautonomous vehicle in a simulated urban environment that attempts to commit the\nleast number of traffic infractions, which used as the baseline the original\narchitecture of the platform for autonomous navigation CaRINA 2. Our agent\ntraveled in simulated scenarios for several hours, demonstrating his\ncapabilities, winning three out of the four tracks of the challenge, and being\nranked second in the remaining track.\n  Our architecture was made towards meeting the requirements of CARLA\nAutonomous Driving Challenge and has components for obstacle detection using 3D\npoint clouds, traffic signs detection and classification which employs\nConvolutional Neural Networks (CNN) and depth information, risk assessment with\ncollision detection using short-term motion prediction, decision-making with\nMarkov Decision Process (MDP), and control using Model Predictive Control\n(MPC).\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 18:07:48 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Rosero", "Luis Alberto", ""], ["Gomes", "Iago Pacheco", ""], ["da Silva", "J\u00fanior Anderson Rodrigues", ""], ["Santos", "Tiago Cesar dos", ""], ["Nakamura", "Angelica Tiemi Mizuno", ""], ["Amaro", "Jean", ""], ["Wolf", "Denis Fernando", ""], ["Os\u00f3rio", "Fernando Santos", ""]]}, {"id": "2010.12606", "submitter": "Roland Zimmermann", "authors": "Judy Borowski, Roland S. Zimmermann, Judith Schepers, Robert Geirhos,\n  Thomas S. A. Wallis, Matthias Bethge, Wieland Brendel", "title": "Exemplary Natural Images Explain CNN Activations Better than\n  State-of-the-Art Feature Visualization", "comments": "Published at ICLR 2021. Joint first and last authors. Code is\n  available at https://bethgelab.github.io/testing_visualizations/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature visualizations such as synthetic maximally activating images are a\nwidely used explanation method to better understand the information processing\nof convolutional neural networks (CNNs). At the same time, there are concerns\nthat these visualizations might not accurately represent CNNs' inner workings.\nHere, we measure how much extremely activating images help humans to predict\nCNN activations. Using a well-controlled psychophysical paradigm, we compare\nthe informativeness of synthetic images by Olah et al. (2017) with a simple\nbaseline visualization, namely exemplary natural images that also strongly\nactivate a specific feature map. Given either synthetic or natural reference\nimages, human participants choose which of two query images leads to strong\npositive activation. The experiments are designed to maximize participants'\nperformance, and are the first to probe intermediate instead of final layer\nrepresentations. We find that synthetic images indeed provide helpful\ninformation about feature map activations ($82\\pm4\\%$ accuracy; chance would be\n$50\\%$). However, natural images - originally intended as a baseline -\noutperform synthetic images by a wide margin ($92\\pm2\\%$). Additionally,\nparticipants are faster and more confident for natural images, whereas\nsubjective impressions about the interpretability of the feature visualizations\nare mixed. The higher informativeness of natural images holds across most\nlayers, for both expert and lay participants as well as for hand- and\nrandomly-picked feature visualizations. Even if only a single reference image\nis given, synthetic images provide less information than natural images\n($65\\pm5\\%$ vs. $73\\pm4\\%$). In summary, synthetic images from a popular\nfeature visualization method are significantly less informative for assessing\nCNN activations than natural images. We argue that visualization methods should\nimprove over this baseline.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 18:31:13 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 10:00:47 GMT"}, {"version": "v3", "created": "Sun, 2 May 2021 19:27:06 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Borowski", "Judy", ""], ["Zimmermann", "Roland S.", ""], ["Schepers", "Judith", ""], ["Geirhos", "Robert", ""], ["Wallis", "Thomas S. A.", ""], ["Bethge", "Matthias", ""], ["Brendel", "Wieland", ""]]}, {"id": "2010.12619", "submitter": "Alexander Rader", "authors": "Alexander Philipp Rader, Ionela G. Mocanu, Vaishak Belle and Brendan\n  Juba", "title": "Learning Implicitly with Noisy Data in Linear Arithmetic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustly learning in expressive languages with real-world data continues to\nbe a challenging task. Numerous conventional methods appeal to heuristics\nwithout any assurances of robustness. While PAC-Semantics offers strong\nguarantees, learning explicit representations is not tractable even in a\npropositional setting. However, recent work on so-called \"implicit\" learning\nhas shown tremendous promise in terms of obtaining polynomial-time results for\nfragments of first-order logic. In this work, we extend implicit learning in\nPAC-Semantics to handle noisy data in the form of intervals and threshold\nuncertainty in the language of linear arithmetic. We prove that our extended\nframework keeps the existing polynomial-time complexity guarantees.\nFurthermore, we provide the first empirical investigation of this hitherto\npurely theoretical framework. Using benchmark problems, we show that our\nimplicit approach to learning optimal linear programming objective constraints\nsignificantly outperforms an explicit approach in practice.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 19:08:46 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Rader", "Alexander Philipp", ""], ["Mocanu", "Ionela G.", ""], ["Belle", "Vaishak", ""], ["Juba", "Brendan", ""]]}, {"id": "2010.12623", "submitter": "Liangming Pan", "authors": "Liangming Pan, Wenhu Chen, Wenhan Xiong, Min-Yen Kan, William Yang\n  Wang", "title": "Unsupervised Multi-hop Question Answering by Question Generation", "comments": "NAACL 2021 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Obtaining training data for multi-hop question answering (QA) is\ntime-consuming and resource-intensive. We explore the possibility to train a\nwell-performed multi-hop QA model without referencing any human-labeled\nmulti-hop question-answer pairs, i.e., unsupervised multi-hop QA. We propose\nMQA-QG, an unsupervised framework that can generate human-like multi-hop\ntraining data from both homogeneous and heterogeneous data sources. MQA-QG\ngenerates questions by first selecting/generating relevant information from\neach data source and then integrating the multiple information to form a\nmulti-hop question. Using only generated training data, we can train a\ncompetent multi-hop QA which achieves 61% and 83% of the supervised learning\nperformance for the HybridQA and the HotpotQA dataset, respectively. We also\nshow that pretraining the QA system with the generated data would greatly\nreduce the demand for human-annotated training data. Our codes are publicly\navailable at https://github.com/teacherpeterpan/Unsupervised-Multi-hop-QA.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 19:13:47 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 01:48:29 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Pan", "Liangming", ""], ["Chen", "Wenhu", ""], ["Xiong", "Wenhan", ""], ["Kan", "Min-Yen", ""], ["Wang", "William Yang", ""]]}, {"id": "2010.12639", "submitter": "Jesse Thomason", "authors": "Shurjo Banerjee, Jesse Thomason, Jason J. Corso", "title": "The RobotSlang Benchmark: Dialog-guided Robot Localization and\n  Navigation", "comments": "Conference on Robot Learning 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous robot systems for applications from search and rescue to assistive\nguidance should be able to engage in natural language dialog with people. To\nstudy such cooperative communication, we introduce Robot Simultaneous\nLocalization and Mapping with Natural Language (RobotSlang), a benchmark of 169\nnatural language dialogs between a human Driver controlling a robot and a human\nCommander providing guidance towards navigation goals. In each trial, the pair\nfirst cooperates to localize the robot on a global map visible to the\nCommander, then the Driver follows Commander instructions to move the robot to\na sequence of target objects. We introduce a Localization from Dialog History\n(LDH) and a Navigation from Dialog History (NDH) task where a learned agent is\ngiven dialog and visual observations from the robot platform as input and must\nlocalize in the global map or navigate towards the next target object,\nrespectively. RobotSlang is comprised of nearly 5k utterances and over 1k\nminutes of robot camera and control streams. We present an initial model for\nthe NDH task, and show that an agent trained in simulation can follow the\nRobotSlang dialog-based navigation instructions for controlling a physical\nrobot platform. Code and data are available at https://umrobotslang.github.io/.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 19:58:17 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Banerjee", "Shurjo", ""], ["Thomason", "Jesse", ""], ["Corso", "Jason J.", ""]]}, {"id": "2010.12645", "submitter": "Yash Chandak", "authors": "Yash Chandak, Scott M. Jordan, Georgios Theocharous, Martha White,\n  Philip S. Thomas", "title": "Towards Safe Policy Improvement for Non-Stationary MDPs", "comments": "Thirty-fourth Conference on Neural Information Processing Systems\n  (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world sequential decision-making problems involve critical systems\nwith financial risks and human-life risks. While several works in the past have\nproposed methods that are safe for deployment, they assume that the underlying\nproblem is stationary. However, many real-world problems of interest exhibit\nnon-stationarity, and when stakes are high, the cost associated with a false\nstationarity assumption may be unacceptable. We take the first steps towards\nensuring safety, with high confidence, for smoothly-varying non-stationary\ndecision problems. Our proposed method extends a type of safe algorithm, called\na Seldonian algorithm, through a synthesis of model-free reinforcement learning\nwith time-series analysis. Safety is ensured using sequential hypothesis\ntesting of a policy's forecasted performance, and confidence intervals are\nobtained using wild bootstrap.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 20:13:51 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 20:26:20 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Chandak", "Yash", ""], ["Jordan", "Scott M.", ""], ["Theocharous", "Georgios", ""], ["White", "Martha", ""], ["Thomas", "Philip S.", ""]]}, {"id": "2010.12678", "submitter": "Baihong Jin", "authors": "Jieyi Lu and Baihong Jin", "title": "Super-Resolution Reconstruction of Interval Energy Data", "comments": "Accepted as a poster abstract by BuildSys'20", "journal-ref": null, "doi": "10.1145/3408308.3431115", "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-resolution data are desired in many data-driven applications; however,\nin many cases only data whose resolution is lower than expected are available\ndue to various reasons. It is then a challenge how to obtain as much useful\ninformation as possible from the low-resolution data. In this paper, we target\ninterval energy data collected by Advanced Metering Infrastructure (AMI), and\npropose a Super-Resolution Reconstruction (SRR) approach to upsample\nlow-resolution (hourly) interval data into higher-resolution (15-minute) data\nusing deep learning. Our preliminary results show that the proposed SRR\napproaches can achieve much improved performance compared to the baseline\nmodel.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 21:34:22 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Lu", "Jieyi", ""], ["Jin", "Baihong", ""]]}, {"id": "2010.12681", "submitter": "Armineh Nourbakhsh", "authors": "Natraj Raman, Armineh Nourbakhsh, Sameena Shah, Manuela Veloso", "title": "Robust Document Representations using Latent Topics and Metadata", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task specific fine-tuning of a pre-trained neural language model using a\ncustom softmax output layer is the de facto approach of late when dealing with\ndocument classification problems. This technique is not adequate when labeled\nexamples are not available at training time and when the metadata artifacts in\na document must be exploited. We address these challenges by generating\ndocument representations that capture both text and metadata artifacts in a\ntask agnostic manner. Instead of traditional auto-regressive or auto-encoding\nbased training, our novel self-supervised approach learns a soft-partition of\nthe input space when generating text embeddings. Specifically, we employ a\npre-learned topic model distribution as surrogate labels and construct a loss\nfunction based on KL divergence. Our solution also incorporates metadata\nexplicitly rather than just augmenting them with text. The generated document\nembeddings exhibit compositional characteristics and are directly used by\ndownstream classification tasks to create decision boundaries from a small\nnumber of labeled examples, thereby eschewing complicated recognition methods.\nWe demonstrate through extensive evaluation that our proposed cross-model\nfusion solution outperforms several competitive baselines on multiple datasets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 21:52:38 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Raman", "Natraj", ""], ["Nourbakhsh", "Armineh", ""], ["Shah", "Sameena", ""], ["Veloso", "Manuela", ""]]}, {"id": "2010.12683", "submitter": "Jyun-Yu Jiang", "authors": "Jyun-Yu Jiang, Chenyan Xiong, Chia-Jung Lee and Wei Wang", "title": "Long Document Ranking with Query-Directed Sparse Transformer", "comments": "Accepted by EMNLP 2020, 12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computing cost of transformer self-attention often necessitates breaking\nlong documents to fit in pretrained models in document ranking tasks. In this\npaper, we design Query-Directed Sparse attention that induces IR-axiomatic\nstructures in transformer self-attention. Our model, QDS-Transformer, enforces\nthe principle properties desired in ranking: local contextualization,\nhierarchical representation, and query-oriented proximity matching, while it\nalso enjoys efficiency from sparsity. Experiments on one fully supervised and\nthree few-shot TREC document ranking benchmarks demonstrate the consistent and\nrobust advantage of QDS-Transformer over previous approaches, as they either\nretrofit long documents into BERT or use sparse attention without emphasizing\nIR principles. We further quantify the computing complexity and demonstrates\nthat our sparse attention with TVM implementation is twice more efficient than\nthe fully-connected self-attention. All source codes, trained model, and\npredictions of this work are available at\nhttps://github.com/hallogameboy/QDS-Transformer.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 21:57:56 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Jiang", "Jyun-Yu", ""], ["Xiong", "Chenyan", ""], ["Lee", "Chia-Jung", ""], ["Wang", "Wei", ""]]}, {"id": "2010.12764", "submitter": "Rodolfo Corona", "authors": "Rodolfo Corona, Daniel Fried, Coline Devin, Dan Klein, Trevor Darrell", "title": "Modular Networks for Compositional Instruction Following", "comments": "Published in NAACL-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard architectures used in instruction following often struggle on novel\ncompositions of subgoals (e.g. navigating to landmarks or picking up objects)\nobserved during training. We propose a modular architecture for following\nnatural language instructions that describe sequences of diverse subgoals. In\nour approach, subgoal modules each carry out natural language instructions for\na specific subgoal type. A sequence of modules to execute is chosen by learning\nto segment the instructions and predicting a subgoal type for each segment.\nWhen compared to standard, non-modular sequence-to-sequence approaches on\nALFRED, a challenging instruction following benchmark, we find that\nmodularization improves generalization to novel subgoal compositions, as well\nas to environments unseen in training.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 03:48:45 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 05:34:01 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Corona", "Rodolfo", ""], ["Fried", "Daniel", ""], ["Devin", "Coline", ""], ["Klein", "Dan", ""], ["Darrell", "Trevor", ""]]}, {"id": "2010.12773", "submitter": "Xiang Deng", "authors": "Xiang Deng, Ahmed Hassan Awadallah, Christopher Meek, Oleksandr\n  Polozov, Huan Sun, Matthew Richardson", "title": "Structure-Grounded Pretraining for Text-to-SQL", "comments": "Accepted to NAACL 2021. Please contact the first author for questions\n  regarding the spider-realistic dataset", "journal-ref": null, "doi": "10.18653/v1/2021.naacl-main.105", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to capture text-table alignment is essential for tasks like\ntext-to-SQL. A model needs to correctly recognize natural language references\nto columns and values and to ground them in the given database schema. In this\npaper, we present a novel weakly supervised Structure-Grounded pretraining\nframework (StruG) for text-to-SQL that can effectively learn to capture\ntext-table alignment based on a parallel text-table corpus. We identify a set\nof novel prediction tasks: column grounding, value grounding and column-value\nmapping, and leverage them to pretrain a text-table encoder. Additionally, to\nevaluate different methods under more realistic text-table alignment settings,\nwe create a new evaluation set Spider-Realistic based on Spider dev set with\nexplicit mentions of column names removed, and adopt eight existing text-to-SQL\ndatasets for cross-database evaluation. STRUG brings significant improvement\nover BERT-LARGE in all settings. Compared with existing pretraining methods\nsuch as GRAPPA, STRUG achieves similar performance on Spider, and outperforms\nall baselines on more realistic sets. All the code and data used in this work\nis public available at https://aka.ms/strug.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 04:35:35 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 21:12:39 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Deng", "Xiang", ""], ["Awadallah", "Ahmed Hassan", ""], ["Meek", "Christopher", ""], ["Polozov", "Oleksandr", ""], ["Sun", "Huan", ""], ["Richardson", "Matthew", ""]]}, {"id": "2010.12780", "submitter": "Yan Zeng", "authors": "Yan Zeng and Jian-Yun Nie", "title": "Open-Domain Dialogue Generation Based on Pre-trained Language Models", "comments": "[v0], 10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models have been successfully used in response\ngeneration for open-domain dialogue. Four main frameworks have been proposed:\n(1) Transformer-ED using Transformer encoder and decoder separately for source\nand target sentences; (2) Transformer-Dec using Transformer decoder for both\nsource and target sentences; (3) Transformer-MLM using Transformer decoder that\napplies bi-directional attention on the source side and left-to-right attention\non the target side with masked language model objective; and (4) Transformer-AR\nthat uses auto-regressive objective instead. In this study, we compare these\nframeworks on 3 datasets, and our comparison reveals that the best framework\nuses bidirectional attention on the source side and does not separate encoder\nand decoder. We also examine model discrepancy, and our experiments confirm\nthat the performance of a model is directly impacted by the underlying\ndiscrepancies. We then propose two correction methods to reduce the\ndiscrepancies, and both improve the model performance. These results show that\ndiscrepancies is an important factor to consider when we use a pre-trained\nmodel, and a reduction in discrepancies can lead to improved performance.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 04:52:28 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Zeng", "Yan", ""], ["Nie", "Jian-Yun", ""]]}, {"id": "2010.12828", "submitter": "Haoyu Zhang", "authors": "Haoyu Zhang, Dingkun Long, Guangwei Xu, Pengjun Xie, Fei Huang, Ji\n  Wang", "title": "Keyphrase Extraction with Dynamic Graph Convolutional Networks and\n  Diversified Inference", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyphrase extraction (KE) aims to summarize a set of phrases that accurately\nexpress a concept or a topic covered in a given document. Recently,\nSequence-to-Sequence (Seq2Seq) based generative framework is widely used in KE\ntask, and it has obtained competitive performance on various benchmarks. The\nmain challenges of Seq2Seq methods lie in acquiring informative latent document\nrepresentation and better modeling the compositionality of the target\nkeyphrases set, which will directly affect the quality of generated keyphrases.\nIn this paper, we propose to adopt the Dynamic Graph Convolutional Networks\n(DGCN) to solve the above two problems simultaneously. Concretely, we explore\nto integrate dependency trees with GCN for latent representation learning.\nMoreover, the graph structure in our model is dynamically modified during the\nlearning process according to the generated keyphrases. To this end, our\napproach is able to explicitly learn the relations within the keyphrases\ncollection and guarantee the information interchange between encoder and\ndecoder in both directions. Extensive experiments on various KE benchmark\ndatasets demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 08:11:23 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Zhang", "Haoyu", ""], ["Long", "Dingkun", ""], ["Xu", "Guangwei", ""], ["Xie", "Pengjun", ""], ["Huang", "Fei", ""], ["Wang", "Ji", ""]]}, {"id": "2010.12844", "submitter": "Sahisnu Mazumder", "authors": "Sahisnu Mazumder, Oriana Riva", "title": "FLIN: A Flexible Natural Language Interface for Web Navigation", "comments": "Accepted to NAACL-HLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI assistants can now carry out tasks for users by directly interacting with\nwebsite UIs. Current semantic parsing and slot-filling techniques cannot\nflexibly adapt to many different websites without being constantly re-trained.\nWe propose FLIN, a natural language interface for web navigation that maps user\ncommands to concept-level actions (rather than low-level UI actions), thus\nbeing able to flexibly adapt to different websites and handle their transient\nnature. We frame this as a ranking problem: given a user command and a webpage,\nFLIN learns to score the most relevant navigation instruction (involving action\nand parameter values). To train and evaluate FLIN, we collect a dataset using\nnine popular websites from three domains. Our results show that FLIN was able\nto adapt to new websites in a given domain.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 09:11:26 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 23:39:18 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Mazumder", "Sahisnu", ""], ["Riva", "Oriana", ""]]}, {"id": "2010.12848", "submitter": "Neil Walton", "authors": "Neil Walton", "title": "An Adiabatic Theorem for Policy Tracking with TD-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate the ability of temporal difference learning to track the reward\nfunction of a policy as it changes over time. Our results apply a new adiabatic\ntheorem that bounds the mixing time of time-inhomogeneous Markov chains. We\nderive finite-time bounds for tabular temporal difference learning and\n$Q$-learning when the policy used for training changes in time. To achieve\nthis, we develop bounds for stochastic approximation under asynchronous\nadiabatic updates.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 09:34:53 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 20:03:20 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Walton", "Neil", ""]]}, {"id": "2010.12852", "submitter": "Radhika Dua", "authors": "Radhika Dua, Sai Srinivas Kancheti and Vineeth N Balasubramanian", "title": "Beyond VQA: Generating Multi-word Answer and Rationale to Visual\n  Questions", "comments": "MULA Workshop, CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Visual Question Answering is a multi-modal task that aims to measure\nhigh-level visual understanding. Contemporary VQA models are restrictive in the\nsense that answers are obtained via classification over a limited vocabulary\n(in the case of open-ended VQA), or via classification over a set of\nmultiple-choice-type answers. In this work, we present a completely generative\nformulation where a multi-word answer is generated for a visual query. To take\nthis a step forward, we introduce a new task: ViQAR (Visual Question Answering\nand Reasoning), wherein a model must generate the complete answer and a\nrationale that seeks to justify the generated answer. We propose an end-to-end\narchitecture to solve this task and describe how to evaluate it. We show that\nour model generates strong answers and rationales through qualitative and\nquantitative evaluation, as well as through a human Turing Test.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 09:44:50 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 09:44:12 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Dua", "Radhika", ""], ["Kancheti", "Sai Srinivas", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "2010.12854", "submitter": "Tushar Khot", "authors": "Shih-Ting Lin and Ashish Sabharwal and Tushar Khot", "title": "ReadOnce Transformers: Reusable Representations of Text for Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While large-scale language models are extremely effective when directly\nfine-tuned on many end-tasks, such models learn to extract information and\nsolve the task simultaneously from end-task supervision. This is wasteful, as\nthe general problem of gathering information from a document is mostly\ntask-independent and need not be re-learned from scratch each time. Moreover,\nonce the information has been captured in a computable representation, it can\nnow be re-used across examples, leading to faster training and evaluation of\nmodels. We present a transformer-based approach, ReadOnce Transformers, that is\ntrained to build such information-capturing representations of text. Our model\ncompresses the document into a variable-length task-independent representation\nthat can now be re-used in different examples and tasks, thereby requiring a\ndocument to only be read once. Additionally, we extend standard text-to-text\nmodels to consume our ReadOnce Representations along with text to solve\nmultiple downstream tasks. We show our task-independent representations can be\nused for multi-hop QA, abstractive QA, and summarization. We observe 2x-5x\nspeedups compared to standard text-to-text models, while also being able to\nhandle long documents that would normally exceed the length limit of current\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 09:53:16 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Lin", "Shih-Ting", ""], ["Sabharwal", "Ashish", ""], ["Khot", "Tushar", ""]]}, {"id": "2010.12869", "submitter": "Farhad Merchant", "authors": "Suresh Nambi, Salim Ullah, Aditya Lohana, Siva Satyendra Sahoo, Farhad\n  Merchant, Akash Kumar", "title": "ExPAN(N)D: Exploring Posits for Efficient Artificial Neural Network\n  Design in FPGA-based Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.ET cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in machine learning, in general, and Artificial Neural\nNetworks (ANN), in particular, has made smart embedded systems an attractive\noption for a larger number of application areas. However, the high\ncomputational complexity, memory footprints, and energy requirements of machine\nlearning models hinder their deployment on resource-constrained embedded\nsystems. Most state-of-the-art works have considered this problem by proposing\nvarious low bit-width data representation schemes, optimized arithmetic\noperators' implementations, and different complexity reduction techniques such\nas network pruning. To further elevate the implementation gains offered by\nthese individual techniques, there is a need to cross-examine and combine these\ntechniques' unique features. This paper presents ExPAN(N)D, a framework to\nanalyze and ingather the efficacy of the Posit number representation scheme and\nthe efficiency of fixed-point arithmetic implementations for ANNs. The Posit\nscheme offers a better dynamic range and higher precision for various\napplications than IEEE $754$ single-precision floating-point format. However,\ndue to the dynamic nature of the various fields of the Posit scheme, the\ncorresponding arithmetic circuits have higher critical path delay and resource\nrequirements than the single-precision-based arithmetic units. Towards this\nend, we propose a novel Posit to fixed-point converter for enabling\nhigh-performance and energy-efficient hardware implementations for ANNs with\nminimal drop in the output accuracy. We also propose a modified Posit-based\nrepresentation to store the trained parameters of a network. Compared to an\n$8$-bit fixed-point-based inference accelerator, our proposed implementation\noffers $\\approx46\\%$ and $\\approx18\\%$ reductions in the storage requirements\nof the parameters and energy consumption of the MAC units, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 11:02:25 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 05:28:28 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Nambi", "Suresh", ""], ["Ullah", "Salim", ""], ["Lohana", "Aditya", ""], ["Sahoo", "Siva Satyendra", ""], ["Merchant", "Farhad", ""], ["Kumar", "Akash", ""]]}, {"id": "2010.12871", "submitter": "Zein Shaheen", "authors": "Zein Shaheen, Gerhard Wohlgenannt, Erwin Filtz", "title": "Large Scale Legal Text Classification Using Transformer Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large multi-label text classification is a challenging Natural Language\nProcessing (NLP) problem that is concerned with text classification for\ndatasets with thousands of labels. We tackle this problem in the legal domain,\nwhere datasets, such as JRC-Acquis and EURLEX57K labeled with the EuroVoc\nvocabulary were created within the legal information systems of the European\nUnion. The EuroVoc taxonomy includes around 7000 concepts. In this work, we\nstudy the performance of various recent transformer-based models in combination\nwith strategies such as generative pretraining, gradual unfreezing and\ndiscriminative learning rates in order to reach competitive classification\nperformance, and present new state-of-the-art results of 0.661 (F1) for\nJRC-Acquis and 0.754 for EURLEX57K. Furthermore, we quantify the impact of\nindividual steps, such as language model fine-tuning or gradual unfreezing in\nan ablation study, and provide reference dataset splits created with an\niterative stratification algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 11:03:01 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Shaheen", "Zein", ""], ["Wohlgenannt", "Gerhard", ""], ["Filtz", "Erwin", ""]]}, {"id": "2010.12872", "submitter": "Aaron Chan", "authors": "Mrigank Raman, Aaron Chan, Siddhant Agarwal, Peifeng Wang, Hansen\n  Wang, Sungchul Kim, Ryan Rossi, Handong Zhao, Nedim Lipka, Xiang Ren", "title": "Learning to Deceive Knowledge Graph Augmented Models via Targeted\n  Perturbation", "comments": "13 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs (KGs) have helped neural models improve performance on\nvarious knowledge-intensive tasks, like question answering and item\nrecommendation. By using attention over the KG, such KG-augmented models can\nalso \"explain\" which KG information was most relevant for making a given\nprediction. In this paper, we question whether these models are really behaving\nas we expect. We show that, through a reinforcement learning policy (or even\nsimple heuristics), one can produce deceptively perturbed KGs, which maintain\nthe downstream performance of the original KG while significantly deviating\nfrom the original KG's semantics and structure. Our findings raise doubts about\nKG-augmented models' ability to reason about KG information and give sensible\nexplanations.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 11:04:45 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 21:56:00 GMT"}, {"version": "v3", "created": "Sat, 2 Jan 2021 10:43:59 GMT"}, {"version": "v4", "created": "Thu, 21 Jan 2021 07:40:13 GMT"}, {"version": "v5", "created": "Thu, 18 Mar 2021 05:50:57 GMT"}, {"version": "v6", "created": "Mon, 3 May 2021 18:38:15 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Raman", "Mrigank", ""], ["Chan", "Aaron", ""], ["Agarwal", "Siddhant", ""], ["Wang", "Peifeng", ""], ["Wang", "Hansen", ""], ["Kim", "Sungchul", ""], ["Rossi", "Ryan", ""], ["Zhao", "Handong", ""], ["Lipka", "Nedim", ""], ["Ren", "Xiang", ""]]}, {"id": "2010.12878", "submitter": "Benedek Rozemberczki", "authors": "Benedek Rozemberczki, Peter Englert, Amol Kapoor, Martin Blais, Bryan\n  Perozzi", "title": "Pathfinder Discovery Networks for Neural Message Passing", "comments": "Code is available here: https://github.com/benedekrozemberczki/PDN/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we propose Pathfinder Discovery Networks (PDNs), a method for\njointly learning a message passing graph over a multiplex network with a\ndownstream semi-supervised model. PDNs inductively learn an aggregated weight\nfor each edge, optimized to produce the best outcome for the downstream\nlearning task. PDNs are a generalization of attention mechanisms on graphs\nwhich allow flexible construction of similarity functions between nodes, edge\nconvolutions, and cheap multiscale mixing layers. We show that PDNs overcome\nweaknesses of existing methods for graph attention (e.g. Graph Attention\nNetworks), such as the diminishing weight problem. Our experimental results\ndemonstrate competitive predictive performance on academic node classification\ntasks. Additional results from a challenging suite of node classification\nexperiments show how PDNs can learn a wider class of functions than existing\nbaselines. We analyze the relative computational complexity of PDNs, and show\nthat PDN runtime is not considerably higher than static-graph models. Finally,\nwe discuss how PDNs can be used to construct an easily interpretable attention\nmechanism that allows users to understand information propagation in the graph.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 11:28:57 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 22:45:42 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Rozemberczki", "Benedek", ""], ["Englert", "Peter", ""], ["Kapoor", "Amol", ""], ["Blais", "Martin", ""], ["Perozzi", "Bryan", ""]]}, {"id": "2010.12896", "submitter": "Loizos Michael", "authors": "Antonis Kakas, Loizos Michael", "title": "Abduction and Argumentation for Explainable Machine Learning: A Position\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Abduction and Argumentation as two principled forms for\nreasoning, and fleshes out the fundamental role that they can play within\nMachine Learning. It reviews the state-of-the-art work over the past few\ndecades on the link of these two reasoning forms with machine learning work,\nand from this it elaborates on how the explanation-generating role of Abduction\nand Argumentation makes them naturally-fitting mechanisms for the development\nof Explainable Machine Learning and AI systems. Abduction contributes towards\nthis goal by facilitating learning through the transformation, preparation, and\nhomogenization of data. Argumentation, as a conservative extension of classical\ndeductive reasoning, offers a flexible prediction and coverage mechanism for\nlearning -- an associated target language for learned knowledge -- that\nexplicitly acknowledges the need to deal, in the context of learning, with\nuncertain, incomplete and inconsistent data that are incompatible with any\nclassically-represented logical theory.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 13:23:44 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Kakas", "Antonis", ""], ["Michael", "Loizos", ""]]}, {"id": "2010.12908", "submitter": "Xiang Ling", "authors": "Xiang Ling, Lingfei Wu, Saizhuo Wang, Gaoning Pan, Tengfei Ma, Fangli\n  Xu, Alex X. Liu, Chunming Wu, Shouling Ji", "title": "Deep Graph Matching and Searching for Semantic Code Retrieval", "comments": "Accepted by ACM Transactions on Knowledge Discovery from Data (ACM\n  TKDD)", "journal-ref": "ACM Trans. Knowl. Discov. Data 15, 5 (2021), 1-21", "doi": "10.1145/3447571", "report-no": null, "categories": "cs.AI cs.IR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code retrieval is to find the code snippet from a large corpus of source code\nrepositories that highly matches the query of natural language description.\nRecent work mainly uses natural language processing techniques to process both\nquery texts (i.e., human natural language) and code snippets (i.e., machine\nprogramming language), however neglecting the deep structured features of query\ntexts and source codes, both of which contain rich semantic information. In\nthis paper, we propose an end-to-end deep graph matching and searching (DGMS)\nmodel based on graph neural networks for the task of semantic code retrieval.\nTo this end, we first represent both natural language query texts and\nprogramming language code snippets with the unified graph-structured data, and\nthen use the proposed graph matching and searching model to retrieve the best\nmatching code snippet. In particular, DGMS not only captures more structural\ninformation for individual query texts or code snippets but also learns the\nfine-grained similarity between them by cross-attention based semantic matching\noperations. We evaluate the proposed DGMS model on two public code retrieval\ndatasets with two representative programming languages (i.e., Java and Python).\nExperiment results demonstrate that DGMS significantly outperforms\nstate-of-the-art baseline models by a large margin on both datasets. Moreover,\nour extensive ablation studies systematically investigate and illustrate the\nimpact of each part of DGMS.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 14:16:50 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 16:38:09 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Ling", "Xiang", ""], ["Wu", "Lingfei", ""], ["Wang", "Saizhuo", ""], ["Pan", "Gaoning", ""], ["Ma", "Tengfei", ""], ["Xu", "Fangli", ""], ["Liu", "Alex X.", ""], ["Wu", "Chunming", ""], ["Ji", "Shouling", ""]]}, {"id": "2010.12914", "submitter": "Xiyao Wang", "authors": "Xiyao Wang, Junge Zhang, Wenzhen Huang, Qiyue Yin", "title": "Planning with Exploration: Addressing Dynamics Bottleneck in Model-based\n  Reinforcement Learning", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning (MBRL) is believed to have higher sample\nefficiency compared with model-free reinforcement learning (MFRL). However,\nMBRL is plagued by dynamics bottleneck dilemma. Dynamics bottleneck dilemma is\nthe phenomenon that the performance of the algorithm falls into the local\noptimum instead of increasing when the interaction step with the environment\nincreases, which means more data can not bring better performance. In this\npaper, we find that the trajectory reward estimation error is the main reason\nthat causes dynamics bottleneck dilemma through theoretical analysis. We give\nan upper bound of the trajectory reward estimation error and point out that\nincreasing the agent's exploration ability is the key to reduce trajectory\nreward estimation error, thereby alleviating dynamics bottleneck dilemma.\nMotivated by this, a model-based control method combined with exploration named\nMOdel-based Progressive Entropy-based Exploration (MOPE2) is proposed. We\nconduct experiments on several complex continuous control benchmark tasks. The\nresults verify that MOPE2 can effectively alleviate dynamics bottleneck dilemma\nand have higher sample efficiency than previous MBRL and MFRL algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 15:29:02 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 01:18:54 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 16:06:52 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Wang", "Xiyao", ""], ["Zhang", "Junge", ""], ["Huang", "Wenzhen", ""], ["Yin", "Qiyue", ""]]}, {"id": "2010.12917", "submitter": "Zan-Xia Jin", "authors": "Zan-Xia Jin, Heran Wu, Chun Yang, Fang Zhou, Jingyan Qin, Lei Xiao and\n  Xu-Cheng Yin", "title": "RUArt: A Novel Text-Centered Solution for Text-Based Visual Question\n  Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based visual question answering (VQA) requires to read and understand\ntext in an image to correctly answer a given question. However, most current\nmethods simply add optical character recognition (OCR) tokens extracted from\nthe image into the VQA model without considering contextual information of OCR\ntokens and mining the relationships between OCR tokens and scene objects. In\nthis paper, we propose a novel text-centered method called RUArt (Reading,\nUnderstanding and Answering the Related Text) for text-based VQA. Taking an\nimage and a question as input, RUArt first reads the image and obtains text and\nscene objects. Then, it understands the question, OCRed text and objects in the\ncontext of the scene, and further mines the relationships among them. Finally,\nit answers the related text for the given question through text semantic\nmatching and reasoning. We evaluate our RUArt on two text-based VQA benchmarks\n(ST-VQA and TextVQA) and conduct extensive ablation studies for exploring the\nreasons behind RUArt's effectiveness. Experimental results demonstrate that our\nmethod can effectively explore the contextual information of the text and mine\nthe stable relationships between the text and objects.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 15:37:09 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Jin", "Zan-Xia", ""], ["Wu", "Heran", ""], ["Yang", "Chun", ""], ["Zhou", "Fang", ""], ["Qin", "Jingyan", ""], ["Xiao", "Lei", ""], ["Yin", "Xu-Cheng", ""]]}, {"id": "2010.12919", "submitter": "Reid Pryzant", "authors": "Reid Pryzant, Dallas Card, Dan Jurafsky, Victor Veitch, Dhanya Sridhar", "title": "Causal Effects of Linguistic Properties", "comments": "To appear at NAACL 2021 (Annual Conference of the North American\n  Chapter of the Association for Computational Linguistics)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of using observational data to estimate the causal\neffects of linguistic properties. For example, does writing a complaint\npolitely lead to a faster response time? How much will a positive product\nreview increase sales? This paper addresses two technical challenges related to\nthe problem before developing a practical method. First, we formalize the\ncausal quantity of interest as the effect of a writer's intent, and establish\nthe assumptions necessary to identify this from observational data. Second, in\npractice, we only have access to noisy proxies for the linguistic properties of\ninterest -- e.g., predictions from classifiers and lexicons. We propose an\nestimator for this setting and prove that its bias is bounded when we perform\nan adjustment for the text. Based on these results, we introduce TextCause, an\nalgorithm for estimating causal effects of linguistic properties. The method\nleverages (1) distant supervision to improve the quality of noisy proxies, and\n(2) a pre-trained language model (BERT) to adjust for the text. We show that\nthe proposed method outperforms related approaches when estimating the effect\nof Amazon review sentiment on semi-simulated sales figures. Finally, we present\nan applied case study investigating the effects of complaint politeness on\nbureaucratic response times.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 15:43:37 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 14:30:35 GMT"}, {"version": "v3", "created": "Fri, 9 Apr 2021 17:01:13 GMT"}, {"version": "v4", "created": "Thu, 20 May 2021 20:10:34 GMT"}, {"version": "v5", "created": "Mon, 14 Jun 2021 14:10:05 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Pryzant", "Reid", ""], ["Card", "Dallas", ""], ["Jurafsky", "Dan", ""], ["Veitch", "Victor", ""], ["Sridhar", "Dhanya", ""]]}, {"id": "2010.12925", "submitter": "Camilo Thorne", "authors": "Dhruba Pujary and Camilo Thorne and Wilker Aziz", "title": "Disease Normalization with Graph Embeddings", "comments": "This is a pre-print of a paper to appear in the proceedings of the\n  IntelliSys 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The detection and normalization of diseases in biomedical texts are key\nbiomedical natural language processing tasks. Disease names need not only be\nidentified, but also normalized or linked to clinical taxonomies describing\ndiseases such as MeSH. In this paper we describe deep learning methods that\ntackle both tasks. We train and test our methods on the known NCBI disease\nbenchmark corpus. We propose to represent disease names by leveraging MeSH's\ngraphical structure together with the lexical information available in the\ntaxonomy using graph embeddings. We also show that combining neural named\nentity recognition models with our graph-based entity linking methods via\nmultitask learning leads to improved disease recognition in the NCBI corpus.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 16:25:05 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Pujary", "Dhruba", ""], ["Thorne", "Camilo", ""], ["Aziz", "Wilker", ""]]}, {"id": "2010.12949", "submitter": "Daniel McDuff", "authors": "Daniel McDuff, Javier Hernandez, Erroll Wood, Xin Liu, Tadas\n  Baltrusaitis", "title": "Advancing Non-Contact Vital Sign Measurement using Synthetic Avatars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-contact physiological measurement has the potential to provide low-cost,\nnon-invasive health monitoring. However, machine vision approaches are often\nlimited by the availability and diversity of annotated video datasets resulting\nin poor generalization to complex real-life conditions. To address these\nchallenges, this work proposes the use of synthetic avatars that display facial\nblood flow changes and allow for systematic generation of samples under a wide\nvariety of conditions. Our results show that training on both simulated and\nreal video data can lead to performance gains under challenging conditions. We\nshow state-of-the-art performance on three large benchmark datasets and\nimproved robustness to skin type and motion.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 18:31:57 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["McDuff", "Daniel", ""], ["Hernandez", "Javier", ""], ["Wood", "Erroll", ""], ["Liu", "Xin", ""], ["Baltrusaitis", "Tadas", ""]]}, {"id": "2010.12995", "submitter": "Mathieu Alain", "authors": "Yann Pequignot, Mathieu Alain, Patrick Dallaire, Alireza\n  Yeganehparast, Pascal Germain, Jos\\'ee Desharnais and Fran\\c{c}ois Laviolette", "title": "Implicit Variational Inference: the Parameter and the Predictor Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Having access to accurate confidence levels along with the predictions allows\nto determine whether making a decision is worth the risk. Under the Bayesian\nparadigm, the posterior distribution over parameters is used to capture model\nuncertainty, a valuable information that can be translated into predictive\nuncertainty. However, computing the posterior distribution for high capacity\npredictors, such as neural networks, is generally intractable, making\napproximate methods such as variational inference a promising alternative.\nWhile most methods perform inference in the space of parameters, we explore the\nbenefits of carrying inference directly in the space of predictors. Relying on\na family of distributions given by a deep generative neural network, we present\ntwo ways of carrying variational inference: one in \\emph{parameter space}, one\nin \\emph{predictor space}. Importantly, the latter requires us to choose a\ndistribution of inputs, therefore allowing us at the same time to explicitly\naddress the question of \\emph{out-of-distribution} uncertainty. We explore from\nvarious perspectives the implications of working in the predictor space induced\nby neural networks as opposed to the parameter space, focusing mainly on the\nquality of uncertainty estimation for data lying outside of the training\ndistribution. We compare posterior approximations obtained with these two\nmethods to several standard methods and present results showing that\nvariational approximations learned in the predictor space distinguish\nthemselves positively from those trained in the parameter space.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 21:41:21 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Pequignot", "Yann", ""], ["Alain", "Mathieu", ""], ["Dallaire", "Patrick", ""], ["Yeganehparast", "Alireza", ""], ["Germain", "Pascal", ""], ["Desharnais", "Jos\u00e9e", ""], ["Laviolette", "Fran\u00e7ois", ""]]}, {"id": "2010.13002", "submitter": "Sam Shleifer", "authors": "Sam Shleifer and Alexander M. Rush", "title": "Pre-trained Summarization Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent state-of-the-art approaches to summarization utilize large pre-trained\nTransformer models. Distilling these models to smaller student models has\nbecome critically important for practical use; however there are many different\ndistillation methods proposed by the NLP literature. Recent work on distilling\nBERT for classification and regression tasks shows strong performance using\ndirect knowledge distillation. Alternatively, machine translation practitioners\ndistill using pseudo-labeling, where a small model is trained on the\ntranslations of a larger model. A third, simpler approach is to 'shrink and\nfine-tune' (SFT), which avoids any explicit distillation by copying parameters\nto a smaller student model and then fine-tuning. We compare these three\napproaches for distillation of Pegasus and BART, the current and former state\nof the art, pre-trained summarization models, and find that SFT outperforms\nknowledge distillation and pseudo-labeling on the CNN/DailyMail dataset, but\nunder-performs pseudo-labeling on the more abstractive XSUM dataset. PyTorch\nCode and checkpoints of different sizes are available through Hugging Face\ntransformers here http://tiny.cc/4iy0tz.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 23:15:43 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 04:47:59 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Shleifer", "Sam", ""], ["Rush", "Alexander M.", ""]]}, {"id": "2010.13009", "submitter": "Jianguo Zhang", "authors": "Jian-Guo Zhang, Kazuma Hashimoto, Wenhao Liu, Chien-Sheng Wu, Yao Wan,\n  Philip S. Yu, Richard Socher, Caiming Xiong", "title": "Discriminative Nearest Neighbor Few-Shot Intent Detection by\n  Transferring Natural Language Inference", "comments": "19 pages, accepted by EMNLP 2020 main conference as a long paper.\n  Code will be available at https://github.com/salesforce/DNNC-few-shot-intent", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intent detection is one of the core components of goal-oriented dialog\nsystems, and detecting out-of-scope (OOS) intents is also a practically\nimportant skill. Few-shot learning is attracting much attention to mitigate\ndata scarcity, but OOS detection becomes even more challenging. In this paper,\nwe present a simple yet effective approach, discriminative nearest neighbor\nclassification with deep self-attention. Unlike softmax classifiers, we\nleverage BERT-style pairwise encoding to train a binary classifier that\nestimates the best matched training example for a user input. We propose to\nboost the discriminative ability by transferring a natural language inference\n(NLI) model. Our extensive experiments on a large-scale multi-domain intent\ndetection task show that our method achieves more stable and accurate in-domain\nand OOS detection accuracy than RoBERTa-based classifiers and embedding-based\nnearest neighbor approaches. More notably, the NLI transfer enables our 10-shot\nmodel to perform competitively with 50-shot or even full-shot classifiers,\nwhile we can keep the inference time constant by leveraging a faster embedding\nretrieval model.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 00:39:32 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Zhang", "Jian-Guo", ""], ["Hashimoto", "Kazuma", ""], ["Liu", "Wenhao", ""], ["Wu", "Chien-Sheng", ""], ["Wan", "Yao", ""], ["Yu", "Philip S.", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "2010.13028", "submitter": "Sayyed Zahiri", "authors": "Sayyed M. Zahiri and Ali Ahmadvand", "title": "CRAB: Class Representation Attentive BERT for Hate Speech Identification\n  in Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, social media platforms have hosted an explosion of hate\nspeech and objectionable content. The urgent need for effective automatic hate\nspeech detection models have drawn remarkable investment from companies and\nresearchers. Social media posts are generally short and their semantics could\ndrastically be altered by even a single token. Thus, it is crucial for this\ntask to learn context-aware input representations, and consider relevancy\nscores between input embeddings and class representations as an additional\nsignal. To accommodate these needs, this paper introduces CRAB (Class\nRepresentation Attentive BERT), a neural model for detecting hate speech in\nsocial media. The model benefits from two semantic representations: (i)\ntrainable token-wise and sentence-wise class representations, and (ii)\ncontextualized input embeddings from state-of-the-art BERT encoder. To\ninvestigate effectiveness of CRAB, we train our model on Twitter data and\ncompare it against strong baselines. Our results show that CRAB achieves 1.89%\nrelative improved Macro-averaged F1 over state-of-the-art baseline. The results\nof this research open an opportunity for the future research on automated\nabusive behavior detection in social media\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 04:11:30 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Zahiri", "Sayyed M.", ""], ["Ahmadvand", "Ali", ""]]}, {"id": "2010.13033", "submitter": "Tin Lai", "authors": "Tin Lai, Philippe Morere", "title": "Robust Hierarchical Planning with Policy Delegation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework and algorithm for hierarchical planning based on\nthe principle of delegation. This framework, the Markov Intent Process,\nfeatures a collection of skills which are each specialised to perform a single\ntask well. Skills are aware of their intended effects and are able to analyse\nplanning goals to delegate planning to the best-suited skill. This principle\ndynamically creates a hierarchy of plans, in which each skill plans for\nsub-goals for which it is specialised. The proposed planning method features\non-demand execution---skill policies are only evaluated when needed. Plans are\nonly generated at the highest level, then expanded and optimised when the\nlatest state information is available. The high-level plan retains the initial\nplanning intent and previously computed skills, effectively reducing the\ncomputation needed to adapt to environmental changes. We show this planning\napproach is experimentally very competitive to classic planning and\nreinforcement learning techniques on a variety of domains, both in terms of\nsolution length and planning time.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 04:36:20 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Lai", "Tin", ""], ["Morere", "Philippe", ""]]}, {"id": "2010.13054", "submitter": "Johan Boetker", "authors": "Johan P. Boetker", "title": "Applying convolutional neural networks to extremely sparse image\n  datasets using an image subdivision approach", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Purpose: The aim of this work is to demonstrate that convolutional neural\nnetworks (CNN) can be applied to extremely sparse image libraries by\nsubdivision of the original image datasets. Methods: Image datasets from a\nconventional digital camera was created and scanning electron microscopy (SEM)\nmeasurements were obtained from the literature. The image datasets were\nsubdivided and CNN models were trained on parts of the subdivided datasets.\nResults: The CNN models were capable of analyzing extremely sparse image\ndatasets by utilizing the proposed method of image subdivision. It was\nfurthermore possible to provide a direct assessment of the various regions\nwhere a given API or appearance was predominant.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 07:43:20 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Boetker", "Johan P.", ""]]}, {"id": "2010.13110", "submitter": "Jing Xu", "authors": "Jing Xu, Fangwei Zhong, Yizhou Wang", "title": "Learning Multi-Agent Coordination for Enhancing Target Coverage in\n  Directional Sensor Networks", "comments": "To appear in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum target coverage by adjusting the orientation of distributed sensors\nis an important problem in directional sensor networks (DSNs). This problem is\nchallenging as the targets usually move randomly but the coverage range of\nsensors is limited in angle and distance. Thus, it is required to coordinate\nsensors to get ideal target coverage with low power consumption, e.g. no\nmissing targets or reducing redundant coverage. To realize this, we propose a\nHierarchical Target-oriented Multi-Agent Coordination (HiT-MAC), which\ndecomposes the target coverage problem into two-level tasks: targets assignment\nby a coordinator and tracking assigned targets by executors. Specifically, the\ncoordinator periodically monitors the environment globally and allocates\ntargets to each executor. In turn, the executor only needs to track its\nassigned targets. To effectively learn the HiT-MAC by reinforcement learning,\nwe further introduce a bunch of practical methods, including a self-attention\nmodule, marginal contribution approximation for the coordinator,\ngoal-conditional observation filter for the executor, etc. Empirical results\ndemonstrate the advantage of HiT-MAC in coverage rate, learning efficiency,and\nscalability, comparing to baselines. We also conduct an ablative analysis on\nthe effectiveness of the introduced components in the framework.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 13:07:03 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Xu", "Jing", ""], ["Zhong", "Fangwei", ""], ["Wang", "Yizhou", ""]]}, {"id": "2010.13117", "submitter": "Danny Stoll", "authors": "Danny Stoll, J\\\"org K.H. Franke, Diane Wagner, Simon Selg, Frank\n  Hutter", "title": "Hyperparameter Transfer Across Developer Adjustments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After developer adjustments to a machine learning (ML) algorithm, how can the\nresults of an old hyperparameter optimization (HPO) automatically be used to\nspeedup a new HPO? This question poses a challenging problem, as developer\nadjustments can change which hyperparameter settings perform well, or even the\nhyperparameter search space itself. While many approaches exist that leverage\nknowledge obtained on previous tasks, so far, knowledge from previous\ndevelopment steps remains entirely untapped. In this work, we remedy this\nsituation and propose a new research framework: hyperparameter transfer across\nadjustments (HT-AA). To lay a solid foundation for this research framework, we\nprovide four simple HT-AA baseline algorithms and eight benchmarks changing\nvarious aspects of ML algorithms, their hyperparameter search spaces, and the\nneural architectures used. The best baseline, on average and depending on the\nbudgets for the old and new HPO, reaches a given performance 1.2--2.6x faster\nthan a prominent HPO algorithm without transfer. As HPO is a crucial step in ML\ndevelopment but requires extensive computational resources, this speedup would\nlead to faster development cycles, lower costs, and reduced environmental\nimpacts. To make these benefits available to ML developers off-the-shelf and to\nfacilitate future research on HT-AA, we provide python packages for our\nbaselines and benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 13:35:37 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Stoll", "Danny", ""], ["Franke", "J\u00f6rg K. H.", ""], ["Wagner", "Diane", ""], ["Selg", "Simon", ""], ["Hutter", "Frank", ""]]}, {"id": "2010.13121", "submitter": "Arthur Bit-Monnot", "authors": "Arthur Bit-Monnot, Malik Ghallab, F\\'elix Ingrand and David E. Smith", "title": "FAPE: a Constraint-based Planner for Generative and Hierarchical\n  Temporal Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal planning offers numerous advantages when based on an expressive\nrepresentation. Timelines have been known to provide the required\nexpressiveness but at the cost of search efficiency. We propose here a temporal\nplanner, called FAPE, which supports many of the expressive temporal features\nof the ANML modeling language without loosing efficiency.\n  FAPE's representation coherently integrates flexible timelines with\nhierarchical refinement methods that can provide efficient control knowledge. A\nnovel reachability analysis technique is proposed and used to develop causal\nnetworks to constrain the search space. It is employed for the design of\ninformed heuristics, inference methods and efficient search strategies.\nExperimental results on common benchmarks in the field permit to assess the\ncomponents and search strategies of FAPE, and to compare it to IPC planners.\nThe results show the proposed approach to be competitive with less expressive\nplanners and often superior when hierarchical control knowledge is provided.\nFAPE, a freely available system, provides other features, not covered here,\nsuch as the integration of planning with acting, and the handling of sensing\nactions in partially observable environments.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 13:46:34 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Bit-Monnot", "Arthur", ""], ["Ghallab", "Malik", ""], ["Ingrand", "F\u00e9lix", ""], ["Smith", "David E.", ""]]}, {"id": "2010.13128", "submitter": "Mokanarangan Thayaparan", "authors": "Mokanarangan Thayaparan, Marco Valentino, Andr\\'e Freitas", "title": "ExplanationLP: Abductive Reasoning for Explainable Science Question\n  Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for answering and explaining multiple-choice\nscience questions by reasoning on grounding and abstract inference chains. This\npaper frames question answering as an abductive reasoning problem, constructing\nplausible explanations for each choice and then selecting the candidate with\nthe best explanation as the final answer. Our system, ExplanationLP, elicits\nexplanations by constructing a weighted graph of relevant facts for each\ncandidate answer and extracting the facts that satisfy certain structural and\nsemantic constraints. To extract the explanations, we employ a linear\nprogramming formalism designed to select the optimal subgraph. The graphs'\nweighting function is composed of a set of parameters, which we fine-tune to\noptimize answer selection performance. We carry out our experiments on the\nWorldTree and ARC-Challenge corpus to empirically demonstrate the following\nconclusions: (1) Grounding-Abstract inference chains provides the semantic\ncontrol to perform explainable abductive reasoning (2) Efficiency and\nrobustness in learning with a fewer number of parameters by outperforming\ncontemporary explainable and transformer-based approaches in a similar setting\n(3) Generalisability by outperforming SOTA explainable approaches on general\nscience question sets.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 14:49:24 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Thayaparan", "Mokanarangan", ""], ["Valentino", "Marco", ""], ["Freitas", "Andr\u00e9", ""]]}, {"id": "2010.13130", "submitter": "Jingsong Wang", "authors": "Jingsong Wang, Tom Ko, Zhen Xu, Xiawei Guo, Souxiang Liu, Wei-Wei Tu,\n  Lei Xie", "title": "AutoSpeech 2020: The Second Automated Machine Learning Challenge for\n  Speech Classification", "comments": "5 pages, 2 figures, Details about AutoSpeech 2020 Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AutoSpeech challenge calls for automated machine learning (AutoML)\nsolutions to automate the process of applying machine learning to speech\nprocessing tasks. These tasks, which cover a large variety of domains, will be\nshown to the automated system in a random order. Each time when the tasks are\nswitched, the information of the new task will be hinted with its corresponding\ntraining set. Thus, every submitted solution should contain an adaptation\nroutine which adapts the system to the new task. Compared to the first edition,\nthe 2020 edition includes advances of 1) more speech tasks, 2) noisier data in\neach task, 3) a modified evaluation metric. This paper outlines the challenge\nand describe the competition protocol, datasets, evaluation metric, starting\nkit, and baseline systems.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 15:01:41 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Wang", "Jingsong", ""], ["Ko", "Tom", ""], ["Xu", "Zhen", ""], ["Guo", "Xiawei", ""], ["Liu", "Souxiang", ""], ["Tu", "Wei-Wei", ""], ["Xie", "Lei", ""]]}, {"id": "2010.13146", "submitter": "Andreea-Ioana Deac", "authors": "Andreea Deac, Petar Veli\\v{c}kovi\\'c, Ognjen Milinkovi\\'c, Pierre-Luc\n  Bacon, Jian Tang, Mladen Nikoli\\'c", "title": "XLVIN: eXecuted Latent Value Iteration Nets", "comments": "NeurIPS 2020 Deep Reinforcement Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value Iteration Networks (VINs) have emerged as a popular method to\nincorporate planning algorithms within deep reinforcement learning, enabling\nperformance improvements on tasks requiring long-range reasoning and\nunderstanding of environment dynamics. This came with several limitations,\nhowever: the model is not incentivised in any way to perform meaningful\nplanning computations, the underlying state space is assumed to be discrete,\nand the Markov decision process (MDP) is assumed fixed and known. We propose\neXecuted Latent Value Iteration Networks (XLVINs), which combine recent\ndevelopments across contrastive self-supervised learning, graph representation\nlearning and neural algorithmic reasoning to alleviate all of the above\nlimitations, successfully deploying VIN-style models on generic environments.\nXLVINs match the performance of VIN-like models when the underlying MDP is\ndiscrete, fixed and known, and provides significant improvements to model-free\nbaselines across three general MDP setups.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 16:04:30 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 16:59:01 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Deac", "Andreea", ""], ["Veli\u010dkovi\u0107", "Petar", ""], ["Milinkovi\u0107", "Ognjen", ""], ["Bacon", "Pierre-Luc", ""], ["Tang", "Jian", ""], ["Nikoli\u0107", "Mladen", ""]]}, {"id": "2010.13149", "submitter": "Nir Regev", "authors": "Nir Regev, Lior Rokach, Asaf Shabtai", "title": "Approximating Aggregated SQL Queries With LSTM Networks", "comments": "12 pages, 5 figures, ICDE2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite continuous investments in data technologies, the latency of querying\ndata still poses a significant challenge. Modern analytic solutions require\nnear real-time responsiveness both to make them interactive and to support\nautomated processing. Current technologies (Hadoop, Spark, Dataflow) scan the\ndataset to execute queries. They focus on providing a scalable data storage to\nmaximize task execution speed. We argue that these solutions fail to offer an\nadequate level of interactivity since they depend on continual access to data.\nIn this paper we present a method for query approximation, also known as\napproximate query processing (AQP), that reduce the need to scan data during\ninference (query calculation), thus enabling a rapid query processing tool. We\nuse LSTM network to learn the relationship between queries and their results,\nand to provide a rapid inference layer for predicting query results. Our method\n(referred as ``Hunch``) produces a lightweight LSTM network which provides a\nhigh query throughput. We evaluated our method using twelve datasets and\ncompared to state-of-the-art AQP engines (VerdictDB, BlinkDB) from query\nlatency, model weight and accuracy perspectives. The results show that our\nmethod predicted queries' results with a normalized root mean squared error\n(NRMSE) ranging from approximately 1\\% to 4\\% which in the majority of our data\nsets was better then the compared benchmarks. Moreover, our method was able to\npredict up to 120,000 queries in a second (streamed together), and with a\nsingle query latency of no more than 2ms.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 16:17:58 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 18:46:52 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 11:32:09 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Regev", "Nir", ""], ["Rokach", "Lior", ""], ["Shabtai", "Asaf", ""]]}, {"id": "2010.13160", "submitter": "Woojeong Kim", "authors": "Woojeong Kim, Suhyun Kim, Mincheol Park, Geonseok Jeon", "title": "Neuron Merging: Compensating for Pruned Neurons", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network pruning is widely used to lighten and accelerate neural network\nmodels. Structured network pruning discards the whole neuron or filter, leading\nto accuracy loss. In this work, we propose a novel concept of neuron merging\napplicable to both fully connected layers and convolution layers, which\ncompensates for the information loss due to the pruned neurons/filters. Neuron\nmerging starts with decomposing the original weights into two matrices/tensors.\nOne of them becomes the new weights for the current layer, and the other is\nwhat we name a scaling matrix, guiding the combination of neurons. If the\nactivation function is ReLU, the scaling matrix can be absorbed into the next\nlayer under certain conditions, compensating for the removed neurons. We also\npropose a data-free and inexpensive method to decompose the weights by\nutilizing the cosine similarity between neurons. Compared to the pruned model\nwith the same topology, our merged model better preserves the output feature\nmap of the original model; thus, it maintains the accuracy after pruning\nwithout fine-tuning. We demonstrate the effectiveness of our approach over\nnetwork pruning for various model architectures and datasets. As an example,\nfor VGG-16 on CIFAR-10, we achieve an accuracy of 93.16% while reducing 64% of\ntotal parameters, without any fine-tuning. The code can be found here:\nhttps://github.com/friendshipkim/neuron-merging\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 16:50:26 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Kim", "Woojeong", ""], ["Kim", "Suhyun", ""], ["Park", "Mincheol", ""], ["Jeon", "Geonseok", ""]]}, {"id": "2010.13166", "submitter": "Xin Wang", "authors": "Xin Wang, Yudong Chen and Wenwu Zhu", "title": "A Survey on Curriculum Learning", "comments": "20 pages, 7 figures, Accepted by IEEE Transactions on Pattern\n  Analysis and Machine Intelligence 2021 (TPAMI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curriculum learning (CL) is a training strategy that trains a machine\nlearning model from easier data to harder data, which imitates the meaningful\nlearning order in human curricula. As an easy-to-use plug-in, the CL strategy\nhas demonstrated its power in improving the generalization capacity and\nconvergence rate of various models in a wide range of scenarios such as\ncomputer vision and natural language processing etc. In this survey article, we\ncomprehensively review CL from various aspects including motivations,\ndefinitions, theories, and applications. We discuss works on curriculum\nlearning within a general CL framework, elaborating on how to design a manually\npredefined curriculum or an automatic curriculum. In particular, we summarize\nexisting CL designs based on the general framework of Difficulty\nMeasurer+Training Scheduler and further categorize the methodologies for\nautomatic CL into four groups, i.e., Self-paced Learning, Transfer Teacher, RL\nTeacher, and Other Automatic CL. We also analyze principles to select different\nCL designs that may benefit practical applications. Finally, we present our\ninsights on the relationships connecting CL and other machine learning concepts\nincluding transfer learning, meta-learning, continual learning and active\nlearning, etc., then point out challenges in CL as well as potential future\nresearch directions deserving further investigations.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 17:15:04 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 03:56:49 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Wang", "Xin", ""], ["Chen", "Yudong", ""], ["Zhu", "Wenwu", ""]]}, {"id": "2010.13266", "submitter": "Ramya Srinivasan", "authors": "Ramya Srinivasan, Kanji Uchino", "title": "Biases in Generative Art -- A Causal Look from the Lens of Art History", "comments": "ACM FAccT March 3--10, 2021, Virtual Event, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With rapid progress in artificial intelligence (AI), popularity of generative\nart has grown substantially. From creating paintings to generating novel art\nstyles, AI based generative art has showcased a variety of applications.\nHowever, there has been little focus concerning the ethical impacts of AI based\ngenerative art. In this work, we investigate biases in the generative art AI\npipeline right from those that can originate due to improper problem\nformulation to those related to algorithm design. Viewing from the lens of art\nhistory, we discuss the socio-cultural impacts of these biases. Leveraging\ncausal models, we highlight how current methods fall short in modeling the\nprocess of art creation and thus contribute to various types of biases. We\nillustrate the same through case studies, in particular those related to style\ntransfer. To the best of our knowledge, this is the first extensive analysis\nthat investigates biases in the generative art AI pipeline from the perspective\nof art history. We hope our work sparks interdisciplinary discussions related\nto accountability of generative art.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 00:49:09 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 19:01:11 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Srinivasan", "Ramya", ""], ["Uchino", "Kanji", ""]]}, {"id": "2010.13319", "submitter": "Ravi Tejwani", "authors": "Ravi Tejwani, Cynthia Breazeal", "title": "Migratable AI : Investigating users' affect on identity and information\n  migration of a conversational AI agent", "comments": "arXiv admin note: text overlap with arXiv:2007.05801", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational AI agents are becoming ubiquitous and provide assistance to us\nin our everyday activities. In recent years, researchers have explored the\nmigration of these agents across different embodiments in order to maintain the\ncontinuity of the task and improve user experience. In this paper, we\ninvestigate user's affective responses in different configurations of the\nmigration parameters. We present a 2x2 between-subjects study in a task-based\nscenario using information migration and identity migration as parameters. We\noutline the affect processing pipeline from the video footage collected during\nthe study and report user's responses in each condition. Our results show that\nusers reported highest joy and were most surprised when both the information\nand identity was migrated; and reported most anger when the information was\nmigrated without the identity of their agent.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 22:31:34 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Tejwani", "Ravi", ""], ["Breazeal", "Cynthia", ""]]}, {"id": "2010.13346", "submitter": "Sayed Amir Hoseini", "authors": "Sayed Amir Hoseini and Ayub Bokani and Jahan Hassan and Shavbo Salehi\n  and Salil S. Kanhere", "title": "Energy and Service-priority aware Trajectory Design for UAV-BSs using\n  Double Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next-generation mobile networks have proposed the integration of Unmanned\nAerial Vehicles (UAVs) as aerial base stations (UAV-BS) to serve ground nodes.\nDespite having advantages of using UAV-BSs, their dependence on the on-board,\nlimited-capacity battery hinders their service continuity. Shorter trajectories\ncan save flying energy, however, UAV-BSs must also serve nodes based on their\nservice priority since nodes' service requirements are not always the same. In\nthis paper, we present an energy-efficient trajectory optimization for a UAV\nassisted IoT system in which the UAV-BS considers the IoT nodes' service\npriorities in making its movement decisions. We solve the trajectory\noptimization problem using Double Q-Learning algorithm. Simulation results\nreveal that the Q-Learning based optimized trajectory outperforms a benchmark\nalgorithm, namely Greedily-served algorithm, in terms of reducing the average\nenergy consumption of the UAV-BS as well as the service delay for high priority\nnodes.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 05:21:30 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Hoseini", "Sayed Amir", ""], ["Bokani", "Ayub", ""], ["Hassan", "Jahan", ""], ["Salehi", "Shavbo", ""], ["Kanhere", "Salil S.", ""]]}, {"id": "2010.13380", "submitter": "Shuyue Guan", "authors": "Shuyue Guan, Murray Loew", "title": "The estimation of training accuracy for two-layer neural networks on\n  random datasets without training", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the neural network (NN) technique plays an important role in machine\nlearning, understanding the mechanism of NN models and the transparency of deep\nlearning still require more basic research. In this study we propose a novel\ntheory based on space partitioning to estimate the approximate training\naccuracy for two-layer neural networks on random datasets without training.\nThere appear to be no other studies that have proposed a method to estimate\ntraining accuracy without using input data or trained models. Our method\nestimates the training accuracy for two-layer fully-connected neural networks\non two-class random datasets using only three arguments: the dimensionality of\ninputs (d), the number of inputs (N), and the number of neurons in the hidden\nlayer (L). We have verified our method using real training accuracies in our\nexperiments. The results indicate that the method will work for any dimension,\nand the proposed theory could extend also to estimate deeper NN models. This\nstudy may provide a starting point for a new way for researchers to make\nprogress on the difficult problem of understanding deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 07:21:29 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Guan", "Shuyue", ""], ["Loew", "Murray", ""]]}, {"id": "2010.13482", "submitter": "Antal Jakovac", "authors": "A. Jakovac, D. Berenyi and P. Posfay", "title": "Understanding understanding: a renormalization group inspired model of\n  (artificial) intelligence", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG hep-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is about the meaning of understanding in scientific and in\nartificial intelligent systems. We give a mathematical definition of the\nunderstanding, where, contrary to the common wisdom, we define the probability\nspace on the input set, and we treat the transformation made by an intelligent\nactor not as a loss of information, but instead a reorganization of the\ninformation in the framework of a new coordinate system. We introduce,\nfollowing the ideas of physical renormalization group, the notions of relevant\nand irrelevant parameters, and discuss, how the different AI tasks can be\ninterpreted along these concepts, and how the process of learning can be\ndescribed. We show, how scientific understanding fits into this framework, and\ndemonstrate, what is the difference between a scientific task and pattern\nrecognition. We also introduce a measure of relevance, which is useful for\nperforming lossy compression.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 11:11:46 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Jakovac", "A.", ""], ["Berenyi", "D.", ""], ["Posfay", "P.", ""]]}, {"id": "2010.13494", "submitter": "Kenji Kobayashi", "authors": "Kenji Kobayashi, Yuri Nakao", "title": "One-vs.-One Mitigation of Intersectional Bias: A General Method to\n  Extend Fairness-Aware Binary Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread adoption of machine learning in the real world, the\nimpact of the discriminatory bias has attracted attention. In recent years,\nvarious methods to mitigate the bias have been proposed. However, most of them\nhave not considered intersectional bias, which brings unfair situations where\npeople belonging to specific subgroups of a protected group are treated worse\nwhen multiple sensitive attributes are taken into consideration. To mitigate\nthis bias, in this paper, we propose a method called One-vs.-One Mitigation by\napplying a process of comparison between each pair of subgroups related to\nsensitive attributes to the fairness-aware machine learning for binary\nclassification. We compare our method and the conventional fairness-aware\nbinary classification methods in comprehensive settings using three approaches\n(pre-processing, in-processing, and post-processing), six metrics (the ratio\nand difference of demographic parity, equalized odds, and equal opportunity),\nand two real-world datasets (Adult and COMPAS). As a result, our method\nmitigates the intersectional bias much better than conventional methods in all\nthe settings. With the result, we open up the potential of fairness-aware\nbinary classification for solving more realistic problems occurring when there\nare multiple sensitive attributes.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 11:35:39 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Kobayashi", "Kenji", ""], ["Nakao", "Yuri", ""]]}, {"id": "2010.13517", "submitter": "Azlan Iqbal", "authors": "Azlan Iqbal", "title": "A Novel Machine Learning Method for Preference Identification", "comments": "16 pages, 3 figure, 6 tables. Full version:\n  https://www.amazon.com/dp/B08P2RW9Q8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human preference or taste within any domain is usually a difficult thing to\nidentify or predict with high probability. In the domain of chess problem\ncomposition, the same is true. Traditional machine learning approaches tend to\nfocus on the ability of computers to process massive amounts of data and\ncontinuously adjust 'weights' within an artificial neural network to better\ndistinguish between say, two groups of objects. Contrasted with chess\ncompositions, there is no clear distinction between what constitutes one and\nwhat does not; even less so between a good one and a poor one. We propose a\ncomputational method that is able to learn from existing databases of 'liked'\nand 'disliked' compositions such that a new and unseen collection can be sorted\nwith increased probability of matching a solver's preferences. The method uses\na simple 'change factor' relating to the Forsyth-Edwards Notation (FEN) of each\ncomposition's starting position, coupled with repeated statistical analysis of\nsample pairs from both databases. Tested using the author's own collections of\ncomputer-generated chess problems, the experimental results showed that the\nmethod was able to sort a new and unseen collection of compositions such that,\non average, over 70% of the preferred compositions were in the top half of the\ncollection. This saves significant time and energy on the part of solvers as\nthey are likely to find more of what they like sooner. The method may even be\napplicable to other domains such as image processing because it does not rely\non any chess-specific rules but rather just a sufficient and quantifiable\n'change' in representation from one object to the next.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 07:43:37 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 00:22:47 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Iqbal", "Azlan", ""]]}, {"id": "2010.13583", "submitter": "Linlin Hou", "authors": "Linlin Hou, Ji Zhang, Ou Wu, Ting Yu, Zhen Wang, Zhao Li, Jianliang\n  Gao, Yingchun Ye, Rujing Yao", "title": "Method and Dataset Entity Mining in Scientific Literature: A CNN +\n  Bi-LSTM Model with Self-attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Literature analysis facilitates researchers to acquire a good understanding\nof the development of science and technology. The traditional literature\nanalysis focuses largely on the literature metadata such as topics, authors,\nabstracts, keywords, references, etc., and little attention was paid to the\nmain content of papers. In many scientific domains such as science, computing,\nengineering, etc., the methods and datasets involved in the scientific papers\npublished in those domains carry important information and are quite useful for\ndomain analysis as well as algorithm and dataset recommendation. In this paper,\nwe propose a novel entity recognition model, called MDER, which is able to\neffectively extract the method and dataset entities from the main textual\ncontent of scientific papers. The model utilizes rule embedding and adopts a\nparallel structure of CNN and Bi-LSTM with the self-attention mechanism. We\nevaluate the proposed model on datasets which are constructed from the\npublished papers of four research areas in computer science, i.e., NLP, CV,\nData Mining and AI. The experimental results demonstrate that our model\nperforms well in all the four areas and it features a good learning capacity\nfor cross-area learning and recognition. We also conduct experiments to\nevaluate the effectiveness of different building modules within our model which\nindicate that the importance of different building modules in collectively\ncontributing to the good entity recognition performance as a whole. The data\naugmentation experiments on our model demonstrated that data augmentation\npositively contributes to model training, making our model much more robust in\ndealing with the scenarios where only small number of training samples are\navailable. We finally apply our model on PAKDD papers published from 2009-2019\nto mine insightful results from scientific papers published in a longer time\nspan.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 13:38:43 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 02:33:37 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Hou", "Linlin", ""], ["Zhang", "Ji", ""], ["Wu", "Ou", ""], ["Yu", "Ting", ""], ["Wang", "Zhen", ""], ["Li", "Zhao", ""], ["Gao", "Jianliang", ""], ["Ye", "Yingchun", ""], ["Yao", "Rujing", ""]]}, {"id": "2010.13585", "submitter": "Reza Marzban", "authors": "Reza Marzban, Christopher John Crick", "title": "Interpreting convolutional networks trained on textual data", "comments": "9 pages, 6 figures, 5 tables", "journal-ref": null, "doi": "10.5220/0010205901960203", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been many advances in the artificial intelligence field due to the\nemergence of deep learning. In almost all sub-fields, artificial neural\nnetworks have reached or exceeded human-level performance. However, most of the\nmodels are not interpretable. As a result, it is hard to trust their decisions,\nespecially in life and death scenarios. In recent years, there has been a\nmovement toward creating explainable artificial intelligence, but most work to\ndate has concentrated on image processing models, as it is easier for humans to\nperceive visual patterns. There has been little work in other fields like\nnatural language processing. In this paper, we train a convolutional model on\ntextual data and analyze the global logic of the model by studying its filter\nvalues. In the end, we find the most important words in our corpus to our\nmodels logic and remove the rest (95%). New models trained on just the 5% most\nimportant words can achieve the same performance as the original model while\nreducing training time by more than half. Approaches such as this will help us\nto understand NLP models, explain their decisions according to their word\nchoices, and improve them by finding blind spots and biases.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 20:12:05 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Marzban", "Reza", ""], ["Crick", "Christopher John", ""]]}, {"id": "2010.13641", "submitter": "Timo Schick", "authors": "Timo Schick, Helmut Schmid, Hinrich Sch\\\"utze", "title": "Automatically Identifying Words That Can Serve as Labels for Few-Shot\n  Text Classification", "comments": "To appear at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent approach for few-shot text classification is to convert textual\ninputs to cloze questions that contain some form of task description, process\nthem with a pretrained language model and map the predicted words to labels.\nManually defining this mapping between words and labels requires both domain\nexpertise and an understanding of the language model's abilities. To mitigate\nthis issue, we devise an approach that automatically finds such a mapping given\nsmall amounts of training data. For a number of tasks, the mapping found by our\napproach performs almost as well as hand-crafted label-to-word mappings.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 14:56:22 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Schick", "Timo", ""], ["Schmid", "Helmut", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2010.13652", "submitter": "Thomas Winters", "authors": "Thomas Winters, Pieter Delobelle", "title": "Dutch Humor Detection by Generating Negative Examples", "comments": "Accepted at the Proceedings of the 32st Benelux Conference on\n  Artificial Intelligence (BNAIC 2020) and the 29th Belgian Dutch Conference on\n  Machine Learning (Benelearn 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting if a text is humorous is a hard task to do computationally, as it\nusually requires linguistic and common sense insights. In machine learning,\nhumor detection is usually modeled as a binary classification task, trained to\npredict if the given text is a joke or another type of text. Rather than using\ncompletely different non-humorous texts, we propose using text generation\nalgorithms for imitating the original joke dataset to increase the difficulty\nfor the learning algorithm. We constructed several different joke and non-joke\ndatasets to test the humor detection abilities of different language\ntechnologies. In particular, we compare the humor detection capabilities of\nclassic neural network approaches with the state-of-the-art Dutch language\nmodel RobBERT. In doing so, we create and compare the first Dutch humor\ndetection systems. We found that while other language models perform well when\nthe non-jokes came from completely different domains, RobBERT was the only one\nthat was able to distinguish jokes from generated negative examples. This\nperformance illustrates the usefulness of using text generation to create\nnegative datasets for humor recognition, and also shows that transformer models\nare a large step forward in humor detection.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 15:15:10 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Winters", "Thomas", ""], ["Delobelle", "Pieter", ""]]}, {"id": "2010.13665", "submitter": "Omer Nguena Timo", "authors": "Tianqi Xiao and Omer Nguena Timo and Florent Avellaneda and Yasir\n  Malik and Stefan Bruda", "title": "An Approach to Evaluating Learning Algorithms for Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning algorithms produce software models for realising critical\nclassification tasks. Decision trees models are simpler than other models such\nas neural network and they are used in various critical domains such as the\nmedical and the aeronautics. Low or unknown learning ability algorithms does\nnot permit us to trust the produced software models, which lead to costly test\nactivities for validating the models and to the waste of learning time in case\nthe models are likely to be faulty due to the learning inability. Methods for\nevaluating the decision trees learning ability, as well as that for the other\nmodels, are needed especially since the testing of the learned models is still\na hot topic. We propose a novel oracle-centered approach to evaluate (the\nlearning ability of) learning algorithms for decision trees. It consists of\ngenerating data from reference trees playing the role of oracles, producing\nlearned trees with existing learning algorithms, and determining the degree of\ncorrectness (DOE) of the learned trees by comparing them with the oracles. The\naverage DOE is used to estimate the quality of the learning algorithm. the We\nassess five decision tree learning algorithms based on the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 15:36:59 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Xiao", "Tianqi", ""], ["Timo", "Omer Nguena", ""], ["Avellaneda", "Florent", ""], ["Malik", "Yasir", ""], ["Bruda", "Stefan", ""]]}, {"id": "2010.13668", "submitter": "Daniel Hannah", "authors": "Tuomas P. Oikarinen (1), Daniel C. Hannah (2), Sohrob Kazerounian (2)\n  ((1) Massachusetts Institute of Technology, (2) Vectra AI)", "title": "GraphMDN: Leveraging graph structure and deep learning to solve inverse\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent introduction of Graph Neural Networks (GNNs) and their growing\npopularity in the past few years has enabled the application of deep learning\nalgorithms to non-Euclidean, graph-structured data. GNNs have achieved\nstate-of-the-art results across an impressive array of graph-based machine\nlearning problems. Nevertheless, despite their rapid pace of development, much\nof the work on GNNs has focused on graph classification and embedding\ntechniques, largely ignoring regression tasks over graph data. In this paper,\nwe develop a Graph Mixture Density Network (GraphMDN), which combines graph\nneural networks with mixture density network (MDN) outputs. By combining these\ntechniques, GraphMDNs have the advantage of naturally being able to incorporate\ngraph structured information into a neural architecture, as well as the ability\nto model multi-modal regression targets. As such, GraphMDNs are designed to\nexcel on regression tasks wherein the data are graph structured, and target\nstatistics are better represented by mixtures of densities rather than singular\nvalues (so-called ``inverse problems\"). To demonstrate this, we extend an\nexisting GNN architecture known as Semantic GCN (SemGCN) to a GraphMDN\nstructure, and show results from the Human3.6M pose estimation task. The\nextended model consistently outperforms both GCN and MDN architectures on their\nown, with a comparable number of parameters.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 15:44:22 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Oikarinen", "Tuomas P.", "", "Massachusetts Institute of Technology"], ["Hannah", "Daniel C.", "", "Vectra AI"], ["Kazerounian", "Sohrob", "", "Vectra AI"]]}, {"id": "2010.13685", "submitter": "Veronica Chelu", "authors": "Veronica Chelu, Doina Precup, Hado van Hasselt", "title": "Forethought and Hindsight in Credit Assignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of credit assignment in reinforcement learning and\nexplore fundamental questions regarding the way in which an agent can best use\nadditional computation to propagate new information, by planning with internal\nmodels of the world to improve its predictions. Particularly, we work to\nunderstand the gains and peculiarities of planning employed as forethought via\nforward models or as hindsight operating with backward models. We establish the\nrelative merits, limitations and complementary properties of both planning\nmechanisms in carefully constructed scenarios. Further, we investigate the best\nuse of models in planning, primarily focusing on the selection of states in\nwhich predictions should be (re)-evaluated. Lastly, we discuss the issue of\nmodel estimation and highlight a spectrum of methods that stretch from explicit\nenvironment-dynamics predictors to more abstract planner-aware models.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 16:00:47 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Chelu", "Veronica", ""], ["Precup", "Doina", ""], ["van Hasselt", "Hado", ""]]}, {"id": "2010.13688", "submitter": "Alexander Kalinowski", "authors": "Alexander Kalinowski, Yuan An", "title": "A Survey of Embedding Space Alignment Methods for Language and Knowledge\n  Graphs", "comments": "27 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural embedding approaches have become a staple in the fields of computer\nvision, natural language processing, and more recently, graph analytics. Given\nthe pervasive nature of these algorithms, the natural question becomes how to\nexploit the embedding spaces to map, or align, embeddings of different data\nsources. To this end, we survey the current research landscape on word,\nsentence and knowledge graph embedding algorithms. We provide a classification\nof the relevant alignment techniques and discuss benchmark datasets used in\nthis field of research. By gathering these diverse approaches into a singular\nsurvey, we hope to further motivate research into alignment of embedding spaces\nof varied data types and sources.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 16:08:13 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Kalinowski", "Alexander", ""], ["An", "Yuan", ""]]}, {"id": "2010.13702", "submitter": "Haiguang Liao", "authors": "Haiguang Liao, Qingyi Dong, Weiyi Qi, Elias Fallon, Levent Burak Kara", "title": "Track-Assignment Detailed Routing Using Attention-based Policy Model\n  With Supervision", "comments": null, "journal-ref": null, "doi": "10.1145/3380446.3430629", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detailed routing is one of the most critical steps in analog circuit design.\nComplete routing has become increasingly more challenging in advanced node\nanalog circuits, making advances in efficient automatic routers ever more\nnecessary. In this work, we propose a machine learning driven method for\nsolving the track-assignment detailed routing problem for advanced node analog\ncircuits. Our approach adopts an attention-based reinforcement learning (RL)\npolicy model. Our main insight and advancement over this RL model is the use of\nsupervision as a way to leverage solutions generated by a conventional genetic\nalgorithm (GA). For this, our approach minimizes the Kullback-Leibler\ndivergence loss between the output from the RL policy model and a solution\ndistribution obtained from the genetic solver. The key advantage of this\napproach is that the router can learn a policy in an offline setting with\nsupervision, while improving the run-time performance nearly 100x over the\ngenetic solver. Moreover, the quality of the solutions our approach produces\nmatches well with those generated by GA. We show that especially for complex\nproblems, our supervised RL method provides good quality solution similar to\nconventional attention-based RL without comprising run time performance. The\nability to learn from example designs and train the router to get similar\nsolutions with orders of magnitude run-time improvement can impact the design\nflow dramatically, potentially enabling increased design exploration and\nroutability-driven placement.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 16:40:11 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Liao", "Haiguang", ""], ["Dong", "Qingyi", ""], ["Qi", "Weiyi", ""], ["Fallon", "Elias", ""], ["Kara", "Levent Burak", ""]]}, {"id": "2010.13753", "submitter": "Jes\\'us Ruiz-Santaquiteria", "authors": "Jesus Ruiz-Santaquiteria, Alberto Velasco-Mata, Noelia Vallez, Gloria\n  Bueno, Juan A. \\'Alvarez-Garc\\'ia, Oscar Deniz", "title": "Handgun detection using combined human pose and weapon appearance", "comments": "17 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Closed-circuit television (CCTV) systems are essential nowadays to prevent\nsecurity threats or dangerous situations, in which early detection is crucial.\nNovel deep learning-based methods have allowed to develop automatic weapon\ndetectors with promising results. However, these approaches are mainly based on\nvisual weapon appearance only. For handguns, body pose may be a useful cue,\nespecially in cases where the gun is barely visible. In this work, a novel\nmethod is proposed to combine, in a single architecture, both weapon appearance\nand human pose information. First, pose keypoints are estimated to extract hand\nregions and generate binary pose images, which are the model inputs. Then, each\ninput is processed in different subnetworks and combined to produce the handgun\nbounding box. Results obtained show that the combined model improves the\nhandgun detection state of the art, achieving from 4.23 to 18.9 AP points more\nthan the best previous approach.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 17:45:12 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 12:00:53 GMT"}, {"version": "v3", "created": "Sun, 31 Jan 2021 17:28:41 GMT"}, {"version": "v4", "created": "Fri, 23 Jul 2021 09:55:57 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Ruiz-Santaquiteria", "Jesus", ""], ["Velasco-Mata", "Alberto", ""], ["Vallez", "Noelia", ""], ["Bueno", "Gloria", ""], ["\u00c1lvarez-Garc\u00eda", "Juan A.", ""], ["Deniz", "Oscar", ""]]}, {"id": "2010.13816", "submitter": "Maarten Sap", "authors": "Xinyao Ma, Maarten Sap, Hannah Rashkin, Yejin Choi", "title": "PowerTransformer: Unsupervised Controllable Revision for Biased Language\n  Correction", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unconscious biases continue to be prevalent in modern text and media, calling\nfor algorithms that can assist writers with bias correction. For example, a\nfemale character in a story is often portrayed as passive and powerless (\"She\ndaydreams about being a doctor\") while a man is portrayed as more proactive and\npowerful (\"He pursues his dream of being a doctor\").\n  We formulate *Controllable Debiasing*, a new revision task that aims to\nrewrite a given text to correct the implicit and potentially undesirable bias\nin character portrayals. We then introduce PowerTransformer as an approach that\ndebiases text through the lens of connotation frames (Sap et al., 2017), which\nencode pragmatic knowledge of implied power dynamics with respect to verb\npredicates. One key challenge of our task is the lack of parallel corpora. To\naddress this challenge, we adopt an unsupervised approach using auxiliary\nsupervision with related tasks such as paraphrasing and self-supervision based\non a reconstruction loss, building on pretrained language models.\n  Through comprehensive experiments based on automatic and human evaluations,\nwe demonstrate that our approach outperforms ablations and existing methods\nfrom related tasks. Furthermore, we demonstrate the use of PowerTransformer as\na step toward mitigating the well-documented gender bias in character portrayal\nin movie scripts.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 18:05:48 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Ma", "Xinyao", ""], ["Sap", "Maarten", ""], ["Rashkin", "Hannah", ""], ["Choi", "Yejin", ""]]}, {"id": "2010.13830", "submitter": "Shelly Bagchi", "authors": "Shelly Bagchi, Jason R. Wilson, Muneeb I. Ahmad, Christian Dondrup,\n  Zhao Han, Justin W. Hart, Matteo Leonetti, Katrin Lohan, Ross Mead, Emmanuel\n  Senft, Jivko Sinapov, Megan L. Zimmerman", "title": "Proceedings of the AI-HRI Symposium at AAAI-FSS 2020", "comments": "Symposium proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Artificial Intelligence (AI) for Human-Robot Interaction (HRI) Symposium\nhas been a successful venue of discussion and collaboration since 2014. In that\ntime, the related topic of trust in robotics has been rapidly growing, with\nmajor research efforts at universities and laboratories across the world.\nIndeed, many of the past participants in AI-HRI have been or are now involved\nwith research into trust in HRI. While trust has no consensus definition, it is\nregularly associated with predictability, reliability, inciting confidence, and\nmeeting expectations. Furthermore, it is generally believed that trust is\ncrucial for adoption of both AI and robotics, particularly when transitioning\ntechnologies from the lab to industrial, social, and consumer applications.\nHowever, how does trust apply to the specific situations we encounter in the\nAI-HRI sphere? Is the notion of trust in AI the same as that in HRI? We see a\ngrowing need for research that lives directly at the intersection of AI and HRI\nthat is serviced by this symposium. Over the course of the two-day meeting, we\npropose to create a collaborative forum for discussion of current efforts in\ntrust for AI-HRI, with a sub-session focused on the related topic of\nexplainable AI (XAI) for HRI.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 18:32:24 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 02:34:58 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 14:22:06 GMT"}, {"version": "v4", "created": "Mon, 14 Dec 2020 19:15:24 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Bagchi", "Shelly", ""], ["Wilson", "Jason R.", ""], ["Ahmad", "Muneeb I.", ""], ["Dondrup", "Christian", ""], ["Han", "Zhao", ""], ["Hart", "Justin W.", ""], ["Leonetti", "Matteo", ""], ["Lohan", "Katrin", ""], ["Mead", "Ross", ""], ["Senft", "Emmanuel", ""], ["Sinapov", "Jivko", ""], ["Zimmerman", "Megan L.", ""]]}, {"id": "2010.13860", "submitter": "Sam Ganzfried", "authors": "Sam Ganzfried", "title": "Computing Nash Equilibria in Multiplayer DAG-Structured Stochastic Games\n  with Persistent Imperfect Information", "comments": "Added experimental results for a smaller game that demonstrate\n  algorithm convergence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important real-world settings contain multiple players interacting over\nan unknown duration with probabilistic state transitions, and are naturally\nmodeled as stochastic games. Prior research on algorithms for stochastic games\nhas focused on two-player zero-sum games, games with perfect information, and\ngames with imperfect-information that is local and does not extend between game\nstates. We present an algorithm for approximating Nash equilibrium in\nmultiplayer general-sum stochastic games with persistent imperfect information\nthat extends throughout game play. We experiment on a 4-player\nimperfect-information naval strategic planning scenario. Using a new procedure,\nwe are able to demonstrate that our algorithm computes a strategy that closely\napproximates Nash equilibrium in this game.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 19:27:26 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 02:38:24 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Ganzfried", "Sam", ""]]}, {"id": "2010.13864", "submitter": "Vivien Cabannes", "authors": "Vivien Cabannes and Thomas Kerdreux and Louis Thiry", "title": "Diptychs of human and machine perceptions", "comments": "7 pages, 36 images", "journal-ref": "creativity workshop NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.GR cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose visual creations that put differences in algorithms and humans\n\\emph{perceptions} into perspective. We exploit saliency maps of neural\nnetworks and visual focus of humans to create diptychs that are\nreinterpretations of an original image according to both machine and human\nattentions. Using those diptychs as a qualitative evaluation of perception, we\ndiscuss some crucial issues of current \\textit{task-oriented} artificial\nintelligence.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 10:22:28 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Cabannes", "Vivien", ""], ["Kerdreux", "Thomas", ""], ["Thiry", "Louis", ""]]}, {"id": "2010.13871", "submitter": "Erik Hoel", "authors": "Simon Mattsson, Eric J. Michaud, Erik Hoel", "title": "Examining the causal structures of deep neural networks using\n  information theory", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are often examined at the level of their response\nto input, such as analyzing the mutual information between nodes and data sets.\nYet DNNs can also be examined at the level of causation, exploring \"what does\nwhat\" within the layers of the network itself. Historically, analyzing the\ncausal structure of DNNs has received less attention than understanding their\nresponses to input. Yet definitionally, generalizability must be a function of\na DNN's causal structure since it reflects how the DNN responds to unseen or\neven not-yet-defined future inputs. Here, we introduce a suite of metrics based\non information theory to quantify and track changes in the causal structure of\nDNNs during training. Specifically, we introduce the effective information (EI)\nof a feedforward DNN, which is the mutual information between layer input and\noutput following a maximum-entropy perturbation. The EI can be used to assess\nthe degree of causal influence nodes and edges have over their downstream\ntargets in each layer. We show that the EI can be further decomposed in order\nto examine the sensitivity of a layer (measured by how well edges transmit\nperturbations) and the degeneracy of a layer (measured by how edge overlap\ninterferes with transmission), along with estimates of the amount of integrated\ninformation of a layer. Together, these properties define where each layer lies\nin the \"causal plane\" which can be used to visualize how layer connectivity\nbecomes more sensitive or degenerate over time, and how integration changes\nduring training, revealing how the layer-by-layer causal structure\ndifferentiates. These results may help in understanding the generalization\ncapabilities of DNNs and provide foundational tools for making DNNs both more\ngeneralizable and more explainable.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 19:53:16 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Mattsson", "Simon", ""], ["Michaud", "Eric J.", ""], ["Hoel", "Erik", ""]]}, {"id": "2010.13880", "submitter": "Laurens Devos", "authors": "Laurens Devos, Wannes Meert, Jesse Davis", "title": "Versatile Verification of Tree Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learned models often must abide by certain requirements (e.g.,\nfairness or legal). This has spurred interested in developing approaches that\ncan provably verify whether a model satisfies certain properties. This paper\nintroduces a generic algorithm called Veritas that enables tackling multiple\ndifferent verification tasks for tree ensemble models like random forests (RFs)\nand gradient boosting decision trees (GBDTs). This generality contrasts with\nprevious work, which has focused exclusively on either adversarial example\ngeneration or robustness checking. Veritas formulates the verification task as\na generic optimization problem and introduces a novel search space\nrepresentation. Veritas offers two key advantages. First, it provides anytime\nlower and upper bounds when the optimization problem cannot be solved exactly.\nIn contrast, many existing methods have focused on exact solutions and are thus\nlimited by the verification problem being NP-complete. Second, Veritas produces\nfull (bounded suboptimal) solutions that can be used to generate concrete\nexamples. We experimentally show that Veritas outperforms the previous state of\nthe art by (a) generating exact solutions more frequently, (b) producing\ntighter bounds when (a) is not possible, and (c) offering orders of magnitude\nspeed ups. Subsequently, Veritas enables tackling more and larger real-world\nverification scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 20:13:17 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 18:21:43 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Devos", "Laurens", ""], ["Meert", "Wannes", ""], ["Davis", "Jesse", ""]]}, {"id": "2010.13900", "submitter": "Tirtharaj Dash", "authors": "Tirtharaj Dash, Ashwin Srinivasan, Lovekesh Vig", "title": "Incorporating Symbolic Domain Knowledge into Graph Neural Networks", "comments": "Accepted in Machine Learning Journal (MLJ)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our interest is in scientific problems with the following characteristics:\n(1) Data are naturally represented as graphs; (2) The amount of data available\nis typically small; and (3) There is significant domain-knowledge, usually\nexpressed in some symbolic form. These kinds of problems have been addressed\neffectively in the past by Inductive Logic Programming (ILP), by virtue of 2\nimportant characteristics: (a) The use of a representation language that easily\ncaptures the relation encoded in graph-structured data, and (b) The inclusion\nof prior information encoded as domain-specific relations, that can alleviate\nproblems of data scarcity, and construct new relations. Recent advances have\nseen the emergence of deep neural networks specifically developed for\ngraph-structured data (Graph-based Neural Networks, or GNNs). While GNNs have\nbeen shown to be able to handle graph-structured data, less has been done to\ninvestigate the inclusion of domain-knowledge. Here we investigate this aspect\nof GNNs empirically by employing an operation we term \"vertex-enrichment\" and\ndenote the corresponding GNNs as \"VEGNNs\". Using over 70 real-world datasets\nand substantial amounts of symbolic domain-knowledge, we examine the result of\nvertex-enrichment across 5 different variants of GNNs. Our results provide\nsupport for the following: (a) Inclusion of domain-knowledge by\nvertex-enrichment can significantly improve the performance of a GNN. That is,\nthe performance VEGNNs is significantly better than GNNs across all GNN\nvariants; (b) The inclusion of domain-specific relations constructed using ILP\nimproves the performance of VEGNNs, across all GNN variants. Taken together,\nthe results provide evidence that it is possible to incorporate symbolic domain\nknowledge into a GNN, and that ILP can play an important role in providing\nhigh-level relationships that are not easily discovered by a GNN.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 16:22:21 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 15:55:52 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Dash", "Tirtharaj", ""], ["Srinivasan", "Ashwin", ""], ["Vig", "Lovekesh", ""]]}, {"id": "2010.13902", "submitter": "Yuning You", "authors": "Yuning You, Tianlong Chen, Yongduo Sui, Ting Chen, Zhangyang Wang,\n  Yang Shen", "title": "Graph Contrastive Learning with Augmentations", "comments": "Supplementary materials are available at\n  https://yyou1996.github.io/files/neurips2020_graphcl_supplement.pdf. NeurIPS\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalizable, transferrable, and robust representation learning on\ngraph-structured data remains a challenge for current graph neural networks\n(GNNs). Unlike what has been developed for convolutional neural networks (CNNs)\nfor image data, self-supervised learning and pre-training are less explored for\nGNNs. In this paper, we propose a graph contrastive learning (GraphCL)\nframework for learning unsupervised representations of graph data. We first\ndesign four types of graph augmentations to incorporate various priors. We then\nsystematically study the impact of various combinations of graph augmentations\non multiple datasets, in four different settings: semi-supervised,\nunsupervised, and transfer learning as well as adversarial attacks. The results\nshow that, even without tuning augmentation extents nor using sophisticated GNN\narchitectures, our GraphCL framework can produce graph representations of\nsimilar or better generalizability, transferrability, and robustness compared\nto state-of-the-art methods. We also investigate the impact of parameterized\ngraph augmentation extents and patterns, and observe further performance gains\nin preliminary experiments. Our codes are available at\nhttps://github.com/Shen-Lab/GraphCL.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 20:13:43 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 15:16:33 GMT"}, {"version": "v3", "created": "Sat, 3 Apr 2021 15:34:00 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["You", "Yuning", ""], ["Chen", "Tianlong", ""], ["Sui", "Yongduo", ""], ["Chen", "Ting", ""], ["Wang", "Zhangyang", ""], ["Shen", "Yang", ""]]}, {"id": "2010.13908", "submitter": "Bonggun Shin", "authors": "Bonggun Shin, Sungsoo Park, JinYeong Bak, Joyce C. Ho", "title": "Controlled Molecule Generator for Optimizing Multiple Chemical\n  Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating a novel and optimized molecule with desired chemical properties is\nan essential part of the drug discovery process. Failure to meet one of the\nrequired properties can frequently lead to failure in a clinical test which is\ncostly. In addition, optimizing these multiple properties is a challenging task\nbecause the optimization of one property is prone to changing other properties.\nIn this paper, we pose this multi-property optimization problem as a sequence\ntranslation process and propose a new optimized molecule generator model based\non the Transformer with two constraint networks: property prediction and\nsimilarity prediction. We further improve the model by incorporating score\npredictions from these constraint networks in a modified beam search algorithm.\nThe experiments demonstrate that our proposed model outperforms\nstate-of-the-art models by a significant margin for optimizing multiple\nproperties simultaneously.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 21:26:14 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Shin", "Bonggun", ""], ["Park", "Sungsoo", ""], ["Bak", "JinYeong", ""], ["Ho", "Joyce C.", ""]]}, {"id": "2010.13912", "submitter": "Chien-Sheng Wu", "authors": "Chien-Sheng Wu and Caiming Xiong", "title": "Probing Task-Oriented Dialogue Representation from Language Models", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates pre-trained language models to find out which model\nintrinsically carries the most informative representation for task-oriented\ndialogue tasks. We approach the problem from two aspects: supervised classifier\nprobe and unsupervised mutual information probe. We fine-tune a feed-forward\nlayer as the classifier probe on top of a fixed pre-trained language model with\nannotated labels in a supervised way. Meanwhile, we propose an unsupervised\nmutual information probe to evaluate the mutual dependence between a real\nclustering and a representation clustering. The goals of this empirical paper\nare to 1) investigate probing techniques, especially from the unsupervised\nmutual information aspect, 2) provide guidelines of pre-trained language model\nselection for the dialogue research community, 3) find insights of pre-training\nfactors for dialogue application that may be the key to success.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 21:34:39 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Wu", "Chien-Sheng", ""], ["Xiong", "Caiming", ""]]}, {"id": "2010.13920", "submitter": "Chien-Sheng Wu", "authors": "Chien-Sheng Wu and Steven Hoi and Caiming Xiong", "title": "Improving Limited Labeled Dialogue State Tracking with Self-Supervision", "comments": "EMNLP 2020 (findings)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing dialogue state tracking (DST) models require plenty of labeled data.\nHowever, collecting high-quality labels is costly, especially when the number\nof domains increases. In this paper, we address a practical DST problem that is\nrarely discussed, i.e., learning efficiently with limited labeled data. We\npresent and investigate two self-supervised objectives: preserving latent\nconsistency and modeling conversational behavior. We encourage a DST model to\nhave consistent latent distributions given a perturbed input, making it more\nrobust to an unseen scenario. We also add an auxiliary utterance generation\ntask, modeling a potential correlation between conversational behavior and\ndialogue states. The experimental results show that our proposed\nself-supervised signals can improve joint goal accuracy by 8.95\\% when only 1\\%\nlabeled data is used on the MultiWOZ dataset. We can achieve an additional\n1.76\\% improvement if some unlabeled data is jointly trained as semi-supervised\nlearning. We analyze and visualize how our proposed self-supervised signals\nhelp the DST task and hope to stimulate future data-efficient DST research.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 21:57:42 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Wu", "Chien-Sheng", ""], ["Hoi", "Steven", ""], ["Xiong", "Caiming", ""]]}, {"id": "2010.13943", "submitter": "Jayanta Mandi", "authors": "Jayanta Mandi, Tias Guns", "title": "Interior Point Solving for LP-based prediction+optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving optimization problems is the key to decision making in many real-life\nanalytics applications. However, the coefficients of the optimization problems\nare often uncertain and dependent on external factors, such as future demand or\nenergy or stock prices. Machine learning (ML) models, especially neural\nnetworks, are increasingly being used to estimate these coefficients in a\ndata-driven way. Hence, end-to-end predict-and-optimize approaches, which\nconsider how effective the predicted values are to solve the optimization\nproblem, have received increasing attention. In case of integer linear\nprogramming problems, a popular approach to overcome their non-differentiabilty\nis to add a quadratic penalty term to the continuous relaxation, such that\nresults from differentiating over quadratic programs can be used. Instead we\ninvestigate the use of the more principled logarithmic barrier term, as widely\nused in interior point solvers for linear programming. Specifically, instead of\ndifferentiating the KKT conditions, we consider the homogeneous self-dual\nformulation of the LP and we show the relation between the interior point step\ndirection and corresponding gradients needed for learning. Finally our\nempirical experiments demonstrate our approach performs as good as if not\nbetter than the state-of-the-art QPTL (Quadratic Programming task loss)\nformulation of Wilder et al. and SPO approach of Elmachtoub and Grigas.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 23:05:21 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Mandi", "Jayanta", ""], ["Guns", "Tias", ""]]}, {"id": "2010.13957", "submitter": "Kate Rakelly", "authors": "Tony Z. Zhao, Anusha Nagabandi, Kate Rakelly, Chelsea Finn, Sergey\n  Levine", "title": "MELD: Meta-Reinforcement Learning from Images via Latent State Models", "comments": "Accepted to CoRL 2020. Supplementary material at\n  https://sites.google.com/view/meld-lsm/home . 16 pages, 19 figures. V2: add\n  funding acknowledgements, reduce file size", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-reinforcement learning algorithms can enable autonomous agents, such as\nrobots, to quickly acquire new behaviors by leveraging prior experience in a\nset of related training tasks. However, the onerous data requirements of\nmeta-training compounded with the challenge of learning from sensory inputs\nsuch as images have made meta-RL challenging to apply to real robotic systems.\nLatent state models, which learn compact state representations from a sequence\nof observations, can accelerate representation learning from visual inputs. In\nthis paper, we leverage the perspective of meta-learning as task inference to\nshow that latent state models can \\emph{also} perform meta-learning given an\nappropriately defined observation space. Building on this insight, we develop\nmeta-RL with latent dynamics (MELD), an algorithm for meta-RL from images that\nperforms inference in a latent state model to quickly acquire new skills given\nobservations and rewards. MELD outperforms prior meta-RL methods on several\nsimulated image-based robotic control problems, and enables a real WidowX\nrobotic arm to insert an Ethernet cable into new locations given a sparse task\ncompletion signal after only $8$ hours of real world meta-training. To our\nknowledge, MELD is the first meta-RL algorithm trained in a real-world robotic\ncontrol setting from images.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 23:50:30 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 16:09:19 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Zhao", "Tony Z.", ""], ["Nagabandi", "Anusha", ""], ["Rakelly", "Kate", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""]]}, {"id": "2010.13962", "submitter": "Cat Le", "authors": "Cat P. Le, Mohammadreza Soltani, Robert Ravier, Vahid Tarokh", "title": "Task-Aware Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The design of handcrafted neural networks requires a lot of time and\nresources. Recent techniques in Neural Architecture Search (NAS) have proven to\nbe competitive or better than traditional handcrafted design, although they\nrequire domain knowledge and have generally used limited search spaces. In this\npaper, we propose a novel framework for neural architecture search, utilizing a\ndictionary of models of base tasks and the similarity between the target task\nand the atoms of the dictionary; hence, generating an adaptive search space\nbased on the base models of the dictionary. By introducing a gradient-based\nsearch algorithm, we can evaluate and discover the best architecture in the\nsearch space without fully training the networks. The experimental results show\nthe efficacy of our proposed task-aware approach.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 00:10:40 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 15:03:38 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 22:02:53 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Le", "Cat P.", ""], ["Soltani", "Mohammadreza", ""], ["Ravier", "Robert", ""], ["Tarokh", "Vahid", ""]]}, {"id": "2010.13982", "submitter": "Hung-Ting Chen", "authors": "Hung-Ting Chen, Yu-Chieh Chao, Ta-Hsuan Chao, Wei-Yun Ma", "title": "Predict and Use Latent Patterns for Short-Text Conversation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many neural network models nowadays have achieved promising performances in\nChit-chat settings. The majority of them rely on an encoder for understanding\nthe post and a decoder for generating the response. Without given assigned\nsemantics, the models lack the fine-grained control over responses as the\nsemantic mapping between posts and responses is hidden on the fly within the\nend-to-end manners. Some previous works utilize sampled latent words as a\ncontrollable semantic form to drive the generated response around the work, but\nfew works attempt to use more complex semantic patterns to guide the\ngeneration. In this paper, we propose to use more detailed semantic forms,\nincluding latent responses and part-of-speech sequences sampled from the\ncorresponding distributions, as the controllable semantics to guide the\ngeneration. Our results show that the richer semantics are not only able to\nprovide informative and diverse responses, but also increase the overall\nperformance of response quality, including fluency and coherence.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 01:31:42 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 03:14:27 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Chen", "Hung-Ting", ""], ["Chao", "Yu-Chieh", ""], ["Chao", "Ta-Hsuan", ""], ["Ma", "Wei-Yun", ""]]}, {"id": "2010.13983", "submitter": "Alishba Imran", "authors": "David Hanson (Hanson Robotics), Alishba Imran (Hanson Robotics),\n  Abhinandan Vellanki (Hanson Robotics), Sanjeew Kanagaraj (Hanson Robotics)", "title": "A Neuro-Symbolic Humanlike Arm Controller for Sophia the Robot", "comments": "12 pages, 11 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We outline the design and construction of novel robotic arms using machine\nperception, convolutional neural networks, and symbolic AI for logical control\nand affordance indexing. We describe our robotic arms built with a humanlike\nmechanical configuration and aesthetic, with 28 degrees of freedom, touch\nsensors, and series elastic actuators. The arms were modelled in Roodle and\nGazebo with URDF models, as well as Unity, and implement motion control\nsolutions for solving live games of Baccarat (the casino card game), rock paper\nscissors, handshaking, and drawing. This includes live interactions with\npeople, incorporating both social control of the hands and facial gestures, and\nphysical inverse kinematics (IK) for grasping and manipulation tasks. The\nresulting framework is an integral part of the Sophia 2020 alpha platform,\nwhich is being used with ongoing research in the authors work with team AHAM,\nan ANA Avatar Xprize effort towards human-AI hybrid telepresence. These results\nare available to test on the broadly released Hanson Robotics Sophia 2020 robot\nplatform, for users to try and extend.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 01:32:03 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Hanson", "David", "", "Hanson Robotics"], ["Imran", "Alishba", "", "Hanson Robotics"], ["Vellanki", "Abhinandan", "", "Hanson Robotics"], ["Kanagaraj", "Sanjeew", "", "Hanson Robotics"]]}, {"id": "2010.13984", "submitter": "Siwon Kim", "authors": "Siwon Kim, Jihun Yi, Eunji Kim, and Sungroh Yoon", "title": "Interpretation of NLP models through input marginalization", "comments": "10 pages, 5 figures, to be published in the 2020 Conference on\n  Empirical Methods in Natural Language Processing (EMNLP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To demystify the \"black box\" property of deep neural networks for natural\nlanguage processing (NLP), several methods have been proposed to interpret\ntheir predictions by measuring the change in prediction probability after\nerasing each token of an input. Since existing methods replace each token with\na predefined value (i.e., zero), the resulting sentence lies out of the\ntraining data distribution, yielding misleading interpretations. In this study,\nwe raise the out-of-distribution problem induced by the existing interpretation\nmethods and present a remedy; we propose to marginalize each token out. We\ninterpret various NLP models trained for sentiment analysis and natural\nlanguage inference using the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 01:40:41 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Kim", "Siwon", ""], ["Yi", "Jihun", ""], ["Kim", "Eunji", ""], ["Yoon", "Sungroh", ""]]}, {"id": "2010.14000", "submitter": "Xiaowei Jia", "authors": "Xiaowei Jia, Beiyu Lin, Jacob Zwart, Jeffrey Sadler, Alison Appling,\n  Samantha Oliver, Jordan Read", "title": "Graph-based Reinforcement Learning for Active Learning in Real Time: An\n  Application in Modeling River Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective training of advanced ML models requires large amounts of labeled\ndata, which is often scarce in scientific problems given the substantial human\nlabor and material cost to collect labeled data. This poses a challenge on\ndetermining when and where we should deploy measuring instruments (e.g.,\nin-situ sensors) to collect labeled data efficiently. This problem differs from\ntraditional pool-based active learning settings in that the labeling decisions\nhave to be made immediately after we observe the input data that come in a time\nseries. In this paper, we develop a real-time active learning method that uses\nthe spatial and temporal contextual information to select representative query\nsamples in a reinforcement learning framework. To reduce the need for large\ntraining data, we further propose to transfer the policy learned from\nsimulation data which is generated by existing physics-based models. We\ndemonstrate the effectiveness of the proposed method by predicting streamflow\nand water temperature in the Delaware River Basin given a limited budget for\ncollecting labeled data. We further study the spatial and temporal distribution\nof selected samples to verify the ability of this method in selecting\ninformative samples over space and time.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 02:19:40 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 18:04:58 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Jia", "Xiaowei", ""], ["Lin", "Beiyu", ""], ["Zwart", "Jacob", ""], ["Sadler", "Jeffrey", ""], ["Appling", "Alison", ""], ["Oliver", "Samantha", ""], ["Read", "Jordan", ""]]}, {"id": "2010.14043", "submitter": "Yuxin Chen", "authors": "Akash Kumar, Hanqi Zhang, Adish Singla, Yuxin Chen", "title": "The Teaching Dimension of Kernel Perceptron", "comments": "AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic machine teaching has been studied under the linear setting where\nexact teaching is possible. However, little is known for teaching nonlinear\nlearners. Here, we establish the sample complexity of teaching, aka teaching\ndimension, for kernelized perceptrons for different families of feature maps.\nAs a warm-up, we show that the teaching complexity is $\\Theta(d)$ for the exact\nteaching of linear perceptrons in $\\mathbb{R}^d$, and $\\Theta(d^k)$ for kernel\nperceptron with a polynomial kernel of order $k$. Furthermore, under certain\nsmooth assumptions on the data distribution, we establish a rigorous bound on\nthe complexity for approximately teaching a Gaussian kernel perceptron. We\nprovide numerical examples of the optimal (approximate) teaching set under\nseveral canonical settings for linear, polynomial and Gaussian kernel\nperceptrons.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 04:06:53 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 23:51:30 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Kumar", "Akash", ""], ["Zhang", "Hanqi", ""], ["Singla", "Adish", ""], ["Chen", "Yuxin", ""]]}, {"id": "2010.14049", "submitter": "Wen-Ting Tseng", "authors": "Wen-Ting Tseng, Tien-Hong Lo, Yung-Chang Hsu and Berlin Chen", "title": "Effective FAQ Retrieval and Question Matching With Unsupervised\n  Knowledge Injection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequently asked question (FAQ) retrieval, with the purpose of providing\ninformation on frequent questions or concerns, has far-reaching applications in\nmany areas, where a collection of question-answer (Q-A) pairs compiled a priori\ncan be employed to retrieve an appropriate answer in response to a user\\u2019s\nquery that is likely to reoccur frequently. To this end, predominant approaches\nto FAQ retrieval typically rank question-answer pairs by considering either the\nsimilarity between the query and a question (q-Q), the relevance between the\nquery and the associated answer of a question (q-A), or combining the clues\ngathered from the q-Q similarity measure and the q-A relevance measure. In this\npaper, we extend this line of research by combining the clues gathered from the\nq-Q similarity measure and the q-A relevance measure and meanwhile injecting\nextra word interaction information, distilled from a generic (open domain)\nknowledge base, into a contextual language model for inferring the q-A\nrelevance. Furthermore, we also explore to capitalize on domain-specific\ntopically-relevant relations between words in an unsupervised manner, acting as\na surrogate to the supervised domain-specific knowledge base information. As\nsuch, it enables the model to equip sentence representations with the knowledge\nabout domain-specific and topically-relevant relations among words, thereby\nproviding a better q-A relevance measure. We evaluate variants of our approach\non a publicly-available Chinese FAQ dataset, and further apply and\ncontextualize it to a large-scale question-matching task, which aims to search\nquestions from a QA dataset that have a similar intent as an input query.\nExtensive experimental results on these two datasets confirm the promising\nperformance of the proposed approach in relation to some state-of-the-art ones.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 05:03:34 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Tseng", "Wen-Ting", ""], ["Lo", "Tien-Hong", ""], ["Hsu", "Yung-Chang", ""], ["Chen", "Berlin", ""]]}, {"id": "2010.14060", "submitter": "Xuli Shen", "authors": "Xuli Shen, Qing Xu, Xiangyang Xue", "title": "Nonlinear Monte Carlo Method for Imbalanced Data Learning", "comments": "update methods and experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For basic machine learning problems, expected error is used to evaluate model\nperformance. Since the distribution of data is usually unknown, we can make\nsimple hypothesis that the data are sampled independently and identically\ndistributed (i.i.d.) and the mean value of loss function is used as the\nempirical risk by Law of Large Numbers (LLN). This is known as the Monte Carlo\nmethod. However, when LLN is not applicable, such as imbalanced data problems,\nempirical risk will cause overfitting and might decrease robustness and\ngeneralization ability. Inspired by the framework of nonlinear expectation\ntheory, we substitute the mean value of loss function with the maximum value of\nsubgroup mean loss. We call it nonlinear Monte Carlo method. In order to use\nnumerical method of optimization, we linearize and smooth the functional of\nmaximum empirical risk and get the descent direction via quadratic programming.\nWith the proposed method, we achieve better performance than SOTA backbone\nmodels with less training steps, and more robustness for basic regression and\nimbalanced classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 05:25:09 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 11:44:34 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Shen", "Xuli", ""], ["Xu", "Qing", ""], ["Xue", "Xiangyang", ""]]}, {"id": "2010.14061", "submitter": "Yan Zeng", "authors": "Yan Zeng and Jian-Yun Nie", "title": "Jointly Optimizing State Operation Prediction and Value Generation for\n  Dialogue State Tracking", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We investigate the problem of multi-domain Dialogue State Tracking (DST) with\nopen vocabulary. Existing approaches exploit BERT encoder and copy-based RNN\ndecoder, where the encoder predicts the state operation, and the decoder\ngenerates new slot values. However, in such a stacked encoder-decoder\nstructure, the operation prediction objective only affects the BERT encoder and\nthe value generation objective mainly affects the RNN decoder. In this paper,\nwe propose a purely Transformer-based framework, where a single BERT works as\nboth the encoder and the decoder. In so doing, the operation prediction\nobjective and the value generation objective can jointly optimize this BERT for\nDST. At the decoding step, we re-use the hidden states of the encoder in the\nself-attention mechanism of the corresponding decoder layers to construct a\nflat encoder-decoder architecture for effective parameter updating.\nExperimental results show that our approach substantially outperforms the\nexisting state-of-the-art framework, and it also achieves very competitive\nperformance to the best ontology-based approaches.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 04:54:52 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 02:04:05 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Zeng", "Yan", ""], ["Nie", "Jian-Yun", ""]]}, {"id": "2010.14068", "submitter": "Navodini Wijethilake", "authors": "Navodini Wijethilake, Mobarakol Islam, Dulani Meedeniya, Charith\n  Chitraranjan, Indika Perera, Hongliang Ren", "title": "Radiogenomics of Glioblastoma: Identification of Radiomics associated\n  with Molecular Subtypes", "comments": "2nd MICCAI workshop on Radiomics and Radiogenomics in Neuro-oncology\n  using AI, Springer, LNCS, (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Glioblastoma is the most malignant type of central nervous system tumor with\nGBM subtypes cleaved based on molecular level gene alterations. These\nalterations are also happened to affect the histology. Thus, it can cause\nvisible changes in images, such as enhancement and edema development. In this\nstudy, we extract intensity, volume, and texture features from the tumor\nsubregions to identify the correlations with gene expression features and\noverall survival. Consequently, we utilize the radiomics to find associations\nwith the subtypes of glioblastoma. Accordingly, the fractal dimensions of the\nwhole tumor, tumor core, and necrosis regions show a significant difference\nbetween the Proneural, Classical and Mesenchymal subtypes. Additionally, the\nsubtypes of GBM are predicted with an average accuracy of 79% utilizing\nradiomics and accuracy over 90% utilizing gene expression profiles.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 05:31:56 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Wijethilake", "Navodini", ""], ["Islam", "Mobarakol", ""], ["Meedeniya", "Dulani", ""], ["Chitraranjan", "Charith", ""], ["Perera", "Indika", ""], ["Ren", "Hongliang", ""]]}, {"id": "2010.14104", "submitter": "Bj\\\"orn Bebensee", "authors": "Bj\\\"orn Bebensee, Byoung-Tak Zhang", "title": "Co-attentional Transformers for Story-Based Video Understanding", "comments": "10 pages, 2 figures, submitted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent trends in vision and language learning, we explore\napplications of attention mechanisms for visio-lingual fusion within an\napplication to story-based video understanding. Like other video-based QA\ntasks, video story understanding requires agents to grasp complex temporal\ndependencies. However, as it focuses on the narrative aspect of video it also\nrequires understanding of the interactions between different characters, as\nwell as their actions and their motivations. We propose a novel co-attentional\ntransformer model to better capture long-term dependencies seen in visual\nstories such as dramas and measure its performance on the video question\nanswering task. We evaluate our approach on the recently introduced DramaQA\ndataset which features character-centered video story understanding questions.\nOur model outperforms the baseline model by 8 percentage points overall, at\nleast 4.95 and up to 12.8 percentage points on all difficulty levels and\nmanages to beat the winner of the DramaQA challenge.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 07:17:09 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Bebensee", "Bj\u00f6rn", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "2010.14108", "submitter": "Mingjun Zhao", "authors": "Mingjun Zhao, Shengli Yan, Bang Liu, Xinwang Zhong, Qian Hao, Haolan\n  Chen, Di Niu, Bowei Long and Weidong Guo", "title": "QBSUM: a Large-Scale Query-Based Document Summarization Dataset from\n  Real-world Applications", "comments": "accepted by Computer Speech & Language", "journal-ref": null, "doi": "10.1016/j.csl.2020.101166", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Query-based document summarization aims to extract or generate a summary of a\ndocument which directly answers or is relevant to the search query. It is an\nimportant technique that can be beneficial to a variety of applications such as\nsearch engines, document-level machine reading comprehension, and chatbots.\nCurrently, datasets designed for query-based summarization are short in numbers\nand existing datasets are also limited in both scale and quality. Moreover, to\nthe best of our knowledge, there is no publicly available dataset for Chinese\nquery-based document summarization. In this paper, we present QBSUM, a\nhigh-quality large-scale dataset consisting of 49,000+ data samples for the\ntask of Chinese query-based document summarization. We also propose multiple\nunsupervised and supervised solutions to the task and demonstrate their\nhigh-speed inference and superior performance via both offline experiments and\nonline A/B tests. The QBSUM dataset is released in order to facilitate future\nadvancement of this research field.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 07:30:04 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 08:39:51 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Zhao", "Mingjun", ""], ["Yan", "Shengli", ""], ["Liu", "Bang", ""], ["Zhong", "Xinwang", ""], ["Hao", "Qian", ""], ["Chen", "Haolan", ""], ["Niu", "Di", ""], ["Long", "Bowei", ""], ["Guo", "Weidong", ""]]}, {"id": "2010.14122", "submitter": "Raktim Gautam Goswami", "authors": "Raktim Gautam Goswami, Sivaganesh Andhavarapu and K Sri Rama Murty", "title": "Phase Aware Speech Enhancement using Realisation of Complex-valued LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the deep learning based speech enhancement (SE) methods rely on\nestimating the magnitude spectrum of the clean speech signal from the observed\nnoisy speech signal, either by magnitude spectral masking or regression. These\nmethods reuse the noisy phase while synthesizing the time-domain waveform from\nthe estimated magnitude spectrum. However, there have been recent works\nhighlighting the importance of phase in SE. There was an attempt to estimate\nthe complex ratio mask taking phase into account using complex-valued\nfeed-forward neural network (FFNN). But FFNNs cannot capture the sequential\ninformation essential for phase estimation. In this work, we propose a\nrealisation of complex-valued long short-term memory (RCLSTM) network to\nestimate the complex ratio mask (CRM) using sequential information along time.\nThe proposed RCLSTM is designed to process the complex-valued sequences using\ncomplex arithmetic, and hence it preserves the dependencies between the real\nand imaginary parts of CRM and thereby the phase. The proposed method is\nevaluated on the noisy speech mixtures formed from the Voice-Bank corpus and\nDEMAND database. When compared to real value based masking methods, the\nproposed RCLSTM improves over them in several objective measures including\nperceptual evaluation of speech quality (PESQ), in which it improves by over\n4.3%\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 08:16:58 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Goswami", "Raktim Gautam", ""], ["Andhavarapu", "Sivaganesh", ""], ["Murty", "K Sri Rama", ""]]}, {"id": "2010.14194", "submitter": "Ahmad Asadi", "authors": "Mehran Taghian, Ahmad Asadi, Reza Safabakhsh", "title": "Learning Financial Asset-Specific Trading Rules via Deep Reinforcement\n  Learning", "comments": "41 pages, 6 figures, submitted to the journal of Expert Systems with\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating asset-specific trading signals based on the financial conditions\nof the assets is one of the challenging problems in automated trading. Various\nasset trading rules are proposed experimentally based on different technical\nanalysis techniques. However, these kind of trading strategies are profitable,\nextracting new asset-specific trading rules from vast historical data to\nincrease total return and decrease the risk of portfolios is difficult for\nhuman experts. Recently, various deep reinforcement learning (DRL) methods are\nemployed to learn the new trading rules for each asset. In this paper, a novel\nDRL model with various feature extraction modules is proposed. The effect of\ndifferent input representations on the performance of the models is\ninvestigated and the performance of DRL-based models in different markets and\nasset situations is studied. The proposed model in this work outperformed the\nother state-of-the-art models in learning single asset-specific trading rules\nand obtained a total return of almost 262% in two years on a specific asset\nwhile the best state-of-the-art model get 78% on the same asset in the same\ntime period.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 10:59:53 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Taghian", "Mehran", ""], ["Asadi", "Ahmad", ""], ["Safabakhsh", "Reza", ""]]}, {"id": "2010.14202", "submitter": "Wenjie Ou", "authors": "Wenjie Ou, Yue Lin", "title": "A Clarifying Question Selection System from NTES_ALONG in Convai3\n  Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the participation of NetEase Game AI Lab team for the\nClariQ challenge at Search-oriented Conversational AI (SCAI) EMNLP workshop in\n2020. The challenge asks for a complete conversational information retrieval\nsystem that can understanding and generating clarification questions. We\npropose a clarifying question selection system which consists of response\nunderstanding, candidate question recalling and clarifying question ranking. We\nfine-tune a RoBERTa model to understand user's responses and use an enhanced\nBM25 model to recall the candidate questions. In clarifying question ranking\nstage, we reconstruct the training dataset and propose two models based on\nELECTRA. Finally we ensemble the models by summing up their output\nprobabilities and choose the question with the highest probability as the\nclarification question. Experiments show that our ensemble ranking model\noutperforms in the document relevance task and achieves the best recall@[20,30]\nmetrics in question relevance task. And in multi-turn conversation evaluation\nin stage2, our system achieve the top score of all document relevance metrics.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 11:22:53 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 11:11:55 GMT"}, {"version": "v3", "created": "Fri, 20 Nov 2020 04:19:33 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Ou", "Wenjie", ""], ["Lin", "Yue", ""]]}, {"id": "2010.14226", "submitter": "Gurpreet Singh", "authors": "Gurpreet Singh, Soumyajit Gupta, Matthew Lease, Clint Dawson", "title": "Range-Net: A High Precision Streaming SVD for Big Data Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.AI cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a Big Data setting computing the dominant SVD factors is restrictive due\nto the main memory requirements. Recently introduced streaming Randomized SVD\nschemes work under the restrictive assumption that the singular value spectrum\nof the data has exponential decay. This is seldom true for any practical data.\nAlthough these methods are claimed to be applicable to scientific computations\ndue to associated tail-energy error bounds, the approximation errors in the\nsingular vectors and values are high when the aforementioned assumption does\nnot hold. Furthermore from a practical perspective, oversampling can still be\nmemory intensive or worse can exceed the feature dimension of the data. To\naddress these issues, we present Range-Net as an alternative to randomized SVD\nthat satisfies the tail-energy lower bound given by Eckart-Young-Mirsky (EYM)\ntheorem. Range-Net is a deterministic two-stage neural optimization approach\nwith random initialization, where the main memory requirement depends\nexplicitly on the feature dimension and desired rank, independent of the sample\ndimension. The data samples are read in a streaming setting with the network\nminimization problem converging to the desired rank-r approximation. Range-Net\nis fully interpretable where all the network outputs and weights have a\nspecific meaning. We provide theoretical guarantees that Range-Net extracted\nSVD factors satisfy EYM tail-energy lower bound at machine precision. Our\nnumerical experiments on real data at various scales confirms this bound. A\ncomparison against the state of the art streaming Randomized SVD shows that\nRange-Net accuracy is better by six orders of magnitude while being memory\nefficient.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 15:42:59 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 20:41:31 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 18:16:45 GMT"}, {"version": "v4", "created": "Wed, 3 Mar 2021 01:30:04 GMT"}, {"version": "v5", "created": "Mon, 8 Mar 2021 15:50:46 GMT"}, {"version": "v6", "created": "Thu, 18 Mar 2021 18:46:17 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Singh", "Gurpreet", ""], ["Gupta", "Soumyajit", ""], ["Lease", "Matthew", ""], ["Dawson", "Clint", ""]]}, {"id": "2010.14227", "submitter": "Quanming Yao", "authors": "Yongqi Zhang and Quanming Yao and Lei Chen", "title": "Efficient, Simple and Automated Negative Sampling for Knowledge Graph\n  Embedding", "comments": "VLDB Journal accepted. arXiv admin note: text overlap with\n  arXiv:1812.06410", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negative sampling, which samples negative triplets from non-observed ones in\nknowledge graph (KG), is an essential step in KG embedding. Recently,\ngenerative adversarial network (GAN), has been introduced in negative sampling.\nBy sampling negative triplets with large gradients, these methods avoid the\nproblem of vanishing gradient and thus obtain better performance. However, they\nmake the original model more complex and harder to train. In this paper,\nmotivated by the observation that negative triplets with large gradients are\nimportant but rare, we propose to directly keep track of them with the cache.\nIn this way, our method acts as a \"distilled\" version of previous GAN-based\nmethods, which does not waste training time on additional parameters to fit the\nfull distribution of negative triplets. However, how to sample from and update\nthe cache are two critical questions. We propose to solve these issues by\nautomated machine learning techniques. The automated version also covers\nGAN-based methods as special cases. Theoretical explanation of NSCaching is\nalso provided, justifying the superior over fixed sampling scheme. Besides, we\nfurther extend NSCaching with skip-gram model for graph embedding. Finally,\nextensive experiments show that our method can gain significant improvements on\nvarious KG embedding models and the skip-gram model, and outperforms the\nstate-of-the-art negative sampling methods.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 14:16:35 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 01:52:43 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Zhang", "Yongqi", ""], ["Yao", "Quanming", ""], ["Chen", "Lei", ""]]}, {"id": "2010.14230", "submitter": "Yuhao Zhou", "authors": "Henry Zhou, Alexei Baevski and Michael Auli", "title": "A Comparison of Discrete Latent Variable Models for Speech\n  Representation Learning", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural latent variable models enable the discovery of interesting structure\nin speech audio data. This paper presents a comparison of two different\napproaches which are broadly based on predicting future time-steps or\nauto-encoding the input signal. Our study compares the representations learned\nby vq-vae and vq-wav2vec in terms of sub-word unit discovery and phoneme\nrecognition performance. Results show that future time-step prediction with\nvq-wav2vec achieves better performance. The best system achieves an error rate\nof 13.22 on the ZeroSpeech 2019 ABX phoneme discrimination challenge\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 01:22:14 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Zhou", "Henry", ""], ["Baevski", "Alexei", ""], ["Auli", "Michael", ""]]}, {"id": "2010.14235", "submitter": "Yao Lu", "authors": "Yao Lu, Yue Dong, Laurent Charlin", "title": "Multi-XScience: A Large-scale Dataset for Extreme Multi-document\n  Summarization of Scientific Articles", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-document summarization is a challenging task for which there exists\nlittle large-scale datasets. We propose Multi-XScience, a large-scale\nmulti-document summarization dataset created from scientific articles.\nMulti-XScience introduces a challenging multi-document summarization task:\nwriting the related-work section of a paper based on its abstract and the\narticles it references. Our work is inspired by extreme summarization, a\ndataset construction protocol that favours abstractive modeling approaches.\nDescriptive statistics and empirical results---using several state-of-the-art\nmodels trained on the Multi-XScience dataset---reveal that Multi-XScience is\nwell suited for abstractive models.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 12:10:19 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Lu", "Yao", ""], ["Dong", "Yue", ""], ["Charlin", "Laurent", ""]]}, {"id": "2010.14236", "submitter": "Pascal Friederich", "authors": "Pascal Friederich, Mario Krenn, Isaac Tamblyn, Alan Aspuru-Guzik", "title": "Scientific intuition inspired by machine learning generated hypotheses", "comments": null, "journal-ref": "Machine Learning: Science and Technology 2, 025027 (2021)", "doi": "10.1088/2632-2153/abda08", "report-no": null, "categories": "cs.LG cs.AI cs.CE physics.chem-ph quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning with application to questions in the physical sciences has\nbecome a widely used tool, successfully applied to classification, regression\nand optimization tasks in many areas. Research focus mostly lies in improving\nthe accuracy of the machine learning models in numerical predictions, while\nscientific understanding is still almost exclusively generated by human\nresearchers analysing numerical results and drawing conclusions. In this work,\nwe shift the focus on the insights and the knowledge obtained by the machine\nlearning models themselves. In particular, we study how it can be extracted and\nused to inspire human scientists to increase their intuitions and understanding\nof natural systems. We apply gradient boosting in decision trees to extract\nhuman interpretable insights from big data sets from chemistry and physics. In\nchemistry, we not only rediscover widely know rules of thumb but also find new\ninteresting motifs that tell us how to control solubility and energy levels of\norganic molecules. At the same time, in quantum physics, we gain new\nunderstanding on experiments for quantum entanglement. The ability to go beyond\nnumerics and to enter the realm of scientific insight and hypothesis generation\nopens the door to use machine learning to accelerate the discovery of\nconceptual understanding in some of the most challenging domains of science.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 12:12:12 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 18:31:14 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Friederich", "Pascal", ""], ["Krenn", "Mario", ""], ["Tamblyn", "Isaac", ""], ["Aspuru-Guzik", "Alan", ""]]}, {"id": "2010.14252", "submitter": "Ziyi Chen", "authors": "Ziyi Chen and Patrick De Causmaecker and Yajie Dou", "title": "Neural Networked Assisted Tree Search for the Personnel Rostering\n  Problem", "comments": "16 pages, 10 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The personnel rostering problem is the problem of finding an optimal way to\nassign employees to shifts, subject to a set of hard constraints which all\nvalid solutions must follow, and a set of soft constraints which define the\nrelative quality of valid solutions. The problem has received significant\nattention in the literature and is addressed by a large number of exact and\nmetaheuristic methods. In order to make the complex and costly design of\nheuristics for the personnel rostering problem automatic, we propose a new\nmethod combined Deep Neural Network and Tree Search. By treating schedules as\nmatrices, the neural network can predict the distance between the current\nsolution and the optimal solution. It can select solution strategies by\nanalyzing existing (near-)optimal solutions to personnel rostering problem\ninstances. Combined with branch and bound, the network can give every node a\nprobability which indicates the distance between it and the optimal one, so\nthat a well-informed choice can be made on which branch to choose next and to\nprune the search tree.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 22:23:20 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Chen", "Ziyi", ""], ["De Causmaecker", "Patrick", ""], ["Dou", "Yajie", ""]]}, {"id": "2010.14255", "submitter": "Jianing Wang", "authors": "Jianing Wang", "title": "RH-Net: Improving Neural Relation Extraction via Reinforcement Learning\n  and Hierarchical Relational Searching", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant supervision (DS) aims to generate large-scale heuristic labeling\ncorpus, which is widely used for neural relation extraction currently. However,\nit heavily suffers from noisy labeling and long-tail distributions problem.\nMany advanced approaches usually separately address two problems, which ignore\ntheir mutual interactions. In this paper, we propose a novel framework named\nRH-Net, which utilizes Reinforcement learning and Hierarchical relational\nsearching module to improve relation extraction. We leverage reinforcement\nlearning to instruct the model to select high-quality instances. We then\npropose the hierarchical relational searching module to share the semantics\nfrom correlative instances between data-rich and data-poor classes. During the\niterative process, the two modules keep interacting to alleviate the noisy and\nlong-tail problem simultaneously. Extensive experiments on widely used NYT data\nset clearly show that our method significant improvements over state-of-the-art\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 12:50:27 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 07:24:01 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Wang", "Jianing", ""]]}, {"id": "2010.14258", "submitter": "Christian H\\\"ager", "authors": "Christian H\\\"ager and Henry D. Pfister", "title": "Physics-Based Deep Learning for Fiber-Optic Communication Systems", "comments": "15 pages, 11 figures, submitted to IEEE J. Sel. Areas Commun., code\n  available at https://github.com/chaeger/LDBP, extension of\n  arXiv:1710.06234(1), arXiv:1804.02799(1), arXiv:1901.07592(2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new machine-learning approach for fiber-optic communication\nsystems whose signal propagation is governed by the nonlinear Schr\\\"odinger\nequation (NLSE). Our main observation is that the popular split-step method\n(SSM) for numerically solving the NLSE has essentially the same functional form\nas a deep multi-layer neural network; in both cases, one alternates linear\nsteps and pointwise nonlinearities. We exploit this connection by\nparameterizing the SSM and viewing the linear steps as general linear\nfunctions, similar to the weight matrices in a neural network. The resulting\nphysics-based machine-learning model has several advantages over \"black-box\"\nfunction approximators. For example, it allows us to examine and interpret the\nlearned solutions in order to understand why they perform well. As an\napplication, low-complexity nonlinear equalization is considered, where the\ntask is to efficiently invert the NLSE. This is commonly referred to as digital\nbackpropagation (DBP). Rather than employing neural networks, the proposed\nalgorithm, dubbed learned DBP (LDBP), uses the physics-based model with\ntrainable filters in each step and its complexity is reduced by progressively\npruning filter taps during gradient descent. Our main finding is that the\nfilters can be pruned to remarkably short lengths-as few as 3 taps/step-without\nsacrificing performance. As a result, the complexity can be reduced by orders\nof magnitude in comparison to prior work. By inspecting the filter responses,\nan additional theoretical justification for the learned parameter\nconfigurations is provided. Our work illustrates that combining data-driven\noptimization with existing domain knowledge can generate new insights into old\ncommunications problems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 12:55:23 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["H\u00e4ger", "Christian", ""], ["Pfister", "Henry D.", ""]]}, {"id": "2010.14260", "submitter": "Ekhine Irurozki", "authors": "Collas Fabien and Irurozki Ekhine", "title": "Concentric mixtures of Mallows models for top-$k$ rankings: sampling and\n  identifiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider mixtures of two Mallows models for top-$k$\nrankings, both with the same location parameter but with different scale\nparameters, i.e., a mixture of concentric Mallows models. This situation arises\nwhen we have a heterogeneous population of voters formed by two homogeneous\npopulations, one of which is a subpopulation of expert voters while the other\nincludes the non-expert voters. We propose efficient sampling algorithms for\nMallows top-$k$ rankings. We show the identifiability of both components, and\nthe learnability of their respective parameters in this setting by, first,\nbounding the sample complexity for the Borda algorithm with top-$k$ rankings\nand second, proposing polynomial time algorithm for the separation of the\nrankings in each component. Finally, since the rank aggregation will suffer\nfrom a large amount of noise introduced by the non-expert voters, we adapt the\nBorda algorithm to be able to recover the ground truth consensus ranking which\nis especially consistent with the expert rankings.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 13:00:37 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 10:59:28 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Fabien", "Collas", ""], ["Ekhine", "Irurozki", ""]]}, {"id": "2010.14265", "submitter": "Alexander Marx", "authors": "Alexander Marx, Arthur Gretton, Joris M. Mooij", "title": "A Weaker Faithfulness Assumption based on Triple Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the core assumptions in causal discovery is the faithfulness\nassumption---i.e. assuming that independencies found in the data are due to\nseparations in the true causal graph. This assumption can, however, be violated\nin many ways, including xor connections, deterministic functions or cancelling\npaths. In this work, we propose a weaker assumption that we call 2-adjacency\nfaithfulness. In contrast to adjacency faithfulness, which assumes that there\nis no conditional independence between each pair of variables that are\nconnected in the causal graph, we only require no conditional independence\nbetween a node and a subset of its Markov blanket that can contain up to two\nnodes. Equivalently, we adapt orientation faithfulness to this setting. We\nfurther propose a sound orientation rule for causal discovery that applies\nunder weaker assumptions. As a proof of concept, we derive a modified Grow and\nShrink algorithm that recovers the Markov blanket of a target node and prove\nits correctness under strictly weaker assumptions than the standard\nfaithfulness assumption.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 13:04:08 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Marx", "Alexander", ""], ["Gretton", "Arthur", ""], ["Mooij", "Joris M.", ""]]}, {"id": "2010.14271", "submitter": "Ming Gong", "authors": "Junhao Liu, Linjun Shou, Jian Pei, Ming Gong, Min Yang, Daxin Jiang", "title": "Cross-lingual Machine Reading Comprehension with Language Branch\n  Knowledge Distillation", "comments": "Accepted as long paper in COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual Machine Reading Comprehension (CLMRC) remains a challenging\nproblem due to the lack of large-scale annotated datasets in low-source\nlanguages, such as Arabic, Hindi, and Vietnamese. Many previous approaches use\ntranslation data by translating from a rich-source language, such as English,\nto low-source languages as auxiliary supervision. However, how to effectively\nleverage translation data and reduce the impact of noise introduced by\ntranslation remains onerous. In this paper, we tackle this challenge and\nenhance the cross-lingual transferring performance by a novel augmentation\napproach named Language Branch Machine Reading Comprehension (LBMRC). A\nlanguage branch is a group of passages in one single language paired with\nquestions in all target languages. We train multiple machine reading\ncomprehension (MRC) models proficient in individual language based on LBMRC.\nThen, we devise a multilingual distillation approach to amalgamate knowledge\nfrom multiple language branch models to a single model for all target\nlanguages. Combining the LBMRC and multilingual distillation can be more robust\nto the data noises, therefore, improving the model's cross-lingual ability.\nMeanwhile, the produced single multilingual model is applicable to all target\nlanguages, which saves the cost of training, inference, and maintenance for\nmultiple models. Extensive experiments on two CLMRC benchmarks clearly show the\neffectiveness of our proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 13:12:17 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Liu", "Junhao", ""], ["Shou", "Linjun", ""], ["Pei", "Jian", ""], ["Gong", "Ming", ""], ["Yang", "Min", ""], ["Jiang", "Daxin", ""]]}, {"id": "2010.14274", "submitter": "Dhruva Tirumala", "authors": "Dhruva Tirumala, Alexandre Galashov, Hyeonwoo Noh, Leonard\n  Hasenclever, Razvan Pascanu, Jonathan Schwarz, Guillaume Desjardins, Wojciech\n  Marian Czarnecki, Arun Ahuja, Yee Whye Teh, Nicolas Heess", "title": "Behavior Priors for Efficient Reinforcement Learning", "comments": "Submitted to Journal of Machine Learning Research (JMLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As we deploy reinforcement learning agents to solve increasingly challenging\nproblems, methods that allow us to inject prior knowledge about the structure\nof the world and effective solution strategies becomes increasingly important.\nIn this work we consider how information and architectural constraints can be\ncombined with ideas from the probabilistic modeling literature to learn\nbehavior priors that capture the common movement and interaction patterns that\nare shared across a set of related tasks or contexts. For example the day-to\nday behavior of humans comprises distinctive locomotion and manipulation\npatterns that recur across many different situations and goals. We discuss how\nsuch behavior patterns can be captured using probabilistic trajectory models\nand how these can be integrated effectively into reinforcement learning\nschemes, e.g.\\ to facilitate multi-task and transfer learning. We then extend\nthese ideas to latent variable models and consider a formulation to learn\nhierarchical priors that capture different aspects of the behavior in reusable\nmodules. We discuss how such latent variable formulations connect to related\nwork on hierarchical reinforcement learning (HRL) and mutual information and\ncuriosity based objectives, thereby offering an alternative perspective on\nexisting ideas. We demonstrate the effectiveness of our framework by applying\nit to a range of simulated continuous control domains.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 13:17:18 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Tirumala", "Dhruva", ""], ["Galashov", "Alexandre", ""], ["Noh", "Hyeonwoo", ""], ["Hasenclever", "Leonard", ""], ["Pascanu", "Razvan", ""], ["Schwarz", "Jonathan", ""], ["Desjardins", "Guillaume", ""], ["Czarnecki", "Wojciech Marian", ""], ["Ahuja", "Arun", ""], ["Teh", "Yee Whye", ""], ["Heess", "Nicolas", ""]]}, {"id": "2010.14282", "submitter": "Sundong Kim", "authors": "Sundong Kim and Tung-Duong Mai and Thi Nguyen Duc Khanh and Sungwon\n  Han and Sungwon Park and Karandeep Singh and Meeyoung Cha", "title": "Take a Chance: Managing the Exploitation-Exploration Dilemma in Customs\n  Fraud Detection via Online Active Learning", "comments": "10 pages, 10 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Continual labeling of training examples is a costly task in supervised\nlearning. Active learning strategies mitigate this cost by identifying\nunlabeled data that are considered the most useful for training a predictive\nmodel. However, sample selection via active learning may lead to an\nexploitation-exploration dilemma. In online settings, profitable items can be\nneglected when uncertain items are annotated instead. To illustrate this\ndilemma, we study a human-in-the-loop customs selection scenario where an\nAI-based system supports customs officers by providing a set of imports to be\ninspected. If the inspected items are fraud, officers levy extra duties, and\nthese items will be used as additional training data for the next iterations.\nInspecting highly suspicious items will inevitably lead to additional customs\nrevenue, yet they may not give any extra knowledge to customs officers. On the\nother hand, inspecting uncertain items will help customs officers to acquire\nnew knowledge, which will be used as supplementary training resources to update\ntheir selection systems. Through years of customs selection simulation, we show\nthat some exploration is needed to cope with the domain shift, and our hybrid\nstrategy of selecting fraud and uncertain items will eventually outperform the\nperformance of the exploitation strategy.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 13:31:31 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Kim", "Sundong", ""], ["Mai", "Tung-Duong", ""], ["Khanh", "Thi Nguyen Duc", ""], ["Han", "Sungwon", ""], ["Park", "Sungwon", ""], ["Singh", "Karandeep", ""], ["Cha", "Meeyoung", ""]]}, {"id": "2010.14289", "submitter": "Daniel Graves PhD", "authors": "Daniel Graves, Johannes G\\\"unther, Jun Luo", "title": "Affordance as general value function: A computational model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General value functions (GVFs) in the reinforcement learning (RL) literature\nare long-term predictive summaries of the outcomes of agents following specific\npolicies in the environment. Affordances as perceived action possibilities with\nspecific valence may be cast into predicted policy-relative goodness and\nmodelled as GVFs. A systematic explication of this connection shows that GVFs\nand especially their deep learning embodiments (1) realize affordance\nprediction as a form of direct perception, (2) illuminate the fundamental\nconnection between action and perception in affordance, and (3) offer a\nscalable way to learn affordances using RL methods. Through an extensive review\nof existing literature on GVF applications and representative affordance\nresearch in robotics, we demonstrate that GVFs provide the right framework for\nlearning affordances in real-world applications. In addition, we highlight a\nfew new avenues of research opened up by the perspective of \"affordance as\nGVF\", including using GVFs for orchestrating complex behaviors.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 13:42:58 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 01:54:32 GMT"}, {"version": "v3", "created": "Sat, 8 May 2021 00:15:11 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Graves", "Daniel", ""], ["G\u00fcnther", "Johannes", ""], ["Luo", "Jun", ""]]}, {"id": "2010.14296", "submitter": "Agnese Chiatti", "authors": "Agnese Chiatti, Enrico Motta, Enrico Daga, Gianluca Bardaro", "title": "Fit to Measure: Reasoning about Sizes for Robust Object Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Service robots can help with many of our daily tasks, especially in those\ncases where it is inconvenient or unsafe for us to intervene: e.g., under\nextreme weather conditions or when social distance needs to be maintained.\nHowever, before we can successfully delegate complex tasks to robots, we need\nto enhance their ability to make sense of dynamic, real world environments. In\nthis context, the first prerequisite to improving the Visual Intelligence of a\nrobot is building robust and reliable object recognition systems. While object\nrecognition solutions are traditionally based on Machine Learning methods,\naugmenting them with knowledge based reasoners has been shown to improve their\nperformance. In particular, based on our prior work on identifying the\nepistemic requirements of Visual Intelligence, we hypothesise that knowledge of\nthe typical size of objects could significantly improve the accuracy of an\nobject recognition system. To verify this hypothesis, in this paper we present\nan approach to integrating knowledge about object sizes in a ML based\narchitecture. Our experiments in a real world robotic scenario show that this\ncombined approach ensures a significant performance increase over state of the\nart Machine Learning methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 13:54:37 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Chiatti", "Agnese", ""], ["Motta", "Enrico", ""], ["Daga", "Enrico", ""], ["Bardaro", "Gianluca", ""]]}, {"id": "2010.14300", "submitter": "Manu Tom", "authors": "Manu Tom and Rajanie Prabha and Tianyu Wu and Emmanuel Baltsavias and\n  Laura Leal-Taixe and Konrad Schindler", "title": "Ice Monitoring in Swiss Lakes from Optical Satellites and Webcams using\n  Machine Learning", "comments": "Accepted for publication in MDPI Remote Sensing Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous observation of climate indicators, such as trends in lake\nfreezing, is important to understand the dynamics of the local and global\nclimate system. Consequently, lake ice has been included among the Essential\nClimate Variables (ECVs) of the Global Climate Observing System (GCOS), and\nthere is a need to set up operational monitoring capabilities. Multi-temporal\nsatellite images and publicly available webcam streams are among the viable\ndata sources to monitor lake ice. In this work we investigate machine\nlearning-based image analysis as a tool to determine the spatio-temporal extent\nof ice on Swiss Alpine lakes as well as the ice-on and ice-off dates, from both\nmultispectral optical satellite images (VIIRS and MODIS) and RGB webcam images.\nWe model lake ice monitoring as a pixel-wise semantic segmentation problem,\ni.e., each pixel on the lake surface is classified to obtain a spatially\nexplicit map of ice cover. We show experimentally that the proposed system\nproduces consistently good results when tested on data from multiple winters\nand lakes. Our satellite-based method obtains mean Intersection-over-Union\n(mIoU) scores >93%, for both sensors. It also generalises well across lakes and\nwinters with mIoU scores >78% and >80% respectively. On average, our webcam\napproach achieves mIoU values of 87% (approx.) and generalisation scores of 71%\n(approx.) and 69% (approx.) across different cameras and winters respectively.\nAdditionally, we put forward a new benchmark dataset of webcam images\n(Photi-LakeIce) which includes data from two winters and three cameras.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 14:02:00 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Tom", "Manu", ""], ["Prabha", "Rajanie", ""], ["Wu", "Tianyu", ""], ["Baltsavias", "Emmanuel", ""], ["Leal-Taixe", "Laura", ""], ["Schindler", "Konrad", ""]]}, {"id": "2010.14322", "submitter": "Oliver Hinder", "authors": "Rudy Bunel, Oliver Hinder, Srinadh Bhojanapalli, Krishnamurthy (Dj)\n  Dvijotham", "title": "An efficient nonconvex reformulation of stagewise convex optimization\n  problems", "comments": "First and second authors made equal contribution. To appear in\n  Neurips 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convex optimization problems with staged structure appear in several\ncontexts, including optimal control, verification of deep neural networks, and\nisotonic regression. Off-the-shelf solvers can solve these problems but may\nscale poorly. We develop a nonconvex reformulation designed to exploit this\nstaged structure. Our reformulation has only simple bound constraints, enabling\nsolution via projected gradient methods and their accelerated variants. The\nmethod automatically generates a sequence of primal and dual feasible solutions\nto the original convex problem, making optimality certification easy. We\nestablish theoretical properties of the nonconvex formulation, showing that it\nis (almost) free of spurious local minima and has the same global optimum as\nthe convex problem. We modify PGD to avoid spurious local minimizers so it\nalways converges to the global minimizer. For neural network verification, our\napproach obtains small duality gaps in only a few gradient steps. Consequently,\nit can quickly solve large-scale verification problems faster than both\noff-the-shelf and specialized solvers.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 14:30:32 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Bunel", "Rudy", "", "Dj"], ["Hinder", "Oliver", "", "Dj"], ["Bhojanapalli", "Srinadh", "", "Dj"], ["Krishnamurthy", "", "", "Dj"], ["Dvijotham", "", ""]]}, {"id": "2010.14353", "submitter": "Julian B\\\"uchel", "authors": "Julian B\\\"uchel, Jonathan Kakon, Michel Perez, Giacomo Indiveri", "title": "Implementing efficient balanced networks with mixed-signal spike-based\n  learning circuits", "comments": "5 pages, 6 figures. Accepted at IEEE International Symposium on\n  Circuits and Systems 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient Balanced Networks (EBNs) are networks of spiking neurons in which\nexcitatory and inhibitory synaptic currents are balanced on a short timescale,\nleading to desirable coding properties such as high encoding precision, low\nfiring rates, and distributed information representation. It is for these\nbenefits that it would be desirable to implement such networks in low-power\nneuromorphic processors. However, the degree of device mismatch in analog\nmixed-signal neuromorphic circuits renders the use of pre-trained EBNs\nchallenging, if not impossible. To overcome this issue, we developed a novel\nlocal learning rule suitable for on-chip implementation that drives a randomly\nconnected network of spiking neurons into a tightly balanced regime. Here we\npresent the integrated circuits that implement this rule and demonstrate their\nexpected behaviour in low-level circuit simulations. Our proposed method paves\nthe way towards a system-level implementation of tightly balanced networks on\nanalog mixed-signal neuromorphic hardware. Thanks to their coding properties\nand sparse activity, neuromorphic electronic EBNs will be ideally suited for\nextreme-edge computing applications that require low-latency, ultra-low power\nconsumption and which cannot rely on cloud computing for data processing.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 15:05:51 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 09:26:16 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["B\u00fcchel", "Julian", ""], ["Kakon", "Jonathan", ""], ["Perez", "Michel", ""], ["Indiveri", "Giacomo", ""]]}, {"id": "2010.14374", "submitter": "Kasun Amarasinghe", "authors": "Kasun Amarasinghe, Kit Rodolfa, Hemank Lamba, Rayid Ghani", "title": "Explainable Machine Learning for Public Policy: Use Cases, Gaps, and\n  Research Directions", "comments": "Submitted for review at Communications of the ACM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability is a crucial requirement for effectiveness as well as the\nadoption of Machine Learning (ML) models supporting decisions in high-stakes\npublic policy areas such as health, criminal justice, education, and\nemployment, While the field of explainable has expanded in recent years, much\nof this work has not taken real-world needs into account. A majority of\nproposed methods use benchmark datasets with generic explainability goals\nwithout clear use-cases or intended end-users. As a result, the applicability\nand effectiveness of this large body of theoretical and methodological work on\nreal-world applications is unclear. This paper focuses on filling this void for\nthe domain of public policy. We develop a taxonomy of explainability use-cases\nwithin public policy problems; for each use-case, we define the end-users of\nexplanations and the specific goals explainability has to fulfill; third, we\nmap existing work to these use-cases, identify gaps, and propose research\ndirections to fill those gaps in order to have a practical societal impact\nthrough ML.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 15:37:00 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 23:52:46 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Amarasinghe", "Kasun", ""], ["Rodolfa", "Kit", ""], ["Lamba", "Hemank", ""], ["Ghani", "Rayid", ""]]}, {"id": "2010.14376", "submitter": "Oliver Niggemann", "authors": "Oliver Niggemann and Alexander Diedrich and Christian Kuehnert and\n  Erik Pfannstiel and Joshua Schraven", "title": "The DigitalTwin from an Artificial Intelligence Perspective", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Services for Cyber-Physical Systems based on Artificial Intelligence and\nMachine Learning require a virtual representation of the physical. To reduce\nmodeling efforts and to synchronize results, for each system, a common and\nunique virtual representation used by all services during the whole system\nlife-cycle is needed, i.e. a DigitalTwin. In this paper such a DigitalTwin,\nnamely the AI reference model AITwin, is defined. This reference model is\nverified by using a running example from process industry and by analyzing the\nwork done in recent projects.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 15:40:36 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Niggemann", "Oliver", ""], ["Diedrich", "Alexander", ""], ["Kuehnert", "Christian", ""], ["Pfannstiel", "Erik", ""], ["Schraven", "Joshua", ""]]}, {"id": "2010.14388", "submitter": "Alun Preece", "authors": "Katie Barrett-Powell, Jack Furby, Liam Hiley, Marc Roig Vilamala,\n  Harrison Taylor, Federico Cerutti, Alun Preece, Tianwei Xing, Luis Garcia,\n  Mani Srivastava, Dave Braines", "title": "An Experimentation Platform for Explainable Coalition Situational\n  Understanding", "comments": "Presented at AAAI FSS-20: Artificial Intelligence in Government and\n  Public Sector, Washington, DC, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an experimentation platform for coalition situational\nunderstanding research that highlights capabilities in explainable artificial\nintelligence/machine learning (AI/ML) and integration of symbolic and\nsubsymbolic AI/ML approaches for event processing. The Situational\nUnderstanding Explorer (SUE) platform is designed to be lightweight, to easily\nfacilitate experiments and demonstrations, and open. We discuss our\nrequirements to support coalition multi-domain operations with emphasis on\nasset interoperability and ad hoc human-machine teaming in a dense urban\nterrain setting. We describe the interface functionality and give examples of\nSUE applied to coalition situational understanding tasks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 15:51:27 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 16:01:15 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Barrett-Powell", "Katie", ""], ["Furby", "Jack", ""], ["Hiley", "Liam", ""], ["Vilamala", "Marc Roig", ""], ["Taylor", "Harrison", ""], ["Cerutti", "Federico", ""], ["Preece", "Alun", ""], ["Xing", "Tianwei", ""], ["Garcia", "Luis", ""], ["Srivastava", "Mani", ""], ["Braines", "Dave", ""]]}, {"id": "2010.14391", "submitter": "Sai Qian Zhang", "authors": "Sai Qian Zhang, Jieyu Lin, Qi Zhang", "title": "Succinct and Robust Multi-Agent Communication With Temporal Message\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that introducing communication between agents can\nsignificantly improve overall performance in cooperative Multi-agent\nreinforcement learning (MARL). However, existing communication schemes often\nrequire agents to exchange an excessive number of messages at run-time under a\nreliable communication channel, which hinders its practicality in many\nreal-world situations. In this paper, we present \\textit{Temporal Message\nControl} (TMC), a simple yet effective approach for achieving succinct and\nrobust communication in MARL. TMC applies a temporal smoothing technique to\ndrastically reduce the amount of information exchanged between agents.\nExperiments show that TMC can significantly reduce inter-agent communication\noverhead without impacting accuracy. Furthermore, TMC demonstrates much better\nrobustness against transmission loss than existing approaches in lossy\nnetworking environments.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 15:55:08 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 23:04:40 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Zhang", "Sai Qian", ""], ["Lin", "Jieyu", ""], ["Zhang", "Qi", ""]]}, {"id": "2010.14407", "submitter": "Andrea Dittadi", "authors": "Andrea Dittadi, Frederik Tr\\\"auble, Francesco Locatello, Manuel\n  W\\\"uthrich, Vaibhav Agrawal, Ole Winther, Stefan Bauer, Bernhard Sch\\\"olkopf", "title": "On the Transfer of Disentangled Representations in Realistic Settings", "comments": "Published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning meaningful representations that disentangle the underlying structure\nof the data generating process is considered to be of key importance in machine\nlearning. While disentangled representations were found to be useful for\ndiverse tasks such as abstract reasoning and fair classification, their\nscalability and real-world impact remain questionable. We introduce a new\nhigh-resolution dataset with 1M simulated images and over 1,800 annotated\nreal-world images of the same setup. In contrast to previous work, this new\ndataset exhibits correlations, a complex underlying structure, and allows to\nevaluate transfer to unseen simulated and real-world settings where the encoder\ni) remains in distribution or ii) is out of distribution. We propose new\narchitectures in order to scale disentangled representation learning to\nrealistic high-resolution settings and conduct a large-scale empirical study of\ndisentangled representations on this dataset. We observe that disentanglement\nis a good predictor for out-of-distribution (OOD) task performance.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 16:15:24 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 11:43:10 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Dittadi", "Andrea", ""], ["Tr\u00e4uble", "Frederik", ""], ["Locatello", "Francesco", ""], ["W\u00fcthrich", "Manuel", ""], ["Agrawal", "Vaibhav", ""], ["Winther", "Ole", ""], ["Bauer", "Stefan", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2010.14439", "submitter": "Bill Yuchen Lin", "authors": "Bill Yuchen Lin, Haitian Sun, Bhuwan Dhingra, Manzil Zaheer, Xiang\n  Ren, William W. Cohen", "title": "Differentiable Open-Ended Commonsense Reasoning", "comments": "Accepted to NAACL 2021. Project website: https://open-csr.github.io", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current commonsense reasoning research focuses on developing models that use\ncommonsense knowledge to answer multiple-choice questions. However, systems\ndesigned to answer multiple-choice questions may not be useful in applications\nthat do not provide a small list of candidate answers to choose from. As a step\ntowards making commonsense reasoning research more realistic, we propose to\nstudy open-ended commonsense reasoning (OpenCSR) -- the task of answering a\ncommonsense question without any pre-defined choices -- using as a resource\nonly a corpus of commonsense facts written in natural language. OpenCSR is\nchallenging due to a large decision space, and because many questions require\nimplicit multi-hop reasoning. As an approach to OpenCSR, we propose DrFact, an\nefficient Differentiable model for multi-hop Reasoning over knowledge Facts. To\nevaluate OpenCSR methods, we adapt several popular commonsense reasoning\nbenchmarks, and collect multiple new answers for each test question via\ncrowd-sourcing. Experiments show that DrFact outperforms strong baseline\nmethods by a large margin.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 10:07:00 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 20:20:27 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Lin", "Bill Yuchen", ""], ["Sun", "Haitian", ""], ["Dhingra", "Bhuwan", ""], ["Zaheer", "Manzil", ""], ["Ren", "Xiang", ""], ["Cohen", "William W.", ""]]}, {"id": "2010.14443", "submitter": "Ufuk Topcu", "authors": "Ufuk Topcu, Nadya Bliss, Nancy Cooke, Missy Cummings, Ashley Llorens,\n  Howard Shrobe, and Lenore Zuck", "title": "Assured Autonomy: Path Toward Living With Autonomous Systems We Can\n  Trust", "comments": "A Computing Community Consortium (CCC) workshop report, 28 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020report_5", "categories": "cs.CY cs.AI cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The challenge of establishing assurance in autonomy is rapidly attracting\nincreasing interest in the industry, government, and academia. Autonomy is a\nbroad and expansive capability that enables systems to behave without direct\ncontrol by a human operator. To that end, it is expected to be present in a\nwide variety of systems and applications. A vast range of industrial sectors,\nincluding (but by no means limited to) defense, mobility, health care,\nmanufacturing, and civilian infrastructure, are embracing the opportunities in\nautonomy yet face the similar barriers toward establishing the necessary level\nof assurance sooner or later. Numerous government agencies are poised to tackle\nthe challenges in assured autonomy.\n  Given the already immense interest and investment in autonomy, a series of\nworkshops on Assured Autonomy was convened to facilitate dialogs and increase\nawareness among the stakeholders in the academia, industry, and government.\nThis series of three workshops aimed to help create a unified understanding of\nthe goals for assured autonomy, the research trends and needs, and a strategy\nthat will facilitate sustained progress in autonomy.\n  The first workshop, held in October 2019, focused on current and anticipated\nchallenges and problems in assuring autonomous systems within and across\napplications and sectors. The second workshop held in February 2020, focused on\nexisting capabilities, current research, and research trends that could address\nthe challenges and problems identified in workshop. The third event was\ndedicated to a discussion of a draft of the major findings from the previous\ntwo workshops and the recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 17:00:01 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Topcu", "Ufuk", ""], ["Bliss", "Nadya", ""], ["Cooke", "Nancy", ""], ["Cummings", "Missy", ""], ["Llorens", "Ashley", ""], ["Shrobe", "Howard", ""], ["Zuck", "Lenore", ""]]}, {"id": "2010.14448", "submitter": "Xavier Ferrer Aran", "authors": "Xavier Ferrer-Aran, Tom van Nuenen, Natalia Criado, Jose M. Such", "title": "Discovering and Interpreting Conceptual Biases in Online Communities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language carries implicit human biases, functioning both as a reflection and\na perpetuation of stereotypes that people carry with them. Recently, ML-based\nNLP methods such as word embeddings have been shown to learn such language\nbiases with striking accuracy. This capability of word embeddings has been\nsuccessfully exploited as a tool to quantify and study human biases. However,\nprevious studies only consider a predefined set of conceptual biases to attest\n(e.g., whether gender is more or less associated with particular jobs), or just\ndiscover biased words without helping to understand their meaning at the\nconceptual level. As such, these approaches are either unable to find\nconceptual biases that have not been defined in advance, or the biases they\nfind are difficult to interpret and study. This makes existing approaches\nunsuitable to discover and interpret biases in online communities, as such\ncommunities may carry different biases than those in mainstream culture. This\npaper proposes a general, data-driven approach to automatically discover and\nhelp interpret conceptual biases encoded in word embeddings. We apply this\napproach to study the conceptual biases present in the language used in online\ncommunities and experimentally show the validity and stability of our method.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 17:07:12 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Ferrer-Aran", "Xavier", ""], ["van Nuenen", "Tom", ""], ["Criado", "Natalia", ""], ["Such", "Jose M.", ""]]}, {"id": "2010.14476", "submitter": "Maruf Ahmed Dhali", "authors": "Mladen Popovi\\'c, Maruf A. Dhali, Lambert Schomaker", "title": "Artificial intelligence based writer identification generates new\n  evidence for the unknown scribes of the Dead Sea Scrolls exemplified by the\n  Great Isaiah Scroll (1QIsaa)", "comments": "23 pages, 15 pages of supplementary materials, submitted to PLOS ONE\n  on 19 October 2019", "journal-ref": "PLoS ONE 2021", "doi": "10.1371/journal.pone.0249769", "report-no": "PLoS ONE 16(4): e0249769", "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dead Sea Scrolls are tangible evidence of the Bible's ancient scribal\nculture. Palaeography - the study of ancient handwriting - can provide access\nto this scribal culture. However, one of the problems of traditional\npalaeography is to determine writer identity when the writing style is near\nuniform. This is exemplified by the Great Isaiah Scroll (1QIsaa). To this end,\nwe used pattern recognition and artificial intelligence techniques to innovate\nthe palaeography of the scrolls regarding writer identification and to pioneer\nthe microlevel of individual scribes to open access to the Bible's ancient\nscribal culture. Although many scholars believe that 1QIsaa was written by one\nscribe, we report new evidence for a breaking point in the series of columns in\nthis scroll. Without prior assumption of writer identity, based on point clouds\nof the reduced-dimensionality feature-space, we found that columns from the\nfirst and second halves of the manuscript ended up in two distinct zones of\nsuch scatter plots, notably for a range of digital palaeography tools, each\naddressing very different featural aspects of the script samples. In a\nsecondary, independent, analysis, now assuming writer difference and using yet\nanother independent feature method and several different types of statistical\ntesting, a switching point was found in the column series. A clear phase\ntransition is apparent around column 27. Given the statistically significant\ndifferences between the two halves, a tertiary, post-hoc analysis was\nperformed. Demonstrating that two main scribes were responsible for the Great\nIsaiah Scroll, this study sheds new light on the Bible's ancient scribal\nculture by providing new, tangible evidence that ancient biblical texts were\nnot copied by a single scribe only but that multiple scribes could closely\ncollaborate on one particular manuscript.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 17:36:18 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Popovi\u0107", "Mladen", ""], ["Dhali", "Maruf A.", ""], ["Schomaker", "Lambert", ""]]}, {"id": "2010.14479", "submitter": "Sugat Chaturvedi", "authors": "Rochana Chaturvedi, Sugat Chaturvedi", "title": "It's All in the Name: A Character Based Approach To Infer Religion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demographic inference from text has received a surge of attention in the\nfield of natural language processing in the last decade. In this paper, we use\npersonal names to infer religion in South Asia - where religion is a salient\nsocial division, and yet, disaggregated data on it remains scarce. Existing\nwork predicts religion using dictionary based method, and therefore, can not\nclassify unseen names. We use character based models which learn character\npatterns and, therefore, can classify unseen names as well with high accuracy.\nThese models are also much faster and can easily be scaled to large data sets.\nWe improve our classifier by combining the name of an individual with that of\ntheir parent/spouse and achieve remarkably high accuracy. Finally, we trace the\nclassification decisions of a convolutional neural network model using\nlayer-wise relevance propagation which can explain the predictions of complex\nnon-linear classifiers and circumvent their purported black box nature. We show\nhow character patterns learned by the classifier are rooted in the linguistic\norigins of names.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 17:38:11 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Chaturvedi", "Rochana", ""], ["Chaturvedi", "Sugat", ""]]}, {"id": "2010.14496", "submitter": "Michael Janner", "authors": "Michael Janner, Igor Mordatch, Sergey Levine", "title": "$\\gamma$-Models: Generative Temporal Difference Learning for\n  Infinite-Horizon Prediction", "comments": "NeurIPS 2020. Project page at:\n  https://people.eecs.berkeley.edu/~janner/gamma-models/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the $\\gamma$-model, a predictive model of environment dynamics\nwith an infinite probabilistic horizon. Replacing standard single-step models\nwith $\\gamma$-models leads to generalizations of the procedures central to\nmodel-based control, including the model rollout and model-based value\nestimation. The $\\gamma$-model, trained with a generative reinterpretation of\ntemporal difference learning, is a natural continuous analogue of the successor\nrepresentation and a hybrid between model-free and model-based mechanisms. Like\na value function, it contains information about the long-term future; like a\nstandard predictive model, it is independent of task reward. We instantiate the\n$\\gamma$-model as both a generative adversarial network and normalizing flow,\ndiscuss how its training reflects an inescapable tradeoff between training-time\nand testing-time compounding errors, and empirically investigate its utility\nfor prediction and control.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 17:54:12 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 03:58:47 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Janner", "Michael", ""], ["Mordatch", "Igor", ""], ["Levine", "Sergey", ""]]}, {"id": "2010.14497", "submitter": "Homanga Bharadhwaj", "authors": "Homanga Bharadhwaj, Aviral Kumar, Nicholas Rhinehart, Sergey Levine,\n  Florian Shkurti, Animesh Garg", "title": "Conservative Safety Critics for Exploration", "comments": "Published as a conference paper in ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safe exploration presents a major challenge in reinforcement learning (RL):\nwhen active data collection requires deploying partially trained policies, we\nmust ensure that these policies avoid catastrophically unsafe regions, while\nstill enabling trial and error learning. In this paper, we target the problem\nof safe exploration in RL by learning a conservative safety estimate of\nenvironment states through a critic, and provably upper bound the likelihood of\ncatastrophic failures at every training iteration. We theoretically\ncharacterize the tradeoff between safety and policy improvement, show that the\nsafety constraints are likely to be satisfied with high probability during\ntraining, derive provable convergence guarantees for our approach, which is no\nworse asymptotically than standard RL, and demonstrate the efficacy of the\nproposed approach on a suite of challenging navigation, manipulation, and\nlocomotion tasks. Empirically, we show that the proposed approach can achieve\ncompetitive task performance while incurring significantly lower catastrophic\nfailure rates during training than prior methods. Videos are at this url\nhttps://sites.google.com/view/conservative-safety-critics/home\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 17:54:25 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 17:38:23 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Bharadhwaj", "Homanga", ""], ["Kumar", "Aviral", ""], ["Rhinehart", "Nicholas", ""], ["Levine", "Sergey", ""], ["Shkurti", "Florian", ""], ["Garg", "Animesh", ""]]}, {"id": "2010.14616", "submitter": "Zeyu Zhang", "authors": "Zeyu Zhang, Guisheng Yin", "title": "Lineage Evolution Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general agent population learning system, and on this basis, we\npropose lineage evolution reinforcement learning algorithm. Lineage evolution\nreinforcement learning is a kind of derivative algorithm which accords with the\ngeneral agent population learning system. We take the agents in DQN and its\nrelated variants as the basic agents in the population, and add the selection,\nmutation and crossover modules in the genetic algorithm to the reinforcement\nlearning algorithm. In the process of agent evolution, we refer to the\ncharacteristics of natural genetic behavior, add lineage factor to ensure the\nretention of potential performance of agent, and comprehensively consider the\ncurrent performance and lineage value when evaluating the performance of agent.\nWithout changing the parameters of the original reinforcement learning\nalgorithm, lineage evolution reinforcement learning can optimize different\nreinforcement learning algorithms. Our experiments show that the idea of\nevolution with lineage improves the performance of original reinforcement\nlearning algorithm in some games in Atari 2600.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 11:58:16 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Zhang", "Zeyu", ""], ["Yin", "Guisheng", ""]]}, {"id": "2010.14617", "submitter": "Yifei Mao", "authors": "Yifei Mao", "title": "From Artificial Intelligence to Brain Intelligence: The basis learning\n  and memory algorithm for brain-like intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The algorithm of brain learning and memory is still undetermined. The\nbackpropagation algorithm of artificial neural networks was thought not\nsuitable for brain cortex, and there is a lack of algorithm for memory engram.\nWe designed a brain version of backpropagation algorithm, which are\nbiologically plausible and could be implemented with virtual neurons to\ncomplete image classification task. An encoding algorithm that can\nautomatically allocate engram cells is proposed, which is an algorithm\nimplementation for memory engram theory, and could simulate how hippocampus\nachieve fast associative memory. The role of the LTP and LTD in the cerebellum\nis also explained in algorithm level. Our results proposed a method for the\nbrain to deploy backpropagation algorithm, and sparse coding method for memory\nengram theory.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 14:25:05 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Mao", "Yifei", ""]]}, {"id": "2010.14618", "submitter": "David Powers", "authors": "David M W Powers", "title": "A computationally and cognitively plausible model of supervised and\n  unsupervised learning", "comments": "12 pages, 2 figures, 24 references. Amended version of paper\n  presented at BICS 2013", "journal-ref": "International Conference on Brain Inspired Cognitive Systems 2013,\n  pp. 145-156", "doi": null, "report-no": null, "categories": "cs.NE cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both empirical and mathematical demonstrations of the importance of\nchance-corrected measures are discussed, and a new model of learning is\nproposed based on empirical psychological results on association learning. Two\nforms of this model are developed, the Informatron as a chance-corrected\nPerceptron, and AdaBook as a chance-corrected AdaBoost procedure. Computational\nresults presented show chance correction facilitates learning.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 00:31:27 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Powers", "David M W", ""]]}, {"id": "2010.14619", "submitter": "Georgiana Neculae", "authors": "Georgiana Neculae and Gavin Brown", "title": "Ensembles of Spiking Neural Networks", "comments": "12 pages, 3 tables, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates that ensembles of spiking neural networks can be\nconstructed so that the ensemble performance is guaranteed to be better than\nthe average performance of a single model. Spiking neural networks have not\nchallenged the performance obtained by conventional neural networks on the same\nproblems. Ensemble learning is a framework that has been used extensively to\nimprove the performance of machine learning models. In this paper, we show how\nto construct ensembles of spiking neural networks that both produce\nstate-of-the-art results, and achieve this with less than 50% of the parameters\nof the original models. We establish the methodology on combining model\npredictions such that performance improvements are guaranteed for spiking\nensembles. For this, we formalize spiking neural networks as GLM predictors,\nidentifying a suitable representation for their target domain. Further, we show\nhow the diversity of our spiking ensembles can be measured using the Ambiguity\nDecomposition.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 17:45:18 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Neculae", "Georgiana", ""], ["Brown", "Gavin", ""]]}, {"id": "2010.14620", "submitter": "Divya Padmanabhan", "authors": "Louis Chen, Divya Padmanabhan, Chee Chin Lim, Karthik Natarajan", "title": "Correlation Robust Influence Maximization", "comments": null, "journal-ref": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a distributionally robust model for the influence maximization\nproblem. Unlike the classic independent cascade model\n\\citep{kempe2003maximizing}, this model's diffusion process is adversarially\nadapted to the choice of seed set. Hence, instead of optimizing under the\nassumption that all influence relationships in the network are independent, we\nseek a seed set whose expected influence under the worst correlation, i.e. the\n\"worst-case, expected influence\", is maximized. We show that this worst-case\ninfluence can be efficiently computed, and though the optimization is NP-hard,\na ($1 - 1/e$) approximation guarantee holds. We also analyze the structure to\nthe adversary's choice of diffusion process, and contrast with established\nmodels. Beyond the key computational advantages, we also highlight the extent\nto which the independence assumption may cost optimality, and provide insights\nfrom numerical experiments comparing the adversarial and independent cascade\nmodel.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 04:43:56 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Chen", "Louis", ""], ["Padmanabhan", "Divya", ""], ["Lim", "Chee Chin", ""], ["Natarajan", "Karthik", ""]]}, {"id": "2010.14624", "submitter": "Gourab K Patro", "authors": "Gourab K Patro, Abhijnan Chakraborty, Niloy Ganguly, Krishna P.\n  Gummadi", "title": "On Fair Virtual Conference Scheduling: Achieving Equitable Participant\n  and Speaker Satisfaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The (COVID-19) pandemic-induced restrictions on travel and social gatherings\nhave prompted most conference organizers to move their events online. However,\nin contrast to physical conferences, virtual conferences face a challenge in\nefficiently scheduling talks, accounting for the availability of participants\nfrom different time-zones as well as their interests in attending different\ntalks. In such settings, a natural objective for the conference organizers\nwould be to maximize some global welfare measure, such as the total expected\naudience participation across all talks. However, we show that optimizing for\nglobal welfare could result in a schedule that is unfair to the stakeholders,\ni.e., the individual utilities for participants and speakers can be highly\nunequal. To address the fairness concerns, we formally define fairness notions\nfor participants and speakers, and subsequently derive suitable fairness\nobjectives for them. We show that the welfare and fairness objectives can be in\nconflict with each other, and there is a need to maintain a balance between\nthese objective while caring for them simultaneously. Thus, we propose a joint\noptimization framework that allows conference organizers to design talk\nschedules that balance (i.e., allow trade-offs) between global welfare,\nparticipant fairness and the speaker fairness objectives. We show that the\noptimization problem can be solved using integer linear programming, and\nempirically evaluate the necessity and benefits of such joint optimization\napproach in virtual conference scheduling.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 15:05:12 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Patro", "Gourab K", ""], ["Chakraborty", "Abhijnan", ""], ["Ganguly", "Niloy", ""], ["Gummadi", "Krishna P.", ""]]}, {"id": "2010.14641", "submitter": "Tim Seyde", "authors": "Tim Seyde, Wilko Schwarting, Sertac Karaman, Daniela Rus", "title": "Learning to Plan Optimistically: Uncertainty-Guided Deep Exploration via\n  Latent Model Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning complex behaviors through interaction requires coordinated long-term\nplanning. Random exploration and novelty search lack task-centric guidance and\nwaste effort on non-informative interactions. Instead, decision making should\ntarget samples with the potential to optimize performance far into the future,\nwhile only reducing uncertainty where conducive to this objective. This paper\npresents latent optimistic value exploration (LOVE), a strategy that enables\ndeep exploration through optimism in the face of uncertain long-term rewards.\nWe combine finite horizon rollouts from a latent model with value function\nestimates to predict infinite horizon returns and recover associated\nuncertainty through ensembling. Policy training then proceeds on an upper\nconfidence bound (UCB) objective to identify and select the interactions most\npromising to improve long-term performance. We apply LOVE to visual control\ntasks in continuous state-action spaces and demonstrate improved sample\ncomplexity on a selection of benchmarking tasks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 22:06:57 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 09:02:23 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Seyde", "Tim", ""], ["Schwarting", "Wilko", ""], ["Karaman", "Sertac", ""], ["Rus", "Daniela", ""]]}, {"id": "2010.14648", "submitter": "Mohammad Abdulaziz", "authors": "Mohammad Abdulaziz and Friedrich Kurz", "title": "Formally Verified SAT-Based AI Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an executable formally verified SAT encoding of classical AI\nplanning. We use the theorem prover Isabelle/HOL to perform the verification.\nWe experimentally test the verified encoding and show that it can be used for\nreasonably sized standard planning benchmarks. We also use it as a reference to\ntest a state-of-the-art SAT-based planner, showing that it sometimes falsely\nclaims that problems have no solutions of certain lengths.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 22:23:04 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 12:19:38 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 09:43:28 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 18:21:00 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Abdulaziz", "Mohammad", ""], ["Kurz", "Friedrich", ""]]}, {"id": "2010.14649", "submitter": "Takashi Wada", "authors": "Takashi Wada, Tomoharu Iwata, Yuji Matsumoto, Timothy Baldwin, Jey Han\n  Lau", "title": "Learning Contextualised Cross-lingual Word Embeddings for Extremely\n  Low-Resource Languages Using Parallel Corpora", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach for learning contextualised cross-lingual word\nembeddings based only on a small parallel corpus (e.g. a few hundred sentence\npairs). Our method obtains word embeddings via an LSTM-based encoder-decoder\nmodel that performs bidirectional translation and reconstruction of the input\nsentence. Through sharing model parameters among different languages, our model\njointly trains the word embeddings in a common multilingual space. We also\npropose a simple method to combine word and subword embeddings to make use of\northographic similarities across different languages. We base our experiments\non real-world data from endangered languages, namely Yongning Na,\nShipibo-Konibo and Griko. Our experiments on bilingual lexicon induction and\nword alignment tasks show that our model outperforms existing methods by a\nlarge margin for most language pairs. These results demonstrate that, contrary\nto common belief, an encoder-decoder translation model is beneficial for\nlearning cross-lingual representations, even in extremely low-resource\nscenarios.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 22:24:01 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Wada", "Takashi", ""], ["Iwata", "Tomoharu", ""], ["Matsumoto", "Yuji", ""], ["Baldwin", "Timothy", ""], ["Lau", "Jey Han", ""]]}, {"id": "2010.14654", "submitter": "Luis Duarte", "authors": "Luis Duarte, Jonathan Torres, Vitor Ribeiro, In\\^es Moreira", "title": "Artificial Intelligence Systems applied to tourism: A Survey", "comments": "bad content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Artificial Intelligence (AI) has been improving the performance of systems\nfor a diverse set of tasks and introduced a more interactive generation of\npersonal agents. Despite the current trend of applying AI for a great amount of\nareas, we have not seen the same quantity of work being developed for the\ntourism sector. This paper reports on the main applications of AI systems\ndeveloped for tourism and the current state of the art for this sector. The\npaper also provides an up-to-date survey of this field regarding several key\nworks and systems that are applied to tourism, like Personal Agents, for\nproviding a more interactive experience. We also carried out an in-depth\nresearch on systems for predicting traffic human flow, more accurate\nrecommendation systems and even how geospatial is trying to display tourism\ndata in a more informative way and prevent problems before they arise.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 22:41:12 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 15:44:03 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Duarte", "Luis", ""], ["Torres", "Jonathan", ""], ["Ribeiro", "Vitor", ""], ["Moreira", "In\u00eas", ""]]}, {"id": "2010.14685", "submitter": "Kookjin Lee", "authors": "Kookjin Lee and Eric J. Parish", "title": "Parameterized Neural Ordinary Differential Equations: Applications to\n  Computational Physics Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes an extension of neural ordinary differential equations\n(NODEs) by introducing an additional set of ODE input parameters to NODEs. This\nextension allows NODEs to learn multiple dynamics specified by the input\nparameter instances. Our extension is inspired by the concept of parameterized\nordinary differential equations, which are widely investigated in computational\nscience and engineering contexts, where characteristics of the governing\nequations vary over the input parameters. We apply the proposed parameterized\nNODEs (PNODEs) for learning latent dynamics of complex dynamical processes that\narise in computational physics, which is an essential component for enabling\nrapid numerical simulations for time-critical physics applications. For this,\nwe propose an encoder-decoder-type framework, which models latent dynamics as\nPNODEs. We demonstrate the effectiveness of PNODEs with important benchmark\nproblems from computational physics.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 00:41:28 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Lee", "Kookjin", ""], ["Parish", "Eric J.", ""]]}, {"id": "2010.14693", "submitter": "Daniel Armstrong", "authors": "Daniel Armstrong and Andr\\'e Jonasson", "title": "AM-RRT*: Informed Sampling-based Planning with Assisting Metric", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new algorithm that extends RRT* and RT-RRT* for\nonline path planning in complex, dynamic environments. Sampling-based\napproaches often perform poorly in environments with narrow passages, a feature\ncommon to many indoor applications of mobile robots as well as computer games.\nOur method extends RRT-based sampling methods to enable the use of an assisting\ndistance metric to improve performance in environments with obstacles. This\nassisting metric, which can be any metric that has better properties than the\nEuclidean metric when line of sight is blocked, is used in combination with the\nstandard Euclidean metric in such a way that the algorithm can reap benefits\nfrom the assisting metric while maintaining the desirable properties of\nprevious RRT variants - namely probabilistic completeness in tree coverage and\nasymptotic optimality in path length. We also introduce a new method of\ntargeted rewiring, aimed at shortening search times and path lengths in tasks\nwhere the goal shifts repeatedly. We demonstrate that our method offers\nconsiderable improvements over existing multi-query planners such as RT-RRT*\nwhen using diffusion distance as an assisting metric; finding near-optimal\npaths with a decrease in search time of several orders of magnitude.\nExperimental results show planning times reduced by 99.5% and path lengths by\n9.8% over existing real-time RRT planners in a variety of environments.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 01:39:40 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Armstrong", "Daniel", ""], ["Jonasson", "Andr\u00e9", ""]]}, {"id": "2010.14708", "submitter": "Xt J", "authors": "BinBin Yong, XueTao Jiang, Jun Shen and Qingguo Zhou", "title": "A methodology of weed-crop classification based on autonomous models\n  choosing and ensemble", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks play an important role in crop-weed classification have high\naccuracy more than 95%. Manually choosing models and fine-tuning are laborious,\nyet it is indispensable in most traditional practices and researches. Moreover,\nclassic training metric are not thoroughly compatible with farming tasks, that\na model still have a noticeable chance of miss classifying crop to weed while\nit reach higher accuracy even more than 99%. In this paper we demonstrate a\nmethodology of weed-crop classification based on autonomous models choosing and\nensemble that could make models choosing and tunning automatically, and improve\nthe prediction with high accuracy(>99% for both data set) in specific class\nwith low risk in incorrect predicting.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 02:35:17 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Yong", "BinBin", ""], ["Jiang", "XueTao", ""], ["Shen", "Jun", ""], ["Zhou", "Qingguo", ""]]}, {"id": "2010.14712", "submitter": "Letian Wang", "authors": "Letian Wang, Liting Sun, Masayoshi Tomizuka, and Wei Zhan", "title": "Socially-Compatible Behavior Design of Autonomous Vehicles with\n  Verification on Real Human Data", "comments": "Accepted by IEEE Robotics and Automation Letters. January 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more and more autonomous vehicles (AVs) are being deployed on public\nroads, designing socially compatible behaviors for them is becoming\nincreasingly important. In order to generate safe and efficient actions, AVs\nneed to not only predict the future behaviors of other traffic participants,\nbut also be aware of the uncertainties associated with such behavior\nprediction. In this paper, we propose an uncertain-aware integrated prediction\nand planning (UAPP) framework. It allows the AVs to infer the characteristics\nof other road users online and generate behaviors optimizing not only their own\nrewards, but also their courtesy to others, and their confidence regarding the\nprediction uncertainties. We first propose the definitions for courtesy and\nconfidence. Based on that, their influences on the behaviors of AVs in\ninteractive driving scenarios are explored. Moreover, we evaluate the proposed\nalgorithm on naturalistic human driving data by comparing the generated\nbehavior against ground truth. Results show that the online inference can\nsignificantly improve the human-likeness of the generated behaviors.\nFurthermore, we find that human drivers show great courtesy to others, even for\nthose without right-of-way. We also find that such driving preferences vary\nsignificantly in different cultures.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 02:47:18 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 09:46:07 GMT"}, {"version": "v3", "created": "Sat, 16 Jan 2021 05:25:20 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 07:56:29 GMT"}, {"version": "v5", "created": "Fri, 12 Feb 2021 05:22:49 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Wang", "Letian", ""], ["Sun", "Liting", ""], ["Tomizuka", "Masayoshi", ""], ["Zhan", "Wei", ""]]}, {"id": "2010.14730", "submitter": "Xiaoyu Kou", "authors": "Xiaoyu Kou, Yankai Lin, Yuntao Li, Jiahao Xu, Peng Li, Jie Zhou, Yan\n  Zhang", "title": "DisenE: Disentangling Knowledge Graph Embeddings", "comments": "There are some mistakes in the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding (KGE), aiming to embed entities and relations into\nlow-dimensional vectors, has attracted wide attention recently. However, the\nexisting research is mainly based on the black-box neural models, which makes\nit difficult to interpret the learned representation. In this paper, we\nintroduce DisenE, an end-to-end framework to learn disentangled knowledge graph\nembeddings. Specially, we introduce an attention-based mechanism that enables\nthe model to explicitly focus on relevant components of entity embeddings\naccording to a given relation. Furthermore, we introduce two novel regularizers\nto encourage each component of the entity representation to independently\nreflect an isolated semantic aspect. Experimental results demonstrate that our\nproposed DisenE investigates a perspective to address the interpretability of\nKGE and is proved to be an effective way to improve the performance of link\nprediction tasks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 03:45:19 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 12:53:03 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Kou", "Xiaoyu", ""], ["Lin", "Yankai", ""], ["Li", "Yuntao", ""], ["Xu", "Jiahao", ""], ["Li", "Peng", ""], ["Zhou", "Jie", ""], ["Zhang", "Yan", ""]]}, {"id": "2010.14746", "submitter": "Amr Mahmoud", "authors": "Amr Mahmoud, Youmna Ismaeil and Mohamed Zohdy", "title": "Continuous Lyapunov Controller and Chaotic Non-linear System\n  Optimization using Deep Machine Learning", "comments": "7 pages, 12 figures", "journal-ref": null, "doi": "10.5923/j.control.20201002.01", "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The introduction of unexpected system disturbances and new system dynamics\ndoes not allow initially selected static system and controller parameters to\nguarantee continued system stability and performance. In this research we\npresent a novel approach for detecting early failure indicators of non-linear\nhighly chaotic system and accordingly predict the best parameter calibrations\nto offset such instability using deep machine learning regression model. The\napproach proposed continuously monitors the system and controller signals. The\nRe-calibration of the system and controller parameters is triggered according\nto a set of conditions designed to maintain system stability without compromise\nto the system speed, intended outcome or required processing power. The deep\nneural model predicts the parameter values that would best counteract the\nexpected system in-stability. To demonstrate the effectiveness of the proposed\napproach, it is applied to the non-linear complex combination of Duffing Van\nder pol oscillators. The approach is also tested under different scenarios the\nsystem and controller parameters are initially chosen incorrectly or the system\nparameters are changed while running or new system dynamics are introduced\nwhile running to measure effectiveness and reaction time.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 04:45:12 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 03:25:53 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Mahmoud", "Amr", ""], ["Ismaeil", "Youmna", ""], ["Zohdy", "Mohamed", ""]]}, {"id": "2010.14753", "submitter": "Yingshi Chen", "authors": "Yingshi Chen", "title": "A short note on the decision tree based neural turing machine", "comments": "5 pages, 1 figure. arXiv admin note: substantial text overlap with\n  arXiv:2010.02921", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Turing machine and decision tree have developed independently for a long\ntime. With the recent development of differentiable models, there is an\nintersection between them. Neural turing machine(NTM) opens door for the memory\nnetwork. It use differentiable attention mechanism to read/write external\nmemory bank. Differentiable forest brings differentiable properties to\nclassical decision tree. In this short note, we show the deep connection\nbetween these two models. That is: differentiable forest is a special case of\nNTM. Differentiable forest is actually decision tree based neural turing\nmachine. Based on this deep connection, we propose a response augmented\ndifferential forest (RaDF). The controller of RaDF is differentiable forest,\nthe external memory of RaDF are response vectors which would be read/write by\nleaf nodes.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 01:39:09 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Chen", "Yingshi", ""]]}, {"id": "2010.14771", "submitter": "Samuele Tosatto", "authors": "Samuele Tosatto, Jo\\~ao Carvalho, Jan Peters", "title": "Batch Reinforcement Learning with a Nonparametric Off-Policy Policy\n  Gradient", "comments": "arXiv admin note: substantial text overlap with arXiv:2001.02435", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy Reinforcement Learning (RL) holds the promise of better data\nefficiency as it allows sample reuse and potentially enables safe interaction\nwith the environment. Current off-policy policy gradient methods either suffer\nfrom high bias or high variance, delivering often unreliable estimates. The\nprice of inefficiency becomes evident in real-world scenarios such as\ninteraction-driven robot learning, where the success of RL has been rather\nlimited, and a very high sample cost hinders straightforward application. In\nthis paper, we propose a nonparametric Bellman equation, which can be solved in\nclosed form. The solution is differentiable w.r.t the policy parameters and\ngives access to an estimation of the policy gradient. In this way, we avoid the\nhigh variance of importance sampling approaches, and the high bias of\nsemi-gradient methods. We empirically analyze the quality of our gradient\nestimate against state-of-the-art methods, and show that it outperforms the\nbaselines in terms of sample efficiency on classical control tasks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 13:40:06 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 11:07:49 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2021 19:10:01 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Tosatto", "Samuele", ""], ["Carvalho", "Jo\u00e3o", ""], ["Peters", "Jan", ""]]}, {"id": "2010.14774", "submitter": "Md Osman Gani", "authors": "Md Osman Gani, Shravan Kethireddy, Marvi Bikak, Paul Griffin, Mohammad\n  Adibuzzaman", "title": "Structural Causal Model with Expert Augmented Knowledge to Estimate the\n  Effect of Oxygen Therapy on Mortality in the ICU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in causal inference techniques, more specifically, in the\ntheory of structural causal models, provide the framework for identification of\ncausal effects from observational data in the cases where the causal graph is\nidentifiable, i.e., the data generating mechanism can be recovered from the\njoint distribution. However, no such studies have been done to demonstrate this\nconcept with a clinical example. We present a complete framework to estimate\nthe causal effect from observational data by augmenting expert knowledge in the\nmodel development phase and with a practical clinical application. Our clinical\napplication entails a timely and important research question, i.e., the effect\nof oxygen therapy intervention in the intensive care unit (ICU); the result of\nthis project is useful in a variety of disease conditions, including severe\nacute respiratory syndrome coronavirus-2 (SARS-CoV-2) patients in the ICU. We\nused data from the MIMIC III database, a standard database in the machine\nlearning community that contains 58,976 admissions from an ICU in Boston, MA,\nfor estimating the oxygen therapy effect on morality. We also identified the\ncovariate-specific effect to oxygen therapy from the model for more\npersonalized intervention.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 05:35:39 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Gani", "Md Osman", ""], ["Kethireddy", "Shravan", ""], ["Bikak", "Marvi", ""], ["Griffin", "Paul", ""], ["Adibuzzaman", "Mohammad", ""]]}, {"id": "2010.14785", "submitter": "Nathan Dahlin", "authors": "Nathan Dahlin, Krishna Chaitanya Kalagarla, Nikhil Naik, Rahul Jain,\n  Pierluigi Nuzzo", "title": "Designing Interpretable Approximations to Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an ever expanding set of research and application areas, deep neural\nnetworks (DNNs) set the bar for algorithm performance. However, depending upon\nadditional constraints such as processing power and execution time limits, or\nrequirements such as verifiable safety guarantees, it may not be feasible to\nactually use such high-performing DNNs in practice. Many techniques have been\ndeveloped in recent years to compress or distill complex DNNs into smaller,\nfaster or more understandable models and controllers. This work seeks to\nidentify reduced models that not only preserve a desired performance level, but\nalso, for example, succinctly explain the latent knowledge represented by a\nDNN. We illustrate the effectiveness of the proposed approach on the evaluation\nof decision tree variants and kernel machines in the context of benchmark\nreinforcement learning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 06:33:09 GMT"}, {"version": "v2", "created": "Sat, 19 Jun 2021 06:04:29 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Dahlin", "Nathan", ""], ["Kalagarla", "Krishna Chaitanya", ""], ["Naik", "Nikhil", ""], ["Jain", "Rahul", ""], ["Nuzzo", "Pierluigi", ""]]}, {"id": "2010.14925", "submitter": "Jiancheng Yang", "authors": "Jiancheng Yang, Rui Shi, Bingbing Ni", "title": "MedMNIST Classification Decathlon: A Lightweight AutoML Benchmark for\n  Medical Image Analysis", "comments": "ISBI 2021. Code and dataset are available at\n  https://medmnist.github.io/", "journal-ref": null, "doi": "10.1109/ISBI48211.2021.9434062", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present MedMNIST, a collection of 10 pre-processed medical open datasets.\nMedMNIST is standardized to perform classification tasks on lightweight 28x28\nimages, which requires no background knowledge. Covering the primary data\nmodalities in medical image analysis, it is diverse on data scale (from 100 to\n100,000) and tasks (binary/multi-class, ordinal regression and multi-label).\nMedMNIST could be used for educational purpose, rapid prototyping, multi-modal\nmachine learning or AutoML in medical image analysis. Moreover, MedMNIST\nClassification Decathlon is designed to benchmark AutoML algorithms on all 10\ndatasets; We have compared several baseline methods, including open-source or\ncommercial AutoML tools. The datasets, evaluation code and baseline methods for\nMedMNIST are publicly available at https://medmnist.github.io/.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 12:41:18 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 05:20:20 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 08:58:41 GMT"}, {"version": "v4", "created": "Thu, 20 May 2021 22:47:30 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Yang", "Jiancheng", ""], ["Shi", "Rui", ""], ["Ni", "Bingbing", ""]]}, {"id": "2010.15006", "submitter": "Xu Li", "authors": "Xu Li, Na Li, Chao Weng, Xunying Liu, Dan Su, Dong Yu, Helen Meng", "title": "Replay and Synthetic Speech Detection with Res2net Architecture", "comments": "Accepted to ICASSP2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches for replay and synthetic speech detection still lack\ngeneralizability to unseen spoofing attacks. This work proposes to leverage a\nnovel model structure, so-called Res2Net, to improve the anti-spoofing\ncountermeasure's generalizability. Res2Net mainly modifies the ResNet block to\nenable multiple feature scales. Specifically, it splits the feature maps within\none block into multiple channel groups and designs a residual-like connection\nacross different channel groups. Such connection increases the possible\nreceptive fields, resulting in multiple feature scales. This multiple scaling\nmechanism significantly improves the countermeasure's generalizability to\nunseen spoofing attacks. It also decreases the model size compared to\nResNet-based models. Experimental results show that the Res2Net model\nconsistently outperforms ResNet34 and ResNet50 by a large margin in both\nphysical access (PA) and logical access (LA) of the ASVspoof 2019 corpus.\nMoreover, integration with the squeeze-and-excitation (SE) block can further\nenhance performance. For feature engineering, we investigate the\ngeneralizability of Res2Net combined with different acoustic features, and\nobserve that the constant-Q transform (CQT) achieves the most promising\nperformance in both PA and LA scenarios. Our best single system outperforms\nother state-of-the-art single systems in both PA and LA of the ASVspoof 2019\ncorpus.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 14:33:42 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 05:47:34 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2021 16:01:36 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Li", "Xu", ""], ["Li", "Na", ""], ["Weng", "Chao", ""], ["Liu", "Xunying", ""], ["Su", "Dan", ""], ["Yu", "Dong", ""], ["Meng", "Helen", ""]]}, {"id": "2010.15011", "submitter": "Yuli Slavutsky", "authors": "Yuli Slavutsky, Yuval Benjamini", "title": "Predicting Classification Accuracy When Adding New Unobserved Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiclass classifiers are often designed and evaluated only on a sample from\nthe classes on which they will eventually be applied. Hence, their final\naccuracy remains unknown. In this work we study how a classifier's performance\nover the initial class sample can be used to extrapolate its expected accuracy\non a larger, unobserved set of classes. For this, we define a measure of\nseparation between correct and incorrect classes that is independent of the\nnumber of classes: the \"reversed ROC\" (rROC), which is obtained by replacing\nthe roles of classes and data-points in the common ROC. We show that the\nclassification accuracy is a function of the rROC in multiclass classifiers,\nfor which the learned representation of data from the initial class sample\nremains unchanged when new classes are added. Using these results we formulate\na robust neural-network-based algorithm, \"CleaneX\", which learns to estimate\nthe accuracy of such classifiers on arbitrarily large sets of classes. Unlike\nprevious methods, our method uses both the observed accuracies of the\nclassifier and densities of classification scores, and therefore achieves\nremarkably better predictions than current state-of-the-art methods on both\nsimulations and real datasets of object detection, face recognition, and brain\ndecoding.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 14:37:25 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 10:56:27 GMT"}, {"version": "v3", "created": "Tue, 9 Mar 2021 14:38:37 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Slavutsky", "Yuli", ""], ["Benjamini", "Yuval", ""]]}, {"id": "2010.15054", "submitter": "Geondo Park", "authors": "Geondo Park, June Yong Yang, Sung Ju Hwang, Eunho Yang", "title": "Attribution Preservation in Network Compression for Reliable Network\n  Interpretation", "comments": "NeurIPS 2020. Code: https://github.com/GeondoPark/attribute-preserve", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks embedded in safety-sensitive applications such as\nself-driving cars and wearable health monitors rely on two important\ntechniques: input attribution for hindsight analysis and network compression to\nreduce its size for edge-computing. In this paper, we show that these seemingly\nunrelated techniques conflict with each other as network compression deforms\nthe produced attributions, which could lead to dire consequences for\nmission-critical applications. This phenomenon arises due to the fact that\nconventional network compression methods only preserve the predictions of the\nnetwork while ignoring the quality of the attributions. To combat the\nattribution inconsistency problem, we present a framework that can preserve the\nattributions while compressing a network. By employing the Weighted Collapsed\nAttribution Matching regularizer, we match the attribution maps of the network\nbeing compressed to its pre-compression former self. We demonstrate the\neffectiveness of our algorithm both quantitatively and qualitatively on diverse\ncompression methods.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 16:02:31 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Park", "Geondo", ""], ["Yang", "June Yong", ""], ["Hwang", "Sung Ju", ""], ["Yang", "Eunho", ""]]}, {"id": "2010.15067", "submitter": "Muhammed Tarik Altuncu", "authors": "M. Tarik Altuncu, Sophia N. Yaliraki, Mauricio Barahona", "title": "Graph-based Topic Extraction from Vector Embeddings of Text Documents:\n  Application to a Corpus of News Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Production of news content is growing at an astonishing rate. To help manage\nand monitor the sheer amount of text, there is an increasing need to develop\nefficient methods that can provide insights into emerging content areas, and\nstratify unstructured corpora of text into `topics' that stem intrinsically\nfrom content similarity. Here we present an unsupervised framework that brings\ntogether powerful vector embeddings from natural language processing with tools\nfrom multiscale graph partitioning that can reveal natural partitions at\ndifferent resolutions without making a priori assumptions about the number of\nclusters in the corpus. We show the advantages of graph-based clustering\nthrough end-to-end comparisons with other popular clustering and topic\nmodelling methods, and also evaluate different text vector embeddings, from\nclassic Bag-of-Words to Doc2Vec to the recent transformers based model Bert.\nThis comparative work is showcased through an analysis of a corpus of US news\ncoverage during the presidential election year of 2016.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 16:20:05 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Altuncu", "M. Tarik", ""], ["Yaliraki", "Sophia N.", ""], ["Barahona", "Mauricio", ""]]}, {"id": "2010.15075", "submitter": "Noushin Hajarolasvadi", "authors": "Noushin Hajarolasvadi, Miguel Arjona Ram\\'irez and Hasan Demirel", "title": "Generative Adversarial Networks in Human Emotion Synthesis:A Review", "comments": "46 pages, 28 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC eess.AS eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesizing realistic data samples is of great value for both academic and\nindustrial communities. Deep generative models have become an emerging topic in\nvarious research areas like computer vision and signal processing. Affective\ncomputing, a topic of a broad interest in computer vision society, has been no\nexception and has benefited from generative models. In fact, affective\ncomputing observed a rapid derivation of generative models during the last two\ndecades. Applications of such models include but are not limited to emotion\nrecognition and classification, unimodal emotion synthesis, and cross-modal\nemotion synthesis. As a result, we conducted a review of recent advances in\nhuman emotion synthesis by studying available databases, advantages, and\ndisadvantages of the generative models along with the related training\nstrategies considering two principal human communication modalities, namely\naudio and video. In this context, facial expression synthesis, speech emotion\nsynthesis, and the audio-visual (cross-modal) emotion synthesis is reviewed\nextensively under different application scenarios. Gradually, we discuss open\nresearch problems to push the boundaries of this research area for future\nworks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 16:45:36 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 11:05:36 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hajarolasvadi", "Noushin", ""], ["Ram\u00edrez", "Miguel Arjona", ""], ["Demirel", "Hasan", ""]]}, {"id": "2010.15082", "submitter": "Cuneyt Gurcan Akcora", "authors": "Cuneyt G. Akcora, Sudhanva Purusotham, Yulia R. Gel, Mitchell\n  Krawiec-Thayer, Murat Kantarcioglu", "title": "How to Not Get Caught When You Launder Money on Blockchain?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of blockchain users has tremendously grown in recent years. As an\nunintended consequence, e-crime transactions on blockchains has been on the\nrise. Consequently, public blockchains have become a hotbed of research for\ndeveloping AI tools to detect and trace users and transactions that are related\nto e-crime.\n  We argue that following a few select strategies can make money laundering on\nblockchain virtually undetectable with most of the existing tools and\nalgorithms. As a result, the effective combating of e-crime activities\ninvolving cryptocurrencies requires the development of novel analytic\nmethodology in AI.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 02:12:15 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Akcora", "Cuneyt G.", ""], ["Purusotham", "Sudhanva", ""], ["Gel", "Yulia R.", ""], ["Krawiec-Thayer", "Mitchell", ""], ["Kantarcioglu", "Murat", ""]]}, {"id": "2010.15149", "submitter": "Yiwei Luo", "authors": "Yiwei Luo, Dallas Card, Dan Jurafsky", "title": "Detecting Stance in Media on Global Warming", "comments": "9 pages, 6 figures", "journal-ref": "Findings of ACL: EMNLP 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Citing opinions is a powerful yet understudied strategy in argumentation. For\nexample, an environmental activist might say, \"Leading scientists agree that\nglobal warming is a serious concern,\" framing a clause which affirms their own\nstance (\"that global warming is serious\") as an opinion endorsed (\"[scientists]\nagree\") by a reputable source (\"leading\"). In contrast, a global warming denier\nmight frame the same clause as the opinion of an untrustworthy source with a\npredicate connoting doubt: \"Mistaken scientists claim [...].\" Our work studies\nopinion-framing in the global warming (GW) debate, an increasingly partisan\nissue that has received little attention in NLP. We introduce Global Warming\nStance Dataset (GWSD), a dataset of stance-labeled GW sentences, and train a\nBERT classifier to study novel aspects of argumentation in how different sides\nof a debate represent their own and each other's opinions. From 56K news\narticles, we find that similar linguistic devices for self-affirming and\nopponent-doubting discourse are used across GW-accepting and skeptic media,\nthough GW-skeptical media shows more opponent-doubt. We also find that authors\noften characterize sources as hypocritical, by ascribing opinions expressing\nthe author's own view to source entities known to publicly endorse the opposing\nview. We release our stance dataset, model, and lexicons of framing devices for\nfuture work on opinion-framing and the automatic detection of GW stance.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 18:01:02 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2021 23:40:55 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Luo", "Yiwei", ""], ["Card", "Dallas", ""], ["Jurafsky", "Dan", ""]]}, {"id": "2010.15158", "submitter": "Boyo Chen", "authors": "Boyo Chen, Buo-Fu Chen, Chun-Min Hsiao", "title": "CNN Profiler on Polar Coordinate Images for Tropical Cyclone Structure\n  Analysis", "comments": "Submitted to AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNN) have achieved great success in analyzing\ntropical cyclones (TC) with satellite images in several tasks, such as TC\nintensity estimation. In contrast, TC structure, which is conventionally\ndescribed by a few parameters estimated subjectively by meteorology\nspecialists, is still hard to be profiled objectively and routinely. This study\napplies CNN on satellite images to create the entire TC structure profiles,\ncovering all the structural parameters. By utilizing the meteorological domain\nknowledge to construct TC wind profiles based on historical structure\nparameters, we provide valuable labels for training in our newly released\nbenchmark dataset. With such a dataset, we hope to attract more attention to\nthis crucial issue among data scientists. Meanwhile, a baseline is established\nwith a specialized convolutional model operating on polar-coordinates. We\ndiscovered that it is more feasible and physically reasonable to extract\nstructural information on polar-coordinates, instead of Cartesian coordinates,\naccording to a TC's rotational and spiral natures. Experimental results on the\nreleased benchmark dataset verified the robustness of the proposed model and\ndemonstrated the potential for applying deep learning techniques for this\nbarely developed yet important topic.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 18:13:19 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Chen", "Boyo", ""], ["Chen", "Buo-Fu", ""], ["Hsiao", "Chun-Min", ""]]}, {"id": "2010.15187", "submitter": "Philip Ball", "authors": "Philip J. Ball, Yingzhen Li, Angus Lamb, Cheng Zhang", "title": "A Study on Efficiency in Continual Learning Inspired by Human Learning", "comments": "Accepted at NeurIPS 2020 BabyMind Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are efficient continual learning systems; we continually learn new\nskills from birth with finite cells and resources. Our learning is highly\noptimized both in terms of capacity and time while not suffering from\ncatastrophic forgetting. In this work we study the efficiency of continual\nlearning systems, taking inspiration from human learning. In particular,\ninspired by the mechanisms of sleep, we evaluate popular pruning-based\ncontinual learning algorithms, using PackNet as a case study. First, we\nidentify that weight freezing, which is used in continual learning without\nbiological justification, can result in over $2\\times$ as many weights being\nused for a given level of performance. Secondly, we note the similarity in\nhuman day and night time behaviors to the training and pruning phases\nrespectively of PackNet. We study a setting where the pruning phase is given a\ntime budget, and identify connections between iterative pruning and multiple\nsleep cycles in humans. We show there exists an optimal choice of iteration\nv.s. epochs given different tasks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 19:11:01 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Ball", "Philip J.", ""], ["Li", "Yingzhen", ""], ["Lamb", "Angus", ""], ["Zhang", "Cheng", ""]]}, {"id": "2010.15195", "submitter": "Wilka Carvalho", "authors": "Wilka Carvalho, Anthony Liang, Kimin Lee, Sungryull Sohn, Honglak Lee,\n  Richard L. Lewis, Satinder Singh", "title": "Reinforcement Learning for Sparse-Reward Object-Interaction Tasks in a\n  First-person Simulated 3D Environment", "comments": "Accepted to IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First-person object-interaction tasks in high-fidelity, 3D, simulated\nenvironments such as the AI2Thor virtual home-environment pose significant\nsample-efficiency challenges for reinforcement learning (RL) agents learning\nfrom sparse task rewards. To alleviate these challenges, prior work has\nprovided extensive supervision via a combination of reward-shaping,\nground-truth object-information, and expert demonstrations. In this work, we\nshow that one can learn object-interaction tasks from scratch without\nsupervision by learning an attentive object-model as an auxiliary task during\ntask learning with an object-centric relational RL agent. Our key insight is\nthat learning an object-model that incorporates object-attention into forward\nprediction provides a dense learning signal for unsupervised representation\nlearning of both objects and their relationships. This, in turn, enables faster\npolicy learning for an object-centric relational RL agent. We demonstrate our\nagent by introducing a set of challenging object-interaction tasks in the\nAI2Thor environment where learning with our attentive object-model is key to\nstrong performance. Specifically, we compare our agent and relational RL agents\nwith alternative auxiliary tasks to a relational RL agent equipped with\nground-truth object-information, and show that learning with our object-model\nbest closes the performance gap in terms of both learning speed and maximum\nsuccess rate. Additionally, we find that incorporating object-attention into an\nobject-model's forward predictions is key to learning representations which\ncapture object-category and object-state.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 19:27:26 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 18:23:57 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Carvalho", "Wilka", ""], ["Liang", "Anthony", ""], ["Lee", "Kimin", ""], ["Sohn", "Sungryull", ""], ["Lee", "Honglak", ""], ["Lewis", "Richard L.", ""], ["Singh", "Satinder", ""]]}, {"id": "2010.15217", "submitter": "Noah Goodall", "authors": "Noah J. Goodall", "title": "Away from Trolley Problems and Toward Risk Management", "comments": "11 pages, 1 figure", "journal-ref": "Applied Artificial Intelligence 30(8), pp. 810-821 (2016)", "doi": "10.1080/08839514.2016.1229922", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As automated vehicles receive more attention from the media, there has been\nan equivalent increase in the coverage of the ethical choices a vehicle may be\nforced to make in certain crash situations with no clear safe outcome. Much of\nthis coverage has focused on a philosophical thought experiment known as the\n\"trolley problem,\" and substituting an automated vehicle for the trolley and\nthe car's software for the bystander. While this is a stark and straightforward\nexample of ethical decision making for an automated vehicle, it risks\nmarginalizing the entire field if it is to become the only ethical problem in\nthe public's mind. In this chapter, I discuss the shortcomings of the trolley\nproblem, and introduce more nuanced examples that involve crash risk and\nuncertainty. Risk management is introduced as an alternative approach, and its\nethical dimensions are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 20:27:50 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Goodall", "Noah J.", ""]]}, {"id": "2010.15232", "submitter": "Hesam Hamledari", "authors": "Hesam Hamledari and Martin Fischer", "title": "Construction Payment Automation Using Blockchain-Enabled Smart Contracts\n  and Reality Capture Technologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a smart contract-based solution for autonomous\nadministration of construction progress payments. It bridges the gap between\npayments (cash flow) and the progress assessments at job sites (product flow)\nenabled by reality capture technologies and building information modeling\n(BIM). The approach eliminates the reliance on the centralized and heavily\nintermediated mechanisms of existing payment applications. The construction\nprogress is stored in a distributed manner using content addressable file\nsharing; it is broadcasted to a smart contract which automates the on-chain\npayment settlements and the transfer of lien rights. The method was\nsuccessfully used for processing payments to 7 subcontractors in two commercial\nconstruction projects where progress monitoring was performed using a\ncamera-equipped unmanned aerial vehicle (UAV) and an unmanned ground vehicle\n(UGV) equipped with a laser scanner. The results show promise for the method's\npotential for increasing the frequency, granularity, and transparency of\npayments. The paper is concluded with a discussion of implications for project\nmanagement, introducing a new model of project as a singleton state machine.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 21:04:47 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 15:27:43 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 17:19:56 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Hamledari", "Hesam", ""], ["Fischer", "Martin", ""]]}, {"id": "2010.15251", "submitter": "Marimuthu Kalimuthu", "authors": "Marimuthu Kalimuthu, Aditya Mogadala, Marius Mosbach, Dietrich Klakow", "title": "Fusion Models for Improved Visual Captioning", "comments": "Accepted at \"Multi-Modal Deep Learning: Challenges and Applications\"\n  (MMDLCA), International Conference on Pattern Recognition (ICPR)-2020,\n  Milano, Italia", "journal-ref": "Springer LNCS, volume 12666, 2021", "doi": "10.1007/978-3-030-68780-9_32", "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Visual captioning aims to generate textual descriptions given images or\nvideos. Traditionally, image captioning models are trained on human annotated\ndatasets such as Flickr30k and MS-COCO, which are limited in size and\ndiversity. This limitation hinders the generalization capabilities of these\nmodels while also rendering them liable to making mistakes. Language models\ncan, however, be trained on vast amounts of freely available unlabelled data\nand have recently emerged as successful language encoders and coherent text\ngenerators. Meanwhile, several unimodal and multimodal fusion techniques have\nbeen proven to work well for natural language generation and automatic speech\nrecognition. Building on these recent developments, and with the aim of\nimproving the quality of generated captions, the contribution of our work in\nthis paper is two-fold: First, we propose a generic multimodal model fusion\nframework for caption generation as well as emendation where we utilize\ndifferent fusion strategies to integrate a pretrained Auxiliary Language Model\n(AuxLM) within the traditional encoder-decoder visual captioning frameworks.\nNext, we employ the same fusion strategies to integrate a pretrained Masked\nLanguage Model (MLM), namely BERT, with a visual captioning model, viz. Show,\nAttend, and Tell, for emending both syntactic and semantic errors in captions.\nOur caption emendation experiments on three benchmark image captioning\ndatasets, viz. Flickr8k, Flickr30k, and MSCOCO, show improvements over the\nbaseline, indicating the usefulness of our proposed multimodal fusion\nstrategies. Further, we perform a preliminary qualitative analysis on the\nemended captions and identify error categories based on the type of\ncorrections.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 21:55:25 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 04:01:02 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Kalimuthu", "Marimuthu", ""], ["Mogadala", "Aditya", ""], ["Mosbach", "Marius", ""], ["Klakow", "Dietrich", ""]]}, {"id": "2010.15255", "submitter": "Sriram Gopalakrishnan", "authors": "Sriram Gopalakrishnan, Subbarao Kambhampati", "title": "Model Minimization For Online Predictability", "comments": "8 pages, 3 figures, 2 tables, 2 pseudocode sections. Accepted at\n  ICAPS workshop on Explainable AI and Planning (XAIP) 2020,\n  href:http://xaip.mybluemix.net/papers/XAIP-2020_paper_13.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For humans in a teaming scenario, context switching between reasoning about a\nteammate's behavior and thinking about thier own task can slow us down,\nespecially if the cognitive cost of predicting the teammate's actions is high.\nSo if we can make the prediction of a robot-teammate's actions quicker, then\nthe human can be more productive. In this paper we present an approach to\nconstrain the actions of a robot so as to increase predictability (specifically\nonline predictability) while keeping the plan costs of the robot within\nacceptable limits. Existing works on human-robot interaction do not consider\nthe computational cost for predictability, which we consider in our approach.\nWe approach this problem from the perspective of directed graph minimization,\nand we connect the concept of predictability to the out-degree of vertices. We\npresent an algorithm to minimize graphs for predictability, and contrast this\nwith minimization for legibility (goal inference) and optimality.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 22:09:10 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Gopalakrishnan", "Sriram", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "2010.15268", "submitter": "Kenny Young", "authors": "Kenny Young and Richard S. Sutton", "title": "Understanding the Pathologies of Approximate Policy Evaluation when\n  Combined with Greedification in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite empirical success, the theory of reinforcement learning (RL) with\nvalue function approximation remains fundamentally incomplete. Prior work has\nidentified a variety of pathological behaviours that arise in RL algorithms\nthat combine approximate on-policy evaluation and greedification. One prominent\nexample is policy oscillation, wherein an algorithm may cycle indefinitely\nbetween policies, rather than converging to a fixed point. What is not well\nunderstood however is the quality of the policies in the region of oscillation.\nIn this paper we present simple examples illustrating that in addition to\npolicy oscillation and multiple fixed points -- the same basic issue can lead\nto convergence to the worst possible policy for a given approximation. Such\nbehaviours can arise when algorithms optimize evaluation accuracy weighted by\nthe distribution of states that occur under the current policy, but greedify\nbased on the value of states which are rare or nonexistent under this\ndistribution. This means the values used for greedification are unreliable and\ncan steer the policy in undesirable directions. Our observation that this can\nlead to the worst possible policy shows that in a general sense such algorithms\nare unreliable. The existence of such examples helps to narrow the kind of\ntheoretical guarantees that are possible and the kind of algorithmic ideas that\nare likely to be helpful. We demonstrate analytically and experimentally that\nsuch pathological behaviours can impact a wide range of RL and dynamic\nprogramming algorithms; such behaviours can arise both with and without\nbootstrapping, and with linear function approximation as well as with more\ncomplex parameterized functions like neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 22:57:57 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Young", "Kenny", ""], ["Sutton", "Richard S.", ""]]}, {"id": "2010.15296", "submitter": "Niall Walsh", "authors": "Stefan Kennedy and Niall Walsh, Kirils Sloka, Jennifer Foster, Andrew\n  McCarren", "title": "Fact or Factitious? Contextualized Opinion Spam Detection", "comments": "6 pages, 3 figures, presented at the 2019 ACL Conference in Florence,\n  Italy", "journal-ref": null, "doi": "10.18653/v1/P19-2048", "report-no": "P19-2048 P19-2048", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we perform an analytic comparison of a number of techniques\nused to detect fake and deceptive online reviews. We apply a number machine\nlearning approaches found to be effective, and introduce our own approach by\nfine-tuning state of the art contextualised embeddings. The results we obtain\nshow the potential of contextualised embeddings for fake review detection, and\nlay the groundwork for future research in this area.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 00:59:06 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Kennedy", "Stefan", ""], ["Walsh", "Niall", ""], ["Sloka", "Kirils", ""], ["Foster", "Jennifer", ""], ["McCarren", "Andrew", ""]]}, {"id": "2010.15314", "submitter": "Drew Linsley", "authors": "Drew Linsley, Junkyung Kim, Alekh Ashok, and Thomas Serre", "title": "Recurrent neural circuits for contour detection", "comments": "Published in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a deep recurrent neural network architecture that approximates\nvisual cortical circuits. We show that this architecture, which we refer to as\nthe gamma-net, learns to solve contour detection tasks with better sample\nefficiency than state-of-the-art feedforward networks, while also exhibiting a\nclassic perceptual illusion, known as the orientation-tilt illusion. Correcting\nthis illusion significantly reduces gamma-net contour detection accuracy by\ndriving it to prefer low-level edges over high-level object boundary contours.\nOverall, our study suggests that the orientation-tilt illusion is a byproduct\nof neural circuits that help biological visual systems achieve robust and\nefficient contour detection, and that incorporating these circuits in\nartificial neural networks can improve computer vision.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 02:09:40 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Linsley", "Drew", ""], ["Kim", "Junkyung", ""], ["Ashok", "Alekh", ""], ["Serre", "Thomas", ""]]}, {"id": "2010.15335", "submitter": "Constantinos Chamzas", "authors": "Constantinos Chamzas, Zachary Kingston, Carlos Quintero-Pe\\~na,\n  Anshumali Shrivastava, and Lydia E. Kavraki", "title": "Learning Sampling Distributions Using Local 3D Workspace Decompositions\n  for Motion Planning in High Dimensions", "comments": "Accepted in International Conference on Robotics and Automation\n  (ICRA), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Earlier work has shown that reusing experience from prior motion planning\nproblems can improve the efficiency of similar, future motion planning queries.\nHowever, for robots with many degrees-of-freedom, these methods exhibit poor\ngeneralization across different environments and often require large datasets\nthat are impractical to gather. We present SPARK and FLAME , two\nexperience-based frameworks for sampling-based planning applicable to complex\nmanipulators in 3 D environments. Both combine samplers associated with\nfeatures from a workspace decomposition into a global biased sampling\ndistribution. SPARK decomposes the environment based on exact geometry while\nFLAME is more general, and uses an octree-based decomposition obtained from\nsensor data. We demonstrate the effectiveness of SPARK and FLAME on a Fetch\nrobot tasked with challenging pick-and-place manipulation problems. Our\napproaches can be trained incrementally and significantly improve performance\nwith only a handful of examples, generalizing better over diverse tasks and\nenvironments as compared to prior approaches.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 03:19:13 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 18:41:11 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Chamzas", "Constantinos", ""], ["Kingston", "Zachary", ""], ["Quintero-Pe\u00f1a", "Carlos", ""], ["Shrivastava", "Anshumali", ""], ["Kavraki", "Lydia E.", ""]]}, {"id": "2010.15344", "submitter": "Ziyuan Zhao", "authors": "Ziyuan Zhao, Kartik Chopra, Zeng Zeng, Xiaoli Li", "title": "Sea-Net: Squeeze-And-Excitation Attention Net For Diabetic Retinopathy\n  Grading", "comments": "Accepted to ICIP 2020", "journal-ref": "2020 IEEE International Conference on Image Processing (ICIP), pp.\n  2496-2500", "doi": "10.1109/ICIP40778.2020.9191345", "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diabetes is one of the most common disease in individuals. \\textit{Diabetic\nretinopathy} (DR) is a complication of diabetes, which could lead to blindness.\nAutomatic DR grading based on retinal images provides a great diagnostic and\nprognostic value for treatment planning. However, the subtle differences among\nseverity levels make it difficult to capture important features using\nconventional methods. To alleviate the problems, a new deep learning\narchitecture for robust DR grading is proposed, referred to as SEA-Net, in\nwhich, spatial attention and channel attention are alternatively carried out\nand boosted with each other, improving the classification performance. In\naddition, a hybrid loss function is proposed to further maximize the\ninter-class distance and reduce the intra-class variability. Experimental\nresults have shown the effectiveness of the proposed architecture.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 03:48:01 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Zhao", "Ziyuan", ""], ["Chopra", "Kartik", ""], ["Zeng", "Zeng", ""], ["Li", "Xiaoli", ""]]}, {"id": "2010.15371", "submitter": "Shuai Wang", "authors": "Liangkai Zhou, Yuncong Hong, Shuai Wang, Ruihua Han, Dachuan Li, Rui\n  Wang, and Qi Hao", "title": "Learning Centric Wireless Resource Allocation for Edge Computing:\n  Algorithm and Experiment", "comments": "8 pages, 4 figures, to appear in IEEE Transactions on Vehicular\n  Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge intelligence is an emerging network architecture that integrates\nsensing, communication, computing components, and supports various machine\nlearning applications, where a fundamental communication question is: how to\nallocate the limited wireless resources (such as time, energy) to the\nsimultaneous model training of heterogeneous learning tasks? Existing methods\nignore two important facts: 1) different models have heterogeneous demands on\ntraining data; 2) there is a mismatch between the simulated environment and the\nreal-world environment. As a result, they could lead to low learning\nperformance in practice. This paper proposes the learning centric wireless\nresource allocation (LCWRA) scheme that maximizes the worst learning\nperformance of multiple tasks. Analysis shows that the optimal transmission\ntime has an inverse power relationship with respect to the generalization\nerror. Finally, both simulation and experimental results are provided to verify\nthe performance of the proposed LCWRA scheme and its robustness in real\nimplementation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 06:20:40 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 08:28:24 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Zhou", "Liangkai", ""], ["Hong", "Yuncong", ""], ["Wang", "Shuai", ""], ["Han", "Ruihua", ""], ["Li", "Dachuan", ""], ["Wang", "Rui", ""], ["Hao", "Qi", ""]]}, {"id": "2010.15372", "submitter": "Zheng Wang", "authors": "Zhuoxi Liu, Zheng Wang, Bo Yang, Kimihiko Nakano", "title": "Learning Personalized Discretionary Lane-Change Initiation for Fully\n  Autonomous Driving Based on Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, the authors present a novel method to learn the personalized\ntactic of discretionary lane-change initiation for fully autonomous vehicles\nthrough human-computer interactions. Instead of learning from human-driving\ndemonstrations, a reinforcement learning technique is employed to learn how to\ninitiate lane changes from traffic context, the action of a self-driving\nvehicle, and in-vehicle user feedback. The proposed offline algorithm rewards\nthe action-selection strategy when the user gives positive feedback and\npenalizes it when negative feedback. Also, a multi-dimensional driving scenario\nis considered to represent a more realistic lane-change trade-off. The results\nshow that the lane-change initiation model obtained by this method can\nreproduce the personal lane-change tactic, and the performance of the\ncustomized models (average accuracy 86.1%) is much better than that of the\nnon-customized models (average accuracy 75.7%). This method allows continuous\nimprovement of customization for users during fully autonomous driving even\nwithout human-driving experience, which will significantly enhance the user\nacceptance of high-level autonomy of self-driving vehicles.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 06:21:23 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Liu", "Zhuoxi", ""], ["Wang", "Zheng", ""], ["Yang", "Bo", ""], ["Nakano", "Kimihiko", ""]]}, {"id": "2010.15376", "submitter": "Wei Chen", "authors": "Wei Chen, Bowen Zhang, Shi Jin, Bo Ai, Zhangdui Zhong", "title": "Solving Sparse Linear Inverse Problems in Communication Systems: A Deep\n  Learning Approach With Adaptive Depth", "comments": "IEEE Journal on Selected Areas in Communications (JSAC), accepted", "journal-ref": "IEEE Journal on Selected Areas in Communications, vol. 39, no. 1,\n  2021", "doi": "10.1109/JSAC.2020.3036959", "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse signal recovery problems from noisy linear measurements appear in many\nareas of wireless communications. In recent years, deep learning (DL) based\napproaches have attracted interests of researchers to solve the sparse linear\ninverse problem by unfolding iterative algorithms as neural networks.\nTypically, research concerning DL assume a fixed number of network layers.\nHowever, it ignores a key character in traditional iterative algorithms, where\nthe number of iterations required for convergence changes with varying sparsity\nlevels. By investigating on the projected gradient descent, we unveil the\ndrawbacks of the existing DL methods with fixed depth. Then we propose an\nend-to-end trainable DL architecture, which involves an extra halting score at\neach layer. Therefore, the proposed method learns how many layers to execute to\nemit an output, and the network depth is dynamically adjusted for each task in\nthe inference phase. We conduct experiments using both synthetic data and\napplications including random access in massive MTC and massive MIMO channel\nestimation, and the results demonstrate the improved efficiency for the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 06:32:53 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Chen", "Wei", ""], ["Zhang", "Bowen", ""], ["Jin", "Shi", ""], ["Ai", "Bo", ""], ["Zhong", "Zhangdui", ""]]}, {"id": "2010.15413", "submitter": "Christopher Fifty", "authors": "Christopher Fifty, Ehsan Amid, Zhe Zhao, Tianhe Yu, Rohan Anil,\n  Chelsea Finn", "title": "Measuring and Harnessing Transference in Multi-Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning can leverage information learned by one task to benefit\nthe training of other tasks. Despite this capacity, naive formulations often\ndegrade performance and in particular, identifying the tasks that would benefit\nfrom co-training remains a challenging design question. In this paper, we\nanalyze the dynamics of information transfer, or transference, across tasks\nthroughout training. Specifically, we develop a similarity measure that can\nquantify transference among tasks and use this quantity to both better\nunderstand the optimization dynamics of multi-task learning as well as improve\noverall learning performance. In the latter case, we propose two methods to\nleverage our transference metric. The first operates at a macro-level by\nselecting which tasks should train together while the second functions at a\nmicro-level by determining how to combine task gradients at each training step.\nWe find these methods can lead to significant improvement over prior work on\nthree supervised multi-task learning benchmarks and one multi-task\nreinforcement learning paradigm.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 08:25:43 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 06:55:50 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Fifty", "Christopher", ""], ["Amid", "Ehsan", ""], ["Zhao", "Zhe", ""], ["Yu", "Tianhe", ""], ["Anil", "Rohan", ""], ["Finn", "Chelsea", ""]]}, {"id": "2010.15469", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere", "title": "Emergence of Spatial Coordinates via Exploration", "comments": "4 pages, 2 figures, BabyMind Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial knowledge is a fundamental building block for the development of\nadvanced perceptive and cognitive abilities. Traditionally, in robotics, the\nEuclidean (x,y,z) coordinate system and the agent's forward model are defined a\npriori. We show that a naive agent can autonomously build an internal\ncoordinate system, with the same dimension and metric regularity as the\nexternal space, simply by learning to predict the outcome of sensorimotor\ntransitions in a self-supervised way.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 10:31:27 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""]]}, {"id": "2010.15578", "submitter": "Niya Stoimenova", "authors": "Niya Stoimenova, Rebecca Price", "title": "Exploring the Nuances of Designing (with/for) Artificial Intelligence", "comments": null, "journal-ref": "Design Issues, 36(4), 45-55 (2020)", "doi": "10.1162/desi_a_00613", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Solutions relying on artificial intelligence are devised to predict data\npatterns and answer questions that are clearly defined, involve an enumerable\nset of solutions, clear rules, and inherently binary decision mechanisms. Yet,\nas they become exponentially implemented in our daily activities, they begin to\ntranscend these initial boundaries and to affect the larger sociotechnical\nsystem in which they are situated. In this arrangement, a solution is under\npressure to surpass true or false criteria and move to an ethical evaluation of\nright and wrong. Neither algorithmic solutions, nor purely humanistic ones will\nbe enough to fully mitigate undesirable outcomes in the narrow state of AI or\nits future incarnations. We must take a holistic view. In this paper we explore\nthe construct of infrastructure as a means to simultaneously address\nalgorithmic and societal issues when designing AI.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 20:34:35 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Stoimenova", "Niya", ""], ["Price", "Rebecca", ""]]}, {"id": "2010.15582", "submitter": "Mustafa Ozdayi", "authors": "Mustafa Safa Ozdayi, Murat Kantarcioglu, Rishabh Iyer", "title": "Improving Accuracy of Federated Learning in Non-IID Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a decentralized machine learning protocol that\nallows a set of participating agents to collaboratively train a model without\nsharing their data. This makes FL particularly suitable for settings where data\nprivacy is desired. However, it has been observed that the performance of FL is\nclosely tied with the local data distributions of agents. Particularly, in\nsettings where local data distributions vastly differ among agents, FL performs\nrather poorly with respect to the centralized training. To address this\nproblem, we hypothesize the reasons behind the performance degradation, and\ndevelop some techniques to address these reasons accordingly. In this work, we\nidentify four simple techniques that can improve the performance of trained\nmodels without incurring any additional communication overhead to FL, but\nrather, some light computation overhead either on the client, or the\nserver-side. In our experimental analysis, combination of our techniques\nimproved the validation accuracy of a model trained via FL by more than 12%\nwith respect to our baseline. This is about 5% less than the accuracy of the\nmodel trained on centralized data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 21:02:14 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Ozdayi", "Mustafa Safa", ""], ["Kantarcioglu", "Murat", ""], ["Iyer", "Rishabh", ""]]}, {"id": "2010.15594", "submitter": "Muhammad Yousefnezhad", "authors": "Muhammad Yousefnezhad, Alessandro Selvitella, Daoqiang Zhang, Andrew\n  J. Greenshaw, Russell Greiner", "title": "Shared Space Transfer Learning for analyzing multi-site fMRI data", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada. The Supplementary Material:\n  https://www.yousefnezhad.com/publications/NeurIPS2020_Paper4157_SuppMat.zip", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.IV math.FA q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-voxel pattern analysis (MVPA) learns predictive models from task-based\nfunctional magnetic resonance imaging (fMRI) data, for distinguishing when\nsubjects are performing different cognitive tasks -- e.g., watching movies or\nmaking decisions. MVPA works best with a well-designed feature set and an\nadequate sample size. However, most fMRI datasets are noisy, high-dimensional,\nexpensive to collect, and with small sample sizes. Further, training a robust,\ngeneralized predictive model that can analyze homogeneous cognitive tasks\nprovided by multi-site fMRI datasets has additional challenges. This paper\nproposes the Shared Space Transfer Learning (SSTL) as a novel transfer learning\n(TL) approach that can functionally align homogeneous multi-site fMRI datasets,\nand so improve the prediction performance in every site. SSTL first extracts a\nset of common features for all subjects in each site. It then uses TL to map\nthese site-specific features to a site-independent shared space in order to\nimprove the performance of the MVPA. SSTL uses a scalable optimization\nprocedure that works effectively for high-dimensional fMRI datasets. The\noptimization procedure extracts the common features for each site by using a\nsingle-iteration algorithm and maps these site-specific common features to the\nsite-independent shared space. We evaluate the effectiveness of the proposed\nmethod for transferring between various cognitive tasks. Our comprehensive\nexperiments validate that SSTL achieves superior performance to other\nstate-of-the-art analysis techniques.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 08:50:26 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Yousefnezhad", "Muhammad", ""], ["Selvitella", "Alessandro", ""], ["Zhang", "Daoqiang", ""], ["Greenshaw", "Andrew J.", ""], ["Greiner", "Russell", ""]]}, {"id": "2010.15597", "submitter": "Hamid Radmard Rahmani", "authors": "Hamid Radmard Rahmani, Carsten Koenke, Marco A. Wiering", "title": "Enhancing reinforcement learning by a finite reward response filter with\n  a case study in intelligent structural control", "comments": "16 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many reinforcement learning (RL) problems, it takes some time until a\ntaken action by the agent reaches its maximum effect on the environment and\nconsequently the agent receives the reward corresponding to that action by a\ndelay called action-effect delay. Such delays reduce the performance of the\nlearning algorithm and increase the computational costs, as the reinforcement\nlearning agent values the immediate rewards more than the future reward that is\nmore related to the taken action. This paper addresses this issue by\nintroducing an applicable enhanced Q-learning method in which at the beginning\nof the learning phase, the agent takes a single action and builds a function\nthat reflects the environments response to that action, called the reflexive\n$\\gamma$ - function. During the training phase, the agent utilizes the created\nreflexive $\\gamma$- function to update the Q-values. We have applied the\ndeveloped method to a structural control problem in which the goal of the agent\nis to reduce the vibrations of a building subjected to earthquake excitations\nwith a specified delay. Seismic control problems are considered as a complex\ntask in structural engineering because of the stochastic and unpredictable\nnature of earthquakes and the complex behavior of the structure. Three\nscenarios are presented to study the effects of zero, medium, and long\naction-effect delays and the performance of the Enhanced method is compared to\nthe standard Q-learning method. Both RL methods use neural network to learn to\nestimate the state-action value function that is used to control the structure.\nThe results show that the enhanced method significantly outperforms the\nperformance of the original method in all cases, and also improves the\nstability of the algorithm in dealing with action-effect delays.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 19:28:35 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Rahmani", "Hamid Radmard", ""], ["Koenke", "Carsten", ""], ["Wiering", "Marco A.", ""]]}, {"id": "2010.15599", "submitter": "Vicen\\c{c} Rubies-Royo", "authors": "Vicenc Rubies-Royo, Eric Mazumdar, Roy Dong, Claire Tomlin, and S.\n  Shankar Sastry", "title": "Expert Selection in High-Dimensional Markov Decision Processes", "comments": "In proceedings of the 59th IEEE Conference on Decision and Control\n  2020. arXiv admin note: text overlap with arXiv:1707.05714", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a multi-armed bandit framework for online expert\nselection in Markov decision processes and demonstrate its use in\nhigh-dimensional settings. Our method takes a set of candidate expert policies\nand switches between them to rapidly identify the best performing expert using\na variant of the classical upper confidence bound algorithm, thus ensuring low\nregret in the overall performance of the system. This is useful in applications\nwhere several expert policies may be available, and one needs to be selected at\nrun-time for the underlying environment.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 03:57:25 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Rubies-Royo", "Vicenc", ""], ["Mazumdar", "Eric", ""], ["Dong", "Roy", ""], ["Tomlin", "Claire", ""], ["Sastry", "S. Shankar", ""]]}, {"id": "2010.15622", "submitter": "Floris den Hengst", "authors": "Michal Nauman and Floris Den Hengst", "title": "Low-Variance Policy Gradient Estimation with World Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose World Model Policy Gradient (WMPG), an approach to\nreduce the variance of policy gradient estimates using learned world models\n(WM's). In WMPG, a WM is trained online and used to imagine trajectories. The\nimagined trajectories are used in two ways. Firstly, to calculate a\nwithout-replacement estimator of the policy gradient. Secondly, the return of\nthe imagined trajectories is used as an informed baseline. We compare the\nproposed approach with AC and MAC on a set of environments of increasing\ncomplexity (CartPole, LunarLander and Pong) and find that WMPG has better\nsample efficiency. Based on these results, we conclude that WMPG can yield\nincreased sample efficiency in cases where a robust latent representation of\nthe environment can be learned.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 14:09:23 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Nauman", "Michal", ""], ["Hengst", "Floris Den", ""]]}, {"id": "2010.15773", "submitter": "Akshay Agarwal", "authors": "Divyam Anshumaan, Akshay Agarwal, Mayank Vatsa, and Richa Singh", "title": "WaveTransform: Crafting Adversarial Examples via Input Decomposition", "comments": "ECCV Workshop Adversarial Robustness in the Real World 2020, 17\n  pages, 3 Tables, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequency spectrum has played a significant role in learning unique and\ndiscriminating features for object recognition. Both low and high frequency\ninformation present in images have been extracted and learnt by a host of\nrepresentation learning techniques, including deep learning. Inspired by this\nobservation, we introduce a novel class of adversarial attacks, namely\n`WaveTransform', that creates adversarial noise corresponding to low-frequency\nand high-frequency subbands, separately (or in combination). The frequency\nsubbands are analyzed using wavelet decomposition; the subbands are corrupted\nand then used to construct an adversarial example. Experiments are performed\nusing multiple databases and CNN models to establish the effectiveness of the\nproposed WaveTransform attack and analyze the importance of a particular\nfrequency component. The robustness of the proposed attack is also evaluated\nthrough its transferability and resiliency against a recent adversarial defense\nalgorithm. Experiments show that the proposed attack is effective against the\ndefense algorithm and is also transferable across CNNs.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 17:16:59 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Anshumaan", "Divyam", ""], ["Agarwal", "Akshay", ""], ["Vatsa", "Mayank", ""], ["Singh", "Richa", ""]]}, {"id": "2010.15792", "submitter": "Zhenyu Gao", "authors": "Jiunhan Chen, Zhenyu Gao", "title": "A Framework for Learning Predator-prey Agents from Simulation to Real\n  World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an evolutionary predatorprey robot system which can\nbe generally implemented from simulation to the real world. We design the\nclosed-loop robot system with camera and infrared sensors as inputs of\ncontroller. Both the predators and prey are co-evolved by NeuroEvolution of\nAugmenting Topologies (NEAT) to learn the expected behaviours. We design a\nframework that integrate Gym of OpenAI, Robot Operating System (ROS), Gazebo.\nIn such a framework, users only need to focus on algorithms without being\nworried about the detail of manipulating robots in both simulation and the real\nworld. Combining simulations, real-world evolution, and robustness analysis, it\ncan be applied to develop the solutions for the predator-prey tasks. For the\nconvenience of users, the source code and videos of the simulated and real\nworld are published on Github.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 17:33:38 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Chen", "Jiunhan", ""], ["Gao", "Zhenyu", ""]]}, {"id": "2010.15832", "submitter": "EPTCS", "authors": "Pedro Quaresma (University of Coimbra, Portugal), Walther Neuper (JKU\n  Johannes Kepler University, Linz, Austria), Jo\\~ao Marcos (UFRN, Brazil)", "title": "Proceedings 9th International Workshop on Theorem Proving Components for\n  Educational Software", "comments": null, "journal-ref": "EPTCS 328, 2020", "doi": "10.4204/EPTCS.328", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 9th International Workshop on Theorem-Proving Components for Educational\nSoftware (ThEdu'20) was scheduled to happen on June 29 as a satellite of the\nIJCAR-FSCD 2020 joint meeting, in Paris. The COVID-19 pandemic came by\nsurprise, though, and the main conference was virtualised. Fearing that an\nonline meeting would not allow our community to fully reproduce the usual\nface-to-face networking opportunities of the ThEdu initiative, the Steering\nCommittee of ThEdu decided to cancel our workshop. Given that many of us had\nalready planned and worked for that moment, we decided that ThEdu'20 could\nstill live in the form of an EPTCS volume. The EPTCS concurred with us,\nrecognising this very singular situation, and accepted our proposal of\norganising a special issue with papers submitted to ThEdu'20. An open call for\npapers was then issued, and attracted five submissions, all of which have been\naccepted by our reviewers, who produced three careful reports on each of the\ncontributions. The resulting revised papers are collected in the present\nvolume. We, the volume editors, hope that this collection of papers will help\nfurther promoting the development of theorem-proving-based software, and that\nit will collaborate to improve the mutual understanding between computer\nmathematicians and stakeholders in education. With some luck, we would actually\nexpect that the very special circumstances set up by the worst sanitary crisis\nin a century will happen to reinforce the need for the application of certified\ncomponents and of verification methods for the production of educational\nsoftware that would be available even when the traditional on-site learning\nexperiences turn out not to be recommendable.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 00:36:08 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Quaresma", "Pedro", "", "University of Coimbra, Portugal"], ["Neuper", "Walther", "", "JKU\n  Johannes Kepler University, Linz, Austria"], ["Marcos", "Jo\u00e3o", "", "UFRN, Brazil"]]}, {"id": "2010.15875", "submitter": "Yunchengh Hua", "authors": "Yuncheng Hua, Yuan-Fang Li, Gholamreza Haffari, Guilin Qi and Wei Wu", "title": "Retrieve, Program, Repeat: Complex Knowledge Base Question Answering via\n  Alternate Meta-learning", "comments": "8 pages, 2 figures, published in IJCAI 2020", "journal-ref": "IJCAI 2020: 3679-3686", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A compelling approach to complex question answering is to convert the\nquestion to a sequence of actions, which can then be executed on the knowledge\nbase to yield the answer, aka the programmer-interpreter approach. Use similar\ntraining questions to the test question, meta-learning enables the programmer\nto adapt to unseen questions to tackle potential distributional biases quickly.\nHowever, this comes at the cost of manually labeling similar questions to learn\na retrieval model, which is tedious and expensive. In this paper, we present a\nnovel method that automatically learns a retrieval model alternately with the\nprogrammer from weak supervision, i.e., the system's performance with respect\nto the produced answers. To the best of our knowledge, this is the first\nattempt to train the retrieval model with the programmer jointly. Our system\nleads to state-of-the-art performance on a large-scale task for complex\nquestion answering over knowledge bases. We have released our code at\nhttps://github.com/DevinJake/MARL.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 18:28:16 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Hua", "Yuncheng", ""], ["Li", "Yuan-Fang", ""], ["Haffari", "Gholamreza", ""], ["Qi", "Guilin", ""], ["Wu", "Wei", ""]]}, {"id": "2010.15877", "submitter": "Yunchengh Hua", "authors": "Yuncheng Hua, Yuan-Fang Li, Gholamreza Haffari, Guilin Qi and Tongtong\n  Wu", "title": "Few-Shot Complex Knowledge Base Question Answering via Meta\n  Reinforcement Learning", "comments": "11 pages, 1 figure, accepted in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex question-answering (CQA) involves answering complex natural-language\nquestions on a knowledge base (KB). However, the conventional neural program\ninduction (NPI) approach exhibits uneven performance when the questions have\ndifferent types, harboring inherently different characteristics, e.g.,\ndifficulty level. This paper proposes a meta-reinforcement learning approach to\nprogram induction in CQA to tackle the potential distributional bias in\nquestions. Our method quickly and effectively adapts the meta-learned\nprogrammer to new questions based on the most similar questions retrieved from\nthe training data. The meta-learned policy is then used to learn a good\nprogramming policy, utilizing the trial trajectories and their rewards for\nsimilar questions in the support set. Our method achieves state-of-the-art\nperformance on the CQA dataset (Saha et al., 2018) while using only five trial\ntrajectories for the top-5 retrieved questions in each support set, and\nmetatraining on tasks constructed from only 1% of the training set. We have\nreleased our code at https://github.com/DevinJake/MRL-CQA.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 18:34:55 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Hua", "Yuncheng", ""], ["Li", "Yuan-Fang", ""], ["Haffari", "Gholamreza", ""], ["Qi", "Guilin", ""], ["Wu", "Tongtong", ""]]}, {"id": "2010.15881", "submitter": "Yunchengh Hua", "authors": "Yuncheng Hua, Yuan-Fang Li, Guilin Qi, Wei Wu, Jingyao Zhang, Daiqing\n  Qi", "title": "Less is More: Data-Efficient Complex Question Answering over Knowledge\n  Bases", "comments": "18 pages, 4 figures, published in JWS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering is an effective method for obtaining information from\nknowledge bases (KB). In this paper, we propose the Neural-Symbolic Complex\nQuestion Answering (NS-CQA) model, a data-efficient reinforcement learning\nframework for complex question answering by using only a modest number of\ntraining samples. Our framework consists of a neural generator and a symbolic\nexecutor that, respectively, transforms a natural-language question into a\nsequence of primitive actions, and executes them over the knowledge base to\ncompute the answer. We carefully formulate a set of primitive symbolic actions\nthat allows us to not only simplify our neural network design but also\naccelerate model convergence. To reduce search space, we employ the copy and\nmasking mechanisms in our encoder-decoder architecture to drastically reduce\nthe decoder output vocabulary and improve model generalizability. We equip our\nmodel with a memory buffer that stores high-reward promising programs. Besides,\nwe propose an adaptive reward function. By comparing the generated trial with\nthe trials stored in the memory buffer, we derive the curriculum-guided reward\nbonus, i.e., the proximity and the novelty. To mitigate the sparse reward\nproblem, we combine the adaptive reward and the reward bonus, reshaping the\nsparse reward into dense feedback. Also, we encourage the model to generate new\ntrials to avoid imitating the spurious trials while making the model remember\nthe past high-reward trials to improve data efficiency. Our NS-CQA model is\nevaluated on two datasets: CQA, a recent large-scale complex question answering\ndataset, and WebQuestionsSP, a multi-hop question answering dataset. On both\ndatasets, our model outperforms the state-of-the-art models. Notably, on CQA,\nNS-CQA performs well on questions with higher complexity, while only using\napproximately 1% of the total training samples.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 18:42:44 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Hua", "Yuncheng", ""], ["Li", "Yuan-Fang", ""], ["Qi", "Guilin", ""], ["Wu", "Wei", ""], ["Zhang", "Jingyao", ""], ["Qi", "Daiqing", ""]]}, {"id": "2010.15896", "submitter": "Kalesha Bullard", "authors": "Kalesha Bullard, Franziska Meier, Douwe Kiela, Joelle Pineau, and\n  Jakob Foerster", "title": "Exploring Zero-Shot Emergent Communication in Embodied Multi-Agent\n  Populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective communication is an important skill for enabling information\nexchange and cooperation in multi-agent settings. Indeed, emergent\ncommunication is now a vibrant field of research, with common settings\ninvolving discrete cheap-talk channels. One limitation of this setting is that\nit does not allow for the emergent protocols to generalize beyond the training\npartners. Furthermore, so far emergent communication has primarily focused on\nthe use of symbolic channels. In this work, we extend this line of work to a\nnew modality, by studying agents that learn to communicate via actuating their\njoints in a 3D environment. We show that under realistic assumptions, a\nnon-uniform distribution of intents and a common-knowledge energy cost, these\nagents can find protocols that generalize to novel partners. We also explore\nand analyze specific difficulties associated with finding these solutions in\npractice. Finally, we propose and evaluate initial training improvements to\naddress these challenges, involving both specific training curricula and\nproviding the latent feature that can be coordinated on during training.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 19:23:10 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 07:45:05 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Bullard", "Kalesha", ""], ["Meier", "Franziska", ""], ["Kiela", "Douwe", ""], ["Pineau", "Joelle", ""], ["Foerster", "Jakob", ""]]}, {"id": "2010.15920", "submitter": "Ashwin Balakrishna", "authors": "Brijen Thananjeyan, Ashwin Balakrishna, Suraj Nair, Michael Luo,\n  Krishnan Srinivasan, Minho Hwang, Joseph E. Gonzalez, Julian Ibarz, Chelsea\n  Finn, Ken Goldberg", "title": "Recovery RL: Safe Reinforcement Learning with Learned Recovery Zones", "comments": "RA-L and ICRA 2021. First two authors contributed equally", "journal-ref": "Robotics and Automation Letters (RA-L) and International\n  Conference on Robotics and Automation (ICRA) 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety remains a central obstacle preventing widespread use of RL in the real\nworld: learning new tasks in uncertain environments requires extensive\nexploration, but safety requires limiting exploration. We propose Recovery RL,\nan algorithm which navigates this tradeoff by (1) leveraging offline data to\nlearn about constraint violating zones before policy learning and (2)\nseparating the goals of improving task performance and constraint satisfaction\nacross two policies: a task policy that only optimizes the task reward and a\nrecovery policy that guides the agent to safety when constraint violation is\nlikely. We evaluate Recovery RL on 6 simulation domains, including two\ncontact-rich manipulation tasks and an image-based navigation task, and an\nimage-based obstacle avoidance task on a physical robot. We compare Recovery RL\nto 5 prior safe RL methods which jointly optimize for task performance and\nsafety via constrained optimization or reward shaping and find that Recovery RL\noutperforms the next best prior method across all domains. Results suggest that\nRecovery RL trades off constraint violations and task successes 2 - 20 times\nmore efficiently in simulation domains and 3 times more efficiently in physical\nexperiments. See https://tinyurl.com/rl-recovery for videos and supplementary\nmaterial.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 20:10:02 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 21:20:48 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Thananjeyan", "Brijen", ""], ["Balakrishna", "Ashwin", ""], ["Nair", "Suraj", ""], ["Luo", "Michael", ""], ["Srinivasan", "Krishnan", ""], ["Hwang", "Minho", ""], ["Gonzalez", "Joseph E.", ""], ["Ibarz", "Julian", ""], ["Finn", "Chelsea", ""], ["Goldberg", "Ken", ""]]}, {"id": "2010.15925", "submitter": "Ekaterina Artemova", "authors": "Tatiana Shavrina and Alena Fenogenova and Anton Emelyanov and Denis\n  Shevelev and Ekaterina Artemova and Valentin Malykh and Vladislav Mikhailov\n  and Maria Tikhonova and Andrey Chertok and Andrey Evlampiev", "title": "RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark", "comments": "to appear in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce an advanced Russian general language\nunderstanding evaluation benchmark -- RussianGLUE. Recent advances in the field\nof universal language models and transformers require the development of a\nmethodology for their broad diagnostics and testing for general intellectual\nskills - detection of natural language inference, commonsense reasoning,\nability to perform simple logical operations regardless of text subject or\nlexicon. For the first time, a benchmark of nine tasks, collected and organized\nanalogically to the SuperGLUE methodology, was developed from scratch for the\nRussian language. We provide baselines, human level evaluation, an open-source\nframework for evaluating models\n(https://github.com/RussianNLP/RussianSuperGLUE), and an overall leaderboard of\ntransformer models for the Russian language. Besides, we present the first\nresults of comparing multilingual models in the adapted diagnostic test set and\noffer the first steps to further expanding or assessing state-of-the-art models\nindependently of language.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 20:31:39 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 11:02:10 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Shavrina", "Tatiana", ""], ["Fenogenova", "Alena", ""], ["Emelyanov", "Anton", ""], ["Shevelev", "Denis", ""], ["Artemova", "Ekaterina", ""], ["Malykh", "Valentin", ""], ["Mikhailov", "Vladislav", ""], ["Tikhonova", "Maria", ""], ["Chertok", "Andrey", ""], ["Evlampiev", "Andrey", ""]]}, {"id": "2010.15999", "submitter": "Gideon Kowadlo", "authors": "Gideon Kowadlo, Abdelrahman Ahmed, David Rawlinson", "title": "Unsupervised One-shot Learning of Both Specific Instances and\n  Generalised Classes with a Hippocampal Architecture", "comments": "To appear at AI 2020 (Australasian Joint Conference on Artificial\n  Intelligence - http://www.ajcai2020.net/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Established experimental procedures for one-shot machine learning do not test\nthe ability to learn or remember specific instances of classes, a key feature\nof animal intelligence. Distinguishing specific instances is necessary for many\nreal-world tasks, such as remembering which cup belongs to you. Generalisation\nwithin classes conflicts with the ability to separate instances of classes,\nmaking it difficult to achieve both capabilities within a single architecture.\nWe propose an extension to the standard Omniglot classification-generalisation\nframework that additionally tests the ability to distinguish specific instances\nafter one exposure and introduces noise and occlusion corruption. Learning is\ndefined as an ability to classify as well as recall training samples.\nComplementary Learning Systems (CLS) is a popular model of mammalian brain\nregions believed to play a crucial role in learning from a single exposure to a\nstimulus. We created an artificial neural network implementation of CLS and\napplied it to the extended Omniglot benchmark. Our unsupervised model\ndemonstrates comparable performance to existing supervised ANNs on the Omniglot\nclassification task (requiring generalisation), without the need for\ndomain-specific inductive biases. On the extended Omniglot instance-recognition\ntask, the same model also demonstrates significantly better performance than a\nbaseline nearest-neighbour approach, given partial occlusion and noise.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 00:10:23 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Kowadlo", "Gideon", ""], ["Ahmed", "Abdelrahman", ""], ["Rawlinson", "David", ""]]}, {"id": "2010.16040", "submitter": "Shufeng Kong", "authors": "Shufeng Kong, Junwen Bai, Jae Hee Lee, Di Chen, Andrew Allyn, Michelle\n  Stuart, Malin Pinsky, Katherine Mills, Carla P. Gomes", "title": "Deep Hurdle Networks for Zero-Inflated Multi-Target Regression:\n  Application to Multiple Species Abundance Estimation", "comments": "Accepted by IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem in computational sustainability is to understand the\ndistribution of species across landscapes over time. This question gives rise\nto challenging large-scale prediction problems since (i) hundreds of species\nhave to be simultaneously modeled and (ii) the survey data are usually inflated\nwith zeros due to the absence of species for a large number of sites. The\nproblem of tackling both issues simultaneously, which we refer to as the\nzero-inflated multi-target regression problem, has not been addressed by\nprevious methods in statistics and machine learning. In this paper, we propose\na novel deep model for the zero-inflated multi-target regression problem. To\nthis end, we first model the joint distribution of multiple response variables\nas a multivariate probit model and then couple the positive outcomes with a\nmultivariate log-normal distribution. By penalizing the difference between the\ntwo distributions' covariance matrices, a link between both distributions is\nestablished. The whole model is cast as an end-to-end learning framework and we\nprovide an efficient learning algorithm for our model that can be fully\nimplemented on GPUs. We show that our model outperforms the existing\nstate-of-the-art baselines on two challenging real-world species distribution\ndatasets concerning bird and fish populations.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 03:26:16 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Kong", "Shufeng", ""], ["Bai", "Junwen", ""], ["Lee", "Jae Hee", ""], ["Chen", "Di", ""], ["Allyn", "Andrew", ""], ["Stuart", "Michelle", ""], ["Pinsky", "Malin", ""], ["Mills", "Katherine", ""], ["Gomes", "Carla P.", ""]]}, {"id": "2010.16051", "submitter": "Alberto Barbado Gonzalez", "authors": "Alberto Barbado, \\'Oscar Corcho", "title": "Interpretable Machine Learning Models for Predicting and Explaining\n  Vehicle Fuel Consumption Anomalies", "comments": "25 pages, 10 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Identifying anomalies in the fuel consumption of the vehicles of a fleet is a\ncrucial aspect for optimizing consumption and reduce costs. However, this\ninformation alone is insufficient, since fleet operators need to know the\ncauses behind anomalous fuel consumption. We combine unsupervised anomaly\ndetection techniques, domain knowledge and interpretable Machine Learning\nmodels for explaining potential causes of abnormal fuel consumption in terms of\nfeature relevance. The explanations are used for generating recommendations\nabout fuel optimization, that are adjusted according to two different user\nprofiles: fleet managers and fleet operators. Results are evaluated over\nreal-world data from telematics devices connected to diesel and petrol vehicles\nfrom different types of industrial fleets. We measure the proposal regarding\nmodel performance, and using Explainable AI metrics that compare the\nexplanations in terms of representativeness, fidelity, stability,\ncontrastiveness and consistency with apriori beliefs. The potential fuel\nreductions that can be achieved is round 35%.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 16:50:17 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 16:37:26 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 08:52:32 GMT"}, {"version": "v4", "created": "Fri, 4 Dec 2020 18:28:18 GMT"}, {"version": "v5", "created": "Thu, 22 Jul 2021 12:13:17 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Barbado", "Alberto", ""], ["Corcho", "\u00d3scar", ""]]}, {"id": "2010.16052", "submitter": "Kamran Kowsari", "authors": "Mehrdad Fazli, Kamran Kowsari, Erfaneh Gharavi, Laura Barnes, Afsaneh\n  Doryab", "title": "HHAR-net: Hierarchical Human Activity Recognition using Neural Networks", "comments": "Accepted in IHCI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activity recognition using built-in sensors in smart and wearable devices\nprovides great opportunities to understand and detect human behavior in the\nwild and gives a more holistic view of individuals' health and well being.\nNumerous computational methods have been applied to sensor streams to recognize\ndifferent daily activities. However, most methods are unable to capture\ndifferent layers of activities concealed in human behavior. Also, the\nperformance of the models starts to decrease with increasing the number of\nactivities. This research aims at building a hierarchical classification with\nNeural Networks to recognize human activities based on different levels of\nabstraction. We evaluate our model on the Extrasensory dataset; a dataset\ncollected in the wild and containing data from smartphones and smartwatches. We\nuse a two-level hierarchy with a total of six mutually exclusive labels namely,\n\"lying down\", \"sitting\", \"standing in place\", \"walking\", \"running\", and\n\"bicycling\" divided into \"stationary\" and \"non-stationary\". The results show\nthat our model can recognize low-level activities (stationary/non-stationary)\nwith 95.8% accuracy and overall accuracy of 92.8% over six labels. This is 3%\nabove our best performing baseline.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 17:06:42 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 22:52:46 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Fazli", "Mehrdad", ""], ["Kowsari", "Kamran", ""], ["Gharavi", "Erfaneh", ""], ["Barnes", "Laura", ""], ["Doryab", "Afsaneh", ""]]}, {"id": "2010.16087", "submitter": "Kazuki Nakamura", "authors": "Kazuki Nakamura, Ryosuke Kojima, Eiichiro Uchino, Koichi Murashita,\n  Ken Itoh, Shigeyuki Nakaji and Yasushi Okuno", "title": "Health improvement framework for planning actionable treatment process\n  using surrogate Bayesian model", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-021-23319-1", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical decision making regarding treatments based on personal\ncharacteristics leads to effective health improvements. Machine learning (ML)\nhas been the primary concern of diagnosis support according to comprehensive\npatient information. However, the remaining prominent issue is the development\nof objective treatment processes in clinical situations. This study proposes a\nnovel framework to plan treatment processes in a data-driven manner. A key\npoint of the framework is the evaluation of the \"actionability\" for personal\nhealth improvements by using a surrogate Bayesian model in addition to a\nhigh-performance nonlinear ML model. We first evaluated the framework from the\nviewpoint of its methodology using a synthetic dataset. Subsequently, the\nframework was applied to an actual health checkup dataset comprising data from\n3,132 participants, to improve systolic blood pressure values at the individual\nlevel. We confirmed that the computed treatment processes are actionable and\nconsistent with clinical knowledge for lowering blood pressure. These results\ndemonstrate that our framework could contribute toward decision making in the\nmedical field, providing clinicians with deeper insights.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 06:02:49 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 08:13:18 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Nakamura", "Kazuki", ""], ["Kojima", "Ryosuke", ""], ["Uchino", "Eiichiro", ""], ["Murashita", "Koichi", ""], ["Itoh", "Ken", ""], ["Nakaji", "Shigeyuki", ""], ["Okuno", "Yasushi", ""]]}, {"id": "2010.16217", "submitter": "Katrin Schulz", "authors": "Fausto Barbero and Katrin Schulz and Sonja Smets and Fernando R.\n  Vel\\'azquez-Quesada and Kaibo Xie", "title": "Thinking About Causation: A Causal Language with Epistemic Operators", "comments": "This is the long version of a paper that is to be published in the\n  post-proceedings of the 3rd Dali Workshop on Dynamic Logic: New Trends and\n  Applications. The post-proceedings will be published by Springer as a Lecture\n  Notes in Computer Science volume", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a formal framework for modeling the interaction of causal\nand (qualitative) epistemic reasoning. To this purpose, we extend the notion of\na causal model with a representation of the epistemic state of an agent. On the\nside of the object language, we add operators to express knowledge and the act\nof observing new information. We provide a sound and complete axiomatization of\nthe logic, and discuss the relation of this framework to causal team semantics.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 12:16:45 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Barbero", "Fausto", ""], ["Schulz", "Katrin", ""], ["Smets", "Sonja", ""], ["Vel\u00e1zquez-Quesada", "Fernando R.", ""], ["Xie", "Kaibo", ""]]}, {"id": "2010.16218", "submitter": "Claudia Schulz", "authors": "Claudia Schulz and Josh Levy-Kramer and Camille Van Assel and Miklos\n  Kepes and Nils Hammerla", "title": "Biomedical Concept Relatedness -- A large EHR-based benchmark", "comments": "Accepted for publication at the 28th International Conference on\n  Computational Linguistics (COLING 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A promising application of AI to healthcare is the retrieval of information\nfrom electronic health records (EHRs), e.g. to aid clinicians in finding\nrelevant information for a consultation or to recruit suitable patients for a\nstudy. This requires search capabilities far beyond simple string matching,\nincluding the retrieval of concepts (diagnoses, symptoms, medications, etc.)\nrelated to the one in question. The suitability of AI methods for such\napplications is tested by predicting the relatedness of concepts with known\nrelatedness scores. However, all existing biomedical concept relatedness\ndatasets are notoriously small and consist of hand-picked concept pairs. We\nopen-source a novel concept relatedness benchmark overcoming these issues: it\nis six times larger than existing datasets and concept pairs are chosen based\non co-occurrence in EHRs, ensuring their relevance for the application of\ninterest. We present an in-depth analysis of our new dataset and compare it to\nexisting ones, highlighting that it is not only larger but also complements\nexisting datasets in terms of the types of concepts included. Initial\nexperiments with state-of-the-art embedding methods show that our dataset is a\nchallenging new benchmark for testing concept relatedness models.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 12:20:18 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Schulz", "Claudia", ""], ["Levy-Kramer", "Josh", ""], ["Van Assel", "Camille", ""], ["Kepes", "Miklos", ""], ["Hammerla", "Nils", ""]]}, {"id": "2010.16228", "submitter": "Gerasimos Spanakis", "authors": "Thalea Schlender and Gerasimos Spanakis", "title": "\"Thy algorithm shalt not bear false witness\": An Evaluation of\n  Multiclass Debiasing Methods on Word Embeddings", "comments": "15 pages, presented at BNAIC/BENELEARN 2020, data/code at\n  https://github.com/thaleaschlender/An-Evaluation-of-Multiclass-Debiasing-Methods-on-Word-Embeddings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the vast development and employment of artificial intelligence\napplications, research into the fairness of these algorithms has been\nincreased. Specifically, in the natural language processing domain, it has been\nshown that social biases persist in word embeddings and are thus in danger of\namplifying these biases when used. As an example of social bias, religious\nbiases are shown to persist in word embeddings and the need for its removal is\nhighlighted. This paper investigates the state-of-the-art multiclass debiasing\ntechniques: Hard debiasing, SoftWEAT debiasing and Conceptor debiasing. It\nevaluates their performance when removing religious bias on a common basis by\nquantifying bias removal via the Word Embedding Association Test (WEAT), Mean\nAverage Cosine Similarity (MAC) and the Relative Negative Sentiment Bias\n(RNSB). By investigating the religious bias removal on three widely used word\nembeddings, namely: Word2Vec, GloVe, and ConceptNet, it is shown that the\npreferred method is ConceptorDebiasing. Specifically, this technique manages to\ndecrease the measured religious bias on average by 82,42%, 96,78% and 54,76%\nfor the three word embedding sets respectively.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 12:49:39 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 09:24:21 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Schlender", "Thalea", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "2010.16241", "submitter": "Elena Stamm", "authors": "Andreas Christ, Franz Quint (eds.)", "title": "Artificial Intelligence: Research Impact on Key Industries; the\n  Upper-Rhine Artificial Intelligence Symposium (UR-AI 2020)", "comments": "ISBN 978-3-943301-29-8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The TriRhenaTech alliance presents a collection of accepted papers of the\ncancelled tri-national 'Upper-Rhine Artificial Inteeligence Symposium' planned\nfor 13th May 2020 in Karlsruhe. The TriRhenaTech alliance is a network of\nuniversities in the Upper-Rhine Trinational Metropolitan Region comprising of\nthe German universities of applied sciences in Furtwangen, Kaiserslautern,\nKarlsruhe, and Offenburg, the Baden-Wuerttemberg Cooperative State University\nLoerrach, the French university network Alsace Tech (comprised of 14 'grandes\n\\'ecoles' in the fields of engineering, architecture and management) and the\nUniversity of Applied Sciences and Arts Northwestern Switzerland. The\nalliance's common goal is to reinforce the transfer of knowledge, research, and\ntechnology, as well as the cross-border mobility of students.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 06:54:46 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Christ", "Andreas", "", "eds."], ["Quint", "Franz", "", "eds."]]}, {"id": "2010.16243", "submitter": "Dimiter Dobrev", "authors": "Dimiter Dobrev", "title": "Language for Description of Worlds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We will reduce the task of creating AI to the task of finding an appropriate\nlanguage for description of the world. This will not be a programing language\nbecause programing languages describe only computable functions, while our\nlanguage will describe a somewhat broader class of functions. Another\nspecificity of this language will be that the description will consist of\nseparate modules. This will enable us look for the description of the world\nautomatically such that we discover it module after module. Our approach to the\ncreation of this new language will be to start with a particular world and\nwrite the description of that particular world. The point is that the language\nwhich can describe this particular world will be appropriate for describing any\nworld.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 14:13:51 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 08:38:37 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 13:01:20 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Dobrev", "Dimiter", ""]]}, {"id": "2010.16244", "submitter": "Aditya Gulati", "authors": "Aditya Gulati, Sarthak Soni, Shrisha Rao", "title": "Interleaving Fast and Slow Decision Making", "comments": "7 pages, 11 figures; typos corrected, references added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The \"Thinking, Fast and Slow\" paradigm of Kahneman proposes that we use two\ndifferent styles of thinking -- a fast and intuitive System 1 for certain\ntasks, along with a slower but more analytical System 2 for others. While the\nidea of using this two-system style of thinking is gaining popularity in AI and\nrobotics, our work considers how to interleave the two styles of\ndecision-making, i.e., how System 1 and System 2 should be used together. For\nthis, we propose a novel and general framework which includes a new System 0 to\noversee Systems 1 and 2. At every point when a decision needs to be made,\nSystem 0 evaluates the situation and quickly hands over the decision-making\nprocess to either System 1 or System 2. We evaluate such a framework on a\nmodified version of the classic Pac-Man game, with an already-trained RL\nalgorithm for System 1, a Monte-Carlo tree search for System 2, and several\ndifferent possible strategies for System 0. As expected, arbitrary switches\nbetween Systems 1 and 2 do not work, but certain strategies do well. With\nSystem 0, an agent is able to perform better than one that uses only System 1\nor System 2.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 13:16:10 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 16:49:24 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Gulati", "Aditya", ""], ["Soni", "Sarthak", ""], ["Rao", "Shrisha", ""]]}, {"id": "2010.16298", "submitter": "Elie Aljalbout", "authors": "Elie Aljalbout and Ji Chen and Konstantin Ritt and Maximilian Ulmer\n  and Sami Haddadin", "title": "Learning Vision-based Reactive Policies for Obstacle Avoidance", "comments": "Accepted for publication at CoRL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of vision-based obstacle avoidance for\nrobotic manipulators. This topic poses challenges for both perception and\nmotion generation. While most work in the field aims at improving one of those\naspects, we provide a unified framework for approaching this problem. The main\ngoal of this framework is to connect perception and motion by identifying the\nrelationship between the visual input and the corresponding motion\nrepresentation. To this end, we propose a method for learning reactive obstacle\navoidance policies. We evaluate our method on goal-reaching tasks for single\nand multiple obstacles scenarios. We show the ability of the proposed method to\nefficiently learn stable obstacle avoidance strategies at a high success rate,\nwhile maintaining closed-loop responsiveness required for critical applications\nlike human-robot interaction.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 14:50:32 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Aljalbout", "Elie", ""], ["Chen", "Ji", ""], ["Ritt", "Konstantin", ""], ["Ulmer", "Maximilian", ""], ["Haddadin", "Sami", ""]]}, {"id": "2010.16322", "submitter": "Francesco Salvetti", "authors": "Vittorio Mazzia, Francesco Salvetti, Diego Aghi and Marcello Chiaberge", "title": "DeepWay: a Deep Learning Waypoint Estimator for Global Path Generation", "comments": "Submitted to Computers and Electronics in Agriculture", "journal-ref": "Volume 184, May 2021, 106091", "doi": "10.1016/j.compag.2021.106091", "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agriculture 3.0 and 4.0 have gradually introduced service robotics and\nautomation into several agricultural processes, mostly improving crops quality\nand seasonal yield. Row-based crops are the perfect settings to test and deploy\nsmart machines capable of monitoring and manage the harvest. In this context,\nglobal path generation is essential either for ground or aerial vehicles, and\nit is the starting point for every type of mission plan. Nevertheless, little\nattention has been currently given to this problem by the research community\nand global path generation automation is still far to be solved. In order to\ngenerate a viable path for an autonomous machine, the presented research\nproposes a feature learning fully convolutional model capable of estimating\nwaypoints given an occupancy grid map. In particular, we apply the proposed\ndata-driven methodology to the specific case of row-based crops with the\ngeneral objective to generate a global path able to cover the extension of the\ncrop completely. Extensive experimentation with a custom made synthetic dataset\nand real satellite-derived images of different scenarios have proved the\neffectiveness of our methodology and demonstrated the feasibility of an\nend-to-end and completely autonomous global path planner.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 15:27:42 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 17:01:14 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Mazzia", "Vittorio", ""], ["Salvetti", "Francesco", ""], ["Aghi", "Diego", ""], ["Chiaberge", "Marcello", ""]]}, {"id": "2010.16326", "submitter": "Ievgen Redko", "authors": "Charlotte Laclau, Ievgen Redko, Manvi Choudhary, Christine Largeron", "title": "All of the Fairness for Edge Prediction with Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and data mining algorithms have been increasingly used\nrecently to support decision-making systems in many areas of high societal\nimportance such as healthcare, education, or security. While being very\nefficient in their predictive abilities, the deployed algorithms sometimes tend\nto learn an inductive model with a discriminative bias due to the presence of\nthis latter in the learning sample. This problem gave rise to a new field of\nalgorithmic fairness where the goal is to correct the discriminative bias\nintroduced by a certain attribute in order to decorrelate it from the model's\noutput. In this paper, we study the problem of fairness for the task of edge\nprediction in graphs, a largely underinvestigated scenario compared to a more\npopular setting of fair classification. To this end, we formulate the problem\nof fair edge prediction, analyze it theoretically, and propose an\nembedding-agnostic repairing procedure for the adjacency matrix of an arbitrary\ngraph with a trade-off between the group and individual fairness. We\nexperimentally show the versatility of our approach and its capacity to provide\nexplicit control over different notions of fairness and prediction accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 15:33:13 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Laclau", "Charlotte", ""], ["Redko", "Ievgen", ""], ["Choudhary", "Manvi", ""], ["Largeron", "Christine", ""]]}, {"id": "2010.16336", "submitter": "Ari Kobren", "authors": "Naveen Jafer Nizar, Ari Kobren", "title": "Leveraging Extracted Model Adversaries for Improved Black Box Attacks", "comments": null, "journal-ref": "Analyzing and interpreting neural networks for NLP, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for adversarial input generation against black box models\nfor reading comprehension based question answering. Our approach is composed of\ntwo steps. First, we approximate a victim black box model via model extraction\n(Krishna et al., 2020). Second, we use our own white box method to generate\ninput perturbations that cause the approximate model to fail. These perturbed\ninputs are used against the victim. In experiments we find that our method\nimproves on the efficacy of the AddAny---a white box attack---performed on the\napproximate model by 25% F1, and the AddSent attack---a black box attack---by\n11% F1 (Jia and Liang, 2017).\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 15:53:50 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 16:38:30 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Nizar", "Naveen Jafer", ""], ["Kobren", "Ari", ""]]}, {"id": "2010.16342", "submitter": "Kartik Paigwar", "authors": "Kartik Paigwar, Lokesh Krishna, Sashank Tirumala, Naman Khetan, Aditya\n  Sagi, Ashish Joglekar, Shalabh Bhatnagar, Ashitava Ghosal, Bharadwaj Amrutur,\n  Shishir Kolathaya", "title": "Robust Quadrupedal Locomotion on Sloped Terrains: A Linear Policy\n  Approach", "comments": "Accepted in 4th Conference on Robot Learning 2020, MIT, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, with a view toward fast deployment of locomotion gaits in\nlow-cost hardware, we use a linear policy for realizing end-foot trajectories\nin the quadruped robot, Stoch $2$. In particular, the parameters of the\nend-foot trajectories are shaped via a linear feedback policy that takes the\ntorso orientation and the terrain slope as inputs. The corresponding desired\njoint angles are obtained via an inverse kinematics solver and tracked via a\nPID control law. Augmented Random Search, a model-free and a gradient-free\nlearning algorithm is used to train this linear policy. Simulation results show\nthat the resulting walking is robust to terrain slope variations and external\npushes. This methodology is not only computationally light-weight but also uses\nminimal sensing and actuation capabilities in the robot, thereby justifying the\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 16:02:08 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 12:29:13 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Paigwar", "Kartik", ""], ["Krishna", "Lokesh", ""], ["Tirumala", "Sashank", ""], ["Khetan", "Naman", ""], ["Sagi", "Aditya", ""], ["Joglekar", "Ashish", ""], ["Bhatnagar", "Shalabh", ""], ["Ghosal", "Ashitava", ""], ["Amrutur", "Bharadwaj", ""], ["Kolathaya", "Shishir", ""]]}, {"id": "2010.16357", "submitter": "Tavpritesh Sethi", "authors": "Ridam Pal, Rohan Pandey, Vaibhav Gautam, Kanav Bhagat, Tavpritesh\n  Sethi", "title": "A Cross-lingual Natural Language Processing Framework for Infodemic\n  Management", "comments": "8 Pages, 2 Figures, 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The COVID-19 pandemic has put immense pressure on health systems which are\nfurther strained due to the misinformation surrounding it. Under such a\nsituation, providing the right information at the right time is crucial. There\nis a growing demand for the management of information spread using Artificial\nIntelligence. Hence, we have exploited the potential of Natural Language\nProcessing for identifying relevant information that needs to be disseminated\namongst the masses. In this work, we present a novel Cross-lingual Natural\nLanguage Processing framework to provide relevant information by matching daily\nnews with trusted guidelines from the World Health Organization. The proposed\npipeline deploys various techniques of NLP such as summarizers, word\nembeddings, and similarity metrics to provide users with news articles along\nwith a corresponding healthcare guideline. A total of 36 models were evaluated\nand a combination of LexRank based summarizer on Word2Vec embedding with Word\nMover distance metric outperformed all other models. This novel open-source\napproach can be used as a template for proactive dissemination of relevant\nhealthcare information in the midst of misinformation spread associated with\nepidemics.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 16:26:35 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Pal", "Ridam", ""], ["Pandey", "Rohan", ""], ["Gautam", "Vaibhav", ""], ["Bhagat", "Kanav", ""], ["Sethi", "Tavpritesh", ""]]}, {"id": "2010.16399", "submitter": "Anand A. Rajasekar", "authors": "Anand A. Rajasekar, Karthik Raman, Balaraman Ravindran", "title": "Goal directed molecule generation using Monte Carlo Tree Search", "comments": "6 pages, 2 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One challenging and essential task in biochemistry is the generation of novel\nmolecules with desired properties. Novel molecule generation remains a\nchallenge since the molecule space is difficult to navigate through, and the\ngenerated molecules should obey the rules of chemical valency. Through this\nwork, we propose a novel method, which we call unitMCTS, to perform molecule\ngeneration by making a unit change to the molecule at every step using Monte\nCarlo Tree Search. We show that this method outperforms the recently published\ntechniques on benchmark molecular optimization tasks such as QED and penalized\nlogP. We also demonstrate the usefulness of this method in improving molecule\nproperties while being similar to the starting molecule. Given that there is no\nlearning involved, our method finds desired molecules within a shorter amount\nof time.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 17:49:59 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 17:56:19 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Rajasekar", "Anand A.", ""], ["Raman", "Karthik", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "2010.16409", "submitter": "Yuzi He", "authors": "Yuzi He, Keith Burghardt, Siyi Guo, Kristina Lerman", "title": "Inherent Trade-offs in the Fair Allocation of Treatments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explicit and implicit bias clouds human judgement, leading to discriminatory\ntreatment of minority groups. A fundamental goal of algorithmic fairness is to\navoid the pitfalls in human judgement by learning policies that improve the\noverall outcomes while providing fair treatment to protected classes. In this\npaper, we propose a causal framework that learns optimal intervention policies\nfrom data subject to fairness constraints. We define two measures of treatment\nbias and infer best treatment assignment that minimizes the bias while\noptimizing overall outcome. We demonstrate that there is a dilemma of balancing\nfairness and overall benefit; however, allowing preferential treatment to\nprotected classes in certain circumstances (affirmative action) can\ndramatically improve the overall benefit while also preserving fairness. We\napply our framework to data containing student outcomes on standardized tests\nand show how it can be used to design real-world policies that fairly improve\nstudent test scores. Our framework provides a principled way to learn fair\ntreatment policies in real-world settings.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 17:55:00 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["He", "Yuzi", ""], ["Burghardt", "Keith", ""], ["Guo", "Siyi", ""], ["Lerman", "Kristina", ""]]}]