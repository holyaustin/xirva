[{"id": "1602.00165", "submitter": "Amulya Yadav", "authors": "Amulya Yadav, Hau Chan, Albert Jiang, Haifeng Xu, Eric Rice, Milind\n  Tambe", "title": "Using Social Networks to Aid Homeless Shelters: Dynamic Influence\n  Maximization under Uncertainty - An Extended Version", "comments": "This is an extended version of our AAMAS 2016 paper (with the same\n  name) with full proofs of all our theorems included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents HEALER, a software agent that recommends sequential\nintervention plans for use by homeless shelters, who organize these\ninterventions to raise awareness about HIV among homeless youth. HEALER's\nsequential plans (built using knowledge of social networks of homeless youth)\nchoose intervention participants strategically to maximize influence spread,\nwhile reasoning about uncertainties in the network. While previous work\npresents influence maximizing techniques to choose intervention participants,\nthey do not address three real-world issues: (i) they completely fail to scale\nup to real-world sizes; (ii) they do not handle deviations in execution of\nintervention plans; (iii) constructing real-world social networks is an\nexpensive process. HEALER handles these issues via four major contributions:\n(i) HEALER casts this influence maximization problem as a POMDP and solves it\nusing a novel planner which scales up to previously unsolvable real-world\nsizes; (ii) HEALER allows shelter officials to modify its recommendations, and\nupdates its future plans in a deviation-tolerant manner; (iii) HEALER\nconstructs social networks of homeless youth at low cost, using a Facebook\napplication. Finally, (iv) we show hardness results for the problem that HEALER\nsolves. HEALER will be deployed in the real world in early Spring 2016 and is\ncurrently undergoing testing at a homeless shelter.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2016 21:59:27 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Yadav", "Amulya", ""], ["Chan", "Hau", ""], ["Jiang", "Albert", ""], ["Xu", "Haifeng", ""], ["Rice", "Eric", ""], ["Tambe", "Milind", ""]]}, {"id": "1602.00198", "submitter": "Chuyu Xiong", "authors": "Chuyu Xiong", "title": "Discussion on Mechanical Learning and Learning Machine", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mechanical learning is a computing system that is based on a set of simple\nand fixed rules, and can learn from incoming data. A learning machine is a\nsystem that realizes mechanical learning. Importantly, we emphasis that it is\nbased on a set of simple and fixed rules, contrasting to often called machine\nlearning that is sophisticated software based on very complicated mathematical\ntheory, and often needs human intervene for software fine tune and manual\nadjustments. Here, we discuss some basic facts and principles of such system,\nand try to lay down a framework for further study. We propose 2 directions to\napproach mechanical learning, just like Church-Turing pair: one is trying to\nrealize a learning machine, another is trying to well describe the mechanical\nlearning.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2016 04:05:50 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Xiong", "Chuyu", ""]]}, {"id": "1602.00203", "submitter": "Angshul Majumdar Dr.", "authors": "Snigdha Tariyal, Angshul Majumdar, Richa Singh and Mayank Vatsa", "title": "Greedy Deep Dictionary Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a new deep learning tool called deep dictionary\nlearning. Multi-level dictionaries are learnt in a greedy fashion, one layer at\na time. This requires solving a simple (shallow) dictionary learning problem,\nthe solution to this is well known. We apply the proposed technique on some\nbenchmark deep learning datasets. We compare our results with other deep\nlearning tools like stacked autoencoder and deep belief network; and state of\nthe art supervised dictionary learning tools like discriminative KSVD and label\nconsistent KSVD. Our method yields better results than all.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2016 06:12:58 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Tariyal", "Snigdha", ""], ["Majumdar", "Angshul", ""], ["Singh", "Richa", ""], ["Vatsa", "Mayank", ""]]}, {"id": "1602.00269", "submitter": "Sunil Mandhan", "authors": "Sarath P R, Sunil Mandhan, Yoshiki Niwa", "title": "Numerical Atrribute Extraction from Clinical Texts", "comments": "6 Pages", "journal-ref": null, "doi": "10.13140/RG.2.1.4763.3365", "report-no": "Submission 42, CLEF 2015", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes about information extraction system, which is an\nextension of the system developed by team Hitachi for \"Disease/Disorder\nTemplate filling\" task organized by ShARe/CLEF eHealth Evolution Lab 2014. In\nthis extension module we focus on extraction of numerical attributes and values\nfrom discharge summary records and associating correct relation between\nattributes and values. We solve the problem in two steps. First step is\nextraction of numerical attributes and values, which is developed as a Named\nEntity Recognition (NER) model using Stanford NLP libraries. Second step is\ncorrectly associating the attributes to values, which is developed as a\nrelation extraction module in Apache cTAKES framework. We integrated Stanford\nNER model as cTAKES pipeline component and used in relation extraction module.\nConditional Random Field (CRF) algorithm is used for NER and Support Vector\nMachines (SVM) for relation extraction. For attribute value relation\nextraction, we observe 95% accuracy using NER alone and combined accuracy of\n87% with NER and SVM.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2016 15:58:51 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["R", "Sarath P", ""], ["Mandhan", "Sunil", ""], ["Niwa", "Yoshiki", ""]]}, {"id": "1602.00487", "submitter": "Frederic Francois", "authors": "Frederic Francois and Erol Gelenbe", "title": "Towards a Cognitive Routing Engine for Software Defined Networks", "comments": "This is a non-final version of the paper submitted to IEEE ICC 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most Software Defined Networks (SDN) traffic engineering applications use\nexcessive and frequent global monitoring in order to find the optimal\nQuality-of-Service (QoS) paths for the current state of the network. In this\nwork, we present the motivations, architecture and initial evaluation of a SDN\napplication called Cognitive Routing Engine (CRE) which is able to find\nnear-optimal paths for a user-specified QoS while using a very small monitoring\noverhead compared to global monitoring which is required to guarantee that\noptimal paths are found. Smaller monitoring overheads bring the advantage of\nsmaller response time for the SDN controllers and switches. The initial\nevaluation of CRE on a SDN representation of the GEANT academic network shows\nthat it is possible to find near-optimal paths with a small optimality gap of\n1.65% while using 9.5 times less monitoring.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2016 11:56:44 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Francois", "Frederic", ""], ["Gelenbe", "Erol", ""]]}, {"id": "1602.00515", "submitter": "Nikola Milo\\v{s}evi\\'c MSc", "authors": "Nikola Milosevic", "title": "Marvin: Semantic annotation using multiple knowledge sources", "comments": "9 pages, 4 figures, keywords: Semantic annotation, text\n  normalization, semantic web, linked data, information management, text\n  mining, information extraction, data curation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  People are producing more written material then anytime in the history. The\nincrease is so high that professionals from the various fields are no more able\nto cope with this amount of publications. Text mining tools can offer tools to\nhelp them and one of the tools that can aid information retrieval and\ninformation extraction is semantic text annotation. In this report we present\nMarvin, a text annotator written in Java, which can be used as a command line\ntool and as a Java library. Marvin is able to annotate text using multiple\nsources, including WordNet, MetaMap, DBPedia and thesauri represented as SKOS.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2016 13:27:34 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2016 11:31:17 GMT"}], "update_date": "2016-02-03", "authors_parsed": [["Milosevic", "Nikola", ""]]}, {"id": "1602.00753", "submitter": "Hessam Bagherinezhad", "authors": "Hessam Bagherinezhad, Hannaneh Hajishirzi, Yejin Choi, Ali Farhadi", "title": "Are Elephants Bigger than Butterflies? Reasoning about Sizes of Objects", "comments": "To appear in AAAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human vision greatly benefits from the information about sizes of objects.\nThe role of size in several visual reasoning tasks has been thoroughly explored\nin human perception and cognition. However, the impact of the information about\nsizes of objects is yet to be determined in AI. We postulate that this is\nmainly attributed to the lack of a comprehensive repository of size\ninformation. In this paper, we introduce a method to automatically infer object\nsizes, leveraging visual and textual information from web. By maximizing the\njoint likelihood of textual and visual observations, our method learns reliable\nrelative size estimates, with no explicit human supervision. We introduce the\nrelative size dataset and show that our method outperforms competitive textual\nand visual baselines in reasoning about size comparisons.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 00:16:39 GMT"}], "update_date": "2016-02-03", "authors_parsed": [["Bagherinezhad", "Hessam", ""], ["Hajishirzi", "Hannaneh", ""], ["Choi", "Yejin", ""], ["Farhadi", "Ali", ""]]}, {"id": "1602.00991", "submitter": "Peter Ondruska", "authors": "Peter Ondruska and Ingmar Posner", "title": "Deep Tracking: Seeing Beyond Seeing Using Recurrent Neural Networks", "comments": "Published in The Thirtieth AAAI Conference on Artificial Intelligence\n  (AAAI-16), Video: https://youtu.be/cdeWCpfUGWc, Code:\n  http://mrg.robots.ox.ac.uk/mrg_people/peter-ondruska/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents to the best of our knowledge the first end-to-end object\ntracking approach which directly maps from raw sensor input to object tracks in\nsensor space without requiring any feature engineering or system identification\nin the form of plant or sensor models. Specifically, our system accepts a\nstream of raw sensor data at one end and, in real-time, produces an estimate of\nthe entire environment state at the output including even occluded objects. We\nachieve this by framing the problem as a deep learning task and exploit\nsequence models in the form of recurrent neural networks to learn a mapping\nfrom sensor measurements to object tracks. In particular, we propose a learning\nmethod based on a form of input dropout which allows learning in an\nunsupervised manner, only based on raw, occluded sensor data without access to\nground-truth annotations. We demonstrate our approach using a synthetic dataset\ndesigned to mimic the task of tracking objects in 2D laser data -- as commonly\nencountered in robotics applications -- and show that it learns to track many\ndynamic objects despite occlusions and the presence of sensor noise.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 16:10:16 GMT"}, {"version": "v2", "created": "Tue, 8 Mar 2016 22:09:05 GMT"}], "update_date": "2016-03-10", "authors_parsed": [["Ondruska", "Peter", ""], ["Posner", "Ingmar", ""]]}, {"id": "1602.01059", "submitter": "Nicolas Maudet", "authors": "Elise Bonzon (LIPADE), J\\'er\\^ome Delobelle (CRIL), S\\'ebastien\n  Konieczny (CRIL), Nicolas Maudet (LIP6)", "title": "A Comparative Study of Ranking-based Semantics for Abstract\n  Argumentation", "comments": "Proceedings of the 30th AAAI Conference on Artificial Intelligence\n  (AAAI-2016), Feb 2016, Phoenix, United States", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Argumentation is a process of evaluating and comparing a set of arguments. A\nway to compare them consists in using a ranking-based semantics which\nrank-order arguments from the most to the least acceptable ones. Recently, a\nnumber of such semantics have been proposed independently, often associated\nwith some desirable properties. However, there is no comparative study which\ntakes a broader perspective. This is what we propose in this work. We provide a\ngeneral comparison of all these semantics with respect to the proposed\nproperties. That allows to underline the differences of behavior between the\nexisting semantics.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 19:49:03 GMT"}], "update_date": "2016-02-03", "authors_parsed": [["Bonzon", "Elise", "", "LIPADE"], ["Delobelle", "J\u00e9r\u00f4me", "", "CRIL"], ["Konieczny", "S\u00e9bastien", "", "CRIL"], ["Maudet", "Nicolas", "", "LIP6"]]}, {"id": "1602.01208", "submitter": "Akira Taniguchi", "authors": "Akira Taniguchi, Tadahiro Taniguchi and Tetsunari Inamura", "title": "Spatial Concept Acquisition for a Mobile Robot that Integrates\n  Self-Localization and Unsupervised Word Discovery from Spoken Sentences", "comments": "This paper was accepted in the IEEE Transactions on Cognitive and\n  Developmental Systems. (04-May-2016)", "journal-ref": null, "doi": "10.1109/TCDS.2016.2565542", "report-no": null, "categories": "cs.AI cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel unsupervised learning method for the\nlexical acquisition of words related to places visited by robots, from human\ncontinuous speech signals. We address the problem of learning novel words by a\nrobot that has no prior knowledge of these words except for a primitive\nacoustic model. Further, we propose a method that allows a robot to effectively\nuse the learned words and their meanings for self-localization tasks. The\nproposed method is nonparametric Bayesian spatial concept acquisition method\n(SpCoA) that integrates the generative model for self-localization and the\nunsupervised word segmentation in uttered sentences via latent variables\nrelated to the spatial concept. We implemented the proposed method SpCoA on\nSIGVerse, which is a simulation environment, and TurtleBot2, which is a mobile\nrobot in a real environment. Further, we conducted experiments for evaluating\nthe performance of SpCoA. The experimental results showed that SpCoA enabled\nthe robot to acquire the names of places from speech sentences. They also\nrevealed that the robot could effectively utilize the acquired spatial concepts\nand reduce the uncertainty in self-localization.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 06:56:51 GMT"}, {"version": "v2", "created": "Wed, 16 Mar 2016 12:17:46 GMT"}, {"version": "v3", "created": "Sat, 7 May 2016 11:59:51 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Taniguchi", "Akira", ""], ["Taniguchi", "Tadahiro", ""], ["Inamura", "Tetsunari", ""]]}, {"id": "1602.01398", "submitter": "Usman Habib Usman Habib", "authors": "Usman Habib, Gerhard Zucker", "title": "Finding the different patterns in buildings data using bag of words\n  representation with clustering", "comments": null, "journal-ref": null, "doi": "10.1109/FIT.2015.60", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The understanding of the buildings operation has become a challenging task\ndue to the large amount of data recorded in energy efficient buildings. Still,\ntoday the experts use visual tools for analyzing the data. In order to make the\ntask realistic, a method has been proposed in this paper to automatically\ndetect the different patterns in buildings. The K Means clustering is used to\nautomatically identify the ON (operational) cycles of the chiller. In the next\nstep the ON cycles are transformed to symbolic representation by using Symbolic\nAggregate Approximation (SAX) method. Then the SAX symbols are converted to bag\nof words representation for hierarchical clustering. Moreover, the proposed\ntechnique is applied to real life data of adsorption chiller. Additionally, the\nresults from the proposed method and dynamic time warping (DTW) approach are\nalso discussed and compared.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 18:11:32 GMT"}], "update_date": "2016-03-04", "authors_parsed": [["Habib", "Usman", ""], ["Zucker", "Gerhard", ""]]}, {"id": "1602.01576", "submitter": "Anantharaman Palacode Narayana Iyer", "authors": "Anantharaman Palacode Narayana Iyer", "title": "A Factorized Recurrent Neural Network based architecture for medium to\n  large vocabulary Language Modelling", "comments": "8 pages", "journal-ref": null, "doi": "10.1109/ICSC.2016.37", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical language models are central to many applications that use\nsemantics. Recurrent Neural Networks (RNN) are known to produce state of the\nart results for language modelling, outperforming their traditional n-gram\ncounterparts in many cases. To generate a probability distribution across a\nvocabulary, these models require a softmax output layer that linearly increases\nin size with the size of the vocabulary. Large vocabularies need a\ncommensurately large softmax layer and training them on typical laptops/PCs\nrequires significant time and machine resources. In this paper we present a new\ntechnique for implementing RNN based large vocabulary language models that\nsubstantially speeds up computation while optimally using the limited memory\nresources. Our technique, while building on the notion of factorizing the\noutput layer by having multiple output layers, improves on the earlier work by\nsubstantially optimizing on the individual output layer size and also\neliminating the need for a multistep prediction process.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2016 07:53:11 GMT"}], "update_date": "2016-02-05", "authors_parsed": [["Iyer", "Anantharaman Palacode Narayana", ""]]}, {"id": "1602.01585", "submitter": "Ruining He", "authors": "Ruining He, Julian McAuley", "title": "Ups and Downs: Modeling the Visual Evolution of Fashion Trends with\n  One-Class Collaborative Filtering", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": "10.1145/2872427.2883037", "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building a successful recommender system depends on understanding both the\ndimensions of people's preferences as well as their dynamics. In certain\ndomains, such as fashion, modeling such preferences can be incredibly\ndifficult, due to the need to simultaneously model the visual appearance of\nproducts as well as their evolution over time. The subtle semantics and\nnon-linear dynamics of fashion evolution raise unique challenges especially\nconsidering the sparsity and large scale of the underlying datasets. In this\npaper we build novel models for the One-Class Collaborative Filtering setting,\nwhere our goal is to estimate users' fashion-aware personalized ranking\nfunctions based on their past feedback. To uncover the complex and evolving\nvisual factors that people consider when evaluating products, our method\ncombines high-level visual features extracted from a deep convolutional neural\nnetwork, users' past feedback, as well as evolving trends within the community.\nExperimentally we evaluate our method on two large real-world datasets from\nAmazon.com, where we show it to outperform state-of-the-art personalized\nranking measures, and also use it to visualize the high-level fashion trends\nacross the 11-year span of our dataset.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2016 08:31:05 GMT"}], "update_date": "2016-02-05", "authors_parsed": [["He", "Ruining", ""], ["McAuley", "Julian", ""]]}, {"id": "1602.01628", "submitter": "Dmytro Terletskyi", "authors": "D. A. Terletskyi, A. I. Provotar", "title": "Fuzzy Object-Oriented Dynamic Networks. II", "comments": "2 figures", "journal-ref": "Cybernetics and Systems Analysis, 2016, Volume 52, Issue 1, pp\n  38-45", "doi": "10.1007/s10559-016-9797-2", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article generalizes object-oriented dynamic networks to the fuzzy case,\nwhich allows one to represent knowledge on objects and classes of objects that\nare fuzzy by nature and also to model their changes in time. Within the\nframework of the approach described, a mechanism is proposed that makes it\npossible to acquire new knowledge on the basis of basic knowledge and\nconsiderably differs from well-known methods used in existing models of\nknowledge representation. The approach is illustrated by an example of\nconstruction of a concrete fuzzy object-oriented dynamic network.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2016 10:50:13 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2016 19:25:12 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Terletskyi", "D. A.", ""], ["Provotar", "A. I.", ""]]}, {"id": "1602.01635", "submitter": "Jules Hedges", "authors": "Jules Hedges, Mehrnoosh Sadrzadeh", "title": "A Generalised Quantifier Theory of Natural Language in Categorical\n  Compositional Distributional Semantics with Bialgebras", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Categorical compositional distributional semantics is a model of natural\nlanguage; it combines the statistical vector space models of words with the\ncompositional models of grammar. We formalise in this model the generalised\nquantifier theory of natural language, due to Barwise and Cooper. The\nunderlying setting is a compact closed category with bialgebras. We start from\na generative grammar formalisation and develop an abstract categorical\ncompositional semantics for it, then instantiate the abstract setting to sets\nand relations and to finite dimensional vector spaces and linear maps. We prove\nthe equivalence of the relational instantiation to the truth theoretic\nsemantics of generalised quantifiers. The vector space instantiation formalises\nthe statistical usages of words and enables us to, for the first time, reason\nabout quantified phrases and sentences compositionally in distributional\nsemantics.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2016 11:15:28 GMT"}, {"version": "v2", "created": "Sat, 2 Sep 2017 10:55:58 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Hedges", "Jules", ""], ["Sadrzadeh", "Mehrnoosh", ""]]}, {"id": "1602.01718", "submitter": "Maryam Kamail", "authors": "Maryam Kamali and Louise A. Dennis and Owen McAree and Michael Fisher\n  and Sandor M. Veres", "title": "Formal Verification of Autonomous Vehicle Platooning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coordination of multiple autonomous vehicles into convoys or platoons is\nexpected on our highways in the near future. However, before such platoons can\nbe deployed, the new autonomous behaviors of the vehicles in these platoons\nmust be certified. An appropriate representation for vehicle platooning is as a\nmulti-agent system in which each agent captures the \"autonomous decisions\"\ncarried out by each vehicle. In order to ensure that these autonomous\ndecision-making agents in vehicle platoons never violate safety requirements,\nwe use formal verification. However, as the formal verification technique used\nto verify the agent code does not scale to the full system and as the global\nverification technique does not capture the essential verification of\nautonomous behavior, we use a combination of the two approaches. This mixed\nstrategy allows us to verify safety requirements not only of a model of the\nsystem, but of the actual agent code used to program the autonomous vehicles.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2016 15:50:22 GMT"}], "update_date": "2016-02-05", "authors_parsed": [["Kamali", "Maryam", ""], ["Dennis", "Louise A.", ""], ["McAree", "Owen", ""], ["Fisher", "Michael", ""], ["Veres", "Sandor M.", ""]]}, {"id": "1602.01921", "submitter": "Haanvid Lee", "authors": "Haanvid Lee, Minju Jung, and Jun Tani", "title": "Recognition of Visually Perceived Compositional Human Actions by\n  Multiple Spatio-Temporal Scales Recurrent Neural Networks", "comments": "10 pages, 9 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current paper proposes a novel neural network model for recognizing\nvisually perceived human actions. The proposed multiple spatio-temporal scales\nrecurrent neural network (MSTRNN) model is derived by introducing multiple\ntimescale recurrent dynamics to the conventional convolutional neural network\nmodel. One of the essential characteristics of the MSTRNN is that its\narchitecture imposes both spatial and temporal constraints simultaneously on\nthe neural activity which vary in multiple scales among different layers. As\nsuggested by the principle of the upward and downward causation, it is assumed\nthat the network can develop meaningful structures such as functional hierarchy\nby taking advantage of such constraints during the course of learning. To\nevaluate the characteristics of the model, the current study uses three types\nof human action video dataset consisting of different types of primitive\nactions and different levels of compositionality on them. The performance of\nthe MSTRNN in testing with these dataset is compared with the ones by other\nrepresentative deep learning models used in the field. The analysis of the\ninternal representation obtained through the learning with the dataset\nclarifies what sorts of functional hierarchy can be developed by extracting the\nessential compositionality underlying the dataset.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 04:00:16 GMT"}, {"version": "v2", "created": "Wed, 5 Oct 2016 07:59:03 GMT"}, {"version": "v3", "created": "Wed, 22 Feb 2017 16:33:49 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Lee", "Haanvid", ""], ["Jung", "Minju", ""], ["Tani", "Jun", ""]]}, {"id": "1602.01971", "submitter": "Erik Andresen", "authors": "Erik Andresen, David Haensel, Mohcine Chraibi, and Armin Seyfried", "title": "Wayfinding and cognitive maps for pedestrian models", "comments": "8 pages, 3 figures, TGF'15 Conference, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usually, routing models in pedestrian dynamics assume that agents have\nfulfilled and global knowledge about the building's structure. However, they\nneglect the fact that pedestrians possess no or only parts of information about\ntheir position relative to final exits and possible routes leading to them. To\nget a more realistic description we introduce the systematics of gathering and\nusing spatial knowledge. A new wayfinding model for pedestrian dynamics is\nproposed. The model defines for every pedestrian an individual knowledge\nrepresentation implying inaccuracies and uncertainties. In addition,\nknowledge-driven search strategies are introduced. The presented concept is\ntested on a fictive example scenario.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 10:25:15 GMT"}], "update_date": "2016-02-08", "authors_parsed": [["Andresen", "Erik", ""], ["Haensel", "David", ""], ["Chraibi", "Mohcine", ""], ["Seyfried", "Armin", ""]]}, {"id": "1602.02086", "submitter": "Peng Lin", "authors": "Peng Lin, Martin Neil, Norman Fenton", "title": "Region Based Approximation for High Dimensional Bayesian Network Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Performing efficient inference on Bayesian Networks (BNs), with large numbers\nof densely connected variables is challenging. With exact inference methods,\nsuch as the Junction Tree algorithm, clustering complexity can grow\nexponentially with the number of nodes and so computation becomes intractable.\nThis paper presents a general purpose approximate inference algorithm called\nTriplet Region Construction (TRC) that reduces the clustering complexity for\nfactorized models from worst case exponential to polynomial. We employ graph\nfactorization to reduce connection complexity and produce clusters of limited\nsize. Unlike MCMC algorithms TRC is guaranteed to converge and we present\nexperiments that show that TRC achieves accurate results when compared with\nexact solutions.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 16:35:51 GMT"}], "update_date": "2016-02-08", "authors_parsed": [["Lin", "Peng", ""], ["Neil", "Martin", ""], ["Fenton", "Norman", ""]]}, {"id": "1602.02089", "submitter": "Martha Lewis", "authors": "Martha Lewis, Bob Coecke", "title": "Harmonic Grammar in a DisCo Model of Meaning", "comments": "Abstract, Advances in Distributional Semantics, IWCS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The model of cognition developed in (Smolensky and Legendre, 2006) seeks to\nunify two levels of description of the cognitive process: the connectionist and\nthe symbolic. The theory developed brings together these two levels into the\nIntegrated Connectionist/Symbolic Cognitive architecture (ICS). Clark and\nPulman (2007) draw a parallel with semantics where meaning may be modelled on\nboth distributional and symbolic levels, developed by Coecke et al, 2010 into\nthe Distributional Compositional (DisCo) model of meaning. In the current work,\nwe revisit Smolensky and Legendre (S&L)'s model. We describe the DisCo\nframework, summarise the key ideas in S&L's architecture, and describe how\ntheir description of harmony as a graded measure of grammaticality may be\napplied in the DisCo model.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 16:40:44 GMT"}], "update_date": "2016-02-08", "authors_parsed": [["Lewis", "Martha", ""], ["Coecke", "Bob", ""]]}, {"id": "1602.02169", "submitter": "Mauricio Toro", "authors": "Mauricio Toro", "title": "Probabilistic Extension to the Concurrent Constraint Factor Oracle Model\n  for Music Improvisation", "comments": "70 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We can program a Real-Time (RT) music improvisation system in C++ without a\nformal semantic or we can model it with process calculi such as the\nNon-deterministic Timed Concurrent Constraint (ntcc) calculus. \"A Concurrent\nConstraints Factor Oracle (FO) model for Music Improvisation\" (Ccfomi) is an\nimprovisation model specified on ntcc. Since Ccfomi improvises\nnon-deterministically, there is no control on choices and therefore little\ncontrol over the sequence variation during the improvisation. To avoid this, we\nextended Ccfomi using the Probabilistic Non-deterministic Timed Concurrent\nConstraint calculus. Our extension to Ccfomi does not change the time and space\ncomplexity of building the FO, thus making our extension compatible with RT.\nHowever, there was not a ntcc interpreter capable of RT to execute Ccfomi. We\ndeveloped Ntccrt --a RT capable interpreter for ntcc-- and we executed Ccfomi\non Ntccrt. In the future, we plan to extend Ntccrt to execute our extension to\nCcfomi.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 21:26:53 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Toro", "Mauricio", ""]]}, {"id": "1602.02210", "submitter": "Aaditya Ramdas", "authors": "Ilmun Kim, Aaditya Ramdas, Aarti Singh, Larry Wasserman", "title": "Classification accuracy as a proxy for two sample testing", "comments": "71 pages, 4 figures. Accepted for publication at the Annals of\n  Statistics (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When data analysts train a classifier and check if its accuracy is\nsignificantly different from chance, they are implicitly performing a\ntwo-sample test. We investigate the statistical properties of this flexible\napproach in the high-dimensional setting. We prove two results that hold for\nall classifiers in any dimensions: if its true error remains $\\epsilon$-better\nthan chance for some $\\epsilon>0$ as $d,n \\to \\infty$, then (a) the\npermutation-based test is consistent (has power approaching to one), (b) a\ncomputationally efficient test based on a Gaussian approximation of the null\ndistribution is also consistent. To get a finer understanding of the rates of\nconsistency, we study a specialized setting of distinguishing Gaussians with\nmean-difference $\\delta$ and common (known or unknown) covariance $\\Sigma$,\nwhen $d/n \\to c \\in (0,\\infty)$. We study variants of Fisher's linear\ndiscriminant analysis (LDA) such as \"naive Bayes\" in a nontrivial regime when\n$\\epsilon \\to 0$ (the Bayes classifier has true accuracy approaching 1/2), and\ncontrast their power with corresponding variants of Hotelling's test.\nSurprisingly, the expressions for their power match exactly in terms of\n$n,d,\\delta,\\Sigma$, and the LDA approach is only worse by a constant factor,\nachieving an asymptotic relative efficiency (ARE) of $1/\\sqrt{\\pi}$ for\nbalanced samples. We also extend our results to high-dimensional elliptical\ndistributions with finite kurtosis. Other results of independent interest\ninclude minimax lower bounds, and the optimality of Hotelling's test when\n$d=o(n)$. Simulation results validate our theory, and we present practical\ntakeaway messages along with natural open problems.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2016 03:48:04 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 22:36:47 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 21:29:08 GMT"}, {"version": "v4", "created": "Mon, 17 Feb 2020 17:56:24 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Kim", "Ilmun", ""], ["Ramdas", "Aaditya", ""], ["Singh", "Aarti", ""], ["Wasserman", "Larry", ""]]}, {"id": "1602.02211", "submitter": "Mohamed El Halaby", "authors": "Mohamed El Halaby, Areeg Abdalla", "title": "Fuzzy Maximum Satisfiability", "comments": "10 pages", "journal-ref": null, "doi": "10.1145/2908446.2908476", "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we extend the Maximum Satisfiability (MaxSAT) problem to\n{\\L}ukasiewicz logic. The MaxSAT problem for a set of formulae {\\Phi} is the\nproblem of finding an assignment to the variables in {\\Phi} that satisfies the\nmaximum number of formulae. Three possible solutions (encodings) are proposed\nto the new problem: (1) Disjunctive Linear Relations (DLRs), (2) Mixed Integer\nLinear Programming (MILP) and (3) Weighted Constraint Satisfaction Problem\n(WCSP). Like its Boolean counterpart, the extended fuzzy MaxSAT will have\nnumerous applications in optimization problems that involve vagueness.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2016 03:57:57 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Halaby", "Mohamed El", ""], ["Abdalla", "Areeg", ""]]}, {"id": "1602.02261", "submitter": "Rodrigo Nogueira", "authors": "Rodrigo Nogueira and Kyunghyun Cho", "title": "End-to-End Goal-Driven Web Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a goal-driven web navigation as a benchmark task for evaluating an\nagent with abilities to understand natural language and plan on partially\nobserved environments. In this challenging task, an agent navigates through a\nwebsite, which is represented as a graph consisting of web pages as nodes and\nhyperlinks as directed edges, to find a web page in which a query appears. The\nagent is required to have sophisticated high-level reasoning based on natural\nlanguages and efficient sequential decision-making capability to succeed. We\nrelease a software tool, called WebNav, that automatically transforms a website\ninto this goal-driven web navigation task, and as an example, we make WikiNav,\na dataset constructed from the English Wikipedia. We extensively evaluate\ndifferent variants of neural net based artificial agents on WikiNav and observe\nthat the proposed goal-driven web navigation well reflects the advances in\nmodels, making it a suitable benchmark for evaluating future progress.\nFurthermore, we extend the WikiNav with question-answer pairs from Jeopardy!\nand test the proposed agent based on recurrent neural networks against strong\ninverted index based search engines. The artificial agents trained on WikiNav\noutperforms the engined based approaches, demonstrating the capability of the\nproposed goal-driven navigation as a good proxy for measuring the progress in\nreal-world tasks such as focused crawling and question-answering.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2016 14:53:02 GMT"}, {"version": "v2", "created": "Fri, 20 May 2016 16:26:58 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Nogueira", "Rodrigo", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1602.02332", "submitter": "Antti Puurula", "authors": "Antti Puurula", "title": "Scalable Text Mining with Sparse Generative Models", "comments": "PhD Thesis, Computer Science, University of Waikato, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The information age has brought a deluge of data. Much of this is in text\nform, insurmountable in scope for humans and incomprehensible in structure for\ncomputers. Text mining is an expanding field of research that seeks to utilize\nthe information contained in vast document collections. General data mining\nmethods based on machine learning face challenges with the scale of text data,\nposing a need for scalable text mining methods.\n  This thesis proposes a solution to scalable text mining: generative models\ncombined with sparse computation. A unifying formalization for generative text\nmodels is defined, bringing together research traditions that have used\nformally equivalent models, but ignored parallel developments. This framework\nallows the use of methods developed in different processing tasks such as\nretrieval and classification, yielding effective solutions across different\ntext mining tasks. Sparse computation using inverted indices is proposed for\ninference on probabilistic models. This reduces the computational complexity of\nthe common text mining operations according to sparsity, yielding probabilistic\nmodels with the scalability of modern search engines.\n  The proposed combination provides sparse generative models: a solution for\ntext mining that is general, effective, and scalable. Extensive experimentation\non text classification and ranked retrieval datasets are conducted, showing\nthat the proposed solution matches or outperforms the leading task-specific\nmethods in effectiveness, with a order of magnitude decrease in classification\ntimes for Wikipedia article categorization with a million classes. The\ndeveloped methods were further applied in two 2014 Kaggle data mining prize\ncompetitions with over a hundred competing teams, earning first and second\nplaces.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2016 02:49:27 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Puurula", "Antti", ""]]}, {"id": "1602.02334", "submitter": "Leopoldo Bertossi", "authors": "Zeinab Bahmani, Leopoldo Bertossi and Nikolaos Vasiloglou", "title": "ERBlox: Combining Matching Dependencies with Machine Learning for Entity\n  Resolution", "comments": "Final journal version, with some minor technical corrections.\n  Extended version of arXiv:1508.06013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity resolution (ER), an important and common data cleaning problem, is\nabout detecting data duplicate representations for the same external entities,\nand merging them into single representations. Relatively recently, declarative\nrules called \"matching dependencies\" (MDs) have been proposed for specifying\nsimilarity conditions under which attribute values in database records are\nmerged. In this work we show the process and the benefits of integrating four\ncomponents of ER: (a) Building a classifier for duplicate/non-duplicate record\npairs built using machine learning (ML) techniques; (b) Use of MDs for\nsupporting the blocking phase of ML; (c) Record merging on the basis of the\nclassifier results; and (d) The use of the declarative language \"LogiQL\" -an\nextended form of Datalog supported by the \"LogicBlox\" platform- for all\nactivities related to data processing, and the specification and enforcement of\nMDs.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2016 03:06:40 GMT"}, {"version": "v2", "created": "Sun, 27 Nov 2016 21:09:37 GMT"}, {"version": "v3", "created": "Wed, 18 Jan 2017 17:43:43 GMT"}], "update_date": "2017-01-19", "authors_parsed": [["Bahmani", "Zeinab", ""], ["Bertossi", "Leopoldo", ""], ["Vasiloglou", "Nikolaos", ""]]}, {"id": "1602.02377", "submitter": "Yong Tan", "authors": "Yong Tan", "title": "Find an Optimal Path in Static System and Dynamical System within\n  Polynomial Runtime", "comments": "27 pages, 9720 words,10 figures,5 trials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.DM cs.RO math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an ancient problem that in a static or dynamical system, sought an\noptimal path, which the context always means within an extremal condition. In\nfact, through those discussions about this theme, we established a universal\nessential calculated model to serve for these complex systems. Meanwhile we\nutilize the sample space to character the system. These contents in this paper\nwould involve in several major areas including the geometry, probability, graph\nalgorithms and some prior approaches, which stands the ultimately subtle linear\nalgorithm to solve this class problem. Along with our progress, our discussion\nwould demonstrate more general meaning and robust character, which provides\nclear ideas or notion to support our concrete applications, who work in a more\npopular complex system.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2016 14:50:45 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Tan", "Yong", ""]]}, {"id": "1602.02473", "submitter": "Hussein Al-Olimat", "authors": "Hussein S. Al-Olimat, Robert C. Green II, Mansoor Alam, Vijay\n  Devabhaktuni and Wei Cheng", "title": "Particle Swarm Optimized Power Consumption of Trilateration", "comments": "19 Pages, 13 Figures, 10 Tables, Journal", "journal-ref": "International Journal in Foundations of Computer Science &\n  Technology (IJFCST), Vol.4, No.4, July 2014", "doi": "10.5121/ijfcst.2014.4401", "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trilateration-based localization (TBL) has become a corner stone of modern\ntechnology. This study formulates the concern on how wireless sensor networks\ncan take advantage of the computational intelligent techniques using both\nsingle- and multi-objective particle swarm optimization (PSO) with an overall\naim of concurrently minimizing the required time for localization, minimizing\nenergy consumed during localization, and maximizing the number of nodes fully\nlocalized through the adjustment of wireless sensor transmission ranges while\nusing TBL process. A parameter-study of the applied PSO variants is performed,\nleading to results that show algorithmic improvements of up to 32% in the\nevaluated objectives.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 06:27:20 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Al-Olimat", "Hussein S.", ""], ["Green", "Robert C.", "II"], ["Alam", "Mansoor", ""], ["Devabhaktuni", "Vijay", ""], ["Cheng", "Wei", ""]]}, {"id": "1602.02617", "submitter": "Arnaud Martin", "authors": "Zhun-Ga Liu, Quan Pan, Jean Dezert (Palaiseau), Arnaud Martin (DRUID)", "title": "Adaptive imputation of missing values for incomplete pattern\n  classification", "comments": null, "journal-ref": "Pattern Recognition, Elsevier, 2016, 52", "doi": "10.1016/j.patcog.2015.10.001", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classification of incomplete pattern, the missing values can either play a\ncrucial role in the class determination, or have only little influence (or\neventually none) on the classification results according to the context. We\npropose a credal classification method for incomplete pattern with adaptive\nimputation of missing values based on belief function theory. At first, we try\nto classify the object (incomplete pattern) based only on the available\nattribute values. As underlying principle, we assume that the missing\ninformation is not crucial for the classification if a specific class for the\nobject can be found using only the available information. In this case, the\nobject is committed to this particular class. However, if the object cannot be\nclassified without ambiguity, it means that the missing values play a main role\nfor achieving an accurate classification. In this case, the missing values will\nbe imputed based on the K-nearest neighbor (K-NN) and self-organizing map (SOM)\ntechniques, and the edited pattern with the imputation is then classified. The\n(original or edited) pattern is respectively classified according to each\ntraining class, and the classification results represented by basic belief\nassignments are fused with proper combination rules for making the credal\nclassification. The object is allowed to belong with different masses of belief\nto the specific classes and meta-classes (which are particular disjunctions of\nseveral single classes). The credal classification captures well the\nuncertainty and imprecision of classification, and reduces effectively the rate\nof misclassifications thanks to the introduction of meta-classes. The\neffectiveness of the proposed method with respect to other classical methods is\ndemonstrated based on several experiments using artificial and real data sets.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 15:52:08 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Liu", "Zhun-Ga", "", "Palaiseau"], ["Pan", "Quan", "", "Palaiseau"], ["Dezert", "Jean", "", "Palaiseau"], ["Martin", "Arnaud", "", "DRUID"]]}, {"id": "1602.02658", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Nir Ben Zrihem, Shie Mannor", "title": "Graying the black box: Understanding DQNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there is a growing interest in using deep representations for\nreinforcement learning. In this paper, we present a methodology and tools to\nanalyze Deep Q-networks (DQNs) in a non-blind matter. Moreover, we propose a\nnew model, the Semi Aggregated Markov Decision Process (SAMDP), and an\nalgorithm that learns it automatically. The SAMDP model allows us to identify\nspatio-temporal abstractions directly from features and may be used as a\nsub-goal detector in future work. Using our tools we reveal that the features\nlearned by DQNs aggregate the state space in a hierarchical fashion, explaining\nits success. Moreover, we are able to understand and describe the policies\nlearned by DQNs for three different Atari2600 games and suggest ways to\ninterpret, debug and optimize deep neural networks in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 17:27:31 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2016 16:13:00 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2016 19:15:55 GMT"}, {"version": "v4", "created": "Mon, 24 Apr 2017 09:57:21 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Zahavy", "Tom", ""], ["Zrihem", "Nir Ben", ""], ["Mannor", "Shie", ""]]}, {"id": "1602.02672", "submitter": "Jakob Foerster", "authors": "Jakob N. Foerster, Yannis M. Assael, Nando de Freitas, Shimon Whiteson", "title": "Learning to Communicate to Solve Riddles with Deep Distributed Recurrent\n  Q-Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose deep distributed recurrent Q-networks (DDRQN), which enable teams\nof agents to learn to solve communication-based coordination tasks. In these\ntasks, the agents are not given any pre-designed communication protocol.\nTherefore, in order to successfully communicate, they must first automatically\ndevelop and agree upon their own communication protocol. We present empirical\nresults on two multi-agent learning problems based on well-known riddles,\ndemonstrating that DDRQN can successfully solve such tasks and discover elegant\ncommunication protocols to do so. To our knowledge, this is the first time deep\nreinforcement learning has succeeded in learning communication protocols. In\naddition, we present ablation experiments that confirm that each of the main\ncomponents of the DDRQN architecture are critical to its success.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 18:01:35 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Foerster", "Jakob N.", ""], ["Assael", "Yannis M.", ""], ["de Freitas", "Nando", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1602.02685", "submitter": "Cristobal Esteban", "authors": "Crist\\'obal Esteban, Oliver Staeck, Yinchong Yang and Volker Tresp", "title": "Predicting Clinical Events by Combining Static and Dynamic Information\n  Using Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In clinical data sets we often find static information (e.g. patient gender,\nblood type, etc.) combined with sequences of data that are recorded during\nmultiple hospital visits (e.g. medications prescribed, tests performed, etc.).\nRecurrent Neural Networks (RNNs) have proven to be very successful for\nmodelling sequences of data in many areas of Machine Learning. In this work we\npresent an approach based on RNNs, specifically designed for the clinical\ndomain, that combines static and dynamic information in order to predict future\nevents. We work with a database collected in the Charit\\'{e} Hospital in Berlin\nthat contains complete information concerning patients that underwent a kidney\ntransplantation. After the transplantation three main endpoints can occur:\nrejection of the kidney, loss of the kidney and death of the patient. Our goal\nis to predict, based on information recorded in the Electronic Health Record of\neach patient, whether any of those endpoints will occur within the next six or\ntwelve months after each visit to the clinic. We compared different types of\nRNNs that we developed for this work, with a model based on a Feedforward\nNeural Network and a Logistic Regression model. We found that the RNN that we\ndeveloped based on Gated Recurrent Units provides the best performance for this\ntask. We also used the same models for a second task, i.e., next event\nprediction, and found that here the model based on a Feedforward Neural Network\noutperformed the other models. Our hypothesis is that long-term dependencies\nare not as relevant in this task.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 18:30:58 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 11:52:19 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Esteban", "Crist\u00f3bal", ""], ["Staeck", "Oliver", ""], ["Yang", "Yinchong", ""], ["Tresp", "Volker", ""]]}, {"id": "1602.02706", "submitter": "Julien Audiffren", "authors": "Julien Audiffren (CMLA), Ralaivola Liva (LIF)", "title": "Decoy Bandits Dueling on a Poset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We adress the problem of dueling bandits defined on partially ordered sets,\nor posets. In this setting, arms may not be comparable, and there may be\nseveral (incomparable) optimal arms. We propose an algorithm, UnchainedBandits,\nthat efficiently finds the set of optimal arms of any poset even when pairs of\ncomparable arms cannot be distinguished from pairs of incomparable arms, with a\nset of minimal assumptions. This algorithm relies on the concept of decoys,\nwhich stems from social psychology. For the easier case where the\nincomparability information may be accessible, we propose a second algorithm,\nSlicingBandits, which takes advantage of this information and achieves a very\nsignificant gain of performance compared to UnchainedBandits. We provide\ntheoretical guarantees and experimental evaluation for both algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 19:32:18 GMT"}, {"version": "v2", "created": "Thu, 9 Jun 2016 06:57:28 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Audiffren", "Julien", "", "CMLA"], ["Liva", "Ralaivola", "", "LIF"]]}, {"id": "1602.02710", "submitter": "Umberto Grandi", "authors": "Umberto Grandi and Emiliano Lorini and Laurent Perrussel", "title": "Strategic disclosure of opinions on a social network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the strategic aspects of social influence in a society of agents\nlinked by a trust network, introducing a new class of games called games of\ninfluence. A game of influence is an infinite repeated game with incomplete\ninformation in which, at each stage of interaction, an agent can make her\nopinions visible (public) or invisible (private) in order to influence other\nagents' opinions. The influence process is mediated by a trust network, as we\nassume that the opinion of a given agent is only affected by the opinions of\nthose agents that she considers trustworthy (i.e., the agents in the trust\nnetwork that are directly linked to her). Each agent is endowed with a goal,\nexpressed in a suitable temporal language inspired from linear temporal logic\n(LTL). We show that games of influence provide a simple abstraction to explore\nthe effects of the trust network structure on the agents' behaviour, by\nconsidering solution concepts from game-theory such as Nash equilibrium, weak\ndominance and winning strategies.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 14:10:44 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Grandi", "Umberto", ""], ["Lorini", "Emiliano", ""], ["Perrussel", "Laurent", ""]]}, {"id": "1602.02743", "submitter": "Michael Brand", "authors": "Michael Brand and David L. Dowe", "title": "The IMP game: Learnability, approximability and adversarial learning\n  beyond $\\Sigma^0_1$", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a problem set-up we call the Iterated Matching Pennies (IMP)\ngame and show that it is a powerful framework for the study of three problems:\nadversarial learnability, conventional (i.e., non-adversarial) learnability and\napproximability. Using it, we are able to derive the following theorems. (1) It\nis possible to learn by example all of $\\Sigma^0_1 \\cup \\Pi^0_1$ as well as\nsome supersets; (2) in adversarial learning (which we describe as a\npursuit-evasion game), the pursuer has a winning strategy (in other words,\n$\\Sigma^0_1$ can be learned adversarially, but $\\Pi^0_1$ not); (3) some\nlanguages in $\\Pi^0_1$ cannot be approximated by any language in $\\Sigma^0_1$.\n  We show corresponding results also for $\\Sigma^0_i$ and $\\Pi^0_i$ for\narbitrary $i$.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2016 04:17:17 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Brand", "Michael", ""], ["Dowe", "David L.", ""]]}, {"id": "1602.02867", "submitter": "Aviv Tamar", "authors": "Aviv Tamar, Yi Wu, Garrett Thomas, Sergey Levine, Pieter Abbeel", "title": "Value Iteration Networks", "comments": "Fixed missing table values", "journal-ref": "Advances in Neural Information Processing Systems 29 pages\n  2154--2162, 2016", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the value iteration network (VIN): a fully differentiable neural\nnetwork with a `planning module' embedded within. VINs can learn to plan, and\nare suitable for predicting outcomes that involve planning-based reasoning,\nsuch as policies for reinforcement learning. Key to our approach is a novel\ndifferentiable approximation of the value-iteration algorithm, which can be\nrepresented as a convolutional neural network, and trained end-to-end using\nstandard backpropagation. We evaluate VIN based policies on discrete and\ncontinuous path-planning domains, and on a natural-language based search task.\nWe show that by learning an explicit planning computation, VIN policies\ngeneralize better to new, unseen domains.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 05:44:36 GMT"}, {"version": "v2", "created": "Sun, 29 May 2016 18:33:04 GMT"}, {"version": "v3", "created": "Sun, 5 Feb 2017 20:06:14 GMT"}, {"version": "v4", "created": "Mon, 20 Mar 2017 21:41:51 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Tamar", "Aviv", ""], ["Wu", "Yi", ""], ["Thomas", "Garrett", ""], ["Levine", "Sergey", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1602.03203", "submitter": "Szymon Sidor", "authors": "Szymon Sidor, Peng Yu, Cheng Fang, Brian Williams", "title": "Time Resource Networks", "comments": "7 pages, submitted for review to IJCAI16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The problem of scheduling under resource constraints is widely applicable.\nOne prominent example is power management, in which we have a limited\ncontinuous supply of power but must schedule a number of power-consuming tasks.\nSuch problems feature tightly coupled continuous resource constraints and\ncontinuous temporal constraints.\n  We address such problems by introducing the Time Resource Network (TRN), an\nencoding for resource-constrained scheduling problems. The definition allows\ntemporal specifications using a general family of representations derived from\nthe Simple Temporal network, including the Simple Temporal Network with\nUncertainty, and the probabilistic Simple Temporal Network (Fang et al.\n(2014)).\n  We propose two algorithms for determining the consistency of a TRN: one based\non Mixed Integer Programing and the other one based on Constraint Programming,\nwhich we evaluate on scheduling problems with Simple Temporal Constraints and\nProbabilistic Temporal Constraints.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 21:49:16 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["Sidor", "Szymon", ""], ["Yu", "Peng", ""], ["Fang", "Cheng", ""], ["Williams", "Brian", ""]]}, {"id": "1602.03291", "submitter": "Habibur Rahman", "authors": "Habibur Rahman and Lucas Joppa and Senjuti Basu Roy", "title": "Feature Based Task Recommendation in Crowdsourcing with Implicit\n  Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing research in crowdsourcing has investigated how to recommend tasks to\nworkers based on which task the workers have already completed, referred to as\n{\\em implicit feedback}. We, on the other hand, investigate the task\nrecommendation problem, where we leverage both implicit feedback and explicit\nfeatures of the task. We assume that we are given a set of workers, a set of\ntasks, interactions (such as the number of times a worker has completed a\nparticular task), and the presence of explicit features of each task (such as,\ntask location). We intend to recommend tasks to the workers by exploiting the\nimplicit interactions, and the presence or absence of explicit features in the\ntasks. We formalize the problem as an optimization problem, propose two\nalternative problem formulations and respective solutions that exploit implicit\nfeedback, explicit features, as well as similarity between the tasks. We\ncompare the efficacy of our proposed solutions against multiple\nstate-of-the-art techniques using two large scale real world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 08:06:32 GMT"}, {"version": "v2", "created": "Wed, 7 Sep 2016 05:13:51 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Rahman", "Habibur", ""], ["Joppa", "Lucas", ""], ["Roy", "Senjuti Basu", ""]]}, {"id": "1602.03348", "submitter": "Daniel J Mankowitz", "authors": "Daniel J. Mankowitz, Timothy A. Mann, Shie Mannor", "title": "Iterative Hierarchical Optimization for Misspecified Problems (IHOMP)", "comments": "arXiv admin note: text overlap with arXiv:1506.03624", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For complex, high-dimensional Markov Decision Processes (MDPs), it may be\nnecessary to represent the policy with function approximation. A problem is\nmisspecified whenever, the representation cannot express any policy with\nacceptable performance. We introduce IHOMP : an approach for solving\nmisspecified problems. IHOMP iteratively learns a set of context specialized\noptions and combines these options to solve an otherwise misspecified problem.\nOur main contribution is proving that IHOMP enjoys theoretical convergence\nguarantees. In addition, we extend IHOMP to exploit Option Interruption (OI)\nenabling it to decide where the learned options can be reused. Our experiments\ndemonstrate that IHOMP can find near-optimal solutions to otherwise\nmisspecified problems and that OI can further improve the solutions.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 12:27:04 GMT"}, {"version": "v2", "created": "Tue, 7 Jun 2016 20:05:14 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Mankowitz", "Daniel J.", ""], ["Mann", "Timothy A.", ""], ["Mannor", "Shie", ""]]}, {"id": "1602.03351", "submitter": "Daniel J Mankowitz", "authors": "Daniel J. Mankowitz, Timothy A. Mann, Shie Mannor", "title": "Adaptive Skills, Adaptive Partitions (ASAP)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Adaptive Skills, Adaptive Partitions (ASAP) framework that\n(1) learns skills (i.e., temporally extended actions or options) as well as (2)\nwhere to apply them. We believe that both (1) and (2) are necessary for a truly\ngeneral skill learning framework, which is a key building block needed to scale\nup to lifelong learning agents. The ASAP framework can also solve related new\ntasks simply by adapting where it applies its existing learned skills. We prove\nthat ASAP converges to a local optimum under natural conditions. Finally, our\nexperimental results, which include a RoboCup domain, demonstrate the ability\nof ASAP to learn where to reuse skills as well as solve multiple tasks with\nconsiderably less experience than solving each task from scratch.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 12:35:37 GMT"}, {"version": "v2", "created": "Tue, 7 Jun 2016 19:50:33 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Mankowitz", "Daniel J.", ""], ["Mann", "Timothy A.", ""], ["Mannor", "Shie", ""]]}, {"id": "1602.03506", "submitter": "Max Tegmark", "authors": "Stuart Russell (Berkeley), Daniel Dewey (FHI), Max Tegmark (MIT)", "title": "Research Priorities for Robust and Beneficial Artificial Intelligence", "comments": "This article gives examples of the type of research advocated by the\n  open letter for robust & beneficial AI at\n  http://futureoflife.org/ai-open-letter", "journal-ref": "AI Magazine 36:4 (2015)", "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Success in the quest for artificial intelligence has the potential to bring\nunprecedented benefits to humanity, and it is therefore worthwhile to\ninvestigate how to maximize these benefits while avoiding potential pitfalls.\nThis article gives numerous examples (which should by no means be construed as\nan exhaustive list) of such worthwhile research aimed at ensuring that AI\nremains robust and beneficial.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 20:29:25 GMT"}], "update_date": "2016-02-15", "authors_parsed": [["Russell", "Stuart", "", "Berkeley"], ["Dewey", "Daniel", "", "FHI"], ["Tegmark", "Max", "", "MIT"]]}, {"id": "1602.03779", "submitter": "Raphael F\\'eraud", "authors": "Rapha\\\"el F\\'eraud", "title": "Network of Bandits insure Privacy of end-users", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to distribute the best arm identification task as close as possible\nto the user's devices, on the edge of the Radio Access Network, we propose a\nnew problem setting, where distributed players collaborate to find the best\narm. This architecture guarantees privacy to end-users since no events are\nstored. The only thing that can be observed by an adversary through the core\nnetwork is aggregated information across users. We provide a first algorithm,\nDistributed Median Elimination, which is optimal in term of number of\ntransmitted bits and near optimal in term of speed-up factor with respect to an\noptimal algorithm run independently on each player. In practice, this first\nalgorithm cannot handle the trade-off between the communication cost and the\nspeed-up factor, and requires some knowledge about the distribution of players.\nExtended Distributed Median Elimination overcomes these limitations, by playing\nin parallel different instances of Distributed Median Elimination and selecting\nthe best one. Experiments illustrate and complete the analysis. According to\nthe analysis, in comparison to Median Elimination performed on each player, the\nproposed algorithm shows significant practical improvements.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 15:55:59 GMT"}, {"version": "v10", "created": "Mon, 5 Dec 2016 15:10:40 GMT"}, {"version": "v11", "created": "Sat, 17 Dec 2016 17:24:05 GMT"}, {"version": "v12", "created": "Mon, 6 Feb 2017 13:09:27 GMT"}, {"version": "v13", "created": "Mon, 20 Mar 2017 14:04:42 GMT"}, {"version": "v14", "created": "Wed, 29 Mar 2017 09:42:40 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2016 16:28:45 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2016 12:26:15 GMT"}, {"version": "v4", "created": "Tue, 1 Mar 2016 17:03:16 GMT"}, {"version": "v5", "created": "Wed, 30 Mar 2016 15:32:59 GMT"}, {"version": "v6", "created": "Tue, 26 Apr 2016 07:37:45 GMT"}, {"version": "v7", "created": "Mon, 6 Jun 2016 12:56:21 GMT"}, {"version": "v8", "created": "Mon, 19 Sep 2016 14:10:21 GMT"}, {"version": "v9", "created": "Tue, 11 Oct 2016 07:28:28 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["F\u00e9raud", "Rapha\u00ebl", ""]]}, {"id": "1602.03814", "submitter": "Vasanth Sarathy", "authors": "Vasanth Sarathy, Jason R. Wilson, Thomas Arnold and Matthias Scheutz", "title": "Enabling Basic Normative HRI in a Cognitive Robotic Architecture", "comments": "Presented at \"2nd Workshop on Cognitive Architectures for Social\n  Human-Robot Interaction 2016 (arXiv:1602.01868)\"", "journal-ref": null, "doi": null, "report-no": "CogArch4sHRI/2016/04", "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative human activities are grounded in social and moral norms, which\nhumans consciously and subconsciously use to guide and constrain their\ndecision-making and behavior, thereby strengthening their interactions and\npreventing emotional and physical harm. This type of norm-based processing is\nalso critical for robots in many human-robot interaction scenarios (e.g., when\nhelping elderly and disabled persons in assisted living facilities, or\nassisting humans in assembly tasks in factories or even the space station). In\nthis position paper, we will briefly describe how several components in an\nintegrated cognitive architecture can be used to implement processes that are\nrequired for normative human-robot interactions, especially in collaborative\ntasks where actions and situations could potentially be perceived as\nthreatening and thus need a change in course of action to mitigate the\nperceived threats.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 18:18:14 GMT"}], "update_date": "2016-02-12", "authors_parsed": [["Sarathy", "Vasanth", ""], ["Wilson", "Jason R.", ""], ["Arnold", "Thomas", ""], ["Scheutz", "Matthias", ""]]}, {"id": "1602.03924", "submitter": "Peter Krafft", "authors": "Peter M. Krafft and Chris L. Baker and Alex Pentland and Joshua B.\n  Tenenbaum", "title": "Modeling Human Ad Hoc Coordination", "comments": "AAAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whether in groups of humans or groups of computer agents, collaboration is\nmost effective between individuals who have the ability to coordinate on a\njoint strategy for collective action. However, in general a rational actor will\nonly intend to coordinate if that actor believes the other group members have\nthe same intention. This circular dependence makes rational coordination\ndifficult in uncertain environments if communication between actors is\nunreliable and no prior agreements have been made. An important normative\nquestion with regard to coordination in these ad hoc settings is therefore how\none can come to believe that other actors will coordinate, and with regard to\nsystems involving humans, an important empirical question is how humans arrive\nat these expectations. We introduce an exact algorithm for computing the\ninfinitely recursive hierarchy of graded beliefs required for rational\ncoordination in uncertain environments, and we introduce a novel mechanism for\nmultiagent coordination that uses it. Our algorithm is valid in any environment\nwith a finite state space, and extensions to certain countably infinite state\nspaces are likely possible. We test our mechanism for multiagent coordination\nas a model for human decisions in a simple coordination game using existing\nexperimental data. We then explore via simulations whether modeling humans in\nthis way may improve human-agent collaboration.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 22:48:59 GMT"}], "update_date": "2016-02-15", "authors_parsed": [["Krafft", "Peter M.", ""], ["Baker", "Chris L.", ""], ["Pentland", "Alex", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1602.03963", "submitter": "Easton Li Xu", "authors": "Easton Li Xu, Xiaoning Qian, Tie Liu, Shuguang Cui", "title": "Detection of Cooperative Interactions in Logistic Regression Models", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important problem in the field of bioinformatics is to identify\ninteractive effects among profiled variables for outcome prediction. In this\npaper, a logistic regression model with pairwise interactions among a set of\nbinary covariates is considered. Modeling the structure of the interactions by\na graph, our goal is to recover the interaction graph from independently\nidentically distributed (i.i.d.) samples of the covariates and the outcome.\n  When viewed as a feature selection problem, a simple quantity called\ninfluence is proposed as a measure of the marginal effects of the interaction\nterms on the outcome. For the case when the underlying interaction graph is\nknown to be acyclic, it is shown that a simple algorithm that is based on a\nmaximum-weight spanning tree with respect to the plug-in estimates of the\ninfluences not only has strong theoretical performance guarantees, but can also\noutperform generic feature selection algorithms for recovering the interaction\ngraph from i.i.d. samples of the covariates and the outcome. Our results can\nalso be extended to the model that includes both individual effects and\npairwise interactions via the help of an auxiliary covariate.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 05:04:21 GMT"}, {"version": "v2", "created": "Wed, 28 Dec 2016 02:11:04 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Xu", "Easton Li", ""], ["Qian", "Xiaoning", ""], ["Liu", "Tie", ""], ["Cui", "Shuguang", ""]]}, {"id": "1602.04019", "submitter": "Anders Sandberg", "authors": "Anders Sandberg", "title": "Energetics of the brain and AI", "comments": null, "journal-ref": null, "doi": null, "report-no": "STR 2016-2", "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Does the energy requirements for the human brain give energy constraints that\ngive reason to doubt the feasibility of artificial intelligence? This report\nwill review some relevant estimates of brain bioenergetics and analyze some of\nthe methods of estimating brain emulation energy requirements. Turning to AI,\nthere are reasons to believe the energy requirements for de novo AI to have\nlittle correlation with brain (emulation) energy requirements since cost could\ndepend merely of the cost of processing higher-level representations rather\nthan billions of neural firings. Unless one thinks the human way of thinking is\nthe most optimal or most easily implementable way of achieving software\nintelligence, we should expect de novo AI to make use of different, potentially\nvery compressed and fast, processes.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 11:32:59 GMT"}], "update_date": "2016-02-15", "authors_parsed": [["Sandberg", "Anders", ""]]}, {"id": "1602.04032", "submitter": "Satyanath Bhat", "authors": "Satyanath Bhat and Divya Padmanabhan and Shweta Jain and Y Narahari", "title": "A Truthful Mechanism with Biparameter Learning for Online Crowdsourcing", "comments": "To appear as Extended Abstract in AAMAS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a problem of allocating divisible jobs, arriving online, to workers\nin a crowdsourcing setting which involves learning two parameters of\nstrategically behaving workers. Each job is split into a certain number of\ntasks that are then allocated to workers. Each arriving job has to be completed\nwithin a deadline and each task has to be completed satisfying an upper bound\non probability of failure. The job population is homogeneous while the workers\nare heterogeneous in terms of costs, completion times, and times to failure.\nThe job completion time and time to failure of each worker are stochastic with\nfixed but unknown means. The requester is faced with the challenge of learning\ntwo separate parameters of each (strategically behaving) worker simultaneously,\nnamely, the mean job completion time and the mean time to failure. The time to\nfailure of a worker depends on the duration of the task handled by the worker.\nAssuming non-strategic workers to start with, we solve this biparameter\nlearning problem by applying the Robust UCB algorithm. Then, we non-trivially\nextend this algorithm to the setting where the workers are strategic about\ntheir costs. Our proposed mechanism is dominant strategy incentive compatible\nand ex-post individually rational with asymptotically optimal regret\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 12:36:13 GMT"}], "update_date": "2016-02-15", "authors_parsed": [["Bhat", "Satyanath", ""], ["Padmanabhan", "Divya", ""], ["Jain", "Shweta", ""], ["Narahari", "Y", ""]]}, {"id": "1602.04257", "submitter": "Bhuvan M S", "authors": "Malladihalli S Bhuvan, Ankit Kumar, Adil Zafar, Vinith Kishore", "title": "Identifying Diabetic Patients with High Risk of Readmission", "comments": "10 pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hospital readmissions are expensive and reflect the inadequacies in\nhealthcare system. In the United States alone, treatment of readmitted diabetic\npatients exceeds 250 million dollars per year. Early identification of patients\nfacing a high risk of readmission can enable healthcare providers to to conduct\nadditional investigations and possibly prevent future readmissions. This not\nonly improves the quality of care but also reduces the medical expenses on\nreadmission. Machine learning methods have been leveraged on public health data\nto build a system for identifying diabetic patients facing a high risk of\nfuture readmission. Number of inpatient visits, discharge disposition and\nadmission type were identified as strong predictors of readmission. Further, it\nwas found that the number of laboratory tests and discharge disposition\ntogether predict whether the patient will be readmitted shortly after being\ndischarged from the hospital (i.e. <30 days) or after a longer period of time\n(i.e. >30 days). These insights can help healthcare providers to improve\ninpatient diabetic care. Finally, the cost analysis suggests that \\$252.76\nmillion can be saved across 98,053 diabetic patient encounters by incorporating\nthe proposed cost sensitive analysis model.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 22:51:11 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Bhuvan", "Malladihalli S", ""], ["Kumar", "Ankit", ""], ["Zafar", "Adil", ""], ["Kishore", "Vinith", ""]]}, {"id": "1602.04259", "submitter": "Viktoriya Krakovna", "authors": "Viktoriya Krakovna, Moshe Looks", "title": "A Minimalistic Approach to Sum-Product Network Learning for Real\n  Applications", "comments": "Accepted to ICLR 2016 workshop track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sum-Product Networks (SPNs) are a class of expressive yet tractable\nhierarchical graphical models. LearnSPN is a structure learning algorithm for\nSPNs that uses hierarchical co-clustering to simultaneously identifying similar\nentities and similar features. The original LearnSPN algorithm assumes that all\nthe variables are discrete and there is no missing data. We introduce a\npractical, simplified version of LearnSPN, MiniSPN, that runs faster and can\nhandle missing data and heterogeneous features common in real applications. We\ndemonstrate the performance of MiniSPN on standard benchmark datasets and on\ntwo datasets from Google's Knowledge Graph exhibiting high missingness rates\nand a mix of discrete and continuous features.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 23:11:05 GMT"}, {"version": "v2", "created": "Thu, 24 Mar 2016 22:37:52 GMT"}, {"version": "v3", "created": "Sun, 24 Apr 2016 23:38:43 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Krakovna", "Viktoriya", ""], ["Looks", "Moshe", ""]]}, {"id": "1602.04290", "submitter": "Kevin H. Knuth", "authors": "Kevin H. Knuth, Philip M. Erner, Scott Frasso", "title": "Designing Intelligent Instruments", "comments": "9 pages, 2 figures. Published in the MaxEnt 2007 Proceedings", "journal-ref": "AIP Conference Proceedings 954, American Institute of Physics,\n  Melville NY, 203-211, 2007", "doi": "10.1063/1.2821263", "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote science operations require automated systems that can both act and\nreact with minimal human intervention. One such vision is that of an\nintelligent instrument that collects data in an automated fashion, and based on\nwhat it learns, decides which new measurements to take. This innovation\nimplements experimental design and unites it with data analysis in such a way\nthat it completes the cycle of learning. This cycle is the basis of the\nScientific Method.\n  The three basic steps of this cycle are hypothesis generation, inquiry, and\ninference. Hypothesis generation is implemented by artificially supplying the\ninstrument with a parameterized set of possible hypotheses that might be used\nto describe the physical system. The act of inquiry is handled by an inquiry\nengine that relies on Bayesian adaptive exploration where the optimal\nexperiment is chosen as the one which maximizes the expected information gain.\nThe inference engine is implemented using the nested sampling algorithm, which\nprovides the inquiry engine with a set of posterior samples from which the\nexpected information gain can be estimated. With these computational structures\nin place, the instrument will refine its hypotheses, and repeat the learning\ncycle by taking measurements until the system under study is described within a\npre-specified tolerance. We will demonstrate our first attempts toward\nachieving this goal with an intelligent instrument constructed using the LEGO\nMINDSTORMS NXT robotics platform.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2016 06:28:22 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Knuth", "Kevin H.", ""], ["Erner", "Philip M.", ""], ["Frasso", "Scott", ""]]}, {"id": "1602.04358", "submitter": "Leonid Gugel", "authors": "Leonid Gugel, Yoel Shkolnisky, Shai Dekel", "title": "Machine olfaction using time scattering of sensor multiresolution graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we construct a learning architecture for high dimensional time\nseries sampled by sensor arrangements. Using a redundant wavelet decomposition\non a graph constructed over the sensor locations, our algorithm is able to\nconstruct discriminative features that exploit the mutual information between\nthe sensors. The algorithm then applies scattering networks to the time series\ngraphs to create the feature space. We demonstrate our method on a machine\nolfaction problem, where one needs to classify the gas type and the location\nwhere it originates from data sampled by an array of sensors. Our experimental\nresults clearly demonstrate that our method outperforms classical machine\nlearning techniques used in previous studies.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2016 17:25:03 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Gugel", "Leonid", ""], ["Shkolnisky", "Yoel", ""], ["Dekel", "Shai", ""]]}, {"id": "1602.04375", "submitter": "Mrinmaya Sachan", "authors": "Mrinmaya Sachan, Avinava Dubey, Eric P. Xing", "title": "Science Question Answering using Instructional Materials", "comments": "Corrected that the science QA dataset is NOT freely available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a solution for elementary science test using instructional\nmaterials. We posit that there is a hidden structure that explains the\ncorrectness of an answer given the question and instructional materials and\npresent a unified max-margin framework that learns to find these hidden\nstructures (given a corpus of question-answer pairs and instructional\nmaterials), and uses what it learns to answer novel elementary science\nquestions. Our evaluation shows that our framework outperforms several strong\nbaselines.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2016 20:13:48 GMT"}, {"version": "v2", "created": "Tue, 5 Apr 2016 01:17:56 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Sachan", "Mrinmaya", ""], ["Dubey", "Avinava", ""], ["Xing", "Eric P.", ""]]}, {"id": "1602.04376", "submitter": "Fahad Muhammad", "authors": "Muhammad Fahad", "title": "BPCMont: Business Process Change Management Ontology", "comments": "5 pages, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Change management for evolving collaborative business process development is\ncrucial when the business logic, transections and workflow change due to\nchanges in business strategies or organizational and technical environment.\nDuring the change implementation, business processes are analyzed and improved\nensuring that they capture the proposed change and they do not contain any\nundesired functionalities or change side-effects. This paper presents Business\nProcess Change Management approach for the efficient and effective\nimplementation of change in the business process. The key technology behind our\napproach is our proposed Business Process Change Management Ontology (BPCMont)\nwhich is the main contribution of this paper. BPCMont, as a formalized change\nspecification, helps to revert BP into a consistent state in case of system\ncrash, intermediate conflicting stage or unauthorized change done, aid in\nchange traceability in the new and old versions of business processes, change\neffects can be seen and estimated effectively, ease for Stakeholders to\nvalidate and verify change implementation, etc.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2016 20:27:44 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Fahad", "Muhammad", ""]]}, {"id": "1602.04435", "submitter": "Denis Sidorov", "authors": "A. Zhukov, D. Sidorov and A. Foley", "title": "Random Forest Based Approach for Concept Drift Handling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept drift has potential in smart grid analysis because the socio-economic\nbehaviour of consumers is not governed by the laws of physics. Likewise there\nare also applications in wind power forecasting. In this paper we present\ndecision tree ensemble classification method based on the Random Forest\nalgorithm for concept drift. The weighted majority voting ensemble aggregation\nrule is employed based on the ideas of Accuracy Weighted Ensemble (AWE) method.\nBase learner weight in our case is computed for each sample evaluation using\nbase learners accuracy and intrinsic proximity measure of Random Forest. Our\nalgorithm exploits both temporal weighting of samples and ensemble pruning as a\nforgetting strategy. We present results of empirical comparison of our method\nwith original random forest with incorporated \"replace-the-looser\" forgetting\nandother state-of-the-art concept-drfit classifiers like AWE2.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2016 09:58:39 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Zhukov", "A.", ""], ["Sidorov", "D.", ""], ["Foley", "A.", ""]]}, {"id": "1602.04473", "submitter": "Michael Ruster", "authors": "Michael Ruster", "title": "Large-Scale Reasoning with OWL", "comments": "Part of the \"Knowledge Representation in the Semantic Web\" Seminar by\n  Matthias Thimm, Koblenz 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  With the growth of the Semantic Web in size and importance, more and more\nknowledge is stored in machine-readable formats such as the Web Ontology\nLanguage OWL. This paper outlines common approaches for efficient reasoning on\nlarge-scale data consisting of billions ($10^9$) of triples. Therefore, OWL and\nits sublanguages, as well as forward and backward chaining techniques are\npresented. The WebPIE reasoner is discussed in detail as an example for forward\nchaining using MapReduce for materialisation. Moreover, the QueryPIE reasoner\nis presented as a backward chaining/hybrid approach which uses query rewriting.\nFurthermore, an overview on other reasoners is given such as OWLIM and TrOWL.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2016 16:18:32 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Ruster", "Michael", ""]]}, {"id": "1602.04484", "submitter": "Phil Long", "authors": "David P. Helmbold and Philip M. Long", "title": "Surprising properties of dropout in deep networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze dropout in deep networks with rectified linear units and the\nquadratic loss. Our results expose surprising differences between the behavior\nof dropout and more traditional regularizers like weight decay. For example, on\nsome simple data sets dropout training produces negative weights even though\nthe output is the sum of the inputs. This provides a counterpoint to the\nsuggestion that dropout discourages co-adaptation of weights. We also show that\nthe dropout penalty can grow exponentially in the depth of the network while\nthe weight-decay penalty remains essentially linear, and that dropout is\ninsensitive to various re-scalings of the input features, outputs, and network\nweights. This last insensitivity implies that there are no isolated local\nminima of the dropout training criterion. Our work uncovers new properties of\ndropout, extends our understanding of why dropout succeeds, and lays the\nfoundation for further progress.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2016 18:20:29 GMT"}, {"version": "v2", "created": "Sat, 5 Mar 2016 23:00:10 GMT"}, {"version": "v3", "created": "Fri, 27 May 2016 23:24:17 GMT"}, {"version": "v4", "created": "Thu, 3 Nov 2016 16:39:19 GMT"}, {"version": "v5", "created": "Wed, 19 Apr 2017 21:15:15 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Helmbold", "David P.", ""], ["Long", "Philip M.", ""]]}, {"id": "1602.04498", "submitter": "Andrew Bate", "authors": "Andrew Bate, Boris Motik, Bernardo Cuenca Grau, Franti\\v{s}ek\n  Siman\\v{c}\\'ik, Ian Horrocks", "title": "Extending Consequence-Based Reasoning to SRIQ", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Consequence-based calculi are a family of reasoning algorithms for\ndescription logics (DLs), and they combine hypertableau and resolution in a way\nthat often achieves excellent performance in practice. Up to now, however, they\nwere proposed for either Horn DLs (which do not support disjunction), or for\nDLs without counting quantifiers. In this paper we present a novel\nconsequence-based calculus for SRIQ---a rich DL that supports both features.\nThis extension is non-trivial since the intermediate consequences that need to\nbe derived during reasoning cannot be captured using DLs themselves. The\nresults of our preliminary performance evaluation suggest the feasibility of\nour approach in practice.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2016 19:56:18 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2016 16:04:55 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2016 21:17:27 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Bate", "Andrew", ""], ["Motik", "Boris", ""], ["Grau", "Bernardo Cuenca", ""], ["Siman\u010d\u00edk", "Franti\u0161ek", ""], ["Horrocks", "Ian", ""]]}, {"id": "1602.04613", "submitter": "Semeh Ben Salem", "authors": "Sami Naouali, Semeh Ben Salem", "title": "Towards reducing the multidimensionality of OLAP cubes using the\n  Evolutionary Algorithms and Factor Analysis Methods", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data Warehouses are structures with large amount of data collected from\nheterogeneous sources to be used in a decision support system. Data Warehouses\nanalysis identifies hidden patterns initially unexpected which analysis\nrequires great memory and computation cost. Data reduction methods were\nproposed to make this analysis easier. In this paper, we present a hybrid\napproach based on Genetic Algorithms (GA) as Evolutionary Algorithms and the\nMultiple Correspondence Analysis (MCA) as Analysis Factor Methods to conduct\nthis reduction. Our approach identifies reduced subset of dimensions from the\ninitial subset p where p'<p where it is proposed to find the profile fact that\nis the closest to reference. GAs identify the possible subsets and the Khi\nformula of the ACM evaluates the quality of each subset. The study is based on\na distance measurement between the reference and n facts profile extracted from\nthe Warehouses.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 10:23:12 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Naouali", "Sami", ""], ["Salem", "Semeh Ben", ""]]}, {"id": "1602.04621", "submitter": "Ian Osband", "authors": "Ian Osband, Charles Blundell, Alexander Pritzel, Benjamin Van Roy", "title": "Deep Exploration via Bootstrapped DQN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration in complex environments remains a major challenge for\nreinforcement learning. We propose bootstrapped DQN, a simple algorithm that\nexplores in a computationally and statistically efficient manner through use of\nrandomized value functions. Unlike dithering strategies such as epsilon-greedy\nexploration, bootstrapped DQN carries out temporally-extended (or deep)\nexploration; this can lead to exponentially faster learning. We demonstrate\nthese benefits in complex stochastic MDPs and in the large-scale Arcade\nLearning Environment. Bootstrapped DQN substantially improves learning times\nand performance across most Atari games.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 10:54:20 GMT"}, {"version": "v2", "created": "Fri, 1 Jul 2016 16:23:55 GMT"}, {"version": "v3", "created": "Mon, 4 Jul 2016 17:11:52 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Osband", "Ian", ""], ["Blundell", "Charles", ""], ["Pritzel", "Alexander", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "1602.04709", "submitter": "Giancarlo Crocetti", "authors": "Giancarlo Crocetti, Amir A. Delay, Fatemeh Seyedmendhi", "title": "Identifying Structures in Social Conversations in NSCLC Patients through\n  the Semi-Automatic extraction of Topical Taxonomies", "comments": "7 pages, 7 figures, 1 table", "journal-ref": "Journal of Engineering Research and Applications, Vol. 6, Issue 1,\n  January 2016, pp.20-26", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploration of social conversations for addressing patient's needs is an\nimportant analytical task in which many scholarly publications are contributing\nto fill the knowledge gap in this area. The main difficulty remains the\ninability to turn such contributions into pragmatic processes the\npharmaceutical industry can leverage in order to generate insight from social\nmedia data, which can be considered as one of the most challenging source of\ninformation available today due to its sheer volume and noise. This study is\nbased on the work by Scott Spangler and Jeffrey Kreulen and applies it to\nidentify structure in social media through the extraction of a topical taxonomy\nable to capture the latent knowledge in social conversations in health-related\nsites. The mechanism for automatically identifying and generating a taxonomy\nfrom social conversations is developed and pressured tested using public data\nfrom media sites focused on the needs of cancer patients and their families.\nMoreover, a novel method for generating the category's label and the\ndetermination of an optimal number of categories is presented which extends\nScott and Jeffrey's research in a meaningful way. We assume the reader is\nfamiliar with taxonomies, what they are and how they are used.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 19:56:49 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Crocetti", "Giancarlo", ""], ["Delay", "Amir A.", ""], ["Seyedmendhi", "Fatemeh", ""]]}, {"id": "1602.04875", "submitter": "Min Chen", "authors": "Min Chen and Emilio Frazzoli and David Hsu and Wee Sun Lee", "title": "POMDP-lite for Robust Robot Planning under Uncertainty", "comments": "In Proc. IEEE International Conference on Robotics & Automation\n  (ICRA) 2016, with supplementary materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The partially observable Markov decision process (POMDP) provides a\nprincipled general model for planning under uncertainty. However, solving a\ngeneral POMDP is computationally intractable in the worst case. This paper\nintroduces POMDP-lite, a subclass of POMDPs in which the hidden state variables\nare constant or only change deterministically. We show that a POMDP-lite is\nequivalent to a set of fully observable Markov decision processes indexed by a\nhidden parameter and is useful for modeling a variety of interesting robotic\ntasks. We develop a simple model-based Bayesian reinforcement learning\nalgorithm to solve POMDP-lite models. The algorithm performs well on\nlarge-scale POMDP-lite models with up to $10^{20}$ states and outperforms the\nstate-of-the-art general-purpose POMDP algorithms. We further show that the\nalgorithm is near-Bayesian-optimal under suitable conditions.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 00:47:08 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2016 03:18:30 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2016 06:44:24 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Chen", "Min", ""], ["Frazzoli", "Emilio", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""]]}, {"id": "1602.04889", "submitter": "Jordan Ash", "authors": "Jordan T. Ash, Robert E. Schapire and Barbara E. Engelhardt", "title": "Unsupervised Domain Adaptation Using Approximate Label Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation addresses the problem created when training data is\ngenerated by a so-called source distribution, but test data is generated by a\nsignificantly different target distribution. In this work, we present\napproximate label matching (ALM), a new unsupervised domain adaptation\ntechnique that creates and leverages a rough labeling on the test samples, then\nuses these noisy labels to learn a transformation that aligns the source and\ntarget samples. We show that the transformation estimated by ALM has favorable\nproperties compared to transformations estimated by other methods, which do not\nuse any kind of target labeling. Our model is regularized by requiring that a\nclassifier trained to discriminate source from transformed target samples\ncannot distinguish between the two. We experiment with ALM on simulated and\nreal data, and show that it outperforms techniques commonly used in the field.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 02:38:25 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2016 05:25:20 GMT"}, {"version": "v3", "created": "Wed, 1 Mar 2017 19:17:35 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Ash", "Jordan T.", ""], ["Schapire", "Robert E.", ""], ["Engelhardt", "Barbara E.", ""]]}, {"id": "1602.04921", "submitter": "Weiyao Lin", "authors": "Weiyao Lin, Yang Mi, Weiyue Wang, Jianxin Wu, Jingdong Wang, Tao Mei", "title": "A diffusion and clustering-based approach for finding coherent motions\n  and understanding crowd scenes", "comments": "This manuscript is the accepted version for TIP (IEEE Transactions on\n  Image Processing), 2016", "journal-ref": null, "doi": "10.1109/TIP.2016.2531281", "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of detecting coherent motions in crowd\nscenes and presents its two applications in crowd scene understanding: semantic\nregion detection and recurrent activity mining. It processes input motion\nfields (e.g., optical flow fields) and produces a coherent motion filed, named\nas thermal energy field. The thermal energy field is able to capture both\nmotion correlation among particles and the motion trends of individual\nparticles which are helpful to discover coherency among them. We further\nintroduce a two-step clustering process to construct stable semantic regions\nfrom the extracted time-varying coherent motions. These semantic regions can be\nused to recognize pre-defined activities in crowd scenes. Finally, we introduce\na cluster-and-merge process which automatically discovers recurrent activities\nin crowd scenes by clustering and merging the extracted coherent motions.\nExperiments on various videos demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 06:25:30 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Lin", "Weiyao", ""], ["Mi", "Yang", ""], ["Wang", "Weiyue", ""], ["Wu", "Jianxin", ""], ["Wang", "Jingdong", ""], ["Mei", "Tao", ""]]}, {"id": "1602.04936", "submitter": "Harshit Sethy", "authors": "Harshit Sethy, Amit Patel", "title": "Reinforcement Learning approach for Real Time Strategy Games Battle city\n  and S3", "comments": "13 pages, vol 9 issue 4 of IJIP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we proposed reinforcement learning algorithms with the\ngeneralized reward function. In our proposed method we use Q-learning and SARSA\nalgorithms with generalised reward function to train the reinforcement learning\nagent. We evaluated the performance of our proposed algorithms on two real-time\nstrategy games called BattleCity and S3. There are two main advantages of\nhaving such an approach as compared to other works in RTS. (1) We can ignore\nthe concept of a simulator which is often game specific and is usually hard\ncoded in any type of RTS games (2) our system can learn from interaction with\nany opponents and quickly change the strategy according to the opponents and do\nnot need any human traces as used in previous works. Keywords : Reinforcement\nlearning, Machine learning, Real time strategy, Artificial intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 08:17:17 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Sethy", "Harshit", ""], ["Patel", "Amit", ""]]}, {"id": "1602.04938", "submitter": "Marco Tulio Ribeiro", "authors": "Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin", "title": "\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite widespread adoption, machine learning models remain mostly black\nboxes. Understanding the reasons behind predictions is, however, quite\nimportant in assessing trust, which is fundamental if one plans to take action\nbased on a prediction, or when choosing whether to deploy a new model. Such\nunderstanding also provides insights into the model, which can be used to\ntransform an untrustworthy model or prediction into a trustworthy one. In this\nwork, we propose LIME, a novel explanation technique that explains the\npredictions of any classifier in an interpretable and faithful manner, by\nlearning an interpretable model locally around the prediction. We also propose\na method to explain models by presenting representative individual predictions\nand their explanations in a non-redundant way, framing the task as a submodular\noptimization problem. We demonstrate the flexibility of these methods by\nexplaining different models for text (e.g. random forests) and image\nclassification (e.g. neural networks). We show the utility of explanations via\nnovel experiments, both simulated and with human subjects, on various scenarios\nthat require trust: deciding if one should trust a prediction, choosing between\nmodels, improving an untrustworthy classifier, and identifying why a classifier\nshould not be trusted.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 08:20:14 GMT"}, {"version": "v2", "created": "Wed, 3 Aug 2016 22:30:58 GMT"}, {"version": "v3", "created": "Tue, 9 Aug 2016 17:54:52 GMT"}], "update_date": "2016-08-10", "authors_parsed": [["Ribeiro", "Marco Tulio", ""], ["Singh", "Sameer", ""], ["Guestrin", "Carlos", ""]]}, {"id": "1602.04951", "submitter": "Anna Harutyunyan", "authors": "Anna Harutyunyan and Marc G. Bellemare and Tom Stepleton and Remi\n  Munos", "title": "Q($\\lambda$) with Off-Policy Corrections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze an alternate approach to off-policy multi-step\ntemporal difference learning, in which off-policy returns are corrected with\nthe current Q-function in terms of rewards, rather than with the target policy\nin terms of transition probabilities. We prove that such approximate\ncorrections are sufficient for off-policy convergence both in policy evaluation\nand control, provided certain conditions. These conditions relate the distance\nbetween the target and behavior policies, the eligibility trace parameter and\nthe discount factor, and formalize an underlying tradeoff in off-policy\nTD($\\lambda$). We illustrate this theoretical relationship empirically on a\ncontinuous-state control task.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 09:09:56 GMT"}, {"version": "v2", "created": "Thu, 11 Aug 2016 09:40:12 GMT"}], "update_date": "2016-08-12", "authors_parsed": [["Harutyunyan", "Anna", ""], ["Bellemare", "Marc G.", ""], ["Stepleton", "Tom", ""], ["Munos", "Remi", ""]]}, {"id": "1602.04983", "submitter": "Sreyasi Nag Chowdhury", "authors": "Sreyasi Nag Chowdhury, Mateusz Malinowski, Andreas Bulling, Mario\n  Fritz", "title": "Contextual Media Retrieval Using Natural Language Queries", "comments": "8 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread integration of cameras in hand-held and head-worn devices as\nwell as the ability to share content online enables a large and diverse visual\ncapture of the world that millions of users build up collectively every day. We\nenvision these images as well as associated meta information, such as GPS\ncoordinates and timestamps, to form a collective visual memory that can be\nqueried while automatically taking the ever-changing context of mobile users\ninto account. As a first step towards this vision, in this work we present\nXplore-M-Ego: a novel media retrieval system that allows users to query a\ndynamic database of images and videos using spatio-temporal natural language\nqueries. We evaluate our system using a new dataset of real user queries as\nwell as through a usability study. One key finding is that there is a\nconsiderable amount of inter-user variability, for example in the resolution of\nspatial relations in natural language utterances. We show that our retrieval\nsystem can cope with this variability using personalisation through an online\nlearning-based retrieval formulation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 11:04:29 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Chowdhury", "Sreyasi Nag", ""], ["Malinowski", "Mateusz", ""], ["Bulling", "Andreas", ""], ["Fritz", "Mario", ""]]}, {"id": "1602.05012", "submitter": "Jaroslav Fowkes", "authors": "Jaroslav Fowkes and Charles Sutton", "title": "A Subsequence Interleaving Model for Sequential Pattern Mining", "comments": "10 pages in KDD 2016: Proceedings of the 22nd ACM SIGKDD\n  International Conference on Knowledge Discovery and Data Mining", "journal-ref": null, "doi": "10.1145/2939672.2939787", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent sequential pattern mining methods have used the minimum description\nlength (MDL) principle to define an encoding scheme which describes an\nalgorithm for mining the most compressing patterns in a database. We present a\nnovel subsequence interleaving model based on a probabilistic model of the\nsequence database, which allows us to search for the most compressing set of\npatterns without designing a specific encoding scheme. Our proposed algorithm\nis able to efficiently mine the most relevant sequential patterns and rank them\nusing an associated measure of interestingness. The efficient inference in our\nmodel is a direct result of our use of a structural expectation-maximization\nframework, in which the expectation-step takes the form of a submodular\noptimization problem subject to a coverage constraint. We show on both\nsynthetic and real world datasets that our model mines a set of sequential\npatterns with low spuriousness and redundancy, high interpretability and\nusefulness in real-world applications. Furthermore, we demonstrate that the\nquality of the patterns from our approach is comparable to, if not better than,\nexisting state of the art sequential pattern mining algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 13:30:10 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 10:43:36 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Fowkes", "Jaroslav", ""], ["Sutton", "Charles", ""]]}, {"id": "1602.05028", "submitter": "Ilya Zakirzyanov", "authors": "Vladimir Ulyantsev, Ilya Zakirzyanov and Anatoly Shalyto", "title": "Symmetry Breaking Predicates for SAT-based DFA Identification", "comments": "14 pages, 9 figures, 5 tables, submitted to Journal of Computer and\n  System Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It was shown before that the NP-hard problem of deterministic finite automata\n(DFA) identification can be effectively translated to Boolean satisfiability\n(SAT). Modern SAT-solvers can tackle hard DFA identification instances\nefficiently. We present a technique to reduce the problem search space by\nenforcing an enumeration of DFA states in depth-first search (DFS) or\nbreadth-first search (BFS) order. We propose symmetry breaking predicates,\nwhich can be added to Boolean formulae representing various DFA identification\nproblems. We show how to apply this technique to DFA identification from both\nnoiseless and noisy data. Also we propose a method to identify all automata of\nthe desired size. The proposed approach outperforms the current\nstate-of-the-art DFASAT method for DFA identification from noiseless data. A\nbig advantage of the proposed approach is that it allows to determine exactly\nthe existence or non-existence of a solution of the noisy DFA identification\nproblem unlike metaheuristic approaches such as genetic algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 14:26:24 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2016 12:10:21 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Ulyantsev", "Vladimir", ""], ["Zakirzyanov", "Ilya", ""], ["Shalyto", "Anatoly", ""]]}, {"id": "1602.05220", "submitter": "Chris Eliasmith", "authors": "Chris Eliasmith and Jan Gosmann and Xuan Choo", "title": "BioSpaun: A large-scale behaving brain model with complex neurons", "comments": "17 pages 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a large-scale functional brain model that includes detailed,\nconductance-based, compartmental models of individual neurons. We call the\nmodel BioSpaun, to indicate the increased biological plausibility of these\nneurons, and because it is a direct extension of the Spaun model\n\\cite{Eliasmith2012b}. We demonstrate that including these detailed\ncompartmental models does not adversely affect performance across a variety of\ntasks, including digit recognition, serial working memory, and counting. We\nthen explore the effects of applying TTX, a sodium channel blocking drug, to\nthe model. We characterize the behavioral changes that result from this\nmolecular level intervention. We believe this is the first demonstration of a\nlarge-scale brain model that clearly links low-level molecular interventions\nand high-level behavior.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 22:09:07 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["Eliasmith", "Chris", ""], ["Gosmann", "Jan", ""], ["Choo", "Xuan", ""]]}, {"id": "1602.05292", "submitter": "Zhenhao Ge", "authors": "Zhenhao Ge, Yufang Sun and Mark J. T. Smith", "title": "Authorship Attribution Using a Neural Network Language Model", "comments": "Proceedings of the 30th AAAI Conference on Artificial Intelligence\n  (AAAI'16)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practice, training language models for individual authors is often\nexpensive because of limited data resources. In such cases, Neural Network\nLanguage Models (NNLMs), generally outperform the traditional non-parametric\nN-gram models. Here we investigate the performance of a feed-forward NNLM on an\nauthorship attribution problem, with moderate author set size and relatively\nlimited data. We also consider how the text topics impact performance. Compared\nwith a well-constructed N-gram baseline method with Kneser-Ney smoothing, the\nproposed method achieves nearly 2:5% reduction in perplexity and increases\nauthor classification accuracy by 3:43% on average, given as few as 5 test\nsentences. The performance is very competitive with the state of the art in\nterms of accuracy and demand on test data. The source code, preprocessed\ndatasets, a detailed description of the methodology and results are available\nat https://github.com/zge/authorship-attribution.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 04:06:28 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["Ge", "Zhenhao", ""], ["Sun", "Yufang", ""], ["Smith", "Mark J. T.", ""]]}, {"id": "1602.05352", "submitter": "Tobias Schnabel", "authors": "Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak and\n  Thorsten Joachims", "title": "Recommendations as Treatments: Debiasing Learning and Evaluation", "comments": "10 pages in ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most data for evaluating and training recommender systems is subject to\nselection biases, either through self-selection by the users or through the\nactions of the recommendation system itself. In this paper, we provide a\nprincipled approach to handling selection biases, adapting models and\nestimation techniques from causal inference. The approach leads to unbiased\nperformance estimators despite biased data, and to a matrix factorization\nmethod that provides substantially improved prediction performance on\nreal-world data. We theoretically and empirically characterize the robustness\nof the approach, finding that it is highly practical and scalable.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 09:58:25 GMT"}, {"version": "v2", "created": "Fri, 27 May 2016 03:18:59 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Schnabel", "Tobias", ""], ["Swaminathan", "Adith", ""], ["Singh", "Ashudeep", ""], ["Chandak", "Navin", ""], ["Joachims", "Thorsten", ""]]}, {"id": "1602.05404", "submitter": "Jos Uiterwijk", "authors": "Jos W.H.M. Uiterwijk", "title": "11 x 11 Domineering is Solved: The first player wins", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have developed a program called MUDoS (Maastricht University Domineering\nSolver) that solves Domineering positions in a very efficient way. This enables\nthe solution of known positions so far (up to the 10 x 10 board) much quicker\n(measured in number of investigated nodes).\n  More importantly, it enables the solution of the 11 x 11 Domineering board, a\nboard up till now far out of reach of previous Domineering solvers. The\nsolution needed the investigation of 259,689,994,008 nodes, using almost half a\nyear of computation time on a single simple desktop computer. The results show\nthat under optimal play the first player wins the 11 x 11 Domineering game,\nirrespective if Vertical or Horizontal starts the game.\n  In addition, several other boards hitherto unsolved were solved. Using the\nconvention that Vertical starts, the 8 x 15, 11 x 9, 12 x 8, 12 x 15, 14 x 8,\nand 17 x 6 boards are all won by Vertical, whereas the 6 x 17, 8 x 12, 9 x 11,\nand 11 x 10 boards are all won by Horizontal.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 13:34:04 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["Uiterwijk", "Jos W. H. M.", ""]]}, {"id": "1602.05450", "submitter": "Adrian \\v{S}o\\v{s}i\\'c", "authors": "Adrian \\v{S}o\\v{s}i\\'c, Wasiur R. KhudaBukhsh, Abdelhak M. Zoubir,\n  Heinz Koeppl", "title": "Inverse Reinforcement Learning in Swarm Systems", "comments": "9 pages, 8 figures; ### Version 2 ### version accepted at AAMAS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse reinforcement learning (IRL) has become a useful tool for learning\nbehavioral models from demonstration data. However, IRL remains mostly\nunexplored for multi-agent systems. In this paper, we show how the principle of\nIRL can be extended to homogeneous large-scale problems, inspired by the\ncollective swarming behavior of natural systems. In particular, we make the\nfollowing contributions to the field: 1) We introduce the swarMDP framework, a\nsub-class of decentralized partially observable Markov decision processes\nendowed with a swarm characterization. 2) Exploiting the inherent homogeneity\nof this framework, we reduce the resulting multi-agent IRL problem to a\nsingle-agent one by proving that the agent-specific value functions in this\nmodel coincide. 3) To solve the corresponding control problem, we propose a\nnovel heterogeneous learning scheme that is particularly tailored to the swarm\nsetting. Results on two example systems demonstrate that our framework is able\nto produce meaningful local reward models from which we can replicate the\nobserved global system dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 15:19:56 GMT"}, {"version": "v2", "created": "Fri, 24 Mar 2017 13:06:48 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["\u0160o\u0161i\u0107", "Adrian", ""], ["KhudaBukhsh", "Wasiur R.", ""], ["Zoubir", "Abdelhak M.", ""], ["Koeppl", "Heinz", ""]]}, {"id": "1602.05473", "submitter": "Lars Maal{\\o}e", "authors": "Lars Maal{\\o}e, Casper Kaae S{\\o}nderby, S{\\o}ren Kaae S{\\o}nderby,\n  Ole Winther", "title": "Auxiliary Deep Generative Models", "comments": "Proceedings of the 33rd International Conference on Machine Learning,\n  New York, NY, USA, 2016, JMLR: Workshop and Conference Proceedings volume 48,\n  Proceedings of the 33rd International Conference on Machine Learning, New\n  York, NY, USA, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models parameterized by neural networks have recently\nachieved state-of-the-art performance in unsupervised and semi-supervised\nlearning. We extend deep generative models with auxiliary variables which\nimproves the variational approximation. The auxiliary variables leave the\ngenerative model unchanged but make the variational distribution more\nexpressive. Inspired by the structure of the auxiliary variable we also propose\na model with two stochastic layers and skip connections. Our findings suggest\nthat more expressive and properly specified deep generative models converge\nfaster with better results. We show state-of-the-art performance within\nsemi-supervised learning on MNIST, SVHN and NORB datasets.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 16:24:50 GMT"}, {"version": "v2", "created": "Thu, 26 May 2016 10:21:34 GMT"}, {"version": "v3", "created": "Fri, 3 Jun 2016 09:19:21 GMT"}, {"version": "v4", "created": "Thu, 16 Jun 2016 06:39:08 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Maal\u00f8e", "Lars", ""], ["S\u00f8nderby", "Casper Kaae", ""], ["S\u00f8nderby", "S\u00f8ren Kaae", ""], ["Winther", "Ole", ""]]}, {"id": "1602.05561", "submitter": "Payam Siyari", "authors": "Payam Siyari, Bistra Dilkina, Constantine Dovrolis", "title": "Lexis: An Optimization Framework for Discovering the Hierarchical\n  Structure of Sequential Data", "comments": null, "journal-ref": null, "doi": "10.1145/2939672.2939741", "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data represented as strings abounds in biology, linguistics, document mining,\nweb search and many other fields. Such data often have a hierarchical\nstructure, either because they were artificially designed and composed in a\nhierarchical manner or because there is an underlying evolutionary process that\ncreates repeatedly more complex strings from simpler substrings. We propose a\nframework, referred to as \"Lexis\", that produces an optimized hierarchical\nrepresentation of a given set of \"target\" strings. The resulting hierarchy,\n\"Lexis-DAG\", shows how to construct each target through the concatenation of\nintermediate substrings, minimizing the total number of such concatenations or\nDAG edges. The Lexis optimization problem is related to the smallest grammar\nproblem. After we prove its NP-Hardness for two cost formulations, we propose\nan efficient greedy algorithm for the construction of Lexis-DAGs. We also\nconsider the problem of identifying the set of intermediate nodes (substrings)\nthat collectively form the \"core\" of a Lexis-DAG, which is important in the\nanalysis of Lexis-DAGs. We show that the Lexis framework can be applied in\ndiverse applications such as optimized synthesis of DNA fragments in genomic\nlibraries, hierarchical structure discovery in protein sequences,\ndictionary-based text compression, and feature extraction from a set of\ndocuments.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 20:36:28 GMT"}, {"version": "v2", "created": "Thu, 3 Mar 2016 21:15:54 GMT"}, {"version": "v3", "created": "Sat, 11 Jun 2016 05:52:26 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Siyari", "Payam", ""], ["Dilkina", "Bistra", ""], ["Dovrolis", "Constantine", ""]]}, {"id": "1602.05699", "submitter": "Heng Zhang", "authors": "Hai Wan, Heng Zhang, Peng Xiao, Haoran Huang, Yan Zhang", "title": "Query Answering with Inconsistent Existential Rules under Stable Model\n  Semantics", "comments": "Accepted by AAAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional inconsistency-tolerent query answering in ontology-based data\naccess relies on selecting maximal components of an ABox/database which are\nconsistent with the ontology. However, some rules in ontologies might be\nunreliable if they are extracted from ontology learning or written by\nunskillful knowledge engineers. In this paper we present a framework of\nhandling inconsistent existential rules under stable model semantics, which is\ndefined by a notion called rule repairs to select maximal components of the\nexistential rules. Surprisingly, for R-acyclic existential rules with\nR-stratified or guarded existential rules with stratified negations, both the\ndata complexity and combined complexity of query answering under the rule\n{repair semantics} remain the same as that under the conventional query\nanswering semantics. This leads us to propose several approaches to handle the\nrule {repair semantics} by calling answer set programming solvers. An\nexperimental evaluation shows that these approaches have good scalability of\nquery answering under rule repairs on realistic cases.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 07:23:28 GMT"}], "update_date": "2016-02-19", "authors_parsed": [["Wan", "Hai", ""], ["Zhang", "Heng", ""], ["Xiao", "Peng", ""], ["Huang", "Haoran", ""], ["Zhang", "Yan", ""]]}, {"id": "1602.05705", "submitter": "Jonathan Nix", "authors": "Jonathan Darren Nix", "title": "A theory of contemplation", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper you can explore the application of some notable Boolean-derived\nmethods, namely the Disjunctive Normal Form representation of logic table\nexpansions, and extend them to a real-valued logic model which is able to\nutilize quantities on the range [0,1], [-1,1], [a,b], (x,y), (x,y,z), and etc.\nso as to produce a logical programming of arbitrary range, precision, and\ndimensionality, thereby enabling contemplation at a logical level in notions of\narbitrary data, colors, and spatial constructs, with an example of the\nproduction of a game character's logic in mathematical form.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 07:42:00 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 01:05:14 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 03:12:55 GMT"}, {"version": "v4", "created": "Sun, 20 Oct 2019 17:51:11 GMT"}, {"version": "v5", "created": "Tue, 22 Oct 2019 23:22:39 GMT"}, {"version": "v6", "created": "Wed, 30 Oct 2019 18:56:58 GMT"}, {"version": "v7", "created": "Tue, 5 Nov 2019 19:57:31 GMT"}, {"version": "v8", "created": "Fri, 8 Nov 2019 17:36:46 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Nix", "Jonathan Darren", ""]]}, {"id": "1602.05765", "submitter": "Steven Schockaert", "authors": "Shoaib Jameel, Steven Schockaert", "title": "Entity Embeddings with Conceptual Subspaces as a Basis for Plausible\n  Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conceptual spaces are geometric representations of conceptual knowledge, in\nwhich entities correspond to points, natural properties correspond to convex\nregions, and the dimensions of the space correspond to salient features. While\nconceptual spaces enable elegant models of various cognitive phenomena, the\nlack of automated methods for constructing such representations have so far\nlimited their application in artificial intelligence. To address this issue, we\npropose a method which learns a vector-space embedding of entities from\nWikipedia and constrains this embedding such that entities of the same semantic\ntype are located in some lower-dimensional subspace. We experimentally\ndemonstrate the usefulness of these subspaces as (approximate) conceptual space\nrepresentations by showing, among others, that important features can be\nmodelled as directions and that natural properties tend to correspond to convex\nregions.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 11:37:50 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 13:48:21 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Jameel", "Shoaib", ""], ["Schockaert", "Steven", ""]]}, {"id": "1602.05828", "submitter": "Zied Bouraoui", "authors": "Jean Francois Baget, Salem Benferhat, Zied Bouraoui, Madalina\n  Croitoru, Marie-Laure Mugnier, Odile Papini, Swan Rocher, Karim Tabia", "title": "A General Modifier-based Framework for Inconsistency-Tolerant Query\n  Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework for inconsistency-tolerant query answering\nwithin existential rule setting. This framework unifies the main semantics\nproposed by the state of art and introduces new ones based on cardinality and\nmajority principles. It relies on two key notions: modifiers and inference\nstrategies. An inconsistency-tolerant semantics is seen as a composite modifier\nplus an inference strategy. We compare the obtained semantics from a\nproductivity point of view.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 15:13:00 GMT"}], "update_date": "2016-02-19", "authors_parsed": [["Baget", "Jean Francois", ""], ["Benferhat", "Salem", ""], ["Bouraoui", "Zied", ""], ["Croitoru", "Madalina", ""], ["Mugnier", "Marie-Laure", ""], ["Papini", "Odile", ""], ["Rocher", "Swan", ""], ["Tabia", "Karim", ""]]}, {"id": "1602.05897", "submitter": "Amit Daniely", "authors": "Amit Daniely and Roy Frostig and Yoram Singer", "title": "Toward Deeper Understanding of Neural Networks: The Power of\n  Initialization and a Dual View on Expressivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a general duality between neural networks and compositional\nkernels, striving towards a better understanding of deep learning. We show that\ninitial representations generated by common random initializations are\nsufficiently rich to express all functions in the dual kernel space. Hence,\nthough the training objective is hard to optimize in the worst case, the\ninitial weights form a good starting point for optimization. Our dual view also\nreveals a pragmatic and aesthetic perspective of neural networks and\nunderscores their expressive power.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 18:14:19 GMT"}, {"version": "v2", "created": "Fri, 19 May 2017 18:39:00 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Daniely", "Amit", ""], ["Frostig", "Roy", ""], ["Singer", "Yoram", ""]]}, {"id": "1602.06052", "submitter": "Johannes Klaus Fichte", "authors": "Johannes K. Fichte and Arne Meier and Irina Schindler", "title": "Strong Backdoors for Default Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a notion of backdoors to Reiter's propositional\ndefault logic and study structural properties of it. Also we consider the\nproblems of backdoor detection (parameterised by the solution size) as well as\nbackdoor evaluation (parameterised by the size of the given backdoor), for\nvarious kinds of target classes (cnf, horn, krom, monotone, identity). We show\nthat backdoor detection is fixed-parameter tractable for the considered target\nclasses, and backdoor evaluation is either fixed-parameter tractable, in\npara-DP2 , or in para-NP, depending on the target class.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2016 06:42:48 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Fichte", "Johannes K.", ""], ["Meier", "Arne", ""], ["Schindler", "Irina", ""]]}, {"id": "1602.06136", "submitter": "Mazen Alsarem", "authors": "Mazen Alsarem (DRIM), Pierre-Edouard Portier (DRIM), Sylvie Calabretto\n  (DRIM), Harald Kosch", "title": "Ordonnancement d'entit\\'es pour la rencontre du web des documents et du\n  web des donn\\'ees", "comments": "in French, Revue des Sciences et Technologies de l'Information -\n  S{\\'e}rie Document Num\\'erique, Lavoisier, 2015, Nouvelles approches en\n  recherche d'information, 18 (2-3/2015 ), pp.123-154", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advances of the Linked Open Data (LOD) initiative are giving rise to a\nmore structured web of data. Indeed, a few datasets act as hubs (e.g., DBpedia)\nconnecting many other datasets. They also made possible new web services for\nentity detection inside plain text (e.g., DBpedia Spotlight), thus allowing for\nnew applications that will benefit from a combination of the web of documents\nand the web of data. To ease the emergence of these new use-cases, we propose a\nquery-biased algorithm for the ranking of entities detected inside a web page.\nOur algorithm combine link analysis with dimensionality reduction. We use\ncrowdsourcing for building a publicly available and reusable dataset on which\nwe compare our algorithm to the state of the art. Finally, we use this\nalgorithm for the construction of semantic snippets for which we evaluate the\nusability and the usefulness with a crowdsourcing-based approach.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2016 13:05:42 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Alsarem", "Mazen", "", "DRIM"], ["Portier", "Pierre-Edouard", "", "DRIM"], ["Calabretto", "Sylvie", "", "DRIM"], ["Kosch", "Harald", ""]]}, {"id": "1602.06347", "submitter": "Ferdinando Fioretto", "authors": "Ferdinando Fioretto, Enrico Pontelli, William Yeoh", "title": "Distributed Constraint Optimization Problems and Applications: A Survey", "comments": null, "journal-ref": "Journal of Artificial Intelligence Research 61 (2018), 623-698", "doi": "10.1613/jair.5565", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of Multi-Agent System (MAS) is an active area of research within\nArtificial Intelligence, with an increasingly important impact in industrial\nand other real-world applications. Within a MAS, autonomous agents interact to\npursue personal interests and/or to achieve common objectives. Distributed\nConstraint Optimization Problems (DCOPs) have emerged as one of the prominent\nagent architectures to govern the agents' autonomous behavior, where both\nalgorithms and communication models are driven by the structure of the specific\nproblem. During the last decade, several extensions to the DCOP model have\nenabled them to support MAS in complex, real-time, and uncertain environments.\nThis survey aims at providing an overview of the DCOP model, giving a\nclassification of its multiple extensions and addressing both resolution\nmethods and applications that find a natural mapping within each class of\nDCOPs. The proposed classification suggests several future perspectives for\nDCOP extensions, and identifies challenges in the design of efficient\nresolution algorithms, possibly through the adaptation of strategies from\ndifferent areas.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2016 00:23:10 GMT"}, {"version": "v2", "created": "Wed, 6 Jul 2016 14:59:14 GMT"}, {"version": "v3", "created": "Thu, 11 May 2017 03:00:42 GMT"}, {"version": "v4", "created": "Thu, 11 Jan 2018 02:26:23 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Fioretto", "Ferdinando", ""], ["Pontelli", "Enrico", ""], ["Yeoh", "William", ""]]}, {"id": "1602.06359", "submitter": "Liang Pang", "authors": "Liang Pang, Yanyan Lan, Jiafeng Guo, Jun Xu, Shengxian Wan, Xueqi\n  Cheng", "title": "Text Matching as Image Recognition", "comments": "Accepted by AAAI-2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matching two texts is a fundamental problem in many natural language\nprocessing tasks. An effective way is to extract meaningful matching patterns\nfrom words, phrases, and sentences to produce the matching score. Inspired by\nthe success of convolutional neural network in image recognition, where neurons\ncan capture many complicated patterns based on the extracted elementary visual\npatterns such as oriented edges and corners, we propose to model text matching\nas the problem of image recognition. Firstly, a matching matrix whose entries\nrepresent the similarities between words is constructed and viewed as an image.\nThen a convolutional neural network is utilized to capture rich matching\npatterns in a layer-by-layer way. We show that by resembling the compositional\nhierarchies of patterns in image recognition, our model can successfully\nidentify salient signals such as n-gram and n-term matchings. Experimental\nresults demonstrate its superiority against the baselines.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2016 02:55:11 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Pang", "Liang", ""], ["Lan", "Yanyan", ""], ["Guo", "Jiafeng", ""], ["Xu", "Jun", ""], ["Wan", "Shengxian", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1602.06458", "submitter": "Leopoldo Bertossi", "authors": "Babak Salimi and Leopoldo Bertossi", "title": "Causes for Query Answers from Databases, Datalog Abduction and\n  View-Updates: The Presence of Integrity Constraints", "comments": "To appear in Proceedings Flairs, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causality has been recently introduced in databases, to model, characterize\nand possibly compute causes for query results (answers). Connections between\nqueryanswer causality, consistency-based diagnosis, database repairs (wrt.\nintegrity constraint violations), abductive diagnosis and the view-update\nproblem have been established. In this work we further investigate connections\nbetween query-answer causality and abductive diagnosis and the view-update\nproblem. In this context, we also define and investigate the notion of\nquery-answer causality in the presence of integrity constraints.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2016 20:57:59 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Salimi", "Babak", ""], ["Bertossi", "Leopoldo", ""]]}, {"id": "1602.06462", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "The Singularity May Never Be Near", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is both much optimism and pessimism around artificial intelligence (AI)\ntoday. The optimists are investing millions of dollars, and even in some cases\nbillions of dollars into AI. The pessimists, on the other hand, predict that AI\nwill end many things: jobs, warfare, and even the human race. Both the\noptimists and the pessimists often appeal to the idea of a technological\nsingularity, a point in time where machine intelligence starts to run away, and\na new, more intelligent species starts to inhabit the earth. If the optimists\nare right, this will be a moment that fundamentally changes our economy and our\nsociety. If the pessimists are right, this will be a moment that also\nfundamentally changes our economy and our society. It is therefore very\nworthwhile spending some time deciding if either of them might be right.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2016 21:09:07 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "1602.06483", "submitter": "Liz Sonenberg", "authors": "Liz Sonenberg, Tim Miller, Adrian Pearce, Paolo Felli, Christian\n  Muise, Frank Dignum", "title": "Social planning for social HRI", "comments": "Presented at \"2nd Workshop on Cognitive Architectures for Social\n  Human-Robot Interaction 2016 (arXiv:1602.01868)\"", "journal-ref": null, "doi": null, "report-no": "CogArch4sHRI/2016/05", "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making a computational agent 'social' has implications for how it perceives\nitself and the environment in which it is situated, including the ability to\nrecognise the behaviours of others. We point to recent work on social planning,\ni.e. planning in settings where the social context is relevant in the\nassessment of the beliefs and capabilities of others, and in making appropriate\nchoices of what to do next.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2016 01:47:23 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Sonenberg", "Liz", ""], ["Miller", "Tim", ""], ["Pearce", "Adrian", ""], ["Felli", "Paolo", ""], ["Muise", "Christian", ""], ["Dignum", "Frank", ""]]}, {"id": "1602.06484", "submitter": "Mark Riedl", "authors": "Mark O. Riedl", "title": "Computational Narrative Intelligence: A Human-Centered Goal for\n  Artificial Intelligence", "comments": "5 pages, published in the CHI 2016 Workshop on Human-Centered Machine\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Narrative intelligence is the ability to craft, tell, understand, and respond\naffectively to stories. We argue that instilling artificial intelligences with\ncomputational narrative intelligence affords a number of applications\nbeneficial to humans. We lay out some of the machine learning challenges\nnecessary to solve to achieve computational narrative intelligence. Finally, we\nargue that computational narrative is a practical step towards machine\nenculturation, the teaching of sociocultural values to machines.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2016 01:59:09 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Riedl", "Mark O.", ""]]}, {"id": "1602.06522", "submitter": "Carlo Vittorio Cannistraci", "authors": "Josephine Maria Thomas, Alessandro Muscoloni, Sara Ciucci, Ginestra\n  Bianconi and Carlo Vittorio Cannistraci", "title": "Machine learning meets network science: dimensionality reduction for\n  fast and efficient embedding of networks in the hyperbolic space", "comments": null, "journal-ref": "Nature Communications 8, 1615 (2017)", "doi": "10.1038/s41467-017-01825-5", "report-no": null, "categories": "cond-mat.dis-nn cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex network topologies and hyperbolic geometry seem specularly connected,\nand one of the most fascinating and challenging problems of recent complex\nnetwork theory is to map a given network to its hyperbolic space. The\nPopularity Similarity Optimization (PSO) model represents - at the moment - the\nclimax of this theory. It suggests that the trade-off between node popularity\nand similarity is a mechanism to explain how complex network topologies emerge\n- as discrete samples - from the continuous world of hyperbolic geometry. The\nhyperbolic space seems appropriate to represent real complex networks. In fact,\nit preserves many of their fundamental topological properties, and can be\nexploited for real applications such as, among others, link prediction and\ncommunity detection. Here, we observe for the first time that a\ntopological-based machine learning class of algorithms - for nonlinear\nunsupervised dimensionality reduction - can directly approximate the network's\nnode angular coordinates of the hyperbolic model into a two-dimensional space,\naccording to a similar topological organization that we named angular\ncoalescence. On the basis of this phenomenon, we propose a new class of\nalgorithms that offers fast and accurate coalescent embedding of networks in\nthe hyperbolic space even for graphs with thousands of nodes.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2016 12:39:58 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Thomas", "Josephine Maria", ""], ["Muscoloni", "Alessandro", ""], ["Ciucci", "Sara", ""], ["Bianconi", "Ginestra", ""], ["Cannistraci", "Carlo Vittorio", ""]]}, {"id": "1602.06539", "submitter": "Liangcheng Liu", "authors": "Liangchen Liu and Arnold Wiliem and Shaokang Chen and Kun Zhao and\n  Brian C. Lovell", "title": "Determining the best attributes for surveillance video keywords\n  generation", "comments": "7 pages, ISBA 2016. arXiv admin note: text overlap with\n  arXiv:1602.01940", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic video keyword generation is one of the key ingredients in reducing\nthe burden of security officers in analyzing surveillance videos. Keywords or\nattributes are generally chosen manually based on expert knowledge of\nsurveillance. Most existing works primarily aim at either supervised learning\napproaches relying on extensive manual labelling or hierarchical probabilistic\nmodels that assume the features are extracted using the bag-of-words approach;\nthus limiting the utilization of the other features. To address this, we turn\nour attention to automatic attribute discovery approaches. However, it is not\nclear which automatic discovery approach can discover the most meaningful\nattributes. Furthermore, little research has been done on how to compare and\nchoose the best automatic attribute discovery methods. In this paper, we\npropose a novel approach, based on the shared structure exhibited amongst\nmeaningful attributes, that enables us to compare between different automatic\nattribute discovery approaches.We then validate our approach by comparing\nvarious attribute discovery methods such as PiCoDeS on two attribute datasets.\nThe evaluation shows that our approach is able to select the automatic\ndiscovery approach that discovers the most meaningful attributes. We then\nemploy the best discovery approach to generate keywords for videos recorded\nfrom a surveillance system. This work shows it is possible to massively reduce\nthe amount of manual work in generating video keywords without limiting\nourselves to a particular video feature descriptor.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2016 15:08:51 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Liu", "Liangchen", ""], ["Wiliem", "Arnold", ""], ["Chen", "Shaokang", ""], ["Zhao", "Kun", ""], ["Lovell", "Brian C.", ""]]}, {"id": "1602.06566", "submitter": "Mohammad Islam", "authors": "Dipayan Maiti and Mohammad Raihanul Islam and Scotland Leman and Naren\n  Ramakrishnan", "title": "Interactive Storytelling over Document Collections", "comments": "This paper has been submitted to a conference for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Storytelling algorithms aim to 'connect the dots' between disparate documents\nby linking starting and ending documents through a series of intermediate\ndocuments. Existing storytelling algorithms are based on notions of coherence\nand connectivity, and thus the primary way by which users can steer the story\nconstruction is via design of suitable similarity functions. We present an\nalternative approach to storytelling wherein the user can interactively and\niteratively provide 'must use' constraints to preferentially support the\nconstruction of some stories over others. The three innovations in our approach\nare distance measures based on (inferred) topic distributions, the use of\nconstraints to define sets of linear inequalities over paths, and the\nintroduction of slack and surplus variables to condition the topic distribution\nto preferentially emphasize desired terms over others. We describe experimental\nresults to illustrate the effectiveness of our interactive storytelling\napproach over multiple text datasets.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2016 18:46:35 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Maiti", "Dipayan", ""], ["Islam", "Mohammad Raihanul", ""], ["Leman", "Scotland", ""], ["Ramakrishnan", "Naren", ""]]}, {"id": "1602.06662", "submitter": "Mikael Henaff", "authors": "Mikael Henaff, Arthur Szlam, Yann LeCun", "title": "Recurrent Orthogonal Networks and Long-Memory Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although RNNs have been shown to be powerful tools for processing sequential\ndata, finding architectures or optimization strategies that allow them to model\nvery long term dependencies is still an active area of research. In this work,\nwe carefully analyze two synthetic datasets originally outlined in (Hochreiter\nand Schmidhuber, 1997) which are used to evaluate the ability of RNNs to store\ninformation over many time steps. We explicitly construct RNN solutions to\nthese problems, and using these constructions, illuminate both the problems\nthemselves and the way in which RNNs store different types of information in\ntheir hidden states. These constructions furthermore explain the success of\nrecent methods that specify unitary initializations or constraints on the\ntransition matrices.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 06:51:25 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 17:45:08 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Henaff", "Mikael", ""], ["Szlam", "Arthur", ""], ["LeCun", "Yann", ""]]}, {"id": "1602.06667", "submitter": "Manikandasriram Srinivasan Ramanagopal", "authors": "Manikandasriram Srinivasan Ramanagopal, Andr\\'e Phu-Van Nguyen, and\n  Jerome Le Ny", "title": "A Motion Planning Strategy for the Active Vision-Based Mapping of\n  Ground-Level Structures", "comments": "Accepted for publication in IEEE Transactions on Automation Science\n  and Engineering. Available in IEEE Xplore at\n  http://ieeexplore.ieee.org/document/8093664", "journal-ref": null, "doi": "10.1109/TASE.2017.2762088", "report-no": null, "categories": "cs.RO cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a strategy to guide a mobile ground robot equipped with a\ncamera or depth sensor, in order to autonomously map the visible part of a\nbounded three-dimensional structure. We describe motion planning algorithms\nthat determine appropriate successive viewpoints and attempt to fill holes\nautomatically in a point cloud produced by the sensing and perception layer.\nThe emphasis is on accurately reconstructing a 3D model of a structure of\nmoderate size rather than mapping large open environments, with applications\nfor example in architecture, construction and inspection. The proposed\nalgorithms do not require any initialization in the form of a mesh model or a\nbounding box, and the paths generated are well adapted to situations where the\nvision sensor is used simultaneously for mapping and for localizing the robot,\nin the absence of additional absolute positioning system. We analyze the\ncoverage properties of our policy, and compare its performance to the classic\nfrontier based exploration algorithm. We illustrate its efficacy for different\nstructure sizes, levels of localization accuracy and range of the depth sensor,\nand validate our design on a real-world experiment.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 07:05:49 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 17:27:45 GMT"}, {"version": "v3", "created": "Sat, 11 Nov 2017 01:00:14 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Ramanagopal", "Manikandasriram Srinivasan", ""], ["Nguyen", "Andr\u00e9 Phu-Van", ""], ["Ny", "Jerome Le", ""]]}, {"id": "1602.06897", "submitter": "Jorge Fandinno", "authors": "Pedro Cabalar and Jorge Fandinno", "title": "Enablers and Inhibitors in Causal Justifications of Logic Programs", "comments": null, "journal-ref": null, "doi": "10.1017/S1471068416000107", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To appear in Theory and Practice of Logic Programming (TPLP). In this paper\nwe propose an extension of logic programming (LP) where each default literal\nderived from the well-founded model is associated to a justification\nrepresented as an algebraic expression. This expression contains both causal\nexplanations (in the form of proof graphs built with rule labels) and terms\nunder the scope of negation that stand for conditions that enable or disable\nthe application of causal rules. Using some examples, we discuss how these new\nconditions, we respectively call \"enablers\" and \"inhibitors\", are intimately\nrelated to default negation and have an essentially different nature from\nregular cause-effect relations. The most important result is a formal\ncomparison to the recent algebraic approaches for justifications in LP:\n\"Why-not Provenance\" (WnP) and \"Causal Graphs\" (CG). We show that the current\napproach extends both WnP and CG justifications under the Well-Founded\nSemantics and, as a byproduct, we also establish a formal relation between\nthese two approaches.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 19:18:54 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Cabalar", "Pedro", ""], ["Fandinno", "Jorge", ""]]}, {"id": "1602.06977", "submitter": "Ethan Fast", "authors": "Ethan Fast, William McGrath, Pranav Rajpurkar, Michael Bernstein", "title": "Augur: Mining Human Behaviors from Fiction to Power Interactive Systems", "comments": "CHI: ACM Conference on Human Factors in Computing Systems 2016", "journal-ref": null, "doi": "10.1145/2858036.2858528", "report-no": null, "categories": "cs.HC cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From smart homes that prepare coffee when we wake, to phones that know not to\ninterrupt us during important conversations, our collective visions of HCI\nimagine a future in which computers understand a broad range of human\nbehaviors. Today our systems fall short of these visions, however, because this\nrange of behaviors is too large for designers or programmers to capture\nmanually. In this paper, we instead demonstrate it is possible to mine a broad\nknowledge base of human behavior by analyzing more than one billion words of\nmodern fiction. Our resulting knowledge base, Augur, trains vector models that\ncan predict many thousands of user activities from surrounding objects in\nmodern contexts: for example, whether a user may be eating food, meeting with a\nfriend, or taking a selfie. Augur uses these predictions to identify actions\nthat people commonly take on objects in the world and estimate a user's future\nactivities given their current situation. We demonstrate Augur-powered,\nactivity-based systems such as a phone that silences itself when the odds of\nyou answering it are low, and a dynamic music player that adjusts to your\npresent activity. A field deployment of an Augur-powered wearable camera\nresulted in 96% recall and 71% precision on its unsupervised predictions of\ncommon daily activities. A second evaluation where human judges rated the\nsystem's predictions over a broad set of input images found that 94% were rated\nsensible.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 21:44:05 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2016 20:54:28 GMT"}], "update_date": "2016-02-26", "authors_parsed": [["Fast", "Ethan", ""], ["McGrath", "William", ""], ["Rajpurkar", "Pranav", ""], ["Bernstein", "Michael", ""]]}, {"id": "1602.06979", "submitter": "Ethan Fast", "authors": "Ethan Fast, Binbin Chen, Michael Bernstein", "title": "Empath: Understanding Topic Signals in Large-Scale Text", "comments": "CHI: ACM Conference on Human Factors in Computing Systems 2016", "journal-ref": null, "doi": "10.1145/2858036.2858535", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human language is colored by a broad range of topics, but existing text\nanalysis tools only focus on a small number of them. We present Empath, a tool\nthat can generate and validate new lexical categories on demand from a small\nset of seed terms (like \"bleed\" and \"punch\" to generate the category violence).\nEmpath draws connotations between words and phrases by deep learning a neural\nembedding across more than 1.8 billion words of modern fiction. Given a small\nset of seed words that characterize a category, Empath uses its neural\nembedding to discover new related terms, then validates the category with a\ncrowd-powered filter. Empath also analyzes text across 200 built-in,\npre-validated categories we have generated from common topics in our web\ndataset, like neglect, government, and social media. We show that Empath's\ndata-driven, human validated categories are highly correlated (r=0.906) with\nsimilar categories in LIWC.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 21:47:43 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Fast", "Ethan", ""], ["Chen", "Binbin", ""], ["Bernstein", "Michael", ""]]}, {"id": "1602.07024", "submitter": "Sailik Sengupta", "authors": "Sailik Sengupta, Satya Gautam Vadlamudi, Subbarao Kambhampati,\n  Marthony Taguinod, Adam Doup\\'e, Ziming Zhao, Gail-Joon Ahn", "title": "Moving Target Defense for Web Applications using Bayesian Stackelberg\n  Games", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present complexity in designing web applications makes software security\na difficult goal to achieve. An attacker can explore a deployed service on the\nweb and attack at his/her own leisure. Moving Target Defense (MTD) in web\napplications is an effective mechanism to nullify this advantage of their\nreconnaissance but the framework demands a good switching strategy when\nswitching between multiple configurations for its web-stack. To address this\nissue, we propose modeling of a real-world MTD web application as a repeated\nBayesian game. We then formulate an optimization problem that generates an\neffective switching strategy while considering the cost of switching between\ndifferent web-stack configurations. To incorporate this model into a developed\nMTD system, we develop an automated system for generating attack sets of Common\nVulnerabilities and Exposures (CVEs) for input attacker types with predefined\ncapabilities. Our framework obtains realistic reward values for the players\n(defenders and attackers) in this game by using security domain expertise on\nCVEs obtained from the National Vulnerability Database (NVD). We also address\nthe issue of prioritizing vulnerabilities that when fixed, improves the\nsecurity of the MTD system. Lastly, we demonstrate the robustness of our\nproposed model by evaluating its performance when there is uncertainty about\ninput attacker information.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 03:44:16 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2016 18:20:38 GMT"}, {"version": "v3", "created": "Thu, 17 Nov 2016 01:04:59 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Sengupta", "Sailik", ""], ["Vadlamudi", "Satya Gautam", ""], ["Kambhampati", "Subbarao", ""], ["Taguinod", "Marthony", ""], ["Doup\u00e9", "Adam", ""], ["Zhao", "Ziming", ""], ["Ahn", "Gail-Joon", ""]]}, {"id": "1602.07029", "submitter": "Siddharth Reddy", "authors": "Siddharth Reddy, Igor Labutov, Thorsten Joachims", "title": "Latent Skill Embedding for Personalized Lesson Sequence Recommendation", "comments": "Under review by the ACM SIGKDD Conference on Knowledge Discovery and\n  Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Students in online courses generate large amounts of data that can be used to\npersonalize the learning process and improve quality of education. In this\npaper, we present the Latent Skill Embedding (LSE), a probabilistic model of\nstudents and educational content that can be used to recommend personalized\nsequences of lessons with the goal of helping students prepare for specific\nassessments. Akin to collaborative filtering for recommender systems, the\nalgorithm does not require students or content to be described by features, but\nit learns a representation using access traces. We formulate this problem as a\nregularized maximum-likelihood embedding of students, lessons, and assessments\nfrom historical student-content interactions. An empirical evaluation on\nlarge-scale data from Knewton, an adaptive learning technology company, shows\nthat this approach predicts assessment results competitively with benchmark\nmodels and is able to discriminate between lesson sequences that lead to\nmastery and failure.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 04:20:40 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Reddy", "Siddharth", ""], ["Labutov", "Igor", ""], ["Joachims", "Thorsten", ""]]}, {"id": "1602.07032", "submitter": "Siddharth Reddy", "authors": "Siddharth Reddy, Igor Labutov, Siddhartha Banerjee, Thorsten Joachims", "title": "Unbounded Human Learning: Optimal Scheduling for Spaced Repetition", "comments": "Accepted to the ACM SIGKDD Conference on Knowledge Discovery and Data\n  Mining 2016", "journal-ref": null, "doi": "10.1145/2939672.2939850", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the study of human learning, there is broad evidence that our ability to\nretain information improves with repeated exposure and decays with delay since\nlast exposure. This plays a crucial role in the design of educational software,\nleading to a trade-off between teaching new material and reviewing what has\nalready been taught. A common way to balance this trade-off is spaced\nrepetition, which uses periodic review of content to improve long-term\nretention. Though spaced repetition is widely used in practice, e.g., in\nelectronic flashcard software, there is little formal understanding of the\ndesign of these systems. Our paper addresses this gap in three ways. First, we\nmine log data from spaced repetition software to establish the functional\ndependence of retention on reinforcement and delay. Second, we use this memory\nmodel to develop a stochastic model for spaced repetition systems. We propose a\nqueueing network model of the Leitner system for reviewing flashcards, along\nwith a heuristic approximation that admits a tractable optimization problem for\nreview scheduling. Finally, we empirically evaluate our queueing model through\na Mechanical Turk experiment, verifying a key qualitative prediction of our\nmodel: the existence of a sharp phase transition in learning outcomes upon\nincreasing the rate of new item introductions.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 04:33:05 GMT"}, {"version": "v2", "created": "Wed, 8 Jun 2016 02:22:16 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Reddy", "Siddharth", ""], ["Labutov", "Igor", ""], ["Banerjee", "Siddhartha", ""], ["Joachims", "Thorsten", ""]]}, {"id": "1602.07057", "submitter": "Bowen Zhou", "authors": "Bowen Zhou, Shahriar Shariat", "title": "Finding Needle in a Million Metrics: Anomaly Detection in a Large-scale\n  Computational Advertising Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online media offers opportunities to marketers to deliver brand messages to a\nlarge audience. Advertising technology platforms enables the advertisers to\nfind the proper group of audiences and deliver ad impressions to them in real\ntime. The recent growth of the real time bidding has posed a significant\nchallenge on monitoring such a complicated system. With so many components we\nneed a reliable system that detects the possible changes in the system and\nalerts the engineering team. In this paper we describe the mechanism that we\ninvented for recovering the representative metrics and detecting the change in\ntheir behavior. We show that this mechanism is able to detect the possible\nproblems in time by describing some incident cases.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 07:07:26 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Zhou", "Bowen", ""], ["Shariat", "Shahriar", ""]]}, {"id": "1602.07064", "submitter": "Jorge Martinez Gil", "authors": "Jorge Martinez-Gil", "title": "SIFT: An Algorithm for Extracting Structural Information From Taxonomies", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present SIFT, a 3-step algorithm for the analysis of the\nstructural information represented by means of a taxonomy. The major advantage\nof this algorithm is the capability to leverage the information inherent to the\nhierarchical structures of taxonomies to infer correspondences which can allow\nto merge them in a later step. This method is particular relevant in scenarios\nwhere taxonomy alignment techniques exploiting textual information from\ntaxonomy nodes cannot operate successfully.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 07:33:02 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Martinez-Gil", "Jorge", ""]]}, {"id": "1602.07332", "submitter": "Ranjay Krishna", "authors": "Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata,\n  Joshua Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David A.\n  Shamma, Michael S. Bernstein, Fei-Fei Li", "title": "Visual Genome: Connecting Language and Vision Using Crowdsourced Dense\n  Image Annotations", "comments": "44 pages, 37 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite progress in perceptual tasks such as image classification, computers\nstill perform poorly on cognitive tasks such as image description and question\nanswering. Cognition is core to tasks that involve not just recognizing, but\nreasoning about our visual world. However, models used to tackle the rich\ncontent in images for cognitive tasks are still being trained using the same\ndatasets designed for perceptual tasks. To achieve success at cognitive tasks,\nmodels need to understand the interactions and relationships between objects in\nan image. When asked \"What vehicle is the person riding?\", computers will need\nto identify the objects in an image as well as the relationships riding(man,\ncarriage) and pulling(horse, carriage) in order to answer correctly that \"the\nperson is riding a horse-drawn carriage\".\n  In this paper, we present the Visual Genome dataset to enable the modeling of\nsuch relationships. We collect dense annotations of objects, attributes, and\nrelationships within each image to learn these models. Specifically, our\ndataset contains over 100K images where each image has an average of 21\nobjects, 18 attributes, and 18 pairwise relationships between objects. We\ncanonicalize the objects, attributes, relationships, and noun phrases in region\ndescriptions and questions answer pairs to WordNet synsets. Together, these\nannotations represent the densest and largest dataset of image descriptions,\nobjects, attributes, relationships, and question answers.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 22:00:40 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Krishna", "Ranjay", ""], ["Zhu", "Yuke", ""], ["Groth", "Oliver", ""], ["Johnson", "Justin", ""], ["Hata", "Kenji", ""], ["Kravitz", "Joshua", ""], ["Chen", "Stephanie", ""], ["Kalantidis", "Yannis", ""], ["Li", "Li-Jia", ""], ["Shamma", "David A.", ""], ["Bernstein", "Michael S.", ""], ["Li", "Fei-Fei", ""]]}, {"id": "1602.07360", "submitter": "Forrest Iandola", "authors": "Forrest N. Iandola, Song Han, Matthew W. Moskewicz, Khalid Ashraf,\n  William J. Dally, Kurt Keutzer", "title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB\n  model size", "comments": "In ICLR Format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on deep neural networks has focused primarily on improving\naccuracy. For a given accuracy level, it is typically possible to identify\nmultiple DNN architectures that achieve that accuracy level. With equivalent\naccuracy, smaller DNN architectures offer at least three advantages: (1)\nSmaller DNNs require less communication across servers during distributed\ntraining. (2) Smaller DNNs require less bandwidth to export a new model from\nthe cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on\nFPGAs and other hardware with limited memory. To provide all of these\nadvantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet\nachieves AlexNet-level accuracy on ImageNet with 50x fewer parameters.\nAdditionally, with model compression techniques we are able to compress\nSqueezeNet to less than 0.5MB (510x smaller than AlexNet).\n  The SqueezeNet architecture is available for download here:\nhttps://github.com/DeepScale/SqueezeNet\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 00:09:45 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2016 20:24:20 GMT"}, {"version": "v3", "created": "Wed, 6 Apr 2016 07:21:49 GMT"}, {"version": "v4", "created": "Fri, 4 Nov 2016 21:26:08 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Iandola", "Forrest N.", ""], ["Han", "Song", ""], ["Moskewicz", "Matthew W.", ""], ["Ashraf", "Khalid", ""], ["Dally", "William J.", ""], ["Keutzer", "Kurt", ""]]}, {"id": "1602.07362", "submitter": "Rachel Cummings", "authors": "Rachel Cummings, David M. Pennock, Jennifer Wortman Vaughan", "title": "The Possibilities and Limitations of Private Prediction Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the design of private prediction markets, financial markets\ndesigned to elicit predictions about uncertain events without revealing too\nmuch information about market participants' actions or beliefs. Our goal is to\ndesign market mechanisms in which participants' trades or wagers influence the\nmarket's behavior in a way that leads to accurate predictions, yet no single\nparticipant has too much influence over what others are able to observe. We\nstudy the possibilities and limitations of such mechanisms using tools from\ndifferential privacy. We begin by designing a private one-shot wagering\nmechanism in which bettors specify a belief about the likelihood of a future\nevent and a corresponding monetary wager. Wagers are redistributed among\nbettors in a way that more highly rewards those with accurate predictions. We\nprovide a class of wagering mechanisms that are guaranteed to satisfy\ntruthfulness, budget balance in expectation, and other desirable properties\nwhile additionally guaranteeing epsilon-joint differential privacy in the\nbettors' reported beliefs, and analyze the trade-off between the achievable\nlevel of privacy and the sensitivity of a bettor's payment to her own report.\nWe then ask whether it is possible to obtain privacy in dynamic prediction\nmarkets, focusing our attention on the popular cost-function framework in which\nsecurities with payments linked to future events are bought and sold by an\nautomated market maker. We show that under general conditions, it is impossible\nfor such a market maker to simultaneously achieve bounded worst-case loss and\nepsilon-differential privacy without allowing the privacy guarantee to degrade\nextremely quickly as the number of trades grows, making such markets\nimpractical in settings in which privacy is valued. We conclude by suggesting\nseveral avenues for potentially circumventing this lower bound.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 00:30:12 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Cummings", "Rachel", ""], ["Pennock", "David M.", ""], ["Vaughan", "Jennifer Wortman", ""]]}, {"id": "1602.07435", "submitter": "Yuan Luo", "authors": "Yuan Luo, Nihar B. Shah, Jianwei Huang, and Jean Walrand", "title": "Parametric Prediction from Parametric Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem of prediction based on opinions elicited from\nheterogeneous rational agents with private information. Making an accurate\nprediction with a minimal cost requires a joint design of the incentive\nmechanism and the prediction algorithm. Such a problem lies at the nexus of\nstatistical learning theory and game theory, and arises in many domains such as\nconsumer surveys and mobile crowdsourcing. In order to elicit heterogeneous\nagents' private information and incentivize agents with different capabilities\nto act in the principal's best interest, we design an optimal joint incentive\nmechanism and prediction algorithm called COPE (COst and Prediction\nElicitation), the analysis of which offers several valuable engineering\ninsights. First, when the costs incurred by the agents are linear in the\nexerted effort, COPE corresponds to a \"crowd contending\" mechanism, where the\nprincipal only employs the agent with the highest capability. Second, when the\ncosts are quadratic, COPE corresponds to a \"crowd-sourcing\" mechanism that\nemploys multiple agents with different capabilities at the same time. Numerical\nsimulations show that COPE improves the principal's profit and the network\nprofit significantly (larger than 30% in our simulations), comparing to those\nmechanisms that assume all agents have equal capabilities.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 08:56:46 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Luo", "Yuan", ""], ["Shah", "Nihar B.", ""], ["Huang", "Jianwei", ""], ["Walrand", "Jean", ""]]}, {"id": "1602.07563", "submitter": "Igor Mozeti\\v{c}", "authors": "Igor Mozetic, Miha Grcar, Jasmina Smailovic", "title": "Multilingual Twitter Sentiment Classification: The Role of Human\n  Annotators", "comments": null, "journal-ref": "PLoS ONE 11(5): e0155036, 2016", "doi": "10.1371/journal.pone.0155036", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What are the limits of automated Twitter sentiment classification? We analyze\na large set of manually labeled tweets in different languages, use them as\ntraining data, and construct automated classification models. It turns out that\nthe quality of classification models depends much more on the quality and size\nof training data than on the type of the model trained. Experimental results\nindicate that there is no statistically significant difference between the\nperformance of the top classification models. We quantify the quality of\ntraining data by applying various annotator agreement measures, and identify\nthe weakest points of different datasets. We show that the model performance\napproaches the inter-annotator agreement when the size of the training set is\nsufficiently large. However, it is crucial to regularly monitor the self- and\ninter-annotator agreements since this improves the training datasets and\nconsequently the model performance. Finally, we show that there is strong\nevidence that humans perceive the sentiment classes (negative, neutral, and\npositive) as ordered.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 15:34:22 GMT"}, {"version": "v2", "created": "Thu, 5 May 2016 07:05:52 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["Mozetic", "Igor", ""], ["Grcar", "Miha", ""], ["Smailovic", "Jasmina", ""]]}, {"id": "1602.07565", "submitter": "Petr Novotn\\'y", "authors": "Tom\\'a\\v{s} Br\\'azdil, Krishnendu Chatterjee, Martin Chmel\\'ik, Anchit\n  Gupta, Petr Novotn\\'y", "title": "Stochastic Shortest Path with Energy Constraints in POMDPs", "comments": "Technical report accompanying a paper published in proceedings of\n  AAMAS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider partially observable Markov decision processes (POMDPs) with a\nset of target states and positive integer costs associated with every\ntransition. The traditional optimization objective (stochastic shortest path)\nasks to minimize the expected total cost until the target set is reached. We\nextend the traditional framework of POMDPs to model energy consumption, which\nrepresents a hard constraint. The energy levels may increase and decrease with\ntransitions, and the hard constraint requires that the energy level must remain\npositive in all steps till the target is reached. First, we present a novel\nalgorithm for solving POMDPs with energy levels, developing on existing POMDP\nsolvers and using RTDP as its main method. Our second contribution is related\nto policy representation. For larger POMDP instances the policies computed by\nexisting solvers are too large to be understandable. We present an automated\nprocedure based on machine learning techniques that automatically extracts\nimportant decisions of the policy allowing us to compute succinct human\nreadable policies. Finally, we show experimentally that our algorithm performs\nwell and computes succinct policies on a number of POMDP instances from the\nliterature that were naturally enhanced with energy levels.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 15:41:22 GMT"}, {"version": "v2", "created": "Wed, 11 May 2016 16:26:20 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["Br\u00e1zdil", "Tom\u00e1\u0161", ""], ["Chatterjee", "Krishnendu", ""], ["Chmel\u00edk", "Martin", ""], ["Gupta", "Anchit", ""], ["Novotn\u00fd", "Petr", ""]]}, {"id": "1602.07566", "submitter": "Andrea Burattin", "authors": "Mirko Polato, Alessandro Sperduti, Andrea Burattin, Massimiliano de\n  Leoni", "title": "Time and Activity Sequence Prediction of Business Process Instances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to know in advance the trend of running process instances, with\nrespect to different features, such as the expected completion time, would\nallow business managers to timely counteract to undesired situations, in order\nto prevent losses. Therefore, the ability to accurately predict future features\nof running business process instances would be a very helpful aid when managing\nprocesses, especially under service level agreement constraints. However,\nmaking such accurate forecasts is not easy: many factors may influence the\npredicted features.\n  Many approaches have been proposed to cope with this problem but all of them\nassume that the underling process is stationary. However, in real cases this\nassumption is not always true. In this work we present new methods for\npredicting the remaining time of running cases. In particular we propose a\nmethod, assuming process stationarity, which outperforms the state-of-the-art\nand two other methods which are able to make predictions even with\nnon-stationary processes. We also describe an approach able to predict the full\nsequence of activities that a running case is going to take. All these methods\nare extensively evaluated on two real case studies.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 15:42:06 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Polato", "Mirko", ""], ["Sperduti", "Alessandro", ""], ["Burattin", "Andrea", ""], ["de Leoni", "Massimiliano", ""]]}, {"id": "1602.07637", "submitter": "Ivens Portugal", "authors": "Ivens Portugal, Paulo Alencar, Donald Cowan", "title": "A Survey on Domain-Specific Languages for Machine Learning in Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of data generated in the modern society is increasing rapidly. New\nproblems and novel approaches of data capture, storage, analysis and\nvisualization are responsible for the emergence of the Big Data research field.\nMachine Learning algorithms can be used in Big Data to make better and more\naccurate inferences. However, because of the challenges Big Data imposes, these\nalgorithms need to be adapted and optimized to specific applications. One\nimportant decision made by software engineers is the choice of the language\nthat is used in the implementation of these algorithms. Therefore, this\nliterature survey identifies and describes domain-specific languages and\nframeworks used for Machine Learning in Big Data. By doing this, software\nengineers can then make more informed choices and beginners have an overview of\nthe main languages used in this domain.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 18:58:34 GMT"}, {"version": "v2", "created": "Tue, 8 Mar 2016 19:34:37 GMT"}], "update_date": "2016-03-09", "authors_parsed": [["Portugal", "Ivens", ""], ["Alencar", "Paulo", ""], ["Cowan", "Donald", ""]]}, {"id": "1602.07714", "submitter": "Hado van Hasselt", "authors": "Hado van Hasselt and Arthur Guez and Matteo Hessel and Volodymyr Mnih\n  and David Silver", "title": "Learning values across many orders of magnitude", "comments": "Paper accepted for publication at NIPS 2016. This version includes\n  the appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most learning algorithms are not invariant to the scale of the function that\nis being approximated. We propose to adaptively normalize the targets used in\nlearning. This is useful in value-based reinforcement learning, where the\nmagnitude of appropriate value approximations can change over time when we\nupdate the policy of behavior. Our main motivation is prior work on learning to\nplay Atari games, where the rewards were all clipped to a predetermined range.\nThis clipping facilitates learning across many different games with a single\nlearning algorithm, but a clipped reward function can result in qualitatively\ndifferent behavior. Using the adaptive normalization we can remove this\ndomain-specific heuristic without diminishing overall performance.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 21:14:52 GMT"}, {"version": "v2", "created": "Tue, 16 Aug 2016 05:27:17 GMT"}], "update_date": "2016-08-17", "authors_parsed": [["van Hasselt", "Hado", ""], ["Guez", "Arthur", ""], ["Hessel", "Matteo", ""], ["Mnih", "Volodymyr", ""], ["Silver", "David", ""]]}, {"id": "1602.07721", "submitter": "Matthew Guzdial", "authors": "Matthew Guzdial and Mark Riedl", "title": "Toward Game Level Generation from Gameplay Videos", "comments": "8 pages, 10 figures, Procedural Content Generation Workshop 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms that generate computer game content require game design knowledge.\nWe present an approach to automatically learn game design knowledge for level\ndesign from gameplay videos. We further demonstrate how the acquired design\nknowledge can be used to generate sections of game levels. Our approach\ninvolves parsing video of people playing a game to detect the appearance of\npatterns of sprites and utilizing machine learning to build a probabilistic\nmodel of sprite placement. We show how rich game design information can be\nautomatically parsed from gameplay videos and represented as a set of\ngenerative probabilistic models. We use Super Mario Bros. as a proof of\nconcept. We evaluate our approach on a measure of playability and stylistic\nsimilarity to the original levels as represented in the gameplay videos.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 02:38:16 GMT"}], "update_date": "2016-02-26", "authors_parsed": [["Guzdial", "Matthew", ""], ["Riedl", "Mark", ""]]}, {"id": "1602.07764", "submitter": "Kamyar Azizzadenesheli Ph.D.", "authors": "Kamyar Azizzadenesheli, Alessandro Lazaric, Animashree Anandkumar", "title": "Reinforcement Learning of POMDPs using Spectral Methods", "comments": null, "journal-ref": "29th Annual Conference on Learning Theory, PMLR 49:193-256, 2016", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new reinforcement learning algorithm for partially observable\nMarkov decision processes (POMDP) based on spectral decomposition methods.\nWhile spectral methods have been previously employed for consistent learning of\n(passive) latent variable models such as hidden Markov models, POMDPs are more\nchallenging since the learner interacts with the environment and possibly\nchanges the future observations in the process. We devise a learning algorithm\nrunning through episodes, in each episode we employ spectral techniques to\nlearn the POMDP parameters from a trajectory generated by a fixed policy. At\nthe end of the episode, an optimization oracle returns the optimal memoryless\nplanning policy which maximizes the expected reward based on the estimated\nPOMDP model. We prove an order-optimal regret bound with respect to the optimal\nmemoryless policy and efficient scaling with respect to the dimensionality of\nobservation and action spaces.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 01:25:36 GMT"}, {"version": "v2", "created": "Sun, 29 May 2016 07:15:21 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Azizzadenesheli", "Kamyar", ""], ["Lazaric", "Alessandro", ""], ["Anandkumar", "Animashree", ""]]}, {"id": "1602.07783", "submitter": "Zhao Kang", "authors": "Zhao Kang and Qiang Cheng", "title": "Top-N Recommendation with Novel Rank Approximation", "comments": "SDM 2016. arXiv admin note: text overlap with arXiv:1601.04800", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of accurate recommender systems has been widely recognized by\nacademia and industry. However, the recommendation quality is still rather low.\nRecently, a linear sparse and low-rank representation of the user-item matrix\nhas been applied to produce Top-N recommendations. This approach uses the\nnuclear norm as a convex relaxation for the rank function and has achieved\nbetter recommendation accuracy than the state-of-the-art methods. In the past\nseveral years, solving rank minimization problems by leveraging nonconvex\nrelaxations has received increasing attention. Some empirical results\ndemonstrate that it can provide a better approximation to original problems\nthan convex relaxation. In this paper, we propose a novel rank approximation to\nenhance the performance of Top-N recommendation systems, where the\napproximation error is controllable. Experimental results on real data show\nthat the proposed rank approximation improves the Top-$N$ recommendation\naccuracy substantially.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 03:33:44 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2016 15:58:56 GMT"}], "update_date": "2016-02-29", "authors_parsed": [["Kang", "Zhao", ""], ["Cheng", "Qiang", ""]]}, {"id": "1602.07857", "submitter": "Daniele Ramazzotti", "authors": "Daniele Ramazzotti and Alex Graudenzi and Giulio Caravagna and Marco\n  Antoniotti", "title": "Modeling cumulative biological phenomena with Suppes-Bayes Causal\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1177/1176934318785167", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several diseases related to cell proliferation are characterized by the\naccumulation of somatic DNA changes, with respect to wildtype conditions.\nCancer and HIV are two common examples of such diseases, where the mutational\nload in the cancerous/viral population increases over time. In these cases,\nselective pressures are often observed along with competition, cooperation and\nparasitism among distinct cellular clones. Recently, we presented a\nmathematical framework to model these phenomena, based on a combination of\nBayesian inference and Suppes' theory of probabilistic causation, depicted in\ngraphical structures dubbed Suppes-Bayes Causal Networks (SBCNs). SBCNs are\ngenerative probabilistic graphical models that recapitulate the potential\nordering of accumulation of such DNA changes during the progression of the\ndisease. Such models can be inferred from data by exploiting likelihood-based\nmodel-selection strategies with regularization. In this paper we discuss the\ntheoretical foundations of our approach and we investigate in depth the\ninfluence on the model-selection task of: (i) the poset based on Suppes' theory\nand (ii) different regularization strategies. Furthermore, we provide an\nexample of application of our framework to HIV genetic data highlighting the\nvaluable insights provided by the inferred.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 09:23:58 GMT"}, {"version": "v2", "created": "Thu, 31 Mar 2016 22:29:11 GMT"}, {"version": "v3", "created": "Wed, 8 Mar 2017 23:40:02 GMT"}, {"version": "v4", "created": "Thu, 5 Jul 2018 02:17:49 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Ramazzotti", "Daniele", ""], ["Graudenzi", "Alex", ""], ["Caravagna", "Giulio", ""], ["Antoniotti", "Marco", ""]]}, {"id": "1602.07860", "submitter": "Yash Satsangi", "authors": "Yash Satsangi, Shimon Whiteson, Frans A. Oliehoek", "title": "Probably Approximately Correct Greedy Maximization with Efficient Bounds\n  on Information Gain for Sensor Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular function maximization finds application in a variety of real-world\ndecision-making problems. However, most existing methods, based on greedy\nmaximization, assume it is computationally feasible to evaluate F, the function\nbeing maximized. Unfortunately, in many realistic settings F is too expensive\nto evaluate exactly even once. We present probably approximately correct greedy\nmaximization, which requires access only to cheap anytime confidence bounds on\nF and uses them to prune elements. We show that, with high probability, our\nmethod returns an approximately optimal set. We propose novel, cheap confidence\nbounds for conditional entropy, which appears in many common choices of F and\nfor which it is difficult to find unbiased or bounded estimates. Finally,\nresults on a real-world dataset from a multi-camera tracking system in a\nshopping mall demonstrate that our approach performs comparably to existing\nmethods, but at a fraction of the computational cost.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 09:34:38 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 12:02:33 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Satsangi", "Yash", ""], ["Whiteson", "Shimon", ""], ["Oliehoek", "Frans A.", ""]]}, {"id": "1602.07868", "submitter": "Tim Salimans", "authors": "Tim Salimans and Diederik P. Kingma", "title": "Weight Normalization: A Simple Reparameterization to Accelerate Training\n  of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present weight normalization: a reparameterization of the weight vectors\nin a neural network that decouples the length of those weight vectors from\ntheir direction. By reparameterizing the weights in this way we improve the\nconditioning of the optimization problem and we speed up convergence of\nstochastic gradient descent. Our reparameterization is inspired by batch\nnormalization but does not introduce any dependencies between the examples in a\nminibatch. This means that our method can also be applied successfully to\nrecurrent models such as LSTMs and to noise-sensitive applications such as deep\nreinforcement learning or generative models, for which batch normalization is\nless well suited. Although our method is much simpler, it still provides much\nof the speed-up of full batch normalization. In addition, the computational\noverhead of our method is lower, permitting more optimization steps to be taken\nin the same amount of time. We demonstrate the usefulness of our method on\napplications in supervised image recognition, generative modelling, and deep\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 10:13:45 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2016 08:53:23 GMT"}, {"version": "v3", "created": "Sat, 4 Jun 2016 01:21:52 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Salimans", "Tim", ""], ["Kingma", "Diederik P.", ""]]}, {"id": "1602.07905", "submitter": "Jan Leike", "authors": "Jan Leike and Tor Lattimore and Laurent Orseau and Marcus Hutter", "title": "Thompson Sampling is Asymptotically Optimal in General Environments", "comments": "UAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss a variant of Thompson sampling for nonparametric reinforcement\nlearning in a countable classes of general stochastic environments. These\nenvironments can be non-Markov, non-ergodic, and partially observable. We show\nthat Thompson sampling learns the environment class in the sense that (1)\nasymptotically its value converges to the optimal value in mean and (2) given a\nrecoverability assumption regret is sublinear.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 12:37:21 GMT"}, {"version": "v2", "created": "Fri, 3 Jun 2016 10:59:36 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Leike", "Jan", ""], ["Lattimore", "Tor", ""], ["Orseau", "Laurent", ""], ["Hutter", "Marcus", ""]]}, {"id": "1602.07970", "submitter": "Antti Hyttinen", "authors": "Antti Hyttinen, Sergey Plis, Matti J\\\"arvisalo, Frederick Eberhardt,\n  David Danks", "title": "Causal Discovery from Subsampled Time Series Data by Constraint\n  Optimization", "comments": "International Conference on Probabilistic Graphical Models, PGM 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on causal structure estimation from time series data in\nwhich measurements are obtained at a coarser timescale than the causal\ntimescale of the underlying system. Previous work has shown that such\nsubsampling can lead to significant errors about the system's causal structure\nif not properly taken into account. In this paper, we first consider the search\nfor the system timescale causal structures that correspond to a given\nmeasurement timescale structure. We provide a constraint satisfaction procedure\nwhose computational performance is several orders of magnitude better than\nprevious approaches. We then consider finite-sample data as input, and propose\nthe first constraint optimization approach for recovering the system timescale\ncausal structure. This algorithm optimally recovers from possible conflicts due\nto statistical errors. More generally, these advances allow for a robust and\nnon-parametric estimation of system timescale causal structures from subsampled\ntime series data.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 15:52:33 GMT"}, {"version": "v2", "created": "Wed, 13 Jul 2016 08:11:35 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["Hyttinen", "Antti", ""], ["Plis", "Sergey", ""], ["J\u00e4rvisalo", "Matti", ""], ["Eberhardt", "Frederick", ""], ["Danks", "David", ""]]}, {"id": "1602.07985", "submitter": "Alexandros A. Voudouris", "authors": "Ioannis Caragiannis, George A. Krimpas, Alexandros A. Voudouris", "title": "How effective can simple ordinal peer grading be?", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinal peer grading has been proposed as a simple and scalable solution for\ncomputing reliable information about student performance in massive open online\ncourses. The idea is to outsource the grading task to the students themselves\nas follows. After the end of an exam, each student is asked to rank -- in terms\nof quality -- a bundle of exam papers by fellow students. An aggregation rule\nthen combines the individual rankings into a global one that contains all\nstudents. We define a broad class of simple aggregation rules, which we call\ntype-ordering aggregation rules, and present a theoretical framework for\nassessing their effectiveness. When statistical information about the grading\nbehaviour of students is available (in terms of a noise matrix that\ncharacterizes the grading behaviour of the average student from a student\npopulation), the framework can be used to compute the optimal rule from this\nclass with respect to a series of performance objectives that compare the\nranking returned by the aggregation rule to the underlying ground truth\nranking. For example, a natural rule known as Borda is proved to be optimal\nwhen students grade correctly. In addition, we present extensive simulations\nthat validate our theory and prove it to be extremely accurate in predicting\nthe performance of aggregation rules even when only rough information about\ngrading behaviour (i.e., an approximation of the noise matrix) is available.\nBoth in the application of our theoretical framework and in our simulations, we\nexploit data about grading behaviour of students that have been extracted from\ntwo field experiments in the University of Patras.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 16:37:57 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 16:23:56 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Caragiannis", "Ioannis", ""], ["Krimpas", "George A.", ""], ["Voudouris", "Alexandros A.", ""]]}, {"id": "1602.08017", "submitter": "Alexey Melnikov", "authors": "Adi Makmal, Alexey A. Melnikov, Vedran Dunjko, Hans J. Briegel", "title": "Meta-learning within Projective Simulation", "comments": "14 pages, 12 figures", "journal-ref": "IEEE Access 4, 2110-2122 (2016)", "doi": "10.1109/access.2016.2556579", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning models of artificial intelligence can nowadays perform very well on\na large variety of tasks. However, in practice different task environments are\nbest handled by different learning models, rather than a single, universal,\napproach. Most non-trivial models thus require the adjustment of several to\nmany learning parameters, which is often done on a case-by-case basis by an\nexternal party. Meta-learning refers to the ability of an agent to autonomously\nand dynamically adjust its own learning parameters, or meta-parameters. In this\nwork we show how projective simulation, a recently developed model of\nartificial intelligence, can naturally be extended to account for meta-learning\nin reinforcement learning settings. The projective simulation approach is based\non a random walk process over a network of clips. The suggested meta-learning\nscheme builds upon the same design and employs clip networks to monitor the\nagent's performance and to adjust its meta-parameters \"on the fly\". We\ndistinguish between \"reflexive adaptation\" and \"adaptation through learning\",\nand show the utility of both approaches. In addition, a trade-off between\nflexibility and learning-time is addressed. The extended model is examined on\nthree different kinds of reinforcement learning tasks, in which the agent has\ndifferent optimal values of the meta-parameters, and is shown to perform well,\nreaching near-optimal to optimal success rates in all of them, without ever\nneeding to manually adjust any meta-parameter.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 18:07:53 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Makmal", "Adi", ""], ["Melnikov", "Alexey A.", ""], ["Dunjko", "Vedran", ""], ["Briegel", "Hans J.", ""]]}, {"id": "1602.08159", "submitter": "Keisuke Fujii", "authors": "Keisuke Fujii and Kohei Nakajima", "title": "Harnessing disordered quantum dynamics for machine learning", "comments": "19 pages, 13 figures", "journal-ref": "Phys. Rev. Applied 8, 024030 (2017)", "doi": "10.1103/PhysRevApplied.8.024030", "report-no": null, "categories": "quant-ph cs.AI cs.LG cs.NE nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computer has an amazing potential of fast information processing.\nHowever, realisation of a digital quantum computer is still a challenging\nproblem requiring highly accurate controls and key application strategies. Here\nwe propose a novel platform, quantum reservoir computing, to solve these issues\nsuccessfully by exploiting natural quantum dynamics, which is ubiquitous in\nlaboratories nowadays, for machine learning. In this framework, nonlinear\ndynamics including classical chaos can be universally emulated in quantum\nsystems. A number of numerical experiments show that quantum systems consisting\nof at most seven qubits possess computational capabilities comparable to\nconventional recurrent neural networks of 500 nodes. This discovery opens up a\nnew paradigm for information processing with artificial intelligence powered by\nquantum physics.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 00:57:59 GMT"}, {"version": "v2", "created": "Wed, 9 Nov 2016 16:05:22 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Fujii", "Keisuke", ""], ["Nakajima", "Kohei", ""]]}, {"id": "1602.08199", "submitter": "Makoto Naruse", "authors": "Makoto Naruse, Song-Ju Kim, Masashi Aono, Martin Berthel, Aur\\'elien\n  Drezet, Serge Huant, and Hirokazu Hori", "title": "Category Theoretic Analysis of Photon-based Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision making is a vital function in this age of machine learning and\nartificial intelligence, yet its physical realization and theoretical\nfundamentals are still not completely understood. In our former study, we\ndemonstrated that single-photons can be used to make decisions in uncertain,\ndynamically changing environments. The two-armed bandit problem was\nsuccessfully solved using the dual probabilistic and particle attributes of\nsingle photons. In this study, we present a category theoretic modeling and\nanalysis of single-photon-based decision making, including a quantitative\nanalysis that is in agreement with the experimental results. A category\ntheoretic model reveals the complex interdependencies of subject matter\nentities in a simplified manner, even in dynamically changing environments. In\nparticular, the octahedral and braid structures in triangulated categories\nprovide a better understanding and quantitative metrics of the underlying\nmechanisms of a single-photon decision maker. This study provides both insight\nand a foundation for analyzing more complex and uncertain problems, to further\nmachine learning and artificial intelligence.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 05:28:42 GMT"}, {"version": "v2", "created": "Wed, 15 Jun 2016 05:02:10 GMT"}, {"version": "v3", "created": "Wed, 9 May 2018 15:49:59 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Naruse", "Makoto", ""], ["Kim", "Song-Ju", ""], ["Aono", "Masashi", ""], ["Berthel", "Martin", ""], ["Drezet", "Aur\u00e9lien", ""], ["Huant", "Serge", ""], ["Hori", "Hirokazu", ""]]}, {"id": "1602.08313", "submitter": "Esra'a Alkafaween", "authors": "Ahmad B. A. Hassanat, Esra'a Alkafaween, Nedal A. Al-Nawaiseh,\n  Mohammad A. Abbadi, Mouhammd Alkasassbeh, Mahmoud B. Alhasanat", "title": "Enhancing Genetic Algorithms using Multi Mutations", "comments": "17 pages, 11 figures, 1 table, 41 references", "journal-ref": "International Journal of Computer Science and Information Security\n  14, no. 7 (2016): 785", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mutation is one of the most important stages of the genetic algorithm because\nof its impact on the exploration of global optima, and to overcome premature\nconvergence. There are many types of mutation, and the problem lies in\nselection of the appropriate type, where the decision becomes more difficult\nand needs more trial and error. This paper investigates the use of more than\none mutation operator to enhance the performance of genetic algorithms. Novel\nmutation operators are proposed, in addition to two selection strategies for\nthe mutation operators, one of which is based on selecting the best mutation\noperator and the other randomly selects any operator. Several experiments on\nsome Travelling Salesman Problems (TSP) were conducted to evaluate the proposed\nmethods, and these were compared to the well-known exchange mutation and\nrearrangement mutation. The results show the importance of some of the proposed\nmethods, in addition to the significant enhancement of the genetic algorithm's\nperformance, particularly when using more than one mutation operator.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 13:26:24 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 20:22:59 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Hassanat", "Ahmad B. A.", ""], ["Alkafaween", "Esra'a", ""], ["Al-Nawaiseh", "Nedal A.", ""], ["Abbadi", "Mohammad A.", ""], ["Alkasassbeh", "Mouhammd", ""], ["Alhasanat", "Mahmoud B.", ""]]}, {"id": "1602.08332", "submitter": "Felix Leibfried", "authors": "Felix Leibfried and Daniel Alexander Braun", "title": "Bounded Rational Decision-Making in Feedforward Neural Networks", "comments": "Proceedings of the 32nd Conference on Uncertainty in Artificial\n  Intelligence (UAI), New York City, NY, USA, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bounded rational decision-makers transform sensory input into motor output\nunder limited computational resources. Mathematically, such decision-makers can\nbe modeled as information-theoretic channels with limited transmission rate.\nHere, we apply this formalism for the first time to multilayer feedforward\nneural networks. We derive synaptic weight update rules for two scenarios,\nwhere either each neuron is considered as a bounded rational decision-maker or\nthe network as a whole. In the update rules, bounded rationality translates\ninto information-theoretically motivated types of regularization in weight\nspace. In experiments on the MNIST benchmark classification task for\nhandwritten digits, we show that such information-theoretic regularization\nsuccessfully prevents overfitting across different architectures and attains\nresults that are competitive with other recent techniques like dropout,\ndropconnect and Bayes by backprop, for both ordinary and convolutional neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 14:15:03 GMT"}, {"version": "v2", "created": "Mon, 23 May 2016 15:51:07 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Leibfried", "Felix", ""], ["Braun", "Daniel Alexander", ""]]}, {"id": "1602.08350", "submitter": "Patrick O. Glauner", "authors": "Patrick O. Glauner, Andre Boechat, Lautaro Dolberg, Radu State, Franck\n  Bettinger, Yves Rangoni, Diogo Duarte", "title": "Large-Scale Detection of Non-Technical Losses in Imbalanced Data Sets", "comments": "Proceedings of the Seventh IEEE Conference on Innovative Smart Grid\n  Technologies (ISGT 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-technical losses (NTL) such as electricity theft cause significant harm\nto our economies, as in some countries they may range up to 40% of the total\nelectricity distributed. Detecting NTLs requires costly on-site inspections.\nAccurate prediction of NTLs for customers using machine learning is therefore\ncrucial. To date, related research largely ignore that the two classes of\nregular and non-regular customers are highly imbalanced, that NTL proportions\nmay change and mostly consider small data sets, often not allowing to deploy\nthe results in production. In this paper, we present a comprehensive approach\nto assess three NTL detection models for different NTL proportions in large\nreal world data sets of 100Ks of customers: Boolean rules, fuzzy logic and\nSupport Vector Machine. This work has resulted in appreciable results that are\nabout to be deployed in a leading industry solution. We believe that the\nconsiderations and observations made in this contribution are necessary for\nfuture smart meter research in order to report their effectiveness on\nimbalanced and large real world data sets.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 14:49:29 GMT"}, {"version": "v2", "created": "Tue, 25 Jul 2017 04:44:12 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Glauner", "Patrick O.", ""], ["Boechat", "Andre", ""], ["Dolberg", "Lautaro", ""], ["State", "Radu", ""], ["Bettinger", "Franck", ""], ["Rangoni", "Yves", ""], ["Duarte", "Diogo", ""]]}, {"id": "1602.08447", "submitter": "Le Hoang Son", "authors": "Mumtaz Ali, Nguyen Van Minh, Le Hoang Son", "title": "A Neutrosophic Recommender System for Medical Diagnosis Based on\n  Algebraic Neutrosophic Measures", "comments": "Keywords: Medical diagnosis, neutrosophic set, neutrosophic\n  recommender system, non-linear regression model", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neutrosophic set has the ability to handle uncertain, incomplete,\ninconsistent, indeterminate information in a more accurate way. In this paper,\nwe proposed a neutrosophic recommender system to predict the diseases based on\nneutrosophic set which includes single-criterion neutrosophic recommender\nsystem (SC-NRS) and multi-criterion neutrosophic recommender system (MC-NRS).\nFurther, we investigated some algebraic operations of neutrosophic recommender\nsystem such as union, complement, intersection, probabilistic sum, bold sum,\nbold intersection, bounded difference, symmetric difference, convex linear sum\nof min and max operators, Cartesian product, associativity, commutativity and\ndistributive. Based on these operations, we studied the algebraic structures\nsuch as lattices, Kleen algebra, de Morgan algebra, Brouwerian algebra, BCK\nalgebra, Stone algebra and MV algebra. In addition, we introduced several types\nof similarity measures based on these algebraic operations and studied some of\ntheir theoretic properties. Moreover, we accomplished a prediction formula\nusing the proposed algebraic similarity measure. We also proposed a new\nalgorithm for medical diagnosis based on neutrosophic recommender system.\nFinally to check the validity of the proposed methodology, we made experiments\non the datasets Heart, RHC, Breast cancer, Diabetes and DMD. At the end, we\npresented the MSE and computational time by comparing the proposed algorithm\nwith the relevant ones such as ICSM, DSM, CARE, CFMD, as well as other variants\nnamely Variant 67, Variant 69, and Varian 71 both in tabular and graphical form\nto analyze the efficiency and accuracy. Finally we analyzed the strength of all\n8 algorithms by ANOVA statistical tool.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 03:20:00 GMT"}], "update_date": "2016-02-29", "authors_parsed": [["Ali", "Mumtaz", ""], ["Van Minh", "Nguyen", ""], ["Son", "Le Hoang", ""]]}, {"id": "1602.08571", "submitter": "Haoxi Zhang", "authors": "Haoxi Zhang, Cesar Sanin, Edward Szczerbicki", "title": "Towards Neural Knowledge DNA", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the Neural Knowledge DNA, a framework that tailors\nthe ideas underlying the success of neural networks to the scope of knowledge\nrepresentation. Knowledge representation is a fundamental field that dedicate\nto representing information about the world in a form that computer systems can\nutilize to solve complex tasks. The proposed Neural Knowledge DNA is designed\nto support discovering, storing, reusing, improving, and sharing knowledge\namong machines and organisation. It is constructed in a similar fashion of how\nDNA formed: built up by four essential elements. As the DNA produces\nphenotypes, the Neural Knowledge DNA carries information and knowledge via its\nfour essential elements, namely, Networks, Experiences, States, and Actions.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2016 08:45:35 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Zhang", "Haoxi", ""], ["Sanin", "Cesar", ""], ["Szczerbicki", "Edward", ""]]}, {"id": "1602.08610", "submitter": "Hongyu Yang", "authors": "Hongyu Yang, Cynthia Rudin, Margo Seltzer", "title": "Scalable Bayesian Rule Lists", "comments": "31 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present an algorithm for building probabilistic rule lists that is two\norders of magnitude faster than previous work. Rule list algorithms are\ncompetitors for decision tree algorithms. They are associative classifiers, in\nthat they are built from pre-mined association rules. They have a logical\nstructure that is a sequence of IF-THEN rules, identical to a decision list or\none-sided decision tree. Instead of using greedy splitting and pruning like\ndecision tree algorithms, we fully optimize over rule lists, striking a\npractical balance between accuracy, interpretability, and computational speed.\nThe algorithm presented here uses a mixture of theoretical bounds (tight enough\nto have practical implications as a screening or bounding procedure),\ncomputational reuse, and highly tuned language libraries to achieve\ncomputational efficiency. Currently, for many practical problems, this method\nachieves better accuracy and sparsity than decision trees; further, in many\ncases, the computational time is practical and often less than that of decision\ntrees. The result is a probabilistic classifier (which estimates P(y = 1|x) for\neach x) that optimizes the posterior of a Bayesian hierarchical model over rule\nlists.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2016 16:29:24 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 07:01:26 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Yang", "Hongyu", ""], ["Rudin", "Cynthia", ""], ["Seltzer", "Margo", ""]]}, {"id": "1602.08671", "submitter": "Greg Yang", "authors": "Greg Yang", "title": "Lie Access Neural Turing Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the recent trend in explicit neural memory structures, we present a\nnew design of an external memory, wherein memories are stored in an Euclidean\nkey space $\\mathbb R^n$. An LSTM controller performs read and write via\nspecialized read and write heads. It can move a head by either providing a new\naddress in the key space (aka random access) or moving from its previous\nposition via a Lie group action (aka Lie access). In this way, the \"L\" and \"R\"\ninstructions of a traditional Turing Machine are generalized to arbitrary\nelements of a fixed Lie group action. For this reason, we name this new model\nthe Lie Access Neural Turing Machine, or LANTM.\n  We tested two different configurations of LANTM against an LSTM baseline in\nseveral basic experiments. We found the right configuration of LANTM to\noutperform the baseline in all of our experiments. In particular, we trained\nLANTM on addition of $k$-digit numbers for $2 \\le k \\le 16$, but it was able to\ngeneralize almost perfectly to $17 \\le k \\le 32$, all with the number of\nparameters 2 orders of magnitude below the LSTM baseline.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2016 04:55:19 GMT"}, {"version": "v2", "created": "Tue, 23 Aug 2016 01:23:46 GMT"}, {"version": "v3", "created": "Tue, 6 Sep 2016 14:42:56 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Yang", "Greg", ""]]}, {"id": "1602.08771", "submitter": "Adam White", "authors": "Adam White, Martha White", "title": "Investigating practical linear temporal difference learning", "comments": "Autonomous Agents and Multi-agent Systems, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy reinforcement learning has many applications including: learning\nfrom demonstration, learning multiple goal seeking policies in parallel, and\nrepresenting predictive knowledge. Recently there has been an proliferation of\nnew policy-evaluation algorithms that fill a longstanding algorithmic void in\nreinforcement learning: combining robustness to off-policy sampling, function\napproximation, linear complexity, and temporal difference (TD) updates. This\npaper contains two main contributions. First, we derive two new hybrid TD\npolicy-evaluation algorithms, which fill a gap in this collection of\nalgorithms. Second, we perform an empirical comparison to elicit which of these\nnew linear TD methods should be preferred in different situations, and make\nconcrete suggestions about practical use.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2016 21:23:54 GMT"}, {"version": "v2", "created": "Thu, 31 Mar 2016 01:10:08 GMT"}], "update_date": "2016-04-01", "authors_parsed": [["White", "Adam", ""], ["White", "Martha", ""]]}, {"id": "1602.08903", "submitter": "Juan Carlos Nieves", "authors": "Mauricio Osorio, Juan Carlos Nieves", "title": "Range-based argumentation semantics as 2-valued models", "comments": "16 pages, to appear in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizations of semi-stable and stage extensions in terms of 2-valued\nlogical models are presented. To this end, the so-called GL-supported and\nGL-stage models are defined. These two classes of logical models are logic\nprogramming counterparts of the notion of range which is an established concept\nin argumentation semantics.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 10:55:12 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Osorio", "Mauricio", ""], ["Nieves", "Juan Carlos", ""]]}, {"id": "1602.09076", "submitter": "Paolo Campigotto", "authors": "Paolo Campigotto, Christian Rudloff, Maximilian Leodolter and Dietmar\n  Bauer", "title": "Personalized and situation-aware multimodal route recommendations: the\n  FAVOUR algorithm", "comments": "12 pages, 6 figures, 1 table. Submitted to IEEE Transactions on\n  Intelligent Transportation Systems journal for publication", "journal-ref": null, "doi": "10.1109/TITS.2016.2565643", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Route choice in multimodal networks shows a considerable variation between\ndifferent individuals as well as the current situational context.\nPersonalization of recommendation algorithms are already common in many areas,\ne.g., online retail. However, most online routing applications still provide\nshortest distance or shortest travel-time routes only, neglecting individual\npreferences as well as the current situation. Both aspects are of particular\nimportance in a multimodal setting as attractivity of some transportation modes\nsuch as biking crucially depends on personal characteristics and exogenous\nfactors like the weather. This paper introduces the FAVourite rOUte\nRecommendation (FAVOUR) approach to provide personalized, situation-aware route\nproposals based on three steps: first, at the initialization stage, the user\nprovides limited information (home location, work place, mobility options,\nsociodemographics) used to select one out of a small number of initial\nprofiles. Second, based on this information, a stated preference survey is\ndesigned in order to sharpen the profile. In this step a mass preference prior\nis used to encode the prior knowledge on preferences from the class identified\nin step one. And third, subsequently the profile is continuously updated during\nusage of the routing services. The last two steps use Bayesian learning\ntechniques in order to incorporate information from all contributing\nindividuals. The FAVOUR approach is presented in detail and tested on a small\nnumber of survey participants. The experimental results on this real-world\ndataset show that FAVOUR generates better-quality recommendations w.r.t.\nalternative learning algorithms from the literature. In particular the\ndefinition of the mass preference prior for initialization of step two is shown\nto provide better predictions than a number of alternatives from the\nliterature.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 18:16:12 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Campigotto", "Paolo", ""], ["Rudloff", "Christian", ""], ["Leodolter", "Maximilian", ""], ["Bauer", "Dietmar", ""]]}, {"id": "1602.09118", "submitter": "Joshua Achiam", "authors": "Joshua Achiam", "title": "Easy Monotonic Policy Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem in reinforcement learning for control with general function\napproximators (such as deep neural networks and other nonlinear functions) is\nthat, for many algorithms employed in practice, updates to the policy or\n$Q$-function may fail to improve performance---or worse, actually cause the\npolicy performance to degrade. Prior work has addressed this for policy\niteration by deriving tight policy improvement bounds; by optimizing the lower\nbound on policy improvement, a better policy is guaranteed. However, existing\napproaches suffer from bounds that are hard to optimize in practice because\nthey include sup norm terms which cannot be efficiently estimated or\ndifferentiated. In this work, we derive a better policy improvement bound where\nthe sup norm of the policy divergence has been replaced with an average\ndivergence; this leads to an algorithm, Easy Monotonic Policy Iteration, that\ngenerates sequences of policies with guaranteed non-decreasing returns and is\neasy to implement in a sample-based framework.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 19:59:16 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Achiam", "Joshua", ""]]}]