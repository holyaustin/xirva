[{"id": "1007.0412", "submitter": "Dimple Juneja Dr.", "authors": "Ujwalla Gawande, Mukesh Zaveri, Avichal Kapur", "title": "Improving Iris Recognition Accuracy By Score Based Fusion Method", "comments": "http://ijict.org/index.php/ijoat/article/view/improving-iris-recognition", "journal-ref": "International Journal of Advancements in Technology, Vol 1, No 1\n  (2010)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Iris recognition technology, used to identify individuals by photographing\nthe iris of their eye, has become popular in security applications because of\nits ease of use, accuracy, and safety in controlling access to high-security\nareas. Fusion of multiple algorithms for biometric verification performance\nimprovement has received considerable attention. The proposed method combines\nthe zero-crossing 1 D wavelet Euler number, and genetic algorithm based for\nfeature extraction. The output from these three algorithms is normalized and\ntheir score are fused to decide whether the user is genuine or imposter. This\nnew strategies is discussed in this paper, in order to compute a multimodal\ncombined score.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2010 09:24:37 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Gawande", "Ujwalla", ""], ["Zaveri", "Mukesh", ""], ["Kapur", "Avichal", ""]]}, {"id": "1007.0546", "submitter": "Pouyan  Rafiei Fard", "authors": "Keyvan Yahya, Pouyan Rafiei Fard", "title": "Computational Model of Music Sight Reading: A Reinforcement Learning\n  Approach", "comments": "This paper is withdrawn by author due to incomplete justification of\n  the model", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the Music Sight Reading process has been studied from the cognitive\npsychology view points, but the computational learning methods like the\nReinforcement Learning have not yet been used to modeling of such processes. In\nthis paper, with regards to essential properties of our specific problem, we\nconsider the value function concept and will indicate that the optimum policy\ncan be obtained by the method we offer without to be getting involved with\ncomputing of the complex value functions. Also, we will offer a normative\nbehavioral model for the interaction of the agent with the musical pitch\nenvironment and by using a slightly different version of Partially observable\nMarkov decision processes we will show that our method helps for faster\nlearning of state-action pairs in our implemented agents.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2010 12:18:56 GMT"}, {"version": "v2", "created": "Thu, 26 Aug 2010 19:32:16 GMT"}, {"version": "v3", "created": "Sat, 28 Aug 2010 10:57:19 GMT"}, {"version": "v4", "created": "Sat, 13 Jul 2013 22:59:26 GMT"}], "update_date": "2013-07-16", "authors_parsed": [["Yahya", "Keyvan", ""], ["Fard", "Pouyan Rafiei", ""]]}, {"id": "1007.0602", "submitter": "Toby Walsh", "authors": "George Katsirelos and Nina Narodytska and Toby Walsh", "title": "On The Complexity and Completeness of Static Constraints for Breaking\n  Row and Column Symmetry", "comments": "To appear in the Proceedings of the 16th International Conference on\n  Principles and Practice of Constraint Programming (CP 2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a common type of symmetry where we have a matrix of decision\nvariables with interchangeable rows and columns. A simple and efficient method\nto deal with such row and column symmetry is to post symmetry breaking\nconstraints like DOUBLELEX and SNAKELEX. We provide a number of positive and\nnegative results on posting such symmetry breaking constraints. On the positive\nside, we prove that we can compute in polynomial time a unique representative\nof an equivalence class in a matrix model with row and column symmetry if the\nnumber of rows (or of columns) is bounded and in a number of other special\ncases. On the negative side, we show that whilst DOUBLELEX and SNAKELEX are\noften effective in practice, they can leave a large number of symmetric\nsolutions in the worst case. In addition, we prove that propagating DOUBLELEX\ncompletely is NP-hard. Finally we consider how to break row, column and value\nsymmetry, correcting a result in the literature about the safeness of combining\ndifferent symmetry breaking constraints. We end with the first experimental\nstudy on how much symmetry is left by DOUBLELEX and SNAKELEX on some benchmark\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2010 02:15:00 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Katsirelos", "George", ""], ["Narodytska", "Nina", ""], ["Walsh", "Toby", ""]]}, {"id": "1007.0603", "submitter": "Toby Walsh", "authors": "Christian Bessiere and George Katsirelos and Nina Narodytska and\n  Claude-Guy Quimper and Toby Walsh", "title": "Decomposition of the NVALUE constraint", "comments": "To appear in the Proceedings of the 16th International Conference on\n  Principles and Practice of Constraint Programming 2010 (CP 2010). An earlier\n  version appeared in the Proceedings of the Eighth International Workshop on\n  Constraint Modelling and Reformulation, held alongside the 15th International\n  Conference on Principles and Practice of Constraint Programming (CP 2009)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study decompositions of the global NVALUE constraint. Our main\ncontribution is theoretical: we show that there are propagators for global\nconstraints like NVALUE which decomposition can simulate with the same time\ncomplexity but with a much greater space complexity. This suggests that the\nbenefit of a global propagator may often not be in saving time but in saving\nspace. Our other theoretical contribution is to show for the first time that\nrange consistency can be enforced on NVALUE with the same worst-case time\ncomplexity as bound consistency. Finally, the decompositions we study are\nreadily encoded as linear inequalities. We are therefore able to use them in\ninteger linear programs.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2010 02:27:09 GMT"}], "update_date": "2010-07-06", "authors_parsed": [["Bessiere", "Christian", ""], ["Katsirelos", "George", ""], ["Narodytska", "Nina", ""], ["Quimper", "Claude-Guy", ""], ["Walsh", "Toby", ""]]}, {"id": "1007.0604", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Symmetry within and between solutions", "comments": "Keynote talk to appear in the Proceedings of the Eleventh Pacific Rim\n  International Conference on Artificial Intelligence (PRICAI-10)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symmetry can be used to help solve many problems. For instance, Einstein's\nfamous 1905 paper (\"On the Electrodynamics of Moving Bodies\") uses symmetry to\nhelp derive the laws of special relativity. In artificial intelligence,\nsymmetry has played an important role in both problem representation and\nreasoning. I describe recent work on using symmetry to help solve constraint\nsatisfaction problems. Symmetries occur within individual solutions of problems\nas well as between different solutions of the same problem. Symmetry can also\nbe applied to the constraints in a problem to give new symmetric constraints.\nReasoning about symmetry can speed up problem solving, and has led to the\ndiscovery of new results in both graph and number theory.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2010 02:36:35 GMT"}], "update_date": "2010-07-06", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "1007.0614", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Online Cake Cutting", "comments": "To appear in Proceedings of the Third International Workshop on\n  Computational Social Choice (COMSOC-2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an online form of the cake cutting problem. This models situations\nwhere players arrive and depart during the process of dividing a resource. We\nshow that well known fair division procedures like cut-and-choose and the\nDubins-Spanier moving knife procedure can be adapted to apply to such online\nproblems. We propose some desirable properties that online cake cutting\nprocedures might possess like online forms of proportionality and\nenvy-freeness, and identify which properties are in fact possessed by the\ndifferent online cake procedures.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2010 04:27:03 GMT"}], "update_date": "2010-07-06", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "1007.0637", "submitter": "Mirco Gelain", "authors": "Mirco Gelain, Maria Silvia Pini, Francesca RossI, Kristen Brent\n  Venable, Toby Walsh", "title": "Local search for stable marriage problems with ties and incomplete lists", "comments": "12 pages, Proc. PRICAI 2010 (11th Pacific Rim International\n  Conference on Artificial Intelligence), Byoung-Tak Zhang and Mehmet A. Orgun\n  eds., Springer LNAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stable marriage problem has a wide variety of practical applications,\nranging from matching resident doctors to hospitals, to matching students to\nschools, or more generally to any two-sided market. We consider a useful\nvariation of the stable marriage problem, where the men and women express their\npreferences using a preference list with ties over a subset of the members of\nthe other sex. Matchings are permitted only with people who appear in these\npreference lists. In this setting, we study the problem of finding a stable\nmatching that marries as many people as possible. Stability is an envy-free\nnotion: no man and woman who are not married to each other would both prefer\neach other to their partners or to being single. This problem is NP-hard. We\ntackle this problem using local search, exploiting properties of the problem to\nreduce the size of the neighborhood and to make local moves efficiently.\nExperimental results show that this approach is able to solve large problems,\nquickly returning stable matchings of large and often optimal size.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2010 08:08:00 GMT"}], "update_date": "2010-07-06", "authors_parsed": [["Gelain", "Mirco", ""], ["Pini", "Maria Silvia", ""], ["RossI", "Francesca", ""], ["Venable", "Kristen Brent", ""], ["Walsh", "Toby", ""]]}, {"id": "1007.0690", "submitter": "Avinash Achar", "authors": "Avinash Achar, Srivatsan Laxman and P. S. Sastry", "title": "A unified view of Automata-based algorithms for Frequent Episode\n  Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequent Episode Discovery framework is a popular framework in Temporal Data\nMining with many applications. Over the years many different notions of\nfrequencies of episodes have been proposed along with different algorithms for\nepisode discovery. In this paper we present a unified view of all such\nfrequency counting algorithms. We present a generic algorithm such that all\ncurrent algorithms are special cases of it. This unified view allows one to\ngain insights into different frequencies and we present quantitative\nrelationships among different frequencies. Our unified view also helps in\nobtaining correctness proofs for various algorithms as we show here. We also\npoint out how this unified view helps us to consider generalization of the\nalgorithm so that they can discover episodes with general partial orders.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2010 14:35:20 GMT"}], "update_date": "2010-07-06", "authors_parsed": [["Achar", "Avinash", ""], ["Laxman", "Srivatsan", ""], ["Sastry", "P. S.", ""]]}, {"id": "1007.0728", "submitter": "Robert Burger PhD", "authors": "John Robert Burger", "title": "Artificial Learning in Artificial Memories", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory refinements are designed below to detect those sequences of actions\nthat have been repeated a given number n. Subsequently such sequences are\npermitted to run without CPU involvement. This mimics human learning. Actions\nare rehearsed and once learned, they are performed automatically without\nconscious involvement.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2010 17:22:06 GMT"}, {"version": "v2", "created": "Sun, 5 Sep 2010 21:06:55 GMT"}], "update_date": "2010-09-07", "authors_parsed": [["Burger", "John Robert", ""]]}, {"id": "1007.0776", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Is Computational Complexity a Barrier to Manipulation?", "comments": "To appear in Proceedings of 11th International Workshop on\n  Computational Logic in Multi-Agent Systems (CLIMA XI 2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When agents are acting together, they may need a simple mechanism to decide\non joint actions. One possibility is to have the agents express their\npreferences in the form of a ballot and use a voting rule to decide the winning\naction(s). Unfortunately, agents may try to manipulate such an election by\nmisreporting their preferences. Fortunately, it has been shown that it is\nNP-hard to compute how to manipulate a number of different voting rules.\nHowever, NP-hardness only bounds the worst-case complexity. Recent theoretical\nresults suggest that manipulation may often be easy in practice. To address\nthis issue, I suggest studying empirically if computational complexity is in\npractice a barrier to manipulation. The basic tool used in my investigations is\nthe identification of computational \"phase transitions\". Such an approach has\nbeen fruitful in identifying hard instances of propositional satisfiability and\nother NP-hard problems. I show that phase transition behaviour gives insight\ninto the hardness of manipulating voting rules, increasing concern that\ncomputational complexity is indeed any sort of barrier. Finally, I look at the\nproblem of computing manipulation of other, related problems like stable\nmarriage and tournament problems.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2010 21:47:29 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "1007.0859", "submitter": "Mirco Gelain", "authors": "M. Gelain and M. S. Pini and F. Rossi and K. B. Venable and T. Walsh", "title": "Local search for stable marriage problems", "comments": "12 pages, Proc. COMSOC 2010 (Third International Workshop on\n  Computational Social Choice)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stable marriage (SM) problem has a wide variety of practical\napplications, ranging from matching resident doctors to hospitals, to matching\nstudents to schools, or more generally to any two-sided market. In the\nclassical formulation, n men and n women express their preferences (via a\nstrict total order) over the members of the other sex. Solving a SM problem\nmeans finding a stable marriage where stability is an envy-free notion: no man\nand woman who are not married to each other would both prefer each other to\ntheir partners or to being single. We consider both the classical stable\nmarriage problem and one of its useful variations (denoted SMTI) where the men\nand women express their preferences in the form of an incomplete preference\nlist with ties over a subset of the members of the other sex. Matchings are\npermitted only with people who appear in these lists, an we try to find a\nstable matching that marries as many people as possible. Whilst the SM problem\nis polynomial to solve, the SMTI problem is NP-hard. We propose to tackle both\nproblems via a local search approach, which exploits properties of the problems\nto reduce the size of the neighborhood and to make local moves efficiently. We\nevaluate empirically our algorithm for SM problems by measuring its runtime\nbehaviour and its ability to sample the lattice of all possible stable\nmarriages. We evaluate our algorithm for SMTI problems in terms of both its\nruntime behaviour and its ability to find a maximum cardinality stable\nmarriage.For SM problems, the number of steps of our algorithm grows only as\nO(nlog(n)), and that it samples very well the set of all stable marriages. It\nis thus a fair and efficient approach to generate stable marriages.Furthermore,\nour approach for SMTI problems is able to solve large problems, quickly\nreturning stable matchings of large and often optimal size despite the\nNP-hardness of this problem.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2010 10:52:44 GMT"}], "update_date": "2010-07-07", "authors_parsed": [["Gelain", "M.", ""], ["Pini", "M. S.", ""], ["Rossi", "F.", ""], ["Venable", "K. B.", ""], ["Walsh", "T.", ""]]}, {"id": "1007.0940", "submitter": "Pedro Alejandro Ortega", "authors": "Pedro A. Ortega, Daniel A. Braun", "title": "An axiomatic formalization of bounded rationality based on a\n  utility-information equivalence", "comments": "22 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classic decision-theory is based on the maximum expected utility (MEU)\nprinciple, but crucially ignores the resource costs incurred when determining\noptimal decisions. Here we propose an axiomatic framework for bounded\ndecision-making that considers resource costs. Agents are formalized as\nprobability measures over input-output streams. We postulate that any such\nprobability measure can be assigned a corresponding conjugate utility function\nbased on three axioms: utilities should be real-valued, additive and monotonic\nmappings of probabilities. We show that these axioms enforce a unique\nconversion law between utility and probability (and thereby, information).\nMoreover, we show that this relation can be characterized as a variational\nprinciple: given a utility function, its conjugate probability measure\nmaximizes a free utility functional. Transformations of probability measures\ncan then be formalized as a change in free utility due to the addition of new\nconstraints expressed by a target utility function. Accordingly, one obtains a\ncriterion to choose a probability measure that trades off the maximization of a\ntarget utility function and the cost of the deviation from a reference\ndistribution. We show that optimal control, adaptive estimation and adaptive\ncontrol problems can be solved this way in a resource-efficient way. When\nresource costs are ignored, the MEU principle is recovered. Our formalization\nmight thus provide a principled approach to bounded rationality that\nestablishes a close link to information theory.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2010 16:18:51 GMT"}], "update_date": "2010-07-09", "authors_parsed": [["Ortega", "Pedro A.", ""], ["Braun", "Daniel A.", ""]]}, {"id": "1007.1024", "submitter": "EPTCS", "authors": "Andreas K\\\"ubler (Symbolic Computation Group, Wilhelm Schickard\n  Institute for Computer Science, Universit\\\"at T\\\"ubingen, Germany), Christoph\n  Zengler (Symbolic Computation Group, Wilhelm Schickard Institute for Computer\n  Science, Universit\\\"at T\\\"ubingen, Germany), Wolfgang K\\\"uchlin (Symbolic\n  Computation Group, Wilhelm Schickard Institute for Computer Science,\n  Universit\\\"at T\\\"ubingen, Germany)", "title": "Model Counting in Product Configuration", "comments": "In Proceedings LoCoCo 2010, arXiv:1007.0831", "journal-ref": "EPTCS 29, 2010, pp. 44-53", "doi": "10.4204/EPTCS.29.5", "report-no": null, "categories": "cs.AI cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe how to use propositional model counting for a quantitative\nanalysis of product configuration data. Our approach computes valuable meta\ninformation such as the total number of valid configurations or the relative\nfrequency of components. This information can be used to assess the severity of\ndocumentation errors or to measure documentation quality. As an application\nexample we show how we apply these methods to product documentation formulas of\nthe Mercedes-Benz line of vehicles. In order to process these large formulas we\ndeveloped and implemented a new model counter for non-CNF formulas. Our model\ncounter can process formulas, whose CNF representations could not be processed\nup till now.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2010 00:13:11 GMT"}], "update_date": "2010-07-08", "authors_parsed": [["K\u00fcbler", "Andreas", "", "Symbolic Computation Group, Wilhelm Schickard\n  Institute for Computer Science, Universit\u00e4t T\u00fcbingen, Germany"], ["Zengler", "Christoph", "", "Symbolic Computation Group, Wilhelm Schickard Institute for Computer\n  Science, Universit\u00e4t T\u00fcbingen, Germany"], ["K\u00fcchlin", "Wolfgang", "", "Symbolic\n  Computation Group, Wilhelm Schickard Institute for Computer Science,\n  Universit\u00e4t T\u00fcbingen, Germany"]]}, {"id": "1007.1268", "submitter": "Huy Nguyen", "authors": "Huy Nguyen and Deokjai Choi", "title": "Application of Data Mining to Network Intrusion Detection: Classifier\n  Selection Model", "comments": "Presented at The 11th Asia-Pacific Network Operations and Management\n  Symposium (APNOMS 2008)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As network attacks have increased in number and severity over the past few\nyears, intrusion detection system (IDS) is increasingly becoming a critical\ncomponent to secure the network. Due to large volumes of security audit data as\nwell as complex and dynamic properties of intrusion behaviors, optimizing\nperformance of IDS becomes an important open problem that is receiving more and\nmore attention from the research community. The uncertainty to explore if\ncertain algorithms perform better for certain attack classes constitutes the\nmotivation for the reported herein. In this paper, we evaluate performance of a\ncomprehensive set of classifier algorithms using KDD99 dataset. Based on\nevaluation results, best algorithms for each attack category is chosen and two\nclassifier algorithm selection models are proposed. The simulation result\ncomparison indicates that noticeable performance improvement and real-time\nintrusion detection can be achieved as we apply the proposed models to detect\ndifferent kinds of network attacks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2010 00:23:40 GMT"}], "update_date": "2010-07-09", "authors_parsed": [["Nguyen", "Huy", ""], ["Choi", "Deokjai", ""]]}, {"id": "1007.1270", "submitter": "Huy Nguyen", "authors": "Huy Nguyen, Tam Van Nguyen, and Deokjai Choi", "title": "How to Maximize User Satisfaction Degree in Multi-service IP Networks", "comments": "Presented at The First Asia Conference on Intelligent Information and\n  Database Systems April, 1-3, 2009, Dong Hoi City, Quang Binh province,\n  Vietnam", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandwidth allocation is a fundamental problem in communication networks. With\ncurrent network moving towards the Future Internet model, the problem is\nfurther intensified as network traffic demanding far from exceeds network\nbandwidth capability. Maintaining a certain user satisfaction degree therefore\nbecomes a challenge research topic. In this paper, we deal with the problem by\nproposing BASMIN, a novel bandwidth allocation scheme that aims to maximize\nnetwork user's happiness. We also defined a new metric for evaluating network\nuser satisfaction degree: network worth. A three-step evaluation process is\nthen conducted to compare BASMIN efficiency with other three popular bandwidth\nallocation schemes. Throughout the tests, we experienced BASMIN's advantages\nover the others; we even found out that one of the most widely used bandwidth\nallocation schemes, in fact, is not effective at all.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2010 00:47:16 GMT"}], "update_date": "2010-07-09", "authors_parsed": [["Nguyen", "Huy", ""], ["Van Nguyen", "Tam", ""], ["Choi", "Deokjai", ""]]}, {"id": "1007.1766", "submitter": "Tshilidzi Marwala", "authors": "Gidudu Anthony, Hulley Gregg, and Marwala Tshilidzi", "title": "An svm multiclassifier approach to land cover mapping", "comments": "ASPRS 2008 Annual Conference Portland, Oregon. April 28 - May 2, 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From the advent of the application of satellite imagery to land cover\nmapping, one of the growing areas of research interest has been in the area of\nimage classification. Image classifiers are algorithms used to extract land\ncover information from satellite imagery. Most of the initial research has\nfocussed on the development and application of algorithms to better existing\nand emerging classifiers. In this paper, a paradigm shift is proposed whereby a\ncommittee of classifiers is used to determine the final classification output.\nTwo of the key components of an ensemble system are that there should be\ndiversity among the classifiers and that there should be a mechanism through\nwhich the results are combined. In this paper, the members of the ensemble\nsystem include: Linear SVM, Gaussian SVM and Quadratic SVM. The final output\nwas determined through a simple majority vote of the individual classifiers.\nFrom the results obtained it was observed that the final derived map generated\nby an ensemble system can potentially improve on the results derived from the\nindividual classifiers making up the ensemble system. The ensemble system\nclassification accuracy was, in this case, better than the linear and quadratic\nSVM result. It was however less than that of the RBF SVM. Areas for further\nresearch could focus on improving the diversity of the ensemble system used in\nthis research.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2010 09:36:07 GMT"}], "update_date": "2010-07-13", "authors_parsed": [["Anthony", "Gidudu", ""], ["Gregg", "Hulley", ""], ["Tshilidzi", "Marwala", ""]]}, {"id": "1007.2364", "submitter": "Loris Bozzato", "authors": "Loris Bozzato and Mauro Ferrari (DICOM - Universit\\`a degli Studi\n  dell'Insubria)", "title": "A Note on Semantic Web Services Specification and Composition in\n  Constructive Description Logics", "comments": "15 pages, 2 figures. Part of this work will appear as a position\n  paper in Proceedings of 4th Int. Conf. on Web Reasoning and Rule Systems (RR\n  2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of the Semantic Web is to annotate Web content and services with\ncomputer interpretable descriptions with the aim to automatize many tasks\ncurrently performed by human users. In the context of Web services, one of the\nmost interesting tasks is their composition. In this paper we formalize this\nproblem in the framework of a constructive description logic. In particular we\npropose a declarative service specification language and a calculus for service\ncomposition. We show by means of an example how this calculus can be used to\ndefine composed Web services and we discuss the problem of automatic service\nsynthesis.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2010 16:02:32 GMT"}], "update_date": "2010-07-15", "authors_parsed": [["Bozzato", "Loris", "", "DICOM - Universit\u00e0 degli Studi\n  dell'Insubria"], ["Ferrari", "Mauro", "", "DICOM - Universit\u00e0 degli Studi\n  dell'Insubria"]]}, {"id": "1007.2449", "submitter": "Kamran Karimi", "authors": "Kamran Karimi", "title": "A Brief Introduction to Temporality and Causality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causality is a non-obvious concept that is often considered to be related to\ntemporality. In this paper we present a number of past and present approaches\nto the definition of temporality and causality from philosophical, physical,\nand computational points of view. We note that time is an important ingredient\nin many relationships and phenomena. The topic is then divided into the two\nmain areas of temporal discovery, which is concerned with finding relations\nthat are stretched over time, and causal discovery, where a claim is made as to\nthe causal influence of certain events on others. We present a number of\ncomputational tools used for attempting to automatically discover temporal and\ncausal relations in data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2010 22:41:30 GMT"}], "update_date": "2010-07-16", "authors_parsed": [["Karimi", "Kamran", ""]]}, {"id": "1007.2534", "submitter": "Xavier Mora", "authors": "Rosa Camps, Xavier Mora, Laia Saumell", "title": "A general method for deciding about logically constrained issues", "comments": "Several substantial improvements have been included. The outline\n  structure of the article has also undergone some changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general method is given for revising degrees of belief and arriving at\nconsistent decisions about a system of logically constrained issues. In\ncontrast to other works about belief revision, here the constraints are assumed\nto be fixed. The method has two variants, dual of each other, whose revised\ndegrees of belief are respectively above and below the original ones. The upper\n[resp. lower] revised degrees of belief are uniquely characterized as the\nlowest [resp. highest] ones that are invariant by a certain max-min [resp.\nmin-max] operation determined by the logical constraints. In both variants,\nmaking balance between the revised degree of belief of a proposition and that\nof its negation leads to decisions that are ensured to be consistent with the\nlogical constraints. These decisions are ensured to agree with the majority\ncriterion as applied to the original degrees of belief whenever this gives a\nconsistent result. They are also also ensured to satisfy a property of respect\nfor unanimity about any particular issue, as well as a property of monotonicity\nwith respect to the original degrees of belief. The application of the method\nto certain special domains comes down to well established or increasingly\naccepted methods, such as the single-link method of cluster analysis and the\nmethod of paths in preferential voting.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2010 11:55:38 GMT"}, {"version": "v2", "created": "Fri, 1 Oct 2010 10:24:34 GMT"}, {"version": "v3", "created": "Wed, 20 Jul 2011 13:23:07 GMT"}, {"version": "v4", "created": "Thu, 8 Mar 2012 17:12:15 GMT"}], "update_date": "2012-03-09", "authors_parsed": [["Camps", "Rosa", ""], ["Mora", "Xavier", ""], ["Saumell", "Laia", ""]]}, {"id": "1007.3159", "submitter": "Fabrizio Riguzzi PhD", "authors": "Marco Gavanelli and Fabrizio Riguzzi and Michela Milano and Paolo\n  Cagnoli", "title": "Logic-Based Decision Support for Strategic Environmental Assessment", "comments": "17 pages, 1 figure, 26th Int'l. Conference on Logic Programming\n  (ICLP'10)", "journal-ref": "Theory and Practice of Logic Programming, 26th Int'l. Conference\n  on Logic Programming (ICLP'10) Special Issue, 10(4-6), 643-658, 2010", "doi": "10.1017/S1471068410000335", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strategic Environmental Assessment is a procedure aimed at introducing\nsystematic assessment of the environmental effects of plans and programs. This\nprocedure is based on the so-called coaxial matrices that define dependencies\nbetween plan activities (infrastructures, plants, resource extractions,\nbuildings, etc.) and positive and negative environmental impacts, and\ndependencies between these impacts and environmental receptors. Up to now, this\nprocedure is manually implemented by environmental experts for checking the\nenvironmental effects of a given plan or program, but it is never applied\nduring the plan/program construction. A decision support system, based on a\nclear logic semantics, would be an invaluable tool not only in assessing a\nsingle, already defined plan, but also during the planning process in order to\nproduce an optimized, environmentally assessed plan and to study possible\nalternative scenarios. We propose two logic-based approaches to the problem,\none based on Constraint Logic Programming and one on Probabilistic Logic\nProgramming that could be, in the future, conveniently merged to exploit the\nadvantages of both. We test the proposed approaches on a real energy plan and\nwe discuss their limitations and advantages.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2010 14:36:54 GMT"}], "update_date": "2010-07-20", "authors_parsed": [["Gavanelli", "Marco", ""], ["Riguzzi", "Fabrizio", ""], ["Milano", "Michela", ""], ["Cagnoli", "Paolo", ""]]}, {"id": "1007.3223", "submitter": "Matti J\\\"arvisalo", "authors": "Robert Brummayer, Matti J\\\"arvisalo", "title": "Testing and Debugging Techniques for Answer Set Solver Development", "comments": "18 pages", "journal-ref": "Theory and Practice of Logic Programming, 10(4-6):741-758, 2010", "doi": "10.1017/S1471068410000396", "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops automated testing and debugging techniques for answer set\nsolver development. We describe a flexible grammar-based black-box ASP fuzz\ntesting tool which is able to reveal various defects such as unsound and\nincomplete behavior, i.e. invalid answer sets and inability to find existing\nsolutions, in state-of-the-art answer set solver implementations. Moreover, we\ndevelop delta debugging techniques for shrinking failure-inducing inputs on\nwhich solvers exhibit defective behavior. In particular, we develop a delta\ndebugging algorithm in the context of answer set solving, and evaluate two\ndifferent elimination strategies for the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2010 17:51:54 GMT"}], "update_date": "2010-07-20", "authors_parsed": [["Brummayer", "Robert", ""], ["J\u00e4rvisalo", "Matti", ""]]}, {"id": "1007.3515", "submitter": "Matthias Knorr", "authors": "Jos\\'e J\\'ulio Alferes, Matthias Knorr, Terrance Swift", "title": "Query-driven Procedures for Hybrid MKNF Knowledge Bases", "comments": "48 pages with 1 figures, submitted to ACM TOCL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid MKNF knowledge bases are one of the most prominent tightly integrated\ncombinations of open-world ontology languages with closed-world (non-monotonic)\nrule paradigms. The definition of Hybrid MKNF is parametric on the description\nlogic (DL) underlying the ontology language, in the sense that non-monotonic\nrules can extend any decidable DL language. Two related semantics have been\ndefined for Hybrid MKNF: one that is based on the Stable Model Semantics for\nlogic programs and one on the Well-Founded Semantics (WFS). Under WFS, the\ndefinition of Hybrid MKNF relies on a bottom-up computation that has polynomial\ndata complexity whenever the DL language is tractable. Here we define a general\nquery-driven procedure for Hybrid MKNF that is sound with respect to the stable\nmodel-based semantics, and sound and complete with respect to its WFS variant.\nThis procedure is able to answer a slightly restricted form of conjunctive\nqueries, and is based on tabled rule evaluation extended with an external\noracle that captures reasoning within the ontology. Such an (abstract) oracle\nreceives as input a query along with knowledge already derived, and replies\nwith a (possibly empty) set of atoms, defined in the rules, whose truth would\nsuffice to prove the initial query. With appropriate assumptions on the\ncomplexity of the abstract oracle, the general procedure maintains the data\ncomplexity of the WFS for Hybrid MKNF knowledge bases.\n  To illustrate this approach, we provide a concrete oracle for EL+, a fragment\nof the light-weight DL EL++. Such an oracle has practical use, as EL++ is the\nlanguage underlying OWL 2 EL, which is part of the W3C recommendations for the\nSemantic Web, and is tractable for reasoning tasks such as subsumption. We show\nthat query-driven Hybrid MKNF preserves polynomial data complexity when using\nthe EL+ oracle and WFS.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2010 21:20:39 GMT"}, {"version": "v2", "created": "Fri, 9 Dec 2011 17:36:35 GMT"}], "update_date": "2011-12-12", "authors_parsed": [["Alferes", "Jos\u00e9 J\u00falio", ""], ["Knorr", "Matthias", ""], ["Swift", "Terrance", ""]]}, {"id": "1007.3663", "submitter": "Piero Bonatti", "authors": "Sabrina Baselice and Piero A. Bonatti", "title": "A decidable subclass of finitary programs", "comments": null, "journal-ref": "Theory and Practice of Logic Programming (2010), 10:481-496\n  Cambridge University Press", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer set programming - the most popular problem solving paradigm based on\nlogic programs - has been recently extended to support uninterpreted function\nsymbols. All of these approaches have some limitation. In this paper we propose\na class of programs called FP2 that enjoys a different trade-off between\nexpressiveness and complexity. FP2 programs enjoy the following unique\ncombination of properties: (i) the ability of expressing predicates with\ninfinite extensions; (ii) full support for predicates with arbitrary arity;\n(iii) decidability of FP2 membership checking; (iv) decidability of skeptical\nand credulous stable model reasoning for call-safe queries. Odd cycles are\nsupported by composing FP2 programs with argument restricted programs.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2010 14:00:14 GMT"}], "update_date": "2010-07-22", "authors_parsed": [["Baselice", "Sabrina", ""], ["Bonatti", "Piero A.", ""]]}, {"id": "1007.3700", "submitter": "Enrico Pontelli", "authors": "Chitta Baral, Gregory Gelfond, Enrico Pontelli, Tran Cao Son", "title": "Logic Programming for Finding Models in the Logics of Knowledge and its\n  Applications: A Case Study", "comments": "16 pages, 1 figure, International Conference on Logic Programming\n  2010", "journal-ref": "Theory and Practice of Logic Programming, Volume 10, Special Issue\n  4-6, July 2010, pages 675-690", "doi": "10.1017/S1471068410000359", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The logics of knowledge are modal logics that have been shown to be effective\nin representing and reasoning about knowledge in multi-agent domains.\nRelatively few computational frameworks for dealing with computation of models\nand useful transformations in logics of knowledge (e.g., to support multi-agent\nplanning with knowledge actions and degrees of visibility) have been proposed.\nThis paper explores the use of logic programming (LP) to encode interesting\nforms of logics of knowledge and compute Kripke models. The LP modeling is\nexpanded with useful operators on Kripke structures, to support multi-agent\nplanning in the presence of both world-altering and knowledge actions. This\nresults in the first ever implementation of a planner for this type of complex\nmulti-agent domains.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2010 17:44:02 GMT"}], "update_date": "2010-07-22", "authors_parsed": [["Baral", "Chitta", ""], ["Gelfond", "Gregory", ""], ["Pontelli", "Enrico", ""], ["Son", "Tran Cao", ""]]}, {"id": "1007.3858", "submitter": "Jon Sneyers", "authors": "Jon Sneyers, Wannes Meert, Joost Vennekens, Yoshitaka Kameya and\n  Taisuke Sato", "title": "CHR(PRISM)-based Probabilistic Logic Learning", "comments": null, "journal-ref": "Theory and Practice of Logic Programming, 10(4-6), 433-447, 2010", "doi": "10.1017/S1471068410000207", "report-no": null, "categories": "cs.PL cs.AI cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  PRISM is an extension of Prolog with probabilistic predicates and built-in\nsupport for expectation-maximization learning. Constraint Handling Rules (CHR)\nis a high-level programming language based on multi-headed multiset rewrite\nrules.\n  In this paper, we introduce a new probabilistic logic formalism, called\nCHRiSM, based on a combination of CHR and PRISM. It can be used for high-level\nrapid prototyping of complex statistical models by means of \"chance rules\". The\nunderlying PRISM system can then be used for several probabilistic inference\ntasks, including probability computation and parameter learning. We define the\nCHRiSM language in terms of syntax and operational semantics, and illustrate it\nwith examples. We define the notion of ambiguous programs and define a\ndistribution semantics for unambiguous programs. Next, we describe an\nimplementation of CHRiSM, based on CHR(PRISM). We discuss the relation between\nCHRiSM and other probabilistic logic programming languages, in particular PCHR.\nFinally we identify potential application domains.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2010 11:32:21 GMT"}], "update_date": "2010-07-23", "authors_parsed": [["Sneyers", "Jon", ""], ["Meert", "Wannes", ""], ["Vennekens", "Joost", ""], ["Kameya", "Yoshitaka", ""], ["Sato", "Taisuke", ""]]}, {"id": "1007.3884", "submitter": "Cassio P. de Campos", "authors": "Cassio P. de Campos", "title": "New Results for the MAP Problem in Bayesian Networks", "comments": "A couple of typos were fixed, as well as the notation in part of\n  section 4, which was misleading. Theoretical and empirical results have not\n  changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents new results for the (partial) maximum a posteriori (MAP)\nproblem in Bayesian networks, which is the problem of querying the most\nprobable state configuration of some of the network variables given evidence.\nFirst, it is demonstrated that the problem remains hard even in networks with\nvery simple topology, such as binary polytrees and simple trees (including the\nNaive Bayes structure). Such proofs extend previous complexity results for the\nproblem. Inapproximability results are also derived in the case of trees if the\nnumber of states per variable is not bounded. Although the problem is shown to\nbe hard and inapproximable even in very simple scenarios, a new exact algorithm\nis described that is empirically fast in networks of bounded treewidth and\nbounded number of states per variable. The same algorithm is used as basis of a\nFully Polynomial Time Approximation Scheme for MAP under such assumptions.\nApproximation schemes were generally thought to be impossible for this problem,\nbut we show otherwise for classes of networks that are important in practice.\nThe algorithms are extensively tested using some well-known networks as well as\nrandom generated cases to show their effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2010 13:38:17 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2010 13:54:46 GMT"}], "update_date": "2010-07-30", "authors_parsed": [["de Campos", "Cassio P.", ""]]}, {"id": "1007.4040", "submitter": "Yisong Wang", "authors": "Yisong Wang and Jia-Huai You and Li Yan Yuan and Yi-Dong Shen", "title": "Loop Formulas for Description Logic Programs", "comments": "29 pages, 1 figures (in pdf), a short version appeared in ICLP'10", "journal-ref": "yisong Wang, Jia-Huai You, Li-Yan Yuan, Yi-Dong Shen: Loop\n  formulas for description logic programs. TPLP 10(4-6): 531-545 (2010)", "doi": "10.1017/S1471068410000268", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Description Logic Programs (dl-programs) proposed by Eiter et al. constitute\nan elegant yet powerful formalism for the integration of answer set programming\nwith description logics, for the Semantic Web. In this paper, we generalize the\nnotions of completion and loop formulas of logic programs to description logic\nprograms and show that the answer sets of a dl-program can be precisely\ncaptured by the models of its completion and loop formulas. Furthermore, we\npropose a new, alternative semantics for dl-programs, called the {\\em canonical\nanswer set semantics}, which is defined by the models of completion that\nsatisfy what are called canonical loop formulas. A desirable property of\ncanonical answer sets is that they are free of circular justifications. Some\nproperties of canonical answer sets are also explored.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2010 04:48:19 GMT"}], "update_date": "2010-07-26", "authors_parsed": [["Wang", "Yisong", ""], ["You", "Jia-Huai", ""], ["Yuan", "Li Yan", ""], ["Shen", "Yi-Dong", ""]]}, {"id": "1007.4767", "submitter": "Marcello Balduccini", "authors": "Marcello Balduccini and Sara Girotto", "title": "Formalization of Psychological Knowledge in Answer Set Programming and\n  its Application", "comments": "26th Int'l. Conference on Logic Programming (ICLP'10)", "journal-ref": "Theory and Practice of Logic Programming, 10(4-6), 725-740, 2010", "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the use of Answer Set Programming (ASP) to\nformalize, and reason about, psychological knowledge. In the field of\npsychology, a considerable amount of knowledge is still expressed using only\nnatural language. This lack of a formalization complicates accurate studies,\ncomparisons, and verification of theories. We believe that ASP, a knowledge\nrepresentation formalism allowing for concise and simple representation of\ndefaults, uncertainty, and evolving domains, can be used successfully for the\nformalization of psychological knowledge. To demonstrate the viability of ASP\nfor this task, in this paper we develop an ASP-based formalization of the\nmechanics of Short-Term Memory. We also show that our approach can have rather\nimmediate practical uses by demonstrating an application of our formalization\nto the task of predicting a user's interaction with a graphical interface.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2010 16:33:33 GMT"}, {"version": "v2", "created": "Thu, 10 Feb 2011 14:28:48 GMT"}], "update_date": "2011-02-11", "authors_parsed": [["Balduccini", "Marcello", ""], ["Girotto", "Sara", ""]]}, {"id": "1007.4868", "submitter": "Athar Kharal", "authors": "Athar Kharal", "title": "Predicting Suicide Attacks: A Fuzzy Soft Set Approach", "comments": "Submitted manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper models a decision support system to predict the occurance of\nsuicide attack in a given collection of cities. The system comprises two parts.\nFirst part analyzes and identifies the factors which affect the prediction.\nAdmitting incomplete information and use of linguistic terms by experts, as two\ncharacteristic features of this peculiar prediction problem we exploit the\nTheory of Fuzzy Soft Sets. Hence the Part 2 of the model is an algorithm vz.\nFSP which takes the assessment of factors given in Part 1 as its input and\nproduces a possibility profile of cities likely to receive the accident. The\nalgorithm is of O(2^n) complexity. It has been illustrated by an example solved\nin detail. Simulation results for the algorithm have been presented which give\ninsight into the strengths and weaknesses of FSP. Three different decision\nmaking measures have been simulated and compared in our discussion.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2010 04:15:17 GMT"}], "update_date": "2010-07-29", "authors_parsed": [["Kharal", "Athar", ""]]}, {"id": "1007.5024", "submitter": "James P. Delgrande", "authors": "James P. Delgrande", "title": "A Program-Level Approach to Revising Logic Programs under the Answer Set\n  Semantics", "comments": null, "journal-ref": "Theory and Practice of Logic Programming, 10, 4--6, 2010, pp.\n  565-580", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach to the revision of logic programs under the answer set semantics\nis presented. For programs P and Q, the goal is to determine the answer sets\nthat correspond to the revision of P by Q, denoted P * Q. A fundamental\nprinciple of classical (AGM) revision, and the one that guides the approach\nhere, is the success postulate. In AGM revision, this stipulates that A is in K\n* A. By analogy with the success postulate, for programs P and Q, this means\nthat the answer sets of Q will in some sense be contained in those of P * Q.\nThe essential idea is that for P * Q, a three-valued answer set for Q,\nconsisting of positive and negative literals, is first determined. The positive\nliterals constitute a regular answer set, while the negated literals make up a\nminimal set of naf literals required to produce the answer set from Q. These\nliterals are propagated to the program P, along with those rules of Q that are\nnot decided by these literals. The approach differs from work in update logic\nprograms in two main respects. First, we ensure that the revising logic program\nhas higher priority, and so we satisfy the success postulate; second, for the\npreference implicit in a revision P * Q, the program Q as a whole takes\nprecedence over P, unlike update logic programs, since answer sets of Q are\npropagated to P. We show that a core group of the AGM postulates are satisfied,\nas are the postulates that have been proposed for update logic programs.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2010 16:14:17 GMT"}], "update_date": "2010-07-29", "authors_parsed": [["Delgrande", "James P.", ""]]}, {"id": "1007.5104", "submitter": "Toby Walsh", "authors": "Jessica Davies and George Katsirelos and Nina Narodystka and Toby\n  Walsh", "title": "An Empirical Study of Borda Manipulation", "comments": "To appear in Proceedings of the Third International Workshop on\n  Computational Social Choice", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of coalitional manipulation in elections using the\nunweighted Borda rule. We provide empirical evidence of the manipulability of\nBorda elections in the form of two new greedy manipulation algorithms based on\nintuitions from the bin-packing and multiprocessor scheduling domains. Although\nwe have not been able to show that these algorithms beat existing methods in\nthe worst-case, our empirical evaluation shows that they significantly\noutperform the existing method and are able to find optimal manipulations in\nthe vast majority of the randomly generated elections that we tested. These\nempirical results provide further evidence that the Borda rule provides little\ndefense against coalitional manipulation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2010 03:21:57 GMT"}], "update_date": "2010-07-30", "authors_parsed": [["Davies", "Jessica", ""], ["Katsirelos", "George", ""], ["Narodystka", "Nina", ""], ["Walsh", "Toby", ""]]}, {"id": "1007.5114", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Where are the hard manipulation problems?", "comments": "Invited tutorial at the Third International Workshop on Computational\n  Social Choice 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One possible escape from the Gibbard-Satterthwaite theorem is computational\ncomplexity. For example, it is NP-hard to compute if the STV rule can be\nmanipulated. However, there is increasing concern that such results may not re\nect the difficulty of manipulation in practice. In this tutorial, I survey\nrecent results in this area.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2010 05:52:53 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "1007.5120", "submitter": "Toby Walsh", "authors": "Maria Silvia Pini and Francesca Rossi and Brent Venable and Toby Walsh", "title": "Stable marriage problems with quantitative preferences", "comments": "To appear in Proceedings of Third International Workshop on\n  Computational Social Choice, Dusseldorf, Germany, September 13-16, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stable marriage problem is a well-known problem of matching men to women\nso that no man and woman, who are not married to each other, both prefer each\nother. Such a problem has a wide variety of practical applications, ranging\nfrom matching resident doctors to hospitals, to matching students to schools or\nmore generally to any two-sided market. In the classical stable marriage\nproblem, both men and women express a strict preference order over the members\nof the other sex, in a qualitative way. Here we consider stable marriage\nproblems with quantitative preferences: each man (resp., woman) provides a\nscore for each woman (resp., man). Such problems are more expressive than the\nclassical stable marriage problems. Moreover, in some real-life situations it\nis more natural to express scores (to model, for example, profits or costs)\nrather than a qualitative preference ordering. In this context, we define new\nnotions of stability and optimality, and we provide algorithms to find\nmarriages which are stable and/or optimal according to these notions. While\nexpressivity greatly increases by adopting quantitative preferences, we show\nthat in most cases the desired solutions can be found by adapting existing\nalgorithms for the classical stable marriage problem.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2010 06:37:12 GMT"}], "update_date": "2016-11-25", "authors_parsed": [["Pini", "Maria Silvia", ""], ["Rossi", "Francesca", ""], ["Venable", "Brent", ""], ["Walsh", "Toby", ""]]}, {"id": "1007.5130", "submitter": "Secretary  Ijaia", "authors": "Giuseppe Della Penna (1), Benedetto Intrigila (2), Daniele Magazzeni\n  (3) and Fabio Mercorio (1) ((1) University of L'Aquila, Italy, (2) University\n  of Rome, Italy and (3) University of Chieti, Italy)", "title": "Resource-Optimal Planning For An Autonomous Planetary Vehicle", "comments": "15 pages, 4 figures", "journal-ref": "International Journal of Artificial Intelligence & Applications\n  1.3 (2010) 15-29", "doi": "10.5121/ijaia.2010.1302", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Autonomous planetary vehicles, also known as rovers, are small autonomous\nvehicles equipped with a variety of sensors used to perform exploration and\nexperiments on a planet's surface. Rovers work in a partially unknown\nenvironment, with narrow energy/time/movement constraints and, typically, small\ncomputational resources that limit the complexity of on-line planning and\nscheduling, thus they represent a great challenge in the field of autonomous\nvehicles. Indeed, formal models for such vehicles usually involve hybrid\nsystems with nonlinear dynamics, which are difficult to handle by most of the\ncurrent planning algorithms and tools. Therefore, when offline planning of the\nvehicle activities is required, for example for rovers that operate without a\ncontinuous Earth supervision, such planning is often performed on simplified\nmodels that are not completely realistic. In this paper we show how the\nUPMurphi model checking based planning tool can be used to generate\nresource-optimal plans to control the engine of an autonomous planetary\nvehicle, working directly on its hybrid model and taking into account several\nsafety constraints, thus achieving very accurate results.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2010 07:27:25 GMT"}], "update_date": "2010-07-30", "authors_parsed": [["Della Penna", "Giuseppe", ""], ["Intrigila", "Benedetto", ""], ["Magazzeni", "Daniele", ""], ["Mercorio", "Fabio", ""]]}, {"id": "1007.5180", "submitter": "Alessandro Dal Pal\\`u", "authors": "Alessandro Dal Palu', Agostino Dovier, Federico Fogolari, Enrico\n  Pontelli", "title": "CLP-based protein fragment assembly", "comments": "special issue dedicated to ICLP 2010", "journal-ref": "Theory and Practice of Logic Programming, special issue dedicated\n  to ICLP 2010. 10(4-6): pp 709-724, July 2010", "doi": "10.1017/S1471068410000372", "report-no": null, "categories": "cs.AI cs.CE cs.PL q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper investigates a novel approach, based on Constraint Logic\nProgramming (CLP), to predict the 3D conformation of a protein via fragments\nassembly. The fragments are extracted by a preprocessor-also developed for this\nwork- from a database of known protein structures that clusters and classifies\nthe fragments according to similarity and frequency. The problem of assembling\nfragments into a complete conformation is mapped to a constraint solving\nproblem and solved using CLP. The constraint-based model uses a medium\ndiscretization degree Ca-side chain centroid protein model that offers\nefficiency and a good approximation for space filling. The approach adapts\nexisting energy models to the protein representation used and applies a large\nneighboring search strategy. The results shows the feasibility and efficiency\nof the method. The declarative nature of the solution allows to include future\nextensions, e.g., different size fragments for better accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2010 10:44:49 GMT"}], "update_date": "2010-08-02", "authors_parsed": [["Palu'", "Alessandro Dal", ""], ["Dovier", "Agostino", ""], ["Fogolari", "Federico", ""], ["Pontelli", "Enrico", ""]]}, {"id": "1007.5421", "submitter": "Matthieu Petit", "authors": "Henning Christiansen, Christian Theil Have, Ole Torp Lassen and\n  Matthieu Petit", "title": "Inference with Constrained Hidden Markov Models in PRISM", "comments": null, "journal-ref": "TPLP 2010, 10 (4-6) 449-464", "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Hidden Markov Model (HMM) is a common statistical model which is widely\nused for analysis of biological sequence data and other sequential phenomena.\nIn the present paper we show how HMMs can be extended with side-constraints and\npresent constraint solving techniques for efficient inference. Defining HMMs\nwith side-constraints in Constraint Logic Programming have advantages in terms\nof more compact expression and pruning opportunities during inference.\n  We present a PRISM-based framework for extending HMMs with side-constraints\nand show how well-known constraints such as cardinality and all different are\nintegrated. We experimentally validate our approach on the biologically\nmotivated problem of global pairwise alignment.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jul 2010 11:55:05 GMT"}], "update_date": "2010-08-02", "authors_parsed": [["Christiansen", "Henning", ""], ["Have", "Christian Theil", ""], ["Lassen", "Ole Torp", ""], ["Petit", "Matthieu", ""]]}]