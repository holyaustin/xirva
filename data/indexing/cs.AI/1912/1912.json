[{"id": "1912.00011", "submitter": "Jaelle Scheuerman", "authors": "Jaelle Scheuerman, Jason L. Harman, Nicholas Mattei, K. Brent Venable", "title": "Heuristic Strategies in Uncertain Approval Voting Environments", "comments": "arXiv admin note: text overlap with arXiv:1905.12104", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many collective decision making situations, agents vote to choose an\nalternative that best represents the preferences of the group. Agents may\nmanipulate the vote to achieve a better outcome by voting in a way that does\nnot reflect their true preferences. In real world voting scenarios, people\noften do not have complete information about other voter preferences and it can\nbe computationally complex to identify a strategy that will maximize their\nexpected utility. In such situations, it is often assumed that voters will vote\ntruthfully rather than expending the effort to strategize. However, being\ntruthful is just one possible heuristic that may be used. In this paper, we\nexamine the effectiveness of heuristics in single winner and multi-winner\napproval voting scenarios with missing votes. In particular, we look at\nheuristics where a voter ignores information about other voting profiles and\nmakes their decisions based solely on how much they like each candidate. In a\nbehavioral experiment, we show that people vote truthfully in some situations\nand prioritize high utility candidates in others. We examine when these\nbehaviors maximize expected utility and show how the structure of the voting\nenvironment affects both how well each heuristic performs and how humans employ\nthese heuristics.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 13:38:34 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Scheuerman", "Jaelle", ""], ["Harman", "Jason L.", ""], ["Mattei", "Nicholas", ""], ["Venable", "K. Brent", ""]]}, {"id": "1912.00074", "submitter": "Pin Wang", "authors": "Pin Wang, Hanhan Li, Ching-Yao Chan", "title": "Quadratic Q-network for Learning Continuous Control for Autonomous\n  Vehicles", "comments": "Machine Learning for Autonomous Driving Workshop on NeurIPS, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning algorithms have recently been proposed to learn\ntime-sequential control policies in the field of autonomous driving. Direct\napplications of Reinforcement Learning algorithms with discrete action space\nwill yield unsatisfactory results at the operational level of driving where\ncontinuous control actions are actually required. In addition, the design of\nneural networks often fails to incorporate the domain knowledge of the\ntargeting problem such as the classical control theories in our case. In this\npaper, we propose a hybrid model by combining Q-learning and classic PID\n(Proportion Integration Differentiation) controller for handling continuous\nvehicle control problems under dynamic driving environment. Particularly,\ninstead of using a big neural network as Q-function approximation, we design a\nQuadratic Q-function over actions with multiple simple neural networks for\nfinding optimal values within a continuous space. We also build an action\nnetwork based on the domain knowledge of the control mechanism of a PID\ncontroller to guide the agent to explore optimal actions more efficiently.We\ntest our proposed approach in simulation under two common but challenging\ndriving situations, the lane change scenario and ramp merge scenario. Results\nshow that the autonomous vehicle agent can successfully learn a smooth and\nefficient driving behavior in both situations.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 21:32:32 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Wang", "Pin", ""], ["Li", "Hanhan", ""], ["Chan", "Ching-Yao", ""]]}, {"id": "1912.00086", "submitter": "Chi Zhang", "authors": "Chi Zhang, Baoxiong Jia, Feng Gao, Yixin Zhu, Hongjing Lu, Song-Chun\n  Zhu", "title": "Learning Perceptual Inference by Contrasting", "comments": "NeurIPS 2019 spotlight. Project page:\n  http://wellyzhang.github.io/project/copinet.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Thinking in pictures,\" [1] i.e., spatial-temporal reasoning, effortless and\ninstantaneous for humans, is believed to be a significant ability to perform\nlogical induction and a crucial factor in the intellectual history of\ntechnology development. Modern Artificial Intelligence (AI), fueled by massive\ndatasets, deeper models, and mighty computation, has come to a stage where\n(super-)human-level performances are observed in certain specific tasks.\nHowever, current AI's ability in \"thinking in pictures\" is still far lacking\nbehind. In this work, we study how to improve machines' reasoning ability on\none challenging task of this kind: Raven's Progressive Matrices (RPM).\nSpecifically, we borrow the very idea of \"contrast effects\" from the field of\npsychology, cognition, and education to design and train a\npermutation-invariant model. Inspired by cognitive studies, we equip our model\nwith a simple inference module that is jointly trained with the perception\nbackbone. Combining all the elements, we propose the Contrastive Perceptual\nInference network (CoPINet) and empirically demonstrate that CoPINet sets the\nnew state-of-the-art for permutation-invariant models on two major datasets. We\nconclude that spatial-temporal reasoning depends on envisaging the\npossibilities consistent with the relations between objects and can be solved\nfrom pixel-level inputs.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 23:02:43 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Zhang", "Chi", ""], ["Jia", "Baoxiong", ""], ["Gao", "Feng", ""], ["Zhu", "Yixin", ""], ["Lu", "Hongjing", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1912.00109", "submitter": "Xinyang Deng", "authors": "Xinyang Deng", "title": "Belief and plausibility measures for D numbers", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a generalization of Dempster-Shafer theory, D number theory provides a\nframework to deal with uncertain information with non-exclusiveness and\nincompleteness. However, some basic concepts in D number theory are not well\ndefined. In this note, the belief and plausibility measures for D numbers have\nbeen proposed, and basic properties of these measures have been revealed as\nwell.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 01:28:18 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Deng", "Xinyang", ""]]}, {"id": "1912.00147", "submitter": "Bin He", "authors": "Bin He, Di Zhou, Jinghui Xiao, Xin jiang, Qun Liu, Nicholas Jing Yuan,\n  Tong Xu", "title": "Integrating Graph Contextualized Knowledge into Pre-trained Language\n  Models", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex node interactions are common in knowledge graphs, and these\ninteractions also contain rich knowledge information. However, traditional\nmethods usually treat a triple as a training unit during the knowledge\nrepresentation learning (KRL) procedure, neglecting contextualized information\nof the nodes in knowledge graphs (KGs). We generalize the modeling object to a\nvery general form, which theoretically supports any subgraph extracted from the\nknowledge graph, and these subgraphs are fed into a novel transformer-based\nmodel to learn the knowledge embeddings. To broaden usage scenarios of\nknowledge, pre-trained language models are utilized to build a model that\nincorporates the learned knowledge representations. Experimental results\ndemonstrate that our model achieves the state-of-the-art performance on several\nmedical NLP tasks, and improvement above TransE indicates that our KRL method\ncaptures the graph contextualized information effectively.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 07:13:25 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 06:36:36 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["He", "Bin", ""], ["Zhou", "Di", ""], ["Xiao", "Jinghui", ""], ["jiang", "Xin", ""], ["Liu", "Qun", ""], ["Yuan", "Nicholas Jing", ""], ["Xu", "Tong", ""]]}, {"id": "1912.00163", "submitter": "Gaurav Sinha", "authors": "Gaurav Sinha, Ayush Chauhan, Aurghya Maiti, Naman Poddar, Pulkit Goel", "title": "Dis-entangling Mixture of Interventions on a Causal Bayesian Network\n  Using Aggregate Observations", "comments": "Accepted at the Ninth International Workshop on Statistical\n  Relational AI, AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the problem of separating a mixture of distributions, all of which\ncome from interventions on a known causal bayesian network. Given oracle access\nto marginals of all distributions resulting from interventions on the network,\nand estimates of marginals from the mixture distribution, we want to recover\nthe mixing proportions of different mixture components.\n  We show that in the worst case, mixing proportions cannot be identified using\nmarginals only. If exact marginals of the mixture distribution were known,\nunder a simple assumption of excluding a few distributions from the mixture, we\nshow that the mixing proportions become identifiable. Our identifiability proof\nis constructive and gives an efficient algorithm recovering the mixing\nproportions exactly. When exact marginals are not available, we design an\noptimization framework to estimate the mixing proportions.\n  Our problem is motivated from a real-world scenario of an e-commerce\nbusiness, where multiple interventions occur at a given time, leading to\ndeviations in expected metrics. We conduct experiments on the well known\npublicly available ALARM network and on a proprietary dataset from a large\ne-commerce company validating the performance of our method.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 09:36:23 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 11:19:47 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Sinha", "Gaurav", ""], ["Chauhan", "Ayush", ""], ["Maiti", "Aurghya", ""], ["Poddar", "Naman", ""], ["Goel", "Pulkit", ""]]}, {"id": "1912.00177", "submitter": "Jeffrey Hawke", "authors": "Jeffrey Hawke, Richard Shen, Corina Gurau, Siddharth Sharma, Daniele\n  Reda, Nikolay Nikolov, Przemyslaw Mazur, Sean Micklethwaite, Nicolas\n  Griffiths, Amar Shah, Alex Kendall", "title": "Urban Driving with Conditional Imitation Learning", "comments": "Under submission; added acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hand-crafting generalised decision-making rules for real-world urban\nautonomous driving is hard. Alternatively, learning behaviour from\neasy-to-collect human driving demonstrations is appealing. Prior work has\nstudied imitation learning (IL) for autonomous driving with a number of\nlimitations. Examples include only performing lane-following rather than\nfollowing a user-defined route, only using a single camera view or heavily\ncropped frames lacking state observability, only lateral (steering) control,\nbut not longitudinal (speed) control and a lack of interaction with traffic.\nImportantly, the majority of such systems have been primarily evaluated in\nsimulation - a simple domain, which lacks real-world complexities. Motivated by\nthese challenges, we focus on learning representations of semantics, geometry\nand motion with computer vision for IL from human driving demonstrations. As\nour main contribution, we present an end-to-end conditional imitation learning\napproach, combining both lateral and longitudinal control on a real vehicle for\nfollowing urban routes with simple traffic. We address inherent dataset bias by\ndata balancing, training our final policy on approximately 30 hours of\ndemonstrations gathered over six months. We evaluate our method on an\nautonomous vehicle by driving 35km of novel routes in European urban streets.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 10:24:45 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 18:17:45 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Hawke", "Jeffrey", ""], ["Shen", "Richard", ""], ["Gurau", "Corina", ""], ["Sharma", "Siddharth", ""], ["Reda", "Daniele", ""], ["Nikolov", "Nikolay", ""], ["Mazur", "Przemyslaw", ""], ["Micklethwaite", "Sean", ""], ["Griffiths", "Nicolas", ""], ["Shah", "Amar", ""], ["Kendall", "Alex", ""]]}, {"id": "1912.00180", "submitter": "Anton Kolonin Dr.", "authors": "Anton Kolonin", "title": "Latent Semantic Search and Information Extraction Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The motivation, concept, design and implementation of latent semantic search\nfor search engines have limited semantic search, entity extraction and property\nattribution features, have insufficient accuracy and response time of latent\nsearch, may impose privacy concerns and the search results are unavailable in\noffline mode for robotic search operations. The alternative suggestion involves\nautonomous search engine with adaptive storage consumption, configurable search\nscope and latent search response time with built-in options for entity\nextraction and property attribution available as open source platform for\nmobile, desktop and server solutions. The suggested architecture attempts to\nimplement artificial general intelligence (AGI) principles as long as\nautonomous behaviour constrained by limited resources is concerned, and it is\napplied for specific task of enabling Web search for artificial agents\nimplementing the AGI.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 10:32:52 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Kolonin", "Anton", ""]]}, {"id": "1912.00191", "submitter": "Jiankai Sun", "authors": "Junning Huang, Sirui Xie, Jiankai Sun, Qiurui Ma, Chunxiao Liu,\n  Jianping Shi, Dahua Lin, Bolei Zhou", "title": "Learning a Decision Module by Imitating Driver's Control Behaviors", "comments": "Proceedings of the Conference on Robot Learning (CoRL) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving systems have a pipeline of perception, decision, planning,\nand control. The decision module processes information from the perception\nmodule and directs the execution of downstream planning and control modules. On\nthe other hand, the recent success of deep learning suggests that this pipeline\ncould be replaced by end-to-end neural control policies, however, safety cannot\nbe well guaranteed for the data-driven neural networks. In this work, we\npropose a hybrid framework to learn neural decisions in the classical modular\npipeline through end-to-end imitation learning. This hybrid framework can\npreserve the merits of the classical pipeline such as the strict enforcement of\nphysical and logical constraints while learning complex driving decisions from\ndata. To circumvent the ambiguous annotation of human driving decisions, our\nmethod learns high-level driving decisions by imitating low-level control\nbehaviors. We show in the simulation experiments that our modular driving agent\ncan generalize its driving decision and control to various complex scenarios\nwhere the rule-based programs fail. It can also generate smoother and safer\ndriving trajectories than end-to-end neural policies.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 11:57:35 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 02:06:49 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 01:38:16 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Huang", "Junning", ""], ["Xie", "Sirui", ""], ["Sun", "Jiankai", ""], ["Ma", "Qiurui", ""], ["Liu", "Chunxiao", ""], ["Shi", "Jianping", ""], ["Lin", "Dahua", ""], ["Zhou", "Bolei", ""]]}, {"id": "1912.00253", "submitter": "Hang Ma", "authors": "Ngai Meng Kou, Cheng Peng, Hang Ma, T. K. Satish Kumar, Sven Koenig", "title": "Idle Time Optimization for Target Assignment and Path Finding in\n  Sortation Centers", "comments": "AAAI 2020, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the one-shot and lifelong versions of the Target\nAssignment and Path Finding problem in automated sortation centers, where each\nagent needs to constantly assign itself a sorting station, move to its assigned\nstation without colliding with obstacles or other agents, wait in the queue of\nthat station to obtain a parcel for delivery, and then deliver the parcel to a\nsorting bin. The throughput of such centers is largely determined by the total\nidle time of all stations since their queues can frequently become empty. To\naddress this problem, we first formalize and study the one-shot version that\nassigns stations to a set of agents and finds collision-free paths for the\nagents to their assigned stations. We present efficient algorithms for this\ntask based on a novel min-cost max-flow formulation that minimizes the total\nidle time of all stations in a fixed time window. We then demonstrate how our\nalgorithms for solving the one-shot problem can be applied to solving the\nlifelong problem as well. Experimentally, we believe to be the first\nresearchers to consider real-world automated sortation centers using an\nindustrial simulator with realistic data and a kinodynamic model of real\nrobots. On this simulator, we showcase the benefits of our algorithms by\ndemonstrating their efficiency and effectiveness for up to 350 agents.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 19:16:18 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Kou", "Ngai Meng", ""], ["Peng", "Cheng", ""], ["Ma", "Hang", ""], ["Kumar", "T. K. Satish", ""], ["Koenig", "Sven", ""]]}, {"id": "1912.00260", "submitter": "Chen Wang", "authors": "Junfeng Ding, Chen Wang, Cewu Lu", "title": "Transferable Force-Torque Dynamics Model for Peg-in-hole Task", "comments": "IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a learning-based force-torque dynamics to achieve model-based\ncontrol for contact-rich peg-in-hole task using force-only inputs. Learning the\nforce-torque dynamics is challenging because of the ambiguity of the\nlow-dimensional 6-d force signal and the requirement of excessive training\ndata. To tackle these problems, we propose a multi-pose force-torque state\nrepresentation, based on which a dynamics model is learned with the data\ngenerated in a sample-efficient offline fashion. In addition, by training the\ndynamics model with peg-and-holes of various shapes, scales, and elasticities,\nthe model could quickly transfer to new peg-and-holes after a small number of\ntrials. Extensive experiments show that our dynamics model could adapt to\nunseen peg-and-holes with 70% fewer samples required compared to learning from\nscratch. Along with the learned dynamics, model predictive control and\nmodel-based reinforcement learning policies achieve over 80% insertion success\nrate. Our video is available at https://youtu.be/ZAqldpVZgm4.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 20:48:33 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ding", "Junfeng", ""], ["Wang", "Chen", ""], ["Lu", "Cewu", ""]]}, {"id": "1912.00303", "submitter": "Hong Xu", "authors": "Han Zhang and Hong Xu", "title": "MANELA: A Multi-Agent Algorithm for Learning Network Embeddings", "comments": "11 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Playing an essential role in data mining, machine learning has a long history\nof being applied to networks on multifarious tasks and has played an essential\nrole in data mining. However, the discrete and sparse natures of networks often\nrender it difficult to apply machine learning directly to networks. To\ncircumvent this difficulty, one major school of thought to approach networks\nusing machine learning is via network embeddings. On the one hand, this network\nembeddings have achieved huge success on aggregated network data in recent\nyears. On the other hand, learning network embeddings on distributively stored\nnetworks still remained understudied: To the best of our knowledge, all\nexisting algorithms for learning network embeddings have hitherto been\nexclusively centralized and thus cannot be applied to these networks. To\naccommodate distributively stored networks, in this paper, we proposed a\nmulti-agent model. Under this model, we developed the multi-agent network\nembedding learning algorithm (MANELA) for learning network embeddings. We\ndemonstrate MANELA's advantages over other existing centralized network\nembedding learning algorithms both theoretically and experimentally. Finally,\nwe further our understanding in MANELA via visualization and exploration of its\nrelationship to DeepWalk.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 02:23:34 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Zhang", "Han", ""], ["Xu", "Hong", ""]]}, {"id": "1912.00318", "submitter": "Yanjun Li", "authors": "Yanjun Li, Mohammad A. Rezaei, Chenglong Li, Xiaolin Li, Dapeng Wu", "title": "DeepAtom: A Framework for Protein-Ligand Binding Affinity Prediction", "comments": "Accepted IEEE BIBM 2019 paper with minor revisions", "journal-ref": "IEEE International Conference on Bioinformatics and Biomedicine\n  (BIBM 2019)", "doi": null, "report-no": null, "categories": "q-bio.BM cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cornerstone of computational drug design is the calculation of binding\naffinity between two biological counterparts, especially a chemical compound,\ni.e., a ligand, and a protein. Predicting the strength of protein-ligand\nbinding with reasonable accuracy is critical for drug discovery. In this paper,\nwe propose a data-driven framework named DeepAtom to accurately predict the\nprotein-ligand binding affinity. With 3D Convolutional Neural Network (3D-CNN)\narchitecture, DeepAtom could automatically extract binding related atomic\ninteraction patterns from the voxelized complex structure. Compared with the\nother CNN based approaches, our light-weight model design effectively improves\nthe model representational capacity, even with the limited available training\ndata. With validation experiments on the PDBbind v.2016 benchmark and the\nindependent Astex Diverse Set, we demonstrate that the less feature engineering\ndependent DeepAtom approach consistently outperforms the other state-of-the-art\nscoring methods. We also compile and propose a new benchmark dataset to further\nimprove the model performances. With the new dataset as training input,\nDeepAtom achieves Pearson's R=0.83 and RMSE=1.23 pK units on the PDBbind v.2016\ncore set. The promising results demonstrate that DeepAtom models can be\npotentially adopted in computational drug development protocols such as\nmolecular docking and virtual screening.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 04:45:56 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Li", "Yanjun", ""], ["Rezaei", "Mohammad A.", ""], ["Li", "Chenglong", ""], ["Li", "Xiaolin", ""], ["Wu", "Dapeng", ""]]}, {"id": "1912.00369", "submitter": "Roger Moore", "authors": "Roger K. Moore", "title": "Talking with Robots: Opportunities and Challenges", "comments": "Submitted for presentation at the UNESCO International Conference\n  Language Technologies for All (LT4All), Paris, 4-6 December 2019\n  (https://en.unesco.org/LT4All)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Notwithstanding the tremendous progress that is taking place in spoken\nlanguage technology, effective speech-based human-robot interaction still\nraises a number of important challenges. Not only do the fields of robotics and\nspoken language technology present their own special problems, but their\ncombination raises an additional set of issues. In particular, there is a large\ngap between the formulaic speech that typifies contemporary spoken dialogue\nsystems and the flexible nature of human-human conversation. It is pointed out\nthat grounded and situated speech-based human-robot interaction may lead to\ndeeper insights into the pragmatics of language usage, thereby overcoming the\ncurrent `habitability gap'.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 09:42:50 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Moore", "Roger K.", ""]]}, {"id": "1912.00398", "submitter": "Lei Yang", "authors": "Rujing Yao, Linlin Hou, Lei Yang, Jie Gui, Qing Yin, and Ou Wu", "title": "Deep Human Answer Understanding for Natural Reverse QA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study focuses on a reverse question answering (QA) procedure, in which\nmachines proactively raise questions and humans supply the answers. This\nprocedure exists in many real human-machine interaction applications. However,\na crucial problem in human-machine interaction is answer understanding. The\nexisting solutions have relied on mandatory option term selection to avoid\nautomatic answer understanding. However, these solutions have led to unnatural\nhuman-computer interaction and negatively affected user experience. To this\nend, the current study proposes a novel deep answer understanding network,\ncalled AntNet, for reverse QA. The network consists of three new modules,\nnamely, skeleton attention for questions, relevance-aware representation of\nanswers, and multi-hop based fusion. As answer understanding for reverse QA has\nnot been explored, a new data corpus is compiled in this study. Experimental\nresults indicate that our proposed network is significantly better than\nexisting methods and those modified from classical natural language processing\ndeep models. The effectiveness of the three new modules is also verified.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 13:03:03 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 04:35:12 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Yao", "Rujing", ""], ["Hou", "Linlin", ""], ["Yang", "Lei", ""], ["Gui", "Jie", ""], ["Yin", "Qing", ""], ["Wu", "Ou", ""]]}, {"id": "1912.00444", "submitter": "Anirudh Srinivasan", "authors": "Anirudh Srinivasan, Dzmitry Bahdanau, Maxime Chevalier-Boisvert and\n  Yoshua Bengio", "title": "Automated curriculum generation for Policy Gradients from Demonstrations", "comments": "Accepted to Deep RL Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a technique that improves the process of training\nan agent (using RL) for instruction following. We develop a training curriculum\nthat uses a nominal number of expert demonstrations and trains the agent in a\nmanner that draws parallels from one of the ways in which humans learn to\nperform complex tasks, i.e by starting from the goal and working backwards. We\ntest our method on the BabyAI platform and show an improvement in sample\nefficiency for some of its tasks compared to a PPO (proximal policy\noptimization) baseline.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 17:08:34 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Srinivasan", "Anirudh", ""], ["Bahdanau", "Dzmitry", ""], ["Chevalier-Boisvert", "Maxime", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1912.00498", "submitter": "Donghwan Lee", "authors": "Donghwan Lee, Niao He, Parameswaran Kamalaruban, Volkan Cevher", "title": "Optimization for Reinforcement Learning: From Single Agent to\n  Cooperative Agents", "comments": null, "journal-ref": null, "doi": "10.1109/MSP.2020.2976000", "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article reviews recent advances in multi-agent reinforcement learning\nalgorithms for large-scale control systems and communication networks, which\nlearn to communicate and cooperate. We provide an overview of this emerging\nfield, with an emphasis on the decentralized setting under different\ncoordination protocols. We highlight the evolution of reinforcement learning\nalgorithms from single-agent to multi-agent systems, from a distributed\noptimization perspective, and conclude with future directions and challenges,\nin the hope to catalyze the growing synergy among distributed optimization,\nsignal processing, and reinforcement learning communities.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 20:39:55 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Lee", "Donghwan", ""], ["He", "Niao", ""], ["Kamalaruban", "Parameswaran", ""], ["Cevher", "Volkan", ""]]}, {"id": "1912.00512", "submitter": "Ugur Kursuncu", "authors": "Ugur Kursuncu, Manas Gaur and Amit Sheth", "title": "Knowledge Infused Learning (K-IL): Towards Deep Incorporation of\n  Knowledge in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning the underlying patterns in data goes beyond instance-based\ngeneralization to external knowledge represented in structured graphs or\nnetworks. Deep learning that primarily constitutes neural computing stream in\nAI has shown significant advances in probabilistically learning latent patterns\nusing a multi-layered network of computational nodes (i.e., neurons/hidden\nunits). Structured knowledge that underlies symbolic computing approaches and\noften supports reasoning, has also seen significant growth in recent years, in\nthe form of broad-based (e.g., DBPedia, Yago) and domain, industry or\napplication specific knowledge graphs. A common substrate with careful\nintegration of the two will raise opportunities to develop neuro-symbolic\nlearning approaches for AI, where conceptual and probabilistic representations\nare combined. As the incorporation of external knowledge will aid in\nsupervising the learning of features for the model, deep infusion of\nrepresentational knowledge from knowledge graphs within hidden layers will\nfurther enhance the learning process. Although much work remains, we believe\nthat knowledge graphs will play an increasing role in developing hybrid\nneuro-symbolic intelligent systems (bottom-up deep learning with top-down\nsymbolic computing) as well as in building explainable AI systems for which\nknowledge graphs will provide scaffolding for punctuating neural computing. In\nthis position paper, we describe our motivation for such a neuro-symbolic\napproach and framework that combines knowledge graph and neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 22:36:14 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 05:26:23 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Kursuncu", "Ugur", ""], ["Gaur", "Manas", ""], ["Sheth", "Amit", ""]]}, {"id": "1912.00569", "submitter": "Kecheng Zheng", "authors": "Kecheng Zheng, Zheng-jun Zha, Wei Wei", "title": "Abstract Reasoning with Distracting Features", "comments": "Published as a conference paper at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstraction reasoning is a long-standing challenge in artificial\nintelligence. Recent studies suggest that many of the deep architectures that\nhave triumphed over other domains failed to work well in abstract reasoning. In\nthis paper, we first illustrate that one of the main challenges in such a\nreasoning task is the presence of distracting features, which requires the\nlearning algorithm to leverage counterevidence and to reject any of the false\nhypotheses in order to learn the true patterns. We later show that carefully\ndesigned learning trajectory over different categories of training data can\neffectively boost learning performance by mitigating the impacts of distracting\nfeatures. Inspired by this fact, we propose feature robust abstract reasoning\n(FRAR) model, which consists of a reinforcement learning based teacher network\nto determine the sequence of training and a student network for predictions.\nExperimental results demonstrated strong improvements over baseline algorithms\nand we are able to beat the state-of-the-art models by 18.7% in the RAVEN\ndataset and 13.3% in the PGM dataset.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 03:14:23 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Zheng", "Kecheng", ""], ["Zha", "Zheng-jun", ""], ["Wei", "Wei", ""]]}, {"id": "1912.00572", "submitter": "Wanling Gao", "authors": "Jianfeng Zhan, Lei Wang, Wanling Gao, and Rui Ren", "title": "BenchCouncil's View on Benchmarking AI and Other Emerging Workloads", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper outlines BenchCouncil's view on the challenges, rules, and vision\nof benchmarking modern workloads like Big Data, AI or machine learning, and\nInternet Services. We conclude the challenges of benchmarking modern workloads\nas FIDSS (Fragmented, Isolated, Dynamic, Service-based, and Stochastic), and\npropose the PRDAERS benchmarking rules that the benchmarks should be specified\nin a paper-and-pencil manner, relevant, diverse, containing different levels of\nabstractions, specifying the evaluation metrics and methodology, repeatable,\nand scaleable. We believe proposing simple but elegant abstractions that help\nachieve both efficiency and general-purpose is the final target of benchmarking\nin future, which may be not pressing. In the light of this vision, we shortly\ndiscuss BenchCouncil's related projects.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 03:40:27 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 06:37:43 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Zhan", "Jianfeng", ""], ["Wang", "Lei", ""], ["Gao", "Wanling", ""], ["Ren", "Rui", ""]]}, {"id": "1912.00581", "submitter": "William Paul Boyce", "authors": "W. Paul Boyce, Tony Lindsay, Arkady Zgonnikov, Ignacio Rano, and\n  KongFatt Wong-Lin", "title": "Optimality and limitations of audio-visual integration for cognitive\n  systems", "comments": "20 pages, 6 figures, 1 table 16/06/2020: Updated version includes\n  expanded discussion and addition of new references. Also updated author\n  affiliation information. This version has been accepted for publication with\n  Frontiers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multimodal integration is an important process in perceptual decision-making.\nIn humans, this process has often been shown to be statistically optimal, or\nnear optimal: sensory information is combined in a fashion that minimises the\naverage error in perceptual representation of stimuli. However, sometimes there\nare costs that come with the optimization, manifesting as illusory percepts. We\nreview audio-visual facilitations and illusions that are products of\nmultisensory integration, and the computational models that account for these\nphenomena. In particular, the same optimal computational model can lead to\nillusory percepts, and we suggest that more studies should be needed to detect\nand mitigate these illusions, as artefacts in artificial cognitive systems. We\nprovide cautionary considerations when designing artificial cognitive systems\nwith the view of avoiding such artefacts. Finally, we suggest avenues of\nresearch towards solutions to potential pitfalls in system design. We conclude\nthat detailed understanding of multisensory integration and the mechanisms\nbehind audio-visual illusions can benefit the design of artificial cognitive\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 05:08:39 GMT"}, {"version": "v2", "created": "Sat, 11 Jan 2020 06:27:55 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 02:10:31 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Boyce", "W. Paul", ""], ["Lindsay", "Tony", ""], ["Zgonnikov", "Arkady", ""], ["Rano", "Ignacio", ""], ["Wong-Lin", "KongFatt", ""]]}, {"id": "1912.00622", "submitter": "Xiaohan Yu", "authors": "Xiaohan Yu, Yang Zhao, Yongsheng Gao, Shengwu Xiong, Xiaohui Yuan", "title": "Patchy Image Structure Classification Using Multi-Orientation Region\n  Transform", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exterior contour and interior structure are both vital features for\nclassifying objects. However, most of the existing methods consider exterior\ncontour feature and internal structure feature separately, and thus fail to\nfunction when classifying patchy image structures that have similar contours\nand flexible structures. To address above limitations, this paper proposes a\nnovel Multi-Orientation Region Transform (MORT), which can effectively\ncharacterize both contour and structure features simultaneously, for patchy\nimage structure classification. MORT is performed over multiple orientation\nregions at multiple scales to effectively integrate patchy features, and thus\nenables a better description of the shape in a coarse-to-fine manner. Moreover,\nthe proposed MORT can be extended to combine with the deep convolutional neural\nnetwork techniques, for further enhancement of classification accuracy. Very\nencouraging experimental results on the challenging ultra-fine-grained cultivar\nrecognition task, insect wing recognition task, and large variation butterfly\nrecognition task are obtained, which demonstrate the effectiveness and\nsuperiority of the proposed MORT over the state-of-the-art methods in\nclassifying patchy image structures. Our code and three patchy image structure\ndatasets are available at: https://github.com/XiaohanYu-GU/MReT2019.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 08:19:30 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Yu", "Xiaohan", ""], ["Zhao", "Yang", ""], ["Gao", "Yongsheng", ""], ["Xiong", "Shengwu", ""], ["Yuan", "Xiaohui", ""]]}, {"id": "1912.00667", "submitter": "Akansha Bhardwaj", "authors": "Akansha Bhardwaj, Jie Yang, Philippe Cudr\\'e-Mauroux", "title": "A Human-AI Loop Approach for Joint Keyword Discovery and Expectation\n  Estimation in Micropost Event Detection", "comments": "Accepted at AAAI, 2020", "journal-ref": "AAAI, 2020", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microblogging platforms such as Twitter are increasingly being used in event\ndetection. Existing approaches mainly use machine learning models and rely on\nevent-related keywords to collect the data for model training. These approaches\nmake strong assumptions on the distribution of the relevant micro-posts\ncontaining the keyword -- referred to as the expectation of the distribution --\nand use it as a posterior regularization parameter during model training. Such\napproaches are, however, limited as they fail to reliably estimate the\ninformativeness of a keyword and its expectation for model training. This paper\nintroduces a Human-AI loop approach to jointly discover informative keywords\nfor model training while estimating their expectation. Our approach iteratively\nleverages the crowd to estimate both keyword specific expectation and the\ndisagreement between the crowd and the model in order to discover new keywords\nthat are most beneficial for model training. These keywords and their\nexpectation not only improve the resulting performance but also make the model\ntraining process more transparent. We empirically demonstrate the merits of our\napproach, both in terms of accuracy and interpretability, on multiple\nreal-world datasets and show that our approach improves the state of the art by\n24.3%.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 10:18:27 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Bhardwaj", "Akansha", ""], ["Yang", "Jie", ""], ["Cudr\u00e9-Mauroux", "Philippe", ""]]}, {"id": "1912.00669", "submitter": "Wenwu Qu", "authors": "Wenwu Qu and Xiaoyu Chi and Wei Zheng", "title": "KRM-based Dialogue Management", "comments": "9 pages, 4 figures,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A KRM-based dialogue management (DM) is proposed using to implement\nhuman-computer dialogue system in complex scenarios. KRM-based DM has a well\ndescription ability and it can ensure the logic of the dialogue process. Then a\ncomplex application scenario in the Internet of Things (IOT) industry and a\ndialogue system implemented based on the KRM-based DM will be introduced, where\nthe system allows enterprise customers to customize topics and adapts\ncorresponding topics in the interaction process with users. The experimental\nresults show that the system can complete the interactive tasks well, and can\neffectively solve the problems of topic switching, information inheritance\nbetween topics, change of dominance.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 10:21:34 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Qu", "Wenwu", ""], ["Chi", "Xiaoyu", ""], ["Zheng", "Wei", ""]]}, {"id": "1912.00682", "submitter": "Duong Nguyen", "authors": "Duong Nguyen, Rodolphe Vadaine, Guillaume Hajduch, Ren\\'e Garello, and\n  Ronan Fablet", "title": "GeoTrackNet-A Maritime Anomaly Detector using Probabilistic Neural\n  Network Representation of AIS Tracks and A Contrario Detection", "comments": "IEEE Transactions on Intelligent Transportation Systems", "journal-ref": null, "doi": "10.1109/TITS.2021.3055614", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing maritime traffic patterns and detecting anomalies from them are\nkey to vessel monitoring and maritime situational awareness. We propose a novel\napproach -- referred to as GeoTrackNet -- for maritime anomaly detection from\nAIS data streams. Our model exploits state-of-the-art neural network schemes to\nlearn a probabilistic representation of AIS tracks and a contrario detection to\ndetect abnormal events. The neural network provides a new means to capture\ncomplex and heterogeneous patterns in vessels' behaviours, while the \\textit{a\ncontrario} detector takes into account the fact that the learnt distribution\nmay be location-dependent. Experiments on a real AIS dataset comprising more\nthan 4.2 million AIS messages demonstrate the relevance of the proposed method\ncompared with state-of-the-art schemes.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 11:04:56 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 12:22:43 GMT"}, {"version": "v3", "created": "Sun, 24 Jan 2021 21:03:37 GMT"}, {"version": "v4", "created": "Tue, 2 Feb 2021 12:57:09 GMT"}, {"version": "v5", "created": "Mon, 8 Feb 2021 21:08:13 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Nguyen", "Duong", ""], ["Vadaine", "Rodolphe", ""], ["Hajduch", "Guillaume", ""], ["Garello", "Ren\u00e9", ""], ["Fablet", "Ronan", ""]]}, {"id": "1912.00690", "submitter": "Benjamin Clavi\\'e", "authors": "Benjamin Clavi\\'e and Kobi Gal", "title": "EduBERT: Pretrained Deep Language Models for Learning Analytics", "comments": "Accepted for poster presentation at the 10th International Learning\n  Analytics and Knowledge (LAK20) Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of large pretrained neural networks to create contextualized word\nembeddings has drastically improved performance on several natural language\nprocessing (NLP) tasks. These computationally expensive models have begun to be\napplied to domain-specific NLP tasks such as re-hospitalization prediction from\nclinical notes. This paper demonstrates that using large pretrained models\nproduces excellent results on common learning analytics tasks. Pre-training\ndeep language models using student forum data from a wide array of online\ncourses improves performance beyond the state of the art on three text\nclassification tasks. We also show that a smaller, distilled version of our\nmodel produces the best results on two of the three tasks while limiting\ncomputational cost. We make both models available to the research community at\nlarge.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 11:32:53 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Clavi\u00e9", "Benjamin", ""], ["Gal", "Kobi", ""]]}, {"id": "1912.00715", "submitter": "Anthony Constantinou", "authors": "Neville Kenneth Kitson and Anthony C. Constantinou", "title": "Learning Bayesian networks from demographic and health survey data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Child mortality from preventable diseases such as pneumonia and diarrhoea in\nlow and middle-income countries remains a serious global challenge. We combine\nknowledge with available Demographic and Health Survey (DHS) data from India,\nto construct Causal Bayesian Networks (CBNs) and investigate the factors\nassociated with childhood diarrhoea. We make use of freeware tools to learn the\ngraphical structure of the DHS data with score-based, constraint-based, and\nhybrid structure learning algorithms. We investigate the effect of missing\nvalues, sample size, and knowledge-based constraints on each of the structure\nlearning algorithms and assess their accuracy with multiple scoring functions.\nWeaknesses in the survey methodology and data available, as well as the\nvariability in the CBNs generated by the different algorithms, mean that it is\nnot possible to learn a definitive CBN from data. However, knowledge-based\nconstraints are found to be useful in reducing the variation in the graphs\nproduced by the different algorithms, and produce graphs which are more\nreflective of the likely influential relationships in the data. Furthermore,\nvaluable insights are gained into the performance and characteristics of the\nstructure learning algorithms. Two score-based algorithms in particular, TABU\nand FGES, demonstrate many desirable qualities; a) with sufficient data, they\nproduce a graph which is similar to the reference graph, b) they are relatively\ninsensitive to missing values, and c) behave well with knowledge-based\nconstraints. The results provide a basis for further investigation of the DHS\ndata and for a deeper understanding of the behaviour of the structure learning\nalgorithms when applied to real-world settings.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 12:24:35 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 12:27:51 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Kitson", "Neville Kenneth", ""], ["Constantinou", "Anthony C.", ""]]}, {"id": "1912.00730", "submitter": "Preslav Nakov", "authors": "Preslav Nakov, Doris Hoogeveen, Llu\\'is M\\`arquez, Alessandro\n  Moschitti, Hamdy Mubarak, Timothy Baldwin, Karin Verspoor", "title": "SemEval-2017 Task 3: Community Question Answering", "comments": "community question answering, question-question similarity,\n  question-comment similarity, answer reranking, Multi-domain Question\n  Duplicate Detection, StackExchange, English, Arabic", "journal-ref": "SemEval-2017", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe SemEval-2017 Task 3 on Community Question Answering. This year,\nwe reran the four subtasks from SemEval-2016:(A) Question-Comment\nSimilarity,(B) Question-Question Similarity,(C) Question-External Comment\nSimilarity, and (D) Rerank the correct answers for a new question in Arabic,\nproviding all the data from 2015 and 2016 for training, and fresh data for\ntesting. Additionally, we added a new subtask E in order to enable\nexperimentation with Multi-domain Question Duplicate Detection in a\nlarger-scale scenario, using StackExchange subforums. A total of 23 teams\nparticipated in the task, and submitted a total of 85 runs (36 primary and 49\ncontrastive) for subtasks A-D. Unfortunately, no teams participated in subtask\nE. A variety of approaches and features were used by the participating systems\nto address the different subtasks. The best systems achieved an official score\n(MAP) of 88.43, 47.22, 15.46, and 61.16 in subtasks A, B, C, and D,\nrespectively. These scores are better than the baselines, especially for\nsubtasks A-C.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 12:57:52 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Nakov", "Preslav", ""], ["Hoogeveen", "Doris", ""], ["M\u00e0rquez", "Llu\u00eds", ""], ["Moschitti", "Alessandro", ""], ["Mubarak", "Hamdy", ""], ["Baldwin", "Timothy", ""], ["Verspoor", "Karin", ""]]}, {"id": "1912.00747", "submitter": "Ross Gruetzemacher", "authors": "Ross Gruetzemacher, Jess Whittlestone", "title": "The Transformative Potential of Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently the concept of transformative AI (TAI) has begun to receive\nattention in the AI policy space. TAI is often framed as an alternative\nformulation to notions of strong AI (e.g. artificial general intelligence or\nsuperintelligence) and reflects increasing consensus that advanced AI which\ndoes not fit these definitions may nonetheless have extreme and long-lasting\nimpacts on society. However, the term TAI is poorly defined and often used\nambiguously. Some use the notion of TAI to describe levels of societal\ntransformation associated with previous 'general purpose technologies' (GPTs)\nsuch as electricity or the internal combustion engine. Others use the term to\nrefer to more drastic levels of transformation comparable to the agricultural\nor industrial revolutions. The notion has also been used much more loosely,\nwith some implying that current AI systems are already having a transformative\nimpact on society. This paper unpacks and analyses the notion of TAI, proposing\na distinction between narrowly transformative AI (NTAI), TAI and radically\ntransformative AI (RTAI), roughly corresponding to associated levels of\nsocietal change. We describe some relevant dimensions associated with each and\ndiscuss what kinds of advances in capabilities they might require. We further\nconsider the relationship between TAI and RTAI and whether we should\nnecessarily expect a period of TAI to precede the emergence of RTAI. This\nanalysis is important as it can help guide discussions among AI policy\nresearchers about how to allocate resources towards mitigating the most extreme\nimpacts of AI and it can bring attention to negative TAI scenarios that are\ncurrently neglected.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 09:37:58 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 14:09:15 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Gruetzemacher", "Ross", ""], ["Whittlestone", "Jess", ""]]}, {"id": "1912.00753", "submitter": "Zhiwen Tang", "authors": "Zhiwen Tang, Grace Hui Yang", "title": "Corpus-Level End-to-End Exploration for Interactive Systems", "comments": "Accepted into AAAI 2020", "journal-ref": null, "doi": "10.1609/aaai.v34i03.5635", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core interest in building Artificial Intelligence (AI) agents is to let\nthem interact with and assist humans. One example is Dynamic Search (DS), which\nmodels the process that a human works with a search engine agent to accomplish\na complex and goal-oriented task. Early DS agents using Reinforcement Learning\n(RL) have only achieved limited success for (1) their lack of direct control\nover which documents to return and (2) the difficulty to recover from wrong\nsearch trajectories. In this paper, we present a novel corpus-level end-to-end\nexploration (CE3) method to address these issues. In our method, an entire text\ncorpus is compressed into a global low-dimensional representation, which\nenables the agent to gain access to the full state and action spaces, including\nthe under-explored areas. We also propose a new form of retrieval function,\nwhose linear approximation allows end-to-end manipulation of documents.\nExperiments on the Text REtrieval Conference (TREC) Dynamic Domain (DD) Track\nshow that CE3 outperforms the state-of-the-art DS systems.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 00:38:56 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 00:30:59 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Tang", "Zhiwen", ""], ["Yang", "Grace Hui", ""]]}, {"id": "1912.00760", "submitter": "Christian Jilek", "authors": "Tobias Tempel, Claudia Nieder\\'ee, Christian Jilek, Andrea Ceroni,\n  Heiko Maus, Yannick Runge, Christian Frings", "title": "Temporarily Unavailable: Memory Inhibition in Cognitive and Computer\n  Science", "comments": "46 pages, 5 figures, preprint, final version published in IWC", "journal-ref": "Interacting with Computers, Volume 31, Issue 3, May 2019, pp.\n  231-249", "doi": "10.1093/iwc/iwz013", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inhibition is one of the core concepts in Cognitive Psychology. The idea of\ninhibitory mechanisms actively weakening representations in the human mind has\ninspired a great number of studies in various research domains. In contrast,\nComputer Science only recently has begun to consider inhibition as a second\nbasic processing quality beside activation. Here, we review psychological\nresearch on inhibition in memory and link the gained insights with the current\nefforts in Computer Science of incorporating inhibitory principles for\noptimizing information retrieval in Personal Information Management. Four\ncommon aspects guide this review in both domains: 1. The purpose of inhibition\nto increase processing efficiency. 2. Its relation to activation. 3. Its links\nto contexts. 4. Its temporariness. In summary, the concept of inhibition has\nbeen used by Computer Science for enhancing software in various ways already.\nYet, we also identify areas for promising future developments of inhibitory\nmechanisms, particularly context inhibition.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 07:21:45 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Tempel", "Tobias", ""], ["Nieder\u00e9e", "Claudia", ""], ["Jilek", "Christian", ""], ["Ceroni", "Andrea", ""], ["Maus", "Heiko", ""], ["Runge", "Yannick", ""], ["Frings", "Christian", ""]]}, {"id": "1912.00761", "submitter": "Alice Xiang", "authors": "Alice Xiang and Inioluwa Deborah Raji", "title": "On the Legal Compatibility of Fairness Definitions", "comments": "6 pages, Workshop on Human-Centric Machine Learning at the 33rd\n  Conference on Neural Information Processing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Past literature has been effective in demonstrating ideological gaps in\nmachine learning (ML) fairness definitions when considering their use in\ncomplex socio-technical systems. However, we go further to demonstrate that\nthese definitions often misunderstand the legal concepts from which they\npurport to be inspired, and consequently inappropriately co-opt legal language.\nIn this paper, we demonstrate examples of this misalignment and discuss the\ndifferences in ML terminology and their legal counterparts, as well as what\nboth the legal and ML fairness communities can learn from these tensions. We\nfocus this paper on U.S. anti-discrimination law since the ML fairness research\ncommunity regularly references terms from this body of law.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 21:28:46 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Xiang", "Alice", ""], ["Raji", "Inioluwa Deborah", ""]]}, {"id": "1912.00782", "submitter": "Ehsan Toreini", "authors": "Ehsan Toreini, Mhairi Aitken, Kovila Coopamootoo, Karen Elliott,\n  Carlos Gonzalez Zelaya, Aad van Moorsel", "title": "The relationship between trust in AI and trustworthy machine learning\n  technologies", "comments": "This submission has been accepted in ACM FAT* 2020 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To build AI-based systems that users and the public can justifiably trust one\nneeds to understand how machine learning technologies impact trust put in these\nservices. To guide technology developments, this paper provides a systematic\napproach to relate social science concepts of trust with the technologies used\nin AI-based services and products. We conceive trust as discussed in the ABI\n(Ability, Benevolence, Integrity) framework and use a recently proposed mapping\nof ABI on qualities of technologies. We consider four categories of machine\nlearning technologies, namely these for Fairness, Explainability, Auditability\nand Safety (FEAS) and discuss if and how these possess the required qualities.\nTrust can be impacted throughout the life cycle of AI-based systems, and we\nintroduce the concept of Chain of Trust to discuss technological needs for\ntrust in different stages of the life cycle. FEAS has obvious relations with\nknown frameworks and therefore we relate FEAS to a variety of international\nPrincipled AI policy and technology frameworks that have emerged in recent\nyears.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 16:36:13 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 11:59:43 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Toreini", "Ehsan", ""], ["Aitken", "Mhairi", ""], ["Coopamootoo", "Kovila", ""], ["Elliott", "Karen", ""], ["Zelaya", "Carlos Gonzalez", ""], ["van Moorsel", "Aad", ""]]}, {"id": "1912.00783", "submitter": "Valentin Robu PhD", "authors": "Valentin Robu, David Flynn, Merlinda Andoni, Maizura Mokhtar", "title": "Consider ethical and social challenges in smart grid research", "comments": "Preprint of paper published in Nature Machine Intelligence, vol. 1\n  (25 Nov. 2019)", "journal-ref": "Nature Machine Intelligence, vol. 1, 25 November 2019", "doi": "10.1038/s42256-019-0120-6", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence and Machine Learning are increasingly seen as key\ntechnologies for building more decentralised and resilient energy grids, but\nresearchers must consider the ethical and social implications of their use\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 11:06:09 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Robu", "Valentin", ""], ["Flynn", "David", ""], ["Andoni", "Merlinda", ""], ["Mokhtar", "Maizura", ""]]}, {"id": "1912.00803", "submitter": "Christopher Goddard", "authors": "Christopher Goddard", "title": "Policies for constraining the behaviour of coalitions of agents in the\n  context of algebraic information theory", "comments": "27 pages", "journal-ref": null, "doi": "10.13140/RG.2.2.22720.28166", "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article takes an oblique sidestep from two previous papers, wherein an\napproach to reformulation of game theory in terms of information theory,\ntopology, as well as a few other notions was indicated. In this document a\ndescription is provided as to how one might determine an approach for an agent\nto choose a policy concerning which actions to take in a game that constrains\nbehaviour of subsidiary agents. It is then demonstrated how these results in\nalgebraic information theory, together with previous investigations in\ngeometric and topological information theory, can be unified into a single\ncohesive framework.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 19:29:46 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Goddard", "Christopher", ""]]}, {"id": "1912.00819", "submitter": "Chandrakant Bothe", "authors": "Chandrakant Bothe, Cornelius Weber, Sven Magg, Stefan Wermter", "title": "EDA: Enriching Emotional Dialogue Acts using an Ensemble of Neural\n  Annotators", "comments": "Proceeding of the LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recognition of emotion and dialogue acts enriches conversational analysis\nand help to build natural dialogue systems. Emotion interpretation makes us\nunderstand feelings and dialogue acts reflect the intentions and performative\nfunctions in the utterances. However, most of the textual and multi-modal\nconversational emotion corpora contain only emotion labels but not dialogue\nacts. To address this problem, we propose to use a pool of various recurrent\nneural models trained on a dialogue act corpus, with and without context. These\nneural models annotate the emotion corpora with dialogue act labels, and an\nensemble annotator extracts the final dialogue act label. We annotated two\naccessible multi-modal emotion corpora: IEMOCAP and MELD. We analyzed the\nco-occurrence of emotion and dialogue act labels and discovered specific\nrelations. For example, Accept/Agree dialogue acts often occur with the Joy\nemotion, Apology with Sadness, and Thanking with Joy. We make the Emotional\nDialogue Acts (EDA) corpus publicly available to the research community for\nfurther study and analysis.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 14:29:22 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 15:31:54 GMT"}, {"version": "v3", "created": "Mon, 16 Mar 2020 14:37:41 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Bothe", "Chandrakant", ""], ["Weber", "Cornelius", ""], ["Magg", "Sven", ""], ["Wermter", "Stefan", ""]]}, {"id": "1912.00864", "submitter": "Makoto Nakatsuji Ph. D.", "authors": "Makoto Nakatsuji, Sohei Okui", "title": "Conclusion-Supplement Answer Generation for Non-Factoid Questions", "comments": "AAAI-2020 (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the goal of conclusion-supplement answer generation for\nnon-factoid questions, which is a critical issue in the field of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), as users often\nrequire supplementary information before accepting a conclusion. The current\nencoder-decoder framework, however, has difficulty generating such answers,\nsince it may become confused when it tries to learn several different long\nanswers to the same non-factoid question. Our solution, called an ensemble\nnetwork, goes beyond single short sentences and fuses logically connected\nconclusion statements and supplementary statements. It extracts the context\nfrom the conclusion decoder's output sequence and uses it to create\nsupplementary decoder states on the basis of an attention mechanism. It also\nassesses the closeness of the question encoder's output sequence and the\nseparate outputs of the conclusion and supplement decoders as well as their\ncombination. As a result, it generates answers that match the questions and\nhave natural-sounding supplementary sequences in line with the context\nexpressed by the conclusion sequence. Evaluations conducted on datasets\nincluding \"Love Advice\" and \"Arts & Humanities\" categories indicate that our\nmodel outputs much more accurate results than the tested baseline models do.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 07:06:25 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Nakatsuji", "Makoto", ""], ["Okui", "Sohei", ""]]}, {"id": "1912.00879", "submitter": "Xiyao Ma", "authors": "Xiyao Ma, Qile Zhu, Yanlin Zhou, Xiaolin Li, Dapeng Wu", "title": "Improving Question Generation with Sentence-level Semantic Matching and\n  Answer Position Inferring", "comments": "Revised version of paper accepted to Thirty-fourth AAAI Conference on\n  Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taking an answer and its context as input, sequence-to-sequence models have\nmade considerable progress on question generation. However, we observe that\nthese approaches often generate wrong question words or keywords and copy\nanswer-irrelevant words from the input. We believe that lacking global question\nsemantics and exploiting answer position-awareness not well are the key root\ncauses. In this paper, we propose a neural question generation model with two\nconcrete modules: sentence-level semantic matching and answer position\ninferring. Further, we enhance the initial state of the decoder by leveraging\nthe answer-aware gated fusion mechanism. Experimental results demonstrate that\nour model outperforms the state-of-the-art (SOTA) models on SQuAD and MARCO\ndatasets. Owing to its generality, our work also improves the existing models\nsignificantly.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 15:57:40 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 21:38:15 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2020 03:13:40 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Ma", "Xiyao", ""], ["Zhu", "Qile", ""], ["Zhou", "Yanlin", ""], ["Li", "Xiaolin", ""], ["Wu", "Dapeng", ""]]}, {"id": "1912.00895", "submitter": "Kehinde Owoeye Mr", "authors": "Kehinde Owoeye", "title": "Learning to smell for wellness", "comments": "10 pages, 1 figure", "journal-ref": "Workshop on AI for Social Good workshop NeurIPS (2019), Vancouver,\n  Canada", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Learning to automatically perceive smell is becoming increasingly important\nwith applications in monitoring the quality of food and drinks for healthy\nliving. In todays age of proliferation of internet of things devices, the\ndeployment of electronic nose otherwise known as smell sensors is on the\nincrease for a variety of olfaction applications with the aid of machine\nlearning models. These models are trained to classify food and drink quality\ninto several categories depending on the granularity of interest. However,\nmodels trained to smell in one domain rarely perform adequately when used in\nanother domain. In this work, we consider a problem where only few samples are\navailable in the target domain and we are faced with the task of leveraging\nknowledge from another domain with relatively abundant data to make reliable\ninference in the target domain. We propose a weakly supervised domain\nadaptation framework where we demonstrate that by building multiple models in a\nmixture of supervised and unsupervised framework, we can generalise effectively\nfrom one domain to another. We evaluate our approach on several datasets of\nbeef cuts and quality collected across different conditions and environments.\nWe empirically show via several experiments that our approach perform\ncompetitively compared to a variety of baselines.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 16:20:26 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Owoeye", "Kehinde", ""]]}, {"id": "1912.00915", "submitter": "Ta-Chung Chi", "authors": "Ta-Chung Chi, Mihail Eric, Seokhwan Kim, Minmin Shen, Dilek\n  Hakkani-tur", "title": "Just Ask:An Interactive Learning Framework for Vision and Language\n  Navigation", "comments": "8 pages, accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the vision and language navigation task, the agent may encounter ambiguous\nsituations that are hard to interpret by just relying on visual information and\nnatural language instructions. We propose an interactive learning framework to\nendow the agent with the ability to ask for users' help in such situations. As\npart of this framework, we investigate multiple learning approaches for the\nagent with different levels of complexity. The simplest model-confusion-based\nmethod lets the agent ask questions based on its confusion, relying on the\npredefined confidence threshold of a next action prediction model. To build on\nthis confusion-based method, the agent is expected to demonstrate more\nsophisticated reasoning such that it discovers the timing and locations to\ninteract with a human. We achieve this goal using reinforcement learning (RL)\nwith a proposed reward shaping term, which enables the agent to ask questions\nonly when necessary. The success rate can be boosted by at least 15% with only\none question asked on average during the navigation. Furthermore, we show that\nthe RL agent is capable of adjusting dynamically to noisy human responses.\nFinally, we design a continual learning strategy, which can be viewed as a data\naugmentation method, for the agent to improve further utilizing its interaction\nhistory with a human. We demonstrate the proposed strategy is substantially\nmore realistic and data-efficient compared to previously proposed\npre-exploration techniques.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 16:45:39 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Chi", "Ta-Chung", ""], ["Eric", "Mihail", ""], ["Kim", "Seokhwan", ""], ["Shen", "Minmin", ""], ["Hakkani-tur", "Dilek", ""]]}, {"id": "1912.00949", "submitter": "Feng Wu", "authors": "Yixiang Wang and Feng Wu", "title": "Multi-Agent Deep Reinforcement Learning with Adaptive Policies", "comments": "arXiv admin note: text overlap with arXiv:1706.02275 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to address one aspect of the non-stationarity\nproblem in multi-agent reinforcement learning (RL), where the other agents may\nalter their policies due to environment changes during execution. This violates\nthe Markov assumption that governs most single-agent RL methods and is one of\nthe key challenges in multi-agent RL. To tackle this, we propose to train\nmultiple policies for each agent and postpone the selection of the best policy\nat execution time. Specifically, we model the environment non-stationarity with\na finite set of scenarios and train policies fitting each scenario. In addition\nto multiple policies, each agent also learns a policy predictor to determine\nwhich policy is the best with its local information. By doing so, each agent is\nable to adapt its policy when the environment changes and consequentially the\nother agents alter their policies during execution. We empirically evaluated\nour method on a variety of common benchmark problems proposed for multi-agent\ndeep RL in the literature. Our experimental results show that the agents\ntrained by our algorithm have better adaptiveness in changing environments and\noutperform the state-of-the-art methods in all the tested environments.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 07:23:37 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Wang", "Yixiang", ""], ["Wu", "Feng", ""]]}, {"id": "1912.00981", "submitter": "Samuel Drews", "authors": "Samuel Drews and Aws Albarghouthi and Loris D'Antoni", "title": "Proving Data-Poisoning Robustness in Decision Trees", "comments": "Changes: revisions to main text for clarity of presentation, and\n  corrections to proofs in the appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are brittle, and small changes in the training data\ncan result in different predictions. We study the problem of proving that a\nprediction is robust to data poisoning, where an attacker can inject a number\nof malicious elements into the training set to influence the learned model. We\ntarget decision-tree models, a popular and simple class of machine learning\nmodels that underlies many complex learning techniques. We present a sound\nverification technique based on abstract interpretation and implement it in a\ntool called Antidote. Antidote abstractly trains decision trees for an\nintractably large space of possible poisoned datasets. Due to the soundness of\nour abstraction, Antidote can produce proofs that, for a given input, the\ncorresponding prediction would not have changed had the training set been\ntampered with or not. We demonstrate the effectiveness of Antidote on a number\nof popular datasets.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 18:20:54 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 22:40:42 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Drews", "Samuel", ""], ["Albarghouthi", "Aws", ""], ["D'Antoni", "Loris", ""]]}, {"id": "1912.01077", "submitter": "Nicholas R. J. Frick", "authors": "Nicholas R. J. Frick, Felix Br\\\"unker, Bj\\\"orn Ross, Stefan Stieglitz", "title": "Towards Successful Collaboration: Design Guidelines for AI-based\n  Services enriching Information Systems in Organisations", "comments": "Proceedings of the 30th Australasian Conference on Information\n  Systems (ACIS), Fremantle, Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information systems (IS) are widely used in organisations to improve business\nperformance. The steady progression in improving technologies like artificial\nintelligence (AI) and the need of securing future success of organisations lead\nto new requirements for IS. This research in progress firstly introduces the\nterm AI-based services (AIBS) describing AI as a component enriching IS aiming\nat collaborating with employees and assisting in the execution of work-related\ntasks. The study derives requirements from ten expert interviews to successful\ndesign AIBS following Design Science Research (DSR). For a successful\ndeployment of AIBS in organisations the D&M IS Success Model will be considered\nto validated requirements within three major dimensions of quality: Information\nQuality, System Quality, and Service Quality. Amongst others, preliminary\nfindings propose that AIBS must be preferably authentic. Further discussion and\nresearch on AIBS is forced, thus, providing first insights on the deployment of\nAIBS in organisations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 21:16:16 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Frick", "Nicholas R. J.", ""], ["Br\u00fcnker", "Felix", ""], ["Ross", "Bj\u00f6rn", ""], ["Stieglitz", "Stefan", ""]]}, {"id": "1912.01094", "submitter": "Kevin Matthew Stangl", "authors": "Avrim Blum, Kevin Stangl", "title": "Recovering from Biased Data: Can Fairness Constraints Improve Accuracy?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple fairness constraints have been proposed in the literature, motivated\nby a range of concerns about how demographic groups might be treated unfairly\nby machine learning classifiers. In this work we consider a different\nmotivation; learning from biased training data. We posit several ways in which\ntraining data may be biased, including having a more noisy or negatively biased\nlabeling process on members of a disadvantaged group, or a decreased prevalence\nof positive or negative examples from the disadvantaged group, or both.\n  Given such biased training data, Empirical Risk Minimization (ERM) may\nproduce a classifier that not only is biased but also has suboptimal accuracy\non the true data distribution. We examine the ability of fairness-constrained\nERM to correct this problem. In particular, we find that the Equal Opportunity\nfairness constraint (Hardt, Price, and Srebro 2016) combined with ERM will\nprovably recover the Bayes Optimal Classifier under a range of bias models. We\nalso consider other recovery methods including reweighting the training data,\nEqualized Odds, and Demographic Parity. These theoretical results provide\nadditional motivation for considering fairness interventions even if an actor\ncares primarily about accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 22:00:14 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Blum", "Avrim", ""], ["Stangl", "Kevin", ""]]}, {"id": "1912.01111", "submitter": "Jayanta Mandi", "authors": "Dipankar Chakrabarti, Neelam Patodia, Udayan Bhattacharya, Indranil\n  Mitra, Satyaki Roy, Jayanta Mandi, Nandini Roy, Prasun Nandy", "title": "Use of Artificial Intelligence to Analyse Risk in Legal Documents for a\n  Better Decision Support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Assessing risk for voluminous legal documents such as request for proposal;\ncontracts is tedious and error prone. We have developed \"risk-o-meter\", a\nframework, based on machine learning and natural language processing to review\nand assess risks of any legal document. Our framework uses Paragraph Vector, an\nunsupervised model to generate vector representation of text. This enables the\nframework to learn contextual relations of legal terms and generate sensible\ncontext aware embedding. The framework then feeds the vector space into a\nsupervised classification algorithm to predict whether a paragraph belongs to a\nper-defined risk category or not. The framework thus extracts risk prone\nparagraphs. This technique efficiently overcomes the limitations of\nkeyword-based search. We have achieved an accuracy of 91% for the risk category\nhaving the largest training dataset. This framework will help organizations\noptimize effort to identify risk from large document base with minimal human\nintervention and thus will help to have risk mitigated sustainable growth. Its\nmachine learning capability makes it scalable to uncover relevant information\nfrom any type of document apart from legal documents, provided the library is\nper-populated and rich.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:07:02 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Chakrabarti", "Dipankar", ""], ["Patodia", "Neelam", ""], ["Bhattacharya", "Udayan", ""], ["Mitra", "Indranil", ""], ["Roy", "Satyaki", ""], ["Mandi", "Jayanta", ""], ["Roy", "Nandini", ""], ["Nandy", "Prasun", ""]]}, {"id": "1912.01160", "submitter": "Hangyu Mao", "authors": "Hangyu Mao, Wulong Liu, Jianye Hao, Jun Luo, Dong Li, Zhengchao Zhang,\n  Jun Wang, Zhen Xiao", "title": "Neighborhood Cognition Consistent Multi-Agent Reinforcement Learning", "comments": "Accepted by AAAI2020 with oral presentation\n  (https://aaai.org/Conferences/AAAI-20/wp-content/uploads/2020/01/AAAI-20-Accepted-Paper-List.pdf).\n  Since AAAI2020 has started, I have the right to distribute this paper on\n  arXiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social psychology and real experiences show that cognitive consistency plays\nan important role to keep human society in order: if people have a more\nconsistent cognition about their environments, they are more likely to achieve\nbetter cooperation. Meanwhile, only cognitive consistency within a neighborhood\nmatters because humans only interact directly with their neighbors. Inspired by\nthese observations, we take the first step to introduce \\emph{neighborhood\ncognitive consistency} (NCC) into multi-agent reinforcement learning (MARL).\nOur NCC design is quite general and can be easily combined with existing MARL\nmethods. As examples, we propose neighborhood cognition consistent deep\nQ-learning and Actor-Critic to facilitate large-scale multi-agent cooperations.\nExtensive experiments on several challenging tasks (i.e., packet routing, wifi\nconfiguration, and Google football player control) justify the superior\nperformance of our methods compared with state-of-the-art MARL approaches.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 02:34:11 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 02:38:59 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Mao", "Hangyu", ""], ["Liu", "Wulong", ""], ["Hao", "Jianye", ""], ["Luo", "Jun", ""], ["Li", "Dong", ""], ["Zhang", "Zhengchao", ""], ["Wang", "Jun", ""], ["Xiao", "Zhen", ""]]}, {"id": "1912.01166", "submitter": "Dongrui Wu", "authors": "He He and Dongrui Wu", "title": "Different Set Domain Adaptation for Brain-Computer Interfaces: A Label\n  Alignment Approach", "comments": "IEEE Trans. on Neural Systems and Rehabilitation Engineering, 2020", "journal-ref": "IEEE Trans. on Neural Systems and Rehabilitation Engineering,\n  28(5), pp. 1091-1108, 2020", "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A brain-computer interface (BCI) system usually needs a long calibration\nsession for each new subject/task to adjust its parameters, which impedes its\ntransition from the laboratory to real-world applications. Domain adaptation,\nwhich leverages labeled data from auxiliary subjects/tasks (source domains),\nhas demonstrated its effectiveness in reducing such calibration effort.\nCurrently, most domain adaptation approaches require the source domains to have\nthe same feature space and label space as the target domain, which limits their\napplications, as the auxiliary data may have different feature spaces and/or\ndifferent label spaces. This paper considers different set domain adaptation\nfor BCIs, i.e., the source and target domains have different label spaces. We\nintroduce a practical setting of different label sets for BCIs, and propose a\nnovel label alignment (LA) approach to align the source label space with the\ntarget label space. It has three desirable properties: 1) LA only needs as few\nas one labeled sample from each class of the target subject; 2) LA can be used\nas a preprocessing step before different feature extraction and classification\nalgorithms; and, 3) LA can be integrated with other domain adaptation\napproaches to achieve even better performance. Experiments on two motor imagery\ndatasets demonstrated the effectiveness of LA.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 02:46:56 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 18:05:56 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 21:11:36 GMT"}, {"version": "v4", "created": "Tue, 10 Mar 2020 02:51:55 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["He", "He", ""], ["Wu", "Dongrui", ""]]}, {"id": "1912.01172", "submitter": "Smitha Milli", "authors": "Ravit Dotan and Smitha Milli", "title": "Value-laden Disciplinary Shifts in Machine Learning", "comments": "Accepted to FAT* 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning models are increasingly used for high-stakes decision\nmaking, scholars have sought to intervene to ensure that such models do not\nencode undesirable social and political values. However, little attention thus\nfar has been given to how values influence the machine learning discipline as a\nwhole. How do values influence what the discipline focuses on and the way it\ndevelops? If undesirable values are at play at the level of the discipline,\nthen intervening on particular models will not suffice to address the problem.\nInstead, interventions at the disciplinary-level are required. This paper\nanalyzes the discipline of machine learning through the lens of philosophy of\nscience. We develop a conceptual framework to evaluate the process through\nwhich types of machine learning models (e.g. neural networks, support vector\nmachines, graphical models) become predominant. The rise and fall of\nmodel-types is often framed as objective progress. However, such disciplinary\nshifts are more nuanced. First, we argue that the rise of a model-type is\nself-reinforcing--it influences the way model-types are evaluated. For example,\nthe rise of deep learning was entangled with a greater focus on evaluations in\ncompute-rich and data-rich environments. Second, the way model-types are\nevaluated encodes loaded social and political values. For example, a greater\nfocus on evaluations in compute-rich and data-rich environments encodes values\nabout centralization of power, privacy, and environmental concerns.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 03:01:27 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Dotan", "Ravit", ""], ["Milli", "Smitha", ""]]}, {"id": "1912.01188", "submitter": "Kevin Lu", "authors": "Kevin Lu, Igor Mordatch, Pieter Abbeel", "title": "Adaptive Online Planning for Continual Lifelong Learning", "comments": "Originally published in NeurIPS Deep RL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study learning control in an online reset-free lifelong learning scenario,\nwhere mistakes can compound catastrophically into the future and the underlying\ndynamics of the environment may change. Traditional model-free policy learning\nmethods have achieved successes in difficult tasks due to their broad\nflexibility, but struggle in this setting, as they can activate failure modes\nearly in their lifetimes which are difficult to recover from and face\nperformance degradation as dynamics change. On the other hand, model-based\nplanning methods learn and adapt quickly, but require prohibitive levels of\ncomputational resources. We present a new algorithm, Adaptive Online Planning\n(AOP), that achieves strong performance in this setting by combining\nmodel-based planning with model-free learning. By approximating the uncertainty\nof the model-free components and the planner performance, AOP is able to call\nupon more extensive planning only when necessary, leading to reduced\ncomputation times, while still gracefully adapting behaviors in the face of\nunpredictable changes in the world -- even when traditional RL fails.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 04:29:01 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 05:28:56 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Lu", "Kevin", ""], ["Mordatch", "Igor", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1912.01217", "submitter": "Carroll Wainwright", "authors": "Carroll L. Wainwright and Peter Eckersley", "title": "SafeLife 1.0: Exploring Side Effects in Complex Environments", "comments": "Updated version was presented at the AAAI SafeAI 2020 Workshop, but\n  now with updated contact info. Previously presented at the 2019 NeurIPS\n  Safety and Robustness in Decision Making Workshop", "journal-ref": "CEUR Workshop Proceedings, 2560 (2020) 117-127", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present SafeLife, a publicly available reinforcement learning environment\nthat tests the safety of reinforcement learning agents. It contains complex,\ndynamic, tunable, procedurally generated levels with many opportunities for\nunsafe behavior. Agents are graded both on their ability to maximize their\nexplicit reward and on their ability to operate safely without unnecessary side\neffects. We train agents to maximize rewards using proximal policy optimization\nand score them on a suite of benchmark levels. The resulting agents are\nperformant but not safe -- they tend to cause large side effects in their\nenvironments -- but they form a baseline against which future safety research\ncan be measured.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 06:44:48 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 05:49:51 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Wainwright", "Carroll L.", ""], ["Eckersley", "Peter", ""]]}, {"id": "1912.01220", "submitter": "Jose Camacho-Collados", "authors": "Zied Bouraoui, Jose Camacho-Collados, Luis Espinosa-Anke and Steven\n  Schockaert", "title": "Modelling Semantic Categories using Conceptual Neighborhood", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While many methods for learning vector space embeddings have been proposed in\nthe field of Natural Language Processing, these methods typically do not\ndistinguish between categories and individuals. Intuitively, if individuals are\nrepresented as vectors, we can think of categories as (soft) regions in the\nembedding space. Unfortunately, meaningful regions can be difficult to\nestimate, especially since we often have few examples of individuals that\nbelong to a given category. To address this issue, we rely on the fact that\ndifferent categories are often highly interdependent. In particular, categories\noften have conceptual neighbors, which are disjoint from but closely related to\nthe given category (e.g.\\ fruit and vegetable). Our hypothesis is that more\naccurate category representations can be learned by relying on the assumption\nthat the regions representing such conceptual neighbors should be adjacent in\nthe embedding space. We propose a simple method for identifying conceptual\nneighbors and then show that incorporating these conceptual neighbors indeed\nleads to more accurate region based representations.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 07:02:38 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Bouraoui", "Zied", ""], ["Camacho-Collados", "Jose", ""], ["Espinosa-Anke", "Luis", ""], ["Schockaert", "Steven", ""]]}, {"id": "1912.01266", "submitter": "Simon Meyer Lauritsen", "authors": "Simon Meyer Lauritsen, Mads Kristensen, Mathias Vassard Olsen, Morten\n  Skaarup Larsen, Katrine Meyer Lauritsen, Marianne Johansson J{\\o}rgensen,\n  Jeppe Lange, Bo Thiesson", "title": "Explainable artificial intelligence model to predict acute critical\n  illness from electronic health records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed an explainable artificial intelligence (AI) early warning score\n(xAI-EWS) system for early detection of acute critical illness. While\nmaintaining a high predictive performance, our system explains to the clinician\non which relevant electronic health records (EHRs) data the prediction is\ngrounded. Acute critical illness is often preceded by deterioration of\nroutinely measured clinical parameters, e.g., blood pressure and heart rate.\nEarly clinical prediction is typically based on manually calculated screening\nmetrics that simply weigh these parameters, such as Early Warning Scores (EWS).\nThe predictive performance of EWSs yields a tradeoff between sensitivity and\nspecificity that can lead to negative outcomes for the patient. Previous work\non EHR-trained AI systems offers promising results with high levels of\npredictive performance in relation to the early, real-time prediction of acute\ncritical illness. However, without insight into the complex decisions by such\nsystem, clinical translation is hindered. In this letter, we present our\nxAI-EWS system, which potentiates clinical translation by accompanying a\nprediction with information on the EHR data explaining it.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 09:52:20 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Lauritsen", "Simon Meyer", ""], ["Kristensen", "Mads", ""], ["Olsen", "Mathias Vassard", ""], ["Larsen", "Morten Skaarup", ""], ["Lauritsen", "Katrine Meyer", ""], ["J\u00f8rgensen", "Marianne Johansson", ""], ["Lange", "Jeppe", ""], ["Thiesson", "Bo", ""]]}, {"id": "1912.01430", "submitter": "Beate Bollig", "authors": "Beate Bollig and Martin Farenholtz", "title": "On the relation between structured $d$-DNNFs and SDDs", "comments": "16 pages. The main result of the paper generalizes one of the results\n  from paper arXiv:1802.04544 where unambiguous nondeterministic OBDDs are\n  considered which can be seen as restricted structured $d$-DNNFs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured $d$-DNNFs and SDDs are restricted negation normal form circuits\nused in knowledge compilation as target languages into which propositional\ntheories are compiled. Structuredness is imposed by so-called vtrees. By\ndefinition SDDs are restricted structured $d$-DNNFs. Beame and Liew (2015) as\nwell as Bova and Szeider (2017) mentioned the question whether structured\n$d$-DNNFs are really more general than SDDs w.r.t. polynomial-size\nrepresentations (w.r.t. the number of Boolean variables the represented\nfunctions are defined on.) The main result in the paper is the proof that a\nfunction can be represented by SDDs of polynomial size if the function and its\ncomplement have polynomial-size structured $d$-DNNFs that respect the same\nvtree.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 12:23:47 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Bollig", "Beate", ""], ["Farenholtz", "Martin", ""]]}, {"id": "1912.01448", "submitter": "Daniel McNamee", "authors": "Daniel McNamee", "title": "Hierarchical model-based policy optimization: from actions to action\n  sequences and back", "comments": "NeurIPS 2019 Optimization Foundations of Reinforcement Learning\n  Workshop. v2: typos fixed, minor edits for improved clarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We develop a normative framework for hierarchical model-based policy\noptimization based on applying second-order methods in the space of all\npossible state-action paths. The resulting natural path gradient performs\npolicy updates in a manner which is sensitive to the long-range correlational\nstructure of the induced stationary state-action densities. We demonstrate that\nthe natural path gradient can be computed exactly given an environment dynamics\nmodel and depends on expressions akin to higher-order successor\nrepresentations. In simulation, we show that the priorization of local policy\nupdates in the resulting policy flow indeed reflects the intuitive state-space\nhierarchy in several toy problems.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 19:01:00 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 13:11:31 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["McNamee", "Daniel", ""]]}, {"id": "1912.01513", "submitter": "Jan Feyereisl", "authors": "Marek Rosa and Olga Afanasjeva and Simon Andersson and Joseph Davidson\n  and Nicholas Guttenberg and Petr Hlubu\\v{c}ek and Martin Poliak and Jaroslav\n  V\\'itku and Jan Feyereisl", "title": "BADGER: Learning to (Learn [Learning Algorithms] through Multi-Agent\n  Communication)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel memory-based multi-agent meta-learning\narchitecture and learning procedure that allows for learning of a shared\ncommunication policy that enables the emergence of rapid adaptation to new and\nunseen environments by learning to learn learning algorithms through\ncommunication. Behavior, adaptation and learning to adapt emerges from the\ninteractions of homogeneous experts inside a single agent. The proposed\narchitecture should allow for generalization beyond the level seen in existing\nmethods, in part due to the use of a single policy shared by all experts within\nthe agent as well as the inherent modularity of 'Badger'.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 16:36:42 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Rosa", "Marek", ""], ["Afanasjeva", "Olga", ""], ["Andersson", "Simon", ""], ["Davidson", "Joseph", ""], ["Guttenberg", "Nicholas", ""], ["Hlubu\u010dek", "Petr", ""], ["Poliak", "Martin", ""], ["V\u00edtku", "Jaroslav", ""], ["Feyereisl", "Jan", ""]]}, {"id": "1912.01519", "submitter": "Martin Thomas Horsch", "authors": "Martin Thomas Horsch and Silvia Chiacchiera and Michael A. Seaton and\n  Ilian T. Todorov and Karel \\v{S}indelka and Martin L\\'isal and Barbara\n  Andreon and Esteban Bayro Kaiser and Gabriele Mogni and Gerhard Goldbeck and\n  Ralf Kunze and Georg Summer and Andreas Fiseni and Hauke Br\\\"uning and Peter\n  Schiffels and Welchy Leite Cavalcanti", "title": "Ontologies for the Virtual Materials Marketplace", "comments": "The Virtual Materials Marketplace (VIMMP) project is funded from the\n  European Union's Horizon 2020 research and innovation programme under grant\n  agreement no. 760907", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Virtual Materials Marketplace (VIMMP) project, which develops an open\nplatform for providing and accessing services related to materials modelling,\nis presented with a focus on its ontology development and data technology\naspects. Within VIMMP, a system of marketplace-level ontologies is developed to\ncharacterize services, models, and interactions between users; the European\nMaterials and Modelling Ontology (EMMO) is employed as a top-level ontology.\nThe ontologies are used to annotate data that are stored in the ZONTAL Space\ncomponent of VIMMP and to support the ingest and retrieval of data and metadata\nat the VIMMP marketplace frontend.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 16:48:05 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 14:08:24 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Horsch", "Martin Thomas", ""], ["Chiacchiera", "Silvia", ""], ["Seaton", "Michael A.", ""], ["Todorov", "Ilian T.", ""], ["\u0160indelka", "Karel", ""], ["L\u00edsal", "Martin", ""], ["Andreon", "Barbara", ""], ["Kaiser", "Esteban Bayro", ""], ["Mogni", "Gabriele", ""], ["Goldbeck", "Gerhard", ""], ["Kunze", "Ralf", ""], ["Summer", "Georg", ""], ["Fiseni", "Andreas", ""], ["Br\u00fcning", "Hauke", ""], ["Schiffels", "Peter", ""], ["Cavalcanti", "Welchy Leite", ""]]}, {"id": "1912.01525", "submitter": "Thibault Gauthier", "authors": "Chad E. Brown, Thibault Gauthier", "title": "Self-Learned Formula Synthesis in Set Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A reinforcement learning algorithm accomplishes the task of synthesizing a\nset-theoretical formula that evaluates to given truth values for given\nassignments.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 16:56:51 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Brown", "Chad E.", ""], ["Gauthier", "Thibault", ""]]}, {"id": "1912.01532", "submitter": "Nicolas Beldiceanu", "authors": "Nicolas Beldiceanu, Mats Carlsson, Claude-Guy Quimper, Maria-Isabel\n  Restrepo-Ruiz", "title": "Classifying Pattern and Feature Properties to Get a $\\Theta(n)$ Checker\n  and Reformulation for Sliding Time-Series Constraints", "comments": "47 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given, a sequence $\\mathcal{X}$ of $n$ variables, a time-series constraint\nctr using the Sum aggregator, and a sliding time-series constraint enforcing\nthe constraint ctr on each sliding window of $\\mathcal{X}$ of $m$ consecutive\nvariables, we describe a $\\Theta(n)$ time complexity checker, as well as a\n$\\Theta(n)$ space complexity reformulation for such sliding constraint.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 17:19:40 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Beldiceanu", "Nicolas", ""], ["Carlsson", "Mats", ""], ["Quimper", "Claude-Guy", ""], ["Restrepo-Ruiz", "Maria-Isabel", ""]]}, {"id": "1912.01557", "submitter": "Xinyang Gu", "authors": "Jingbin Liu, Xinyang Gu, Shuai Liu", "title": "Policy Optimization Reinforcement Learning with Entropy Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy regularization is an important idea in reinforcement learning, with\ngreat success in recent algorithms like Soft Q Network (SQN) and Soft\nActor-Critic (SAC1). In this work, we extend this idea into the on-policy\nrealm. We propose the soft policy gradient theorem (SPGT) for on-policy maximum\nentropy reinforcement learning. With SPGT, a series of new policy optimization\nalgorithms are derived, such as SPG, SA2C, SA3C, SDDPG, STRPO, SPPO, SIMPALA\nand so on. We find that SDDPG is equivalent to SAC1. For policy gradient, the\npolicy network is often represented as a Gaussian distribution with a global\naction variance, which damages the representation capacity. We introduce a\nlocal action variance for policy network and find it can work collaboratively\nwith the idea of entropy regularization. Our method outperforms prior works on\na range of benchmark tasks. Furthermore, our method can be easily extended to\nlarge scale experiment with great stability and parallelism.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 11:01:32 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 03:28:45 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 05:51:08 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Liu", "Jingbin", ""], ["Gu", "Xinyang", ""], ["Liu", "Shuai", ""]]}, {"id": "1912.01592", "submitter": "Sahan Bulathwela", "authors": "Sahan Bulathwela, Maria Perez-Ortiz, Emine Yilmaz and John\n  Shawe-Taylor", "title": "Towards an Integrative Educational Recommender for Lifelong Learners", "comments": "In Proceedings of AAAI Conference on Artificial Intelligence 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most ambitious use cases of computer-assisted learning is to build\na recommendation system for lifelong learning. Most recommender algorithms\nexploit similarities between content and users, overseeing the necessity to\nleverage sensible learning trajectories for the learner. Lifelong learning thus\npresents unique challenges, requiring scalable and transparent models that can\naccount for learner knowledge and content novelty simultaneously, while also\nretaining accurate learners representations for long periods of time. We\nattempt to build a novel educational recommender, that relies on an integrative\napproach combining multiple drivers of learners engagement. Our first step\ntowards this goal is TrueLearn, which models content novelty and background\nknowledge of learners and achieves promising performance while retaining a\nhuman interpretable learner model.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 18:40:44 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Bulathwela", "Sahan", ""], ["Perez-Ortiz", "Maria", ""], ["Yilmaz", "Emine", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "1912.01603", "submitter": "Danijar Hafner", "authors": "Danijar Hafner, Timothy Lillicrap, Jimmy Ba, Mohammad Norouzi", "title": "Dream to Control: Learning Behaviors by Latent Imagination", "comments": "9 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learned world models summarize an agent's experience to facilitate learning\ncomplex behaviors. While learning world models from high-dimensional sensory\ninputs is becoming feasible through deep learning, there are many potential\nways for deriving behaviors from them. We present Dreamer, a reinforcement\nlearning agent that solves long-horizon tasks from images purely by latent\nimagination. We efficiently learn behaviors by propagating analytic gradients\nof learned state values back through trajectories imagined in the compact state\nspace of a learned world model. On 20 challenging visual control tasks, Dreamer\nexceeds existing approaches in data-efficiency, computation time, and final\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 18:57:16 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 17:07:58 GMT"}, {"version": "v3", "created": "Tue, 17 Mar 2020 17:10:58 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Hafner", "Danijar", ""], ["Lillicrap", "Timothy", ""], ["Ba", "Jimmy", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1912.01629", "submitter": "Tarik A. Rashid", "authors": "Danial A. Muhammed, Soran A.M. Saeed, Tarik A. Rashid", "title": "A Simulation Model for Pedestrian Crowd Evacuation Based on Various AI\n  Techniques", "comments": "10 pages", "journal-ref": "Revue d'Intelligence Artificielle, 2019", "doi": "10.18280/ria.330404", "report-no": null, "categories": "cs.MA cs.AI physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper attempts to design an intelligent simulation model for pedestrian\ncrowd evacuation. For this purpose, the cellular automata(CA) was fully\nintegrated with fuzzy logic, the kth nearest neighbors (KNN), and some\nstatistical equations. In this model, each pedestrian was assigned a specific\nspeed, according to his/her physical, biological and emotional features. The\nemergency behavior and evacuation efficiency of each pedestrian were evaluated\nby coupling his or her speed with various elements, such as environment,\npedestrian distribution and familiarity with the exits. These elements all have\ngreat impacts on the evacuation process. Several experiments were carried out\nto verify the performance of the model in different emergency scenarios. The\nresults show that the proposed model can predict the evacuation time and\nemergency behavior in various types of building interiors and pedestrian\ndistributions. The research provides a good reference to the design of building\nevacuation systems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 19:03:57 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Muhammed", "Danial A.", ""], ["Saeed", "Soran A. M.", ""], ["Rashid", "Tarik A.", ""]]}, {"id": "1912.01683", "submitter": "Alexander Turner", "authors": "Alexander Matt Turner, Logan Smith, Rohin Shah, Andrew Critch, Prasad\n  Tadepalli", "title": "Optimal Policies Tend to Seek Power", "comments": "NeurIPS 2021 submission. 12 pages, 42 pages with references and\n  appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some researchers speculate that intelligent reinforcement learning (RL)\nagents would be incentivized to seek resources and power in pursuit of their\nobjectives. Other researchers are skeptical, because human-like power-seeking\ninstincts need not be present in RL agents. To clarify this debate, we develop\nthe first formal theory of the statistical tendencies of optimal policies in\nreinforcement learning. In the context of Markov decision processes, we prove\nthat certain environmental symmetries are sufficient for optimal policies to\ntend to seek power over the environment. These symmetries exist in many\nenvironments in which the agent can be shut down or destroyed. We prove that\nfor most prior beliefs one might have about the agent's reward function\n(including as a special case the situations where the reward function is\nknown), one should expect optimal policies to seek power in these environments.\nThese policies seek power by keeping a range of options available and, when the\ndiscount rate is sufficiently close to 1, by navigating towards larger sets of\npotential terminal states.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 20:45:49 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 19:25:51 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 14:56:27 GMT"}, {"version": "v4", "created": "Tue, 14 Apr 2020 22:13:56 GMT"}, {"version": "v5", "created": "Fri, 5 Jun 2020 22:41:45 GMT"}, {"version": "v6", "created": "Wed, 2 Dec 2020 21:40:39 GMT"}, {"version": "v7", "created": "Tue, 1 Jun 2021 16:59:04 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Turner", "Alexander Matt", ""], ["Smith", "Logan", ""], ["Shah", "Rohin", ""], ["Critch", "Andrew", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1912.01715", "submitter": "Ali Shafti", "authors": "Jonas Tjomsland, Ali Shafti, A. Aldo Faisal", "title": "Human-Robot Collaboration via Deep Reinforcement Learning of Real-World\n  Interactions", "comments": "Presented at NeurIPS'19 Workshop on Robot Learning: Control and\n  Interaction in the Real World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a robotic setup for real-world testing and evaluation of\nhuman-robot and human-human collaborative learning. Leveraging the\nsample-efficiency of the Soft Actor-Critic algorithm, we have implemented a\nrobotic platform able to learn a non-trivial collaborative task with a human\npartner, without pre-training in simulation, and using only 30 minutes of\nreal-world interactions. This enables us to study Human-Robot and Human-Human\ncollaborative learning through real-world interactions. We present preliminary\nresults, showing that state-of-the-art deep learning methods can take\nhuman-robot collaborative learning a step closer to that of humans interacting\nwith each other.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 12:07:23 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Tjomsland", "Jonas", ""], ["Shafti", "Ali", ""], ["Faisal", "A. Aldo", ""]]}, {"id": "1912.01734", "submitter": "Jesse Thomason", "authors": "Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson\n  Han, Roozbeh Mottaghi, Luke Zettlemoyer, and Dieter Fox", "title": "ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday\n  Tasks", "comments": "Computer Vision and Pattern Recognition (CVPR) 2020 ;\n  https://askforalfred.com/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ALFRED (Action Learning From Realistic Environments and\nDirectives), a benchmark for learning a mapping from natural language\ninstructions and egocentric vision to sequences of actions for household tasks.\nALFRED includes long, compositional tasks with non-reversible state changes to\nshrink the gap between research benchmarks and real-world applications. ALFRED\nconsists of expert demonstrations in interactive visual environments for 25k\nnatural language directives. These directives contain both high-level goals\nlike \"Rinse off a mug and place it in the coffee maker.\" and low-level language\ninstructions like \"Walk to the coffee maker on the right.\" ALFRED tasks are\nmore complex in terms of sequence length, action space, and language than\nexisting vision-and-language task datasets. We show that a baseline model based\non recent embodied vision-and-language tasks performs poorly on ALFRED,\nsuggesting that there is significant room for developing innovative grounded\nvisual language understanding models with this benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 23:18:59 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 01:18:33 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Shridhar", "Mohit", ""], ["Thomason", "Jesse", ""], ["Gordon", "Daniel", ""], ["Bisk", "Yonatan", ""], ["Han", "Winson", ""], ["Mottaghi", "Roozbeh", ""], ["Zettlemoyer", "Luke", ""], ["Fox", "Dieter", ""]]}, {"id": "1912.01741", "submitter": "Marco Sim\\~oes", "authors": "Marco A. C. Sim\\~oes, Robson Marinho da Silva and Tatiane Nogueira", "title": "A Dataset Schema for Cooperative Learning from Demonstration in\n  Multi-robots Systems", "comments": "This is a pre-print of an article published in the Journal of\n  Intelligent & Robotic Systems. The final authenticated version will be\n  available online at: https://doi. org/10.1007/s10846-019-01123-w", "journal-ref": null, "doi": "10.1007/s10846-019-01123-w", "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Multi-Agent Systems (MASs) have been used to solve complex problems that\ndemand intelligent agents working together to reach the desired goals. These\nAgents should effectively synchronize their individual behaviors so that they\ncan act as a team in a coordinated manner to achieve the common goal of the\nwhole system. One of the main issues in MASs is the agents' coordination, being\ncommon domain experts observing MASs execution disapprove agents' decisions.\nEven if the MAS was designed using the best methods and tools for agents'\ncoordination, this difference of decisions between experts and MAS is\nconfirmed. Therefore, this paper proposes a new dataset schema to support\nlearning the coordinated behavior in MASs from demonstration. The results of\nthe proposed solution are validated in a Multi-Robot System (MRS) organizing a\ncollection of new cooperative plans recommendations from the demonstration by\ndomain experts.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 23:42:24 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Sim\u00f5es", "Marco A. C.", ""], ["da Silva", "Robson Marinho", ""], ["Nogueira", "Tatiane", ""]]}, {"id": "1912.01752", "submitter": "Benjamin Toms", "authors": "Benjamin A. Toms, Elizabeth A. Barnes, Imme Ebert-Uphoff", "title": "Physically Interpretable Neural Networks for the Geosciences:\n  Applications to Earth System Variability", "comments": "The second version of this manuscript is currently under review at\n  the Journal of Advances in Modeling Earth Systems (JAMES)", "journal-ref": null, "doi": "10.1029/2019MS002002", "report-no": null, "categories": "physics.ao-ph cs.AI physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have become increasingly prevalent within the geosciences,\nalthough a common limitation of their usage has been a lack of methods to\ninterpret what the networks learn and how they make decisions. As such, neural\nnetworks have often been used within the geosciences to most accurately\nidentify a desired output given a set of inputs, with the interpretation of\nwhat the network learns used as a secondary metric to ensure the network is\nmaking the right decision for the right reason. Neural network interpretation\ntechniques have become more advanced in recent years, however, and we therefore\npropose that the ultimate objective of using a neural network can also be the\ninterpretation of what the network has learned rather than the output itself.\n  We show that the interpretation of neural networks can enable the discovery\nof scientifically meaningful connections within geoscientific data. In\nparticular, we use two methods for neural network interpretation called\nbackwards optimization and layerwise relevance propagation, both of which\nproject the decision pathways of a network back onto the original input\ndimensions. To the best of our knowledge, LRP has not yet been applied to\ngeoscientific research, and we believe it has great potential in this area. We\nshow how these interpretation techniques can be used to reliably infer\nscientifically meaningful information from neural networks by applying them to\ncommon climate patterns. These results suggest that combining interpretable\nneural networks with novel scientific hypotheses will open the door to many new\navenues in neural network-related geoscience research.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 00:37:17 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 05:43:18 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Toms", "Benjamin A.", ""], ["Barnes", "Elizabeth A.", ""], ["Ebert-Uphoff", "Imme", ""]]}, {"id": "1912.01795", "submitter": "Fanchao Qi", "authors": "Fanchao Qi, Liang Chang, Maosong Sun, Sicong Ouyang, Zhiyuan Liu", "title": "Towards Building a Multilingual Sememe Knowledge Base: Predicting\n  Sememes for BabelNet Synsets", "comments": "Accepted by AAAI Conference on Artificial Intelligence 2020 for oral\n  presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sememe is defined as the minimum semantic unit of human languages. Sememe\nknowledge bases (KBs), which contain words annotated with sememes, have been\nsuccessfully applied to many NLP tasks. However, existing sememe KBs are built\non only a few languages, which hinders their widespread utilization. To address\nthe issue, we propose to build a unified sememe KB for multiple languages based\non BabelNet, a multilingual encyclopedic dictionary. We first build a dataset\nserving as the seed of the multilingual sememe KB. It manually annotates\nsememes for over $15$ thousand synsets (the entries of BabelNet). Then, we\npresent a novel task of automatic sememe prediction for synsets, aiming to\nexpand the seed dataset into a usable KB. We also propose two simple and\neffective models, which exploit different information of synsets. Finally, we\nconduct quantitative and qualitative analyses to explore important factors and\ndifficulties in the task. All the source code and data of this work can be\nobtained on https://github.com/thunlp/BabelNet-Sememe-Prediction.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 04:39:32 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Qi", "Fanchao", ""], ["Chang", "Liang", ""], ["Sun", "Maosong", ""], ["Ouyang", "Sicong", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "1912.01819", "submitter": "Yanou Ramon", "authors": "Yanou Ramon, David Martens, Foster Provost, Theodoros Evgeniou", "title": "Counterfactual Explanation Algorithms for Behavioral and Textual Data", "comments": "24 pages, 7 figures, currently under review", "journal-ref": null, "doi": "10.1007/s11634-020-00418-3", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the interpretability of predictive systems that use high-dimensonal\nbehavioral and textual data. Examples include predicting product interest based\non online browsing data and detecting spam emails or objectionable web content.\nRecently, counterfactual explanations have been proposed for generating insight\ninto model predictions, which focus on what is relevant to a particular\ninstance. Conducting a complete search to compute counterfactuals is very\ntime-consuming because of the huge dimensionality. To our knowledge, for\nbehavioral and text data, only one model-agnostic heuristic algorithm (SEDC)\nfor finding counterfactual explanations has been proposed in the literature.\nHowever, there may be better algorithms for finding counterfactuals quickly.\nThis study aligns the recently proposed Linear Interpretable Model-agnostic\nExplainer (LIME) and Shapley Additive Explanations (SHAP) with the notion of\ncounterfactual explanations, and empirically benchmarks their effectiveness and\nefficiency against SEDC using a collection of 13 data sets. Results show that\nLIME-Counterfactual (LIME-C) and SHAP-Counterfactual (SHAP-C) have low and\nstable computation times, but mostly, they are less efficient than SEDC.\nHowever, for certain instances on certain data sets, SEDC's run time is\ncomparably large. With regard to effectiveness, LIME-C and SHAP-C find\nreasonable, if not always optimal, counterfactual explanations. SHAP-C,\nhowever, seems to have difficulties with highly unbalanced data. Because of its\ngood overall performance, LIME-C seems to be a favorable alternative to SEDC,\nwhich failed for some nonlinear models to find counterfactuals because of the\nparticular heuristic search algorithm it uses. A main upshot of this paper is\nthat there is a good deal of room for further research. For example, we propose\nalgorithmic adjustments that are direct upshots of the paper's findings.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 06:48:34 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ramon", "Yanou", ""], ["Martens", "David", ""], ["Provost", "Foster", ""], ["Evgeniou", "Theodoros", ""]]}, {"id": "1912.01876", "submitter": "Munyque Mittelmann", "authors": "Munyque Mittelmann, Laurent Perrussel", "title": "Game Description Logic with Integers: A GDL Numerical Extension", "comments": "23 pages, extended version of the paper published at the conference\n  FoIKS 2020 (11th International Symposium on Foundations of Information and\n  Knowledge Systems)", "journal-ref": null, "doi": "10.1007/978-3-030-39951-1_12", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems can be viewed as games, where one or more agents try to ensure\nthat certain objectives hold no matter the behavior from the environment and\nother agents. In recent years, a number of logical formalisms have been\nproposed for specifying games among which the Game Description Language (GDL)\nwas established as the official language for General Game Playing. Although\nnumbers are recurring in games, the description of games with numerical\nfeatures in GDL requires the enumeration from all possible numeric values and\nthe relation among them. Thereby, in this paper, we introduce the Game\nDescription Logic with Integers (GDLZ) to describe games with numerical\nvariables, numerical parameters, as well as to perform numerical comparisons.\nWe compare our approach with GDL and show that when describing the same game,\nGDLZ is more compact.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 10:13:33 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Mittelmann", "Munyque", ""], ["Perrussel", "Laurent", ""]]}, {"id": "1912.02059", "submitter": "Zheyuan Wang", "authors": "Zheyuan Wang and Matthew Gombolay", "title": "Learning to Dynamically Coordinate Multi-Robot Teams in Graph Attention\n  Networks", "comments": "This paper has been extended to an article in IEEE Robotics and\n  Automation Letters (DOI: 10.1109/LRA.2020.3002198)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing interest in integrating advanced robotics within manufacturing has\nspurred a renewed concentration in developing real-time scheduling solutions to\ncoordinate human-robot collaboration in this environment. Traditionally, the\nproblem of scheduling agents to complete tasks with temporal and spatial\nconstraints has been approached either with exact algorithms, which are\ncomputationally intractable for large-scale, dynamic coordination, or\napproximate methods that require domain experts to craft heuristics for each\napplication. We seek to overcome the limitations of these conventional methods\nby developing a novel graph attention network formulation to automatically\nlearn features of scheduling problems to allow their deployment. To learn\neffective policies for combinatorial optimization problems via machine\nlearning, we combine imitation learning on smaller problems with deep\nQ-learning on larger problems, in a non-parametric framework, to allow for\nfast, near-optimal scheduling of robot teams. We show that our network-based\npolicy finds at least twice as many solutions over prior state-of-the-art\nmethods in all testing scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 15:32:53 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 20:20:33 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Wang", "Zheyuan", ""], ["Gombolay", "Matthew", ""]]}, {"id": "1912.02074", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Bo Dai, Ilya Kostrikov, Yinlam Chow, Lihong Li, Dale\n  Schuurmans", "title": "AlgaeDICE: Policy Gradient from Arbitrary Experience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world applications of reinforcement learning (RL), interactions\nwith the environment are limited due to cost or feasibility. This presents a\nchallenge to traditional RL algorithms since the max-return objective involves\nan expectation over on-policy samples. We introduce a new formulation of\nmax-return optimization that allows the problem to be re-expressed by an\nexpectation over an arbitrary behavior-agnostic and off-policy data\ndistribution. We first derive this result by considering a regularized version\nof the dual max-return objective before extending our findings to unregularized\nobjectives through the use of a Lagrangian formulation of the linear\nprogramming characterization of Q-values. We show that, if auxiliary dual\nvariables of the objective are optimized, then the gradient of the off-policy\nobjective is exactly the on-policy policy gradient, without any use of\nimportance weighting. In addition to revealing the appealing theoretical\nproperties of this approach, we also show that it delivers good practical\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 16:06:10 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Nachum", "Ofir", ""], ["Dai", "Bo", ""], ["Kostrikov", "Ilya", ""], ["Chow", "Yinlam", ""], ["Li", "Lihong", ""], ["Schuurmans", "Dale", ""]]}, {"id": "1912.02102", "submitter": "Amulya Yadav", "authors": "Amulya Yadav", "title": "Artificial Intelligence for Low-Resource Communities: Influence\n  Maximization in an Uncertain World", "comments": "PhD thesis, USC (2018). arXiv admin note: text overlap with\n  arXiv:1806.07757 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential of Artificial Intelligence (AI) to tackle challenging problems\nthat afflict society is enormous, particularly in the areas of healthcare,\nconservation and public safety and security. Many problems in these domains\ninvolve harnessing social networks of under-served communities to enable\npositive change, e.g., using social networks of homeless youth to raise\nawareness about Human Immunodeficiency Virus (HIV) and other STDs.\nUnfortunately, most of these real-world problems are characterized by\nuncertainties about social network structure and influence models, and previous\nresearch in AI fails to sufficiently address these uncertainties. This thesis\naddresses these shortcomings by advancing the state-of-the-art to a new\ngeneration of algorithms for interventions in social networks. In particular,\nthis thesis describes the design and development of new influence maximization\nalgorithms which can handle various uncertainties that commonly exist in\nreal-world social networks. These algorithms utilize techniques from sequential\nplanning problems and social network theory to develop new kinds of AI\nalgorithms. Further, this thesis also demonstrates the real-world impact of\nthese algorithms by describing their deployment in three pilot studies to\nspread awareness about HIV among actual homeless youth in Los Angeles. This\nrepresents one of the first-ever deployments of computer science based\ninfluence maximization algorithms in this domain. Our results show that our AI\nalgorithms improved upon the state-of-the-art by 160% in the real-world. We\ndiscuss research and implementation challenges faced in deploying these\nalgorithms, and lessons that can be gleaned for future deployment of such\nalgorithms. The positive results from these deployments illustrate the enormous\npotential of AI in addressing societally relevant problems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 02:11:50 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Yadav", "Amulya", ""]]}, {"id": "1912.02105", "submitter": "Amulya Yadav", "authors": "Amulya Yadav", "title": "Influence Maximization for Social Good: Use of Social Networks in Low\n  Resource Communities", "comments": "arXiv admin note: substantial text overlap with arXiv:1602.00165", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis proposal makes the following technical contributions: (i) we\nprovide a definition of the Dynamic Influence Maximization Under Uncertainty\n(or DIME) problem, which models the problem faced by homeless shelters\naccurately; (ii) we propose a novel Partially Observable Markov Decision\nProcess (POMDP) model for solving the DIME problem; (iii) we design two\nscalable POMDP algorithms (PSINET and HEALER) for solving the DIME problem,\nsince conventional POMDP solvers fail to scale up to sizes of interest; and\n(iv) we test our algorithms effectiveness in the real world by conducting a\npilot study with actual homeless youth in Los Angeles. The success of this\npilot (as explained later) shows the promise of using influence maximization\nfor social good on a larger scale.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 02:27:44 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Yadav", "Amulya", ""]]}, {"id": "1912.02127", "submitter": "Harsh Thakkar", "authors": "Renzo Angles, Harsh Thakkar, Dominik Tomaszuk", "title": "Directly Mapping RDF Databases to Property Graph Databases", "comments": "This work has been accepted and published at the IEEE Access Journal\n  DOI: 10.1109/ACCESS.2020.2993117", "journal-ref": "IEEE Access Volume 8, 2020", "doi": "10.1109/ACCESS.2020.2993117", "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  RDF triplestores and property graph databases are two approaches for data\nmanagement which are based on modeling, storing, and querying graph-like data.\nIn spite of such common principles, they present special features that\ncomplicate the task of database interoperability. While there exist some\nmethods to transform RDF graphs into property graphs, and vice versa, they lack\ncompatibility and a solid formal foundation. This paper presents three direct\nmappings (schema-dependent and schema-independent) for transforming an RDF\ndatabase into a property graph database, including data and schema. We show\nthat two of the proposed mappings satisfy the properties of semantics\npreservation and information preservation. The existence of both mappings\nallows us to conclude that the property graph data model subsumes the\ninformation capacity of the RDF data model.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 17:20:33 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 18:43:11 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Angles", "Renzo", ""], ["Thakkar", "Harsh", ""], ["Tomaszuk", "Dominik", ""]]}, {"id": "1912.02150", "submitter": "Reazul Hasan Russel", "authors": "Reazul Hasan Russel", "title": "A Probabilistic Approach to Satisfiability of Propositional Logic\n  Formulae", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a version of WalkSAT algorithm, named as BetaWalkSAT. This method\nuses probabilistic reasoning for biasing the starting state of the local search\nalgorithm. Beta distribution is used to model the belief over boolean values of\nthe literals. Our results suggest that, the proposed BetaWalkSAT algorithm can\noutperform other uninformed local search approaches for complex boolean\nsatisfiability problems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 17:58:28 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Russel", "Reazul Hasan", ""]]}, {"id": "1912.02164", "submitter": "Rosanne Liu", "authors": "Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane Hung, Eric Frank,\n  Piero Molino, Jason Yosinski, Rosanne Liu", "title": "Plug and Play Language Models: A Simple Approach to Controlled Text\n  Generation", "comments": "ICLR 2020 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large transformer-based language models (LMs) trained on huge text corpora\nhave shown unparalleled generation capabilities. However, controlling\nattributes of the generated language (e.g. switching topic or sentiment) is\ndifficult without modifying the model architecture or fine-tuning on\nattribute-specific data and entailing the significant cost of retraining. We\npropose a simple alternative: the Plug and Play Language Model (PPLM) for\ncontrollable language generation, which combines a pretrained LM with one or\nmore simple attribute classifiers that guide text generation without any\nfurther training of the LM. In the canonical scenario we present, the attribute\nmodels are simple classifiers consisting of a user-specified bag of words or a\nsingle learned layer with 100,000 times fewer parameters than the LM. Sampling\nentails a forward and backward pass in which gradients from the attribute model\npush the LM's hidden activations and thus guide the generation. Model samples\ndemonstrate control over a range of topics and sentiment styles, and extensive\nautomated and human annotated evaluations show attribute alignment and fluency.\nPPLMs are flexible in that any combination of differentiable attribute models\nmay be used to steer text generation, which will allow for diverse and creative\napplications beyond the examples given in this paper.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 18:32:15 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 01:02:25 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 06:05:58 GMT"}, {"version": "v4", "created": "Tue, 3 Mar 2020 05:33:49 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Dathathri", "Sumanth", ""], ["Madotto", "Andrea", ""], ["Lan", "Janice", ""], ["Hung", "Jane", ""], ["Frank", "Eric", ""], ["Molino", "Piero", ""], ["Yosinski", "Jason", ""], ["Liu", "Rosanne", ""]]}, {"id": "1912.02241", "submitter": "Jing Bi", "authors": "Jing Bi, Vikas Dhiman, Tianyou Xiao, Chenliang Xu", "title": "Learning from Interventions using Hierarchical Policies for Safe\n  Learning", "comments": "Accepted for publication at the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from Demonstrations (LfD) via Behavior Cloning (BC) works well on\nmultiple complex tasks. However, a limitation of the typical LfD approach is\nthat it requires expert demonstrations for all scenarios, including those in\nwhich the algorithm is already well-trained. The recently proposed Learning\nfrom Interventions (LfI) overcomes this limitation by using an expert overseer.\nThe expert overseer only intervenes when it suspects that an unsafe action is\nabout to be taken. Although LfI significantly improves over LfD, the\nstate-of-the-art LfI fails to account for delay caused by the expert's reaction\ntime and only learns short-term behavior. We address these limitations by 1)\ninterpolating the expert's interventions back in time, and 2) by splitting the\npolicy into two hierarchical levels, one that generates sub-goals for the\nfuture and another that generates actions to reach those desired sub-goals.\nThis sub-goal prediction forces the algorithm to learn long-term behavior while\nalso being robust to the expert's reaction time. Our experiments show that LfI\nusing sub-goals in a hierarchical policy framework trains faster and achieves\nbetter asymptotic performance than typical LfD.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 20:28:51 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Bi", "Jing", ""], ["Dhiman", "Vikas", ""], ["Xiao", "Tianyou", ""], ["Xu", "Chenliang", ""]]}, {"id": "1912.02258", "submitter": "Raj Dasgupta", "authors": "Prithviraj Dasgupta and Joseph B. Collins", "title": "A Survey of Game Theoretic Approaches for Adversarial Machine Learning\n  in Cybersecurity Tasks", "comments": "13 pages, 2 figures, 1 table", "journal-ref": "AI Magazine, 40(2), 31-43 (2019)", "doi": "10.1609/aimag.v40i2.2847", "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques are currently used extensively for automating\nvarious cybersecurity tasks. Most of these techniques utilize supervised\nlearning algorithms that rely on training the algorithm to classify incoming\ndata into different categories, using data encountered in the relevant domain.\nA critical vulnerability of these algorithms is that they are susceptible to\nadversarial attacks where a malicious entity called an adversary deliberately\nalters the training data to misguide the learning algorithm into making\nclassification errors. Adversarial attacks could render the learning algorithm\nunsuitable to use and leave critical systems vulnerable to cybersecurity\nattacks. Our paper provides a detailed survey of the state-of-the-art\ntechniques that are used to make a machine learning algorithm robust against\nadversarial attacks using the computational framework of game theory. We also\ndiscuss open problems and challenges and possible directions for further\nresearch that would make deep machine learning-based systems more robust and\nreliable for cybersecurity tasks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 21:42:15 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Dasgupta", "Prithviraj", ""], ["Collins", "Joseph B.", ""]]}, {"id": "1912.02288", "submitter": "Hengyuan Hu", "authors": "Hengyuan Hu, Jakob N Foerster", "title": "Simplified Action Decoder for Deep Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years we have seen fast progress on a number of benchmark problems\nin AI, with modern methods achieving near or super human performance in Go,\nPoker and Dota. One common aspect of all of these challenges is that they are\nby design adversarial or, technically speaking, zero-sum. In contrast to these\nsettings, success in the real world commonly requires humans to collaborate and\ncommunicate with others, in settings that are, at least partially, cooperative.\nIn the last year, the card game Hanabi has been established as a new benchmark\nenvironment for AI to fill this gap. In particular, Hanabi is interesting to\nhumans since it is entirely focused on theory of mind, i.e., the ability to\neffectively reason over the intentions, beliefs and point of view of other\nagents when observing their actions. Learning to be informative when observed\nby others is an interesting challenge for Reinforcement Learning (RL):\nFundamentally, RL requires agents to explore in order to discover good\npolicies. However, when done naively, this randomness will inherently make\ntheir actions less informative to others during training. We present a new deep\nmulti-agent RL method, the Simplified Action Decoder (SAD), which resolves this\ncontradiction exploiting the centralized training phase. During training SAD\nallows other agents to not only observe the (exploratory) action chosen, but\nagents instead also observe the greedy action of their team mates. By combining\nthis simple intuition with best practices for multi-agent learning, SAD\nestablishes a new SOTA for learning methods for 2-5 players on the self-play\npart of the Hanabi challenge. Our ablations show the contributions of SAD\ncompared with the best practice components. All of our code and trained agents\nare available at https://github.com/facebookresearch/Hanabi_SAD.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 22:34:54 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 05:32:45 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Hu", "Hengyuan", ""], ["Foerster", "Jakob N", ""]]}, {"id": "1912.02318", "submitter": "Adam Lerer", "authors": "Adam Lerer, Hengyuan Hu, Jakob Foerster, Noam Brown", "title": "Improving Policies via Search in Cooperative Partially Observable Games", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent superhuman results in games have largely been achieved in a variety of\nzero-sum settings, such as Go and Poker, in which agents need to compete\nagainst others. However, just like humans, real-world AI systems have to\ncoordinate and communicate with other agents in cooperative partially\nobservable environments as well. These settings commonly require participants\nto both interpret the actions of others and to act in a way that is informative\nwhen being interpreted. Those abilities are typically summarized as theory f\nmind and are seen as crucial for social interactions. In this paper we propose\ntwo different search techniques that can be applied to improve an arbitrary\nagreed-upon policy in a cooperative partially observable game. The first one,\nsingle-agent search, effectively converts the problem into a single agent\nsetting by making all but one of the agents play according to the agreed-upon\npolicy. In contrast, in multi-agent search all agents carry out the same\ncommon-knowledge search procedure whenever doing so is computationally\nfeasible, and fall back to playing according to the agreed-upon policy\notherwise. We prove that these search procedures are theoretically guaranteed\nto at least maintain the original performance of the agreed-upon policy (up to\na bounded approximation error). In the benchmark challenge problem of Hanabi,\nour search technique greatly improves the performance of every agent we tested\nand when applied to a policy trained using RL achieves a new state-of-the-art\nscore of 24.61 / 25 in the game, compared to a previous-best of 24.08 / 25.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 00:14:34 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Lerer", "Adam", ""], ["Hu", "Hengyuan", ""], ["Foerster", "Jakob", ""], ["Brown", "Noam", ""]]}, {"id": "1912.02346", "submitter": "Grace Hui Yang", "authors": "Grace Hui Yang", "title": "Information Retrieval and Its Sister Disciplines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a summary graph to show the relationships between\nInformation Retrieval (IR) and other related disciplines. The figure tells the\nkey differences between them and the conditions under which one would\ntransition into another.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 02:03:30 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Yang", "Grace Hui", ""]]}, {"id": "1912.02368", "submitter": "Abdul Rahman Kreidieh", "authors": "Abdul Rahman Kreidieh, Glen Berseth, Brandon Trabucco, Samyak\n  Parajuli, Sergey Levine, Alexandre M. Bayen", "title": "Inter-Level Cooperation in Hierarchical Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical models for deep reinforcement learning (RL) have emerged as\npowerful methods for generating meaningful control strategies in difficult long\ntime horizon tasks. Training of said hierarchical models, however, continue to\nsuffer from instabilities that limit their applicability. In this paper, we\naddress instabilities that arise from the concurrent optimization of\ngoal-assignment and goal-achievement policies. Drawing connections between this\nconcurrent optimization scheme and communication and cooperation in multi-agent\nRL, we redefine the standard optimization procedure to explicitly promote\ncooperation between these disparate tasks. Our method is demonstrated to\nachieve superior results to existing techniques in a set of difficult long time\nhorizon tasks, and serves to expand the scope of solvable tasks by hierarchical\nreinforcement learning. Videos of the results are available at:\nhttps://sites.google.com/berkeley.edu/cooperative-hrl.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 03:56:44 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 08:46:11 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Kreidieh", "Abdul Rahman", ""], ["Berseth", "Glen", ""], ["Trabucco", "Brandon", ""], ["Parajuli", "Samyak", ""], ["Levine", "Sergey", ""], ["Bayen", "Alexandre M.", ""]]}, {"id": "1912.02390", "submitter": "Vasant Honavar", "authors": "Sanghack Lee and Vasant Honavar", "title": "Towards Robust Relational Causal Discovery", "comments": "14 pages", "journal-ref": "Proceedings of the 35th Conference on Uncertainty in Artificial\n  Intelligence, UAI 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning causal relationships from relational\ndata. Existing approaches rely on queries to a relational conditional\nindependence (RCI) oracle to establish and orient causal relations in such a\nsetting. In practice, queries to a RCI oracle have to be replaced by reliable\ntests for RCI against available data. Relational data present several unique\nchallenges in testing for RCI. We study the conditions under which traditional\niid-based conditional independence (CI) tests yield reliable answers to RCI\nqueries against relational data. We show how to conduct CI tests against\nrelational data to robustly recover the underlying relational causal structure.\nResults of our experiments demonstrate the effectiveness of our proposed\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 05:13:22 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Lee", "Sanghack", ""], ["Honavar", "Vasant", ""]]}, {"id": "1912.02523", "submitter": "Eduardo Soares Mr", "authors": "Plamen Angelov, Eduardo Soares", "title": "Towards Explainable Deep Neural Networks (xDNN)", "comments": "Preprint submitted to the Neural Networks Journal for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an elegant solution that is directly addressing the\nbottlenecks of the traditional deep learning approaches and offers a clearly\nexplainable internal architecture that can outperform the existing methods,\nrequires very little computational resources (no need for GPUs) and short\ntraining times (in the order of seconds). The proposed approach, xDNN is using\nprototypes. Prototypes are actual training data samples (images), which are\nlocal peaks of the empirical data distribution called typicality as well as of\nthe data density. This generative model is identified in a closed form and\nequates to the pdf but is derived automatically and entirely from the training\ndata with no user- or problem-specific thresholds, parameters or intervention.\nThe proposed xDNN offers a new deep learning architecture that combines\nreasoning and learning in a synergy. It is non-iterative and non-parametric,\nwhich explains its efficiency in terms of time and computational resources.\nFrom the user perspective, the proposed approach is clearly understandable to\nhuman users. We tested it on some well-known benchmark data sets such as iRoads\nand Caltech-256. xDNN outperforms the other methods including deep learning in\nterms of accuracy, time to train and offers a clearly explainable classifier.\nIn fact, the result on the very hard Caltech-256 problem (which has 257\nclasses) represents a world record.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 12:01:15 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Angelov", "Plamen", ""], ["Soares", "Eduardo", ""]]}, {"id": "1912.02532", "submitter": "Jan Malte Lichtenberg", "authors": "Jan Malte Lichtenberg and \\\"Ozg\\\"ur \\c{S}im\\c{s}ek", "title": "Iterative Policy-Space Expansion in Reinforcement Learning", "comments": "Workshop on Biological and Artificial Reinforcement Learning at the\n  33rd Conference on Neural Information Processing Systems (NeurIPS 2019),\n  Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans and animals solve a difficult problem much more easily when they are\npresented with a sequence of problems that starts simple and slowly increases\nin difficulty. We explore this idea in the context of reinforcement learning.\nRather than providing the agent with an externally provided curriculum of\nprogressively more difficult tasks, the agent solves a single task utilizing a\ndecreasingly constrained policy space. The algorithm we propose first learns to\ncategorize features into positive and negative before gradually learning a more\nrefined policy. Experimental results in Tetris demonstrate superior learning\nrate of our approach when compared to existing algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 12:32:15 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Lichtenberg", "Jan Malte", ""], ["\u015eim\u015fek", "\u00d6zg\u00fcr", ""]]}, {"id": "1912.02535", "submitter": "Markus Wagner", "authors": "Aldeida Aleti, Mark Wallace, Markus Wagner", "title": "Is perturbation an effective restart strategy?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Premature convergence can be detrimental to the performance of search\nmethods, which is why many search algorithms include restart strategies to deal\nwith it. While it is common to perturb the incumbent solution with\ndiversification steps of various sizes with the hope that the search method\nwill find a new basin of attraction leading to a better local optimum, it is\nusually not clear how big the perturbation step should be. We introduce a new\nproperty of fitness landscapes termed \"Neighbours with Similar Fitness\" and we\ndemonstrate that the effectiveness of a restart strategy depends on this\nproperty.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 12:33:40 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Aleti", "Aldeida", ""], ["Wallace", "Mark", ""], ["Wagner", "Markus", ""]]}, {"id": "1912.02552", "submitter": "Maor Gaon", "authors": "Maor Gaon and Ronen I. Brafman", "title": "Reinforcement Learning with Non-Markovian Rewards", "comments": "To Appear in AAAI 2020", "journal-ref": null, "doi": null, "report-no": "Report-no: AAAI20", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard RL world model is that of a Markov Decision Process (MDP). A\nbasic premise of MDPs is that the rewards depend on the last state and action\nonly. Yet, many real-world rewards are non-Markovian. For example, a reward for\nbringing coffee only if requested earlier and not yet served, is non-Markovian\nif the state only records current requests and deliveries. Past work considered\nthe problem of modeling and solving MDPs with non-Markovian rewards (NMR), but\nwe know of no principled approaches for RL with NMR. Here, we address the\nproblem of policy learning from experience with such rewards. We describe and\nevaluate empirically four combinations of the classical RL algorithm Q-learning\nand R-max with automata learning algorithms to obtain new RL algorithms for\ndomains with NMR. We also prove that some of these variants converge to an\noptimal policy in the limit.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 13:09:16 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Gaon", "Maor", ""], ["Brafman", "Ronen I.", ""]]}, {"id": "1912.02696", "submitter": "Reazul Hasan Russel", "authors": "Reazul Hasan Russel, Bahram Behzadian, Marek Petrik", "title": "Optimizing Norm-Bounded Weighted Ambiguity Sets for Robust MDPs", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.10786", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal policies in Markov decision processes (MDPs) are very sensitive to\nmodel misspecification. This raises serious concerns about deploying them in\nhigh-stake domains. Robust MDPs (RMDP) provide a promising framework to\nmitigate vulnerabilities by computing policies with worst-case guarantees in\nreinforcement learning. The solution quality of an RMDP depends on the\nambiguity set, which is a quantification of model uncertainties. In this paper,\nwe propose a new approach for optimizing the shape of the ambiguity sets for\nRMDPs. Our method departs from the conventional idea of constructing a\nnorm-bounded uniform and symmetric ambiguity set. We instead argue that the\nstructure of a near-optimal ambiguity set is problem specific. Our proposed\nmethod computes a weight parameter from the value functions, and these weights\nthen drive the shape of the ambiguity sets. Our theoretical analysis\ndemonstrates the rationale of the proposed idea. We apply our method to several\ndifferent problem domains, and the empirical results further furnish the\npractical promise of weighted near-optimal ambiguity sets.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 17:38:57 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Russel", "Reazul Hasan", ""], ["Behzadian", "Bahram", ""], ["Petrik", "Marek", ""]]}, {"id": "1912.02714", "submitter": "Brandon Trabucco", "authors": "Brandon Trabucco, Albert Qu, Simon Li, Ganeshkumar Ashokavardhanan", "title": "Inferring the Optimal Policy using Markov Chain Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates methods for estimating the optimal stochastic control\npolicy for a Markov Decision Process with unknown transition dynamics and an\nunknown reward function. This form of model-free reinforcement learning\ncomprises many real world systems such as playing video games, simulated\ncontrol tasks, and real robot locomotion. Existing methods for estimating the\noptimal stochastic control policy rely on high variance estimates of the policy\ndescent. However, these methods are not guaranteed to find the optimal\nstochastic policy, and the high variance gradient estimates make convergence\nunstable. In order to resolve these problems, we propose a technique using\nMarkov Chain Monte Carlo to generate samples from the posterior distribution of\nthe parameters conditioned on being optimal. Our method provably converges to\nthe globally optimal stochastic policy, and empirically similar variance\ncompared to the policy gradient.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 00:08:24 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Trabucco", "Brandon", ""], ["Qu", "Albert", ""], ["Li", "Simon", ""], ["Ashokavardhanan", "Ganeshkumar", ""]]}, {"id": "1912.02734", "submitter": "Martin Diller", "authors": "Gerhard Brewka, Martin Diller, Georg Heissenberger, Thomas\n  Linsbichler, Stefan Woltran", "title": "Solving Advanced Argumentation Problems with Answer Set Programming", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 391-431", "doi": "10.1017/S1471068419000474", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Powerful formalisms for abstract argumentation have been proposed, among them\nabstract dialectical frameworks (ADFs) that allow for a succinct and flexible\nspecification of the relationship between arguments, and the GRAPPA framework\nwhich allows argumentation scenarios to be represented as arbitrary\nedge-labelled graphs. The complexity of ADFs and GRAPPA is located beyond NP\nand ranges up to the third level of the polynomial hierarchy. The combined\ncomplexity of Answer Set Programming (ASP) exactly matches this complexity when\nprograms are restricted to predicates of bounded arity. In this paper, we\nexploit this coincidence and present novel efficient translations from ADFs and\nGRAPPA to ASP. More specifically, we provide reductions for the five main ADF\nsemantics of admissible, complete, preferred, grounded, and stable\ninterpretations, and exemplify how these reductions need to be adapted for\nGRAPPA for the admissible, complete and preferred semantics. Under\nconsideration in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 17:20:34 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Brewka", "Gerhard", ""], ["Diller", "Martin", ""], ["Heissenberger", "Georg", ""], ["Linsbichler", "Thomas", ""], ["Woltran", "Stefan", ""]]}, {"id": "1912.02759", "submitter": "Pavel Naumov", "authors": "Pavel Naumov and Jia Tao", "title": "Duty to Warn in Strategic Games", "comments": "Proc. of the 19th International Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS 2020) May 9--13, 2020, Auckland, New Zealand, B.\n  An, N. Yorke-Smith, A. El Fallah Seghrouchni, G.~Sukthankar (eds.). arXiv\n  admin note: substantial text overlap with arXiv:1811.02446", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper investigates the second-order blameworthiness or duty to warn\nmodality \"one coalition knew how another coalition could have prevented an\noutcome\". The main technical result is a sound and complete logical system that\ndescribes the interplay between the distributed knowledge and the duty to warn\nmodalities.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 19:57:02 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 16:54:55 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Naumov", "Pavel", ""], ["Tao", "Jia", ""]]}, {"id": "1912.02811", "submitter": "Siyu Zhou", "authors": "Siyu Zhou, Mariano Phielipp, Jorge A. Sefair, Sara I. Walker, Heni Ben\n  Amor", "title": "Clone Swarms: Learning to Predict and Control Multi-Robot Systems by\n  Imitation", "comments": null, "journal-ref": null, "doi": "10.1109/IROS40897.2019.8967824", "report-no": null, "categories": "cs.NE cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose SwarmNet -- a neural network architecture that can\nlearn to predict and imitate the behavior of an observed swarm of agents in a\ncentralized manner. Tested on artificially generated swarm motion data, the\nnetwork achieves high levels of prediction accuracy and imitation authenticity.\nWe compare our model to previous approaches for modelling interaction systems\nand show how modifying components of other models gradually approaches the\nperformance of ours. Finally, we also discuss an extension of SwarmNet that can\ndeal with nondeterministic, noisy, and uncertain environments, as often found\nin robotics applications.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 18:55:56 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 00:24:04 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Zhou", "Siyu", ""], ["Phielipp", "Mariano", ""], ["Sefair", "Jorge A.", ""], ["Walker", "Sara I.", ""], ["Amor", "Heni Ben", ""]]}, {"id": "1912.02875", "submitter": "Juergen Schmidhuber", "authors": "Juergen Schmidhuber", "title": "Reinforcement Learning Upside Down: Don't Predict Rewards -- Just Map\n  Them to Actions", "comments": "22 pages, 81 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We transform reinforcement learning (RL) into a form of supervised learning\n(SL) by turning traditional RL on its head, calling this Upside Down RL (UDRL).\nStandard RL predicts rewards, while UDRL instead uses rewards as task-defining\ninputs, together with representations of time horizons and other computable\nfunctions of historic and desired future data. UDRL learns to interpret these\ninput observations as commands, mapping them to actions (or action\nprobabilities) through SL on past (possibly accidental) experience. UDRL\ngeneralizes to achieve high rewards or other goals, through input commands such\nas: get lots of reward within at most so much time! A separate paper [63] on\nfirst experiments with UDRL shows that even a pilot version of UDRL can\noutperform traditional baseline algorithms on certain challenging RL problems.\nWe also also conceptually simplify an approach [60] for teaching a robot to\nimitate humans. First videotape humans imitating the robot's current behaviors,\nthen let the robot learn through SL to map the videos (as input commands) to\nthese behaviors, then let it generalize and imitate videos of humans executing\npreviously unknown behavior. This Imitate-Imitator concept may actually explain\nwhy biological evolution has resulted in parents who imitate the babbling of\ntheir babies.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 21:10:08 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 15:55:05 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Schmidhuber", "Juergen", ""]]}, {"id": "1912.02877", "submitter": "Rupesh Kumar Srivastava", "authors": "Rupesh Kumar Srivastava, Pranav Shyam, Filipe Mutz, Wojciech\n  Ja\\'skowski, J\\\"urgen Schmidhuber", "title": "Training Agents using Upside-Down Reinforcement Learning", "comments": "NNAISENSE Technical Report. 17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional Reinforcement Learning (RL) algorithms either predict rewards\nwith value functions or maximize them using policy search. We study an\nalternative: Upside-Down Reinforcement Learning (Upside-Down RL or UDRL), that\nsolves RL problems primarily using supervised learning techniques. Many of its\nmain principles are outlined in a companion report [34]. Here we present the\nfirst concrete implementation of UDRL and demonstrate its feasibility on\ncertain episodic learning problems. Experimental results show that its\nperformance can be surprisingly competitive with, and even exceed that of\ntraditional baseline algorithms developed over decades of research.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 21:13:36 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Srivastava", "Rupesh Kumar", ""], ["Shyam", "Pranav", ""], ["Mutz", "Filipe", ""], ["Ja\u015bkowski", "Wojciech", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1912.02906", "submitter": "Guannan Qu", "authors": "Guannan Qu, Adam Wierman, Na Li", "title": "Scalable Reinforcement Learning of Localized Policies for Multi-Agent\n  Networked Systems", "comments": "Added experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study reinforcement learning (RL) in a setting with a network of agents\nwhose states and actions interact in a local manner where the objective is to\nfind localized policies such that the (discounted) global reward is maximized.\nA fundamental challenge in this setting is that the state-action space size\nscales exponentially in the number of agents, rendering the problem intractable\nfor large networks. In this paper, we propose a Scalable Actor-Critic (SAC)\nframework that exploits the network structure and finds a localized policy that\nis a $O(\\rho^\\kappa)$-approximation of a stationary point of the objective for\nsome $\\rho\\in(0,1)$, with complexity that scales with the local state-action\nspace size of the largest $\\kappa$-hop neighborhood of the network.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 22:44:07 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 19:42:18 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Qu", "Guannan", ""], ["Wierman", "Adam", ""], ["Li", "Na", ""]]}, {"id": "1912.02943", "submitter": "P. M. Krafft", "authors": "Michael Katell, Meg Young, Bernease Herman, Dharma Dailey, Aaron Tam,\n  Vivian Guetler, Corinne Binz, Daniella Raz, P. M. Krafft", "title": "An Algorithmic Equity Toolkit for Technology Audits by Community\n  Advocates and Activists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wave of recent scholarship documenting the discriminatory harms of\nalgorithmic systems has spurred widespread interest in algorithmic\naccountability and regulation. Yet effective accountability and regulation is\nstymied by a persistent lack of resources supporting public understanding of\nalgorithms and artificial intelligence. Through interactions with a US-based\ncivil rights organization and their coalition of community organizations, we\nidentify a need for (i) heuristics that aid stakeholders in distinguishing\nbetween types of analytic and information systems in lay language, and (ii)\nrisk assessment tools for such systems that begin by making algorithms more\nlegible. The present work delivers a toolkit to achieve these aims. This paper\nboth presents the Algorithmic Equity Toolkit (AEKit) Equity as an artifact, and\ndetails how our participatory process shaped its design. Our work fits within\nhuman-computer interaction scholarship as a demonstration of the value of HCI\nmethods and approaches to problems in the area of algorithmic transparency and\naccountability.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 01:32:16 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Katell", "Michael", ""], ["Young", "Meg", ""], ["Herman", "Bernease", ""], ["Dailey", "Dharma", ""], ["Tam", "Aaron", ""], ["Guetler", "Vivian", ""], ["Binz", "Corinne", ""], ["Raz", "Daniella", ""], ["Krafft", "P. M.", ""]]}, {"id": "1912.02967", "submitter": "Dustin Morrill", "authors": "Ryan D'Orazio, Dustin Morrill, James R. Wright, Michael Bowling", "title": "Alternative Function Approximation Parameterizations for Solving Games:\n  An Analysis of $f$-Regression Counterfactual Regret Minimization", "comments": "11 pages, includes appendix", "journal-ref": "Nineteenth International Conference on Autonomous Agents and\n  Multi-Agent Systems, 9-13 May 2020, Auckland, New Zealand", "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Function approximation is a powerful approach for structuring large decision\nproblems that has facilitated great achievements in the areas of reinforcement\nlearning and game playing. Regression counterfactual regret minimization (RCFR)\nis a simple algorithm for approximately solving imperfect information games\nwith normalized rectified linear unit (ReLU) parameterized policies. In\ncontrast, the more conventional softmax parameterization is standard in the\nfield of reinforcement learning and yields a regret bound with a better\ndependence on the number of actions. We derive approximation error-aware regret\nbounds for $(\\Phi, f)$-regret matching, which applies to a general class of\nlink functions and regret objectives. These bounds recover a tighter bound for\nRCFR and provide a theoretical justification for RCFR implementations with\nalternative policy parameterizations ($f$-RCFR), including softmax. We provide\nexploitability bounds for $f$-RCFR with the polynomial and exponential link\nfunctions in zero-sum imperfect information games and examine empirically how\nthe link function interacts with the severity of the approximation. We find\nthat the previously studied ReLU parameterization performs better when the\napproximation error is small while the softmax parameterization can perform\nbetter when the approximation error is large.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 03:32:29 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 20:40:46 GMT"}, {"version": "v3", "created": "Sat, 18 Apr 2020 19:30:16 GMT"}, {"version": "v4", "created": "Mon, 27 Apr 2020 20:33:50 GMT"}, {"version": "v5", "created": "Fri, 1 May 2020 15:01:30 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["D'Orazio", "Ryan", ""], ["Morrill", "Dustin", ""], ["Wright", "James R.", ""], ["Bowling", "Michael", ""]]}, {"id": "1912.02975", "submitter": "Xingyou Song", "authors": "Xingyou Song, Yiding Jiang, Stephen Tu, Yilun Du, Behnam Neyshabur", "title": "Observational Overfitting in Reinforcement Learning", "comments": "Published as a conference paper in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major component of overfitting in model-free reinforcement learning (RL)\ninvolves the case where the agent may mistakenly correlate reward with certain\nspurious features from the observations generated by the Markov Decision\nProcess (MDP). We provide a general framework for analyzing this scenario,\nwhich we use to design multiple synthetic benchmarks from only modifying the\nobservation space of an MDP. When an agent overfits to different observation\nspaces even if the underlying MDP dynamics is fixed, we term this observational\noverfitting. Our experiments expose intriguing properties especially with\nregards to implicit regularization, and also corroborate results from previous\nworks in RL generalization and supervised learning (SL).\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 04:52:16 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 04:04:43 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Song", "Xingyou", ""], ["Jiang", "Yiding", ""], ["Tu", "Stephen", ""], ["Du", "Yilun", ""], ["Neyshabur", "Behnam", ""]]}, {"id": "1912.02986", "submitter": "Fei Feng Ms.", "authors": "Fei Feng, Wotao Yin, Lin F. Yang", "title": "How Does an Approximate Model Help in Reinforcement Learning?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key approaches to save samples in reinforcement learning (RL) is\nto use knowledge from an approximate model such as its simulator. However, how\nmuch does an approximate model help to learn a near-optimal policy of the true\nunknown model? Despite numerous empirical studies of transfer reinforcement\nlearning, an answer to this question is still elusive. In this paper, we study\nthe sample complexity of RL while an approximate model of the environment is\nprovided. For an unknown Markov decision process (MDP), we show that the\napproximate model can effectively reduce the complexity by eliminating\nsub-optimal actions from the policy searching space. In particular, we provide\nan algorithm that uses $\\widetilde{O}(N/(1-\\gamma)^3/\\varepsilon^2)$ samples in\na generative model to learn an $\\varepsilon$-optimal policy, where $\\gamma$ is\nthe discount factor and $N$ is the number of near-optimal actions in the\napproximate model. This can be much smaller than the learning-from-scratch\ncomplexity $\\widetilde{\\Theta}(SA/(1-\\gamma)^3/\\varepsilon^2)$, where $S$ and\n$A$ are the sizes of state and action spaces respectively. We also provide a\nlower bound showing that the above upper bound is nearly-tight if the value gap\nbetween near-optimal actions and sub-optimal actions in the approximate model\nis sufficiently large. Our results provide a very precise characterization of\nhow an approximate model helps reinforcement learning when no additional\nassumption on the model is posed.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 06:05:59 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 18:42:20 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Feng", "Fei", ""], ["Yin", "Wotao", ""], ["Yang", "Lin F.", ""]]}, {"id": "1912.03072", "submitter": "Youngnam Lee", "authors": "Youngduck Choi, Youngnam Lee, Dongmin Shin, Junghyun Cho, Seoyon Park,\n  Seewoo Lee, Jineon Baek, Chan Bae, Byungsoo Kim, Jaewe Heo", "title": "EdNet: A Large-Scale Hierarchical Dataset in Education", "comments": "AIED 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With advances in Artificial Intelligence in Education (AIEd) and the\never-growing scale of Interactive Educational Systems (IESs), data-driven\napproach has become a common recipe for various tasks such as knowledge tracing\nand learning path recommendation. Unfortunately, collecting real students'\ninteraction data is often challenging, which results in the lack of public\nlarge-scale benchmark dataset reflecting a wide variety of student behaviors in\nmodern IESs. Although several datasets, such as ASSISTments, Junyi Academy,\nSynthetic and STATICS, are publicly available and widely used, they are not\nlarge enough to leverage the full potential of state-of-the-art data-driven\nmodels and limits the recorded behaviors to question-solving activities. To\nthis end, we introduce EdNet, a large-scale hierarchical dataset of diverse\nstudent activities collected by Santa, a multi-platform self-study solution\nequipped with artificial intelligence tutoring system. EdNet contains\n131,441,538 interactions from 784,309 students collected over more than 2\nyears, which is the largest among the ITS datasets released to the public so\nfar. Unlike existing datasets, EdNet provides a wide variety of student actions\nranging from question-solving to lecture consumption and item purchasing. Also,\nEdNet has a hierarchical structure where the student actions are divided into 4\ndifferent levels of abstractions. The features of EdNet are domain-agnostic,\nallowing EdNet to be extended to different domains easily. The dataset is\npublicly released under Creative Commons Attribution-NonCommercial 4.0\nInternational license for research purposes. We plan to host challenges in\nmultiple AIEd tasks with EdNet to provide a common ground for the fair\ncomparison between different state of the art models and encourage the\ndevelopment of practical and effective methods.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 11:46:18 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 09:03:18 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 10:09:08 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Choi", "Youngduck", ""], ["Lee", "Youngnam", ""], ["Shin", "Dongmin", ""], ["Cho", "Junghyun", ""], ["Park", "Seoyon", ""], ["Lee", "Seewoo", ""], ["Baek", "Jineon", ""], ["Bae", "Chan", ""], ["Kim", "Byungsoo", ""], ["Heo", "Jaewe", ""]]}, {"id": "1912.03184", "submitter": "Roman Klinger", "authors": "Laura Bostan and Evgeny Kim and Roman Klinger", "title": "GoodNewsEveryone: A Corpus of News Headlines Annotated with Emotions,\n  Semantic Roles, and Reader Perception", "comments": "Accepted at LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most research on emotion analysis from text focuses on the task of emotion\nclassification or emotion intensity regression. Fewer works address emotions as\na phenomenon to be tackled with structured learning, which can be explained by\nthe lack of relevant datasets. We fill this gap by releasing a dataset of 5000\nEnglish news headlines annotated via crowdsourcing with their associated\nemotions, the corresponding emotion experiencers and textual cues, related\nemotion causes and targets, as well as the reader's perception of the emotion\nof the headline. This annotation task is comparably challenging, given the\nlarge number of classes and roles to be identified. We therefore propose a\nmultiphase annotation procedure in which we first find relevant instances with\nemotional content and then annotate the more fine-grained aspects. Finally, we\ndevelop a baseline for the task of automatic prediction of semantic role\nstructures and discuss the results. The corpus we release enables further\nresearch on emotion classification, emotion intensity prediction, emotion cause\ndetection, and supports further qualitative studies.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 15:30:58 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 10:02:19 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 13:32:42 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Bostan", "Laura", ""], ["Kim", "Evgeny", ""], ["Klinger", "Roman", ""]]}, {"id": "1912.03277", "submitter": "Divyat Mahajan", "authors": "Divyat Mahajan, Chenhao Tan, Amit Sharma", "title": "Preserving Causal Constraints in Counterfactual Explanations for Machine\n  Learning Classifiers", "comments": "2019 NeurIPS Workshop on Do the right thing: Machine learning and\n  Causal Inference for improved decision making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To construct interpretable explanations that are consistent with the original\nML model, counterfactual examples---showing how the model's output changes with\nsmall perturbations to the input---have been proposed. This paper extends the\nwork in counterfactual explanations by addressing the challenge of feasibility\nof such examples. For explanations of ML models in critical domains such as\nhealthcare and finance, counterfactual examples are useful for an end-user only\nto the extent that perturbation of feature inputs is feasible in the real\nworld. We formulate the problem of feasibility as preserving causal\nrelationships among input features and present a method that uses (partial)\nstructural causal models to generate actionable counterfactuals. When\nfeasibility constraints cannot be easily expressed, we consider an alternative\nmechanism where people can label generated CF examples on feasibility: whether\nit is feasible to intervene and realize the candidate CF example from the\noriginal input. To learn from this labelled feasibility data, we propose a\nmodified variational auto encoder loss for generating CF examples that\noptimizes for feasibility as people interact with its output. Our experiments\non Bayesian networks and the widely used ''Adult-Income'' dataset show that our\nproposed methods can generate counterfactual explanations that better satisfy\nfeasibility constraints than existing methods.. Code repository can be accessed\nhere: \\textit{https://github.com/divyat09/cf-feasibility}\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 18:16:29 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 10:18:41 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 23:46:46 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Mahajan", "Divyat", ""], ["Tan", "Chenhao", ""], ["Sharma", "Amit", ""]]}, {"id": "1912.03283", "submitter": "Pablo Antonio Moreno Casares", "authors": "P. A. M. Casares and M. A. Martin-Delgado", "title": "A quantum active learning algorithm for sampling against adversarial\n  attacks", "comments": "Contains an additional dequantization appendix E that does not appear\n  in the published version", "journal-ref": "New Journal of Physics, 2020", "doi": "10.1088/1367-2630/ab976f", "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks represent a serious menace for learning algorithms and\nmay compromise the security of future autonomous systems. A theorem by Khoury\nand Hadfield-Menell (KH), provides sufficient conditions to guarantee the\nrobustness of machine learning algorithms, but comes with a caveat: it is\ncrucial to know the smallest distance among the classes of the corresponding\nclassification problem. We propose a theoretical framework that allows us to\nthink of active learning as sampling the most promising new points to be\nclassified, so that the minimum distance between classes can be found and the\ntheorem KH used. Additionally, we introduce a quantum active learning algorithm\nthat makes use of such framework and whose complexity is polylogarithmic in the\ndimension of the space, $m$, and the size of the initial training data $n$,\nprovided the use of qRAMs; and polynomial in the precision, achieving an\nexponential speedup over the equivalent classical algorithm in $n$ and $m$.\nThis algorithm may be nevertheless `dequantized' reducing the advantage to\npolynomial.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 18:26:47 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 20:05:22 GMT"}, {"version": "v3", "created": "Sun, 19 Jul 2020 11:46:10 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Casares", "P. A. M.", ""], ["Martin-Delgado", "M. A.", ""]]}, {"id": "1912.03295", "submitter": "Paul Riggins", "authors": "Paul Riggins and David McPherson", "title": "Tools for Mathematical Ludology", "comments": "20 pages, 9 figures; minor corrections and clarifications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the study of mathematical ludology, which aims to formally\ninterrogate questions of interest to game studies and game design in\nparticular. The goal is to extend our mathematical understanding of complex\ngames beyond decision-making---the typical focus of game theory and artificial\nintelligence efforts---to explore other aspects such as game mechanics,\nstructure, relationships between games, and connections between game rules and\nuser-interfaces, as well as exploring related gameplay phenomena and typical\nplayer behavior. In this paper, we build a basic foundation for this line of\nstudy by developing a hierarchy of game descriptions, mathematical formalism to\ncompactly describe complex discrete games, and equivalence relations on the\nspace of game systems.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 18:52:07 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 18:48:17 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Riggins", "Paul", ""], ["McPherson", "David", ""]]}, {"id": "1912.03298", "submitter": "Siddhant Bhambri", "authors": "Mudit Verma, Siddhant Bhambri, Saurabh Gupta, Arun Balaji Buduru", "title": "Making Smart Homes Smarter: Optimizing Energy Consumption with Human in\n  the Loop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid advancements in the Internet of Things (IoT) have facilitated more\nefficient deployment of smart environment solutions for specific user\nrequirement. With the increase in the number of IoT devices, it has become\ndifficult for the user to control or operate every individual smart device into\nachieving some desired goal like optimized power consumption, scheduled\nappliance running time, etc. Furthermore, existing solutions to automatically\nadapt the IoT devices are not capable enough to incorporate the user behavior.\nThis paper presents a novel approach to accurately configure IoT devices while\nachieving the twin objectives of energy optimization along with conforming to\nuser preferences. Our work comprises of unsupervised clustering of devices'\ndata to find the states of operation for each device, followed by\nprobabilistically analyzing user behavior to determine their preferred states.\nEventually, we deploy an online reinforcement learning (RL) agent to find the\nbest device settings automatically. Results for three different smart homes'\ndata-sets show the effectiveness of our methodology. To the best of our\nknowledge, this is the first time that a practical approach has been adopted to\nachieve the above mentioned objectives without any human interaction within the\nsystem.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 18:58:44 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 07:47:20 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 15:22:16 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Verma", "Mudit", ""], ["Bhambri", "Siddhant", ""], ["Gupta", "Saurabh", ""], ["Buduru", "Arun Balaji", ""]]}, {"id": "1912.03393", "submitter": "Naveen Arivazhagan", "authors": "Naveen Arivazhagan, Colin Cherry, Te I, Wolfgang Macherey, Pallavi\n  Baljekar, George Foster", "title": "Re-Translation Strategies For Long Form, Simultaneous, Spoken Language\n  Translation", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of simultaneous machine translation of long-form\nspeech content. We target a continuous speech-to-text scenario, generating\ntranslated captions for a live audio feed, such as a lecture or play-by-play\ncommentary. As this scenario allows for revisions to our incremental\ntranslations, we adopt a re-translation approach to simultaneous translation,\nwhere the source is repeatedly translated from scratch as it grows. This\napproach naturally exhibits very low latency and high final quality, but at the\ncost of incremental instability as the output is continuously refined. We\nexperiment with a pipeline of industry-grade speech recognition and translation\ntools, augmented with simple inference heuristics to improve stability. We use\nTED Talks as a source of multilingual test data, developing our techniques on\nEnglish-to-German spoken language translation. Our minimalist approach to\nsimultaneous translation allows us to easily scale our final evaluation to six\nmore target languages, dramatically improving incremental stability for all of\nthem.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 23:46:37 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 19:25:47 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Arivazhagan", "Naveen", ""], ["Cherry", "Colin", ""], ["I", "Te", ""], ["Macherey", "Wolfgang", ""], ["Baljekar", "Pallavi", ""], ["Foster", "George", ""]]}, {"id": "1912.03509", "submitter": "Sascha Rosbach", "authors": "Sascha Rosbach, Vinit James, Simon Gro{\\ss}johann, Silviu Homoceanu,\n  Xing Li and Stefan Roth", "title": "Driving Style Encoder: Situational Reward Adaptation for General-Purpose\n  Planning in Automated Driving", "comments": "To appear in Proceedings of the IEEE International Conference on\n  Robotics and Automation (ICRA), Paris, France, June 2020 (Virtual\n  Conference). Accepted version. Corrected figure font", "journal-ref": "IEEE International Conference on Robotics and Automation (ICRA),\n  Paris, France, 2020, pp. 6419-6425", "doi": "10.1109/ICRA40945.2020.9196778", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General-purpose planning algorithms for automated driving combine mission,\nbehavior, and local motion planning. Such planning algorithms map features of\nthe environment and driving kinematics into complex reward functions. To\nachieve this, planning experts often rely on linear reward functions. The\nspecification and tuning of these reward functions is a tedious process and\nrequires significant experience. Moreover, a manually designed linear reward\nfunction does not generalize across different driving situations. In this work,\nwe propose a deep learning approach based on inverse reinforcement learning\nthat generates situation-dependent reward functions. Our neural network\nprovides a mapping between features and actions of sampled driving policies of\na model-predictive control-based planner and predicts reward functions for\nupcoming planning cycles. In our evaluation, we compare the driving style of\nreward functions predicted by our deep network against clustered and linear\nreward functions. Our proposed deep learning approach outperforms clustered\nlinear reward functions and is at par with linear reward functions with\na-priori knowledge about the situation.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 14:30:22 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 12:10:13 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Rosbach", "Sascha", ""], ["James", "Vinit", ""], ["Gro\u00dfjohann", "Simon", ""], ["Homoceanu", "Silviu", ""], ["Li", "Xing", ""], ["Roth", "Stefan", ""]]}, {"id": "1912.03513", "submitter": "Warren Powell", "authors": "Warren B Powell", "title": "From Reinforcement Learning to Optimal Control: A unified framework for\n  sequential decisions", "comments": "47 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are over 15 distinct communities that work in the general area of\nsequential decisions and information, often referred to as decisions under\nuncertainty or stochastic optimization. We focus on two of the most important\nfields: stochastic optimal control, with its roots in deterministic optimal\ncontrol, and reinforcement learning, with its roots in Markov decision\nprocesses. Building on prior work, we describe a unified framework that covers\nall 15 different communities, and note the strong parallels with the modeling\nframework of stochastic optimal control. By contrast, we make the case that the\nmodeling framework of reinforcement learning, inherited from discrete Markov\ndecision processes, is quite limited. Our framework (and that of stochastic\ncontrol) is based on the core problem of optimizing over policies. We describe\nfour classes of policies that we claim are universal, and show that each of\nthese two fields have, in their own way, evolved to include examples of each of\nthese four classes.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 14:50:37 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 14:20:17 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Powell", "Warren B", ""]]}, {"id": "1912.03535", "submitter": "Guilherme Maeda", "authors": "Guilherme Maeda, Okan Koc, Jun Morimoto", "title": "Phase Portraits as Movement Primitives for Fast Humanoid Robot Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, usual approaches for fast robot control are largely reliant on\nsolving online optimal control problems. Such methods are known to be\ncomputationally intensive and sensitive to model accuracy. On the other hand,\nanimals plan complex motor actions not only fast but seemingly with little\neffort even on unseen tasks. This natural sense to infer temporal dynamics and\ncoordination motivates us to approach robot control from a motor skill learning\nperspective to design fast and computationally light controllers that can be\nlearned autonomously by the robot under mild modeling assumptions. This article\nintroduces Phase Portrait Movement Primitives (PPMP), a primitive that predicts\ndynamics on a low dimensional phase space which in turn is used to govern the\nhigh dimensional kinematics of the task. The stark difference with other\nprimitive formulations is a built-in mechanism for phase prediction in the form\nof coupled oscillators that replaces model-based state estimators such as\nKalman filters. The policy is trained by optimizing the parameters of the\noscillators whose output is connected to a kinematic distribution in the form\nof a phase portrait. The drastic reduction in dimensionality allows us to\nefficiently train and execute PPMPs on a real human-sized, dual-arm humanoid\nupper body on a task involving 20 degrees-of-freedom. We demonstrate PPMPs in\ninteractions requiring fast reactions times while generating anticipative pose\nadaptation in both discrete and cyclic tasks.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 17:44:43 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 03:00:41 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 13:52:54 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Maeda", "Guilherme", ""], ["Koc", "Okan", ""], ["Morimoto", "Jun", ""]]}, {"id": "1912.03553", "submitter": "Spencer Frazier", "authors": "Spencer Frazier, Md Sultan Al Nahian, Mark Riedl, Brent Harrison", "title": "Learning Norms from Stories: A Prior for Value Aligned Agents", "comments": "AIES 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value alignment is a property of an intelligent agent indicating that it can\nonly pursue goals and activities that are beneficial to humans. Traditional\napproaches to value alignment use imitation learning or preference learning to\ninfer the values of humans by observing their behavior. We introduce a\ncomplementary technique in which a value aligned prior is learned from\nnaturally occurring stories which encode societal norms. Training data is\nsourced from the childrens educational comic strip, Goofus and Gallant. In this\nwork, we train multiple machine learning models to classify natural language\ndescriptions of situations found in the comic strip as normative or non\nnormative by identifying if they align with the main characters behavior. We\nalso report the models performance when transferring to two unrelated tasks\nwith little to no additional training on the new task.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 20:12:43 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Frazier", "Spencer", ""], ["Nahian", "Md Sultan Al", ""], ["Riedl", "Mark", ""], ["Harrison", "Brent", ""]]}, {"id": "1912.03564", "submitter": "Jan Karwowski", "authors": "Jan Karwowski and Jacek Ma\\'ndziuk and Adam \\.Zychowski", "title": "Anchoring Theory in Sequential Stackelberg Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An underlying assumption of Stackelberg Games (SGs) is perfect rationality of\nthe players. However, in real-life situations (which are often modeled by SGs)\nthe followers (terrorists, thieves, poachers or smugglers) -- as humans in\ngeneral -- may act not in a perfectly rational way, as their decisions may be\naffected by biases of various kinds which bound rationality of their decisions.\nOne of the popular models of bounded rationality (BR) is Anchoring Theory (AT)\nwhich claims that humans have a tendency to flatten probabilities of available\noptions, i.e. they perceive a distribution of these probabilities as being\ncloser to the uniform distribution than it really is. This paper proposes an\nefficient formulation of AT in sequential extensive-form SGs (named ATSG),\nsuitable for Mixed-Integer Linear Program (MILP) solution methods. ATSG is\nimplemented in three MILP/LP-based state-of-the-art methods for solving\nsequential SGs and two recently introduced non-MILP approaches: one relying on\nMonte Carlo sampling (O2UCT) and the other one (EASG) employing Evolutionary\nAlgorithms. Experimental evaluation indicates that both non-MILP heuristic\napproaches scale better in time than MILP solutions while providing optimal or\nclose-to-optimal solutions. Except for competitive time scalability, an\nadditional asset of non-MILP methods is flexibility of potential BR\nformulations they are able to incorporate. While MILP approaches accept BR\nformulations with linear constraints only, no restrictions on the BR form are\nimposed in either of the two non-MILP methods.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 21:34:14 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 16:27:58 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Karwowski", "Jan", ""], ["Ma\u0144dziuk", "Jacek", ""], ["\u017bychowski", "Adam", ""]]}, {"id": "1912.03735", "submitter": "Shahbaz Rezaei", "authors": "Shahbaz Rezaei and Xin Liu", "title": "Security of Deep Learning Methodologies: Challenges and Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the plethora of studies about security vulnerabilities and defenses\nof deep learning models, security aspects of deep learning methodologies, such\nas transfer learning, have been rarely studied. In this article, we highlight\nthe security challenges and research opportunities of these methodologies,\nfocusing on vulnerabilities and attacks unique to them.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 18:23:23 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Rezaei", "Shahbaz", ""], ["Liu", "Xin", ""]]}, {"id": "1912.03802", "submitter": "Candice Schumann", "authors": "Candice Schumann, Zhi Lang, Nicholas Mattei, John P. Dickerson", "title": "Group Fairness in Bandit Arm Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel formulation of group fairness in the contextual\nmulti-armed bandit (CMAB) setting. In the CMAB setting a sequential decision\nmaker must at each time step choose an arm to pull from a finite set of arms\nafter observing some context for each of the potential arm pulls. In our model\narms are partitioned into two or more sensitive groups based on some protected\nfeature (e.g., age, race, or socio-economic status). Despite the fact that\nthere may be differences in expected payout between the groups, we may wish to\nensure some form of fairness between picking arms from the various groups. In\nthis work we explore two definitions of fairness: equal group probability,\nwherein the probability of pulling an arm from any of the protected groups is\nthe same; and proportional parity, wherein the probability of choosing an arm\nfrom a particular group is proportional to the size of that group. We provide a\nnovel algorithm that can accommodate these notions of fairness for an arbitrary\nnumber of groups, and provide bounds on the regret for our algorithm. We then\nvalidate our algorithm using synthetic data as well as two real-world datasets\nfor intervention settings wherein we want to allocate resources fairly across\nprotected groups.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 01:02:35 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 17:26:41 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Schumann", "Candice", ""], ["Lang", "Zhi", ""], ["Mattei", "Nicholas", ""], ["Dickerson", "John P.", ""]]}, {"id": "1912.03817", "submitter": "Varun Chandrasekaran", "authors": "Lucas Bourtoule, Varun Chandrasekaran, Christopher A. Choquette-Choo,\n  Hengrui Jia, Adelin Travers, Baiwu Zhang, David Lie and Nicolas Papernot", "title": "Machine Unlearning", "comments": "Published in IEEE S&P 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Once users have shared their data online, it is generally difficult for them\nto revoke access and ask for the data to be deleted. Machine learning (ML)\nexacerbates this problem because any model trained with said data may have\nmemorized it, putting users at risk of a successful privacy attack exposing\ntheir information. Yet, having models unlearn is notoriously difficult. We\nintroduce SISA training, a framework that expedites the unlearning process by\nstrategically limiting the influence of a data point in the training procedure.\nWhile our framework is applicable to any learning algorithm, it is designed to\nachieve the largest improvements for stateful algorithms like stochastic\ngradient descent for deep neural networks. SISA training reduces the\ncomputational overhead associated with unlearning, even in the worst-case\nsetting where unlearning requests are made uniformly across the training set.\nIn some cases, the service provider may have a prior on the distribution of\nunlearning requests that will be issued by users. We may take this prior into\naccount to partition and order data accordingly, and further decrease overhead\nfrom unlearning. Our evaluation spans several datasets from different domains,\nwith corresponding motivations for unlearning. Under no distributional\nassumptions, for simple learning tasks, we observe that SISA training improves\ntime to unlearn points from the Purchase dataset by 4.63x, and 2.45x for the\nSVHN dataset, over retraining from scratch. SISA training also provides a\nspeed-up of 1.36x in retraining for complex learning tasks such as ImageNet\nclassification; aided by transfer learning, this results in a small degradation\nin accuracy. Our work contributes to practical data governance in machine\nunlearning.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 02:16:53 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 20:09:45 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 05:39:28 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Bourtoule", "Lucas", ""], ["Chandrasekaran", "Varun", ""], ["Choquette-Choo", "Christopher A.", ""], ["Jia", "Hengrui", ""], ["Travers", "Adelin", ""], ["Zhang", "Baiwu", ""], ["Lie", "David", ""], ["Papernot", "Nicolas", ""]]}, {"id": "1912.03820", "submitter": "Mingzhang Yin", "authors": "Mingzhang Yin, George Tucker, Mingyuan Zhou, Sergey Levine, Chelsea\n  Finn", "title": "Meta-Learning without Memorization", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn new concepts with small amounts of data is a critical\naspect of intelligence that has proven challenging for deep learning methods.\nMeta-learning has emerged as a promising technique for leveraging data from\nprevious tasks to enable efficient learning of new tasks. However, most\nmeta-learning algorithms implicitly require that the meta-training tasks be\nmutually-exclusive, such that no single model can solve all of the tasks at\nonce. For example, when creating tasks for few-shot image classification, prior\nwork uses a per-task random assignment of image classes to N-way classification\nlabels. If this is not done, the meta-learner can ignore the task training data\nand learn a single model that performs all of the meta-training tasks\nzero-shot, but does not adapt effectively to new image classes. This\nrequirement means that the user must take great care in designing the tasks,\nfor example by shuffling labels or removing task identifying information from\nthe inputs. In some domains, this makes meta-learning entirely inapplicable. In\nthis paper, we address this challenge by designing a meta-regularization\nobjective using information theory that places precedence on data-driven\nadaptation. This causes the meta-learner to decide what must be learned from\nthe task training data and what should be inferred from the task testing input.\nBy doing so, our algorithm can successfully use data from\nnon-mutually-exclusive tasks to efficiently adapt to novel tasks. We\ndemonstrate its applicability to both contextual and gradient-based\nmeta-learning algorithms, and apply it in practical settings where applying\nstandard meta-learning has been difficult. Our approach substantially\noutperforms standard meta-learning algorithms in these settings.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 02:30:46 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 19:49:41 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 22:33:53 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Yin", "Mingzhang", ""], ["Tucker", "George", ""], ["Zhou", "Mingyuan", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1912.03821", "submitter": "Kaiqing Zhang", "authors": "Kaiqing Zhang, Zhuoran Yang, Tamer Ba\\c{s}ar", "title": "Decentralized Multi-Agent Reinforcement Learning with Networked Agents:\n  Recent Advances", "comments": "This is a invited submission to a Special Issue of the Journal of\n  Frontiers of Information Technology & Electronic Engineering (FITEE). Most of\n  the contents are based on the Sec. 4 in our recent overview arXiv:1911.10635,\n  with focus on the setting of decentralized MARL with networked agents", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning (MARL) has long been a significant and\neverlasting research topic in both machine learning and control. With the\nrecent development of (single-agent) deep RL, there is a resurgence of\ninterests in developing new MARL algorithms, especially those that are backed\nby theoretical analysis. In this paper, we review some recent advances a\nsub-area of this topic: decentralized MARL with networked agents. Specifically,\nmultiple agents perform sequential decision-making in a common environment,\nwithout the coordination of any central controller. Instead, the agents are\nallowed to exchange information with their neighbors over a communication\nnetwork. Such a setting finds broad applications in the control and operation\nof robots, unmanned vehicles, mobile sensor networks, and smart grid. This\nreview is built upon several our research endeavors in this direction, together\nwith some progresses made by other researchers along the line. We hope this\nreview to inspire the devotion of more research efforts to this exciting yet\nchallenging area.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 02:33:57 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Yang", "Zhuoran", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1912.03851", "submitter": "Ujwal Padam Tewari", "authors": "Ujwal Padam Tewari, Vishal Bidawatka, Varsha Raveendran, Vinay\n  Sudhakaran, Shreedhar Kodate Shreeshail, Jayanth Prakash Kulkarni", "title": "Intelligent Coordination among Multiple Traffic Intersections Using\n  Multi-Agent Reinforcement Learning", "comments": "Accepted in the NeurIPS 2019 Deep RL Workshop :\n  https://sites.google.com/view/deep-rl-workshop-neurips-2019/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use Asynchronous Advantage Actor Critic (A3C) for implementing an AI agent\nin the controllers that optimize flow of traffic across a single intersection\nand then extend it to multiple intersections by considering a multi-agent\nsetting. We explore three different methodologies to address the multi-agent\nproblem - (1) use of asynchronous property of A3C to control multiple\nintersections using a single agent (2) utilise self/competitive play among\nindependent agents across multiple intersections and (3) ingest a global reward\nfunction among agents to introduce cooperative behavior between intersections.\nWe observe that (1) & (2) leads to a reduction in traffic congestion.\nAdditionally the use of (3) with (1) & (2) led to a further reduction in\ncongestion.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 04:54:31 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 12:53:18 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 15:58:24 GMT"}, {"version": "v4", "created": "Sun, 28 Jun 2020 14:21:09 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Tewari", "Ujwal Padam", ""], ["Bidawatka", "Vishal", ""], ["Raveendran", "Varsha", ""], ["Sudhakaran", "Vinay", ""], ["Shreeshail", "Shreedhar Kodate", ""], ["Kulkarni", "Jayanth Prakash", ""]]}, {"id": "1912.03905", "submitter": "Prabhat Nagarajan", "authors": "Yasuhiro Fujita, Prabhat Nagarajan, Toshiki Kataoka, Takahiro Ishikawa", "title": "ChainerRL: A Deep Reinforcement Learning Library", "comments": "Journal of Machine Learning Research", "journal-ref": "Journal of Machine Learning Research 22(77) (2021) 1-14;", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce ChainerRL, an open-source deep reinforcement\nlearning (DRL) library built using Python and the Chainer deep learning\nframework. ChainerRL implements a comprehensive set of DRL algorithms and\ntechniques drawn from state-of-the-art research in the field. To foster\nreproducible research, and for instructional purposes, ChainerRL provides\nscripts that closely replicate the original papers' experimental settings and\nreproduce published benchmark results for several algorithms. Lastly, ChainerRL\noffers a visualization tool that enables the qualitative inspection of trained\nagents. The ChainerRL source code can be found on GitHub:\nhttps://github.com/chainer/chainerrl.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 08:59:15 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 03:24:48 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Fujita", "Yasuhiro", ""], ["Nagarajan", "Prabhat", ""], ["Kataoka", "Toshiki", ""], ["Ishikawa", "Takahiro", ""]]}, {"id": "1912.04034", "submitter": "Swapnil Kumar", "authors": "Sasikanth Goteti, Swapnil Kumar", "title": "Novel Approach for Solving a Variant of Equal Flow Problem", "comments": "10 pages", "journal-ref": null, "doi": "10.7287/peerj.preprints.27264v1", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we consider a certain sub class of Integer Equal Flow\nproblem, which are known NP hard [8]. Currently there exist no direct solutions\nfor the same. It is a common problem in various inventory management systems.\nHere we discuss a local minima solution which uses projection of the convex\nspaces to resolve the equal flows and turn the problem into a known linear\ninteger programming or constraint satisfaction problem which have reasonable\nknown solutions and can be effectively solved using simplex or other standard\noptimization strategies.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 13:38:44 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 07:39:13 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Goteti", "Sasikanth", ""], ["Kumar", "Swapnil", ""]]}, {"id": "1912.04061", "submitter": "Amritanshu Agrawal", "authors": "Amritanshu Agrawal, Xueqi Yang, Rishabh Agrawal, Rahul Yedida, Xipeng\n  Shen, Tim Menzies", "title": "Simpler Hyperparameter Optimization for Software Analytics: Why, How,\n  When?", "comments": "15 pages", "journal-ref": "Transactions on Software Engineering, 2021", "doi": "10.1109/TSE.2021.3073242", "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we make software analytics simpler and faster? One method is to match\nthe complexity of analysis to the intrinsic complexity of the data being\nexplored. For example, hyperparameter optimizers find the control settings for\ndata miners that improve the predictions generated via software analytics.\nSometimes, very fast hyperparameter optimization can be achieved by\n\"DODGE-ing\"; i.e. simply steering way from settings that lead to similar\nconclusions. But when is it wise to use that simple approach and when must we\nuse more complex (and much slower) optimizers?} To answer this, we applied\nhyperparameter optimization to 120 SE data sets that explored bad smell\ndetection, predicting Github issue close time, bug report analysis, defect\nprediction, and dozens of other non-SE problems. We find that the simple DODGE\nworks best for data sets with low \"intrinsic dimensionality\" (u ~ 3) and very\npoorly for higher-dimensional data (u > 8). Nearly all the SE data seen here\nwas intrinsically low-dimensional, indicating that DODGE is applicable for many\nSE analytics tasks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 14:10:40 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 15:46:19 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 23:04:25 GMT"}, {"version": "v4", "created": "Fri, 16 Apr 2021 14:28:07 GMT"}, {"version": "v5", "created": "Thu, 22 Apr 2021 14:29:22 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Agrawal", "Amritanshu", ""], ["Yang", "Xueqi", ""], ["Agrawal", "Rishabh", ""], ["Yedida", "Rahul", ""], ["Shen", "Xipeng", ""], ["Menzies", "Tim", ""]]}, {"id": "1912.04201", "submitter": "Aaron Havens", "authors": "Aaron Havens, Yi Ouyang, Prabhat Nagarajan, Yasuhiro Fujita", "title": "Learning Latent State Spaces for Planning through Reward Prediction", "comments": "Deep RL Workshop, Neurips 2019, Vancouver", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning methods typically learn models for\nhigh-dimensional state spaces by aiming to reconstruct and predict the original\nobservations. However, drawing inspiration from model-free reinforcement\nlearning, we propose learning a latent dynamics model directly from rewards. In\nthis work, we introduce a model-based planning framework which learns a latent\nreward prediction model and then plans in the latent state-space. The latent\nrepresentation is learned exclusively from multi-step reward prediction which\nwe show to be the only necessary information for successful planning. With this\nframework, we are able to benefit from the concise model-free representation,\nwhile still enjoying the data-efficiency of model-based algorithms. We\ndemonstrate our framework in multi-pendulum and multi-cheetah environments\nwhere several pendulums or cheetahs are shown to the agent but only one of\nwhich produces rewards. In these environments, it is important for the agent to\nconstruct a concise latent representation to filter out irrelevant\nobservations. We find that our method can successfully learn an accurate latent\nreward prediction model in the presence of the irrelevant information while\nexisting model-based methods fail. Planning in the learned latent state-space\nshows strong performance and high sample efficiency over model-free and\nmodel-based baselines.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 17:32:51 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Havens", "Aaron", ""], ["Ouyang", "Yi", ""], ["Nagarajan", "Prabhat", ""], ["Fujita", "Yasuhiro", ""]]}, {"id": "1912.04217", "submitter": "Tom White", "authors": "Tom White", "title": "Shared Visual Abstractions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper presents abstract art created by neural networks and broadly\nrecognizable across various computer vision systems. The existence of abstract\nforms that trigger specific labels independent of neural architecture or\ntraining set suggests convolutional neural networks build shared visual\nrepresentations for the categories they understand. Computer vision classifiers\nencountering these drawings often respond with strong responses for specific\nlabels - in extreme cases stronger than all examples from the validation set.\nBy surveying human subjects we confirm that these abstract artworks are also\nbroadly recognizable by people, suggesting visual representations triggered by\nthese drawings are shared across human and computer vision systems.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 18:51:02 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["White", "Tom", ""]]}, {"id": "1912.04226", "submitter": "Allan Jabri", "authors": "Allan Jabri, Kyle Hsu, Ben Eysenbach, Abhishek Gupta, Sergey Levine,\n  Chelsea Finn", "title": "Unsupervised Curricula for Visual Meta-Reinforcement Learning", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In principle, meta-reinforcement learning algorithms leverage experience\nacross many tasks to learn fast reinforcement learning (RL) strategies that\ntransfer to similar tasks. However, current meta-RL approaches rely on\nmanually-defined distributions of training tasks, and hand-crafting these task\ndistributions can be challenging and time-consuming. Can \"useful\" pre-training\ntasks be discovered in an unsupervised manner? We develop an unsupervised\nalgorithm for inducing an adaptive meta-training task distribution, i.e. an\nautomatic curriculum, by modeling unsupervised interaction in a visual\nenvironment. The task distribution is scaffolded by a parametric density model\nof the meta-learner's trajectory distribution. We formulate unsupervised\nmeta-RL as information maximization between a latent task variable and the\nmeta-learner's data distribution, and describe a practical instantiation which\nalternates between integration of recent experience into the task distribution\nand meta-learning of the updated tasks. Repeating this procedure leads to\niterative reorganization such that the curriculum adapts as the meta-learner's\ndata distribution shifts. In particular, we show how discriminative clustering\nfor visual representation can support trajectory-level task acquisition and\nexploration in domains with pixel observations, avoiding pitfalls of\nalternatives. In experiments on vision-based navigation and manipulation\ndomains, we show that the algorithm allows for unsupervised meta-learning that\ntransfers to downstream tasks specified by hand-crafted reward functions and\nserves as pre-training for more efficient supervised meta-learning of test task\ndistributions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 18:05:05 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Jabri", "Allan", ""], ["Hsu", "Kyle", ""], ["Eysenbach", "Ben", ""], ["Gupta", "Abhishek", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1912.04302", "submitter": "Aljaz Bozic", "authors": "Alja\\v{z} Bo\\v{z}i\\v{c}, Michael Zollh\\\"ofer, Christian Theobalt,\n  Matthias Nie{\\ss}ner", "title": "DeepDeform: Learning Non-rigid RGB-D Reconstruction with Semi-supervised\n  Data", "comments": "Video: https://youtu.be/OrHLacCDZVQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying data-driven approaches to non-rigid 3D reconstruction has been\ndifficult, which we believe can be attributed to the lack of a large-scale\ntraining corpus. Unfortunately, this method fails for important cases such as\nhighly non-rigid deformations. We first address this problem of lack of data by\nintroducing a novel semi-supervised strategy to obtain dense inter-frame\ncorrespondences from a sparse set of annotations. This way, we obtain a large\ndataset of 400 scenes, over 390,000 RGB-D frames, and 5,533 densely aligned\nframe pairs; in addition, we provide a test set along with several metrics for\nevaluation. Based on this corpus, we introduce a data-driven non-rigid feature\nmatching approach, which we integrate into an optimization-based reconstruction\npipeline. Here, we propose a new neural network that operates on RGB-D frames,\nwhile maintaining robustness under large non-rigid deformations and producing\naccurate predictions. Our approach significantly outperforms existing non-rigid\nreconstruction methods that do not use learned data terms, as well as\nlearning-based approaches that only use self-supervision.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 19:00:04 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 19:00:02 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Bo\u017ei\u010d", "Alja\u017e", ""], ["Zollh\u00f6fer", "Michael", ""], ["Theobalt", "Christian", ""], ["Nie\u00dfner", "Matthias", ""]]}, {"id": "1912.04464", "submitter": "Oswald Barral", "authors": "Cristina Conati, Oswald Barral, Vanessa Putnam, Lea Rieger", "title": "Toward Personalized XAI: A Case Study in Intelligent Tutoring Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our research is a step toward ascertaining the need for personalization, in\nXAI, and we do so in the context of investigating the value of explanations of\nAI-driven hints and feedback are useful in Intelligent Tutoring Systems (ITS).\nWe added an explanation functionality for the adaptive hints provided by the\nAdaptive CSP (ACSP) applet, an interactive simulation that helps students learn\nan algorithm for constraint satisfaction problems by providing AI-driven hints\nadapted to their predicted level of learning. We present the design of the\nexplanation functionality and the results of a controlled study to evaluate its\nimpact on students' learning and perception of the ACPS hints. The study\nincludes an analysis of how these outcomes are modulated by several user\ncharacteristics such as personality traits and cognitive abilities, to asses if\nexplanations should be personalized to these characteristics. Our results\nindicate that providing explanations increase students' trust in the ACPS\nhints, perceived usefulness of the hints, and intention to use them again. In\naddition, we show that students' access of the explanation and learning gains\nare modulated by user characteristics, providing insights toward designing\npersonalized Explainable AI (XAI) for ITS.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 02:57:17 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 23:13:18 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 16:11:24 GMT"}, {"version": "v4", "created": "Wed, 12 Aug 2020 23:01:46 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Conati", "Cristina", ""], ["Barral", "Oswald", ""], ["Putnam", "Vanessa", ""], ["Rieger", "Lea", ""]]}, {"id": "1912.04472", "submitter": "Daniel Brown", "authors": "Daniel S. Brown and Scott Niekum", "title": "Deep Bayesian Reward Learning from Preferences", "comments": "Workshop on Safety and Robustness in Decision Making at the 33rd\n  Conference on Neural Information Processing Systems (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inverse reinforcement learning (IRL) methods are ideal for safe\nimitation learning, as they allow a learning agent to reason about reward\nuncertainty and the safety of a learned policy. However, Bayesian IRL is\ncomputationally intractable for high-dimensional problems because each sample\nfrom the posterior requires solving an entire Markov Decision Process (MDP).\nWhile there exist non-Bayesian deep IRL methods, these methods typically infer\npoint estimates of reward functions, precluding rigorous safety and uncertainty\nanalysis. We propose Bayesian Reward Extrapolation (B-REX), a highly efficient,\npreference-based Bayesian reward learning algorithm that scales to\nhigh-dimensional, visual control tasks. Our approach uses successor feature\nrepresentations and preferences over demonstrations to efficiently generate\nsamples from the posterior distribution over the demonstrator's reward function\nwithout requiring an MDP solver. Using samples from the posterior, we\ndemonstrate how to calculate high-confidence bounds on policy performance in\nthe imitation learning setting, in which the ground-truth reward function is\nunknown. We evaluate our proposed approach on the task of learning to play\nAtari games via imitation learning from pixel inputs, with no access to the\ngame score. We demonstrate that B-REX learns imitation policies that are\ncompetitive with a state-of-the-art deep imitation learning method that only\nlearns a point estimate of the reward function. Furthermore, we demonstrate\nthat samples from the posterior generated via B-REX can be used to compute\nhigh-confidence performance bounds for a variety of evaluation policies. We\nshow that high-confidence performance bounds are useful for accurately ranking\ndifferent evaluation policies when the reward function is unknown. We also\ndemonstrate that high-confidence performance bounds may be useful for detecting\nreward hacking.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 03:29:51 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Brown", "Daniel S.", ""], ["Niekum", "Scott", ""]]}, {"id": "1912.04616", "submitter": "Matthias Samwald", "authors": "Anna Breit, Simon Ott, Asan Agibetov, Matthias Samwald", "title": "OpenBioLink: A benchmarking framework for large-scale biomedical link\n  prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  SUMMARY: Recently, novel machine-learning algorithms have shown potential for\npredicting undiscovered links in biomedical knowledge networks. However,\ndedicated benchmarks for measuring algorithmic progress have not yet emerged.\nWith OpenBioLink, we introduce a large-scale, high-quality and highly\nchallenging biomedical link prediction benchmark to transparently and\nreproducibly evaluate such algorithms. Furthermore, we present preliminary\nbaseline evaluation results. AVAILABILITY AND IMPLEMENTATION: Source code, data\nand supplementary files are openly available at\nhttps://github.com/OpenBioLink/OpenBioLink CONTACT: matthias.samwald ((at))\nmeduniwien.ac.at\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 10:26:13 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 14:53:06 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Breit", "Anna", ""], ["Ott", "Simon", ""], ["Agibetov", "Asan", ""], ["Samwald", "Matthias", ""]]}, {"id": "1912.04816", "submitter": "Blai Bonet", "authors": "Blai Bonet and Hector Geffner", "title": "Qualitative Numeric Planning: Reductions and Complexity", "comments": null, "journal-ref": "Journal of Artificial Intelligence Research 69 (2020) 923-961", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Qualitative numerical planning is classical planning extended with\nnon-negative real variables that can be increased or decreased \"qualitatively\",\ni.e., by positive indeterminate amounts. While deterministic planning with\nnumerical variables is undecidable in general, qualitative numerical planning\nis decidable and provides a convenient abstract model for generalized planning.\nThe solutions to qualitative numerical problems (QNPs) were shown to correspond\nto the strong cyclic solutions of an associated fully observable\nnon-deterministic (FOND) problem that terminate. This leads to a\ngenerate-and-test algorithm for solving QNPs where solutions to a FOND problem\nare generated one by one and tested for termination. The computational\nshortcomings of this approach for solving QNPs, however, are that it is not\nsimple to amend FOND planners to generate all solutions, and that the number of\nsolutions to check can be doubly exponential in the number of variables. In\nthis work we address these limitations while providing additional insights on\nQNPs. More precisely, we introduce two polynomial-time reductions, one from\nQNPs to FOND problems and the other from FOND problems to QNPs both of which do\nnot involve termination tests. A result of these reductions is that QNPs are\nshown to have the same expressive power and the same complexity as FOND\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 16:50:41 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 14:48:27 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Bonet", "Blai", ""], ["Geffner", "Hector", ""]]}, {"id": "1912.04900", "submitter": "Hong Zhu", "authors": "Hong Zhu, Dongmei Liu, Ian Bayley, Rachel Harrison and Fabio Cuzzolin", "title": "Datamorphic Testing: A Methodology for Testing AI Applications", "comments": "This technical report is an extended version of conference paper:\n  [Zhu, H., Liu, D., Ian Bayley, I., Harrison, R. and Cuzzolin, F., Datamorphic\n  Testing: A Method for Testing Intelligent Applications, The 1st IEEE\n  International Conference On Artificial Intelligence Testing (IEEE AITest\n  2019), San Francisco, California, USA, April, 4 - 9, 2019.]", "journal-ref": null, "doi": null, "report-no": "OBU-ECM-AFM-2018-02", "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of the applications of machine learning (ML) and other\nartificial intelligence (AI) techniques, adequate testing has become a\nnecessity to ensure their quality. This paper identifies the characteristics of\nAI applications that distinguish them from traditional software, and analyses\nthe main difficulties in applying existing testing methods. Based on this\nanalysis, we propose a new method called datamorphic testing and illustrate the\nmethod with an example of testing face recognition applications. We also report\nan experiment with four real industrial application systems of face recognition\nto validate the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 13:26:53 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Zhu", "Hong", ""], ["Liu", "Dongmei", ""], ["Bayley", "Ian", ""], ["Harrison", "Rachel", ""], ["Cuzzolin", "Fabio", ""]]}, {"id": "1912.04964", "submitter": "Dimiter Dobrev", "authors": "Dimiter Dobrev", "title": "Before we can find a model, we must forget about perfection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With Reinforcement Learning we assume that a model of the world does exist.\nWe assume furthermore that the model in question is perfect (i.e. it describes\nthe world completely and unambiguously). This article will demonstrate that it\ndoes not make sense to search for the perfect model because this model is too\ncomplicated and practically impossible to find. We will show that we should\nabandon the pursuit of perfection and pursue Event-Driven (ED) models instead.\nThese models are generalization of Markov Decision Process (MDP) models. This\ngeneralization is essential because nothing can be found without it. Rather\nthan a single MDP, we will aim to find a raft of neat simple ED models each one\ndescribing a simple dependency or property. In other words, we will replace the\nsearch for a singular and complex perfect model with a search for a large\nnumber of simple models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 20:20:34 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Dobrev", "Dimiter", ""]]}, {"id": "1912.04999", "submitter": "Maen Alzubi", "authors": "Maen Alzubi, Mohammad Almseidin, Mohd Aaqib Lone and Szilveszter\n  Kovacs", "title": "Fuzzy Rule Interpolation Toolbox for the GNU Open-Source OCTAVE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most fuzzy control applications (applying classical fuzzy reasoning), the\nreasoning method requires a complete fuzzy rule-base, i.e all the possible\nobservations must be covered by the antecedents of the fuzzy rules, which is\nnot always available. Fuzzy control systems based on the Fuzzy Rule\nInterpolation (FRI) concept play a major role in different platforms, in case\nif only a sparse fuzzy rule-base is available. This cases the fuzzy model\ncontains only the most relevant rules, without covering all the antecedent\nuniverses. The first FRI toolbox being able to handle different FRI methods was\ndeveloped by Johanyak et. al. in 2006 for the MATLAB environment. The goal of\nthis paper is to introduce some details of the adaptation of the FRI toolbox to\nsupport the GNU/OCTAVE programming language. The OCTAVE Fuzzy Rule\nInterpolation (OCTFRI) Toolbox is an open-source toolbox for OCTAVE programming\nlanguage, providing a large functionally compatible subset of the MATLAB FRI\ntoolbox as well as many extensions. The OCTFRI Toolbox includes functions that\nenable the user to evaluate Fuzzy Inference Systems (FISs) from the command\nline and from OCTAVE scripts, read/write FISs and OBS to/from files, and\nproduce a graphical visualisation of both the membership functions and the FIS\noutputs. Future work will focus on implementing advanced fuzzy inference\ntechniques and GUI tools.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 22:04:29 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Alzubi", "Maen", ""], ["Almseidin", "Mohammad", ""], ["Lone", "Mohd Aaqib", ""], ["Kovacs", "Szilveszter", ""]]}, {"id": "1912.05008", "submitter": "Desmond Ong", "authors": "Desmond C. Ong, Zhengxuan Wu, Tan Zhi-Xuan, Marianne Reddan, Isabella\n  Kahhale, Alison Mattek, Jamil Zaki", "title": "Modeling emotion in complex stories: the Stanford Emotional Narratives\n  Dataset", "comments": "16 pages, 7 figures; accepted for publication at IEEE Transactions on\n  Affective Computing", "journal-ref": null, "doi": "10.1109/TAFFC.2019.2955949", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human emotions unfold over time, and more affective computing research has to\nprioritize capturing this crucial component of real-world affect. Modeling\ndynamic emotional stimuli requires solving the twin challenges of time-series\nmodeling and of collecting high-quality time-series datasets. We begin by\nassessing the state-of-the-art in time-series emotion recognition, and we\nreview contemporary time-series approaches in affective computing, including\ndiscriminative and generative models. We then introduce the first version of\nthe Stanford Emotional Narratives Dataset (SENDv1): a set of rich, multimodal\nvideos of self-paced, unscripted emotional narratives, annotated for emotional\nvalence over time. The complex narratives and naturalistic expressions in this\ndataset provide a challenging test for contemporary time-series emotion\nrecognition models. We demonstrate several baseline and state-of-the-art\nmodeling approaches on the SEND, including a Long Short-Term Memory model and a\nmultimodal Variational Recurrent Neural Network, which perform comparably to\nthe human-benchmark. We end by discussing the implications for future research\nin time-series affective computing.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 07:55:08 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Ong", "Desmond C.", ""], ["Wu", "Zhengxuan", ""], ["Zhi-Xuan", "Tan", ""], ["Reddan", "Marianne", ""], ["Kahhale", "Isabella", ""], ["Mattek", "Alison", ""], ["Zaki", "Jamil", ""]]}, {"id": "1912.05011", "submitter": "Felix Biessmann", "authors": "Felix Biessmann and Dionysius Irza Refiano", "title": "A psychophysics approach for quantitative comparison of interpretable\n  computer vision models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of transparent Machine Learning (ML) has contributed many novel\nmethods aiming at better interpretability for computer vision and ML models in\ngeneral. But how useful the explanations provided by transparent ML methods are\nfor humans remains difficult to assess. Most studies evaluate interpretability\nin qualitative comparisons, they use experimental paradigms that do not allow\nfor direct comparisons amongst methods or they report only offline experiments\nwith no humans in the loop. While there are clear advantages of evaluations\nwith no humans in the loop, such as scalability, reproducibility and less\nalgorithmic bias than with humans in the loop, these metrics are limited in\ntheir usefulness if we do not understand how they relate to other metrics that\ntake human cognition into account. Here we investigate the quality of\ninterpretable computer vision algorithms using techniques from psychophysics.\nIn crowdsourced annotation tasks we study the impact of different\ninterpretability approaches on annotation accuracy and task time. In order to\nrelate these findings to quality measures for interpretability without humans\nin the loop we compare quality metrics with and without humans in the loop. Our\nresults demonstrate that psychophysical experiments allow for robust quality\nassessment of transparency in machine learning. Interestingly the quality\nmetrics computed without humans in the loop did not provide a consistent\nranking of interpretability methods nor were they representative for how useful\nan explanation was for humans. These findings highlight the potential of\nmethods from classical psychophysics for modern machine learning applications.\nWe hope that our results provide convincing arguments for evaluating\ninterpretability in its natural habitat, human-ML interaction, if the goal is\nto obtain an authentic assessment of interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 16:51:20 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Biessmann", "Felix", ""], ["Refiano", "Dionysius Irza", ""]]}, {"id": "1912.05022", "submitter": "Mohammadreza Fani Sani", "authors": "Mohammadreza Fani Sani, Sebastiaan J. van Zelst, Wil M.P. van der\n  Aalst", "title": "Conformance Checking Approximation using Subset Selection and Edit\n  Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conformance checking techniques let us find out to what degree a process\nmodel and real execution data correspond to each other. In recent years,\nalignments have proven extremely useful in calculating conformance statistics.\nMost techniques to compute alignments provide an exact solution. However, in\nmany applications, it is enough to have an approximation of the conformance\nvalue. Specifically, for large event data, the computing time for alignments is\nconsiderably long using current techniques which makes them inapplicable in\nreality. Also, it is no longer feasible to use standard hardware for complex\nprocesses. Hence, we need techniques that enable us to obtain fast, and at the\nsame time, accurate approximation of the conformance values. This paper\nproposes new approximation techniques to compute approximated conformance\nchecking values close to exact solution values in a faster time. Those methods\nalso provide upper and lower bounds for the approximated alignment value. Our\nexperiments on real event data show that it is possible to improve the\nperformance of conformance checking by using the proposed methods compared to\nusing the state-of-the-art alignment approximation technique. Results show that\nin most of the cases, we provide tight bounds, accurate approximated alignment\nvalues, and similar deviation statistics.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 00:31:52 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Sani", "Mohammadreza Fani", ""], ["van Zelst", "Sebastiaan J.", ""], ["van der Aalst", "Wil M. P.", ""]]}, {"id": "1912.05063", "submitter": "Aaron Eberhart", "authors": "Aaron Eberhart, Monireh Ebrahimi, Lu Zhou, Cogan Shimizu, and Pascal\n  Hitzler", "title": "Completion Reasoning Emulation for the Description Logic EL+", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to integrating deep learning with knowledge-based\nsystems that we believe shows promise. Our approach seeks to emulate reasoning\nstructure, which can be inspected part-way through, rather than simply learning\nreasoner answers, which is typical in many of the black-box systems currently\nin use. We demonstrate that this idea is feasible by training a long short-term\nmemory (LSTM) artificial neural network to learn EL+ reasoning patterns with\ntwo different data sets. We also show that this trained system is resistant to\nnoise by corrupting a percentage of the test data and comparing the reasoner's\nand LSTM's predictions on corrupt data with correct answers.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 00:29:18 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Eberhart", "Aaron", ""], ["Ebrahimi", "Monireh", ""], ["Zhou", "Lu", ""], ["Shimizu", "Cogan", ""], ["Hitzler", "Pascal", ""]]}, {"id": "1912.05100", "submitter": "Kacper Sokol", "authors": "Kacper Sokol and Peter Flach", "title": "Explainability Fact Sheets: A Framework for Systematic Assessment of\n  Explainable Approaches", "comments": "Conference on Fairness, Accountability, and Transparency (FAT* '20),\n  January 27-30, 2020, Barcelona, Spain", "journal-ref": null, "doi": "10.1145/3351095.3372870", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explanations in Machine Learning come in many forms, but a consensus\nregarding their desired properties is yet to emerge. In this paper we introduce\na taxonomy and a set of descriptors that can be used to characterise and\nsystematically assess explainable systems along five key dimensions:\nfunctional, operational, usability, safety and validation. In order to design a\ncomprehensive and representative taxonomy and associated descriptors we\nsurveyed the eXplainable Artificial Intelligence literature, extracting the\ncriteria and desiderata that other authors have proposed or implicitly used in\ntheir research. The survey includes papers introducing new explainability\nalgorithms to see what criteria are used to guide their development and how\nthese algorithms are evaluated, as well as papers proposing such criteria from\nboth computer science and social science perspectives. This novel framework\nallows to systematically compare and contrast explainability approaches, not\njust to better understand their capabilities but also to identify discrepancies\nbetween their theoretical qualities and properties of their implementations. We\ndeveloped an operationalisation of the framework in the form of Explainability\nFact Sheets, which enable researchers and practitioners alike to quickly grasp\ncapabilities and limitations of a particular explainable method. When used as a\nWork Sheet, our taxonomy can guide the development of new explainability\napproaches by aiding in their critical evaluation along the five proposed\ndimensions.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 03:21:23 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Sokol", "Kacper", ""], ["Flach", "Peter", ""]]}, {"id": "1912.05104", "submitter": "Riashat Islam", "authors": "Riashat Islam, Raihan Seraj, Pierre-Luc Bacon, Doina Precup", "title": "Entropy Regularization with Discounted Future State Distribution in\n  Policy Gradient Methods", "comments": "In Submission; Appeared at NeurIPS 2019 Optimization Foundations of\n  Reinforcement Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The policy gradient theorem is defined based on an objective with respect to\nthe initial distribution over states. In the discounted case, this results in\npolicies that are optimal for one distribution over initial states, but may not\nbe uniformly optimal for others, no matter where the agent starts from.\nFurthermore, to obtain unbiased gradient estimates, the starting point of the\npolicy gradient estimator requires sampling states from a normalized discounted\nweighting of states. However, the difficulty of estimating the normalized\ndiscounted weighting of states, or the stationary state distribution, is quite\nwell-known. Additionally, the large sample complexity of policy gradient\nmethods is often attributed to insufficient exploration, and to remedy this, it\nis often assumed that the restart distribution provides sufficient exploration\nin these algorithms. In this work, we propose exploration in policy gradient\nmethods based on maximizing entropy of the discounted future state\ndistribution. The key contribution of our work includes providing a practically\nfeasible algorithm to estimate the normalized discounted weighting of states,\ni.e, the \\textit{discounted future state distribution}. We propose that\nexploration can be achieved by entropy regularization with the discounted state\ndistribution in policy gradients, where a metric for maximal coverage of the\nstate space can be based on the entropy of the induced state distribution. The\nproposed approach can be considered as a three time-scale algorithm and under\nsome mild technical conditions, we prove its convergence to a locally optimal\npolicy. Experimentally, we demonstrate usefulness of regularization with the\ndiscounted future state distribution in terms of increased state space coverage\nand faster learning on a range of complex tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 03:40:46 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Islam", "Riashat", ""], ["Seraj", "Raihan", ""], ["Bacon", "Pierre-Luc", ""], ["Precup", "Doina", ""]]}, {"id": "1912.05205", "submitter": "Tianying Wang", "authors": "Tianying Wang, Hao Zhang, Wei Qi Toh, Hongyuan Zhu, Cheston Tan, Yan\n  Wu, Yong Liu, Wei Jing", "title": "Efficient Robotic Task Generalization Using Deep Model Fusion\n  Reinforcement Learning", "comments": "Accepted by ROBIO 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based methods have been used to pro-gram robotic tasks in recent\nyears. However, extensive training is usually required not only for the initial\ntask learning but also for generalizing the learned model to the same task but\nin different environments. In this paper, we propose a novel Deep Reinforcement\nLearning algorithm for efficient task generalization and environment adaptation\nin the robotic task learning problem. The proposed method is able to\nefficiently generalize the previously learned task by model fusion to solve the\nenvironment adaptation problem. The proposed Deep Model Fusion (DMF) method\nreuses and combines the previously trained model to improve the learning\nefficiency and results.Besides, we also introduce a Multi-objective Guided\nReward(MGR) shaping technique to further improve training efficiency.The\nproposed method was benchmarked with previous methods in various environments\nto validate its effectiveness.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 09:53:21 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Wang", "Tianying", ""], ["Zhang", "Hao", ""], ["Toh", "Wei Qi", ""], ["Zhu", "Hongyuan", ""], ["Tan", "Cheston", ""], ["Wu", "Yan", ""], ["Liu", "Yong", ""], ["Jing", "Wei", ""]]}, {"id": "1912.05238", "submitter": "Patrick Schramowski", "authors": "Patrick Schramowski, Cigdem Turan, Sophie Jentzsch, Constantin\n  Rothkopf and Kristian Kersting", "title": "BERT has a Moral Compass: Improvements of ethical and moral values of\n  machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Allowing machines to choose whether to kill humans would be devastating for\nworld peace and security. But how do we equip machines with the ability to\nlearn ethical or even moral choices? Jentzsch et al.(2019) showed that applying\nmachine learning to human texts can extract deontological ethical reasoning\nabout \"right\" and \"wrong\" conduct by calculating a moral bias score on a\nsentence level using sentence embeddings. The machine learned that it is\nobjectionable to kill living beings, but it is fine to kill time; It is\nessential to eat, yet one might not eat dirt; it is important to spread\ninformation, yet one should not spread misinformation. However, the evaluated\nmoral bias was restricted to simple actions -- one verb -- and a ranking of\nactions with surrounding context. Recently BERT ---and variants such as RoBERTa\nand SBERT--- has set a new state-of-the-art performance for a wide range of NLP\ntasks. But has BERT also a better moral compass? In this paper, we discuss and\nshow that this is indeed the case. Thus, recent improvements of language\nrepresentations also improve the representation of the underlying ethical and\nmoral values of the machine. We argue that through an advanced semantic\nrepresentation of text, BERT allows one to get better insights of moral and\nethical values implicitly represented in text. This enables the Moral Choice\nMachine (MCM) to extract more accurate imprints of moral choices and ethical\nvalues.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 11:27:06 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Schramowski", "Patrick", ""], ["Turan", "Cigdem", ""], ["Jentzsch", "Sophie", ""], ["Rothkopf", "Constantin", ""], ["Kersting", "Kristian", ""]]}, {"id": "1912.05284", "submitter": "Tomi Peltola", "authors": "Mustafa Mert \\c{C}elikok, Tomi Peltola, Pedram Daee, Samuel Kaski", "title": "Interactive AI with a Theory of Mind", "comments": "This is a slightly updated version of a manuscript that appeared in\n  ACM CHI 2019 Workshop: Computational Modeling in Human-Computer Interaction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding each other is the key to success in collaboration. For humans,\nattributing mental states to others, the theory of mind, provides the crucial\nadvantage. We argue for formulating human--AI interaction as a multi-agent\nproblem, endowing AI with a computational theory of mind to understand and\nanticipate the user. To differentiate the approach from previous work, we\nintroduce a categorisation of user modelling approaches based on the level of\nagency learnt in the interaction. We describe our recent work in using nested\nmulti-agent modelling to formulate user models for multi-armed bandit based\ninteractive AI systems, including a proof-of-concept user study.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 19:26:48 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["\u00c7elikok", "Mustafa Mert", ""], ["Peltola", "Tomi", ""], ["Daee", "Pedram", ""], ["Kaski", "Samuel", ""]]}, {"id": "1912.05291", "submitter": "Michael Horowitz", "authors": "Michael C. Horowitz, Paul Scharre, and Alexander Velez-Green", "title": "A Stable Nuclear Future? The Impact of Autonomous Systems and Artificial\n  Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential for advances in information-age technologies to undermine\nnuclear deterrence and influence the potential for nuclear escalation\nrepresents a critical question for international politics. One challenge is\nthat uncertainty about the trajectory of technologies such as autonomous\nsystems and artificial intelligence (AI) makes assessments difficult. This\npaper evaluates the relative impact of autonomous systems and artificial\nintelligence in three areas: nuclear command and control, nuclear delivery\nplatforms and vehicles, and conventional applications of autonomous systems\nwith consequences for nuclear stability. We argue that countries may be more\nlikely to use risky forms of autonomy when they fear that their second-strike\ncapabilities will be undermined. Additionally, the potential deployment of\nuninhabited, autonomous nuclear delivery platforms and vehicles could raise the\nprospect for accidents and miscalculation. Conventional military applications\nof autonomous systems could simultaneously influence nuclear force postures and\nfirst-strike stability in previously unanticipated ways. In particular, the\nneed to fight at machine speed and the cognitive risk introduced by automation\nbias could increase the risk of unintended escalation. Finally, used properly,\nthere should be many applications of more autonomous systems in nuclear\noperations that can increase reliability, reduce the risk of accidents, and buy\nmore time for decision-makers in a crisis.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 13:35:36 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 18:37:36 GMT"}], "update_date": "2019-12-28", "authors_parsed": [["Horowitz", "Michael C.", ""], ["Scharre", "Paul", ""], ["Velez-Green", "Alexander", ""]]}, {"id": "1912.05304", "submitter": "Hangyu Mao", "authors": "Hangyu Mao, Zhengchao Zhang, Zhen Xiao, Zhibo Gong, Yan Ni", "title": "Learning Agent Communication under Limited Bandwidth by Message Pruning", "comments": "accepted as a regular paper with poster presentation @ AAAI20. arXiv\n  admin note: text overlap with arXiv:1903.05561", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication is a crucial factor for the big multi-agent world to stay\norganized and productive. Recently, Deep Reinforcement Learning (DRL) has been\napplied to learn the communication strategy and the control policy for multiple\nagents. However, the practical \\emph{\\textbf{limited bandwidth}} in multi-agent\ncommunication has been largely ignored by the existing DRL methods.\nSpecifically, many methods keep sending messages incessantly, which consumes\ntoo much bandwidth. As a result, they are inapplicable to multi-agent systems\nwith limited bandwidth. To handle this problem, we propose a gating mechanism\nto adaptively prune less beneficial messages. We evaluate the gating mechanism\non several tasks. Experiments demonstrate that it can prune a lot of messages\nwith little impact on performance. In fact, the performance may be greatly\nimproved by pruning redundant messages. Moreover, the proposed gating mechanism\nis applicable to several previous methods, equipping them the ability to\naddress bandwidth restricted settings.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 02:41:36 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Mao", "Hangyu", ""], ["Zhang", "Zhengchao", ""], ["Xiao", "Zhen", ""], ["Gong", "Zhibo", ""], ["Ni", "Yan", ""]]}, {"id": "1912.05313", "submitter": "Tinghao Zhang", "authors": "Tinghao Zhang, Jing Luo, Ping Chen, Jie Liu", "title": "Flow Rate Control in Smart District Heating Systems Using Deep\n  Reinforcement Learning", "comments": "Submitted to Information Processing in Sensor Networks (IPSN 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At high latitudes, many cities adopt a centralized heating system to improve\nthe energy generation efficiency and to reduce pollution. In multi-tier\nsystems, so-called district heating, there are a few efficient approaches for\nthe flow rate control during the heating process. In this paper, we describe\nthe theoretical methods to solve this problem by deep reinforcement learning\nand propose a cloud-based heating control system for implementation. A\nreal-world case study shows the effectiveness and practicability of the\nproposed system controlled by humans, and the simulated experiments for deep\nreinforcement learning show about 1985.01 gigajoules of heat quantity and\n42276.45 tons of water are saved per hour compared with manual control.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 17:55:51 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Zhang", "Tinghao", ""], ["Luo", "Jing", ""], ["Chen", "Ping", ""], ["Liu", "Jie", ""]]}, {"id": "1912.05324", "submitter": "Renata Pelissari", "authors": "Renata Pelissari and Alvaro Jos\\'e Abackerli and Sarah Ben Amor and\n  Maria C\\'elia Oliveira and Kleber Manoel Infante", "title": "Multiple criteria hierarchy process for sorting problems under\n  uncertainty applied to the evaluation of the operational maturity of research\n  institutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the availability of qualified research personnel, up-to-date research\nfacilities and experience in developing applied research and innovation, many\nworldwide research institutions face difficulties when managing contracted\nResearch and Development (R&D) projects due to expectations from Industry\n(private sector). Such difficulties have motivated funding agents to create\nevaluation processes to check whether the operational procedures of funded\nresearch institutions are sufficient to provide timely answers to demand for\ninnovation from industry and also to identify aspects that require quality\nimprovement in research development. For this purpose, several multiple\ncriteria decision-making approaches can be applied. Among the available\nmultiple criteria approaches, sorting methods are one prominent tool to\nevaluate the operational capacity. However, the first difficulty in applying\nmultiple criteria sorting methods is the need to hierarchically structure\nmultiple criteria in order to represent the intended decision process.\nAdditional challenges include the elicitation of the preference information and\nthe definition of criteria evaluation, since these are frequently affected by\nsome imprecision. In this paper, a new sorting method is proposed to deal with\nall of those critical points simultaneously. To consider multiple levels for\nthe decision criteria, the FlowSort method is extended to account for\nhierarchical criteria. To deal with imprecise data, the FlowSort is integrated\nwith fuzzy approaches. To yield solutions that consider fluctuations from\nimprecise weights, the Stochastic Multicriteria Acceptability Analysis is used.\nFinally, the proposed method is applied to the evaluation of research\ninstitutions, classifying them according to their operational maturity for\ndevelopment of applied research.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 19:24:37 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Pelissari", "Renata", ""], ["Abackerli", "Alvaro Jos\u00e9", ""], ["Amor", "Sarah Ben", ""], ["Oliveira", "Maria C\u00e9lia", ""], ["Infante", "Kleber Manoel", ""]]}, {"id": "1912.05328", "submitter": "Bo Zhou", "authors": "Bo Zhou, Hongsheng Zeng, Fan Wang, Yunxiang Li, Hao Tian", "title": "Efficient and Robust Reinforcement Learning with Uncertainty-based Value\n  Expansion", "comments": "1st place in NeurIPS 2019: Learn to Move - Walk Around competition\n  and best paper award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By integrating dynamics models into model-free reinforcement learning (RL)\nmethods, model-based value expansion (MVE) algorithms have shown a significant\nadvantage in sample efficiency as well as value estimation. However, these\nmethods suffer from higher function approximation errors than model-free\nmethods in stochastic environments due to a lack of modeling the environmental\nrandomness. As a result, their performance lags behind the best model-free\nalgorithms in some challenging scenarios. In this paper, we propose a novel\nHybrid-RL method that builds on MVE, namely the Risk Averse Value Expansion\n(RAVE). With imaginative rollouts generated by an ensemble of probabilistic\ndynamics models, we further introduce the aversion of risks by seeking the\nlower confidence bound of the estimation. Experiments on a range of challenging\nenvironments show that by modeling the uncertainty completely, RAVE\nsubstantially enhances the robustness of previous model-based methods, and\nyields state-of-the-art performance. With this technique, our solution gets the\nfirst place in NeurIPS 2019: Learn to Move.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 09:56:14 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Zhou", "Bo", ""], ["Zeng", "Hongsheng", ""], ["Wang", "Fan", ""], ["Li", "Yunxiang", ""], ["Tian", "Hao", ""]]}, {"id": "1912.05407", "submitter": "Yanghao Lin", "authors": "Xu Cao, Yanghao Lin", "title": "UCT-ADP Progressive Bias Algorithm for Solving Gomoku", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine Adaptive Dynamic Programming (ADP), a reinforcement learning\nmethod and UCB applied to trees (UCT) algorithm with a more powerful heuristic\nfunction based on Progressive Bias method and two pruning strategies for a\ntraditional board game Gomoku. For the Adaptive Dynamic Programming part, we\ntrain a shallow forward neural network to give a quick evaluation of Gomoku\nboard situations. UCT is a general approach in MCTS as a tree policy. Our\nframework use UCT to balance the exploration and exploitation of Gomoku game\ntrees while we also apply powerful pruning strategies and heuristic function to\nre-select the available 2-adjacent grids of the state and use ADP instead of\nsimulation to give estimated values of expanded nodes. Experiment result shows\nthat this method can eliminate the search depth defect of the simulation\nprocess and converge to the correct value faster than single UCT. This approach\ncan be applied to design new Gomoku AI and solve other Gomoku-like board game.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 16:05:39 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Cao", "Xu", ""], ["Lin", "Yanghao", ""]]}, {"id": "1912.05453", "submitter": "Krishn Bera", "authors": "Krishn Bera, Yash Mandilwar and Bapi Raju", "title": "Value-of-Information based Arbitration between Model-based and\n  Model-free Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There have been numerous attempts in explaining the general learning\nbehaviours using model-based and model-free methods. While the model-based\ncontrol is flexible yet computationally expensive in planning, the model-free\ncontrol is quick but inflexible. The model-based control is therefore immune\nfrom reward devaluation and contingency degradation. Multiple arbitration\nschemes have been suggested to achieve the data efficiency and computational\nefficiency of model-based and model-free control respectively. In this context,\nwe propose a quantitative 'value of information' based arbitration between both\nthe controllers in order to establish a general computational framework for\nskill learning. The interacting model-based and model-free reinforcement\nlearning processes are arbitrated using an uncertainty-based value of\ninformation. We further show that our algorithm performs better than Q-learning\nas well as Q-learning with experience replay.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 07:26:33 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Bera", "Krishn", ""], ["Mandilwar", "Yash", ""], ["Raju", "Bapi", ""]]}, {"id": "1912.05492", "submitter": "Masataro Asai", "authors": "Masataro Asai", "title": "Neural-Symbolic Descriptive Action Model from Images: The Search for\n  STRIPS", "comments": "Technical Report; not going to be submitted to the conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on Neural-Symbolic systems that learn the discrete planning model\nfrom images has opened a promising direction for expanding the scope of\nAutomated Planning and Scheduling to the raw, noisy data. However, previous\nwork only partially addressed this problem, utilizing the black-box neural\nmodel as the successor generator. In this work, we propose Double-Stage Action\nModel Acquisition (DSAMA), a system that obtains a descriptive PDDL action\nmodel with explicit preconditions and effects over the propositional variables\nunsupervized-learned from images. DSAMA trains a set of Random Forest\nrule-based classifiers and compiles them into logical formulae in PDDL. While\nwe obtained a competitively accurate PDDL model compared to a black-box model,\nwe observed that the resulting PDDL is too large and complex for the\nstate-of-the-art standard planners such as Fast Downward primarily due to the\nPDDL-SAS+ translator bottleneck. From this negative result, we argue that this\ntranslator bottleneck cannot be addressed just by using a different, existing\nrule-based learning method, and we point to the potential future directions.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 17:45:29 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Asai", "Masataro", ""]]}, {"id": "1912.05500", "submitter": "Zeyu Zheng", "authors": "Zeyu Zheng, Junhyuk Oh, Matteo Hessel, Zhongwen Xu, Manuel Kroiss,\n  Hado van Hasselt, David Silver, Satinder Singh", "title": "What Can Learned Intrinsic Rewards Capture?", "comments": "ICML 2020. The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of a reinforcement learning agent is to behave so as to\nmaximise the sum of a suitable scalar function of state: the reward. These\nrewards are typically given and immutable. In this paper, we instead consider\nthe proposition that the reward function itself can be a good locus of learned\nknowledge. To investigate this, we propose a scalable meta-gradient framework\nfor learning useful intrinsic reward functions across multiple lifetimes of\nexperience. Through several proof-of-concept experiments, we show that it is\nfeasible to learn and capture knowledge about long-term exploration and\nexploitation into a reward function. Furthermore, we show that unlike policy\ntransfer methods that capture \"how\" the agent should behave, the learned reward\nfunctions can generalise to other kinds of agents and to changes in the\ndynamics of the environment by capturing \"what\" the agent should strive to do.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 18:00:05 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 02:17:29 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 21:16:59 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Zheng", "Zeyu", ""], ["Oh", "Junhyuk", ""], ["Hessel", "Matteo", ""], ["Xu", "Zhongwen", ""], ["Kroiss", "Manuel", ""], ["van Hasselt", "Hado", ""], ["Silver", "David", ""], ["Singh", "Satinder", ""]]}, {"id": "1912.05510", "submitter": "Glen Berseth", "authors": "Glen Berseth, Daniel Geng, Coline Devin, Nicholas Rhinehart, Chelsea\n  Finn, Dinesh Jayaraman, Sergey Levine", "title": "SMiRL: Surprise Minimizing Reinforcement Learning in Unstable\n  Environments", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every living organism struggles against disruptive environmental forces to\ncarve out and maintain an orderly niche. We propose that such a struggle to\nachieve and preserve order might offer a principle for the emergence of useful\nbehaviors in artificial agents. We formalize this idea into an unsupervised\nreinforcement learning method called surprise minimizing reinforcement learning\n(SMiRL). SMiRL alternates between learning a density model to evaluate the\nsurprise of a stimulus, and improving the policy to seek more predictable\nstimuli. The policy seeks out stable and repeatable situations that counteract\nthe environment's prevailing sources of entropy. This might include avoiding\nother hostile agents, or finding a stable, balanced pose for a bipedal robot in\nthe face of disturbance forces. We demonstrate that our surprise minimizing\nagents can successfully play Tetris, Doom, control a humanoid to avoid falls,\nand navigate to escape enemies in a maze without any task-specific reward\nsupervision. We further show that SMiRL can be used together with standard task\nrewards to accelerate reward-driven learning.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 18:19:11 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 20:10:36 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 00:44:48 GMT"}, {"version": "v4", "created": "Mon, 8 Feb 2021 02:58:22 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Berseth", "Glen", ""], ["Geng", "Daniel", ""], ["Devin", "Coline", ""], ["Rhinehart", "Nicholas", ""], ["Finn", "Chelsea", ""], ["Jayaraman", "Dinesh", ""], ["Levine", "Sergey", ""]]}, {"id": "1912.05525", "submitter": "Leon Lang", "authors": "Benjamin Kolb, Leon Lang, Henning Bartsch, Arwin Gansekoele, Raymond\n  Koopmanschap, Leonardo Romor, David Speck, Mathijs Mul, Elia Bruni", "title": "Learning to Request Guidance in Emergent Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous research into agent communication has shown that a pre-trained guide\ncan speed up the learning process of an imitation learning agent. The guide\nachieves this by providing the agent with discrete messages in an emerged\nlanguage about how to solve the task. We extend this one-directional\ncommunication by a one-bit communication channel from the learner back to the\nguide: It is able to ask the guide for help, and we limit the guidance by\npenalizing the learner for these requests. During training, the agent learns to\ncontrol this gate based on its current observation. We find that the amount of\nrequested guidance decreases over time and guidance is requested in situations\nof high uncertainty. We investigate the agent's performance in cases of open\nand closed gates and discuss potential motives for the observed gating\nbehavior.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 18:48:05 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Kolb", "Benjamin", ""], ["Lang", "Leon", ""], ["Bartsch", "Henning", ""], ["Gansekoele", "Arwin", ""], ["Koopmanschap", "Raymond", ""], ["Romor", "Leonardo", ""], ["Speck", "David", ""], ["Mul", "Mathijs", ""], ["Bruni", "Elia", ""]]}, {"id": "1912.05530", "submitter": "Arash Shaban-Nejad", "authors": "Jon Hael Brenas, Eun Kyong Shin, Arash Shaban-Nejad", "title": "Adverse Childhood Experiences Ontology for Mental Health Surveillance,\n  Research, and Evaluation: Advanced Knowledge Representation and Semantic Web\n  Techniques", "comments": "11 Pages, 10 figures", "journal-ref": "JMIR Ment Health. 2019 May 21;6(5):e13498", "doi": "10.2196/13498", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: Adverse Childhood Experiences (ACEs), a set of negative events\nand processes that a person might encounter during childhood and adolescence,\nhave been proven to be linked to increased risks of a multitude of negative\nhealth outcomes and conditions when children reach adulthood and beyond.\n  Objective: To better understand the relationship between ACEs and their\nrelevant risk factors with associated health outcomes and to eventually design\nand implement preventive interventions, access to an integrated coherent\ndataset is needed. Therefore, we implemented a formal ontology as a resource to\nallow the mental health community to facilitate data integration and knowledge\nmodeling and to improve ACEs surveillance and research.\n  Methods: We use advanced knowledge representation and Semantic Web tools and\ntechniques to implement the ontology. The current implementation of the\nontology is expressed in the description logic ALCRIQ(D), a sublogic of Web\nOntology Language (OWL 2).\n  Results: The ACEs Ontology has been implemented and made available to the\nmental health community and the public via the BioPortal repository. Moreover,\nmultiple use-case scenarios have been introduced to showcase and evaluate the\nusability of the ontology in action. The ontology was created to be used by\nmajor actors in the ACEs community with different applications, from the\ndiagnosis of individuals and predicting potential negative outcomes that they\nmight encounter to the prevention of ACEs in a population and designing\ninterventions and policies.\n  Conclusions: The ACEs Ontology provides a uniform and reusable semantic\nnetwork and an integrated knowledge structure for mental health practitioners\nand researchers to improve ACEs surveillance and evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 22:44:40 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Brenas", "Jon Hael", ""], ["Shin", "Eun Kyong", ""], ["Shaban-Nejad", "Arash", ""]]}, {"id": "1912.05604", "submitter": "Clemens Eppner", "authors": "Clemens Eppner and Arsalan Mousavian and Dieter Fox", "title": "A Billion Ways to Grasp: An Evaluation of Grasp Sampling Schemes on a\n  Dense, Physics-based Grasp Data Set", "comments": "For associated web page, see\n  https://sites.google.com/view/abillionwaystograsp . 19th International\n  Symposium of Robotics Research (ISRR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot grasping is often formulated as a learning problem. With the increasing\nspeed and quality of physics simulations, generating large-scale grasping data\nsets that feed learning algorithms is becoming more and more popular. An often\noverlooked question is how to generate the grasps that make up these data sets.\nIn this paper, we review, classify, and compare different grasp sampling\nstrategies. Our evaluation is based on a fine-grained discretization of SE(3)\nand uses physics-based simulation to evaluate the quality and robustness of the\ncorresponding parallel-jaw grasps. Specifically, we consider more than 1\nbillion grasps for each of the 21 objects from the YCB data set. This dense\ndata set lets us evaluate existing sampling schemes w.r.t. their bias and\nefficiency. Our experiments show that some popular sampling schemes contain\nsignificant bias and do not cover all possible ways an object can be grasped.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 20:22:52 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Eppner", "Clemens", ""], ["Mousavian", "Arsalan", ""], ["Fox", "Dieter", ""]]}, {"id": "1912.05638", "submitter": "Kadir G\\\"um\\\"us", "authors": "Kadir G\\\"um\\\"us, Alex Alvarado, Bin Chen, Christian H\\\"ager, Erik\n  Agrell", "title": "End-to-End Learning of Geometrical Shaping Maximizing Generalized Mutual\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GMI-based end-to-end learning is shown to be highly nonconvex. We apply\ngradient descent initialized with Gray-labeled APSK constellations directly to\nthe constellation coordinates. State-of-the-art constellations in 2D and 4D are\nfound providing reach increases up to 26\\% w.r.t. to QAM.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 21:25:46 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["G\u00fcm\u00fcs", "Kadir", ""], ["Alvarado", "Alex", ""], ["Chen", "Bin", ""], ["H\u00e4ger", "Christian", ""], ["Agrell", "Erik", ""]]}, {"id": "1912.05654", "submitter": "Nikolaos Passalis", "authors": "Nikolaos Passalis and Stavros Doropoulos", "title": "deepsing: Generating Sentiment-aware Visual Stories using Cross-modal\n  Music Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a deep learning method for performing\nattributed-based music-to-image translation. The proposed method is applied for\nsynthesizing visual stories according to the sentiment expressed by songs. The\ngenerated images aim to induce the same feelings to the viewers, as the\noriginal song does, reinforcing the primary aim of music, i.e., communicating\nfeelings. The process of music-to-image translation poses unique challenges,\nmainly due to the unstable mapping between the different modalities involved in\nthis process. In this paper, we employ a trainable cross-modal translation\nmethod to overcome this limitation, leading to the first, to the best of our\nknowledge, deep learning method for generating sentiment-aware visual stories.\nVarious aspects of the proposed method are extensively evaluated and discussed\nusing different songs.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 21:46:41 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Passalis", "Nikolaos", ""], ["Doropoulos", "Stavros", ""]]}, {"id": "1912.05662", "submitter": "Roger Immich", "authors": "Diego O. Rodrigues, Frances A. Santos, Geraldo P. Rocha Filho, Ademar\n  T. Akabane, Raquel Cabral, Roger Immich, Wellington L. Junior, Felipe D.\n  Cunha, Daniel L. Guidoni, Thiago H. Silva, Denis Ros\\'ario, Eduardo\n  Cerqueira, Antonio A. F. Loureiro, Leandro A. Villas", "title": "Computa\\c{c}\\~ao Urbana da Teoria \\`a Pr\\'atica: Fundamentos,\n  Aplica\\c{c}\\~oes e Desafios", "comments": "in Portuguese. Simp\\'osio Brasileiro de Redes de Computadores e\n  Sistemas Distribu\\'idos (SBRC) 2019 - Minicursos", "journal-ref": "Simposio Brasileiro de Redes de Computadores e Sistemas\n  Distribuidos (SBRC), 2019", "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.DC cs.HC cs.IR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing of cities has resulted in innumerable technical and managerial\nchallenges for public administrators such as energy consumption, pollution,\nurban mobility and even supervision of private and public spaces in an\nappropriate way. Urban Computing emerges as a promising paradigm to solve such\nchallenges, through the extraction of knowledge, from a large amount of\nheterogeneous data existing in urban space. Moreover, Urban Computing\ncorrelates urban sensing, data management, and analysis to provide services\nthat have the potential to improve the quality of life of the citizens of large\nurban centers. Consider this context, this chapter aims to present the\nfundamentals of Urban Computing and the steps necessary to develop an\napplication in this area. To achieve this goal, the following questions will be\ninvestigated, namely: (i) What are the main research problems of Urban\nComputing?; (ii) What are the technological challenges for the implementation\nof services in Urban Computing?; (iii) What are the main methodologies used for\nthe development of services in Urban Computing?; and (iv) What are the\nrepresentative applications in this field?\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 15:01:58 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Rodrigues", "Diego O.", ""], ["Santos", "Frances A.", ""], ["Filho", "Geraldo P. Rocha", ""], ["Akabane", "Ademar T.", ""], ["Cabral", "Raquel", ""], ["Immich", "Roger", ""], ["Junior", "Wellington L.", ""], ["Cunha", "Felipe D.", ""], ["Guidoni", "Daniel L.", ""], ["Silva", "Thiago H.", ""], ["Ros\u00e1rio", "Denis", ""], ["Cerqueira", "Eduardo", ""], ["Loureiro", "Antonio A. F.", ""], ["Villas", "Leandro A.", ""]]}, {"id": "1912.05663", "submitter": "Stephanie Chan", "authors": "Stephanie C.Y. Chan, Samuel Fishman, John Canny, Anoop Korattikara,\n  Sergio Guadarrama", "title": "Measuring the Reliability of Reinforcement Learning Algorithms", "comments": "Accepted for publication at ICLR 2020 (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lack of reliability is a well-known issue for reinforcement learning (RL)\nalgorithms. This problem has gained increasing attention in recent years, and\nefforts to improve it have grown substantially. To aid RL researchers and\nproduction users with the evaluation and improvement of reliability, we propose\na set of metrics that quantitatively measure different aspects of reliability.\nIn this work, we focus on variability and risk, both during training and after\nlearning (on a fixed policy). We designed these metrics to be general-purpose,\nand we also designed complementary statistical tests to enable rigorous\ncomparisons on these metrics. In this paper, we first describe the desired\nproperties of the metrics and their design, the aspects of reliability that\nthey measure, and their applicability to different scenarios. We then describe\nthe statistical tests and make additional practical recommendations for\nreporting results. The metrics and accompanying statistical tools have been\nmade available as an open-source library at\nhttps://github.com/google-research/rl-reliability-metrics. We apply our metrics\nto a set of common RL algorithms and environments, compare them, and analyze\nthe results.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 17:50:33 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 19:23:15 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Chan", "Stephanie C. Y.", ""], ["Fishman", "Samuel", ""], ["Canny", "John", ""], ["Korattikara", "Anoop", ""], ["Guadarrama", "Sergio", ""]]}, {"id": "1912.05728", "submitter": "Fenglin Li", "authors": "Feng-Lin Li, Weijia Chen, Qi Huang, Yikun Guo", "title": "AliMe KBQA: Question Answering over Structured Knowledge for E-commerce\n  Customer Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the rise of knowledge graph (KG), question answering over knowledge base\n(KBQA) has attracted increasing attention in recent years. Despite much\nresearch has been conducted on this topic, it is still challenging to apply\nKBQA technology in industry because business knowledge and real-world questions\ncan be rather complicated. In this paper, we present AliMe-KBQA, a bold attempt\nto apply KBQA in the E-commerce customer service field. To handle real\nknowledge and questions, we extend the classic \"subject-predicate-object (SPO)\"\nstructure with property hierarchy, key-value structure and compound value type\n(CVT), and enhance traditional KBQA with constraints recognition and reasoning\nability. We launch AliMe-KBQA in the Marketing Promotion scenario for merchants\nduring the \"Double 11\" period in 2018 and other such promotional events\nafterwards. Online results suggest that AliMe-KBQA is not only able to gain\nbetter resolution and improve customer satisfaction, but also becomes the\npreferred knowledge management method by business knowledge staffs since it\noffers a more convenient and efficient management experience.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 02:04:44 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Li", "Feng-Lin", ""], ["Chen", "Weijia", ""], ["Huang", "Qi", ""], ["Guo", "Yikun", ""]]}, {"id": "1912.05743", "submitter": "Akanksha Atrey", "authors": "Akanksha Atrey, Kaleigh Clary, David Jensen", "title": "Exploratory Not Explanatory: Counterfactual Analysis of Saliency Maps\n  for Deep Reinforcement Learning", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saliency maps are frequently used to support explanations of the behavior of\ndeep reinforcement learning (RL) agents. However, a review of how saliency maps\nare used in practice indicates that the derived explanations are often\nunfalsifiable and can be highly subjective. We introduce an empirical approach\ngrounded in counterfactual reasoning to test the hypotheses generated from\nsaliency maps and assess the degree to which they correspond to the semantics\nof RL environments. We use Atari games, a common benchmark for deep RL, to\nevaluate three types of saliency maps. Our results show the extent to which\nexisting claims about Atari games can be evaluated and suggest that saliency\nmaps are best viewed as an exploratory tool rather than an explanatory tool.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 12:42:07 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 21:40:15 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Atrey", "Akanksha", ""], ["Clary", "Kaleigh", ""], ["Jensen", "David", ""]]}, {"id": "1912.05748", "submitter": "Mehdi Dadvar", "authors": "Mehdi Dadvar, Saeed Moazami, Harley R. Myler, and Hassan Zargarzadeh", "title": "Multi-Agent Task Allocation in Complementary Teams: A Hunter and\n  Gatherer Approach", "comments": "15 pages, 12 figures", "journal-ref": "Complexity, vol. 2020, Article ID 1752571, 15 pages, 2020", "doi": "10.1155/2020/1752571", "report-no": null, "categories": "cs.MA cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a dynamic task allocation problem, where tasks are unknowingly\ndistributed over an environment. This paper considers each task comprised of\ntwo sequential subtasks: detection and completion, where each subtask can only\nbe carried out by a certain type of agent. We address this problem using a\nnovel nature-inspired approach called \"hunter and gatherer\". The proposed\nmethod employs two complementary teams of agents: one agile in detecting\n(hunters) and another skillful in completing (gatherers) the tasks. To minimize\nthe collective cost of task accomplishments in a distributed manner, a\ngame-theoretic solution is introduced to couple agents from complementary\nteams. We utilize market-based negotiation models to develop incentive-based\ndecision-making algorithms relying on innovative notions of \"certainty and\nuncertainty profit margins\". The simulation results demonstrate that employing\ntwo complementary teams of hunters and gatherers can effectually improve the\nnumber of tasks completed by agents compared to conventional methods, while the\ncollective cost of accomplishments is minimized. In addition, the stability and\nefficacy of the proposed solutions are studied using Nash equilibrium analysis\nand statistical analysis respectively. It is also numerically shown that the\nproposed solutions function fairly, i.e. for each type of agent, the overall\nworkload is distributed equally.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 03:13:29 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 22:15:20 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Dadvar", "Mehdi", ""], ["Moazami", "Saeed", ""], ["Myler", "Harley R.", ""], ["Zargarzadeh", "Hassan", ""]]}, {"id": "1912.05783", "submitter": "Dzmitry Bahdanau", "authors": "Dzmitry Bahdanau, Harm de Vries, Timothy J. O'Donnell, Shikhar Murty,\n  Philippe Beaudoin, Yoshua Bengio, Aaron Courville", "title": "CLOSURE: Assessing Systematic Generalization of CLEVR Models", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CLEVR dataset of natural-looking questions about 3D-rendered scenes has\nrecently received much attention from the research community. A number of\nmodels have been proposed for this task, many of which achieved very high\naccuracies of around 97-99%. In this work, we study how systematic the\ngeneralization of such models is, that is to which extent they are capable of\nhandling novel combinations of known linguistic constructs. To this end, we\ntest models' understanding of referring expressions based on matching object\nproperties (such as e.g. \"another cube that is the same size as the brown\ncube\") in novel contexts. Our experiments on the thereby constructed CLOSURE\nbenchmark show that state-of-the-art models often do not exhibit systematicity\nafter being trained on CLEVR. Surprisingly, we find that an explicitly\ncompositional Neural Module Network model also generalizes badly on CLOSURE,\neven when it has access to the ground-truth programs at test time. We improve\nthe NMN's systematic generalization by developing a novel Vector-NMN module\narchitecture with vector-valued inputs and outputs. Lastly, we investigate how\nmuch few-shot transfer learning can help models that are pretrained on CLEVR to\nadapt to CLOSURE. Our few-shot learning experiments contrast the adaptation\nbehavior of the models with intermediate discrete programs with that of the\nend-to-end continuous models.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 05:56:53 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 23:58:06 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Bahdanau", "Dzmitry", ""], ["de Vries", "Harm", ""], ["O'Donnell", "Timothy J.", ""], ["Murty", "Shikhar", ""], ["Beaudoin", "Philippe", ""], ["Bengio", "Yoshua", ""], ["Courville", "Aaron", ""]]}, {"id": "1912.05784", "submitter": "Yaoxin Wu", "authors": "Yaoxin Wu, Wen Song, Zhiguang Cao, Jie Zhang, Andrew Lim", "title": "Learning Improvement Heuristics for Solving Routing Problems", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies in using deep learning to solve routing problems focus on\nconstruction heuristics, the solutions of which are still far from optimality.\nImprovement heuristics have great potential to narrow this gap by iteratively\nrefining a solution. However, classic improvement heuristics are all guided by\nhand-crafted rules which may limit their performance. In this paper, we propose\na deep reinforcement learning framework to learn the improvement heuristics for\nrouting problems. We design a self-attention based deep architecture as the\npolicy network to guide the selection of next solution. We apply our method to\ntwo important routing problems, i.e. travelling salesman problem (TSP) and\ncapacitated vehicle routing problem (CVRP). Experiments show that our method\noutperforms state-of-the-art deep learning based approaches. The learned\npolicies are more effective than the traditional hand-crafted ones, and can be\nfurther enhanced by simple diversifying strategies. Moreover, the policies\ngeneralize well to different problem sizes, initial solutions and even\nreal-world dataset.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 05:57:58 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 14:21:56 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Wu", "Yaoxin", ""], ["Song", "Wen", ""], ["Cao", "Zhiguang", ""], ["Zhang", "Jie", ""], ["Lim", "Andrew", ""]]}, {"id": "1912.05796", "submitter": "Haoyu Yang", "authors": "Haoyu Yang, Wen Chen, Piyush Pathak, Frank Gennari, Ya-Chieh Lai, Bei\n  Yu", "title": "Automatic Layout Generation with Applications in Machine Learning Engine\n  Evaluation", "comments": "6 pages, submitted to 1st ACM/IEEE Workshop on Machine Learning for\n  CAD (MLCAD) for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning-based lithography hotspot detection has been deeply studied\nrecently, from varies feature extraction techniques to efficient learning\nmodels. It has been observed that such machine learning-based frameworks are\nproviding satisfactory metal layer hotspot prediction results on known public\nmetal layer benchmarks. In this work, we seek to evaluate how these machine\nlearning-based hotspot detectors generalize to complicated patterns. We first\nintroduce a automatic layout generation tool that can synthesize varies layout\npatterns given a set of design rules. The tool currently supports both metal\nlayer and via layer generation. As a case study, we conduct hotspot detection\non the generated via layer layouts with representative machine learning-based\nhotspot detectors, which shows that continuous study on model robustness and\ngenerality is necessary to prototype and integrate the learning engines in DFM\nflows. The source code of the layout generation tool will be available at\nhttps://github. com/phdyang007/layout-generation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 06:52:12 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Yang", "Haoyu", ""], ["Chen", "Wen", ""], ["Pathak", "Piyush", ""], ["Gennari", "Frank", ""], ["Lai", "Ya-Chieh", ""], ["Yu", "Bei", ""]]}, {"id": "1912.05828", "submitter": "Francesco Belardinelli", "authors": "Ria Jha, Francesco Belardinelli, Francesca Toni", "title": "Formal Verification of Debates in Argumentation Theory", "comments": "Accepted for publication as full paper at the 35th ACM/SIGAPP\n  Symposium On Applied Computing (SAC2020), KRR track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans engage in informal debates on a daily basis. By expressing their\nopinions and ideas in an argumentative fashion, they are able to gain a deeper\nunderstanding of a given problem and in some cases, find the best possible\ncourse of actions towards resolving it. In this paper, we develop a methodology\nto verify debates formalised as abstract argumentation frameworks. We first\npresent a translation from debates to transition systems. Such transition\nsystems can model debates and represent their evolution over time using a\nfinite set of states. We then formalise relevant debate properties using\ntemporal and strategy logics. These formalisations, along with a debate\ntransition system, allow us to verify whether a given debate satisfies certain\nproperties. The verification process can be automated using model checkers.\nTherefore, we also measure their performance when verifying debates, and use\nthe results to discuss the feasibility of model checking debates.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 08:31:34 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Jha", "Ria", ""], ["Belardinelli", "Francesco", ""], ["Toni", "Francesca", ""]]}, {"id": "1912.05877", "submitter": "Hinrich Sch\\\"utze", "authors": "James L. McClelland, Felix Hill, Maja Rudolph, Jason Baldridge and\n  Hinrich Sch\\\"utze", "title": "Extending Machine Language Models toward Human-Level Language\n  Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language is crucial for human intelligence, but what exactly is its role? We\ntake language to be a part of a system for understanding and communicating\nabout situations. The human ability to understand and communicate about\nsituations emerges gradually from experience and depends on domain-general\nprinciples of biological neural networks: connection-based learning,\ndistributed representation, and context-sensitive, mutual constraint\nsatisfaction-based processing. Current artificial language processing systems\nrely on the same domain general principles, embodied in artificial neural\nnetworks. Indeed, recent progress in this field depends on \\emph{query-based\nattention}, which extends the ability of these systems to exploit context and\nhas contributed to remarkable breakthroughs. Nevertheless, most current models\nfocus exclusively on language-internal tasks, limiting their ability to perform\ntasks that depend on understanding situations. These systems also lack memory\nfor the contents of prior situations outside of a fixed contextual span. We\ndescribe the organization of the brain's distributed understanding system,\nwhich includes a fast learning system that addresses the memory problem. We\nsketch a framework for future models of understanding drawing equally on\ncognitive neuroscience and artificial intelligence and exploiting query-based\nattention. We highlight relevant current directions and consider further\ndevelopments needed to fully capture human-level language understanding in a\ncomputational system.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 11:02:30 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 10:17:32 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["McClelland", "James L.", ""], ["Hill", "Felix", ""], ["Rudolph", "Maja", ""], ["Baldridge", "Jason", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1912.05906", "submitter": "Felix Axel Gimeno Gil", "authors": "Xujie Si, Yujia Li, Vinod Nair, Felix Gimeno", "title": "Prioritized Unit Propagation with Periodic Resetting is (Almost) All You\n  Need for Random SAT Solving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose prioritized unit propagation with periodic resetting, which is a\nsimple but surprisingly effective algorithm for solving random SAT instances\nthat are meant to be hard. In particular, an evaluation on the Random Track of\nthe 2017 and 2018 SAT competitions shows that a basic prototype of this simple\nidea already ranks at second place in both years. We share this observation in\nthe hope that it helps the SAT community better understand the hardness of\nrandom instances used in competitions and inspire other interesting ideas on\nSAT solving.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 14:57:02 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Si", "Xujie", ""], ["Li", "Yujia", ""], ["Nair", "Vinod", ""], ["Gimeno", "Felix", ""]]}, {"id": "1912.05907", "submitter": "Thomas Chatain", "authors": "Thomas Chatain (MEXICO, LSV, ENS Paris Saclay), Mathilde Boltenhagen\n  (LSV, CNRS, MEXICO), Josep Carmona (UPC)", "title": "Anti-Alignments -- Measuring The Precision of Process Models and Event\n  Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processes are a crucial artefact in organizations, since they coordinate the\nexecution of activities so that products and services are provided. The use of\nmodels to analyse the underlying processes is a well-known practice. However,\ndue to the complexity and continuous evolution of their processes,\norganizations need an effective way of analysing the relation between processes\nand models. Conformance checking techniques asses the suitability of a process\nmodel in representing an underlying process, observed through a collection of\nreal executions. One important metric in conformance checking is to asses the\nprecision of the model with respect to the observed executions, i.e.,\ncharacterize the ability of the model to produce behavior unrelated to the one\nobserved. In this paper we present the notion of anti-alignment as a concept to\nhelp unveiling runs in the model that may deviate significantly from the\nobserved behavior. Using anti-alignments, a new metric for precision is\nproposed. In contrast to existing metrics, anti-alignment based precision\nmetrics satisfy most of the required axioms highlighted in a recent\npublication. Moreover, a complexity analysis of the problem of computing\nanti-alignments is provided, which sheds light into the practicability of using\nanti-alignment to estimate precision. Experiments are provided that witness the\nvalidity of the concepts introduced in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 07:39:23 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Chatain", "Thomas", "", "MEXICO, LSV, ENS Paris Saclay"], ["Boltenhagen", "Mathilde", "", "LSV, CNRS, MEXICO"], ["Carmona", "Josep", "", "UPC"]]}, {"id": "1912.05929", "submitter": "Karol Suchan", "authors": "Hern\\'an Lespay and Karol Suchan", "title": "A case study of Consistent Vehicle Routing Problem with Time Windows", "comments": null, "journal-ref": null, "doi": "10.1111/itor.12885", "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a heuristic for the Consistent Vehicle Routing Problem with Time\nWindows (ConVRPTW), which is motivated by a real-world application at a food\ncompany's distribution center. Besides standard VRPTW restrictions, ConVRPTW\nassigns each customer just one driver to fulfill their orders during the whole\nmulti-period planning horizon. For each driver and period, a route is sought to\nserve all their customers with positive demand. For each customer, the number\nof periods between consecutive orders and the ordered quantities are highly\nirregular. This causes difficulties in the daily routing, negatively impacting\nthe service level of the company. Similar problems have been studied as ConVRP,\nwhere the number of drivers is fixed a priori, and only the total travel time\nis minimized. Moreover, the clients present no time window constraints, but the\nvisits should be scheduled with a small arrival time variation. In our model,\nthe objective is to minimize the number of drivers. We impose hard time windows\nbut do not consider time consistency in more detail. We compare solutions given\nby the heuristic with solutions of a MILP model on a set of small artificial\ninstances and solutions used by the food company on real-world instances. The\nresults show the effectiveness of the heuristic. For the company, we obtain\nsignificant improvements in the routing plans, with a lower number of vehicles\nand a higher rate of orders delivered within the prescribed time window.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 15:58:47 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 19:49:15 GMT"}, {"version": "v3", "created": "Sun, 6 Dec 2020 13:58:33 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Lespay", "Hern\u00e1n", ""], ["Suchan", "Karol", ""]]}, {"id": "1912.05935", "submitter": "Eros Grigoryan", "authors": "E. Grigoryan", "title": "Linear algorithm for solution n-Queens Completion problem", "comments": "37 pages, 11 figures, 2 tables, Prepared for publication in \"Discrete\n  Mathematics & Theoretical Computer Science\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A linear algorithm is described for solving the n-Queens Completion problem\nfor an arbitrary composition of k queens, consistently distributed on a\nchessboard of size n x n. Two important rules are used in the algorithm: a) the\nrule of sequential risk elimination for the entire system as a whole; b) the\nrule of formation of minimal damage in the given selection conditions. For any\ncomposition of k queens (1<= k<n), a solution is provided, or a decision is\nmade that this composition can't be completed. The probability of an error in\nmaking such a decision does not exceed 0.0001, and its value decreases, with\nincreasing n. It is established that the average time, required for the queen\nto be placed on one row, decreases with increasing value of n. A description is\ngiven of two random selection models and the results of their comparative\nanalysis. A model for organizing the Back Tracking procedure is proposed based\non the separation of the solution matrix into two basic levels. Regression\nformulas are given for the dependence of basic levels on the value of n. It was\nfound that for n=(7-100000) the number of solutions in which the Back Tracking\nprocedure has never been used exceeds 35%. Moreover, for n=(320-22500), the\nnumber of such cases exceeds 50 %. A quick algorithm for verifying the\ncorrectness of n-Queens problem solution or arbitrary composition of k queens\nis given.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 14:21:16 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 10:05:41 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Grigoryan", "E.", ""]]}, {"id": "1912.06074", "submitter": "Yifan Wu", "authors": "Fan Yang, Liu Leqi, Yifan Wu, Zachary C. Lipton, Pradeep Ravikumar,\n  William W. Cohen, Tom Mitchell", "title": "Game Design for Eliciting Distinguishable Behavior", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to inferring latent psychological traits from human behavior is\nkey to developing personalized human-interacting machine learning systems.\nApproaches to infer such traits range from surveys to manually-constructed\nexperiments and games. However, these traditional games are limited because\nthey are typically designed based on heuristics. In this paper, we formulate\nthe task of designing \\emph{behavior diagnostic games} that elicit\ndistinguishable behavior as a mutual information maximization problem, which\ncan be solved by optimizing a variational lower bound. Our framework is\ninstantiated by using prospect theory to model varying player traits, and\nMarkov Decision Processes to parameterize the games. We validate our approach\nempirically, showing that our designed games can successfully distinguish among\nplayers with different traits, outperforming manually-designed ones by a large\nmargin.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 16:50:43 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Yang", "Fan", ""], ["Leqi", "Liu", ""], ["Wu", "Yifan", ""], ["Lipton", "Zachary C.", ""], ["Ravikumar", "Pradeep", ""], ["Cohen", "William W.", ""], ["Mitchell", "Tom", ""]]}, {"id": "1912.06088", "submitter": "Dibya Ghosh", "authors": "Dibya Ghosh, Abhishek Gupta, Ashwin Reddy, Justin Fu, Coline Devin,\n  Benjamin Eysenbach, Sergey Levine", "title": "Learning to Reach Goals via Iterated Supervised Learning", "comments": "First two authors contributed equally. Code available at\n  https://github.com/dibyaghosh/gcsl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current reinforcement learning (RL) algorithms can be brittle and difficult\nto use, especially when learning goal-reaching behaviors from sparse rewards.\nAlthough supervised imitation learning provides a simple and stable\nalternative, it requires access to demonstrations from a human supervisor. In\nthis paper, we study RL algorithms that use imitation learning to acquire goal\nreaching policies from scratch, without the need for expert demonstrations or a\nvalue function. In lieu of demonstrations, we leverage the property that any\ntrajectory is a successful demonstration for reaching the final state in that\nsame trajectory. We propose a simple algorithm in which an agent continually\nrelabels and imitates the trajectories it generates to progressively learn\ngoal-reaching behaviors from scratch. Each iteration, the agent collects new\ntrajectories using the latest policy, and maximizes the likelihood of the\nactions along these trajectories under the goal that was actually reached, so\nas to improve the policy. We formally show that this iterated supervised\nlearning procedure optimizes a bound on the RL objective, derive performance\nbounds of the learned policy, and empirically demonstrate improved\ngoal-reaching performance and robustness over current RL algorithms in several\nbenchmark tasks.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 17:26:47 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 01:42:38 GMT"}, {"version": "v3", "created": "Wed, 10 Jun 2020 17:22:46 GMT"}, {"version": "v4", "created": "Fri, 2 Oct 2020 19:49:10 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ghosh", "Dibya", ""], ["Gupta", "Abhishek", ""], ["Reddy", "Ashwin", ""], ["Fu", "Justin", ""], ["Devin", "Coline", ""], ["Eysenbach", "Benjamin", ""], ["Levine", "Sergey", ""]]}, {"id": "1912.06095", "submitter": "Qingbiao Li", "authors": "Qingbiao Li, Fernando Gama, Alejandro Ribeiro, Amanda Prorok", "title": "Graph Neural Networks for Decentralized Multi-Robot Path Planning", "comments": "This paper has been accepted in the IEEE/RSJ International Conference\n  on Intelligent Robots and Systems (IROS) 2020. For the simulation demo, see\n  this https URL \"https://youtu.be/AGDk2RozpMQ\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective communication is key to successful, decentralized, multi-robot path\nplanning. Yet, it is far from obvious what information is crucial to the task\nat hand, and how and when it must be shared among robots. To side-step these\nissues and move beyond hand-crafted heuristics, we propose a combined model\nthat automatically synthesizes local communication and decision-making policies\nfor robots navigating in constrained workspaces. Our architecture is composed\nof a convolutional neural network (CNN) that extracts adequate features from\nlocal observations, and a graph neural network (GNN) that communicates these\nfeatures among robots. We train the model to imitate an expert algorithm, and\nuse the resulting model online in decentralized planning involving only local\ncommunication and local observations. We evaluate our method in simulations {by\nnavigating teams of robots to their destinations in 2D} cluttered workspaces.\nWe measure the success rates and sum of costs over the planned paths. The\nresults show a performance close to that of our expert algorithm, demonstrating\nthe validity of our approach. In particular, we show our model's capability to\ngeneralize to previously unseen cases (involving larger environments and larger\nrobot teams).\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 17:48:14 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 13:04:20 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Li", "Qingbiao", ""], ["Gama", "Fernando", ""], ["Ribeiro", "Alejandro", ""], ["Prorok", "Amanda", ""]]}, {"id": "1912.06101", "submitter": "Carlos Purves", "authors": "Carlos Purves, C\\u{a}t\\u{a}lina Cangea, Petar Veli\\v{c}kovi\\'c", "title": "The PlayStation Reinforcement Learning Environment (PSXLE)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new benchmark environment for evaluating Reinforcement Learning\n(RL) algorithms: the PlayStation Learning Environment (PSXLE), a PlayStation\nemulator modified to expose a simple control API that enables rich game-state\nrepresentations. We argue that the PlayStation serves as a suitable progression\nfor agent evaluation and propose a framework for such an evaluation. We build\nan action-driven abstraction for a PlayStation game with support for the OpenAI\nGym interface and demonstrate its use by running OpenAI Baselines.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 17:59:52 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Purves", "Carlos", ""], ["Cangea", "C\u0103t\u0103lina", ""], ["Veli\u010dkovi\u0107", "Petar", ""]]}, {"id": "1912.06194", "submitter": "Jens D\\\"orpinghaus", "authors": "Jens D\\\"orpinghaus, Alexander Apke, Vanessa Lage-Rupprecht, Andreas\n  Stefan", "title": "Data Exploration and Validation on dense knowledge graphs for biomedical\n  research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we present a holistic approach for data exploration on dense knowledge\ngraphs as a novel approach with a proof-of-concept in biomedical research.\nKnowledge graphs are increasingly becoming a vital factor in knowledge mining\nand discovery as they connect data using technologies from the semantic web. In\nthis paper we extend a basic knowledge graph extracted from biomedical\nliterature by context data like named entities and relations obtained by text\nmining and other linked data sources like ontologies and databases. We will\npresent an overview about this novel network. The aim of this work was to\nextend this current knowledge with approaches from graph theory. This method\nwill build the foundation for quality control, validation of hypothesis,\ndetection of missing data and time series analysis of biomedical knowledge in\ngeneral. In this context we tried to apply multiple-valued decision diagrams to\nthese questions. In addition this knowledge representation of linked data can\nbe used as FAIR approach to answer semantic questions. This paper sheds new\nlights on dense and very large knowledge graphs and the importance of a\ngraph-theoretic understanding of these networks.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 12:52:35 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["D\u00f6rpinghaus", "Jens", ""], ["Apke", "Alexander", ""], ["Lage-Rupprecht", "Vanessa", ""], ["Stefan", "Andreas", ""]]}, {"id": "1912.06310", "submitter": "Shuai Han", "authors": "Shuai L\\\"u and Shuai Han and Wenbo Zhou and Junwei Zhang", "title": "Recruitment-imitation Mechanism for Evolutionary Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning, evolutionary algorithms and imitation learning are\nthree principal methods to deal with continuous control tasks. Reinforcement\nlearning is sample efficient, yet sensitive to hyper-parameters setting and\nneeds efficient exploration; Evolutionary algorithms are stable, but with low\nsample efficiency; Imitation learning is both sample efficient and stable,\nhowever it requires the guidance of expert data. In this paper, we propose\nRecruitment-imitation Mechanism (RIM) for evolutionary reinforcement learning,\na scalable framework that combines advantages of the three methods mentioned\nabove. The core of this framework is a dual-actors and single critic\nreinforcement learning agent. This agent can recruit high-fitness actors from\nthe population of evolutionary algorithms, which instructs itself to learn from\nexperience replay buffer. At the same time, low-fitness actors in the\nevolutionary population can imitate behavior patterns of the reinforcement\nlearning agent and improve their adaptability. Reinforcement and imitation\nlearners in this framework can be replaced with any off-policy actor-critic\nreinforcement learner or data-driven imitation learner. We evaluate RIM on a\nseries of benchmarks for continuous control tasks in Mujoco. The experimental\nresults show that RIM outperforms prior evolutionary or reinforcement learning\nmethods. The performance of RIM's components is significantly better than\ncomponents of previous evolutionary reinforcement learning algorithm, and the\nrecruitment using soft update enables reinforcement learning agent to learn\nfaster than that using hard update.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 03:26:14 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["L\u00fc", "Shuai", ""], ["Han", "Shuai", ""], ["Zhou", "Wenbo", ""], ["Zhang", "Junwei", ""]]}, {"id": "1912.06321", "submitter": "Joanne Truong", "authors": "Abhishek Kadian, Joanne Truong, Aaron Gokaslan, Alexander Clegg, Erik\n  Wijmans, Stefan Lee, Manolis Savva, Sonia Chernova, Dhruv Batra", "title": "Sim2Real Predictivity: Does Evaluation in Simulation Predict Real-World\n  Performance?", "comments": null, "journal-ref": "IEEE Robotics and Automation Letters (RA-L) 2020", "doi": "10.1109/LRA.2020.3013848", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Does progress in simulation translate to progress on robots? If one method\noutperforms another in simulation, how likely is that trend to hold in reality\non a robot? We examine this question for embodied PointGoal navigation,\ndeveloping engineering tools and a research paradigm for evaluating a simulator\nby its sim2real predictivity. First, we develop Habitat-PyRobot Bridge (HaPy),\na library for seamless execution of identical code on simulated agents and\nrobots, transferring simulation-trained agents to a LoCoBot platform with a\none-line code change. Second, we investigate the sim2real predictivity of\nHabitat-Sim for PointGoal navigation. We 3D-scan a physical lab space to create\na virtualized replica, and run parallel tests of 9 different models in reality\nand simulation. We present a new metric called Sim-vs-Real Correlation\nCoefficient (SRCC) to quantify predictivity. We find that SRCC for Habitat as\nused for the CVPR19 challenge is low (0.18 for the success metric), suggesting\nthat performance differences in this simulator-based challenge do not persist\nafter physical deployment. This gap is largely due to AI agents learning to\nexploit simulator imperfections, abusing collision dynamics to 'slide' along\nwalls, leading to shortcuts through otherwise non-navigable space. Naturally,\nsuch exploits do not work in the real world. Our experiments show that it is\npossible to tune simulation parameters to improve sim2real predictivity (e.g.\nimproving $SRCC_{Succ}$ from 0.18 to 0.844), increasing confidence that\nin-simulation comparisons will translate to deployed systems in reality.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 04:29:38 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 03:26:55 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Kadian", "Abhishek", ""], ["Truong", "Joanne", ""], ["Gokaslan", "Aaron", ""], ["Clegg", "Alexander", ""], ["Wijmans", "Erik", ""], ["Lee", "Stefan", ""], ["Savva", "Manolis", ""], ["Chernova", "Sonia", ""], ["Batra", "Dhruv", ""]]}, {"id": "1912.06432", "submitter": "Luis Ignacio Lopera Gonz\\'alez", "authors": "Luis Ignacio Lopera Gonz\\'alez, Adrian Derungs, Oliver Amft\n  (Friedrich-Alexander University Erlangen-N\\\"urnberg, Erlangen, Germany)", "title": "A Bayesian Approach to Rule Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the increasing belief criterion in association\nrule mining. The criterion uses a recursive application of Bayes' theorem to\ncompute a rule's belief. Extracted rules are required to have their belief\nincrease with their last observation. We extend the taxonomy of association\nrule mining algorithms with a new branch for Bayesian rule mining~(BRM), which\nuses increasing belief as the rule selection criterion. In contrast, the\nwell-established frequent association rule mining~(FRM) branch relies on the\nminimum-support concept to extract rules. We derive properties of the\nincreasing belief criterion, such as the increasing belief boundary,\nno-prior-worries, and conjunctive premises. Subsequently, we implement a BRM\nalgorithm using the increasing belief criterion, and illustrate its\nfunctionality in three experiments: (1)~a proof-of-concept to illustrate BRM\nproperties, (2)~an analysis relating socioeconomic information and chemical\nexposure data, and (3)~mining behaviour routines in patients undergoing\nneurological rehabilitation. We illustrate how BRM is capable of extracting\nrare rules and does not suffer from support dilution. Furthermore, we show that\nBRM focuses on the individual event generating processes, while FRM focuses on\ntheir commonalities. We consider BRM's increasing belief as an alternative\ncriterion to thresholds on rule support, as often applied in FRM, to determine\nrule usefulness.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 12:06:38 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 20:47:15 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Gonz\u00e1lez", "Luis Ignacio Lopera", "", "Friedrich-Alexander University Erlangen-N\u00fcrnberg, Erlangen, Germany"], ["Derungs", "Adrian", "", "Friedrich-Alexander University Erlangen-N\u00fcrnberg, Erlangen, Germany"], ["Amft", "Oliver", "", "Friedrich-Alexander University Erlangen-N\u00fcrnberg, Erlangen, Germany"]]}, {"id": "1912.06485", "submitter": "Hong-Ning Dai Prof.", "authors": "Zibin Zheng and Hong-Ning Dai and Jiajing Wu", "title": "Blockchain Intelligence: When Blockchain Meets Artificial Intelligence", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.DC cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain is gaining extensive attention due to its provision of secure and\ndecentralized resource sharing manner. However, the incumbent blockchain\nsystems also suffer from a number of challenges in operational maintenance,\nquality assurance of smart contracts and malicious behaviour detection of\nblockchain data. The recent advances in artificial intelligence bring the\nopportunities in overcoming the above challenges. The integration of blockchain\nwith artificial intelligence can be beneficial to enhance current blockchain\nsystems. This article presents an introduction of the convergence of blockchain\nand artificial intelligence (namely blockchain intelligence). This article also\ngives a case study to further demonstrate the feasibility of blockchain\nintelligence and point out the future directions.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 02:56:45 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 03:57:05 GMT"}, {"version": "v3", "created": "Fri, 3 Apr 2020 22:41:18 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zheng", "Zibin", ""], ["Dai", "Hong-Ning", ""], ["Wu", "Jiajing", ""]]}, {"id": "1912.06497", "submitter": "Vahid Behzadan", "authors": "Ibrahim Baggili and Vahid Behzadan", "title": "Founding The Domain of AI Forensics", "comments": "Accepted for presentation at SafeAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread integration of AI in everyday and critical technologies,\nit seems inevitable to witness increasing instances of failure in AI systems.\nIn such cases, there arises a need for technical investigations that produce\nlegally acceptable and scientifically indisputable findings and conclusions on\nthe causes of such failures. Inspired by the domain of cyber forensics, this\npaper introduces the need for the establishment of AI Forensics as a new\ndiscipline under AI safety. Furthermore, we propose a taxonomy of the subfields\nunder this discipline, and present a discussion on the foundational challenges\nthat lay ahead of this new research area.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 23:39:57 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Baggili", "Ibrahim", ""], ["Behzadan", "Vahid", ""]]}, {"id": "1912.06513", "submitter": "Charlotte Roman", "authors": "Charlotte Roman and Paolo Turrini", "title": "Reducing selfish routing inefficiencies using traffic lights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic congestion games abstract away from the costs of junctions in\ntransport networks, yet, in urban environments, these often impact journey\ntimes significantly. In this paper we equip congestion games with traffic\nlights, modelled as junction-based waiting cycles, therefore enabling more\nrealistic route planning strategies. Using the SUMO simulator, we show that our\nmodelling choices coincide with realistic routing behaviours, in particular,\nthat drivers' decisions about route choices are based on the proportion of red\nlight time for their direction of travel. Drawing upon the experimental\nresults, we show that the effects of the notorious Braess' paradox can be\navoided in theory and significantly reduced in practice, by allocating the\nappropriate traffic light cycles along a transport network.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 14:18:13 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Roman", "Charlotte", ""], ["Turrini", "Paolo", ""]]}, {"id": "1912.06594", "submitter": "Thierry Denoeux", "authors": "Thierry Denoeux and Prakash P. Shenoy", "title": "An Interval-Valued Utility Theory for Decision Making with\n  Dempster-Shafer Belief Functions", "comments": null, "journal-ref": "International Journal of Approximate Reasoning, vol. 124, pages\n  194-216, 2020", "doi": "10.1016/j.ijar.2020.06.008", "report-no": "Working Paper No. 336, August 2019, School of Business, University\n  of Kansas", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this paper is to describe an axiomatic utility theory for\nDempster-Shafer belief function lotteries. The axiomatic framework used is\nanalogous to von Neumann-Morgenstern's utility theory for probabilistic\nlotteries as described by Luce and Raiffa. Unlike the probabilistic case, our\naxiomatic framework leads to interval-valued utilities, and therefore, to a\npartial (incomplete) preference order on the set of all belief function\nlotteries. If the belief function reference lotteries we use are Bayesian\nbelief functions, then our representation theorem coincides with Jaffray's\nrepresentation theorem for his linear utility theory for belief functions. We\nillustrate our representation theorem using some examples discussed in the\nliterature, and we propose a simple model for assessing utilities based on an\ninterval-valued pessimism index representing a decision-maker's attitude to\nambiguity and indeterminacy. Finally, we compare our decision theory with those\nproposed by Jaffray, Smets, Dubois et al., Giang and Shenoy, and Shafer.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 16:37:32 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 02:27:35 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Denoeux", "Thierry", ""], ["Shenoy", "Prakash P.", ""]]}, {"id": "1912.06602", "submitter": "Rahul Shome", "authors": "Malihe Alikhani, Baber Khalid, Rahul Shome, Chaitanya Mitash, Kostas\n  Bekris, Matthew Stone", "title": "That and There: Judging the Intent of Pointing Actions with Robotic Arms", "comments": "Accepted to AAAI 2020, New York City", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative robotics requires effective communication between a robot and a\nhuman partner. This work proposes a set of interpretive principles for how a\nrobotic arm can use pointing actions to communicate task information to people\nby extending existing models from the related literature. These principles are\nevaluated through studies where English-speaking human subjects view animations\nof simulated robots instructing pick-and-place tasks. The evaluation\ndistinguishes two classes of pointing actions that arise in pick-and-place\ntasks: referential pointing (identifying objects) and locating pointing\n(identifying locations). The study indicates that human subjects show greater\nflexibility in interpreting the intent of referential pointing compared to\nlocating pointing, which needs to be more deliberate. The results also\ndemonstrate the effects of variation in the environment and task context on the\ninterpretation of pointing. Our corpus, experiments and design principles\nadvance models of context, common sense reasoning and communication in embodied\ncommunication.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 16:54:38 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Alikhani", "Malihe", ""], ["Khalid", "Baber", ""], ["Shome", "Rahul", ""], ["Mitash", "Chaitanya", ""], ["Bekris", "Kostas", ""], ["Stone", "Matthew", ""]]}, {"id": "1912.06612", "submitter": "Henri Prade M", "authors": "Zied Bouraoui and Antoine Cornu\\'ejols and Thierry Den{\\oe}ux and\n  S\\'ebastien Destercke and Didier Dubois and Romain Guillaume and Jo\\~ao\n  Marques-Silva and J\\'er\\^ome Mengin and Henri Prade and Steven Schockaert and\n  Mathieu Serrurier and Christel Vrain", "title": "From Shallow to Deep Interactions Between Knowledge Representation,\n  Reasoning and Machine Learning (Kay R. Amel group)", "comments": "53 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a tentative and original survey of meeting points between\nKnowledge Representation and Reasoning (KRR) and Machine Learning (ML), two\nareas which have been developing quite separately in the last three decades.\nSome common concerns are identified and discussed such as the types of used\nrepresentation, the roles of knowledge and data, the lack or the excess of\ninformation, or the need for explanations and causal understanding. Then some\nmethodologies combining reasoning and learning are reviewed (such as inductive\nlogic programming, neuro-symbolic reasoning, formal concept analysis,\nrule-based representations and ML, uncertainty in ML, or case-based reasoning\nand analogical reasoning), before discussing examples of synergies between KRR\nand ML (including topics such as belief functions on regression, EM algorithm\nversus revision, the semantic description of vector representations, the\ncombination of deep learning with high level inference, knowledge graph\ncompletion, declarative frameworks for data mining, or preferences and\nrecommendation). This paper is the first step of a work in progress aiming at a\nbetter mutual understanding of research in KRR and ML, and how they could\ncooperate.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 17:20:52 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Bouraoui", "Zied", ""], ["Cornu\u00e9jols", "Antoine", ""], ["Den\u0153ux", "Thierry", ""], ["Destercke", "S\u00e9bastien", ""], ["Dubois", "Didier", ""], ["Guillaume", "Romain", ""], ["Marques-Silva", "Jo\u00e3o", ""], ["Mengin", "J\u00e9r\u00f4me", ""], ["Prade", "Henri", ""], ["Schockaert", "Steven", ""], ["Serrurier", "Mathieu", ""], ["Vrain", "Christel", ""]]}, {"id": "1912.06745", "submitter": "Rahul Radhakrishnan Iyer", "authors": "Rahul Radhakrishnan Iyer, Katia Sycara", "title": "An Unsupervised Domain-Independent Framework for Automated Detection of\n  Persuasion Tactics in Text", "comments": "19 pages, 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing growth of social media, people have started relying\nheavily on the information shared therein to form opinions and make decisions.\nWhile such a reliance is motivation for a variety of parties to promote\ninformation, it also makes people vulnerable to exploitation by slander,\nmisinformation, terroristic and predatorial advances. In this work, we aim to\nunderstand and detect such attempts at persuasion. Existing works on detecting\npersuasion in text make use of lexical features for detecting persuasive\ntactics, without taking advantage of the possible structures inherent in the\ntactics used. We formulate the task as a multi-class classification problem and\npropose an unsupervised, domain-independent machine learning framework for\ndetecting the type of persuasion used in text, which exploits the inherent\nsentence structure present in the different persuasion tactics. Our work shows\npromising results as compared to existing work.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 23:32:38 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Iyer", "Rahul Radhakrishnan", ""], ["Sycara", "Katia", ""]]}, {"id": "1912.06787", "submitter": "Dicong Qiu", "authors": "Dicong Qiu, Yibiao Zhao, Chris L. Baker", "title": "PODDP: Partially Observable Differential Dynamic Programming for Latent\n  Belief Space Planning", "comments": "16 pages, 6 figures, preprint", "journal-ref": "Robotics: Science and Systems, 2020. 69.1-69.10", "doi": "10.15607/RSS.2020.XVI.069", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents are limited in their ability to observe the world state.\nPartially observable Markov decision processes (POMDPs) formally model the\nproblem of planning under world state uncertainty, but POMDPs with continuous\nactions and nonlinear dynamics suitable for robotics applications are\nchallenging to solve. In this paper, we present an efficient differential\ndynamic programming (DDP) algorithm for belief space planning in POMDPs with\nuncertainty over a discrete latent state, and continuous states, actions,\nobservations, and nonlinear dynamics. This representation allows planning of\ndynamic trajectories which are sensitive to structured uncertainty over\ndiscrete latent world states. We develop dynamic programming techniques to\noptimize a contingency plan over a tree of possible observations and belief\nspace trajectories, and also derive a hierarchical version of the algorithm.\nOur method is applicable to problems with uncertainty over the cost or reward\nfunction (e.g., the configuration of goals or obstacles), uncertainty over the\ndynamics (e.g., the dynamical mode of a hybrid system), and uncertainty about\ninteractions, where other agents' behavior is conditioned on latent intentions.\nBenchmarks show that our algorithm outperforms popular heuristic approaches to\nplanning under uncertainty, and results from an autonomous lane changing task\ndemonstrate that our algorithm can synthesize robust interactive trajectories.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 05:28:59 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Qiu", "Dicong", ""], ["Zhao", "Yibiao", ""], ["Baker", "Chris L.", ""]]}, {"id": "1912.06817", "submitter": "Ricardo Morla", "authors": "Ricardo Morla", "title": "Ten AI Stepping Stones for Cybersecurity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the turmoil in cybersecurity and the mind-blowing advances in AI, it is\nonly natural that cybersecurity practitioners consider further employing\nlearning techniques to help secure their organizations and improve the\nefficiency of their security operation centers. But with great fears come great\nopportunities for both the good and the evil, and a myriad of bad deals. This\npaper discusses ten issues in cybersecurity that hopefully will make it easier\nfor practitioners to ask detailed questions about what they want from an AI\nsystem in their cybersecurity operations. We draw on the state of the art to\nprovide factual arguments for a discussion on well-established AI in\ncybersecurity issues, including the current scope of AI and its application to\ncybersecurity, the impact of privacy concerns on the cybersecurity data that\ncan be collected and shared externally to the organization, how an AI decision\ncan be explained to the person running the operations center, and the\nimplications of the adversarial nature of cybersecurity in the learning\ntechniques. We then discuss the use of AI by attackers on a level playing field\nincluding several issues in an AI battlefield, and an AI perspective on the old\ncat-and-mouse game including how the adversary may assess your AI power.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 09:54:36 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Morla", "Ricardo", ""]]}, {"id": "1912.06825", "submitter": "Hongwei Zeng", "authors": "Qinghua Zheng, Jun Liu, Hongwei Zeng, Zhaotong Guo, Bei Wu, Bifan Wei", "title": "Knowledge forest: a novel model to organize knowledge fragments", "comments": "Accepted for publication in Science China Information Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of knowledge, it shows a steady trend of knowledge\nfragmentization. Knowledge fragmentization manifests as that the knowledge\nrelated to a specific topic in a course is scattered in isolated and autonomous\nknowledge sources. We term the knowledge of a facet in a specific topic as a\nknowledge fragment. The problem of knowledge fragmentization brings two\nchallenges: First, knowledge is scattered in various knowledge sources, which\nexerts users' considerable efforts to search for the knowledge of their\ninterested topics, thereby leading to information overload. Second, learning\ndependencies which refer to the precedence relationships between topics in the\nlearning process are concealed by the isolation and autonomy of knowledge\nsources, thus causing learning disorientation. To solve the knowledge\nfragmentization problem, we propose a novel knowledge organization model,\nknowledge forest, which consists of facet trees and learning dependencies.\nFacet trees can organize knowledge fragments with facet hyponymy to alleviate\ninformation overload. Learning dependencies can organize disordered topics to\ncope with learning disorientation. We conduct extensive experiments on three\nmanually constructed datasets from the Data Structure, Data Mining, and\nComputer Network courses, and the experimental results show that knowledge\nforest can effectively organize knowledge fragments, and alleviate information\noverload and learning disorientation.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 11:02:17 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 20:41:24 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Zheng", "Qinghua", ""], ["Liu", "Jun", ""], ["Zeng", "Hongwei", ""], ["Guo", "Zhaotong", ""], ["Wu", "Bei", ""], ["Wei", "Bifan", ""]]}, {"id": "1912.06860", "submitter": "George Vouros VOUROS GEORGE", "authors": "Theocharis Kravaris, Christos Spatharis, Alevizos Bastas, George A.\n  Vouros, Konstantinos Blekas, Gennady Andrienko, Natalia Andrienko, Jose\n  Manuel Cordero Garcia", "title": "Resolving Congestions in the Air Traffic Management Domain via\n  Multiagent Reinforcement Learning Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this article, we report on the efficiency and effectiveness of multiagent\nreinforcement learning methods (MARL) for the computation of flight delays to\nresolve congestion problems in the Air Traffic Management (ATM) domain.\nSpecifically, we aim to resolve cases where demand of airspace use exceeds\ncapacity (demand-capacity problems), via imposing ground delays to flights at\nthe pre-tactical stage of operations (i.e. few days to few hours before\noperation). Casting this into the multiagent domain, agents, representing\nflights, need to decide on own delays w.r.t. own preferences, having no\ninformation about others' payoffs, preferences and constraints, while they plan\nto execute their trajectories jointly with others, adhering to operational\nconstraints. Specifically, we formalize the problem as a multiagent Markov\nDecision Process (MA-MDP) and we show that it can be considered as a Markov\ngame in which interacting agents need to reach an equilibrium: What makes the\nproblem more interesting is the dynamic setting in which agents operate, which\nis also due to the unforeseen, emergent effects of their decisions in the whole\nsystem. We propose collaborative multiagent reinforcement learning methods to\nresolve demand-capacity imbalances: Extensive experimental study on real-world\ncases, shows the potential of the proposed approaches in resolving problems,\nwhile advanced visualizations provide detailed views towards understanding the\nquality of solutions provided.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 15:06:35 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Kravaris", "Theocharis", ""], ["Spatharis", "Christos", ""], ["Bastas", "Alevizos", ""], ["Vouros", "George A.", ""], ["Blekas", "Konstantinos", ""], ["Andrienko", "Gennady", ""], ["Andrienko", "Natalia", ""], ["Garcia", "Jose Manuel Cordero", ""]]}, {"id": "1912.06880", "submitter": "Wenhang Bao", "authors": "Wenhang Bao, Xiao-yang Liu", "title": "Spatial Influence-aware Reinforcement Learning for Intelligent\n  Transportation System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent transportation systems (ITSs) are envisioned to be crucial for\nsmart cities, which aims at improving traffic flow to improve the life quality\nof urban residents and reducing congestion to improve the efficiency of\ncommuting. However, several challenges need to be resolved before such systems\ncan be deployed, for example, conventional solutions for Markov decision\nprocess (MDP) and single-agent Reinforcement Learning (RL) algorithms suffer\nfrom poor scalability, and multi-agent systems suffer from poor communication\nand coordination. In this paper, we explore the potential of mutual information\nsharing, or in other words, spatial influence based communication, to optimize\ntraffic light control policy. First, we mathematically analyze the\ntransportation system. We conclude that the transportation system does not have\nstationary Nash Equilibrium, thereby reinforcement learning algorithms offer\nsuitable solutions. Secondly, we describe how to build a multi-agent Deep\nDeterministic Policy Gradient (DDPG) system with spatial influence and social\ngroup utility incorporated. Then we utilize the grid topology road network to\nempirically demonstrate the scalability of the new system. We demonstrate three\ntypes of directed communications to show the effect of directions of social\ninfluence on the entire network utility and individual utility. Lastly, we\ndefine \"selfish index\" and analyze the effect of it on total group utility.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 16:57:56 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Bao", "Wenhang", ""], ["Liu", "Xiao-yang", ""]]}, {"id": "1912.06910", "submitter": "Tom Schaul", "authors": "Tom Schaul, Diana Borsa, David Ding, David Szepesvari, Georg\n  Ostrovski, Will Dabney, Simon Osindero", "title": "Adapting Behaviour for Learning Progress", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining what experience to generate to best facilitate learning (i.e.\nexploration) is one of the distinguishing features and open challenges in\nreinforcement learning. The advent of distributed agents that interact with\nparallel instances of the environment has enabled larger scales and greater\nflexibility, but has not removed the need to tune exploration to the task,\nbecause the ideal data for the learning algorithm necessarily depends on its\nprocess of learning. We propose to dynamically adapt the data generation by\nusing a non-stationary multi-armed bandit to optimize a proxy of the learning\nprogress. The data distribution is controlled by modulating multiple parameters\nof the policy (such as stochasticity, consistency or optimism) without\nsignificant overhead. The adaptation speed of the bandit can be increased by\nexploiting the factored modulation structure. We demonstrate on a suite of\nAtari 2600 games how this unified approach produces results comparable to\nper-task tuning at a fraction of the cost.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 19:34:47 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Schaul", "Tom", ""], ["Borsa", "Diana", ""], ["Ding", "David", ""], ["Szepesvari", "David", ""], ["Ostrovski", "Georg", ""], ["Dabney", "Will", ""], ["Osindero", "Simon", ""]]}, {"id": "1912.07045", "submitter": "Janarthanan Rajendran", "authors": "Janarthanan Rajendran, Richard Lewis, Vivek Veeriah, Honglak Lee and\n  Satinder Singh", "title": "How Should an Agent Practice?", "comments": "AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for learning intrinsic reward functions to drive the\nlearning of an agent during periods of practice in which extrinsic task rewards\nare not available. During practice, the environment may differ from the one\navailable for training and evaluation with extrinsic rewards. We refer to this\nsetup of alternating periods of practice and objective evaluation as\npractice-match, drawing an analogy to regimes of skill acquisition common for\nhumans in sports and games. The agent must effectively use periods in the\npractice environment so that performance improves during matches. In the\nproposed method the intrinsic practice reward is learned through a\nmeta-gradient approach that adapts the practice reward parameters to reduce the\nextrinsic match reward loss computed from matches. We illustrate the method on\na simple grid world, and evaluate it in two games in which the practice\nenvironment differs from match: Pong with practice against a wall without an\nopponent, and PacMan with practice in a maze without ghosts. The results show\ngains from learning in practice in addition to match periods over learning in\nmatches only.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 14:14:51 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Rajendran", "Janarthanan", ""], ["Lewis", "Richard", ""], ["Veeriah", "Vivek", ""], ["Lee", "Honglak", ""], ["Singh", "Satinder", ""]]}, {"id": "1912.07060", "submitter": "Mayukh Das", "authors": "Mayukh Das, Nandini Ramanan, Janardhan Rao Doppa and Sriraam Natarajan", "title": "One-Shot Induction of Generalized Logical Concepts via Human Guidance", "comments": "STARAI '20, Workshop version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning generalized first-order representations\nof concepts from a single example. To address this challenging problem, we\naugment an inductive logic programming learner with two novel algorithmic\ncontributions. First, we define a distance measure between candidate concept\nrepresentations that improves the efficiency of search for target concept and\ngeneralization. Second, we leverage richer human inputs in the form of advice\nto improve the sample-efficiency of learning. We prove that the proposed\ndistance measure is semantically valid and use that to derive a PAC bound. Our\nexperimental analysis on diverse concept learning tasks demonstrates both the\neffectiveness and efficiency of the proposed approach over a first-order\nconcept learner using only examples.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 15:31:45 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Das", "Mayukh", ""], ["Ramanan", "Nandini", ""], ["Doppa", "Janardhan Rao", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "1912.07381", "submitter": "Q.Vera Liao", "authors": "Q. Vera Liao, Michael Muller", "title": "Enabling Value Sensitive AI Systems through Participatory Design\n  Fictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two general routes have been followed to develop artificial agents that are\nsensitive to human values---a top-down approach to encode values into the\nagents, and a bottom-up approach to learn from human actions, whether from\nreal-world interactions or stories. Although both approaches have made exciting\nscientific progress, they may face challenges when applied to the current\ndevelopment practices of AI systems, which require the under-standing of the\nspecific domains and specific stakeholders involved. In this work, we bring\ntogether perspectives from the human-computer interaction (HCI) community,\nwhere designing technologies sensitive to user values has been a longstanding\nfocus. We highlight several well-established areas focusing on developing\nempirical methods for inquiring user values. Based on these methods, we propose\nparticipatory design fictions to study user values involved in AI systems and\npresent preliminary results from a case study. With this paper, we invite the\nconsideration of user-centered value inquiry and value learning.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 01:16:03 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Liao", "Q. Vera", ""], ["Muller", "Michael", ""]]}, {"id": "1912.07416", "submitter": "Byung Hyung Kim", "authors": "Byung Hyung Kim, Seunghun Koh, Sejoon Huh, Sungho Jo, Sunghee Choi", "title": "Improved Explanatory Efficacy on Human Affect and Workload through\n  Interactive Process in Artificial Intelligence", "comments": null, "journal-ref": "IEEE Access, Vol.8, 2020", "doi": "10.1109/ACCESS.2020.3032056", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite recent advances in the field of explainable artificial intelligence\nsystems, a concrete quantitative measure for evaluating the usability of such\nsystems is nonexistent. Ensuring the success of an explanatory interface in\ninteracting with users requires a cyclic, symbiotic relationship between human\nand artificial intelligence. We, therefore, propose explanatory efficacy, a\nnovel metric for evaluating the strength of the cyclic relationship the\ninterface exhibits. Furthermore, in a user study, we evaluated the perceived\naffect and workload and recorded the EEG signals of our participants as they\ninteracted with our custom-built, iterative explanatory interface to build\npersonalized recommendation systems. We found that systems for perceptually\ndriven iterative tasks with greater explanatory efficacy are characterized by\nstatistically significant hemispheric differences in neural signals with 62.4%\naccuracy, indicating the feasibility of neural correlates as a measure of\nexplanatory efficacy. These findings are beneficial for researchers who aim to\nstudy the circular ecosystem of the human-artificial intelligence partnership.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 14:08:49 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 01:53:08 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Kim", "Byung Hyung", ""], ["Koh", "Seunghun", ""], ["Huh", "Sejoon", ""], ["Jo", "Sungho", ""], ["Choi", "Sunghee", ""]]}, {"id": "1912.07421", "submitter": "Frejus Laleye", "authors": "Fr\\'ejus A. A. Laleye, Antonia Blani\\'e, Antoine Brouquet, Dan\n  Behnamou, Ga\\\"el de Chalendar", "title": "Semantic Similarity To Improve Question Understanding in a Virtual\n  Patient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In medicine, a communicating virtual patient or doctor allows students to\ntrain in medical diagnosis and develop skills to conduct a medical\nconsultation. In this paper, we describe a conversational virtual standardized\npatient system to allow medical students to simulate a diagnosis strategy of an\nabdominal surgical emergency. We exploited the semantic properties captured by\ndistributed word representations to search for similar questions in the virtual\npatient dialogue system. We created two dialogue systems that were evaluated on\ndatasets collected during tests with students. The first system based on\nhand-crafted rules obtains $92.29\\%$ as $F1$-score on the studied clinical case\nwhile the second system that combines rules and semantic similarity achieves\n$94.88\\%$. It represents an error reduction of $9.70\\%$ as compared to the\nrules-only-based system.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 14:45:56 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Laleye", "Fr\u00e9jus A. A.", ""], ["Blani\u00e9", "Antonia", ""], ["Brouquet", "Antoine", ""], ["Behnamou", "Dan", ""], ["de Chalendar", "Ga\u00ebl", ""]]}, {"id": "1912.07475", "submitter": "Shqiponja Ahmetaj", "authors": "Shqiponja Ahmetaj, Magdalena Ortiz, and Mantas Simkus", "title": "Polynomial Rewritings from Expressive Description Logics with Closed\n  Predicates to Variants of Datalog", "comments": null, "journal-ref": null, "doi": "10.1016/j.artint.2019.103220", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many scenarios, complete and incomplete information coexist. For this\nreason, the knowledge representation and database communities have long shown\ninterest in simultaneously supporting the closed- and the open-world views when\nreasoning about logic theories. Here we consider the setting of querying\npossibly incomplete data using logic theories, formalized as the evaluation of\nan ontology-mediated query (OMQ) that pairs a query with a theory, sometimes\ncalled an ontology, expressing background knowledge. This can be further\nenriched by specifying a set of closed predicates from the theory that are to\nbe interpreted under the closed-world assumption, while the rest are\ninterpreted with the open-world view. In this way we can retrieve more precise\nanswers to queries by leveraging the partial completeness of the data.\n  The central goal of this paper is to understand the relative expressiveness\nof OMQ languages in which the ontology is written in the expressive Description\nLogic (DL) ALCHOI and includes a set of closed predicates. We consider a\nrestricted class of conjunctive queries. Our main result is to show that every\nquery in this non-monotonic query language can be translated in polynomial time\ninto Datalog with negation under the stable model semantics. To overcome the\nchallenge that Datalog has no direct means to express the existential\nquantification present in ALCHOI, we define a two-player game that\ncharacterizes the satisfaction of the ontology, and design a Datalog query that\ncan decide the existence of a winning strategy for the game. If there are no\nclosed predicates, that is in the case of querying a plain ALCHOI knowledge\nbase, our translation yields a positive disjunctive Datalog program of\npolynomial size. To the best of our knowledge, unlike previous translations for\nrelated fragments with expressive (non-Horn) DLs, these are the first\npolynomial time translations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 16:15:06 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Ahmetaj", "Shqiponja", ""], ["Ortiz", "Magdalena", ""], ["Simkus", "Mantas", ""]]}, {"id": "1912.07521", "submitter": "Mehdi Dadvar", "authors": "Mehdi Dadvar, Saeed Moazami, Harley R. Myler, and Hassan Zargarzadeh", "title": "Exploration and Coordination of Complementary Multi-Robot Teams in a\n  Hunter and Gatherer Scenario", "comments": "19 pages, 10 figures. arXiv admin note: text overlap with\n  arXiv:1912.05748", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hunter and gatherer approach copes with the problem of dynamic\nmulti-robot task allocation, where tasks are unknowingly distributed over an\nenvironment. This approach employs two complementary teams of agents: one agile\nin exploring (hunters) and another dexterous in completing (gatherers) the\ntasks. Although this approach has been studied from the task planning point of\nview in our previous works, the multi-robot exploration and coordination\naspects of the problem remain uninvestigated. This paper proposes a multi-robot\nexploration algorithm for hunters based on innovative notions of \"expected\ninformation gain\" to minimize the collective cost of task accomplishments in a\ndistributed manner. Besides, we present a coordination solution between hunters\nand gatherers by integrating the novel notion of profit margins into the\nconcept of expected information gain. Statistical analysis of extensive\nsimulation results confirms the efficacy of the proposed algorithms compared in\ndifferent environments with varying levels of obstacles complexities. We also\ndemonstrate that the lack of effective coordination between hunters and\ngatherers significantly hurts the total effectiveness of the planning,\nespecially in environments containing dense obstacles and confined corridors.\nFinally, it is statistically proven that the overall workload is distributed\nequally for each type of agent which ensures that the proposed solution is not\nbiased to a particular agent and all agents behave analogously under similar\ncharacteristics.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 03:48:40 GMT"}, {"version": "v2", "created": "Sun, 21 Jun 2020 13:01:01 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Dadvar", "Mehdi", ""], ["Moazami", "Saeed", ""], ["Myler", "Harley R.", ""], ["Zargarzadeh", "Hassan", ""]]}, {"id": "1912.07544", "submitter": "John Winder", "authors": "John Winder, Stephanie Milani, Matthew Landen, Erebus Oh, Shane Parr,\n  Shawn Squire, Marie desJardins, Cynthia Matuszek", "title": "Planning with Abstract Learned Models While Learning Transferable\n  Subtasks", "comments": "Accepted at AAAI-20, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an algorithm for model-based hierarchical reinforcement learning\nto acquire self-contained transition and reward models suitable for\nprobabilistic planning at multiple levels of abstraction. We call this\nframework Planning with Abstract Learned Models (PALM). By representing\nsubtasks symbolically using a new formal structure, the lifted abstract Markov\ndecision process (L-AMDP), PALM learns models that are independent and modular.\nThrough our experiments, we show how PALM integrates planning and execution,\nfacilitating a rapid and efficient learning of abstract, hierarchical models.\nWe also demonstrate the increased potential for learned models to be\ntransferred to new and related tasks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 17:47:57 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 15:09:33 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Winder", "John", ""], ["Milani", "Stephanie", ""], ["Landen", "Matthew", ""], ["Oh", "Erebus", ""], ["Parr", "Shane", ""], ["Squire", "Shawn", ""], ["desJardins", "Marie", ""], ["Matuszek", "Cynthia", ""]]}, {"id": "1912.07650", "submitter": "Alexander Hayes", "authors": "Alexander L. Hayes and Mayukh Das and Phillip Odom and Sriraam\n  Natarajan", "title": "User Friendly Automatic Construction of Background Knowledge: Mode\n  Construction from ER Diagrams", "comments": "8 pages. Published in Proceedings of the Knowledge Capture\n  Conference, 2017", "journal-ref": "Proceedings of the Knowledge Capture Conference (2017) 30:1-30:8", "doi": "10.1145/3148011.3148027", "report-no": null, "categories": "cs.AI cs.DB cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  One of the key advantages of Inductive Logic Programming systems is the\nability of the domain experts to provide background knowledge as modes that\nallow for efficient search through the space of hypotheses. However, there is\nan inherent assumption that this expert should also be an ILP expert to provide\neffective modes. We relax this assumption by designing a graphical user\ninterface that allows the domain expert to interact with the system using\nEntity Relationship diagrams. These interactions are used to construct modes\nfor the learning system. We evaluate our algorithm on a probabilistic logic\nlearning system where we demonstrate that the user is able to construct\neffective background knowledge on par with the expert-encoded knowledge on five\ndata sets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 19:30:57 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Hayes", "Alexander L.", ""], ["Das", "Mayukh", ""], ["Odom", "Phillip", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "1912.07662", "submitter": "Alessio Pagani Dr", "authors": "Alessio Pagani, Abhinav Mehrotra and Mirco Musolesi", "title": "Graph Input Representations for Machine Learning Applications in Urban\n  Network Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and learning the characteristics of network paths has been of\nparticular interest for decades and has led to several successful applications.\nSuch analysis becomes challenging for urban networks as their size and\ncomplexity are significantly higher compared to other networks. The\nstate-of-the-art machine learning (ML) techniques allow us to detect hidden\npatterns and, thus, infer the features associated with them. However, very\nlittle is known about the impact on the performance of such predictive models\nby the use of different input representations. In this paper, we design and\nevaluate six different graph input representations (i.e., representations of\nthe network paths), by considering the network's topological and temporal\ncharacteristics, for being used as inputs for machine learning models to learn\nthe behavior of urban networks paths. The representations are validated and\nthen tested with a real-world taxi journeys dataset predicting the tips using a\nroad network of New York. Our results demonstrate that the input\nrepresentations that use temporal information help the model to achieve the\nhighest accuracy (RMSE of 1.42$).\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 19:28:00 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Pagani", "Alessio", ""], ["Mehrotra", "Abhinav", ""], ["Musolesi", "Mirco", ""]]}, {"id": "1912.07663", "submitter": "Haoxing Lin", "authors": "Haoxing Lin, Weijia Jia, Yiping Sun, Yongjian You", "title": "Spatial-Temporal Self-Attention Network for Flow Prediction", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow prediction (e.g., crowd flow, traffic flow) with features of\nspatial-temporal is increasingly investigated in AI research field. It is very\nchallenging due to the complicated spatial dependencies between different\nlocations and dynamic temporal dependencies among different time intervals.\nAlthough measurements of both dependencies are employed, existing methods\nsuffer from the following two problems. First, the temporal dependencies are\nmeasured either uniformly or bias against long-term dependencies, which\noverlooks the distinctive impacts of short-term and long-term temporal\ndependencies. Second, the existing methods capture spatial and temporal\ndependencies independently, which wrongly assumes that the correlations between\nthese dependencies are weak and ignores the complicated mutual influences\nbetween them. To address these issues, we propose a Spatial-Temporal\nSelf-Attention Network (ST-SAN). As the path-length of attending long-term\ndependency is shorter in the self-attention mechanism, the vanishing of\nlong-term temporal dependencies is prevented. In addition, since our model\nrelies solely on attention mechanisms, the spatial and temporal dependencies\ncan be simultaneously measured. Experimental results on real-world data\ndemonstrate that, in comparison with state-of-the-art methods, our model\nreduces the root mean square errors by 9% in inflow prediction and 4% in\noutflow prediction on Taxi-NYC data, which is very significant compared to the\nprevious improvement.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 07:42:35 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 02:02:09 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Lin", "Haoxing", ""], ["Jia", "Weijia", ""], ["Sun", "Yiping", ""], ["You", "Yongjian", ""]]}, {"id": "1912.07670", "submitter": "Youngwoon Lee", "authors": "Youngwoon Lee, Edward S. Hu, Zhengyu Yang, Joseph J. Lim", "title": "To Follow or not to Follow: Selective Imitation Learning from\n  Observations", "comments": "Published at the Conference on Robot Learning (CoRL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from demonstrations is a useful way to transfer a skill from one\nagent to another. While most imitation learning methods aim to mimic an expert\nskill by following the demonstration step-by-step, imitating every step in the\ndemonstration often becomes infeasible when the learner and its environment are\ndifferent from the demonstration. In this paper, we propose a method that can\nimitate a demonstration composed solely of observations, which may not be\nreproducible with the current agent. Our method, dubbed selective imitation\nlearning from observations (SILO), selects reachable states in the\ndemonstration and learns how to reach the selected states. Our experiments on\nboth simulated and real robot environments show that our method reliably\nperforms a new task by following a demonstration. Videos and code are available\nat https://clvrai.com/silo .\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 20:05:37 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Lee", "Youngwoon", ""], ["Hu", "Edward S.", ""], ["Yang", "Zhengyu", ""], ["Lim", "Joseph J.", ""]]}, {"id": "1912.07712", "submitter": "Marco Ciccone", "authors": "Andrea Celli, Marco Ciccone, Raffaele Bongo, Nicola Gatti", "title": "Coordination in Adversarial Sequential Team Games via Multi-Agent Deep\n  Reinforcement Learning", "comments": "Preliminary version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world applications involve teams of agents that have to coordinate\ntheir actions to reach a common goal against potential adversaries. This paper\nfocuses on zero-sum games where a team of players faces an opponent, as is the\ncase, for example, in Bridge, collusion in poker, and collusion in bidding. The\npossibility for the team members to communicate before gameplay---that is,\ncoordinate their strategies ex ante---makes the use of behavioral strategies\nunsatisfactory. We introduce Soft Team Actor-Critic (STAC) as a solution to the\nteam's coordination problem that does not require any prior domain knowledge.\nSTAC allows team members to effectively exploit ex ante communication via\nexogenous signals that are shared among the team. STAC reaches near-optimal\ncoordinated strategies both in perfectly observable and partially observable\ngames, where previous deep RL algorithms fail to reach optimal coordinated\nbehaviors.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 21:30:04 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Celli", "Andrea", ""], ["Ciccone", "Marco", ""], ["Bongo", "Raffaele", ""], ["Gatti", "Nicola", ""]]}, {"id": "1912.07758", "submitter": "Marcel B\\\"ohme", "authors": "Marcel B\\\"ohme, Charaka Geethal, Van-Thuan Pham", "title": "Human-In-The-Loop Automatic Program Repair", "comments": "Accepted as full paper (10+2 pages) at ICST'20\n  (https://icst2020.info/) *** Tool and Replication Package at:\n  https://github.com/mboehme/learn2fix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Learn2fix, the first human-in-the-loop, semi-automatic repair\ntechnique when no bug oracle--except for the user who is reporting the bug--is\navailable. Our approach negotiates with the user the condition under which the\nbug is observed. Only when a budget of queries to the user is exhausted, it\nattempts to repair the bug. A query can be thought of as the following\nquestion: \"When executing this alternative test input, the program produces the\nfollowing output; is the bug observed\"? Through systematic queries, Learn2fix\ntrains an automatic bug oracle that becomes increasingly more accurate in\npredicting the user's response. Our key challenge is to maximize the oracle's\naccuracy in predicting which tests are bug-exposing given a small budget of\nqueries. From the alternative tests that were labeled by the user, test-driven\nautomatic repair produces the patch.\n  Our experiments demonstrate that Learn2fix learns a sufficiently accurate\nautomatic oracle with a reasonably low labeling effort (lt. 20 queries). Given\nLearn2fix's test suite, the GenProg test-driven repair tool produces a\nhigher-quality patch (i.e., passing a larger proportion of validation tests)\nthan using manual test suites provided with the repair benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 23:39:08 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["B\u00f6hme", "Marcel", ""], ["Geethal", "Charaka", ""], ["Pham", "Van-Thuan", ""]]}, {"id": "1912.07796", "submitter": "Nathan Long", "authors": "Nathan K Long, Karl Sammut, Daniel Sgarioto, Matthew Garratt, Hussein\n  Abbass", "title": "A Comprehensive Review of Shepherding as a Bio-inspired Swarm-Robotics\n  Guidance Approach", "comments": "Copyright 2020 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The simultaneous control of multiple coordinated robotic agents represents an\nelaborate problem. If solved, however, the interaction between the agents can\nlead to solutions to sophisticated problems. The concept of swarming, inspired\nby nature, can be described as the emergence of complex system-level behaviors\nfrom the interactions of relatively elementary agents. Due to the effectiveness\nof solutions found in nature, bio-inspired swarming-based control techniques\nare receiving a lot of attention in robotics. One method, known as swarm\nshepherding, is founded on the sheep herding behavior exhibited by sheepdogs,\nwhere a swarm of relatively simple agents are governed by a shepherd (or\nshepherds) which is responsible for high-level guidance and planning. Many\nstudies have been conducted on shepherding as a control technique, ranging from\nthe replication of sheep herding via simulation, to the control of uninhabited\nvehicles and robots for a variety of applications. We present a comprehensive\nreview of the literature on swarm shepherding to reveal the advantages and\npotential of the approach to be applied to a plethora of robotic systems in the\nfuture.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 03:00:36 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 09:35:18 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 08:08:18 GMT"}, {"version": "v4", "created": "Thu, 30 Apr 2020 05:26:22 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Long", "Nathan K", ""], ["Sammut", "Karl", ""], ["Sgarioto", "Daniel", ""], ["Garratt", "Matthew", ""], ["Abbass", "Hussein", ""]]}, {"id": "1912.07804", "submitter": "Shufang Zhu", "authors": "Shufang Zhu, Giuseppe De Giacomo, Geguang Pu, Moshe Vardi", "title": "LTLf Synthesis with Fairness and Stability Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In synthesis, assumptions are constraints on the environment that rule out\ncertain environment behaviors. A key observation here is that even if we\nconsider systems with LTLf goals on finite traces, environment assumptions need\nto be expressed over infinite traces, since accomplishing the agent goals may\nrequire an unbounded number of environment action. To solve synthesis with\nrespect to finite-trace LTLf goals under infinite-trace assumptions, we could\nreduce the problem to LTL synthesis. Unfortunately, while synthesis in LTLf and\nin LTL have the same worst-case complexity (both 2EXPTIME-complete), the\nalgorithms available for LTL synthesis are much more difficult in practice than\nthose for LTLf synthesis. In this work we show that in interesting cases we can\navoid such a detour to LTL synthesis and keep the simplicity of LTLf synthesis.\nSpecifically, we develop a BDD-based fixpoint-based technique for handling\nbasic forms of fairness and of stability assumptions. We show, empirically,\nthat this technique performs much better than standard LTL synthesis.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 03:44:39 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Zhu", "Shufang", ""], ["De Giacomo", "Giuseppe", ""], ["Pu", "Geguang", ""], ["Vardi", "Moshe", ""]]}, {"id": "1912.07834", "submitter": "Michiaki Tatsubori", "authors": "Michiaki Tatsubori, Asim Munawar, Takao Moriyama", "title": "Design and Implementation of Linked Planning Domain Definition Language", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning is a critical component of any artificial intelligence system that\nconcerns the realization of strategies or action sequences typically for\nintelligent agents and autonomous robots. Given predefined parameterized\nactions, a planning service should accept a query with the goal and initial\nstate to give a solution with a sequence of actions applied to environmental\nobjects. This paper addresses the problem by providing a repository of actions\ngenerically applicable to various environmental objects based on Semantic Web\ntechnologies. Ontologies are used for asserting constraints in common sense as\nwell as for resolving compatibilities between actions and states. Constraints\nare defined using Web standards such as SPARQL and SHACL to allow conditional\npredicates. We demonstrate the usefulness of the proposed planning domain\ndescription language with our robotics applications.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 06:05:49 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Tatsubori", "Michiaki", ""], ["Munawar", "Asim", ""], ["Moriyama", "Takao", ""]]}, {"id": "1912.07840", "submitter": "Zihan Wang", "authors": "Karthikeyan K, Zihan Wang, Stephen Mayhew, Dan Roth", "title": "Cross-Lingual Ability of Multilingual BERT: An Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has exhibited the surprising cross-lingual abilities of\nmultilingual BERT (M-BERT) -- surprising since it is trained without any\ncross-lingual objective and with no aligned data. In this work, we provide a\ncomprehensive study of the contribution of different components in M-BERT to\nits cross-lingual ability. We study the impact of linguistic properties of the\nlanguages, the architecture of the model, and the learning objectives. The\nexperimental study is done in the context of three typologically different\nlanguages -- Spanish, Hindi, and Russian -- and using two conceptually\ndifferent NLP tasks, textual entailment and named entity recognition. Among our\nkey conclusions is the fact that the lexical overlap between languages plays a\nnegligible role in the cross-lingual success, while the depth of the network is\nan integral part of it. All our models and implementations can be found on our\nproject page: http://cogcomp.org/page/publication_view/900 .\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 06:53:05 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 18:48:42 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["K", "Karthikeyan", ""], ["Wang", "Zihan", ""], ["Mayhew", "Stephen", ""], ["Roth", "Dan", ""]]}, {"id": "1912.07882", "submitter": "Yiming Gu", "authors": "Donsuk Lee, Yiming Gu, Jerrick Hoang, Micol Marchetti-Bowick", "title": "Joint Interaction and Trajectory Prediction for Autonomous Driving using\n  Graph Neural Networks", "comments": "Accepted in Machine Learning for Autonomous Driving NeurIPS 2019\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we aim to predict the future motion of vehicles in a traffic\nscene by explicitly modeling their pairwise interactions. Specifically, we\npropose a graph neural network that jointly predicts the discrete interaction\nmodes and 5-second future trajectories for all agents in the scene. Our model\ninfers an interaction graph whose nodes are agents and whose edges capture the\nlong-term interaction intents among the agents. In order to train the model to\nrecognize known modes of interaction, we introduce an auto-labeling function to\ngenerate ground truth interaction labels. Using a large-scale real-world\ndriving dataset, we demonstrate that jointly predicting the trajectories along\nwith the explicit interaction types leads to significantly lower trajectory\nerror than baseline methods. Finally, we show through simulation studies that\nthe learned interaction modes are semantically meaningful.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 09:06:31 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Lee", "Donsuk", ""], ["Gu", "Yiming", ""], ["Hoang", "Jerrick", ""], ["Marchetti-Bowick", "Micol", ""]]}, {"id": "1912.07915", "submitter": "Fengshi Jing", "authors": "Fengshi Jing and Qingpeng Zhang", "title": "Knowledge-Enhanced Attentive Learning for Answer Selection in Community\n  Question Answering Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the community question answering (CQA) system, the answer selection task\naims to identify the best answer for a specific question, and thus is playing a\nkey role in enhancing the service quality through recommending appropriate\nanswers for new questions. Recent advances in CQA answer selection focus on\nenhancing the performance by incorporating the community information,\nparticularly the expertise (previous answers) and authority (position in the\nsocial network) of an answerer. However, existing approaches for incorporating\nsuch information are limited in (a) only considering either the expertise or\nthe authority, but not both; (b) ignoring the domain knowledge to differentiate\ntopics of previous answers; and (c) simply using the authority information to\nadjust the similarity score, instead of fully utilizing it in the process of\nmeasuring the similarity between segments of the question and the answer. We\npropose the Knowledge-enhanced Attentive Answer Selection (KAAS) model, which\nenhances the performance through (a) considering both the expertise and the\nauthority of the answerer; (b) utilizing the human-labeled tags, the taxonomy\nof the tags, and the votes as the domain knowledge to infer the expertise of\nthe answer; (c) using matrix decomposition of the social network (formed by\nfollowing-relationship) to infer the authority of the answerer and\nincorporating such information in the process of evaluating the similarity\nbetween segments. Besides, for vertical community, we incorporate an external\nknowledge graph to capture more professional information for vertical CQA\nsystems. Then we adopt the attention mechanism to integrate the analysis of the\ntext of questions and answers and the aforementioned community information.\nExperiments with both vertical and general CQA sites demonstrate the superior\nperformance of the proposed KAAS model.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 10:33:17 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Jing", "Fengshi", ""], ["Zhang", "Qingpeng", ""]]}, {"id": "1912.08055", "submitter": "Heramb Nemlekar", "authors": "Yifang Chen, Alex Cuellar, Haipeng Luo, Jignesh Modi, Heramb Nemlekar\n  and Stefanos Nikolaidis", "title": "Fair Contextual Multi-Armed Bandits: Theory and Experiments", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When an AI system interacts with multiple users, it frequently needs to make\nallocation decisions. For instance, a virtual agent decides whom to pay\nattention to in a group setting, or a factory robot selects a worker to deliver\na part. Demonstrating fairness in decision making is essential for such systems\nto be broadly accepted. We introduce a Multi-Armed Bandit algorithm with\nfairness constraints, where fairness is defined as a minimum rate that a task\nor a resource is assigned to a user. The proposed algorithm uses contextual\ninformation about the users and the task and makes no assumptions on how the\nlosses capturing the performance of different users are generated. We provide\ntheoretical guarantees of performance and empirical results from simulation and\nan online user study. The results highlight the benefit of accounting for\ncontexts in fair decision making, especially when users perform better at some\ncontexts and worse at others.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 22:25:34 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Chen", "Yifang", ""], ["Cuellar", "Alex", ""], ["Luo", "Haipeng", ""], ["Modi", "Jignesh", ""], ["Nemlekar", "Heramb", ""], ["Nikolaidis", "Stefanos", ""]]}, {"id": "1912.08066", "submitter": "Panayiotis Danassis", "authors": "Panayiotis Danassis, Marija Sakota, Aris Filos-Ratsikas, Boi Faltings", "title": "Putting Ridesharing to the Test: Efficient and Scalable Solutions and\n  the Power of Dynamic Vehicle Relocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform a systematic evaluation of a diverse set of algorithms for the\nridesharing problem which is, to the best of our knowledge, one of the largest\nand most comprehensive to date. In particular, we evaluate 12 different\nalgorithms over 12 metrics related to global efficiency, complexity, passenger,\ndriver, and platform incentives. Our evaluation setting is specifically\ndesigned to resemble reality as closely as possible. We achieve this by (a)\nusing actual data from the NYC's yellow taxi trip records, both for modeling\ncustomer requests, and taxis (b) following closely the pricing model employed\nby ridesharing platforms and (c) running our simulations to the scale of the\nactual problem faced by the ridesharing platforms.\n  Our results provide a clear-cut recommendation to ridesharing platforms on\nwhich solutions can be employed in practice and demonstrate the large potential\nfor efficiency gains. Moreover, we show that simple, lightweight relocation\nschemes -- which can be used as independent components to any ridesharing\nalgorithm -- can significantly improve Quality of Service metrics by up to 50%.\nAs a highlight of our findings, we identify a scalable, on-device heuristic\nthat offers an efficient, end-to-end solution for the Dynamic Ridesharing and\nFleet Relocation problem.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 15:10:03 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 15:34:19 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Danassis", "Panayiotis", ""], ["Sakota", "Marija", ""], ["Filos-Ratsikas", "Aris", ""], ["Faltings", "Boi", ""]]}, {"id": "1912.08097", "submitter": "Avinash Kumar Singh", "authors": "Avinash Kumar Singh, Kai-Florian Richter", "title": "Conflict Detection and Resolution in Table Top Scenarios for Human-Robot\n  Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As in any interaction process, misunderstandings, ambiguity, and failures to\ncorrectly understand the interaction partner are bound to happen in human-robot\ninteraction. We term these failures 'conflicts' and are interested in both\nconflict detection and conflict resolution. In that, we focus on the robot's\nperspective. For the robot, conflicts may occur because of errors in its\nperceptual processes or because of ambiguity stemming from human input. This\nposter presents a brief system overview, and details Here, we briefly outline\nthe project's motivation and setting, introduce the general processing\nframework, and then present two kinds of conflicts in some more detail: 1) a\nfailure to identify a relevant object at all; 2) ambiguity emerging from\nmultiple matches in scene perception.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 12:04:52 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 15:37:25 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Singh", "Avinash Kumar", ""], ["Richter", "Kai-Florian", ""]]}, {"id": "1912.08140", "submitter": "Yashaswi Verma", "authors": "Yashaswi Verma", "title": "An Embarrassingly Simple Baseline for eXtreme Multi-label Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of eXtreme Multi-label Learning (XML) is to design and learn a model\nthat can automatically annotate a given data point with the most relevant\nsubset of labels from an extremely large label set. Recently, many techniques\nhave been proposed for XML that achieve reasonable performance on benchmark\ndatasets. Motivated by the complexities of these methods and their subsequent\ntraining requirements, in this paper we propose a simple baseline technique for\nthis task. Precisely, we present a global feature embedding technique for XML\nthat can easily scale to very large datasets containing millions of data points\nin very high-dimensional feature space, irrespective of number of samples and\nlabels. Next we show how an ensemble of such global embeddings can be used to\nachieve further boost in prediction accuracies with only linear increase in\ntraining and prediction time. During testing, we assign the labels using a\nweighted k-nearest neighbour classifier in the embedding space. Experiments\nreveal that though conceptually simple, this technique achieves quite\ncompetitive results, and has training time of less than one minute using a\nsingle CPU core with 15.6 GB RAM even for large-scale datasets such as\nAmazon-3M.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 17:11:17 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Verma", "Yashaswi", ""]]}, {"id": "1912.08142", "submitter": "Daniel C. Castro", "authors": "Daniel C. Castro, Ian Walker, Ben Glocker", "title": "Causality matters in medical imaging", "comments": "20 pages, 5 figures, 4 tables", "journal-ref": "Nature Communications 11 (2020) 3673", "doi": "10.1038/s41467-020-17478-w", "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article discusses how the language of causality can shed new light on\nthe major challenges in machine learning for medical imaging: 1) data scarcity,\nwhich is the limited availability of high-quality annotations, and 2) data\nmismatch, whereby a trained algorithm may fail to generalize in clinical\npractice. Looking at these challenges through the lens of causality allows\ndecisions about data collection, annotation procedures, and learning strategies\nto be made (and scrutinized) more transparently. We discuss how causal\nrelationships between images and annotations can not only have profound effects\non the performance of predictive models, but may even dictate which learning\nstrategies should be considered in the first place. For example, we conclude\nthat semi-supervision may be unsuitable for image segmentation---one of the\npossibly surprising insights from our causal analysis, which is illustrated\nwith representative real-world examples of computer-aided diagnosis (skin\nlesion classification in dermatology) and radiotherapy (automated contouring of\ntumours). We highlight that being aware of and accounting for the causal\nrelationships in medical imaging data is important for the safe development of\nmachine learning and essential for regulation and responsible reporting. To\nfacilitate this we provide step-by-step recommendations for future studies.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 17:15:02 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Castro", "Daniel C.", ""], ["Walker", "Ian", ""], ["Glocker", "Ben", ""]]}, {"id": "1912.08195", "submitter": "Luca Weihs", "authors": "Luca Weihs, Aniruddha Kembhavi, Kiana Ehsani, Sarah M Pratt, Winson\n  Han, Alvaro Herrasti, Eric Kolve, Dustin Schwenk, Roozbeh Mottaghi, Ali\n  Farhadi", "title": "Learning Generalizable Visual Representations via Interactive Gameplay", "comments": "Replaced with version accepted to ICLR'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing body of research suggests that embodied gameplay, prevalent not\njust in human cultures but across a variety of animal species including turtles\nand ravens, is critical in developing the neural flexibility for creative\nproblem solving, decision making, and socialization. Comparatively little is\nknown regarding the impact of embodied gameplay upon artificial agents. While\nrecent work has produced agents proficient in abstract games, these\nenvironments are far removed from the real world and thus these agents can\nprovide little insight into the advantages of embodied play. Hiding games, such\nas hide-and-seek, played universally, provide a rich ground for studying the\nimpact of embodied gameplay on representation learning in the context of\nperspective taking, secret keeping, and false belief understanding. Here we are\nthe first to show that embodied adversarial reinforcement learning agents\nplaying Cache, a variant of hide-and-seek, in a high fidelity, interactive,\nenvironment, learn generalizable representations of their observations encoding\ninformation such as object permanence, free space, and containment. Moving\ncloser to biologically motivated learning strategies, our agents'\nrepresentations, enhanced by intentionality and memory, are developed through\ninteraction and play. These results serve as a model for studying how facets of\nvision develop through interaction, provide an experimental framework for\nassessing what is learned by artificial agents, and demonstrates the value of\nmoving from large, static, datasets towards experiential, interactive,\nrepresentation learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 18:57:50 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 17:45:41 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 17:51:31 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Weihs", "Luca", ""], ["Kembhavi", "Aniruddha", ""], ["Ehsani", "Kiana", ""], ["Pratt", "Sarah M", ""], ["Han", "Winson", ""], ["Herrasti", "Alvaro", ""], ["Kolve", "Eric", ""], ["Schwenk", "Dustin", ""], ["Mottaghi", "Roozbeh", ""], ["Farhadi", "Ali", ""]]}, {"id": "1912.08198", "submitter": "Alexander Hayes", "authors": "Alexander L. Hayes", "title": "srlearn: A Python Library for Gradient-Boosted Statistical Relational\n  Models", "comments": "Ninth International Workshop on Statistical Relational AI (StarAI\n  2020). Software online at https://github.com/hayesall/srlearn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present srlearn, a Python library for boosted statistical relational\nmodels. We adapt the scikit-learn interface to this setting and provide\nexamples for how this can be used to express learning and inference problems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 20:46:32 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Hayes", "Alexander L.", ""]]}, {"id": "1912.08374", "submitter": "Somak Aditya", "authors": "Somak Aditya, Atanu Sinha", "title": "Uncovering Relations for Marketing Knowledge Representation", "comments": "8 pages, 1 figure, 8 tables (2 page Appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online behaviors of consumers and marketers generate massive marketing data,\nwhich ever more sophisticated models attempt to turn into insights and aid\ndecisions by marketers. Yet, in making decisions human managers bring to bear\nmarketing knowledge which reside outside of data and models. Thus, it behooves\ncreation of an automated marketing knowledge base that can interact with data\nand models. Currently, marketing knowledge is dispersed in large corpora, but\nno definitive knowledge base for marketing exists. Out of the two broad aspects\nof marketing knowledge - representation and reasoning - this treatise focuses\non the former. Specifically, we focus on creation of marketing knowledge graph\nfrom corpora, which requires identification of entities and relations. The\nrelation identification task is particularly challenging in marketing, because\nof the non-factoid nature of much marketing knowledge, and the difficulty of\nforming rules that govern relations. Specifically, we define a set of relations\nto capture marketing knowledge, propose a pipeline for creating the knowledge\ngraph from text and propose a rule-guided semi-supervised relation prediction\nalgorithm to extract relations between marketing entities from sentences.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 04:32:18 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 09:05:59 GMT"}, {"version": "v3", "created": "Fri, 24 Jan 2020 03:49:50 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Aditya", "Somak", ""], ["Sinha", "Atanu", ""]]}, {"id": "1912.08388", "submitter": "Vedant Nanda", "authors": "Vedant Nanda and Pan Xu and Karthik Abinav Sankararaman and John P.\n  Dickerson and Aravind Srinivasan", "title": "Balancing the Tradeoff between Profit and Fairness in Rideshare\n  Platforms During High-Demand Hours", "comments": "8 pages, 4 figures, Accepted at AAAI 2020 & AIES (Oral) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rideshare platforms, when assigning requests to drivers, tend to maximize\nprofit for the system and/or minimize waiting time for riders. Such platforms\ncan exacerbate biases that drivers may have over certain types of requests. We\nconsider the case of peak hours when the demand for rides is more than the\nsupply of drivers. Drivers are well aware of their advantage during the peak\nhours and can choose to be selective about which rides to accept. Moreover, if\nin such a scenario, the assignment of requests to drivers (by the platform) is\nmade only to maximize profit and/or minimize wait time for riders, requests of\na certain type (e.g. from a non-popular pickup location, or to a non-popular\ndrop-off location) might never be assigned to a driver. Such a system can be\nhighly unfair to riders. However, increasing fairness might come at a cost of\nthe overall profit made by the rideshare platform. To balance these conflicting\ngoals, we present a flexible, non-adaptive algorithm, \\lpalg, that allows the\nplatform designer to control the profit and fairness of the system via\nparameters $\\alpha$ and $\\beta$ respectively. We model the matching problem as\nan online bipartite matching where the set of drivers is offline and requests\narrive online. Upon the arrival of a request, we use \\lpalg to assign it to a\ndriver (the driver might then choose to accept or reject it) or reject the\nrequest. We formalize the measures of profit and fairness in our setting and\nshow that by using \\lpalg, the competitive ratios for profit and fairness\nmeasures would be no worse than $\\alpha/e$ and $\\beta/e$ respectively.\nExtensive experimental results on both real-world and synthetic datasets\nconfirm the validity of our theoretical lower bounds. Additionally, they show\nthat $\\lpalg$ under some choice of $(\\alpha, \\beta)$ can beat two natural\nheuristics, Greedy and Uniform, on \\emph{both} fairness and profit.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 05:39:11 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 01:41:53 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Nanda", "Vedant", ""], ["Xu", "Pan", ""], ["Sankararaman", "Karthik Abinav", ""], ["Dickerson", "John P.", ""], ["Srinivasan", "Aravind", ""]]}, {"id": "1912.08404", "submitter": "Weixin Zeng", "authors": "Weixin Zeng, Xiang Zhao, Jiuyang Tang, and Xuemin Lin", "title": "Collective Entity Alignment via Adaptive Features", "comments": "ICDE20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity alignment (EA) identifies entities that refer to the same real-world\nobject but locate in different knowledge graphs (KGs), and has been harnessed\nfor KG construction and integration. When generating EA results, current\nsolutions treat entities independently and fail to take into account the\ninterdependence between entities. To fill this gap, we propose a collective EA\nframework. We first employ three representative features, i.e., structural,\nsemantic and string signals, which are adapted to capture different aspects of\nthe similarity between entities in heterogeneous KGs. In order to make\ncollective EA decisions, we formulate EA as the classical stable matching\nproblem, which is further effectively solved by deferred acceptance algorithm.\nOur proposal is evaluated on both cross-lingual and mono-lingual EA benchmarks\nagainst state-of-the-art solutions, and the empirical results verify its\neffectiveness and superiority.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 06:25:12 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 13:50:21 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 08:49:39 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zeng", "Weixin", ""], ["Zhao", "Xiang", ""], ["Tang", "Jiuyang", ""], ["Lin", "Xuemin", ""]]}, {"id": "1912.08441", "submitter": "Fanchao Qi", "authors": "Lei Zhang, Fanchao Qi, Zhiyuan Liu, Yasheng Wang, Qun Liu, Maosong Sun", "title": "Multi-channel Reverse Dictionary Model", "comments": "Accepted by AAAI Conference on Artificial Intelligence 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A reverse dictionary takes the description of a target word as input and\noutputs the target word together with other words that match the description.\nExisting reverse dictionary methods cannot deal with highly variable input\nqueries and low-frequency target words successfully. Inspired by the\ndescription-to-word inference process of humans, we propose the multi-channel\nreverse dictionary model, which can mitigate the two problems simultaneously.\nOur model comprises a sentence encoder and multiple predictors. The predictors\nare expected to identify different characteristics of the target word from the\ninput query. We evaluate our model on English and Chinese datasets including\nboth dictionary definitions and human-written descriptions. Experimental\nresults show that our model achieves the state-of-the-art performance, and even\noutperforms the most popular commercial reverse dictionary system on the\nhuman-written description dataset. We also conduct quantitative analyses and a\ncase study to demonstrate the effectiveness and robustness of our model. All\nthe code and data of this work can be obtained on\nhttps://github.com/thunlp/MultiRD.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 08:13:43 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 02:12:09 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Zhang", "Lei", ""], ["Qi", "Fanchao", ""], ["Liu", "Zhiyuan", ""], ["Wang", "Yasheng", ""], ["Liu", "Qun", ""], ["Sun", "Maosong", ""]]}, {"id": "1912.08442", "submitter": "Xinting Huang", "authors": "Xinting Huang, Jianzhong Qi, Yu Sun, Rui Zhang", "title": "MALA: Cross-Domain Dialogue Generation with Action Learning", "comments": "Update: Accepted to Proceedings of AAAI 2020", "journal-ref": null, "doi": "10.1609/aaai.v34i05.6306", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Response generation for task-oriented dialogues involves two basic\ncomponents: dialogue planning and surface realization. These two components,\nhowever, have a discrepancy in their objectives, i.e., task completion and\nlanguage quality. To deal with such discrepancy, conditioned response\ngeneration has been introduced where the generation process is factorized into\naction decision and language generation via explicit action representations. To\nobtain action representations, recent studies learn latent actions in an\nunsupervised manner based on the utterance lexical similarity. Such an action\nlearning approach is prone to diversities of language surfaces, which may\nimpinge task completion and language quality. To address this issue, we propose\nmulti-stage adaptive latent action learning (MALA) that learns semantic latent\nactions by distinguishing the effects of utterances on dialogue progress. We\nmodel the utterance effect using the transition of dialogue states caused by\nthe utterance and develop a semantic similarity measurement that estimates\nwhether utterances have similar effects. For learning semantic actions on\ndomains without dialogue states, MsALA extends the semantic similarity\nmeasurement across domains progressively, i.e., from aligning shared actions to\nlearning domain-specific actions. Experiments using multi-domain datasets, SMD\nand MultiWOZ, show that our proposed model achieves consistent improvements\nover the baselines models in terms of both task completion and language\nquality.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 08:14:10 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 13:33:38 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Huang", "Xinting", ""], ["Qi", "Jianzhong", ""], ["Sun", "Yu", ""], ["Zhang", "Rui", ""]]}, {"id": "1912.08444", "submitter": "Yichuan Charlie Tang", "authors": "Lionel Blond\\'e, Yichuan Charlie Tang, Jian Zhang, Russ Webb", "title": "Relational Mimic for Visual Adversarial Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce a new method for imitation learning from video\ndemonstrations. Our method, Relational Mimic (RM), improves on previous visual\nimitation learning methods by combining generative adversarial networks and\nrelational learning. RM is flexible and can be used in conjunction with other\nrecent advances in generative adversarial imitation learning to better address\nthe need for more robust and sample-efficient approaches. In addition, we\nintroduce a new neural network architecture that improves upon the previous\nstate-of-the-art in reinforcement learning and illustrate how increasing the\nrelational reasoning capabilities of the agent enables the latter to achieve\nincreasingly higher performance in a challenging locomotion task with pixel\ninputs. Finally, we study the effects and contributions of relational learning\nin policy evaluation, policy improvement and reward learning through ablation\nstudies.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 08:19:39 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Blond\u00e9", "Lionel", ""], ["Tang", "Yichuan Charlie", ""], ["Zhang", "Jian", ""], ["Webb", "Russ", ""]]}, {"id": "1912.08473", "submitter": "Daniel Graziotin", "authors": "Falko Koetter, Matthias Blohm, Jens Drawehn, Monika Kochanowski,\n  Joscha Goetzer, Daniel Graziotin, Stefan Wagner", "title": "Conversational Agents for Insurance Companies: From Theory to Practice", "comments": "26 pages, 7 figures. ICAART 2019 extension. Extension of\n  arXiv:1812.07339", "journal-ref": "Koetter F. et al. (2019) Conversational Agents for Insurance\n  Companies: From Theory to Practice. In: Agents and Artificial Intelligence.\n  ICAART 2019. LNCS, vol 11978. Springer, Cham", "doi": "10.1007/978-3-030-37494-5_17", "report-no": null, "categories": "cs.HC cs.AI cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in artificial intelligence have renewed interest in conversational\nagents. Additionally to software developers, today all kinds of employees show\ninterest in new technologies and their possible applications for customers.\nGerman insurance companies generally are interested in improving their customer\nservice and digitizing their business processes. In this work we investigate\nthe potential use of conversational agents in insurance companies theoretically\nby determining which classes of agents exist which are of interest to insurance\ncompanies, finding relevant use cases and requirements. We add two practical\nparts: First we develop a showcase prototype for an exemplary insurance\nscenario in claim management. Additionally in a second step, we create a\nprototype focusing on customer service in a chatbot hackathon, fostering\ninnovation in interdisciplinary teams. In this work, we describe the results of\nboth prototypes in detail. We evaluate both chatbots defining criteria for both\nsettings in detail and compare the results and draw conclusions for the\nmaturity of chatbot technology for practical use, describing the opportunities\nand challenges companies, especially small and medium enterprises, face.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 09:26:55 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Koetter", "Falko", ""], ["Blohm", "Matthias", ""], ["Drawehn", "Jens", ""], ["Kochanowski", "Monika", ""], ["Goetzer", "Joscha", ""], ["Graziotin", "Daniel", ""], ["Wagner", "Stefan", ""]]}, {"id": "1912.08578", "submitter": "Adil Rasheed Professor", "authors": "Eivind Meyer, Haakon Robinson, Adil Rasheed, Omer San", "title": "Taming an autonomous surface vehicle for path following and collision\n  avoidance using deep reinforcement learning", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we explore the feasibility of applying proximal policy\noptimization, a state-of-the-art deep reinforcement learning algorithm for\ncontinuous control tasks, on the dual-objective problem of controlling an\nunderactuated autonomous surface vehicle to follow an a priori known path while\navoiding collisions with non-moving obstacles along the way. The artificial\nintelligent agent, which is equipped with multiple rangefinder sensors for\nobstacle detection, is trained and evaluated in a challenging, stochastically\ngenerated simulation environment based on the OpenAI gym python toolkit.\nNotably, the agent is provided with real-time insight into its own reward\nfunction, allowing it to dynamically adapt its guidance strategy. Depending on\nits strategy, which ranges from radical path-adherence to radical obstacle\navoidance, the trained agent achieves an episodic success rate between 84 and\n100%.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 13:08:30 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Meyer", "Eivind", ""], ["Robinson", "Haakon", ""], ["Rasheed", "Adil", ""], ["San", "Omer", ""]]}, {"id": "1912.08633", "submitter": "Anastasios Nentidis", "authors": "Anastasios Nentidis, Konstantinos Bougiatiotis, Anastasia Krithara,\n  Georgios Paliouras", "title": "iASiS Open Data Graph: Automated Semantic Integration of\n  Disease-Specific Knowledge", "comments": "6 pages, 2 figures, accepted in IEEE 33rd International Symposium on\n  Computer Based Medical Systems (CBMS2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In biomedical research, unified access to up-to-date domain-specific\nknowledge is crucial, as such knowledge is continuously accumulated in\nscientific literature and structured resources. Identifying and extracting\nspecific information is a challenging task and computational analysis of\nknowledge bases can be valuable in this direction. However, for\ndisease-specific analyses researchers often need to compile their own datasets,\nintegrating knowledge from different resources, or reuse existing datasets,\nthat can be out-of-date. In this study, we propose a framework to automatically\nretrieve and integrate disease-specific knowledge into an up-to-date semantic\ngraph, the iASiS Open Data Graph. This disease-specific semantic graph provides\naccess to knowledge relevant to specific concepts and their individual aspects,\nin the form of concept relations and attributes. The proposed approach is\nimplemented as an open-source framework and applied to three diseases (Lung\nCancer, Dementia, and Duchenne Muscular Dystrophy). Exemplary queries are\npresented, investigating the potential of this automatically generated semantic\ngraph as a basis for retrieval and analysis of disease-specific knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 14:33:05 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 10:47:56 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Nentidis", "Anastasios", ""], ["Bougiatiotis", "Konstantinos", ""], ["Krithara", "Anastasia", ""], ["Paliouras", "Georgios", ""]]}, {"id": "1912.08664", "submitter": "Aleksandr Panov", "authors": "Alexey Skrynnik, Aleksey Staroverov, Ermek Aitygulov, Kirill Aksenov,\n  Vasilii Davydov, Aleksandr I. Panov", "title": "Hierarchical Deep Q-Network from Imperfect Demonstrations in Minecraft", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present Hierarchical Deep Q-Network (HDQfD) that took first place in the\nMineRL competition. HDQfD works on imperfect demonstrations and utilizes the\nhierarchical structure of expert trajectories. We introduce the procedure of\nextracting an effective sequence of meta-actions and subgoals from\ndemonstration data. We present a structured task-dependent replay buffer and\nadaptive prioritizing technique that allow the HDQfD agent to gradually erase\npoor-quality expert data from the buffer. In this paper, we present the details\nof the HDQfD algorithm and give the experimental results in the Minecraft\ndomain.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 15:30:49 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 07:49:09 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 16:37:44 GMT"}, {"version": "v4", "created": "Mon, 13 Jul 2020 09:24:50 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Skrynnik", "Alexey", ""], ["Staroverov", "Aleksey", ""], ["Aitygulov", "Ermek", ""], ["Aksenov", "Kirill", ""], ["Davydov", "Vasilii", ""], ["Panov", "Aleksandr I.", ""]]}, {"id": "1912.08740", "submitter": "Marcio Ferreira Moreno", "authors": "Marcio Moreno, Daniel Civitarese, Rafael Brandao, Renato Cerqueira", "title": "Effective Integration of Symbolic and Connectionist Approaches through a\n  Hybrid Representation", "comments": "3 pages, 3 figures, accepted on NeSy'2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our position for a neuralsymbolic integration\nstrategy, arguing in favor of a hybrid representation to promote an effective\nintegration. Such description differs from others fundamentally, since its\nentities aim at representing AI models in general, allowing to describe both\nnonsymbolic and symbolic knowledge, the integration between them and their\ncorresponding processors. Moreover, the entities also support representing\nworkflows, leveraging traceability to keep track of every change applied to\nmodels and their related entities (e.g., data or concepts) throughout the\nlifecycle of the models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 17:10:58 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Moreno", "Marcio", ""], ["Civitarese", "Daniel", ""], ["Brandao", "Rafael", ""], ["Cerqueira", "Renato", ""]]}, {"id": "1912.08785", "submitter": "Piotr S. Maci\\k{a}g", "authors": "Piotr S. Maci\\k{a}g (1), Marzena Kryszkiewicz (1), Robert Bembenik\n  (1), Jesus L. Lobo (2), Javier Del Ser (2 and 3) ((1) Institute of Computer\n  Science, Warsaw University of Technology, Warsaw, Poland, (2) TECNALIA Parque\n  Tecnol\\'ogico de Bizkaia, Derio, Spain, (3) University of the Basque Country\n  UPV/EHU, Bilbao, Spain)", "title": "Unsupervised Anomaly Detection in Stream Data with Online Evolving\n  Spiking Neural Networks", "comments": "52 pages", "journal-ref": "Neural Networks, Volume 139, 2021, Pages 118-139", "doi": "10.1016/j.neunet.2021.02.017", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Unsupervised anomaly discovery in stream data is a research topic with many\npractical applications. However, in many cases, it is not easy to collect\nenough training data with labeled anomalies for supervised learning of an\nanomaly detector in order to deploy it later for identification of real\nanomalies in streaming data. It is thus important to design anomalies detectors\nthat can correctly detect anomalies without access to labeled training data.\nOur idea is to adapt the Online evolving Spiking Neural Network (OeSNN)\nclassifier to the anomaly detection task. As a result, we offer an Online\nevolving Spiking Neural Network for Unsupervised Anomaly Detection algorithm\n(OeSNN-UAD), which, unlike OeSNN, works in an unsupervised way and does not\nseparate output neurons into disjoint decision classes. OeSNN-UAD uses our\nproposed new two-step anomaly detection method. Also, we derive new theoretical\nproperties of neuronal model and input layer encoding of OeSNN, which enable\nmore effective and efficient detection of anomalies in our OeSNN-UAD approach.\nThe proposed OeSNN-UAD detector was experimentally compared with\nstate-of-the-art unsupervised and semi-supervised detectors of anomalies in\nstream data from the Numenta Anomaly Benchmark and Yahoo Anomaly Datasets\nrepositories. Our approach outperforms the other solutions provided in the\nliterature in the case of data streams from the Numenta Anomaly Benchmark\nrepository. Also, in the case of real data files of the Yahoo Anomaly Benchmark\nrepository, OeSNN-UAD outperforms other selected algorithms, whereas in the\ncase of Yahoo Anomaly Benchmark synthetic data files, it provides competitive\nresults to the results recently reported in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 18:36:01 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 20:17:42 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Maci\u0105g", "Piotr S.", "", "2 and 3"], ["Kryszkiewicz", "Marzena", "", "2 and 3"], ["Bembenik", "Robert", "", "2 and 3"], ["Lobo", "Jesus L.", "", "2 and 3"], ["Del Ser", "Javier", "", "2 and 3"]]}, {"id": "1912.08786", "submitter": "Thomas Bartz-Beielstein", "authors": "Thomas Bartz-Beielstein", "title": "Why we need an AI-resilient society", "comments": "For associated TEDx video, see https://youtu.be/f6c2ngp7rqY", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Artificial intelligence is considered as a key technology. It has a huge\nimpact on our society. Besides many positive effects, there are also some\nnegative effects or threats. Some of these threats to society are well-known,\ne.g., weapons or killer robots. But there are also threats that are ignored.\nThese unknown-knowns or blind spots affect privacy, and facilitate manipulation\nand mistaken identities. We cannot trust data, audio, video, and identities any\nmore. Democracies are able to cope with known threats, the known-knowns.\nTransforming unknown-knowns to known-knowns is one important cornerstone of\nresilient societies. An AI-resilient society is able to transform threats\ncaused by new AI tecchnologies such as generative adversarial networks.\nResilience can be seen as a positive adaptation of these threats. We propose\nthree strategies how this adaptation can be achieved: awareness, agreements,\nand red flags. This article accompanies the TEDx talk \"Why we urgently need an\nAI-resilient society\", see https://youtu.be/f6c2ngp7rqY.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 18:36:20 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Bartz-Beielstein", "Thomas", ""]]}, {"id": "1912.08919", "submitter": "Michael Franklin Mbouopda", "authors": "Michael Mbouopda (LIMOS), Engelbert Mephu Nguifo (LIMOS)", "title": "Classification des S{\\'e}ries Temporelles Incertaines par Transformation\n  Shapelet", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time serie classification is used in a diverse range of domain such as\nmeteorology, medicine and physics. It aims to classify chronological data. Many\naccurate approaches have been built during the last decade and shapelet\ntransformation is one of them. However, none of these approaches does take data\nuncertainty into account. Using uncertainty propagation techiniques, we propose\na new dissimilarity measure based on euclidean distance. We also show how to\nuse this new measure to adapt shapelet transformation to uncertain time series\nclassification. An experimental assessment of our contribution is done on some\nstate of the art datasets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 14:58:19 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Mbouopda", "Michael", "", "LIMOS"], ["Nguifo", "Engelbert Mephu", "", "LIMOS"]]}, {"id": "1912.08946", "submitter": "Francisco C. Santos", "authors": "Luis Moniz Pereira and Francisco C. Santos", "title": "Counterfactual thinking in cooperation dynamics", "comments": "18 pages", "journal-ref": "in: Model-based reason-ing in science and technology - Inferential\n  models for Logic, Language, Cognition and Computation, Collection on Studies\n  in Applied Philosophy, Epistemology and Rational Ethics (SAPERE), Springer,\n  2019", "doi": "10.1007/978-3-030-32722-4_5", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual Thinking is a human cognitive ability studied in a wide\nvariety of domains. It captures the process of reasoning about a past event\nthat did not occur, namely what would have happened had this event occurred,\nor, otherwise, to reason about an event that did occur but what would ensue had\nit not. Given the wide cognitive empowerment of counterfactual reasoning in the\nhuman individual, the question arises of how the presence of individuals with\nthis capability may improve cooperation in populations of self-regarding\nindividuals. Here we propose a mathematical model, grounded on Evolutionary\nGame Theory, to examine the population dynamics emerging from the interplay\nbetween counterfactual thinking and social learning (i.e., individuals that\nlearn from the actions and success of others) whenever the individuals in the\npopulation face a collective dilemma. Our results suggest that counterfactual\nreasoning fosters coordination in collective action problems occurring in large\npopulations, and has a limited impact on cooperation dilemmas in which\ncoordination is not required. Moreover, we show that a small prevalence of\nindividuals resorting to counterfactual thinking is enough to nudge an entire\npopulation towards highly cooperative standards.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 23:38:34 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Pereira", "Luis Moniz", ""], ["Santos", "Francisco C.", ""]]}, {"id": "1912.08964", "submitter": "Ross Gruetzemacher", "authors": "Shahar Avin, Ross Gruetzemacher, James Fox", "title": "Exploring AI Futures Through Role Play", "comments": "Accepted to AIES", "journal-ref": null, "doi": "10.1145/3375627.3375817", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an innovative methodology for studying and teaching the impacts of\nAI through a role play game. The game serves two primary purposes: 1) training\nAI developers and AI policy professionals to reflect on and prepare for future\nsocial and ethical challenges related to AI and 2) exploring possible futures\ninvolving AI technology development, deployment, social impacts, and\ngovernance. While the game currently focuses on the inter relations between\nshort --, mid and long term impacts of AI, it has potential to be adapted for a\nbroad range of scenarios, exploring in greater depths issues of AI policy\nresearch and affording training within organizations. The game presented here\nhas undergone two years of development and has been tested through over 30\nevents involving between 3 and 70 participants. The game is under active\ndevelopment, but preliminary findings suggest that role play is a promising\nmethodology for both exploring AI futures and training individuals and\norganizations in thinking about, and reflecting on, the impacts of AI and\nstrategic mistakes that can be avoided today.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 00:41:11 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Avin", "Shahar", ""], ["Gruetzemacher", "Ross", ""], ["Fox", "James", ""]]}, {"id": "1912.08998", "submitter": "Yoshihiko Suhara", "authors": "Masahiro Kazama, Yoshihiko Suhara, Andrey Bogomolov, Alex `Sandy'\n  Pentland", "title": "Understanding Human Judgments of Causality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discriminating between causality and correlation is a major problem in\nmachine learning, and theoretical tools for determining causality are still\nbeing developed. However, people commonly make causality judgments and are\noften correct, even in unfamiliar domains. What are humans doing to make these\njudgments? This paper examines differences in human experts' and non-experts'\nability to attribute causality by comparing their performances to those of\nmachine-learning algorithms. We collected human judgments by using Amazon\nMechanical Turk (MTurk) and then divided the human subjects into two groups:\nexperts and non-experts. We also prepared expert and non-expert machine\nalgorithms based on different training of convolutional neural network (CNN)\nmodels. The results showed that human experts' judgments were similar to those\nmade by an \"expert\" CNN model trained on a large number of examples from the\ntarget domain. The human non-experts' judgments resembled the prediction\noutputs of the CNN model that was trained on only the small number of examples\nused during the MTurk instruction. We also analyzed the differences between the\nexpert and non-expert machine algorithms based on their neural representations\nto evaluate the performances, providing insight into the human experts' and\nnon-experts' cognitive abilities.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 03:08:11 GMT"}], "update_date": "2019-12-21", "authors_parsed": [["Kazama", "Masahiro", ""], ["Suhara", "Yoshihiko", ""], ["Bogomolov", "Andrey", ""], ["Pentland", "Alex `Sandy'", ""]]}, {"id": "1912.09007", "submitter": "Pedro Sequeira", "authors": "Pedro Sequeira and Melinda Gervasio", "title": "Interestingness Elements for Explainable Reinforcement Learning:\n  Understanding Agents' Capabilities and Limitations", "comments": "To appear in: Artificial Intelligence", "journal-ref": null, "doi": "10.1016/j.artint.2020.103367", "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an explainable reinforcement learning (XRL) framework that\nanalyzes an agent's history of interaction with the environment to extract\ninterestingness elements that help explain its behavior. The framework relies\non data readily available from standard RL algorithms, augmented with data that\ncan easily be collected by the agent while learning. We describe how to create\nvisual summaries of an agent's behavior in the form of short video-clips\nhighlighting key interaction moments, based on the proposed elements. We also\nreport on a user study where we evaluated the ability of humans to correctly\nperceive the aptitude of agents with different characteristics, including their\ncapabilities and limitations, given visual summaries automatically generated by\nour framework. The results show that the diversity of aspects captured by the\ndifferent interestingness elements is crucial to help humans correctly\nunderstand an agent's strengths and limitations in performing a task, and\ndetermine when it might need adjustments to improve its performance.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 03:46:22 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 03:25:14 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Sequeira", "Pedro", ""], ["Gervasio", "Melinda", ""]]}, {"id": "1912.09015", "submitter": "Dongmyung Shin", "authors": "Dongmyung Shin, Sooyeon Ji, Doohee Lee, Jieun Lee, Se-Hong Oh, and\n  Jongho Lee", "title": "Deep Reinforcement Learning Designed Shinnar-Le Roux RF Pulse using\n  Root-Flipping: DeepRF_SLR", "comments": "Accepted at IEEE transactions on Medical Imaging\n  (https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9174664)", "journal-ref": null, "doi": "10.1109/TMI.2020.3018508", "report-no": null, "categories": "cs.LG cs.AI eess.IV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach of applying deep reinforcement learning to an RF pulse\ndesign is introduced. This method, which is referred to as DeepRF_SLR, is\ndesigned to minimize the peak amplitude or, equivalently, minimize the pulse\nduration of a multiband refocusing pulse generated by the Shinar Le-Roux (SLR)\nalgorithm. In the method, the root pattern of SLR polynomial, which determines\nthe RF pulse shape, is optimized by iterative applications of deep\nreinforcement learning and greedy tree search. When tested for the designs of\nthe multiband factors of three and seven RFs, DeepRF_SLR demonstrated improved\nperformance compared to conventional methods, generating shorter duration RF\npulses in shorter computational time. In the experiments, the RF pulse from\nDeepRF_SLR produced a slice profile similar to the minimum-phase SLR RF pulse\nand the profiles matched to that of the computer simulation. Our approach\nsuggests a new way of designing an RF by applying a machine learning algorithm,\ndemonstrating a machine-designed MRI sequence.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 04:51:57 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 13:20:04 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 08:46:31 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Shin", "Dongmyung", ""], ["Ji", "Sooyeon", ""], ["Lee", "Doohee", ""], ["Lee", "Jieun", ""], ["Oh", "Se-Hong", ""], ["Lee", "Jongho", ""]]}, {"id": "1912.09024", "submitter": "Andreas Holzinger", "authors": "Andreas Holzinger, Andr\\'e Carrington, Heimo M\\\"uller", "title": "Measuring the Quality of Explanations: The System Causability Scale\n  (SCS). Comparing Human and Machine Explanations", "comments": "6 pages, 1 figure, 1 table, will appear in Springer/Nature KI -\n  K\\\"unstliche Intelligenz (2020), Volume 34, Issue 2", "journal-ref": "Springer/Nature KI Kuenstliche Intelligenz 34, 193-198 (2020)", "doi": "10.1007/s13218-020-00636-z", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent success in Artificial Intelligence (AI) and Machine Learning (ML)\nallow problem solving automatically without any human intervention. Autonomous\napproaches can be very convenient. However, in certain domains, e.g., in the\nmedical domain, it is necessary to enable a domain expert to understand, why an\nalgorithm came up with a certain result. Consequently, the field of Explainable\nAI (xAI) rapidly gained interest worldwide in various domains, particularly in\nmedicine. Explainable AI studies transparency and traceability of opaque AI/ML\nand there are already a huge variety of methods. For example with layer-wise\nrelevance propagation relevant parts of inputs to, and representations in, a\nneural network which caused a result, can be highlighted. This is a first\nimportant step to ensure that end users, e.g., medical professionals, assume\nresponsibility for decision making with AI/ML and of interest to professionals\nand regulators. Interactive ML adds the component of human expertise to AI/ML\nprocesses by enabling them to re-enact and retrace AI/ML results, e.g. let them\ncheck it for plausibility. This requires new human-AI interfaces for\nexplainable AI. In order to build effective and efficient interactive human-AI\ninterfaces we have to deal with the question of how to evaluate the quality of\nexplanations given by an explainable AI system. In this paper we introduce our\nSystem Causability Scale (SCS) to measure the quality of explanations. It is\nbased on our notion of Causability (Holzinger et al., 2019) combined with\nconcepts adapted from a widely accepted usability scale.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 05:34:08 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Holzinger", "Andreas", ""], ["Carrington", "Andr\u00e9", ""], ["M\u00fcller", "Heimo", ""]]}, {"id": "1912.09211", "submitter": "Jorge Fandinno", "authors": "Jorge Fandinno and Johannes Fichte", "title": "Proceedings of the twelfth Workshop on Answer Set Programming and Other\n  Computing Paradigms 2019", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the twelfth Workshop on Answer Set Programming and\nOther Computing Paradigms (ASPOCP) 2019, which was held in Philadelphia, USA,\nJune 3rd , 2019.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:47:40 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Fandinno", "Jorge", ""], ["Fichte", "Johannes", ""]]}, {"id": "1912.09260", "submitter": "Christopher Mutschler", "authors": "Leonid Butyrev, Thorsten Edelh\\\"au{\\ss}er, Christopher Mutschler", "title": "Deep Reinforcement Learning for Motion Planning of Mobile Robots", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel motion and trajectory planning algorithm for\nnonholonomic mobile robots that uses recent advances in deep reinforcement\nlearning. Starting from a random initial state, i.e., position, velocity and\norientation, the robot reaches an arbitrary target state while taking both\nkinematic and dynamic constraints into account. Our deep reinforcement learning\nagent not only processes a continuous state space it also executes continuous\nactions, i.e., the acceleration of wheels and the adaptation of the steering\nangle. We evaluate our motion and trajectory planning on a mobile robot with a\ndifferential drive in a simulation environment.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 15:12:39 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Butyrev", "Leonid", ""], ["Edelh\u00e4u\u00dfer", "Thorsten", ""], ["Mutschler", "Christopher", ""]]}, {"id": "1912.09322", "submitter": "Sergio Gast\\'on Burdisso", "authors": "Sergio G. Burdisso, Marcelo Errecalde, Manuel Montes-y-G\\'omez", "title": "PySS3: A Python package implementing a novel text classifier with\n  visualization tools for Explainable AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recently introduced text classifier, called SS3, has obtained\nstate-of-the-art performance on the CLEF's eRisk tasks. SS3 was created to deal\nwith risk detection over text streams and, therefore, not only supports\nincremental training and classification but also can visually explain its\nrationale. However, little attention has been paid to the potential use of SS3\nas a general classifier. We believe this could be due to the unavailability of\nan open-source implementation of SS3. In this work, we introduce PySS3, a\npackage that implements SS3 and also comes with visualization tools that allow\nresearchers to deploy robust, explainable, and trusty machine learning models\nfor text classification.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 16:01:41 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 00:31:35 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Burdisso", "Sergio G.", ""], ["Errecalde", "Marcelo", ""], ["Montes-y-G\u00f3mez", "Manuel", ""]]}, {"id": "1912.09445", "submitter": "S. Mohammad Mirbagheri", "authors": "S. Mohammad Mirbagheri, Howard J. Hamilton", "title": "FIBS: A Generic Framework for Classifying Interval-based Temporal\n  Sequences", "comments": "In: Big Data Analytics and Knowledge Discovery. DaWaK 2020. Springer,\n  Cham", "journal-ref": "22nd International Conference on Big Data Analytics and Knowledge\n  Discovery (DaWaK), Bratislava, Slovakia, September 14-17, 2020. Springer,\n  Cham", "doi": "10.1007/978-3-030-59065-9_24", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of classifying interval-based temporal sequences\n(IBTSs). Since common classification algorithms cannot be directly applied to\nIBTSs, the main challenge is to define a set of features that effectively\nrepresents the data such that classifiers can be applied. Most prior work\nutilizes frequent pattern mining to define a feature set based on discovered\npatterns. However, frequent pattern mining is computationally expensive and\noften discovers many irrelevant patterns. To address this shortcoming, we\npropose the FIBS framework for classifying IBTSs. FIBS extracts features\nrelevant to classification from IBTSs based on relative frequency and temporal\nrelations. To avoid selecting irrelevant features, a filter-based selection\nstrategy is incorporated into FIBS. Our empirical evaluation on eight\nreal-world datasets demonstrates the effectiveness of our methods in practice.\nThe results provide evidence that FIBS effectively represents IBTSs for\nclassification algorithms, which contributes to similar or significantly better\naccuracy compared to state-of-the-art competitors. It also suggests that the\nfeature selection strategy is beneficial to FIBS's performance.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 18:23:27 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 18:21:47 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Mirbagheri", "S. Mohammad", ""], ["Hamilton", "Howard J.", ""]]}, {"id": "1912.09501", "submitter": "Haozhen Zhao", "authors": "Christian J. Mahoney, Jianping Zhang, Nathaniel Huber-Fliflet, Peter\n  Gronvall, Haozhen Zhao", "title": "A Framework for Explainable Text Classification in Legal Document Review", "comments": "2019 IEEE International Conference on Big Data (Big Data). arXiv\n  admin note: text overlap with arXiv:1904.01721", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Companies regularly spend millions of dollars producing electronically-stored\ndocuments in legal matters. Recently, parties on both sides of the 'legal\naisle' are accepting the use of machine learning techniques like text\nclassification to cull massive volumes of data and to identify responsive\ndocuments for use in these matters. While text classification is regularly used\nto reduce the discovery costs in legal matters, it also faces a peculiar\nperception challenge: amongst lawyers, this technology is sometimes looked upon\nas a \"black box\", little information provided for attorneys to understand why\ndocuments are classified as responsive. In recent years, a group of AI and ML\nresearchers have been actively researching Explainable AI, in which actions or\ndecisions are human understandable. In legal document review scenarios, a\ndocument can be identified as responsive, if one or more of its text snippets\nare deemed responsive. In these scenarios, if text classification can be used\nto locate these snippets, then attorneys could easily evaluate the model's\nclassification decision. When deployed with defined and explainable results,\ntext classification can drastically enhance overall quality and speed of the\nreview process by reducing the review time. Moreover, explainable predictive\ncoding provides lawyers with greater confidence in the results of that\nsupervised learning task. This paper describes a framework for explainable text\nclassification as a valuable tool in legal services: for enhancing the quality\nand efficiency of legal document review and for assisting in locating\nresponsive snippets within responsive documents. This framework has been\nimplemented in our legal analytics product, which has been used in hundreds of\nlegal matters. We also report our experimental results using the data from an\nactual legal matter that used this type of document review.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 19:07:23 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Mahoney", "Christian J.", ""], ["Zhang", "Jianping", ""], ["Huber-Fliflet", "Nathaniel", ""], ["Gronvall", "Peter", ""], ["Zhao", "Haozhen", ""]]}, {"id": "1912.09539", "submitter": "Hamidreza Kasaei", "authors": "S. Hamidreza Kasaei", "title": "Interactive Open-Ended Learning for 3D Object Recognition", "comments": "PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The thesis contributes in several important ways to the research area of 3D\nobject category learning and recognition. To cope with the mentioned\nlimitations, we look at human cognition, in particular at the fact that human\nbeings learn to recognize object categories ceaselessly over time. This ability\nto refine knowledge from the set of accumulated experiences facilitates the\nadaptation to new environments. Inspired by this capability, we seek to create\na cognitive object perception and perceptual learning architecture that can\nlearn 3D object categories in an open-ended fashion. In this context,\n``open-ended'' implies that the set of categories to be learned is not known in\nadvance, and the training instances are extracted from actual experiences of a\nrobot, and thus become gradually available, rather than being available since\nthe beginning of the learning process. In particular, this architecture\nprovides perception capabilities that will allow robots to incrementally learn\nobject categories from the set of accumulated experiences and reason about how\nto perform complex tasks. This framework integrates detection, tracking,\nteaching, learning, and recognition of objects. An extensive set of systematic\nexperiments, in multiple experimental settings, was carried out to thoroughly\nevaluate the described learning approaches. Experimental results show that the\nproposed system is able to interact with human users, learn new object\ncategories over time, as well as perform complex tasks. The contributions\npresented in this thesis have been fully implemented and evaluated on different\nstandard object and scene datasets and empirically evaluated on different\nrobotic platforms.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 20:46:51 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Kasaei", "S. Hamidreza", ""]]}, {"id": "1912.09551", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro and Vinay P. Namboodiri", "title": "Deep Exemplar Networks for VQA and VQG", "comments": "This work is an extension of CVPR-2018 accepted paper\n  arXiv:1804.00298 and EMNLP-2018 accepted paper arXiv:1808.03986", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we consider the problem of solving semantic tasks such as\n`Visual Question Answering' (VQA), where one aims to answers related to an\nimage and `Visual Question Generation' (VQG), where one aims to generate a\nnatural question pertaining to an image. Solutions for VQA and VQG tasks have\nbeen proposed using variants of encoder-decoder deep learning based frameworks\nthat have shown impressive performance. Humans however often show\ngeneralization by relying on exemplar based approaches. For instance, the work\nby Tversky and Kahneman suggests that humans use exemplars when making\ncategorizations and decisions. In this work, we propose the incorporation of\nexemplar based approaches towards solving these problems. Specifically, we\nincorporate exemplar based approaches and show that an exemplar based module\ncan be incorporated in almost any of the deep learning architectures proposed\nin the literature and the addition of such a block results in improved\nperformance for solving these tasks. Thus, just as the incorporation of\nattention is now considered de facto useful for solving these tasks, similarly,\nincorporating exemplars also can be considered to improve any proposed\narchitecture for solving this task. We provide extensive empirical analysis for\nthe same through various architectures, ablations, and state of the art\ncomparisons.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 21:29:22 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Patro", "Badri N.", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1912.09571", "submitter": "Samuel Alexander", "authors": "Samuel Allen Alexander", "title": "Measuring the intelligence of an idealized mechanical knowing agent", "comments": "17 pages, CIFMA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a notion of the intelligence level of an idealized mechanical\nknowing agent. This is motivated by efforts within artificial intelligence\nresearch to define real-number intelligence levels of complicated intelligent\nsystems. Our agents are more idealized, which allows us to define a much\nsimpler measure of intelligence level for them. In short, we define the\nintelligence level of a mechanical knowing agent to be the supremum of the\ncomputable ordinals that have codes the agent knows to be codes of computable\nordinals. We prove that if one agent knows certain things about another agent,\nthen the former necessarily has a higher intelligence level than the latter.\nThis allows our intelligence notion to serve as a stepping stone to obtain\nresults which, by themselves, are not stated in terms of our intelligence\nnotion (results of potential interest even to readers totally skeptical that\nour notion correctly captures intelligence). As an application, we argue that\nthese results comprise evidence against the possibility of intelligence\nexplosion (that is, the notion that sufficiently intelligent machines will\neventually be capable of designing even more intelligent machines, which can\nthen design even more intelligent machines, and so on).\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 02:03:00 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Alexander", "Samuel Allen", ""]]}, {"id": "1912.09589", "submitter": "Denis Gudovskiy", "authors": "Denis Gudovskiy, Gyuri Han, Takuya Yamaguchi, Sotaro Tsukizawa", "title": "Smart Home Appliances: Chat with Your Fridge", "comments": "NeurIPS 2019 demo track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current home appliances are capable to execute a limited number of voice\ncommands such as turning devices on or off, adjusting music volume or light\nconditions. Recent progress in machine reasoning gives an opportunity to\ndevelop new types of conversational user interfaces for home appliances. In\nthis paper, we apply state-of-the-art visual reasoning model and demonstrate\nthat it is feasible to ask a smart fridge about its contents and various\nproperties of the food with close-to-natural conversation experience. Our\nvisual reasoning model answers user questions about existence, count, category\nand freshness of each product by analyzing photos made by the image sensor\ninside the smart fridge. Users may chat with their fridge using off-the-shelf\nphone messenger while being away from home, for example, when shopping in the\nsupermarket. We generate a visually realistic synthetic dataset to train\nmachine learning reasoning model that achieves 95% answer accuracy on test\ndata. We present the results of initial user tests and discuss how we modify\ndistribution of generated questions for model training based on\nhuman-in-the-loop guidance. We open source code for the whole system including\ndataset generation, reasoning model and demonstration scripts.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 23:12:25 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Gudovskiy", "Denis", ""], ["Han", "Gyuri", ""], ["Yamaguchi", "Takuya", ""], ["Tsukizawa", "Sotaro", ""]]}, {"id": "1912.09621", "submitter": "Barath Narayanan Narayanan", "authors": "Barath Narayanan Narayanan, Manawaduge Supun De Silva, Russell C.\n  Hardie, Nathan K. Kueterman, Redha Ali", "title": "Understanding Deep Neural Network Predictions for Medical Imaging\n  Applications", "comments": "20 pages, 28 Figures and 9 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computer-aided detection has been a research area attracting great interest\nin the past decade. Machine learning algorithms have been utilized extensively\nfor this application as they provide a valuable second opinion to the doctors.\nDespite several machine learning models being available for medical imaging\napplications, not many have been implemented in the real-world due to the\nuninterpretable nature of the decisions made by the network. In this paper, we\ninvestigate the results provided by deep neural networks for the detection of\nmalaria, diabetic retinopathy, brain tumor, and tuberculosis in different\nimaging modalities. We visualize the class activation mappings for all the\napplications in order to enhance the understanding of these networks. This type\nof visualization, along with the corresponding network performance metrics,\nwould aid the data science experts in better understanding of their models as\nwell as assisting doctors in their decision-making process.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 02:57:05 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Narayanan", "Barath Narayanan", ""], ["De Silva", "Manawaduge Supun", ""], ["Hardie", "Russell C.", ""], ["Kueterman", "Nathan K.", ""], ["Ali", "Redha", ""]]}, {"id": "1912.09644", "submitter": "Dongfang Zhao", "authors": "Dongfang Zhao", "title": "The Blockchain Game: Synthesis of Byzantine Systems and Nash Equilibria", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This position paper presents a synthesis viewpoint of blockchains from two\northogonal perspectives: fault-tolerant distributed systems and game theory.\nSpecifically, we formulate a new game-theoretical problem in the context of\nblockchains and sketch a closed-form Nash equilibrium to the problem.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 05:14:20 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Zhao", "Dongfang", ""]]}, {"id": "1912.09715", "submitter": "Andrzej Szalas", "authors": "Andrzej Szalas", "title": "A Paraconsistent ASP-like Language with Tractable Model Generation", "comments": null, "journal-ref": "Journal of Applied Logic - IfColog Journal of Logic and their\n  Applications, vol. 7, No. 3, 2020, 361-389,\n  http://www.collegepublications.co.uk/downloads/ifcolog00039.pdf", "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is nowadays a dominant rule-based knowledge\nrepresentation tool. Though existing ASP variants enjoy efficient\nimplementations, generating an answer set remains intractable. The goal of this\nresearch is to define a new \\asp-like rule language, 4SP, with tractable model\ngeneration. The language combines ideas of ASP and a paraconsistent rule\nlanguage 4QL. Though 4SP shares the syntax of \\asp and for each program all its\nanswer sets are among 4SP models, the new language differs from ASP in its\nlogical foundations, the intended methodology of its use and complexity of\ncomputing models.\n  As we show in the paper, 4QL can be seen as a paraconsistent counterpart of\nASP programs stratified with respect to default negation. Although model\ngeneration of well-supported models for 4QL programs is tractable, dropping\nstratification makes both 4QL and ASP intractable. To retain tractability while\nallowing non-stratified programs, in 4SP we introduce trial expressions\ninterlacing programs with hypotheses as to the truth values of default\nnegations. This allows us to develop a~model generation algorithm with\ndeterministic polynomial time complexity.\n  We also show relationships among 4SP, ASP and 4QL.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 09:35:29 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Szalas", "Andrzej", ""]]}, {"id": "1912.09729", "submitter": "Deheng Ye", "authors": "Deheng Ye, Zhao Liu, Mingfei Sun, Bei Shi, Peilin Zhao, Hao Wu,\n  Hongsheng Yu, Shaojie Yang, Xipeng Wu, Qingwei Guo, Qiaobo Chen, Yinyuting\n  Yin, Hao Zhang, Tengfei Shi, Liang Wang, Qiang Fu, Wei Yang, Lanxiao Huang", "title": "Mastering Complex Control in MOBA Games with Deep Reinforcement Learning", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the reinforcement learning problem of complex action control in the\nMulti-player Online Battle Arena (MOBA) 1v1 games. This problem involves far\nmore complicated state and action spaces than those of traditional 1v1 games,\nsuch as Go and Atari series, which makes it very difficult to search any\npolicies with human-level performance. In this paper, we present a deep\nreinforcement learning framework to tackle this problem from the perspectives\nof both system and algorithm. Our system is of low coupling and high\nscalability, which enables efficient explorations at large scale. Our algorithm\nincludes several novel strategies, including control dependency decoupling,\naction mask, target attention, and dual-clip PPO, with which our proposed\nactor-critic network can be effectively trained in our system. Tested on the\nMOBA game Honor of Kings, our AI agent, called Tencent Solo, can defeat top\nprofessional human players in full 1v1 games.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 09:56:50 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 02:39:43 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 14:21:40 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Ye", "Deheng", ""], ["Liu", "Zhao", ""], ["Sun", "Mingfei", ""], ["Shi", "Bei", ""], ["Zhao", "Peilin", ""], ["Wu", "Hao", ""], ["Yu", "Hongsheng", ""], ["Yang", "Shaojie", ""], ["Wu", "Xipeng", ""], ["Guo", "Qingwei", ""], ["Chen", "Qiaobo", ""], ["Yin", "Yinyuting", ""], ["Zhang", "Hao", ""], ["Shi", "Tengfei", ""], ["Wang", "Liang", ""], ["Fu", "Qiang", ""], ["Yang", "Wei", ""], ["Huang", "Lanxiao", ""]]}, {"id": "1912.09881", "submitter": "Hong Zhu Prof.", "authors": "Hong Zhu, Ian Bayley, Dongmei Liu and Xiaoyu Zheng", "title": "Morphy: A Datamorphic Software Test Automation Tool", "comments": "This is a technical report on Morphy software testing tool", "journal-ref": null, "doi": null, "report-no": "Technical Report OBU-ECM-AFM-2019-01", "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an automated tool called Morphy for datamorphic testing.\nIt classifies software test artefacts into test entities and test morphisms,\nwhich are mappings on testing entities. In addition to datamorphisms,\nmetamorphisms and seed test case makers, Morphy also employs a set of other\ntest morphisms including test case metrics and filters, test set metrics and\nfilters, test result analysers and test executers to realise test automation.\nIn particular, basic testing activities can be automated by invoking test\nmorphisms. Test strategies can be realised as complex combinations of test\nmorphisms. Test processes can be automated by recording, editing and playing\ntest scripts that invoke test morphisms and strategies. Three types of test\nstrategies have been implemented in Morphy: datamorphism combination\nstrategies, cluster border exploration strategies and strategies for test set\noptimisation via genetic algorithms. This paper focuses on the datamorphism\ncombination strategies by giving their definitions and implementation\nalgorithms. The paper also illustrates their uses for testing both traditional\nsoftware and AI applications with three case studies.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 15:28:25 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Zhu", "Hong", ""], ["Bayley", "Ian", ""], ["Liu", "Dongmei", ""], ["Zheng", "Xiaoyu", ""]]}, {"id": "1912.09987", "submitter": "Daniel A Arag\\~ao", "authors": "Daniel Arag\\~ao Abreu Filho", "title": "Busca de melhor caminho entre m\\'ultiplas origens e m\\'ultiplos destinos\n  em redes complexas que representam cidades", "comments": "40 pages, in Portuguese, 21 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Was investigated in this paper the use of a search strategy in the problem of\nfinding the best path among multiple origins and multiple destinations. In this\nkind of problem, it must be decided within a lot of combinations which is the\nbest origin and the best destination, and also the best path between these two\nregions. One remarkable difficulty to answer this sort of problem is to perform\nthe search in a reduced time. This monography is a extension of previous\nresearch in which the problem described here was studied only in a bus network\nin the city of Fortaleza. This extension consisted of an exploration of the\nsearch strategy in graphs that represent public ways in cities like Fortaleza,\nMumbai and Tokyo. Using this strategy with a heuristic algorithm, Haversine\ndistance, was noticed that is possible to reduce substantially the time of the\nsearch, but introducing an error because of the loss of the admissible\ncharacteristic of the heuristic function applied.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 13:04:22 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Filho", "Daniel Arag\u00e3o Abreu", ""]]}, {"id": "1912.09996", "submitter": "Konrad Czechowski", "authors": "Piotr Mi{\\l}o\\'s, {\\L}ukasz Kuci\\'nski, Konrad Czechowski, Piotr\n  Kozakowski, Maciek Klimek", "title": "Uncertainty-sensitive Learning and Planning with Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a reinforcement learning framework for discrete environments in\nwhich an agent makes both strategic and tactical decisions. The former\nmanifests itself through the use of value function, while the latter is powered\nby a tree search planner. These tools complement each other. The planning\nmodule performs a local \\textit{what-if} analysis, which allows to avoid\ntactical pitfalls and boost backups of the value function. The value function,\nbeing global in nature, compensates for inherent locality of the planner. In\norder to further solidify this synergy, we introduce an exploration mechanism\nwith two distinctive components: uncertainty modelling and risk measurement. To\nmodel the uncertainty we use value function ensembles, and to reflect risk we\nuse propose several functionals that summarize the implied by the ensemble. We\nshow that our method performs well on hard exploration environments: Deep-sea,\ntoy Montezuma's Revenge, and Sokoban. In all the cases, we obtain speed-up in\nlearning and boost in performance.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 17:58:25 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 23:00:07 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 17:47:28 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Mi\u0142o\u015b", "Piotr", ""], ["Kuci\u0144ski", "\u0141ukasz", ""], ["Czechowski", "Konrad", ""], ["Kozakowski", "Piotr", ""], ["Klimek", "Maciek", ""]]}, {"id": "1912.10000", "submitter": "Luca Costabello", "authors": "Pedro Tabacof, Luca Costabello", "title": "Probability Calibration for Knowledge Graph Embedding Models", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding research has overlooked the problem of probability\ncalibration. We show popular embedding models are indeed uncalibrated. That\nmeans probability estimates associated to predicted triples are unreliable. We\npresent a novel method to calibrate a model when ground truth negatives are not\navailable, which is the usual case in knowledge graphs. We propose to use Platt\nscaling and isotonic regression alongside our method. Experiments on three\ndatasets with ground truth negatives show our contribution leads to\nwell-calibrated models when compared to the gold standard of using negatives.\nWe get significantly better results than the uncalibrated models from all\ncalibration methods. We show isotonic regression offers the best the\nperformance overall, not without trade-offs. We also show that calibrated\nmodels reach state-of-the-art accuracy without the need to define\nrelation-specific decision thresholds.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 18:31:33 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 10:38:54 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Tabacof", "Pedro", ""], ["Costabello", "Luca", ""]]}, {"id": "1912.10005", "submitter": "Holger Lyre", "authors": "Holger Lyre", "title": "Does AlphaGo actually play Go? Concerning the State Space of Artificial\n  Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overarching goal of this paper is to develop a general model of the state\nspace of AI. Given the breathtaking progress in AI research and technologies in\nrecent years, such conceptual work is of substantial theoretical interest. The\npresent AI hype is mainly driven by the triumph of deep learning neural\nnetworks. As the distinguishing feature of such networks is the ability to\nself-learn, self-learning is identified as one important dimension of the AI\nstate space. Another main dimension lies in the possibility to go over from\nspecific to more general types of problems. The third main dimension is\nprovided by semantic grounding. Since this is a philosophically complex and\ncontroversial dimension, a larger part of the paper is devoted to it. We take a\nfresh look at known foundational arguments in the philosophy of mind and\ncognition that are gaining new relevance in view of the recent AI developments\nincluding the blockhead objection, the Turing test, the symbol grounding\nproblem, the Chinese room argument, and general use-theoretic considerations of\nmeaning. Finally, the AI state space, spanned by the main dimensions\ngeneralization, grounding and \"selfx-ness\", possessing self-x properties such\nas self-learning, is outlined.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 23:35:18 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Lyre", "Holger", ""]]}, {"id": "1912.10084", "submitter": "Nuno Henriques", "authors": "Nuno A. C. Henriques, Helder Coelho, Leonel Garcia-Marques", "title": "SensAI+Expanse Adaptation on Human Behaviour Towards Emotional Valence\n  Prediction", "comments": "Accepted as regular paper in ADAPTIVE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An agent, artificial or human, must be continuously adjusting its behaviour\nin order to thrive in a more or less demanding environment. An artificial agent\nwith the ability to predict human emotional valence in a geospatial and\ntemporal context requires proper adaptation to its mobile device environment\nwith resource consumption strict restrictions (e.g., power from battery). The\ndeveloped distributed system includes a mobile device embodied agent (SensAI)\nplus Cloud-expanded (Expanse) cognition and memory resources. The system is\ndesigned with several adaptive mechanisms in a best effort for the agent to\ncope with its interacting humans and to be resilient on collecting data for\nmachine learning towards prediction. These mechanisms encompass\nhomeostatic-like adjustments such as auto recovering from an unexpected failure\nin the mobile device, forgetting repeated data to save local memory, adjusting\nactions to a proper moment (e.g., notify only when human is interacting), and\nthe Expanse complementary learning algorithms' parameters with auto\nadjustments. Regarding emotional valence prediction performance, results from a\ncomparison study between state-of-the-art algorithms revealed Extreme Gradient\nBoosting on average the best model for prediction with efficient energy use,\nand explainable using feature importance inspection. Therefore, this work\ncontributes with a smartphone sensing-based system, distributed in the Cloud,\nrobust to unexpected behaviours from humans and the environment, able to\npredict emotional valence states with very good performance.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 20:11:06 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 18:00:17 GMT"}, {"version": "v3", "created": "Mon, 6 Jan 2020 19:43:48 GMT"}, {"version": "v4", "created": "Sat, 7 Mar 2020 20:34:04 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Henriques", "Nuno A. C.", ""], ["Coelho", "Helder", ""], ["Garcia-Marques", "Leonel", ""]]}, {"id": "1912.10092", "submitter": "Jhonatan Souza Oliveira", "authors": "Cory J. Butz, Jhonatan S. Oliveira, Robert Peharz", "title": "Sum-Product Network Decompilation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exists a dichotomy between classical probabilistic graphical models,\nsuch as Bayesian networks (BNs), and modern tractable models, such as\nsum-product networks (SPNs). The former generally have intractable inference,\nbut provide a high level of interpretability, while the latter admits a wide\nrange of tractable inference routines, but are typically harder to interpret.\nDue to this dichotomy, tools to convert between BNs and SPNs are desirable.\nWhile one direction -- compiling BNs into SPNs -- is well discussed in\nDarwiche's seminal work on arithmetic circuit compilation, the converse\ndirection -- decompiling SPNs into BNs -- has received surprisingly little\nattention.\n  In this paper, we fill this gap by proposing SPN2BN, an algorithm that\ndecompiles an SPN into a BN. SPN2BN has several salient features when compared\nto the only other two works decompiling SPNs. Most significantly, the BNs\nreturned by SPN2BN are minimal independence-maps that are more parsimonious\nwith respect to the introduction of latent variables. Secondly, the output BN\nproduced by SPN2BN can be precisely characterized with respect to a compiled\nBN. More specifically, a certain set of directed edges will be added to the\ninput BN, giving what we will call the moral-closure. Lastly, it is established\nthat our compilation-decompilation process is idempotent. This has practical\nsignificance as it limits the size of the decompiled SPN.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 20:39:28 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 17:52:00 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Butz", "Cory J.", ""], ["Oliveira", "Jhonatan S.", ""], ["Peharz", "Robert", ""]]}, {"id": "1912.10113", "submitter": "In\\^es Louren\\c{c}o", "authors": "In\\^es Louren\\c{c}o, Bo Wahlberg, Rodrigo Ventura", "title": "Teaching robots to perceive time -- A reinforcement learning approach\n  (Extended version)", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time perception is the phenomenological experience of time by an individual.\nIn this paper, we study how to replicate neural mechanisms involved in time\nperception, allowing robots to take a step towards temporal cognition. Our\nframework follows a twofold biologically inspired approach. The first step\nconsists of estimating the passage of time from sensor measurements, since\nenvironmental stimuli influence the perception of time. Sensor data is modeled\nas Gaussian processes that represent the second-order statistics of the natural\nenvironment. The estimated elapsed time between two events is computed from the\nmaximum likelihood estimate of the joint distribution of the data collected\nbetween them. Moreover, exactly how time is encoded in the brain remains\nunknown, but there is strong evidence of the involvement of dopaminergic\nneurons in timing mechanisms. Since their phasic activity has a similar\nbehavior to the reward prediction error of temporal-difference learning models,\nthe latter are used to replicate this behavior. The second step of this\napproach consists therefore of applying the agent's estimate of the elapsed\ntime in a reinforcement learning problem, where a feature representation called\nMicrostimuli is used. We validate our framework by applying it to an experiment\nthat was originally conducted with mice, and conclude that a robot using this\nframework is able to reproduce the timing mechanisms of the animal's brain.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 21:41:38 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Louren\u00e7o", "In\u00eas", ""], ["Wahlberg", "Bo", ""], ["Ventura", "Rodrigo", ""]]}, {"id": "1912.10146", "submitter": "Sheng Li", "authors": "Sheng Li, Maxim Egorov and Mykel Kochenderfer", "title": "Optimizing Collision Avoidance in Dense Airspace using Deep\n  Reinforcement Learning", "comments": "Thirteenth USA/Europe Air Traffic Management Research and Development\n  Seminar", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New methodologies will be needed to ensure the airspace remains safe and\nefficient as traffic densities rise to accommodate new unmanned operations.\nThis paper explores how unmanned free-flight traffic may operate in dense\nairspace. We develop and analyze autonomous collision avoidance systems for\naircraft operating in dense airspace where traditional collision avoidance\nsystems fail. We propose a metric for quantifying the decision burden on a\ncollision avoidance system as well as a metric for measuring the impact of the\ncollision avoidance system on airspace. We use deep reinforcement learning to\ncompute corrections for an existing collision avoidance approach to account for\ndense airspace. The results show that a corrected collision avoidance system\ncan operate more efficiently than traditional methods in dense airspace while\nmaintaining high levels of safety.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 23:31:44 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Li", "Sheng", ""], ["Egorov", "Maxim", ""], ["Kochenderfer", "Mykel", ""]]}, {"id": "1912.10160", "submitter": "Gaurav Kumar", "authors": "Gaurav Kumar, Rishabh Joshi, Jaspreet Singh, Promod Yenigalla", "title": "AMUSED: A Multi-Stream Vector Representation Method for Use in Natural\n  Dialogue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of building a coherent and non-monotonous conversational agent\nwith proper discourse and coverage is still an area of open research. Current\narchitectures only take care of semantic and contextual information for a given\nquery and fail to completely account for syntactic and external knowledge which\nare crucial for generating responses in a chit-chat system. To overcome this\nproblem, we propose an end to end multi-stream deep learning architecture which\nlearns unified embeddings for query-response pairs by leveraging contextual\ninformation from memory networks and syntactic information by incorporating\nGraph Convolution Networks (GCN) over their dependency parse. A stream of this\nnetwork also utilizes transfer learning by pre-training a bidirectional\ntransformer to extract semantic representation for each input sentence and\nincorporates external knowledge through the the neighborhood of the entities\nfrom a Knowledge Base (KB). We benchmark these embeddings on next sentence\nprediction task and significantly improve upon the existing techniques.\nFurthermore, we use AMUSED to represent query and responses along with its\ncontext to develop a retrieval based conversational agent which has been\nvalidated by expert linguists to have comprehensive engagement with humans.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 17:35:03 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Kumar", "Gaurav", ""], ["Joshi", "Rishabh", ""], ["Singh", "Jaspreet", ""], ["Yenigalla", "Promod", ""]]}, {"id": "1912.10305", "submitter": "Jordan Ott", "authors": "Jordan Ott", "title": "Questions to Guide the Future of Artificial Intelligence Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of machine learning has focused, primarily, on discretized\nsub-problems (i.e. vision, speech, natural language) of intelligence. While\nneuroscience tends to be observation heavy, providing few guiding theories. It\nis unlikely that artificial intelligence will emerge through only one of these\ndisciplines. Instead, it is likely to be some amalgamation of their algorithmic\nand observational findings. As a result, there are a number of problems that\nshould be addressed in order to select the beneficial aspects of both fields.\nIn this article, we propose leading questions to guide the future of artificial\nintelligence research. There are clear computational principles on which the\nbrain operates. The problem is finding these computational needles in a\nhaystack of biological complexity. Biology has clear constraints but by not\nusing it as a guide we are constraining ourselves.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 17:48:31 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 15:31:34 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Ott", "Jordan", ""]]}, {"id": "1912.10389", "submitter": "Eun Seo Jo", "authors": "Eun Seo Jo, Timnit Gebru", "title": "Lessons from Archives: Strategies for Collecting Sociocultural Data in\n  Machine Learning", "comments": "To be published in Conference on Fairness, Accountability, and\n  Transparency FAT* '20, January 27-30, 2020, Barcelona, Spain. ACM, New York,\n  NY, USA, 11 pages", "journal-ref": null, "doi": "10.1145/3351095.3372829", "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing body of work shows that many problems in fairness, accountability,\ntransparency, and ethics in machine learning systems are rooted in decisions\nsurrounding the data collection and annotation process. In spite of its\nfundamental nature however, data collection remains an overlooked part of the\nmachine learning (ML) pipeline. In this paper, we argue that a new\nspecialization should be formed within ML that is focused on methodologies for\ndata collection and annotation: efforts that require institutional frameworks\nand procedures. Specifically for sociocultural data, parallels can be drawn\nfrom archives and libraries. Archives are the longest standing communal effort\nto gather human information and archive scholars have already developed the\nlanguage and procedures to address and discuss many challenges pertaining to\ndata collection such as consent, power, inclusivity, transparency, and ethics &\nprivacy. We discuss these five key approaches in document collection practices\nin archives that can inform data collection in sociocultural ML. By showing\ndata collection practices from another field, we encourage ML research to be\nmore cognizant and systematic in data collection and draw from\ninterdisciplinary expertise.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 05:56:55 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Jo", "Eun Seo", ""], ["Gebru", "Timnit", ""]]}, {"id": "1912.10445", "submitter": "Fabricio Olivetti de Franca", "authors": "Fabricio Olivetti de Franca, Denis Fantinato, Karine Miras, A.E.\n  Eiben, Patricia A. Vargas", "title": "EvoMan: Game-playing Competition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a competition proposal for evolving Intelligent Agents\nfor the game-playing framework called EvoMan. The framework is based on the\nboss fights of the game called Mega Man II developed by Capcom. For this\nparticular competition, the main goal is to beat all of the eight bosses using\na generalist strategy. In other words, the competitors should train the agent\nto beat a set of the bosses and then the agent will be evaluated by its\nperformance against all eight bosses. At the end of this paper, the competitors\nare provided with baseline results so that they can have an intuition on how\ngood their results are.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 13:30:41 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 14:39:10 GMT"}, {"version": "v3", "created": "Sat, 4 Jan 2020 14:24:55 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["de Franca", "Fabricio Olivetti", ""], ["Fantinato", "Denis", ""], ["Miras", "Karine", ""], ["Eiben", "A. E.", ""], ["Vargas", "Patricia A.", ""]]}, {"id": "1912.10490", "submitter": "Athanasios Davvetas", "authors": "Athanasios Davvetas and Iraklis A. Klampanos", "title": "Learning Improved Representations by Transferring Incomplete Evidence\n  Across Heterogeneous Tasks", "comments": "8 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquiring ground truth labels for unlabelled data can be a costly procedure,\nsince it often requires manual labour that is error-prone. Consequently, the\navailable amount of labelled data is increasingly reduced due to the\nlimitations of manual data labelling. It is possible to increase the amount of\nlabelled data samples by performing automated labelling or crowd-sourcing the\nannotation procedure. However, they often introduce noise or uncertainty in the\nlabelset, that leads to decreased performance of supervised deep learning\nmethods. On the other hand, weak supervision methods remain robust during noisy\nlabelsets or can be effective even with low amounts of labelled data. In this\npaper we evaluate the effectiveness of a representation learning method that\nuses external categorical evidence called \"Evidence Transfer\", against low\namount of corresponding evidence termed as incomplete evidence. Evidence\ntransfer is a robust solution against external unknown categorical evidence\nthat can introduce noise or uncertainty. In our experimental evaluation,\nevidence transfer proves to be effective and robust against different levels of\nincompleteness, for two types of incomplete evidence.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 17:44:24 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Davvetas", "Athanasios", ""], ["Klampanos", "Iraklis A.", ""]]}, {"id": "1912.10514", "submitter": "Idris Abdulmumin", "authors": "Idris Abdulmumin, Bashir Shehu Galadanci and Aliyu Garba", "title": "Tag-less Back-Translation", "comments": "29 pages, 4 figures, 13 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An effective method to generate a large number of parallel sentences for\ntraining improved neural machine translation (NMT) systems is the use of the\nback-translations of the target-side monolingual data. The standard\nback-translation method has been shown to be unable to efficiently utilize the\navailable huge amount of existing monolingual data because of the inability of\ntranslation models to differentiate between the authentic and synthetic\nparallel data during training. Tagging, or using gates, has been used to enable\ntranslation models to distinguish between synthetic and authentic data,\nimproving standard back-translation and also enabling the use of iterative\nback-translation on language pairs that underperformed using standard\nback-translation. In this work, we approach back-translation as a domain\nadaptation problem, eliminating the need for explicit tagging. In the approach\n-- \\emph{tag-less back-translation} -- the synthetic and authentic parallel\ndata are treated as out-of-domain and in-domain data respectively and, through\npre-training and fine-tuning, the translation model is shown to be able to\nlearn more efficiently from them during training. Experimental results have\nshown that the approach outperforms the standard and tagged back-translation\napproaches on low resource English-Vietnamese and English-German neural machine\ntranslation.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 19:20:10 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 09:07:53 GMT"}, {"version": "v3", "created": "Tue, 9 Feb 2021 15:53:24 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Abdulmumin", "Idris", ""], ["Galadanci", "Bashir Shehu", ""], ["Garba", "Aliyu", ""]]}, {"id": "1912.10515", "submitter": "Marlo Souza", "authors": "Marlo Souza, \\'Alvaro Moreira", "title": "Bringing Belief Base Change into Dynamic Epistemic Logic", "comments": "Published at DaLI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AGM's belief revision is one of the main paradigms in the study of belief\nchange operations. In this context, belief bases (prioritised bases) have been\nprimarily used to specify the agent's belief state. While the connection of\niterated AGM-like operations and their encoding in dynamic epistemic logics\nhave been studied before, few works considered how well-known postulates from\niterated belief revision theory can be characterised by means of belief bases\nand their counterpart in dynamic epistemic logic. Particularly, it has been\nshown that some postulates can be characterised through transformations in\npriority graphs, while others may not be represented that way. This work\ninvestigates changes in the semantics of Dynamic Preference Logic that give\nrise to an appropriate syntactic representation for its models that allow us to\nrepresent and reason about iterated belief base change in this logic.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 19:21:05 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Souza", "Marlo", ""], ["Moreira", "\u00c1lvaro", ""]]}, {"id": "1912.10564", "submitter": "Julia Stoyanovich", "authors": "Julia Stoyanovich and Armanda Lewis", "title": "Teaching Responsible Data Science: Charting New Pedagogical Territory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although numerous ethics courses are available, with many focusing\nspecifically on technology and computer ethics, pedagogical approaches employed\nin these courses rely exclusively on texts rather than on software development\nor data analysis. Technical students often consider these courses unimportant\nand a distraction from the \"real\" material. To develop instructional materials\nand methodologies that are thoughtful and engaging, we must strive for balance:\nbetween texts and coding, between critique and solution, and between\ncutting-edge research and practical applicability. Finding such balance is\nparticularly difficult in the nascent field of responsible data science (RDS),\nwhere we are only starting to understand how to interface between the\nintrinsically different methodologies of engineering and social sciences. In\nthis paper we recount a recent experience in developing and teaching an RDS\ncourse to graduate and advanced undergraduate students in data science. We then\ndive into an area that is critically important to RDS -- transparency and\ninterpretability of machine-assisted decision-making, and tie this area to the\nneeds of emerging RDS curricula. Recounting our own experience, and leveraging\nliterature on pedagogical methods in data science and beyond, we propose the\nnotion of an \"object-to-interpret-with\". We link this notion to \"nutritional\nlabels\" -- a family of interpretability tools that are gaining popularity in\nRDS research and practice. With this work we aim to contribute to the nascent\narea of RDS education, and to inspire others in the community to come together\nto develop a deeper theoretical understanding of the pedagogical needs of RDS,\nand contribute concrete educational materials and methodologies that others can\nuse. All course materials are publicly available at\nhttps://dataresponsibly.github.io/courses.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 00:10:22 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Stoyanovich", "Julia", ""], ["Lewis", "Armanda", ""]]}, {"id": "1912.10577", "submitter": "Zhihan Xiong", "authors": "Tian Tan, Zhihan Xiong, Vikranth R. Dwaracherla", "title": "Parameterized Indexed Value Function for Efficient Exploration in\n  Reinforcement Learning", "comments": "17 pages, 4 figures, Proceedings of the 34th AAAI Conference on\n  Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that quantifying uncertainty in the action-value estimates\nis crucial for efficient exploration in reinforcement learning. Ensemble\nsampling offers a relatively computationally tractable way of doing this using\nrandomized value functions. However, it still requires a huge amount of\ncomputational resources for complex problems. In this paper, we present an\nalternative, computationally efficient way to induce exploration using index\nsampling. We use an indexed value function to represent uncertainty in our\naction-value estimates. We first present an algorithm to learn parameterized\nindexed value function through a distributional version of temporal difference\nin a tabular setting and prove its regret bound. Then, in a computational point\nof view, we propose a dual-network architecture, Parameterized Indexed Networks\n(PINs), comprising one mean network and one uncertainty network to learn the\nindexed value function. Finally, we show the efficacy of PINs through\ncomputational experiments.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 01:28:53 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 18:33:52 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Tan", "Tian", ""], ["Xiong", "Zhihan", ""], ["Dwaracherla", "Vikranth R.", ""]]}, {"id": "1912.10600", "submitter": "Yang Guan", "authors": "Yang Guan, Shengbo Eben Li, Jingliang Duan, Jie Li, Yangang Ren, Qi\n  Sun, Bo Cheng", "title": "Direct and indirect reinforcement learning", "comments": "Published in International Journal of Intelligent Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms have been successfully applied to a\nrange of challenging sequential decision making and control tasks. In this\npaper, we classify RL into direct and indirect RL according to how they seek\nthe optimal policy of the Markov decision process problem. The former solves\nthe optimal policy by directly maximizing an objective function using gradient\ndescent methods, in which the objective function is usually the expectation of\naccumulative future rewards. The latter indirectly finds the optimal policy by\nsolving the Bellman equation, which is the sufficient and necessary condition\nfrom Bellman's principle of optimality. We study policy gradient forms of\ndirect and indirect RL and show that both of them can derive the actor-critic\narchitecture and can be unified into a policy gradient with the approximate\nvalue function and the stationary state distribution, revealing the equivalence\nof direct and indirect RL. We employ a Gridworld task to verify the influence\nof different forms of policy gradient, suggesting their differences and\nrelationships experimentally. Finally, we classify current mainstream RL\nalgorithms using the direct and indirect taxonomy, together with other ones\nincluding value-based and policy-based, model-based and model-free.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 03:20:42 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 12:14:44 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Guan", "Yang", ""], ["Li", "Shengbo Eben", ""], ["Duan", "Jingliang", ""], ["Li", "Jie", ""], ["Ren", "Yangang", ""], ["Sun", "Qi", ""], ["Cheng", "Bo", ""]]}, {"id": "1912.10648", "submitter": "Xiaobai Ma Mr.", "authors": "Xiaobai Ma, Katherine Driggs-Campbell, Zongzhang Zhang, Mykel J.\n  Kochenderfer", "title": "Monte-Carlo Tree Search for Policy Optimization", "comments": "IJCAI 2019", "journal-ref": "In Proceedings of the 28th International Joint Conference on\n  Artificial Intelligence, pp. 3116-3122. AAAI Press, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gradient-based methods are often used for policy optimization in deep\nreinforcement learning, despite being vulnerable to local optima and saddle\npoints. Although gradient-free methods (e.g., genetic algorithms or evolution\nstrategies) help mitigate these issues, poor initialization and local optima\nare still concerns in highly nonconvex spaces. This paper presents a method for\npolicy optimization based on Monte-Carlo tree search and gradient-free\noptimization. Our method, called Monte-Carlo tree search for policy\noptimization (MCTSPO), provides a better exploration-exploitation trade-off\nthrough the use of the upper confidence bound heuristic. We demonstrate\nimproved performance on reinforcement learning tasks with deceptive or sparse\nreward functions compared to popular gradient-based and deep genetic algorithm\nbaselines.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 07:04:24 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Ma", "Xiaobai", ""], ["Driggs-Campbell", "Katherine", ""], ["Zhang", "Zongzhang", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1912.10762", "submitter": "Wen Song", "authors": "Wen Song, Zhiguang Cao, Jie Zhang, Andrew Lim", "title": "Learning Variable Ordering Heuristics for Solving Constraint\n  Satisfaction Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backtracking search algorithms are often used to solve the Constraint\nSatisfaction Problem (CSP). The efficiency of backtracking search depends\ngreatly on the variable ordering heuristics. Currently, the most commonly used\nheuristics are hand-crafted based on expert knowledge. In this paper, we\npropose a deep reinforcement learning based approach to automatically discover\nnew variable ordering heuristics that are better adapted for a given class of\nCSP instances. We show that directly optimizing the search cost is hard for\nbootstrapping, and propose to optimize the expected cost of reaching a leaf\nnode in the search tree. To capture the complex relations among the variables\nand constraints, we design a representation scheme based on Graph Neural\nNetwork that can process CSP instances with different sizes and constraint\narities. Experimental results on random CSP instances show that the learned\npolicies outperform classical hand-crafted heuristics in terms of minimizing\nthe search tree size, and can effectively generalize to instances that are\nlarger than those used in training.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 12:27:04 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 06:45:31 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Song", "Wen", ""], ["Cao", "Zhiguang", ""], ["Zhang", "Jie", ""], ["Lim", "Andrew", ""]]}, {"id": "1912.10815", "submitter": "Mateusz Dorobek B.S", "authors": "Mateusz Dorobek", "title": "Wykorzystanie sztucznej inteligencji do generowania tre\\'sci muzycznych", "comments": "Bachelor Thesis, in Polish", "journal-ref": null, "doi": "10.13140/RG.2.2.23824.66564", "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis is presenting a method for generating short musical phrases using\na deep convolutional generative adversarial network (DCGAN). To train neural\nnetwork were used datasets of classical and jazz music MIDI recordings. Our\napproach introduces translating the MIDI data into graphical images in a piano\nroll format suitable for the network input size, using the RGB channels as\nadditional information carriers for improved performance. The network has\nlearned to generate images that are indistinguishable from the input data and,\nwhen translated back to MIDI and played back, include several musically\ninteresting rhythmic and harmonic structures. The results of the conducted\nexperiments are described and discussed, with conclusions for further work and\na short comparison with selected existing solutions.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 02:48:16 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Dorobek", "Mateusz", ""]]}, {"id": "1912.10818", "submitter": "Daniel Acuna", "authors": "Lizhen Liang and Daniel E. Acuna", "title": "Artificial mental phenomena: Psychophysics as a framework to detect\n  perception biases in AI models", "comments": "FAT Conference 2020", "journal-ref": null, "doi": "10.1145/3351095.3375623", "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting biases in artificial intelligence has become difficult because of\nthe impenetrable nature of deep learning. The central difficulty is in relating\nunobservable phenomena deep inside models with observable, outside quantities\nthat we can measure from inputs and outputs. For example, can we detect\ngendered perceptions of occupations (e.g., female librarian, male electrician)\nusing questions to and answers from a word embedding-based system? Current\ntechniques for detecting biases are often customized for a task, dataset, or\nmethod, affecting their generalization. In this work, we draw from\nPsychophysics in Experimental Psychology---meant to relate quantities from the\nreal world (i.e., \"Physics\") into subjective measures in the mind (i.e.,\n\"Psyche\")---to propose an intellectually coherent and generalizable framework\nto detect biases in AI. Specifically, we adapt the two-alternative forced\nchoice task (2AFC) to estimate potential biases and the strength of those\nbiases in black-box models. We successfully reproduce previously-known biased\nperceptions in word embeddings and sentiment analysis predictions. We discuss\nhow concepts in experimental psychology can be naturally applied to\nunderstanding artificial mental phenomena, and how psychophysics can form a\nuseful methodological foundation to study fairness in AI.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 19:48:48 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Liang", "Lizhen", ""], ["Acuna", "Daniel E.", ""]]}, {"id": "1912.10891", "submitter": "Xinyang Gu", "authors": "Jingbin Liu, Shuai Liu, Xinyang Gu", "title": "Soft Q Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Q Network (DQN) is a very successful algorithm, yet the inherent problem\nof reinforcement learning, i.e. the exploit-explore balance, remains. In this\nwork, we introduce entropy regularization into DQN and propose SQN. We find\nthat the backup equation of soft Q learning can enjoy the corrective feedback\nif we view the soft backup as policy improvement in the form of Q, instead of\npolicy evaluation. We show that Soft Q Learning with Corrective Feedback\n(SQL-CF) underlies the on-plicy nature of SQL and the equivalence of SQL and\nSoft Policy Gradient (SPG). With these insights, we propose an on-policy\nversion of deep Q learning algorithm, i.e. Q On-Policy (QOP). We experiment\nwith QOP on a self-play environment called Google Research Football (GRF). The\nQOP algorithm exhibits great stability and efficiency in training GRF agents.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 01:55:40 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 08:12:57 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Liu", "Jingbin", ""], ["Liu", "Shuai", ""], ["Gu", "Xinyang", ""]]}, {"id": "1912.10944", "submitter": "Kun Shao", "authors": "Kun Shao, Zhentao Tang, Yuanheng Zhu, Nannan Li, Dongbin Zhao", "title": "A Survey of Deep Reinforcement Learning in Video Games", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has made great achievements since proposed.\nGenerally, DRL agents receive high-dimensional inputs at each step, and make\nactions according to deep-neural-network-based policies. This learning\nmechanism updates the policy to maximize the return with an end-to-end method.\nIn this paper, we survey the progress of DRL methods, including value-based,\npolicy gradient, and model-based algorithms, and compare their main techniques\nand properties. Besides, DRL plays an important role in game artificial\nintelligence (AI). We also take a review of the achievements of DRL in various\nvideo games, including classical Arcade games, first-person perspective games\nand multi-agent real-time strategy games, from 2D to 3D, and from single-agent\nto multi-agent. A large number of video game AIs with DRL have achieved\nsuper-human performance, while there are still some challenges in this domain.\nTherefore, we also discuss some key points when applying DRL methods to this\nfield, including exploration-exploitation, sample efficiency, generalization\nand transfer, multi-agent learning, imperfect information, and delayed spare\nrewards, as well as some research directions.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 16:04:40 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 14:47:34 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Shao", "Kun", ""], ["Tang", "Zhentao", ""], ["Zhu", "Yuanheng", ""], ["Li", "Nannan", ""], ["Zhao", "Dongbin", ""]]}, {"id": "1912.10986", "submitter": "Thanh Pham Dinh", "authors": "Tran Ba Trung and Huynh Thi Thanh Binh and Le Tien Thanh and Ly Trung\n  Hieu and Pham Dinh Thanh", "title": "Multifactorial Evolutionary Algorithm For Clustered Minimum Routing Cost\n  Problem", "comments": null, "journal-ref": null, "doi": "10.1145/3368926.3369712", "report-no": null, "categories": "cs.NE cs.AI cs.DM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Minimum Routing Cost Clustered Tree Problem (CluMRCT) is applied in various\nfields in both theory and application. Because the CluMRCT is NP-Hard, the\napproximate approaches are suitable to find the solution for this problem.\nRecently, Multifactorial Evolutionary Algorithm (MFEA) has emerged as one of\nthe most efficient approximation algorithms to deal with many different kinds\nof problems. Therefore, this paper studies to apply MFEA for solving CluMRCT\nproblems. In the proposed MFEA, we focus on crossover and mutation operators\nwhich create a valid solution of CluMRCT problem in two levels: first level\nconstructs spanning trees for graphs in clusters while the second level builds\na spanning tree for connecting among clusters. To reduce the consuming\nresources, we will also introduce a new method of calculating the cost of\nCluMRCT solution. The proposed algorithm is experimented on numerous types of\ndatasets. The experimental results demonstrate the effectiveness of the\nproposed algorithm, partially on large instances\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 17:27:22 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Trung", "Tran Ba", ""], ["Binh", "Huynh Thi Thanh", ""], ["Thanh", "Le Tien", ""], ["Hieu", "Ly Trung", ""], ["Thanh", "Pham Dinh", ""]]}, {"id": "1912.11032", "submitter": "Richard Li", "authors": "Richard Li, Allan Jabri, Trevor Darrell, Pulkit Agrawal", "title": "Towards Practical Multi-Object Manipulation using Relational\n  Reinforcement Learning", "comments": "10 pages, 4 figures and 1 table in main article, 3 figures and 3\n  tables in appendix. Supplementary website and videos at\n  https://richardrl.github.io/relational-rl/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning robotic manipulation tasks using reinforcement learning with sparse\nrewards is currently impractical due to the outrageous data requirements. Many\npractical tasks require manipulation of multiple objects, and the complexity of\nsuch tasks increases with the number of objects. Learning from a curriculum of\nincreasingly complex tasks appears to be a natural solution, but unfortunately,\ndoes not work for many scenarios. We hypothesize that the inability of the\nstate-of-the-art algorithms to effectively utilize a task curriculum stems from\nthe absence of inductive biases for transferring knowledge from simpler to\ncomplex tasks. We show that graph-based relational architectures overcome this\nlimitation and enable learning of complex tasks when provided with a simple\ncurriculum of tasks with increasing numbers of objects. We demonstrate the\nutility of our framework on a simulated block stacking task. Starting from\nscratch, our agent learns to stack six blocks into a tower. Despite using\nstep-wise sparse rewards, our method is orders of magnitude more data-efficient\nand outperforms the existing state-of-the-art method that utilizes human\ndemonstrations. Furthermore, the learned policy exhibits zero-shot\ngeneralization, successfully stacking blocks into taller towers and previously\nunseen configurations such as pyramids, without any further training.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 18:56:42 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Li", "Richard", ""], ["Jabri", "Allan", ""], ["Darrell", "Trevor", ""], ["Agrawal", "Pulkit", ""]]}, {"id": "1912.11038", "submitter": "Christophe Demko", "authors": "Christophe Demko and Karell Bertet and Cyril Faucher and\n  Jean-Fran\\c{c}ois Viaud and Serge\\\"i Kuznetsov", "title": "Next Priority Concept: A new and generic algorithm computing concepts\n  from complex and heterogeneous data", "comments": "28 pages, 8 figures, 7 algorithms", "journal-ref": null, "doi": "10.1016/j.tcs.2020.08.026", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we present a new data type agnostic algorithm calculating a\nconcept lattice from heterogeneous and complex data. Our NextPriorityConcept\nalgorithm is first introduced and proved in the binary case as an extension of\nBordat's algorithm with the notion of strategies to select only some\npredecessors of each concept, avoiding the generation of unreasonably large\nlattices. The algorithm is then extended to any type of data in a generic way.\nIt is inspired from pattern structure theory, where data are locally described\nby predicates independent of their types, allowing the management of\nheterogeneous data.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 19:55:39 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Demko", "Christophe", ""], ["Bertet", "Karell", ""], ["Faucher", "Cyril", ""], ["Viaud", "Jean-Fran\u00e7ois", ""], ["Kuznetsov", "Serge\u00ef", ""]]}, {"id": "1912.11077", "submitter": "Olivier Delalleau", "authors": "Olivier Delalleau, Maxim Peter, Eloi Alonso, Adrien Logut", "title": "Discrete and Continuous Action Representation for Practical RL in Video\n  Games", "comments": "Presented at the AAAI-20 Workshop on Reinforcement Learning in Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most current research in Reinforcement Learning (RL) focuses on\nimproving the performance of the algorithms in controlled environments, the use\nof RL under constraints like those met in the video game industry is rarely\nstudied. Operating under such constraints, we propose Hybrid SAC, an extension\nof the Soft Actor-Critic algorithm able to handle discrete, continuous and\nparameterized actions in a principled way. We show that Hybrid SAC can\nsuccessfully solve a highspeed driving task in one of our games, and is\ncompetitive with the state-of-the-art on parameterized actions benchmark tasks.\nWe also explore the impact of using normalizing flows to enrich the\nexpressiveness of the policy at minimal computational cost, and identify a\npotential undesired effect of SAC when used with normalizing flows, that may be\naddressed by optimizing a different objective.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 19:37:13 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Delalleau", "Olivier", ""], ["Peter", "Maxim", ""], ["Alonso", "Eloi", ""], ["Logut", "Adrien", ""]]}, {"id": "1912.11078", "submitter": "Deven Santosh Shah", "authors": "Deven Shah, H. Andrew Schwartz, Dirk Hovy", "title": "Predictive Biases in Natural Language Processing Models: A Conceptual\n  Framework and Overview", "comments": "9 pages excluding references, 1 figure, 3 pages for appendix", "journal-ref": "Association for Computational Linguistics. (2020) 5248--5264", "doi": "10.18653/v1/2020.acl-main.468", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of works in natural language processing have addressed\nthe effect of bias on the predicted outcomes, introducing mitigation techniques\nthat act on different parts of the standard NLP pipeline (data and models).\nHowever, these works have been conducted in isolation, without a unifying\nframework to organize efforts within the field. This leads to repetitive\napproaches, and puts an undue focus on the effects of bias, rather than on\ntheir origins. Research focused on bias symptoms rather than the underlying\norigins could limit the development of effective countermeasures. In this\npaper, we propose a unifying conceptualization: the predictive bias framework\nfor NLP. We summarize the NLP literature and propose a general mathematical\ndefinition of predictive bias in NLP along with a conceptual framework,\ndifferentiating four main origins of biases: label bias, selection bias, model\noveramplification, and semantic bias. We discuss how past work has countered\neach bias origin. Our framework serves to guide an introductory overview of\npredictive bias in NLP, integrating existing work into a single structure and\nopening avenues for future research.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 23:53:19 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 19:56:10 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Shah", "Deven", ""], ["Schwartz", "H. Andrew", ""], ["Hovy", "Dirk", ""]]}, {"id": "1912.11095", "submitter": "P. M. Krafft", "authors": "P. M. Krafft, Meg Young, Michael Katell, Karen Huang, Ghislain Bugingo", "title": "Defining AI in Policy versus Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent concern about harms of information technologies motivate consideration\nof regulatory action to forestall or constrain certain developments in the\nfield of artificial intelligence (AI). However, definitional ambiguity hampers\nthe possibility of conversation about this urgent topic of public concern.\nLegal and regulatory interventions require agreed-upon definitions, but\nconsensus around a definition of AI has been elusive, especially in policy\nconversations. With an eye towards practical working definitions and a broader\nunderstanding of positions on these issues, we survey experts and review\npublished policy documents to examine researcher and policy-maker conceptions\nof AI. We find that while AI researchers favor definitions of AI that emphasize\ntechnical functionality, policy-makers instead use definitions that compare\nsystems to human thinking and behavior. We point out that definitions adhering\nclosely to the functionality of AI systems are more inclusive of technologies\nin use today, whereas definitions that emphasize human-like capabilities are\nmost applicable to hypothetical future technologies. As a result of this gap,\nethical and regulatory efforts may overemphasize concern about future\ntechnologies at the expense of pressing issues with existing deployed\ntechnologies.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 20:18:21 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Krafft", "P. M.", ""], ["Young", "Meg", ""], ["Katell", "Michael", ""], ["Huang", "Karen", ""], ["Bugingo", "Ghislain", ""]]}, {"id": "1912.11187", "submitter": "Yan Kang", "authors": "Yang Liu, Yan Kang, Xinwei Zhang, Liping Li, Yong Cheng, Tianjian\n  Chen, Mingyi Hong, Qiang Yang", "title": "A Communication Efficient Collaborative Learning Framework for\n  Distributed Features", "comments": "This paper is published at the 2nd International Workshop on\n  Federated Learning for Data Privacy and Confidentiality, in Conjunction with\n  NeurIPS 2019 (FL-NeurIPS 19):\n  https://nips.cc/Conferences/2019/ScheduleMultitrack?event=13202", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a collaborative learning framework allowing multiple parties\nhaving different sets of attributes about the same user to jointly build models\nwithout exposing their raw data or model parameters. In particular, we propose\na Federated Stochastic Block Coordinate Descent (FedBCD) algorithm, in which\neach party conducts multiple local updates before each communication to\neffectively reduce the number of communication rounds among parties, a\nprincipal bottleneck for collaborative learning problems. We analyze\ntheoretically the impact of the number of local updates and show that when the\nbatch size, sample size, and the local iterations are selected appropriately,\nwithin $T$ iterations, the algorithm performs $\\mathcal{O}(\\sqrt{T})$\ncommunication rounds and achieves some $\\mathcal{O}(1/\\sqrt{T})$ accuracy\n(measured by the average of the gradient norm squared). The approach is\nsupported by our empirical evaluations on a variety of tasks and datasets,\ndemonstrating advantages over stochastic gradient descent (SGD) approaches.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 03:08:55 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 05:53:13 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2020 05:27:34 GMT"}, {"version": "v4", "created": "Mon, 22 Jun 2020 02:37:02 GMT"}, {"version": "v5", "created": "Wed, 24 Jun 2020 05:51:41 GMT"}, {"version": "v6", "created": "Fri, 31 Jul 2020 13:28:34 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Liu", "Yang", ""], ["Kang", "Yan", ""], ["Zhang", "Xinwei", ""], ["Li", "Liping", ""], ["Cheng", "Yong", ""], ["Chen", "Tianjian", ""], ["Hong", "Mingyi", ""], ["Yang", "Qiang", ""]]}, {"id": "1912.11203", "submitter": "Sasha Rubin", "authors": "Benjamin Aminof and Giuseppe De Giacomo and Sasha Rubin", "title": "Stochastic Fairness and Language-Theoretic Fairness in Planning on\n  Nondeterministic Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address two central notions of fairness in the literature of planning on\nnondeterministic fully observable domains. The first, which we call stochastic\nfairness, is classical, and assumes an environment which operates\nprobabilistically using possibly unknown probabilities. The second, which is\nlanguage-theoretic, assumes that if an action is taken from a given state\ninfinitely often then all its possible outcomes should appear infinitely often\n(we call this state-action fairness). While the two notions coincide for\nstandard reachability goals, they diverge for temporally extended goals. This\nimportant difference has been overlooked in the planning literature, and we\nargue has led to confusion in a number of published algorithms which use\nreductions that were stated for state-action fairness, for which they are\nincorrect, while being correct for stochastic fairness. We remedy this and\nprovide an optimal sound and complete algorithm for solving state-action fair\nplanning for LTL/LTLf goals, as well as a correct proof of the lower bound of\nthe goal-complexity (our proof is general enough that it provides new proofs\nalso for the no-fairness and stochastic-fairness cases). Overall, we show that\nstochastic fairness is better behaved than state-action fairness.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 04:35:33 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Aminof", "Benjamin", ""], ["De Giacomo", "Giuseppe", ""], ["Rubin", "Sasha", ""]]}, {"id": "1912.11308", "submitter": "Frederik Gossen", "authors": "Frederik Gossen, Alnis Murtovi, Philip Zweihoff, Bernhard Steffen", "title": "ADD-Lib: Decision Diagrams in Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper, we present the ADD-Lib, our efficient and easy to use framework\nfor Algebraic Decision Diagrams (ADDs). The focus of the ADD-Lib is not so much\non its efficient implementation of individual operations, which are taken by\nother established ADD frameworks, but its ease and flexibility, which arise at\ntwo levels: the level of individual ADD-tools, which come with a dedicated\nuser-friendly web-based graphical user interface, and at the meta level, where\nsuch tools are specified. Both levels are described in the paper: the meta\nlevel by explaining how we can construct an ADD-tool tailored for Random Forest\nrefinement and evaluation, and the accordingly generated Web-based\ndomain-specific tool, which we also provide as an artifact for cooperative\nexperimentation. In particular, the artifact allows readers to combine a given\nRandom Forest with their own ADDs regarded as expert knowledge and to\nexperience the corresponding effect.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 12:11:00 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Gossen", "Frederik", ""], ["Murtovi", "Alnis", ""], ["Zweihoff", "Philip", ""], ["Steffen", "Bernhard", ""]]}, {"id": "1912.11323", "submitter": "Gal Cohensius", "authors": "Gal Cohensius, Reshef Meir, Nadav Oved and Roni Stern", "title": "Bidding in Spades", "comments": "13 pages, 7 figures, to be published in ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Spades bidding algorithm that is superior to recreational human\nplayers and to publicly available bots. Like in Bridge, the game of Spades is\ncomposed of two independent phases, \\textit{bidding} and \\textit{playing}. This\npaper focuses on the bidding algorithm, since this phase holds a precise\nchallenge: based on the input, choose the bid that maximizes the agent's\nwinning probability. Our \\emph{Bidding-in-Spades} (BIS) algorithm heuristically\ndetermines the bidding strategy by comparing the expected utility of each\npossible bid. A major challenge is how to estimate these expected utilities. To\nthis end, we propose a set of domain-specific heuristics, and then correct them\nvia machine learning using data from real-world players. The \\BIS algorithm we\npresent can be attached to any playing algorithm. It beats rule-based bidding\nbots when all use the same playing component. When combined with a rule-based\nplaying algorithm, it is superior to the average recreational human.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 12:49:53 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 13:45:27 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Cohensius", "Gal", ""], ["Meir", "Reshef", ""], ["Oved", "Nadav", ""], ["Stern", "Roni", ""]]}, {"id": "1912.11462", "submitter": "Thibaut Vidal", "authors": "Florian Arnold, \\'Italo Santana, Kenneth S\\\"orensen, Thibaut Vidal", "title": "PILS: Exploring high-order neighborhoods by pattern mining and injection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce pattern injection local search (PILS), an optimization strategy\nthat uses pattern mining to explore high-order local-search neighborhoods, and\nillustrate its application on the vehicle routing problem. PILS operates by\nstoring a limited number of frequent patterns from elite solutions. During the\nlocal search, each pattern is used to define one move in which 1) incompatible\nedges are disconnected, 2) the edges defined by the pattern are reconnected,\nand 3) the remaining solution fragments are optimally reconnected. Each such\nmove is accepted only in case of solution improvement. As visible in our\nexperiments, this strategy results in a new paradigm of local search, which\ncomplements and enhances classical search approaches in a controllable amount\nof computational time. We demonstrate that PILS identifies useful high-order\nmoves (e.g., 9-opt and 10-opt) which would otherwise not be found by\nenumeration, and that it significantly improves the performance of\nstate-of-the-art population-based and neighborhood-centered metaheuristics.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 18:36:07 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Arnold", "Florian", ""], ["Santana", "\u00cdtalo", ""], ["S\u00f6rensen", "Kenneth", ""], ["Vidal", "Thibaut", ""]]}, {"id": "1912.11531", "submitter": "Luca Pasqualini", "authors": "Luca Pasqualini, Maurizio Parton", "title": "Pseudo Random Number Generation: a Reinforcement Learning approach", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pseudo-Random Numbers Generators (PRNGs) are algorithms produced to generate\nlong sequences of statistically uncorrelated numbers, i.e. Pseudo-Random\nNumbers (PRNs). These numbers are widely employed in mid-level cryptography and\nin software applications. Test suites are used to evaluate PRNGs quality by\nchecking statistical properties of the generated sequences. Machine learning\ntechniques are often used to break these generators, for instance approximating\na certain generator or a certain sequence using a neural network. But what\nabout using machine learning to generate PRNs generators? This paper proposes a\nReinforcement Learning (RL) approach to the task of generating PRNGs from\nscratch by learning a policy to solve an N-dimensional navigation problem. In\nthis context, N is the length of the period of the generated sequence, and the\npolicy is iteratively improved using the average value of an appropriate test\nsuite run over that period. Aim of this work is to demonstrate the feasibility\nof the proposed approach, to compare it with classical methods, and to lay the\nfoundation of a research path which combines RL and PRNGs.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 13:32:07 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Pasqualini", "Luca", ""], ["Parton", "Maurizio", ""]]}, {"id": "1912.11533", "submitter": "Fl\\'avio Jos\\'e Mendes Coelho", "authors": "Fl\\'avio Jos\\'e Mendes Coelho", "title": "Estudo comparativo de meta-heur\\'isticas para problemas de\n  colora\\c{c}\\~oes de grafos", "comments": "in Portuguese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A classic graph coloring problem is to assign colors to vertices of any graph\nso that distinct colors are assigned to adjacent vertices. Optimal graph\ncoloring colors a graph with a minimum number of colors, which is its chromatic\nnumber. Finding out the chromatic number is a combinatorial optimization\nproblem proven to be computationally intractable, which implies that no\nalgorithm that computes large instances of the problem in a reasonable time is\nknown. For this reason, approximate methods and metaheuristics form a set of\ntechniques that do not guarantee optimality but obtain good solutions in a\nreasonable time. This paper reports a comparative study of the Hill-Climbing,\nSimulated Annealing, Tabu Search, and Iterated Local Search metaheuristics for\nthe classic graph coloring problem considering its time efficiency for\nprocessing the DSJC125 and DSJC250 instances of the DIMACS benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 22:46:23 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Coelho", "Fl\u00e1vio Jos\u00e9 Mendes", ""]]}, {"id": "1912.11554", "submitter": "Neeraj Pradhan", "authors": "Du Phan, Neeraj Pradhan, Martin Jankowiak", "title": "Composable Effects for Flexible and Accelerated Probabilistic\n  Programming in NumPyro", "comments": "10 pages, 2 figures; NeurIPS 2019 Program Transformations for Machine\n  Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NumPyro is a lightweight library that provides an alternate NumPy backend to\nthe Pyro probabilistic programming language with the same modeling interface,\nlanguage primitives and effect handling abstractions. Effect handlers allow\nPyro's modeling API to be extended to NumPyro despite its being built atop a\nfundamentally different JAX-based functional backend. In this work, we\ndemonstrate the power of composing Pyro's effect handlers with the program\ntransformations that enable hardware acceleration, automatic differentiation,\nand vectorization in JAX. In particular, NumPyro provides an iterative\nformulation of the No-U-Turn Sampler (NUTS) that can be end-to-end JIT\ncompiled, yielding an implementation that is much faster than existing\nalternatives in both the small and large dataset regimes.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 22:09:36 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Phan", "Du", ""], ["Pradhan", "Neeraj", ""], ["Jankowiak", "Martin", ""]]}, {"id": "1912.11580", "submitter": "Muhammad Usman", "authors": "Muhammad Usman, Wenxi Wang, Kaiyuan Wang, Marko Vasic, Haris Vikalo,\n  Sarfraz Khurshid", "title": "A Study of the Learnability of Relational Properties: Model Counting\n  Meets Machine Learning (MCML)", "comments": null, "journal-ref": null, "doi": "10.1145/3385412.3386015", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the MCML approach for empirically studying the\nlearnability of relational properties that can be expressed in the well-known\nsoftware design language Alloy. A key novelty of MCML is quantification of the\nperformance of and semantic differences among trained machine learning (ML)\nmodels, specifically decision trees, with respect to entire (bounded) input\nspaces, and not just for given training and test datasets (as is the common\npractice). MCML reduces the quantification problems to the classic complexity\ntheory problem of model counting, and employs state-of-the-art model counters.\nThe results show that relatively simple ML models can achieve surprisingly high\nperformance (accuracy and F1-score) when evaluated in the common setting of\nusing training and test datasets - even when the training dataset is much\nsmaller than the test dataset - indicating the seeming simplicity of learning\nrelational properties. However, MCML metrics based on model counting show that\nthe performance can degrade substantially when tested against the entire\n(bounded) input space, indicating the high complexity of precisely learning\nthese properties, and the usefulness of model counting in quantifying the true\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 02:44:13 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 02:14:51 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Usman", "Muhammad", ""], ["Wang", "Wenxi", ""], ["Wang", "Kaiyuan", ""], ["Vasic", "Marko", ""], ["Vikalo", "Haris", ""], ["Khurshid", "Sarfraz", ""]]}, {"id": "1912.11595", "submitter": "Cullen O'Keefe", "authors": "Cullen O'Keefe, Peter Cihon, Ben Garfinkel, Carrick Flynn, Jade Leung,\n  Allan Dafoe", "title": "The Windfall Clause: Distributing the Benefits of AI for the Common Good", "comments": "Short version to be published in proceedings of AIES", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the transformative potential of AI has become increasingly salient as a\nmatter of public and political interest, there has been growing discussion\nabout the need to ensure that AI broadly benefits humanity. This in turn has\nspurred debate on the social responsibilities of large technology companies to\nserve the interests of society at large. In response, ethical principles and\ncodes of conduct have been proposed to meet the escalating demand for this\nresponsibility to be taken seriously. As yet, however, few institutional\ninnovations have been suggested to translate this responsibility into legal\ncommitments which apply to companies positioned to reap large financial gains\nfrom the development and use of AI. This paper offers one potentially\nattractive tool for addressing such issues: the Windfall Clause, which is an ex\nante commitment by AI firms to donate a significant amount of any eventual\nextremely large profits. By this we mean an early commitment that profits that\na firm could not earn without achieving fundamental, economically\ntransformative breakthroughs in AI capabilities will be donated to benefit\nhumanity broadly, with particular attention towards mitigating any downsides\nfrom deployment of windfall-generating AI.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 05:30:40 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 18:43:43 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["O'Keefe", "Cullen", ""], ["Cihon", "Peter", ""], ["Garfinkel", "Ben", ""], ["Flynn", "Carrick", ""], ["Leung", "Jade", ""], ["Dafoe", "Allan", ""]]}, {"id": "1912.11599", "submitter": "Zhenzhen Gu", "authors": "Zhenzhen Gu, Cungen Cao, Ya Wang and Yuefei Sui", "title": "A Logical Model for Supporting Social Commonsense Knowledge Acquisition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To make machine exhibit human-like abilities in the domains like robotics and\nconversation, social commonsense knowledge (SCK), i.e., common sense about\nsocial contexts and social roles, is absolutely necessarily. Therefor, our\nultimate goal is to acquire large-scale SCK to support much more intelligent\napplications. Before that, we need to know clearly what is SCK and how to\nrepresent it, since automatic information processing requires data and\nknowledge are organized in structured and semantically related ways. For this\nreason, in this paper, we identify and formalize three basic types of SCK based\non first-order theory. Firstly, we identify and formalize the\ninterrelationships, such as having-role and having-social_relation, among\nsocial contexts, roles and players from the perspective of considering both\ncontexts and roles as first-order citizens and not generating role instances.\nSecondly, we provide a four level structure to identify and formalize the\nintrinsic information, such as events and desires, of social contexts, roles\nand players, and illustrate the way of harvesting the intrinsic information of\nsocial contexts and roles from the exhibition of players in concrete contexts.\nAnd thirdly, enlightened by some observations of actual contexts, we further\nintroduce and formalize the embedding of social contexts, and depict the way of\nexcavating the intrinsic information of social contexts and roles from the\nembedded smaller and simpler contexts. The results of this paper lay the\nfoundation not only for formalizing much more complex SCK but also for\nacquiring these three basic types of SCK.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 05:50:20 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Gu", "Zhenzhen", ""], ["Cao", "Cungen", ""], ["Wang", "Ya", ""], ["Sui", "Yuefei", ""]]}, {"id": "1912.11668", "submitter": "Jianhao Shen", "authors": "Yikai Zhu, Jianhao Shen, Ming Zhang", "title": "Learning to Answer Ambiguous Questions with Knowledge Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the task of factoid question answering over knowledge base, many questions\nhave more than one plausible interpretation. Previous works on SimpleQuestions\nassume only one interpretation as the ground truth for each question, so they\nlack the ability to answer ambiguous questions correctly. In this paper, we\npresent a new way to utilize the dataset that takes into account the existence\nof ambiguous questions. Then we introduce a simple and effective model which\ncombines local knowledge subgraph with attention mechanism. Our experimental\nresults show that our approach achieves outstanding performance in this task.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 13:43:44 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Zhu", "Yikai", ""], ["Shen", "Jianhao", ""], ["Zhang", "Ming", ""]]}, {"id": "1912.11739", "submitter": "Haiyue Song", "authors": "Haiyue Song, Raj Dabre, Atsushi Fujita, Sadao Kurohashi", "title": "Coursera Corpus Mining and Multistage Fine-Tuning for Improving Lectures\n  Translation", "comments": "10 pages, 1 figure, 9 tables, under review by LREC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lectures translation is a case of spoken language translation and there is a\nlack of publicly available parallel corpora for this purpose. To address this,\nwe examine a language independent framework for parallel corpus mining which is\na quick and effective way to mine a parallel corpus from publicly available\nlectures at Coursera. Our approach determines sentence alignments, relying on\nmachine translation and cosine similarity over continuous-space sentence\nrepresentations. We also show how to use the resulting corpora in a multistage\nfine-tuning based domain adaptation for high-quality lectures translation. For\nJapanese--English lectures translation, we extracted parallel data of\napproximately 40,000 lines and created development and test sets through manual\nfiltering for benchmarking translation performance. We demonstrate that the\nmined corpus greatly enhances the quality of translation when used in\nconjunction with out-of-domain parallel corpora via multistage training. This\npaper also suggests some guidelines to gather and clean corpora, mine parallel\nsentences, address noise in the mined data, and create high-quality evaluation\nsplits. For the sake of reproducibility, we will release our code for parallel\ndata creation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 01:12:31 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 03:16:24 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Song", "Haiyue", ""], ["Dabre", "Raj", ""], ["Fujita", "Atsushi", ""], ["Kurohashi", "Sadao", ""]]}, {"id": "1912.11755", "submitter": "Min Shi Mr.", "authors": "Min Shi, Yufei Tang, Xingquan Zhu and Jianxun Liu", "title": "Feature-Attention Graph Convolutional Networks for Noise Resilient\n  Learning", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noise and inconsistency commonly exist in real-world information networks,\ndue to inherent error-prone nature of human or user privacy concerns. To date,\ntremendous efforts have been made to advance feature learning from networks,\nincluding the most recent Graph Convolutional Networks (GCN) or attention GCN,\nby integrating node content and topology structures. However, all existing\nmethods consider networks as error-free sources and treat feature content in\neach node as independent and equally important to model node relations. The\nerroneous node content, combined with sparse features, provide essential\nchallenges for existing methods to be used on real-world noisy networks. In\nthis paper, we propose FA-GCN, a feature-attention graph convolution learning\nframework, to handle networks with noisy and sparse node content. To tackle\nnoise and sparse content in each node, FA-GCN first employs a long short-term\nmemory (LSTM) network to learn dense representation for each feature. To model\ninteractions between neighboring nodes, a feature-attention mechanism is\nintroduced to allow neighboring nodes learn and vary feature importance, with\nrespect to their connections. By using spectral-based graph convolution\naggregation process, each node is allowed to concentrate more on the most\ndetermining neighborhood features aligned with the corresponding learning task.\nExperiments and validations, w.r.t. different noise levels, demonstrate that\nFA-GCN achieves better performance than state-of-the-art methods on both\nnoise-free and noisy networks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 02:51:55 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Shi", "Min", ""], ["Tang", "Yufei", ""], ["Zhu", "Xingquan", ""], ["Liu", "Jianxun", ""]]}, {"id": "1912.11861", "submitter": "Filippos Gouidis Mr.", "authors": "Filippos Gouidis, Alexandros Vassiliades, Theodore Patkos, Antonis\n  Argyros, Nick Bassiliades and Dimitris Plexousakis", "title": "A Review on Intelligent Object Perception Methods Combining\n  Knowledge-based Reasoning and Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object perception is a fundamental sub-field of Computer Vision, covering a\nmultitude of individual areas and having contributed high-impact results. While\nMachine Learning has been traditionally applied to address related problems,\nrecent works also seek ways to integrate knowledge engineering in order to\nexpand the level of intelligence of the visual interpretation of objects, their\nproperties and their relations with their environment. In this paper, we\nattempt a systematic investigation of how knowledge-based methods contribute to\ndiverse object perception tasks. We review the latest achievements and identify\nprominent research directions.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 13:26:49 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 14:50:43 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Gouidis", "Filippos", ""], ["Vassiliades", "Alexandros", ""], ["Patkos", "Theodore", ""], ["Argyros", "Antonis", ""], ["Bassiliades", "Nick", ""], ["Plexousakis", "Dimitris", ""]]}, {"id": "1912.11899", "submitter": "Mihailo Jovanovic", "authors": "Hesameddin Mohammadi, Armin Zare, Mahdi Soltanolkotabi, Mihailo R.\n  Jovanovi\\'c", "title": "Convergence and sample complexity of gradient methods for the model-free\n  linear quadratic regulator problem", "comments": "39 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.SY eess.SY physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning attempts to find an optimal control action\nfor an unknown dynamical system by directly searching over the parameter space\nof controllers. The convergence behavior and statistical properties of these\napproaches are often poorly understood because of the nonconvex nature of the\nunderlying optimization problems and the lack of exact gradient computation. In\nthis paper, we take a step towards demystifying the performance and efficiency\nof such methods by focusing on the standard infinite-horizon linear quadratic\nregulator problem for continuous-time systems with unknown state-space\nparameters. We establish exponential stability for the ordinary differential\nequation (ODE) that governs the gradient-flow dynamics over the set of\nstabilizing feedback gains and show that a similar result holds for the\ngradient descent method that arises from the forward Euler discretization of\nthe corresponding ODE. We also provide theoretical bounds on the convergence\nrate and sample complexity of the random search method with two-point gradient\nestimates. We prove that the required simulation time for achieving\n$\\epsilon$-accuracy in the model-free setup and the total number of function\nevaluations both scale as $\\log \\, (1/\\epsilon)$.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 16:56:59 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 19:54:18 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 18:45:23 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Mohammadi", "Hesameddin", ""], ["Zare", "Armin", ""], ["Soltanolkotabi", "Mahdi", ""], ["Jovanovi\u0107", "Mihailo R.", ""]]}, {"id": "1912.11912", "submitter": "Devesh Jha", "authors": "Devesh Jha, Arvind Raghunathan, Diego Romeres", "title": "Quasi-Newton Trust Region Policy Optimization", "comments": "3rd Conference on Robot Learning (CoRL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a trust region method for policy optimization that employs\nQuasi-Newton approximation for the Hessian, called Quasi-Newton Trust Region\nPolicy Optimization QNTRPO. Gradient descent is the de facto algorithm for\nreinforcement learning tasks with continuous controls. The algorithm has\nachieved state-of-the-art performance when used in reinforcement learning\nacross a wide range of tasks. However, the algorithm suffers from a number of\ndrawbacks including: lack of stepsize selection criterion, and slow\nconvergence. We investigate the use of a trust region method using dogleg step\nand a Quasi-Newton approximation for the Hessian for policy optimization. We\ndemonstrate through numerical experiments over a wide range of challenging\ncontinuous control tasks that our particular choice is efficient in terms of\nnumber of samples and improves performance\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 18:29:38 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Jha", "Devesh", ""], ["Raghunathan", "Arvind", ""], ["Romeres", "Diego", ""]]}, {"id": "1912.11913", "submitter": "Xiaolong Li", "authors": "Xiaolong Li, He Wang, Li Yi, Leonidas Guibas, A. Lynn Abbott, Shuran\n  Song", "title": "Category-Level Articulated Object Pose Estimation", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This project addresses the task of category-level pose estimation for\narticulated objects from a single depth image. We present a novel\ncategory-level approach that correctly accommodates object instances previously\nunseen during training. We introduce Articulation-aware Normalized Coordinate\nSpace Hierarchy (ANCSH) - a canonical representation for different articulated\nobjects in a given category. As the key to achieve intra-category\ngeneralization, the representation constructs a canonical object space as well\nas a set of canonical part spaces. The canonical object space normalizes the\nobject orientation,scales and articulations (e.g. joint parameters and states)\nwhile each canonical part space further normalizes its part pose and scale. We\ndevelop a deep network based on PointNet++ that predicts ANCSH from a single\ndepth point cloud, including part segmentation, normalized coordinates, and\njoint parameters in the canonical object space. By leveraging the canonicalized\njoints, we demonstrate: 1) improved performance in part pose and scale\nestimations using the induced kinematic constraints from joints; 2) high\naccuracy for joint parameter estimation in camera space.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 18:34:37 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 19:46:04 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Li", "Xiaolong", ""], ["Wang", "He", ""], ["Yi", "Li", ""], ["Guibas", "Leonidas", ""], ["Abbott", "A. Lynn", ""], ["Song", "Shuran", ""]]}, {"id": "1912.11936", "submitter": "Yen-Chia Hsu", "authors": "Yen-Chia Hsu, Jennifer Cross, Paul Dille, Michael Tasota, Beatrice\n  Dias, Randy Sargent, Ting-Hao 'Kenneth' Huang, Illah Nourbakhsh", "title": "Smell Pittsburgh: Engaging Community Citizen Science for Air Quality", "comments": "Accepted by ACM Transactions on Interactive Intelligent Systems on\n  2020. This is an extended version of the arXiv:1810.11143, which was accepted\n  by the ACM IUI 2019 conference. arXiv admin note: substantial text overlap\n  with arXiv:1810.11143", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban air pollution has been linked to various human health concerns,\nincluding cardiopulmonary diseases. Communities who suffer from poor air\nquality often rely on experts to identify pollution sources due to the lack of\naccessible tools. Taking this into account, we developed Smell Pittsburgh, a\nsystem that enables community members to report odors and track where these\nodors are frequently concentrated. All smell report data are publicly\naccessible online. These reports are also sent to the local health department\nand visualized on a map along with air quality data from monitoring stations.\nThis visualization provides a comprehensive overview of the local pollution\nlandscape. Additionally, with these reports and air quality data, we developed\na model to predict upcoming smell events and send push notifications to inform\ncommunities. We also applied regression analysis to identify statistically\nsignificant effects of push notifications on user engagement. Our evaluation of\nthis system demonstrates that engaging residents in documenting their\nexperiences with pollution odors can help identify local air pollution\npatterns, and can empower communities to advocate for better air quality. All\ncitizen-contributed smell data are publicly accessible and can be downloaded\nfrom https://smellpgh.org.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 21:31:39 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 08:04:58 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 18:03:59 GMT"}, {"version": "v4", "created": "Fri, 20 Nov 2020 23:40:31 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Hsu", "Yen-Chia", ""], ["Cross", "Jennifer", ""], ["Dille", "Paul", ""], ["Tasota", "Michael", ""], ["Dias", "Beatrice", ""], ["Sargent", "Randy", ""], ["Huang", "Ting-Hao 'Kenneth'", ""], ["Nourbakhsh", "Illah", ""]]}, {"id": "1912.11945", "submitter": "Alexandra Luccioni", "authors": "Alexandra Luccioni and Yoshua Bengio", "title": "On the Morality of Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Much of the existing research on the social and ethical impact of Artificial\nIntelligence has been focused on defining ethical principles and guidelines\nsurrounding Machine Learning (ML) and other Artificial Intelligence (AI)\nalgorithms [IEEE, 2017, Jobin et al., 2019]. While this is extremely useful for\nhelping define the appropriate social norms of AI, we believe that it is\nequally important to discuss both the potential and risks of ML and to inspire\nthe community to use ML for beneficial objectives. In the present article,\nwhich is specifically aimed at ML practitioners, we thus focus more on the\nlatter, carrying out an overview of existing high-level ethical frameworks and\nguidelines, but above all proposing both conceptual and practical principles\nand guidelines for ML research and deployment, insisting on concrete actions\nthat can be taken by practitioners to pursue a more ethical and moral practice\nof ML aimed at using AI for social good.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 23:06:54 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Luccioni", "Alexandra", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1912.11970", "submitter": "Natalia Arzeno", "authors": "Natalia M. Arzeno, Haris Vikalo", "title": "Evolutionary Clustering via Message Passing", "comments": "To be published in IEEE Transactions on Knowledge and Data\n  Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are often interested in clustering objects that evolve over time and\nidentifying solutions to the clustering problem for every time step.\nEvolutionary clustering provides insight into cluster evolution and temporal\nchanges in cluster memberships while enabling performance superior to that\nachieved by independently clustering data collected at different time points.\nIn this paper we introduce evolutionary affinity propagation (EAP), an\nevolutionary clustering algorithm that groups data points by exchanging\nmessages on a factor graph. EAP promotes temporal smoothness of the solution to\nclustering time-evolving data by linking the nodes of the factor graph that are\nassociated with adjacent data snapshots, and introduces consensus nodes to\nenable cluster tracking and identification of cluster births and deaths. Unlike\nexisting evolutionary clustering methods that require additional processing to\napproximate the number of clusters or match them across time, EAP determines\nthe number of clusters and tracks them automatically. A comparison with\nexisting methods on simulated and experimental data demonstrates effectiveness\nof the proposed EAP algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 03:09:16 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Arzeno", "Natalia M.", ""], ["Vikalo", "Haris", ""]]}, {"id": "1912.12125", "submitter": "Kilian Kleeberger", "authors": "Kilian Kleeberger and Christian Landgraf and Marco F. Huber", "title": "Large-scale 6D Object Pose Estimation Dataset for Industrial Bin-Picking", "comments": "Accepted at 2019 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new public dataset for 6D object pose\nestimation and instance segmentation for industrial bin-picking. The dataset\ncomprises both synthetic and real-world scenes. For both, point clouds, depth\nimages, and annotations comprising the 6D pose (position and orientation), a\nvisibility score, and a segmentation mask for each object are provided. Along\nwith the raw data, a method for precisely annotating real-world scenes is\nproposed. To the best of our knowledge, this is the first public dataset for 6D\nobject pose estimation and instance segmentation for bin-picking containing\nsufficiently annotated data for learning-based approaches. Furthermore, it is\none of the largest public datasets for object pose estimation in general. The\ndataset is publicly available at http://www.bin-picking.ai/en/dataset.html.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 14:32:04 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Kleeberger", "Kilian", ""], ["Landgraf", "Christian", ""], ["Huber", "Marco F.", ""]]}, {"id": "1912.12191", "submitter": "Sukriti Verma", "authors": "Nikaash Puri, Sukriti Verma, Piyush Gupta, Dhruv Kayastha, Shripad\n  Deshmukh, Balaji Krishnamurthy, Sameer Singh", "title": "Explain Your Move: Understanding Agent Actions Using Specific and\n  Relevant Feature Attribution", "comments": "Accepted at the International Conference on Learning Representations\n  (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep reinforcement learning (RL) is applied to more tasks, there is a need\nto visualize and understand the behavior of learned agents. Saliency maps\nexplain agent behavior by highlighting the features of the input state that are\nmost relevant for the agent in taking an action. Existing perturbation-based\napproaches to compute saliency often highlight regions of the input that are\nnot relevant to the action taken by the agent. Our proposed approach, SARFA\n(Specific and Relevant Feature Attribution), generates more focused saliency\nmaps by balancing two aspects (specificity and relevance) that capture\ndifferent desiderata of saliency. The first captures the impact of perturbation\non the relative expected reward of the action to be explained. The second\ndownweighs irrelevant features that alter the relative expected rewards of\nactions other than the action to be explained. We compare SARFA with existing\napproaches on agents trained to play board games (Chess and Go) and Atari games\n(Breakout, Pong and Space Invaders). We show through illustrative examples\n(Chess, Atari, Go), human studies (Chess), and automated evaluation methods\n(Chess) that SARFA generates saliency maps that are more interpretable for\nhumans than existing approaches. For the code release and demo videos, see\nhttps://nikaashpuri.github.io/sarfa-saliency/.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 07:52:15 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 06:59:01 GMT"}, {"version": "v3", "created": "Sun, 29 Mar 2020 12:51:36 GMT"}, {"version": "v4", "created": "Fri, 3 Apr 2020 20:27:29 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Puri", "Nikaash", ""], ["Verma", "Sukriti", ""], ["Gupta", "Piyush", ""], ["Kayastha", "Dhruv", ""], ["Deshmukh", "Shripad", ""], ["Krishnamurthy", "Balaji", ""], ["Singh", "Sameer", ""]]}, {"id": "1912.12204", "submitter": "Boyi Liu", "authors": "Boyi Liu, Lujia Wang, Ming Liu, Cheng-Zhong Xu", "title": "Federated Imitation Learning: A Novel Framework for Cloud Robotic\n  Systems with Heterogeneous Sensor Data", "comments": "arXiv admin note: substantial text overlap with arXiv:1909.00895", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are capable of learning a new behavior by observing others to perform\nthe skill. Similarly, robots can also implement this by imitation learning.\nFurthermore, if with external guidance, humans can master the new behavior more\nefficiently. So, how can robots achieve this? To address the issue, we present\na novel framework named FIL. It provides a heterogeneous knowledge fusion\nmechanism for cloud robotic systems. Then, a knowledge fusion algorithm in FIL\nis proposed. It enables the cloud to fuse heterogeneous knowledge from local\nrobots and generate guide models for robots with service requests. After that,\nwe introduce a knowledge transfer scheme to facilitate local robots acquiring\nknowledge from the cloud. With FIL, a robot is capable of utilizing knowledge\nfrom other robots to increase its imitation learning in accuracy and\nefficiency. Compared with transfer learning and meta-learning, FIL is more\nsuitable to be deployed in cloud robotic systems. Finally, we conduct\nexperiments of a self-driving task for robots (cars). The experimental results\ndemonstrate that the shared model generated by FIL increases imitation learning\nefficiency of local robots in cloud robotic systems.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 11:23:23 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Liu", "Boyi", ""], ["Wang", "Lujia", ""], ["Liu", "Ming", ""], ["Xu", "Cheng-Zhong", ""]]}, {"id": "1912.12223", "submitter": "Kumar Sankar Ray", "authors": "Litan Kumar Das and Kumar Sankar Ray", "title": "Bitopological Duality for Algebras of Fittings logic and Natural Duality\n  extension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate a bitopological duality for algebras of\nFitting's multi-valued logic. We also extend the natural duality theory for\n$\\mathbb{ISP_I}(\\mathcal{L})$ by developing a duality for\n$\\mathbb{ISP}(\\mathcal{L})$, where $\\mathcal{L}$ is a finite algebra in which\nunderlying lattice is bounded distributive.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 08:38:19 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Das", "Litan Kumar", ""], ["Ray", "Kumar Sankar", ""]]}, {"id": "1912.12294", "submitter": "Dian Chen", "authors": "Dian Chen and Brady Zhou and Vladlen Koltun and Philipp Kr\\\"ahenb\\\"uhl", "title": "Learning by Cheating", "comments": "Paper published in CoRL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-based urban driving is hard. The autonomous system needs to learn to\nperceive the world and act in it. We show that this challenging learning\nproblem can be simplified by decomposing it into two stages. We first train an\nagent that has access to privileged information. This privileged agent cheats\nby observing the ground-truth layout of the environment and the positions of\nall traffic participants. In the second stage, the privileged agent acts as a\nteacher that trains a purely vision-based sensorimotor agent. The resulting\nsensorimotor agent does not have access to any privileged information and does\nnot cheat. This two-stage training procedure is counter-intuitive at first, but\nhas a number of important advantages that we analyze and empirically\ndemonstrate. We use the presented approach to train a vision-based autonomous\ndriving system that substantially outperforms the state of the art on the CARLA\nbenchmark and the recent NoCrash benchmark. Our approach achieves, for the\nfirst time, 100% success rate on all tasks in the original CARLA benchmark,\nsets a new record on the NoCrash benchmark, and reduces the frequency of\ninfractions by an order of magnitude compared to the prior state of the art.\nFor the video that summarizes this work, see https://youtu.be/u9ZCxxD-UUw\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 18:59:04 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Chen", "Dian", ""], ["Zhou", "Brady", ""], ["Koltun", "Vladlen", ""], ["Kr\u00e4henb\u00fchl", "Philipp", ""]]}, {"id": "1912.12345", "submitter": "Richard Shin", "authors": "Richard Shin, Neel Kant, Kavi Gupta, Christopher Bender, Brandon\n  Trabucco, Rishabh Singh, Dawn Song", "title": "Synthetic Datasets for Neural Program Synthesis", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of program synthesis is to automatically generate programs in a\nparticular language from corresponding specifications, e.g. input-output\nbehavior. Many current approaches achieve impressive results after training on\nrandomly generated I/O examples in limited domain-specific languages (DSLs), as\nwith string transformations in RobustFill. However, we empirically discover\nthat applying test input generation techniques for languages with control flow\nand rich input space causes deep networks to generalize poorly to certain data\ndistributions; to correct this, we propose a new methodology for controlling\nand evaluating the bias of synthetic data distributions over both programs and\nspecifications. We demonstrate, using the Karel DSL and a small Calculator DSL,\nthat training deep networks on these distributions leads to improved\ncross-distribution generalization performance.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 21:28:10 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Shin", "Richard", ""], ["Kant", "Neel", ""], ["Gupta", "Kavi", ""], ["Bender", "Christopher", ""], ["Trabucco", "Brandon", ""], ["Singh", "Rishabh", ""], ["Song", "Dawn", ""]]}, {"id": "1912.12418", "submitter": "Carlo Vittorio Cannistraci", "authors": "A. Acevedo, S. Ciucci, MJ. Kuo, C. Duran and CV. Cannistraci", "title": "Measuring group-separability in geometrical space for evaluation of\n  pattern recognition and embedding algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating data separation in a geometrical space is fundamental for pattern\nrecognition. A plethora of dimensionality reduction (DR) algorithms have been\ndeveloped in order to reveal the emergence of geometrical patterns in a low\ndimensional visible representation space, in which high-dimensional samples\nsimilarities are approximated by geometrical distances. However, statistical\nmeasures to evaluate directly in the low dimensional geometrical space the\nsample group separability attaiend by these DR algorithms are missing.\nCertainly, these separability measures could be used both to compare algorithms\nperformance and to tune algorithms parameters. Here, we propose three\nstatistical measures (named as PSI-ROC, PSI-PR, and PSI-P) that have origin\nfrom the Projection Separability (PS) rationale introduced in this study, which\nis expressly designed to assess group separability of data samples in a\ngeometrical space. Traditional cluster validity indices (CVIs) might be applied\nin this context but they show limitations because they are not specifically\ntailored for DR. Our PS measures are compared to six baseline cluster validity\nindices, using five non-linear datasets and six different DR algorithms. The\nresults provide clear evidence that statistical-based measures based on PS\nrationale are more accurate than CVIs and can be adopted to control the tuning\nof parameter-dependent DR algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 07:34:35 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Acevedo", "A.", ""], ["Ciucci", "S.", ""], ["Kuo", "MJ.", ""], ["Duran", "C.", ""], ["Cannistraci", "CV.", ""]]}, {"id": "1912.12442", "submitter": "Andreas Pieris", "authors": "Pablo Barcelo, Victor Dalmau, Cristina Feier, Carsten Lutz, Andreas\n  Pieris", "title": "The Limits of Efficiency for Open- and Closed-World Query Evaluation\n  Under Guarded TGDs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology-mediated querying and querying in the presence of constraints are\ntwo key database problems where tuple-generating dependencies (TGDs) play a\ncentral role. In ontology-mediated querying, TGDs can formalize the ontology\nand thus derive additional facts from the given data, while in querying in the\npresence of constraints, they restrict the set of admissible databases. In this\nwork, we study the limits of efficient query evaluation in the context of the\nabove two problems, focussing on guarded and frontier-guarded TGDs and on UCQs\nas the actual queries. We show that a class of ontology-mediated queries (OMQs)\nbased on guarded TGDs can be evaluated in FPT iff the OMQs in the class are\nequivalent to OMQs in which the actual query has bounded treewidth, up to some\nreasonable assumptions. For querying in the presence of constraints, we\nconsider classes of constraint-query specifications (CQSs) that bundle a set of\nconstraints with an actual query. We show a dichotomy result for CQSs based on\nguarded TGDs that parallels the one for OMQs except that, additionally, FPT\ncoincides with PTime combined complexity. The proof is based on a novel\nconnection between OMQ and CQS evaluation. Using a direct proof, we also show a\nsimilar dichotomy result, again up to some reasonable assumptions, for CQSs\nbased on frontier-guarded TGDs with a bounded number of atoms in TGD heads. Our\nresults on CQSs can be viewed as extensions of Grohe's well-known\ncharacterization of the tractable classes of CQs (without constraints). Like\nGrohe's characterization, all the above results assume that the arity of\nrelation symbols is bounded by a constant. We also study the associated meta\nproblems, i.e., whether a given OMQ or CQS is equivalent to one in which the\nactual query has bounded treewidth.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 11:08:33 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Barcelo", "Pablo", ""], ["Dalmau", "Victor", ""], ["Feier", "Cristina", ""], ["Lutz", "Carsten", ""], ["Pieris", "Andreas", ""]]}, {"id": "1912.12482", "submitter": "Milan Cvitkovic", "authors": "Keng Wah Loon, Laura Graesser, Milan Cvitkovic", "title": "SLM Lab: A Comprehensive Benchmark and Modular Software Framework for\n  Reproducible Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SLM Lab, a software framework for reproducible reinforcement\nlearning (RL) research. SLM Lab implements a number of popular RL algorithms,\nprovides synchronous and asynchronous parallel experiment execution,\nhyperparameter search, and result analysis. RL algorithms in SLM Lab are\nimplemented in a modular way such that differences in algorithm performance can\nbe confidently ascribed to differences between algorithms, not between\nimplementations. In this work we present the design choices behind SLM Lab and\nuse it to produce a comprehensive single-codebase RL algorithm benchmark. In\naddition, as a consequence of SLM Lab's modular design, we introduce and\nevaluate a discrete-action variant of the Soft Actor-Critic algorithm (Haarnoja\net al., 2018) and a hybrid synchronous/asynchronous training method for RL\nagents.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 16:29:58 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Loon", "Keng Wah", ""], ["Graesser", "Laura", ""], ["Cvitkovic", "Milan", ""]]}, {"id": "1912.12534", "submitter": "Charalampos Andriotis", "authors": "C.P. Andriotis, K.G. Papakonstantinou, E.N. Chatzi", "title": "Value of structural health information in partially observable\n  stochastic environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient integration of uncertain observations with decision-making\noptimization is key for prescribing informed intervention actions, able to\npreserve structural safety of deteriorating engineering systems. To this end,\nit is necessary that scheduling of inspection and monitoring strategies be\nobjectively performed on the basis of their expected value-based gains that,\namong others, reflect quantitative metrics such as the Value of Information\n(VoI) and the Value of Structural Health Monitoring (VoSHM). In this work, we\nintroduce and study the theoretical and computational foundations of the above\nmetrics within the context of Partially Observable Markov Decision Processes\n(POMDPs), thus alluding to a broad class of decision-making problems of\npartially observable stochastic deteriorating environments that can be modeled\nas POMDPs. Step-wise and life-cycle VoI and VoSHM definitions are devised and\ntheir bounds are analyzed as per the properties stemming from the Bellman\nequation and the resulting optimal value function. It is shown that a POMDP\npolicy inherently leverages the notion of VoI to guide observational actions in\nan optimal way at every decision step, and that the permanent or intermittent\ninformation provided by SHM or inspection visits, respectively, can only\nimprove the cost of this policy in the long-term, something that is not\nnecessarily true under locally optimal policies, typically adopted in\ndecision-making of structures and infrastructure. POMDP solutions are derived\nbased on point-based value iteration methods, and the various definitions are\nquantified in stationary and non-stationary deteriorating environments, with\nboth infinite and finite planning horizons, featuring single- or\nmulti-component engineering systems.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 22:18:48 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 16:49:06 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Andriotis", "C. P.", ""], ["Papakonstantinou", "K. G.", ""], ["Chatzi", "E. N.", ""]]}, {"id": "1912.12613", "submitter": "Pulkit Verma", "authors": "Pulkit Verma, Shashank Rao Marpally, Siddharth Srivastava", "title": "Asking the Right Questions: Learning Interpretable Action Models Through\n  Query Answering", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a new approach for estimating an interpretable,\nrelational model of a black-box autonomous agent that can plan and act. Our\nmain contributions are a new paradigm for estimating such models using a\nminimal query interface with the agent, and a hierarchical querying algorithm\nthat generates an interrogation policy for estimating the agent's internal\nmodel in a vocabulary provided by the user. Empirical evaluation of our\napproach shows that despite the intractable search space of possible agent\nmodels, our approach allows correct and scalable estimation of interpretable\nagent models for a wide class of black-box autonomous agents. Our results also\nshow that this approach can use predicate classifiers to learn interpretable\nmodels of planning agents that represent states as images.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 09:05:06 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 02:45:09 GMT"}, {"version": "v3", "created": "Sat, 18 Jul 2020 02:28:51 GMT"}, {"version": "v4", "created": "Mon, 14 Sep 2020 17:17:24 GMT"}, {"version": "v5", "created": "Sat, 6 Mar 2021 04:44:49 GMT"}, {"version": "v6", "created": "Fri, 9 Apr 2021 16:17:14 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Verma", "Pulkit", ""], ["Marpally", "Shashank Rao", ""], ["Srivastava", "Siddharth", ""]]}, {"id": "1912.12623", "submitter": "Marti Sanchez-Fibla", "authors": "Berkay Demirel, Mart\\'i S\\'anchez-Fibla", "title": "Speeding up reinforcement learning by combining attention and agency\n  features", "comments": "9 pages, 5 figures, Paper appeared in CCIA 2019", "journal-ref": null, "doi": "10.3233/FAIA190111", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When playing video-games we immediately detect which entity we control and we\ncenter the attention towards it to focus the learning and reduce its\ndimensionality. Reinforcement Learning (RL) has been able to deal with big\nstate spaces, including states derived from pixel images in Atari games, but\nthe learning is slow, depends on the brute force mapping from the global state\nto the action values (Q-function), thus its performance is severely affected by\nthe dimensionality of the state and cannot be transferred to other games or\nother parts of the same game. We propose different transformations of the input\nstate that combine attention and agency detection mechanisms which both have\nbeen addressed separately in RL but not together to our knowledge. We propose\nand benchmark different architectures including both global and local agency\ncentered versions of the state and also including summaries of the\nsurroundings. Results suggest that even a redundant global-local state network\ncan learn faster than the global alone. Summarized versions of the state look\npromising to achieve input-size independence learning.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 10:23:01 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Demirel", "Berkay", ""], ["S\u00e1nchez-Fibla", "Mart\u00ed", ""]]}, {"id": "1912.12630", "submitter": "Pooyan Fazli", "authors": "Yuxiang Sun and Pooyan Fazli", "title": "Real-time Policy Distillation in Deep Reinforcement Learning", "comments": "In Proceedings of the Workshop on ML for Systems, Thirty-third\n  Conference on Neural Information Processing Systems (NeurIPS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy distillation in deep reinforcement learning provides an effective way\nto transfer control policies from a larger network to a smaller untrained\nnetwork without a significant degradation in performance. However, policy\ndistillation is underexplored in deep reinforcement learning, and existing\napproaches are computationally inefficient, resulting in a long distillation\ntime. In addition, the effectiveness of the distillation process is still\nlimited to the model capacity. We propose a new distillation mechanism, called\nreal-time policy distillation, in which training the teacher model and\ndistilling the policy to the student model occur simultaneously. Accordingly,\nthe teacher's latest policy is transferred to the student model in real time.\nThis reduces the distillation time to half the original time or even less and\nalso makes it possible for extremely small student models to learn skills at\nthe expert level. We evaluated the proposed algorithm in the Atari 2600 domain.\nThe results show that our approach can achieve full distillation in most games,\neven with compression ratios up to 1.7%.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 11:10:37 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Sun", "Yuxiang", ""], ["Fazli", "Pooyan", ""]]}, {"id": "1912.12633", "submitter": "Marti Sanchez-Fibla", "authors": "Marco Jerome Gasparrini, Mart\\'i S\\'anchez-Fibla", "title": "Loss aversion fosters coordination among independent reinforcement\n  learners", "comments": "5 pages, 2 figures, appeared in CCIA 2018", "journal-ref": null, "doi": "10.3233/978-1-61499-918-8-307", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study what are the factors that can accelerate the emergence of\ncollaborative behaviours among independent selfish learning agents. We depart\nfrom the \"Battle of the Exes\" (BoE), a spatial repeated game from which human\nbehavioral data has been obtained (by Hawkings and Goldstone, 2016) that we\nfind interesting because it considers two cases: a classic game theory version,\ncalled ballistic, in which agents can only make one action/decision (equivalent\nto the Battle of the Sexes) and a spatial version, called dynamic, in which\nagents can change decision (a spatial continuous version). We model both\nversions of the game with independent reinforcement learning agents and we\nmanipulate the reward function transforming it into an utility introducing\n\"loss aversion\": the reward that an agent obtains can be perceived as less\nvaluable when compared to what the other got. We prove experimentally the\nintroduction of loss aversion fosters cooperation by accelerating its\nappearance, and by making it possible in some cases like in the dynamic\ncondition. We suggest that this may be an important factor explaining the rapid\nconverge of human behaviour towards collaboration reported in the experiment of\nHawkings and Goldstone.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 11:22:30 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Gasparrini", "Marco Jerome", ""], ["S\u00e1nchez-Fibla", "Mart\u00ed", ""]]}, {"id": "1912.12671", "submitter": "Mart\\'i S\\'anchez-Fibla", "authors": "Marco Jerome Gasparrini, Ricard Sol\\'e, Mart\\'i S\\'anchez-Fibla", "title": "Individual specialization in multi-task environments with multiagent\n  reinforcement learners", "comments": "5 pages, 2 figures, paper appeared in CCIA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is a growing interest in Multi-Agent Reinforcement Learning (MARL) as\nthe first steps towards building general intelligent agents that learn to make\nlow and high-level decisions in non-stationary complex environments in the\npresence of other agents. Previous results point us towards increased\nconditions for coordination, efficiency/fairness, and common-pool resource\nsharing. We further study coordination in multi-task environments where several\nrewarding tasks can be performed and thus agents don't necessarily need to\nperform well in all tasks, but under certain conditions may specialize. An\nobservation derived from the study is that epsilon greedy exploration of\nvalue-based reinforcement learning methods is not adequate for multi-agent\nindependent learners because the epsilon parameter that controls the\nprobability of selecting a random action synchronizes the agents artificially\nand forces them to have deterministic policies at the same time. By using\npolicy-based methods with independent entropy regularised exploration updates,\nwe achieved a better and smoother convergence. Another result that needs to be\nfurther investigated is that with an increased number of agents specialization\ntends to be more probable.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 15:20:24 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Gasparrini", "Marco Jerome", ""], ["Sol\u00e9", "Ricard", ""], ["S\u00e1nchez-Fibla", "Mart\u00ed", ""]]}, {"id": "1912.12676", "submitter": "Gurcan Comert", "authors": "Gurcan Comert, Zadid Khan, Mizanur Rahman, Mashrur Chowdhury", "title": "Grey Models for Short-Term Queue Length Predictions for Adaptive Traffic\n  Signal Control", "comments": "16 pages, 8 figures, submitted to Expert Systems with Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic congestion at a signalized intersection greatly reduces the travel\ntime reliability in urban areas. Adaptive signal control system (ASCS) is the\nmost advanced traffic signal technology that regulates the signal phasing and\ntimings considering the patterns in real-time in order to reduce congestion.\nReal-time prediction of queue lengths can be used to adjust the phasing and\ntimings for different movements at an intersection with ASCS. The accuracy of\nthe prediction varies based on the factors, such as the stochastic nature of\nthe vehicle arrival rates, time of the day, weather and driver characteristics.\nIn addition, accurate prediction for multilane, undersaturated and saturated\ntraffic scenarios is challenging. Thus, the objective of this study is to\ndevelop queue length prediction models for signalized intersections that can be\nleveraged by ASCS using four variations of Grey systems: (i) the first order\nsingle variable Grey model (GM(1,1)); (ii) GM(1,1) with Fourier error\ncorrections; (iii) the Grey Verhulst model (GVM), and (iv) GVM with Fourier\nerror corrections. The efficacy of the GM is that they facilitate fast\nprocessing; as these models do not require a large amount of data; as would be\nneeded in artificial intelligence models; and they are able to adapt to\nstochastic changes, unlike statistical models. We have conducted a case study\nusing queue length data from five intersections with ASCS on a calibrated\nroadway network in Lexington, South Carolina. GM were compared with linear,\nnonlinear time series models, and long short-term memory (LSTM) neural network.\nBased on our analyses, we found that EGVM reduces the prediction error over\nclosest competing models (i.e., LSTM and time series models) in predicting\naverage and maximum queue lengths by 40% and 42%, respectively, in terms of\nRoot Mean Squared Error, and 51% and 50%, respectively, in terms of Mean\nAbsolute Error.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 15:33:03 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Comert", "Gurcan", ""], ["Khan", "Zadid", ""], ["Rahman", "Mizanur", ""], ["Chowdhury", "Mashrur", ""]]}, {"id": "1912.12716", "submitter": "Zhaoxian Wu", "authors": "Zhaoxian Wu, Qing Ling, Tianyi Chen, and Georgios B. Giannakis", "title": "Federated Variance-Reduced Stochastic Gradient Descent with Robustness\n  to Byzantine Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with distributed finite-sum optimization for learning over\nnetworks in the presence of malicious Byzantine attacks. To cope with such\nattacks, most resilient approaches so far combine stochastic gradient descent\n(SGD) with different robust aggregation rules. However, the sizeable\nSGD-induced stochastic gradient noise makes it challenging to distinguish\nmalicious messages sent by the Byzantine attackers from noisy stochastic\ngradients sent by the 'honest' workers. This motivates us to reduce the\nvariance of stochastic gradients as a means of robustifying SGD in the presence\nof Byzantine attacks. To this end, the present work puts forth a Byzantine\nattack resilient distributed (Byrd-) SAGA approach for learning tasks involving\nfinite-sum optimization over networks. Rather than the mean employed by\ndistributed SAGA, the novel Byrd- SAGA relies on the geometric median to\naggregate the corrected stochastic gradients sent by the workers. When less\nthan half of the workers are Byzantine attackers, the robustness of geometric\nmedian to outliers enables Byrd-SAGA to attain provably linear convergence to a\nneighborhood of the optimal solution, with the asymptotic learning error\ndetermined by the number of Byzantine workers. Numerical tests corroborate the\nrobustness to various Byzantine attacks, as well as the merits of Byrd- SAGA\nover Byzantine attack resilient distributed SGD.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 19:46:03 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 07:34:10 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Wu", "Zhaoxian", ""], ["Ling", "Qing", ""], ["Chen", "Tianyi", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1912.12719", "submitter": "Mirza Rami\\v{c}i\\'c", "authors": "Mirza Ramicic, Andrea Bonarini", "title": "Augmented Replay Memory in Reinforcement Learning With Continuous\n  Control", "comments": null, "journal-ref": "IEEE Transactions on Cognitive and Developmental Systems (2021)\n  1-12", "doi": "10.1109/TCDS.2021.3050723", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online reinforcement learning agents are currently able to process an\nincreasing amount of data by converting it into a higher order value functions.\nThis expansion of the information collected from the environment increases the\nagent's state space enabling it to scale up to a more complex problems but also\nincreases the risk of forgetting by learning on redundant or conflicting data.\nTo improve the approximation of a large amount of data, a random mini-batch of\nthe past experiences that are stored in the replay memory buffer is often\nreplayed at each learning step. The proposed work takes inspiration from a\nbiological mechanism which act as a protective layer of human brain higher\ncognitive functions: active memory consolidation mitigates the effect of\nforgetting of previous memories by dynamically processing the new ones. The\nsimilar dynamics are implemented by a proposed augmented memory replay AMR\ncapable of optimizing the replay of the experiences from the agent's memory\nstructure by altering or augmenting their relevance. Experimental results show\nthat an evolved AMR augmentation function capable of increasing the\nsignificance of the specific memories is able to further increase the stability\nand convergence speed of the learning algorithms dealing with the complexity of\ncontinuous action domains.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 20:07:18 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Ramicic", "Mirza", ""], ["Bonarini", "Andrea", ""]]}, {"id": "1912.12800", "submitter": "Varun Gangal", "authors": "Varun Gangal, Abhinav Arora, Arash Einolghozati, Sonal Gupta", "title": "Likelihood Ratios and Generative Classifiers for Unsupervised\n  Out-of-Domain Detection In Task Oriented Dialog", "comments": "Accepted for AAAI-2020 Main Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of identifying out-of-domain (OOD) input examples directly at\ntest-time has seen renewed interest recently due to increased real world\ndeployment of models. In this work, we focus on OOD detection for natural\nlanguage sentence inputs to task-based dialog systems. Our findings are\nthree-fold: First, we curate and release ROSTD (Real Out-of-Domain Sentences\nFrom Task-oriented Dialog) - a dataset of 4K OOD examples for the publicly\navailable dataset from (Schuster et al. 2019). In contrast to existing settings\nwhich synthesize OOD examples by holding out a subset of classes, our examples\nwere authored by annotators with apriori instructions to be out-of-domain with\nrespect to the sentences in an existing dataset. Second, we explore likelihood\nratio based approaches as an alternative to currently prevalent paradigms.\nSpecifically, we reformulate and apply these approaches to natural language\ninputs. We find that they match or outperform the latter on all datasets, with\nlarger improvements on non-artificial OOD benchmarks such as our dataset. Our\nablations validate that specifically using likelihood ratios rather than plain\nlikelihood is necessary to discriminate well between OOD and in-domain data.\nThird, we propose learning a generative classifier and computing a marginal\nlikelihood (ratio) for OOD detection. This allows us to use a principled\nlikelihood while at the same time exploiting training-time labels. We find that\nthis approach outperforms both simple likelihood (ratio) based and other prior\napproaches. We are hitherto the first to investigate the use of generative\nclassifiers for OOD detection at test-time.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 03:31:17 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Gangal", "Varun", ""], ["Arora", "Abhinav", ""], ["Einolghozati", "Arash", ""], ["Gupta", "Sonal", ""]]}, {"id": "1912.12893", "submitter": "Martin Dieguez", "authors": "Philippe Balbiani and Joseph Boudou and Mart\\'in Di\\'eguez and David\n  Fern\\'andez-Duque", "title": "Intuitionistic Linear Temporal Logics", "comments": "arXiv admin note: text overlap with arXiv:1704.02847,\n  arXiv:1803.05078", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider intuitionistic variants of linear temporal logic with `next',\n`until' and `release' based on expanding posets: partial orders equipped with\nan order-preserving transition function. This class of structures gives rise to\na logic which we denote $\\iltl$, and by imposing additional constraints we\nobtain the logics $\\itlb$ of persistent posets and $\\itlht$ of here-and-there\ntemporal logic, both of which have been considered in the literature. We prove\nthat $\\iltl$ has the effective finite model property and hence is decidable,\nwhile $\\itlb$ does not have the finite model property. We also introduce\nnotions of bounded bisimulations for these logics and use them to show that the\n`until' and `release' operators are not definable in terms of each other, even\nover the class of persistent posets.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 11:49:31 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Balbiani", "Philippe", ""], ["Boudou", "Joseph", ""], ["Di\u00e9guez", "Mart\u00edn", ""], ["Fern\u00e1ndez-Duque", "David", ""]]}, {"id": "1912.12932", "submitter": "Regis Pierrard", "authors": "R\\'egis Pierrard (LIST, MICS), Jean-Philippe Poli (LIST), C\\'eline\n  Hudelot (MICS)", "title": "A New Approach for Explainable Multiple Organ Annotation with Few Data", "comments": null, "journal-ref": "IJCAI 2019 Workshop on Explainable Artificial Intelligence (XAI),\n  Aug 2019, Macao, Macau SAR China", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent successes of deep learning, such models are still far from\nsome human abilities like learning from few examples, reasoning and explaining\ndecisions. In this paper, we focus on organ annotation in medical images and we\nintroduce a reasoning framework that is based on learning fuzzy relations on a\nsmall dataset for generating explanations. Given a catalogue of relations, it\nefficiently induces the most relevant relations and combines them for building\nconstraints in order to both solve the organ annotation task and generate\nexplanations. We test our approach on a publicly available dataset of medical\nimages where several organs are already segmented. A demonstration of our model\nis proposed with an example of explained annotations. It was trained on a small\ntraining set containing as few as a couple of examples.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 14:06:32 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Pierrard", "R\u00e9gis", "", "LIST, MICS"], ["Poli", "Jean-Philippe", "", "LIST"], ["Hudelot", "C\u00e9line", "", "MICS"]]}, {"id": "1912.12957", "submitter": "EPTCS", "authors": "Claudia Schon, Sophie Siebert, Frieder Stolzenburg", "title": "Using ConceptNet to Teach Common Sense to an Automated Theorem Prover", "comments": "In Proceedings ARCADE 2019, arXiv:1912.11786", "journal-ref": "EPTCS 311, 2019, pp. 19-24", "doi": "10.4204/EPTCS.311.3", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CoRg system is a system to solve commonsense reasoning problems. The core\nof the CoRg system is the automated theorem prover Hyper that is fed with large\namounts of background knowledge. This background knowledge plays a crucial role\nin solving commonsense reasoning problems. In this paper we present different\nways to use knowledge graphs as background knowledge and discuss challenges\nthat arise.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 15:13:53 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Schon", "Claudia", ""], ["Siebert", "Sophie", ""], ["Stolzenburg", "Frieder", ""]]}, {"id": "1912.12958", "submitter": "EPTCS", "authors": "Giles Reger (University of Manchester)", "title": "Boldly Going Where No Prover Has Gone Before", "comments": "In Proceedings ARCADE 2019, arXiv:1912.11786", "journal-ref": "EPTCS 311, 2019, pp. 37-41", "doi": "10.4204/EPTCS.311.6", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I argue that the most interesting goal facing researchers in automated\nreasoning is being able to solve problems that cannot currently be solved by\nexisting tools and methods. This may appear obvious, and is clearly not an\noriginal thought, but focusing on this as a primary goal allows us to examine\nother goals in a new light. Many successful theorem provers employ a portfolio\nof different methods for solving problems. This changes the landscape on which\nwe perform our research: solving problems that can already be solved may not\nimprove the state of the art and a method that can solve a handful of problems\nunsolvable by current methods, but generally performs poorly on most problems,\ncan be very useful. We acknowledge that forcing new methods to compete against\nportfolio solvers can stifle innovation. However, this is only the case when\ncomparisons are made at the level of total problems solved. We propose a\nmovement towards focussing on unique solutions in evaluation and competitions\ni.e. measuring the potential contribution to a portfolio solver. This state of\naffairs is particularly prominent in first-order logic, which is undecidable.\nWhen reasoning in a decidable logic there can be a focus on optimising a\ndecision procedure and measuring average solving times. But in a setting where\nsolutions are difficult to find, average solving times lose meaning, and whilst\nimproving the efficiency of a technique can move potential solutions within\nacceptable time limits, in general, complementary strategies may be more\nsuccessful.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 15:14:10 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Reger", "Giles", "", "University of Manchester"]]}, {"id": "1912.12959", "submitter": "EPTCS", "authors": "Naveen Sundar Govindarajulu (Rensselaer AI and Reasoning Lab), Selmer\n  Bringsjord (Rensselaer Polytechnic Institute), Matthew Peveler (Rensselaer\n  Polytechnic Institute)", "title": "On Quantified Modal Theorem Proving for Modeling Ethics", "comments": "In Proceedings ARCADE 2019, arXiv:1912.11786", "journal-ref": "EPTCS 311, 2019, pp. 43-49", "doi": "10.4204/EPTCS.311.7", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, formal logics have been used to model a wide range of\nethical theories and principles with the goal of using these models within\nautonomous systems. Logics for modeling ethical theories, and their automated\nreasoners, have requirements that are different from modal logics used for\nother purposes, e.g. for temporal reasoning. Meeting these requirements\nnecessitates investigation of new approaches for proof automation.\nParticularly, a quantified modal logic, the deontic cognitive event calculus\n(DCEC), has been used to model various versions of the doctrine of double\neffect, akrasia, and virtue ethics. Using a fragment of DCEC, we outline these\ndistinct characteristics and present a sketches of an algorithm that can help\nwith some aspects proof automation for DCEC.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 15:14:21 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Govindarajulu", "Naveen Sundar", "", "Rensselaer AI and Reasoning Lab"], ["Bringsjord", "Selmer", "", "Rensselaer Polytechnic Institute"], ["Peveler", "Matthew", "", "Rensselaer\n  Polytechnic Institute"]]}, {"id": "1912.13037", "submitter": "Daniel Hsu", "authors": "Daniel Hsu", "title": "A New Framework for Query Efficient Active Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to align agent policy with human expert behavior in a reinforcement\nlearning (RL) setting, without any prior knowledge about dynamics, reward\nfunction, and unsafe states. There is a human expert knowing the rewards and\nunsafe states based on his preference and objective, but querying that human\nexpert is expensive. To address this challenge, we propose a new framework for\nimitation learning (IL) algorithm that actively and interactively learns a\nmodel of the user's reward function with efficient queries. We build an\nadversarial generative model of states and a successor feature (SR) model\ntrained over transition experience collected by learning policy. Our method\nuses these models to select state-action pairs, asking the user to comment on\nthe optimality or safety, and trains a adversarial neural network to predict\nthe rewards. Different from previous papers, which are almost all based on\nuncertainty sampling, the key idea is to actively and efficiently select\nstate-action pairs from both on-policy and off-policy experience, by\ndiscriminating the queried (expert) and unqueried (generated) data and\nmaximizing the efficiency of value function learning. We call this method\nadversarial reward query with successor representation. We evaluate the\nproposed method with simulated human on a state-based 2D navigation task,\nrobotic control tasks and the image-based video games, which have\nhigh-dimensional observation and complex state dynamics. The results show that\nthe proposed method significantly outperforms uncertainty-based methods on\nlearning reward models, achieving better query efficiency, where the\nadversarial discriminator can make the agent learn human behavior more\nefficiently and the SR can select states which have stronger impact on value\nfunction. Moreover, the proposed method can also learn to avoid unsafe states\nwhen training the reward model.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 18:12:27 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Hsu", "Daniel", ""]]}, {"id": "1912.13082", "submitter": "Makarand Tapaswi", "authors": "Atef Chaudhury, Makarand Tapaswi, Seung Wook Kim, Sanja Fidler", "title": "The Shmoop Corpus: A Dataset of Stories with Loosely Aligned Summaries", "comments": "Project page: http://www.cs.toronto.edu/~makarand/shmoop/ Dataset at:\n  https://github.com/achaudhury/shmoop-corpus/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding stories is a challenging reading comprehension problem for\nmachines as it requires reading a large volume of text and following long-range\ndependencies. In this paper, we introduce the Shmoop Corpus: a dataset of 231\nstories that are paired with detailed multi-paragraph summaries for each\nindividual chapter (7,234 chapters), where the summary is chronologically\naligned with respect to the story chapter. From the corpus, we construct a set\nof common NLP tasks, including Cloze-form question answering and a simplified\nform of abstractive summarization, as benchmarks for reading comprehension on\nstories. We then show that the chronological alignment provides a strong\nsupervisory signal that learning-based methods can exploit leading to\nsignificant improvements on these tasks. We believe that the unique structure\nof this corpus provides an important foothold towards making machine story\ncomprehension more approachable.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 21:03:59 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 16:06:48 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Chaudhury", "Atef", ""], ["Tapaswi", "Makarand", ""], ["Kim", "Seung Wook", ""], ["Fidler", "Sanja", ""]]}, {"id": "1912.13122", "submitter": "Andres Garcia-Camino", "authors": "Andr\\'es Garc\\'ia-Camino", "title": "Declarative Mechanism Design", "comments": null, "journal-ref": null, "doi": null, "report-no": "Report-no: 01", "categories": "cs.AI cs.LG cs.LO cs.MA cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regulation of Multi-Agent Systems (MAS) and Declarative Electronic\nInstitutions (DEIs) was a multidisciplinary research topic of the past decade\ninvolving (Physical and Software) Agents and Law since the beginning, but\nrecently evolved towards News-claimed Robot Lawyer since 2016. One of these\nfirst proposals of restricting the behaviour of Software Agentswas Electronic\nInstitutions.However, with the recent reformulation of Artificial Neural\nNetworks (ANNs) as Deep Learning (DL), Security, Privacy,Ethical and Legal\nissues regarding the use of DL has raised concerns in the Artificial\nIntelligence (AI) Community. Now that the Regulation of MAS is almost correctly\naddressed, we propose the Regulation of Artificial Neural Networks as\nAgent-based Training of a special type of regulated Artificial Neural Network\nthat we call Institutional Neural Network (INN).The main purpose of this paper\nis to bring attention to Artificial Teaching (AT) and to give a tentative\nanswer showing a proof-of-concept implementation of Regulated Deep Learning\n(RDL). This paper introduces the former concept and provide sI, a language\npreviously used to model declaratively and extend Electronic Institutions, as a\nmeans to regulate the execution of Artificial Neural Networks and their\ninteractions with Artificial Teachers (ATs)\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 00:10:50 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 22:36:52 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2020 17:19:26 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Garc\u00eda-Camino", "Andr\u00e9s", ""]]}, {"id": "1912.13157", "submitter": "Ehsan Khodabandeh", "authors": "Ehsan Khodabandeh, Lawrence V. Snyder, John Dennis, Joshua Hammond,\n  Cody Wanless", "title": "C. H. Robinson Uses Heuristics to Solve Rich Vehicle Routing Problems", "comments": "12 pages, 3 figures, and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a wide family of vehicle routing problem variants with many\ncomplex and practical constraints, known as rich vehicle routing problems,\nwhich are faced on a daily basis by C.H. Robinson (CHR). Since CHR has many\ncustomers, each with distinct requirements, various routing problems with\ndifferent objectives and constraints should be solved. We propose a set\npartitioning framework with a number of route generation algorithms, which have\nshown to be effective in solving a variety of different problems. The proposed\nalgorithms have outperformed the existing technologies at CHR on 10 benchmark\ninstances and since, have been embedded into the company's transportation\nplanning and execution technology platform.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 03:24:46 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Khodabandeh", "Ehsan", ""], ["Snyder", "Lawrence V.", ""], ["Dennis", "John", ""], ["Hammond", "Joshua", ""], ["Wanless", "Cody", ""]]}, {"id": "1912.13186", "submitter": "Robert B. Allen", "authors": "Robert B. Allen", "title": "Definitions and Semantic Simulations Based on Object-Oriented Analysis\n  and Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have proposed going beyond traditional ontologies to use rich semantics\nimplemented in programming languages for modeling. In this paper, we discuss\nthe application of executable semantic models to two examples, first a\nstructured definition of a waterfall and second the cardiopulmonary system. We\nexamine the components of these models and the way those components interact.\nUltimately, such models should provide the basis for direct representation.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 05:59:02 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Allen", "Robert B.", ""]]}, {"id": "1912.13230", "submitter": "Vahid Noroozi", "authors": "Vahid Noroozi, Sara Bahaadini, Samira Sheikhi, Nooshin Mojab, Philip\n  S. Yu", "title": "Leveraging Semi-Supervised Learning for Fairness using Neural Networks", "comments": "6 pages, 5 figures, accepted to ICMLA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a growing concern about the fairness of decision-making\nsystems based on machine learning. The shortage of labeled data has been always\na challenging problem facing machine learning based systems. In such scenarios,\nsemi-supervised learning has shown to be an effective way of exploiting\nunlabeled data to improve upon the performance of model. Notably, unlabeled\ndata do not contain label information which itself can be a significant source\nof bias in training machine learning systems. This inspired us to tackle the\nchallenge of fairness by formulating the problem in a semi-supervised\nframework. In this paper, we propose a semi-supervised algorithm using neural\nnetworks benefiting from unlabeled data to not just improve the performance but\nalso improve the fairness of the decision-making process. The proposed model,\ncalled SSFair, exploits the information in the unlabeled data to mitigate the\nbias in the training data.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 09:11:26 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Noroozi", "Vahid", ""], ["Bahaadini", "Sara", ""], ["Sheikhi", "Samira", ""], ["Mojab", "Nooshin", ""], ["Yu", "Philip S.", ""]]}, {"id": "1912.13263", "submitter": "Gianluca Baldassarre PhD", "authors": "Gianluca Baldassarre", "title": "Intrinsic motivations and open-ended learning", "comments": "24 pages, 2 figures, 2 tables, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest and literature on intrinsic motivations and\nopen-ended learning in both cognitive robotics and machine learning on one\nside, and in psychology and neuroscience on the other. This paper aims to\nreview some relevant contributions from the two literature threads and to draw\nlinks between them. To this purpose, the paper starts by defining intrinsic\nmotivations and by presenting a computationally-driven theoretical taxonomy of\ntheir different types. Then it presents relevant contributions from the\npsychological and neuroscientific literature related to intrinsic motivations,\ninterpreting them based on the grid, and elucidates the mechanisms and\nfunctions they play in animals and humans. Endowed with such concepts and their\nbiological underpinnings, the paper next presents a selection of models from\ncognitive robotics and machine learning that computationally operationalise the\nconcepts of intrinsic motivations and links them to biology concepts. The\ncontribution finally presents some of the open challenges of the field from\nboth the psychological/neuroscientific and computational perspectives.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 10:56:02 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Baldassarre", "Gianluca", ""]]}, {"id": "1912.13283", "submitter": "Alon Talmor", "authors": "Alon Talmor, Yanai Elazar, Yoav Goldberg, Jonathan Berant", "title": "oLMpics -- On what Language Model Pre-training Captures", "comments": "TACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent success of pre-trained language models (LMs) has spurred widespread\ninterest in the language capabilities that they possess. However, efforts to\nunderstand whether LM representations are useful for symbolic reasoning tasks\nhave been limited and scattered. In this work, we propose eight reasoning\ntasks, which conceptually require operations such as comparison, conjunction,\nand composition. A fundamental challenge is to understand whether the\nperformance of a LM on a task should be attributed to the pre-trained\nrepresentations or to the process of fine-tuning on the task data. To address\nthis, we propose an evaluation protocol that includes both zero-shot evaluation\n(no fine-tuning), as well as comparing the learning curve of a fine-tuned LM to\nthe learning curve of multiple controls, which paints a rich picture of the LM\ncapabilities. Our main findings are that: (a) different LMs exhibit\nqualitatively different reasoning abilities, e.g., RoBERTa succeeds in\nreasoning tasks where BERT fails completely; (b) LMs do not reason in an\nabstract manner and are context-dependent, e.g., while RoBERTa can compare\nages, it can do so only when the ages are in the typical range of human ages;\n(c) On half of our reasoning tasks all models fail completely. Our findings and\ninfrastructure can help future work on designing new datasets, models and\nobjective functions for pre-training.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 12:11:35 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 08:24:06 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Talmor", "Alon", ""], ["Elazar", "Yanai", ""], ["Goldberg", "Yoav", ""], ["Berant", "Jonathan", ""]]}, {"id": "1912.13366", "submitter": "Seungcheol Park", "authors": "Seungcheol Park, Huiwen Xu, Taehun Kim, Inhwan Hwang, Kyung-Jun Kim\n  and U Kang", "title": "Fast and Accurate Transferability Measurement for Heterogeneous\n  Multivariate Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of heterogeneous source datasets with their classifiers, how can\nwe quickly find the most useful source dataset for a specific target task? We\naddress the problem of measuring transferability between source and target\ndatasets, where the source and the target have different feature spaces and\ndistributions. We propose Transmeter, a fast and accurate method to estimate\nthe transferability of two heterogeneous multivariate datasets. We address\nthree challenges in measuring transferability between two heterogeneous\nmultivariate datasets: reducing time, minimizing domain gap, and extracting\nmeaningful homogeneous representations. To overcome the above issues, we\nutilize a pre-trained source model, an adversarial network, and an\nencoder-decoder architecture. Extensive experiments on heterogeneous\nmultivariate datasets show that Transmeter gives the most accurate\ntransferability measurement with up to 10.3 times faster performance than its\ncompetitor. We also show that selecting the best source data with Transmeter\nfollowed by a full transfer leads to the best transfer accuracy and the fastest\nrunning time.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 18:42:17 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 09:25:12 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Park", "Seungcheol", ""], ["Xu", "Huiwen", ""], ["Kim", "Taehun", ""], ["Hwang", "Inhwan", ""], ["Kim", "Kyung-Jun", ""], ["Kang", "U", ""]]}, {"id": "1912.13380", "submitter": "Momme Von Sydow", "authors": "Momme von Sydow (1), Christoph Merdes (2), Ulrike Hahn (3) ((1)\n  Ludwig-Maximilians-Universit\\\"at M\\\"unchen, MCMP, Germany, (2) Friedrich\n  Alexander University Erlangen-N\\\"urnberg, ZiWiS, Erlangen, Germany, (3)\n  Birkbeck College London, Department of Psychological Science, London)", "title": "The Temporal Dynamics of Belief-based Updating of Epistemic Trust: Light\n  at the End of the Tunnel?", "comments": "7 pages, 6 figures. The paper was presented 2019 at the TeaP in\n  London and at the 41st Annual Meeting of the Cognitive Science Society in\n  Montreal (Canada). We intend to submit an extended and improved version for\n  publication in a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We start with the distinction of outcome- and belief-based Bayesian models of\nthe sequential update of agents' beliefs and subjective reliability of sources\n(trust). We then focus on discussing the influential Bayesian model of\nbelief-based trust update by Eric Olsson, which models dichotomic events and\nexplicitly represents anti-reliability. After sketching some disastrous recent\nresults for this perhaps most promising model of belief update, we show new\nsimulation results for the temporal dynamics of learning belief with and\nwithout trust update and with and without communication. The results seem to\nshed at least a somewhat more positive light on the\ncommunicating-and-trust-updating agents. This may be a light at the end of the\ntunnel of belief-based models of trust updating, but the interpretation of the\nclear findings is much less clear.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 15:36:12 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["von Sydow", "Momme", ""], ["Merdes", "Christoph", ""], ["Hahn", "Ulrike", ""]]}, {"id": "1912.13405", "submitter": "Jesse Read", "authors": "Jesse Read, Bernhard Pfahringer, Geoff Holmes, Eibe Frank", "title": "Classifier Chains: A Review and Perspectives", "comments": null, "journal-ref": "Journal of Artificial Intelligence Research 70 (2021) 683-718", "doi": "10.1613/jair.1.12376", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The family of methods collectively known as classifier chains has become a\npopular approach to multi-label learning problems. This approach involves\nlinking together off-the-shelf binary classifiers in a chain structure, such\nthat class label predictions become features for other classifiers. Such\nmethods have proved flexible and effective and have obtained state-of-the-art\nempirical performance across many datasets and multi-label evaluation metrics.\nThis performance led to further studies of how exactly it works, and how it\ncould be improved, and in the recent decade numerous studies have explored\nclassifier chains mechanisms on a theoretical level, and many improvements have\nbeen made to the training and inference procedures, such that this method\nremains among the state-of-the-art options for multi-label learning. Given this\npast and ongoing interest, which covers a broad range of applications and\nresearch themes, the goal of this work is to provide a review of classifier\nchains, a survey of the techniques and extensions provided in the literature,\nas well as perspectives for this approach in the domain of multi-label\nclassification in the future. We conclude positively, with a number of\nrecommendations for researchers and practitioners, as well as outlining a\nnumber of areas for future research.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 11:44:54 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 11:36:27 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Read", "Jesse", ""], ["Pfahringer", "Bernhard", ""], ["Holmes", "Geoff", ""], ["Frank", "Eibe", ""]]}, {"id": "1912.13414", "submitter": "Xingyu Lu", "authors": "Xingyu Lu, Stas Tiomkin, Pieter Abbeel", "title": "Predictive Coding for Boosting Deep Reinforcement Learning with Sparse\n  Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent progress in deep reinforcement learning has enabled robots to\nlearn complex behaviors, tasks with long horizons and sparse rewards remain an\nongoing challenge. In this work, we propose an effective reward shaping method\nthrough predictive coding to tackle sparse reward problems. By learning\npredictive representations offline and using these representations for reward\nshaping, we gain access to reward signals that understand the structure and\ndynamics of the environment. In particular, our method achieves better learning\nby providing reward signals that 1) understand environment dynamics 2)\nemphasize on features most useful for learning 3) resist noise in learned\nrepresentations through reward accumulation. We demonstrate the usefulness of\nthis approach in different domains ranging from robotic manipulation to\nnavigation, and we show that reward signals produced through predictive coding\nare as effective for learning as hand-crafted rewards.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 03:32:00 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 01:28:14 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Lu", "Xingyu", ""], ["Tiomkin", "Stas", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1912.13430", "submitter": "Alberto Camacho", "authors": "Alberto Camacho, Sheila A. McIlraith", "title": "Towards Neural-Guided Program Synthesis for Linear Temporal Logic\n  Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL cs.GT cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesizing a program that realizes a logical specification is a classical\nproblem in computer science. We examine a particular type of program synthesis,\nwhere the objective is to synthesize a strategy that reacts to a potentially\nadversarial environment while ensuring that all executions satisfy a Linear\nTemporal Logic (LTL) specification. Unfortunately, exact methods to solve\nso-called LTL synthesis via logical inference do not scale. In this work, we\ncast LTL synthesis as an optimization problem. We employ a neural network to\nlearn a Q-function that is then used to guide search, and to construct programs\nthat are subsequently verified for correctness. Our method is unique in\ncombining search with deep learning to realize LTL synthesis. In our\nexperiments the learned Q-function provides effective guidance for synthesis\nproblems with relatively small specifications.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 17:09:49 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Camacho", "Alberto", ""], ["McIlraith", "Sheila A.", ""]]}, {"id": "1912.13490", "submitter": "Gianluca Baldassarre PhD", "authors": "Gianluca Baldassarre and Giovanni Granato", "title": "Representation Internal-Manipulation (RIM): A Neuro-Inspired\n  Computational Theory of Consciousness", "comments": "16 pages, 5 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many theories, based on neuroscientific and psychological empirical evidence\nand on computational concepts, have been elaborated to explain the emergence of\nconsciousness in the central nervous system. These theories propose key\nfundamental mechanisms to explain consciousness, but they only partially\nconnect such mechanisms to the possible functional and adaptive role of\nconsciousness. Recently, some cognitive and neuroscientific models try to solve\nthis gap by linking consciousness to various aspects of goal-directed\nbehaviour, the pivotal cognitive process that allows mammals to flexibly act in\nchallenging environments. Here we propose the Representation\nInternal-Manipulation (RIM) theory of consciousness, a theory that links the\nmain elements of consciousness theories to components and functions of\ngoal-directed behaviour, ascribing a central role for consciousness to the\ngoal-directed manipulation of internal representations. This manipulation\nrelies on four specific computational operations to perform the flexible\ninternal adaptation of all key elements of goal-directed computation, from the\nrepresentations of objects to those of goals, actions, and plans. Finally, we\npropose the concept of `manipulation agency' relating the sense of agency to\nthe internal manipulation of representations. This allows us to propose that\nthe subjective experience of consciousness is associated to the human capacity\nto generate and control a simulated internal reality that is vividly perceived\nand felt through the same perceptual and emotional mechanisms used to tackle\nthe external world.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 18:45:33 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Baldassarre", "Gianluca", ""], ["Granato", "Giovanni", ""]]}]