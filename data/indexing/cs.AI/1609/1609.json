[{"id": "1609.00030", "submitter": "Marcello Balduccini", "authors": "Marcello Balduccini, Daniele Magazzeni, Marco Maratea", "title": "PDDL+ Planning via Constraint Answer Set Programming", "comments": "Paper presented at the 9th Workshop on Answer Set Programming and\n  Other Computing Paradigms (ASPOCP 2016), New York City, USA, 16 October 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PDDL+ is an extension of PDDL that enables modelling planning domains with\nmixed discrete-continuous dynamics. In this paper we present a new approach to\nPDDL+ planning based on Constraint Answer Set Programming (CASP), i.e. ASP\nrules plus numerical constraints. To the best of our knowledge, ours is the\nfirst attempt to link PDDL+ planning and logic programming. We provide an\nencoding of PDDL+ models into CASP problems. The encoding can handle non-linear\nhybrid domains, and represents a solid basis for applying logic programming to\nPDDL+ planning. As a case study, we consider the EZCSP CASP solver and obtain\npromising results on a set of PDDL+ benchmark problems.\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2016 20:38:30 GMT"}], "update_date": "2016-09-02", "authors_parsed": [["Balduccini", "Marcello", ""], ["Magazzeni", "Daniele", ""], ["Maratea", "Marco", ""]]}, {"id": "1609.00036", "submitter": "Amogh Gudi", "authors": "Agne Grinciunaite, Amogh Gudi, Emrah Tasli, Marten den Uyl", "title": "Human Pose Estimation in Space and Time using 3D CNN", "comments": "Accepted at ECCV 2016 Workshop on: Brave new ideas for motion\n  representations in videos", "journal-ref": null, "doi": "10.1007/978-3-319-49409-8_5", "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the capabilities of convolutional neural networks to deal\nwith a task that is easily manageable for humans: perceiving 3D pose of a human\nbody from varying angles. However, in our approach, we are restricted to using\na monocular vision system. For this purpose, we apply a convolutional neural\nnetwork approach on RGB videos and extend it to three dimensional convolutions.\nThis is done via encoding the time dimension in videos as the 3\\ts{rd}\ndimension in convolutional space, and directly regressing to human body joint\npositions in 3D coordinate space. This research shows the ability of such a\nnetwork to achieve state-of-the-art performance on the selected Human3.6M\ndataset, thus demonstrating the possibility of successfully representing\ntemporal data with an additional dimension in the convolutional operation.\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2016 20:55:26 GMT"}, {"version": "v2", "created": "Wed, 14 Sep 2016 16:17:15 GMT"}, {"version": "v3", "created": "Wed, 19 Oct 2016 12:44:15 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Grinciunaite", "Agne", ""], ["Gudi", "Amogh", ""], ["Tasli", "Emrah", ""], ["Uyl", "Marten den", ""]]}, {"id": "1609.00085", "submitter": "Rajasekar Venkatesan", "authors": "Rajasekar Venkatesan, Meng Joo Er", "title": "A Novel Progressive Learning Technique for Multi-class Classification", "comments": "23 pages, 13 tables, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a progressive learning technique for multi-class\nclassification is proposed. This newly developed learning technique is\nindependent of the number of class constraints and it can learn new classes\nwhile still retaining the knowledge of previous classes. Whenever a new class\n(non-native to the knowledge learnt thus far) is encountered, the neural\nnetwork structure gets remodeled automatically by facilitating new neurons and\ninterconnections, and the parameters are calculated in such a way that it\nretains the knowledge learnt thus far. This technique is suitable for\nreal-world applications where the number of classes is often unknown and online\nlearning from real-time data is required. The consistency and the complexity of\nthe progressive learning technique are analyzed. Several standard datasets are\nused to evaluate the performance of the developed technique. A comparative\nstudy shows that the developed technique is superior.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 01:50:18 GMT"}, {"version": "v2", "created": "Sun, 22 Jan 2017 09:52:06 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Venkatesan", "Rajasekar", ""], ["Er", "Meng Joo", ""]]}, {"id": "1609.00086", "submitter": "Rajasekar Venkatesan", "authors": "Rajasekar Venkatesan, Meng Joo Er, Mihika Dave, Mahardhika Pratama,\n  Shiqian Wu", "title": "A novel online multi-label classifier for high-speed streaming data\n  applications", "comments": "18 pages, 7 tables, 3 figures. arXiv admin note: text overlap with\n  arXiv:1608.08898", "journal-ref": null, "doi": "10.1007/s12530-016-9162-8", "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a high-speed online neural network classifier based on extreme\nlearning machines for multi-label classification is proposed. In multi-label\nclassification, each of the input data sample belongs to one or more than one\nof the target labels. The traditional binary and multi-class classification\nwhere each sample belongs to only one target class forms the subset of\nmulti-label classification. Multi-label classification problems are far more\ncomplex than binary and multi-class classification problems, as both the number\nof target labels and each of the target labels corresponding to each of the\ninput samples are to be identified. The proposed work exploits the high-speed\nnature of the extreme learning machines to achieve real-time multi-label\nclassification of streaming data. A new threshold-based online sequential\nlearning algorithm is proposed for high speed and streaming data classification\nof multi-label problems. The proposed method is experimented with six different\ndatasets from different application domains such as multimedia, text, and\nbiology. The hamming loss, accuracy, training time and testing time of the\nproposed technique is compared with nine different state-of-the-art methods.\nExperimental studies shows that the proposed technique outperforms the existing\nmulti-label classifiers in terms of performance and speed.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 01:58:50 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Venkatesan", "Rajasekar", ""], ["Er", "Meng Joo", ""], ["Dave", "Mihika", ""], ["Pratama", "Mahardhika", ""], ["Wu", "Shiqian", ""]]}, {"id": "1609.00116", "submitter": "Martin  Biehl", "authors": "Nicholas Guttenberg, Martin Biehl, Ryota Kanai", "title": "Neural Coarse-Graining: Extracting slowly-varying latent degrees of\n  freedom with neural networks", "comments": "9 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a loss function for neural networks that encompasses an idea of\ntrivial versus non-trivial predictions, such that the network jointly\ndetermines its own prediction goals and learns to satisfy them. This permits\nthe network to choose sub-sets of a problem which are most amenable to its\nabilities to focus on solving, while discarding 'distracting' elements that\ninterfere with its learning. To do this, the network first transforms the raw\ndata into a higher-level categorical representation, and then trains a\npredictor from that new time series to its future. To prevent a trivial\nsolution of mapping the signal to zero, we introduce a measure of\nnon-triviality via a contrast between the prediction error of the learned model\nwith a naive model of the overall signal statistics. The transform can learn to\ndiscard uninformative and unpredictable components of the signal in favor of\nthe features which are both highly predictive and highly predictable. This\ncreates a coarse-grained model of the time-series dynamics, focusing on\npredicting the slowly varying latent parameters which control the statistics of\nthe time-series, rather than predicting the fast details directly. The result\nis a semi-supervised algorithm which is capable of extracting latent\nparameters, segmenting sections of time-series with differing statistics, and\nbuilding a higher-level representation of the underlying dynamics from\nunlabeled data.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 05:34:23 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Guttenberg", "Nicholas", ""], ["Biehl", "Martin", ""], ["Kanai", "Ryota", ""]]}, {"id": "1609.00149", "submitter": "Giuseppe Pirr\\'o", "authors": "Valeria Fionda, Giuseppe Pirr\\`o", "title": "From Community Detection to Community Deception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The community deception problem is about how to hide a target community C\nfrom community detection algorithms. The need for deception emerges whenever a\ngroup of entities (e.g., activists, police enforcements) want to cooperate\nwhile concealing their existence as a community. In this paper we introduce and\nformalize the community deception problem. To solve this problem, we describe\nalgorithms that carefully rewire the connections of C's members. We\nexperimentally show how several existing community detection algorithms can be\ndeceived, and quantify the level of deception by introducing a deception score.\nWe believe that our study is intriguing since, while showing how deception can\nbe realized it raises awareness for the design of novel detection algorithms\nrobust to deception techniques.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 08:58:51 GMT"}], "update_date": "2016-09-02", "authors_parsed": [["Fionda", "Valeria", ""], ["Pirr\u00f2", "Giuseppe", ""]]}, {"id": "1609.00222", "submitter": "Hande Alemdar", "authors": "Hande Alemdar and Vincent Leroy and Adrien Prost-Boucle and\n  Fr\\'ed\\'eric P\\'etrot", "title": "Ternary Neural Networks for Resource-Efficient AI Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation and storage requirements for Deep Neural Networks (DNNs) are\nusually high. This issue limits their deployability on ubiquitous computing\ndevices such as smart phones, wearables and autonomous drones. In this paper,\nwe propose ternary neural networks (TNNs) in order to make deep learning more\nresource-efficient. We train these TNNs using a teacher-student approach based\non a novel, layer-wise greedy methodology. Thanks to our two-stage training\nprocedure, the teacher network is still able to use state-of-the-art methods\nsuch as dropout and batch normalization to increase accuracy and reduce\ntraining time. Using only ternary weights and activations, the student ternary\nnetwork learns to mimic the behavior of its teacher network without using any\nmultiplication. Unlike its -1,1 binary counterparts, a ternary neural network\ninherently prunes the smaller weights by setting them to zero during training.\nThis makes them sparser and thus more energy-efficient. We design a\npurpose-built hardware architecture for TNNs and implement it on FPGA and ASIC.\nWe evaluate TNNs on several benchmark datasets and demonstrate up to 3.1x\nbetter energy efficiency with respect to the state of the art while also\nimproving accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 13:08:47 GMT"}, {"version": "v2", "created": "Sun, 26 Feb 2017 09:44:34 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Alemdar", "Hande", ""], ["Leroy", "Vincent", ""], ["Prost-Boucle", "Adrien", ""], ["P\u00e9trot", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1609.00292", "submitter": "Zhi-Hua Zhou", "authors": "Yao-Xiang Ding and Zhi-Hua Zhou", "title": "Crowdsourcing with Unsure Option", "comments": "25 pages, 1 figures", "journal-ref": "Machine Learning, 2018, 107(4): 749-766", "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the fundamental problems in crowdsourcing is the trade-off between the\nnumber of the workers needed for high-accuracy aggregation and the budget to\npay. For saving budget, it is important to ensure high quality of the\ncrowd-sourced labels, hence the total cost on label collection will be reduced.\nSince the self-confidence of the workers often has a close relationship with\ntheir abilities, a possible way for quality control is to request the workers\nto return the labels only when they feel confident, by means of providing\nunsure option to them. On the other hand, allowing workers to choose unsure\noption also leads to the potential danger of budget waste. In this work, we\npropose the analysis towards understanding when providing the unsure option\nindeed leads to significant cost reduction, as well as how the confidence\nthreshold is set. We also propose an online mechanism, which is alternative for\nthreshold selection when the estimation of the crowd ability distribution is\ndifficult.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 15:53:52 GMT"}, {"version": "v2", "created": "Sat, 12 Aug 2017 12:03:32 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Ding", "Yao-Xiang", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1609.00331", "submitter": "Roman Yampolskiy", "authors": "Roman V. Yampolskiy", "title": "Verifier Theory and Unverifiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant developments in Proof Theory, surprisingly little\nattention has been devoted to the concept of proof verifier. In particular, the\nmathematical community may be interested in studying different types of proof\nverifiers (people, programs, oracles, communities, superintelligences) as\nmathematical objects. Such an effort could reveal their properties, their\npowers and limitations (particularly in human mathematicians), minimum and\nmaximum complexity, as well as self-verification and self-reference issues. We\npropose an initial classification system for verifiers and provide some\nrudimentary analysis of solved and open problems in this important domain. Our\nmain contribution is a formal introduction of the notion of unverifiability,\nfor which the paper could serve as a general citation in domains of theorem\nproving, as well as software and AI verification.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 18:10:23 GMT"}, {"version": "v2", "created": "Thu, 8 Sep 2016 21:18:29 GMT"}, {"version": "v3", "created": "Tue, 25 Oct 2016 18:21:14 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Yampolskiy", "Roman V.", ""]]}, {"id": "1609.00462", "submitter": "Markus Wagner", "authors": "Markus Wagner, Marius Lindauer, Mustafa Misir, Samadhi Nallaperuma,\n  Frank Hutter", "title": "A case study of algorithm selection for the traveling thief problem", "comments": "23 pages, this article is underview", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems are composed of several interacting components. In\norder to facilitate research on such interactions, the Traveling Thief Problem\n(TTP) was created in 2013 as the combination of two well-understood\ncombinatorial optimization problems.\n  With this article, we contribute in four ways. First, we create a\ncomprehensive dataset that comprises the performance data of 21 TTP algorithms\non the full original set of 9720 TTP instances. Second, we define 55\ncharacteristics for all TPP instances that can be used to select the best\nalgorithm on a per-instance basis. Third, we use these algorithms and features\nto construct the first algorithm portfolios for TTP, clearly outperforming the\nsingle best algorithm. Finally, we study which algorithms contribute most to\nthis portfolio.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 04:03:22 GMT"}], "update_date": "2016-09-05", "authors_parsed": [["Wagner", "Markus", ""], ["Lindauer", "Marius", ""], ["Misir", "Mustafa", ""], ["Nallaperuma", "Samadhi", ""], ["Hutter", "Frank", ""]]}, {"id": "1609.00464", "submitter": "Trey Grainger", "authors": "Trey Grainger, Khalifeh AlJadda, Mohammed Korayem, Andries Smith", "title": "The Semantic Knowledge Graph: A compact, auto-generated model for\n  real-time traversal and ranking of any relationship within a domain", "comments": "Accepted for publication in 2016 IEEE 3rd International Conference on\n  Data Science and Advanced Analytics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new kind of knowledge representation and mining system\nwhich we are calling the Semantic Knowledge Graph. At its heart, the Semantic\nKnowledge Graph leverages an inverted index, along with a complementary\nuninverted index, to represent nodes (terms) and edges (the documents within\nintersecting postings lists for multiple terms/nodes). This provides a layer of\nindirection between each pair of nodes and their corresponding edge, enabling\nedges to materialize dynamically from underlying corpus statistics. As a\nresult, any combination of nodes can have edges to any other nodes materialize\nand be scored to reveal latent relationships between the nodes. This provides\nnumerous benefits: the knowledge graph can be built automatically from a\nreal-world corpus of data, new nodes - along with their combined edges - can be\ninstantly materialized from any arbitrary combination of preexisting nodes\n(using set operations), and a full model of the semantic relationships between\nall entities within a domain can be represented and dynamically traversed using\na highly compact representation of the graph. Such a system has widespread\napplications in areas as diverse as knowledge modeling and reasoning, natural\nlanguage processing, anomaly detection, data cleansing, semantic search,\nanalytics, data classification, root cause analysis, and recommendations\nsystems. The main contribution of this paper is the introduction of a novel\nsystem - the Semantic Knowledge Graph - which is able to dynamically discover\nand score interesting relationships between any arbitrary combination of\nentities (words, phrases, or extracted concepts) through dynamically\nmaterializing nodes and edges from a compact graphical representation built\nautomatically from a corpus of data representative of a knowledge domain.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 04:26:54 GMT"}, {"version": "v2", "created": "Mon, 5 Sep 2016 15:06:45 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Grainger", "Trey", ""], ["AlJadda", "Khalifeh", ""], ["Korayem", "Mohammed", ""], ["Smith", "Andries", ""]]}, {"id": "1609.00759", "submitter": "Jo Devriendt", "authors": "San Pham, Jo Devriendt, Maurice Bruynooghe, Patrick De Causmaecker", "title": "A MIP Backend for the IDP System", "comments": "internal report, 10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The IDP knowledge base system currently uses MiniSAT(ID) as its backend\nConstraint Programming (CP) solver. A few similar systems have used a Mixed\nInteger Programming (MIP) solver as backend. However, so far little is known\nabout when the MIP solver is preferable. This paper explores this question. It\ndescribes the use of CPLEX as a backend for IDP and reports on experiments\ncomparing both backends.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 22:20:05 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Pham", "San", ""], ["Devriendt", "Jo", ""], ["Bruynooghe", "Maurice", ""], ["De Causmaecker", "Patrick", ""]]}, {"id": "1609.00843", "submitter": "Rajasekar Venkatesan", "authors": "Meng Joo Er, Rajasekar Venkatesan, Ning Wang", "title": "An Online Universal Classifier for Binary, Multi-class and Multi-label\n  Classification", "comments": "6 pages, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification involves the learning of the mapping function that associates\ninput samples to corresponding target label. There are two major categories of\nclassification problems: Single-label classification and Multi-label\nclassification. Traditional binary and multi-class classifications are\nsub-categories of single-label classification. Several classifiers are\ndeveloped for binary, multi-class and multi-label classification problems, but\nthere are no classifiers available in the literature capable of performing all\nthree types of classification. In this paper, a novel online universal\nclassifier capable of performing all the three types of classification is\nproposed. Being a high speed online classifier, the proposed technique can be\napplied to streaming data applications. The performance of the developed\nclassifier is evaluated using datasets from binary, multi-class and multi-label\nproblems. The results obtained are compared with state-of-the-art techniques\nfrom each of the classification types.\n", "versions": [{"version": "v1", "created": "Sat, 3 Sep 2016 17:03:14 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Er", "Meng Joo", ""], ["Venkatesan", "Rajasekar", ""], ["Wang", "Ning", ""]]}, {"id": "1609.00904", "submitter": "Eric Holloway", "authors": "Eric Holloway and Robert Marks II", "title": "High Dimensional Human Guided Machine Learning", "comments": "3 pages, 1 figure, HCOMP 2016 submission, work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Have you ever looked at a machine learning classification model and thought,\nI could have made that? Well, that is what we test in this project, comparing\nXGBoost trained on human engineered features to training directly on data. The\nhuman engineered features do not outperform XGBoost trained di- rectly on the\ndata, but they are comparable. This project con- tributes a novel method for\nutilizing human created classifi- cation models on high dimensional datasets.\n", "versions": [{"version": "v1", "created": "Sun, 4 Sep 2016 08:45:26 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Holloway", "Eric", ""], ["Marks", "Robert", "II"]]}, {"id": "1609.00932", "submitter": "Hao Wu", "authors": "Hao Wu and Frank No\\'e", "title": "Spectral learning of dynamic systems from nonequilibrium data", "comments": null, "journal-ref": "Proceedings of the 29th conference on Neural Information\n  Processing Systems (NIPS), Barcelona, Spain, 2016, pp. 4179-4187", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY math.PR physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observable operator models (OOMs) and related models are one of the most\nimportant and powerful tools for modeling and analyzing stochastic systems.\nThey exactly describe dynamics of finite-rank systems and can be efficiently\nand consistently estimated through spectral learning under the assumption of\nidentically distributed data. In this paper, we investigate the properties of\nspectral learning without this assumption due to the requirements of analyzing\nlarge-time scale systems, and show that the equilibrium dynamics of a system\ncan be extracted from nonequilibrium observation data by imposing an\nequilibrium constraint. In addition, we propose a binless extension of spectral\nlearning for continuous data. In comparison with the other continuous-valued\nspectral algorithms, the binless algorithm can achieve consistent estimation of\nequilibrium dynamics with only linear complexity.\n", "versions": [{"version": "v1", "created": "Sun, 4 Sep 2016 13:31:36 GMT"}, {"version": "v2", "created": "Tue, 20 Jun 2017 20:30:33 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Wu", "Hao", ""], ["No\u00e9", "Frank", ""]]}, {"id": "1609.01459", "submitter": "Emmanuel Osegi", "authors": "Emmanuel Ndidi Osegi (NOUN), Vincent Ike Anireh", "title": "Deviant Learning Algorithm: Learning Sparse Mismatch Representations\n  through Time and Space", "comments": "Working Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Predictive coding (PDC) has recently attracted attention in the neuroscience\nand computing community as a candidate unifying paradigm for neuronal studies\nand artificial neural network implementations particularly targeted at\nunsupervised learning systems. The Mismatch Negativity (MMN) has also recently\nbeen studied in relation to PC and found to be a useful ingredient in neural\npredictive coding systems. Backed by the behavior of living organisms, such\nnetworks are particularly useful in forming spatio-temporal transitions and\ninvariant representations of the input world. However, most neural systems\nstill do not account for large number of synapses even though this has been\nshown by a few machine learning researchers as an effective and very important\ncomponent of any neural system if such a system is to behave properly. Our\nmajor point here is that PDC systems with the MMN effect in addition to a large\nnumber of synapses can greatly improve any neural learning system's performance\nand ability to make decisions in the machine world. In this paper, we propose a\nnovel bio-mimetic computational intelligence algorithm -- the Deviant Learning\nAlgorithm, inspired by these key ideas and functional properties of recent\nbrain-cognitive discoveries and theories. We also show by numerical experiments\nguided by theoretical insights, how our invented bio-mimetic algorithm can\nachieve competitive predictions even with very small problem specific data.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 09:35:14 GMT"}, {"version": "v2", "created": "Wed, 7 Sep 2016 09:20:09 GMT"}, {"version": "v3", "created": "Tue, 6 Dec 2016 18:53:24 GMT"}, {"version": "v4", "created": "Wed, 7 Dec 2016 20:55:33 GMT"}, {"version": "v5", "created": "Sun, 1 Jan 2017 11:26:06 GMT"}, {"version": "v6", "created": "Tue, 3 Jan 2017 02:49:15 GMT"}], "update_date": "2017-01-04", "authors_parsed": [["Osegi", "Emmanuel Ndidi", "", "NOUN"], ["Anireh", "Vincent Ike", ""]]}, {"id": "1609.01468", "submitter": "Kardi Teknomo", "authors": "Wilfredo Badoy Jr. and Kardi Teknomo", "title": "Q-Learning with Basic Emotions", "comments": "7 pages, Badoy, W. and Teknomo, K. (2014) Q-Learning with Basic\n  Emotions, Proceeding of the 7th IEEE International Conference Humanoid,\n  Nanotechnology, Information Technology Communication and Control, Environment\n  and Management (HNICEM) 12-16 November 2014 Hotel Centro, Puerto Princesa,\n  Palawan, Philippines", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Q-learning is a simple and powerful tool in solving dynamic problems where\nenvironments are unknown. It uses a balance of exploration and exploitation to\nfind an optimal solution to the problem. In this paper, we propose using four\nbasic emotions: joy, sadness, fear, and anger to influence a Qlearning agent.\nSimulations show that the proposed affective agent requires lesser number of\nsteps to find the optimal path. We found when affective agent finds the optimal\npath, the ratio between exploration to exploitation gradually decreases,\nindicating lower total step count in the long run\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 10:03:27 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Badoy", "Wilfredo", "Jr."], ["Teknomo", "Kardi", ""]]}, {"id": "1609.01472", "submitter": "Kardi Teknomo", "authors": "Chelcie Narboneta and Kardi Teknomo", "title": "OpenTripPlanner, OpenStreetMap, General Transit Feed Specification:\n  Tools for Disaster Relief and Recovery", "comments": "6 pages, Narboneta, C. G. and Teknomo, K. (2014) OpenTripPlanner,\n  OpenStreetMap, General Transit Feed Specification: Tools for Disaster Relief\n  and Recovery, Proceeding of the 7th IEEE International Conference Humanoid,\n  Nanotechnology, Information Technology Communication and Control, Environment\n  and Management (HNICEM) 12-16 November 2014 Hotel Centro, Puerto Princesa,\n  Palawan, Philippines", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open Trip Planner was identified as the most promising open source\nmulti-modal trip planning software. Open Street Map, which provides mapping\ndata to Open Trip Planner, is one of the most well-known open source\ninternational repository of geographic data. General Transit Feed\nSpecification, which provides transportation data to Open Trip Planner, has\nbeen the standard for describing transit systems and platform for numerous\napplications. Together, when used to implement an instance of Open Trip\nPlanner, these software has been helping in traffic decongestion all over the\nworld by assisting commuters to shift from using private transportation modes\nto public ones. Their potential however goes beyond providing multi-modal\npublic transportation routes. This paper aims to first discuss the researchers'\nexperience in implementing a public transportation route planner for the\npurpose of traffic decongestion.The researchers would examine the prospective\nof using the system for disaster preparedness and recovery and concrete ways on\nhow to realize them.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 10:11:27 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Narboneta", "Chelcie", ""], ["Teknomo", "Kardi", ""]]}, {"id": "1609.01475", "submitter": "Kardi Teknomo", "authors": "Allan Lao and Kardi Teknomo", "title": "Multi Exit Configuration of Mesoscopic Pedestrian Simulation", "comments": "7 pages, Lao, A. and Teknomo, K. (2014) Multi Exit Configuration of\n  Mesoscopic Pedestrian Simulation, Proceeding of the 12th National Conference\n  in Information Technology Education (NCITE 2014), October 23 - 25, 2014,\n  Boracay, Philippines", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mesoscopic approach to modeling pedestrian simulation with multiple exits\nis proposed in this paper. A floor field based on Qlearning Algorithm is used.\nAttractiveness of exits to pedestrian typically is based on shortest path.\nHowever, several factors may influence pedestrian choice of exits. Scenarios\nwith multiple exits are presented and effect of Q-learning rewards system on\nnavigation is investigated\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 10:18:25 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Lao", "Allan", ""], ["Teknomo", "Kardi", ""]]}, {"id": "1609.01493", "submitter": "Christoph Benzm\\\"uller", "authors": "Christoph Benzm\\\"uller and Dana S. Scott", "title": "Axiomatizing Category Theory in Free Logic", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Starting from a generalization of the standard axioms for a monoid we present\na stepwise development of various, mutually equivalent foundational axiom\nsystems for category theory. Our axiom sets have been formalized in the\nIsabelle/HOL interactive proof assistant, and this formalization utilizes a\nsemantically correct embedding of free logic in classical higher-order logic.\nThe modeling and formal analysis of our axiom sets has been significantly\nsupported by series of experiments with automated reasoning tools integrated\nwith Isabelle/HOL. We also address the relation of our axiom systems to\nalternative proposals from the literature, including an axiom set proposed by\nFreyd and Scedrov for which we reveal a technical issue (when encoded in free\nlogic where free variables range over defined and undefined objects): either\nall operations, e.g. morphism composition, are total or their axiom system is\ninconsistent. The repair for this problem is quite straightforward, however.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 11:30:37 GMT"}, {"version": "v2", "created": "Thu, 8 Sep 2016 13:43:00 GMT"}, {"version": "v3", "created": "Wed, 14 Sep 2016 13:54:59 GMT"}, {"version": "v4", "created": "Fri, 28 Apr 2017 04:45:54 GMT"}, {"version": "v5", "created": "Fri, 12 Oct 2018 09:33:18 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Benzm\u00fcller", "Christoph", ""], ["Scott", "Dana S.", ""]]}, {"id": "1609.01710", "submitter": "Kardi Teknomo", "authors": "Saman Saadat and Kardi Teknomo", "title": "Automation of Pedestrian Tracking in a Crowded Situation", "comments": "10 Pages, Saadat, S., and Teknomo, K., Automation of Pedestrian\n  Tracking in a Crowded Situation, the Fifth International Conference on\n  Pedestrian and Evacuation Dynamics, March 8-10, 2010, National Institute of\n  Standards and Technology, Gaithersburg, MD USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies on microscopic pedestrian requires large amounts of trajectory data\nfrom real-world pedestrian crowds. Such data collection, if done manually,\nneeds tremendous effort and is very time consuming. Though many studies have\nasserted the possibility of automating this task using video cameras, we found\nthat only a few have demonstrated good performance in very crowded situations\nor from a top-angled view scene. This paper deals with tracking pedestrian\ncrowd under heavy occlusions from an angular scene. Our automated tracking\nsystem consists of two modules that perform sequentially. The first module\ndetects moving objects as blobs. The second module is a tracking system. We\nemploy probability distribution from the detection of each pedestrian and use\nBayesian update to track the next position. The result of such tracking is a\ndatabase of pedestrian trajectories over time and space. With certain prior\ninformation, we showed that the system can track a large number of people under\nocclusion and clutter scene.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 10:36:23 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Saadat", "Saman", ""], ["Teknomo", "Kardi", ""]]}, {"id": "1609.01926", "submitter": "Giovanni Carmantini", "authors": "Giovanni Sirio Carmantini, Peter beim Graben, Mathieu Desroches,\n  Serafim Rodrigues", "title": "A modular architecture for transparent computation in Recurrent Neural\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2016.09.001", "report-no": null, "categories": "cs.NE cs.AI cs.CL cs.FL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation is classically studied in terms of automata, formal languages and\nalgorithms; yet, the relation between neural dynamics and symbolic\nrepresentations and operations is still unclear in traditional eliminative\nconnectionism. Therefore, we suggest a unique perspective on this central\nissue, to which we would like to refer as to transparent connectionism, by\nproposing accounts of how symbolic computation can be implemented in neural\nsubstrates. In this study we first introduce a new model of dynamics on a\nsymbolic space, the versatile shift, showing that it supports the real-time\nsimulation of a range of automata. We then show that the Goedelization of\nversatile shifts defines nonlinear dynamical automata, dynamical systems\nevolving on a vectorial space. Finally, we present a mapping between nonlinear\ndynamical automata and recurrent artificial neural networks. The mapping\ndefines an architecture characterized by its granular modularity, where data,\nsymbolic operations and their control are not only distinguishable in\nactivation space, but also spatially localizable in the network itself, while\nmaintaining a distributed encoding of symbolic representations. The resulting\nnetworks simulate automata in real-time and are programmed directly, in absence\nof network training. To discuss the unique characteristics of the architecture\nand their consequences, we present two examples: i) the design of a Central\nPattern Generator from a finite-state locomotive controller, and ii) the\ncreation of a network simulating a system of interactive automata that supports\nthe parsing of garden-path sentences as investigated in psycholinguistics\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 10:44:28 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Carmantini", "Giovanni Sirio", ""], ["Graben", "Peter beim", ""], ["Desroches", "Mathieu", ""], ["Rodrigues", "Serafim", ""]]}, {"id": "1609.01995", "submitter": "Martha White", "authors": "Martha White", "title": "Unifying task specification in reinforcement learning", "comments": "Modification of contraction result for weight dpi", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning tasks are typically specified as Markov decision\nprocesses. This formalism has been highly successful, though specifications\noften couple the dynamics of the environment and the learning objective. This\nlack of modularity can complicate generalization of the task specification, as\nwell as obfuscate connections between different task settings, such as episodic\nand continuing. In this work, we introduce the RL task formalism, that provides\na unification through simple constructs including a generalization to\ntransition-based discounting. Through a series of examples, we demonstrate the\ngenerality and utility of this formalism. Finally, we extend standard learning\nconstructs, including Bellman operators, and extend some seminal theoretical\nresults, including approximation errors bounds. Overall, we provide a\nwell-understood and sound formalism on which to build theoretical results and\nsimplify algorithm use and development.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 14:27:56 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 02:36:21 GMT"}, {"version": "v3", "created": "Fri, 7 Jul 2017 09:55:23 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["White", "Martha", ""]]}, {"id": "1609.02009", "submitter": "Telmo Menezes", "authors": "Telmo Menezes", "title": "Non-Evolutionary Superintelligences Do Nothing, Eventually", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is overwhelming evidence that human intelligence is a product of\nDarwinian evolution. Investigating the consequences of self-modification, and\nmore precisely, the consequences of utility function self-modification, leads\nto the stronger claim that not only human, but any form of intelligence is\nultimately only possible within evolutionary processes. Human-designed\nartificial intelligences can only remain stable until they discover how to\nmanipulate their own utility function. By definition, a human designer cannot\nprevent a superhuman intelligence from modifying itself, even if protection\nmechanisms against this action are put in place. Without evolutionary pressure,\nsufficiently advanced artificial intelligences become inert by simplifying\ntheir own utility function. Within evolutionary processes, the implicit utility\nfunction is always reducible to persistence, and the control of superhuman\nintelligences embedded in evolutionary processes is not possible. Mechanisms\nagainst utility function self-modification are ultimately futile. Instead,\nscientific effort toward the mitigation of existential risks from the\ndevelopment of superintelligences should be in two directions: understanding\nconsciousness, and the complex dynamics of evolutionary systems.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 15:06:18 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Menezes", "Telmo", ""]]}, {"id": "1609.02010", "submitter": "Pedro Cabalar", "authors": "Pedro Cabalar, Carlos P\\'erez, Gilberto P\\'erez", "title": "Equilibrium Graphs", "comments": "Paper presented at the 9th Workshop on Answer Set Programming and\n  Other Computing Paradigms (ASPOCP 2016), New York City, USA, 16 October 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an extension of Peirce's existential graphs to\nprovide a diagrammatic representation of expressions in Quantified Equilibrium\nLogic (QEL). Using this formalisation, logical connectives are replaced by\nencircled regions (circles and squares) and quantified variables are\nrepresented as \"identity\" lines. Although the expressive power is equivalent to\nthat of QEL, the new representation can be useful for illustrative or\neducational purposes.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 15:07:21 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Cabalar", "Pedro", ""], ["P\u00e9rez", "Carlos", ""], ["P\u00e9rez", "Gilberto", ""]]}, {"id": "1609.02036", "submitter": "Zhirong Wu", "authors": "Zhirong Wu, Dahua Lin, Xiaoou Tang", "title": "Deep Markov Random Field for Image Modeling", "comments": "Accepted at ECCV 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Random Fields (MRFs), a formulation widely used in generative image\nmodeling, have long been plagued by the lack of expressive power. This issue is\nprimarily due to the fact that conventional MRFs formulations tend to use\nsimplistic factors to capture local patterns. In this paper, we move beyond\nsuch limitations, and propose a novel MRF model that uses fully-connected\nneurons to express the complex interactions among pixels. Through theoretical\nanalysis, we reveal an inherent connection between this model and recurrent\nneural networks, and thereon derive an approximated feed-forward network that\ncouples multiple RNNs along opposite directions. This formulation combines the\nexpressive power of deep neural networks and the cyclic dependency structure of\nMRF in a unified model, bringing the modeling capability to a new level. The\nfeed-forward approximation also allows it to be efficiently learned from data.\nExperimental results on a variety of low-level vision tasks show notable\nimprovement over state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 15:56:36 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Wu", "Zhirong", ""], ["Lin", "Dahua", ""], ["Tang", "Xiaoou", ""]]}, {"id": "1609.02043", "submitter": "Shirish Karande", "authors": "Purushotam Radadia, Shirish Karande", "title": "Feasibility of Post-Editing Speech Transcriptions with a Mismatched\n  Crowd", "comments": "HCOMP 2016 Works-in-Progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manual correction of speech transcription can involve a selection from\nplausible transcriptions. Recent work has shown the feasibility of employing a\nmismatched crowd for speech transcription. However, it is yet to be established\nwhether a mismatched worker has sufficiently fine-granular speech perception to\nchoose among the phonetically proximate options that are likely to be generated\nfrom the trellis of an ASRU. Hence, we consider five languages, Arabic, German,\nHindi, Russian and Spanish. For each we generate synthetic, phonetically\nproximate, options which emulate post-editing scenarios of varying difficulty.\nWe consistently observe non-trivial crowd ability to choose among fine-granular\noptions.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 16:05:20 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Radadia", "Purushotam", ""], ["Karande", "Shirish", ""]]}, {"id": "1609.02132", "submitter": "Iasonas Kokkinos", "authors": "Iasonas Kokkinos", "title": "UberNet: Training a `Universal' Convolutional Neural Network for Low-,\n  Mid-, and High-Level Vision using Diverse Datasets and Limited Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce a convolutional neural network (CNN) that jointly\nhandles low-, mid-, and high-level vision tasks in a unified architecture that\nis trained end-to-end. Such a universal network can act like a `swiss knife'\nfor vision tasks; we call this architecture an UberNet to indicate its\noverarching nature.\n  We address two main technical challenges that emerge when broadening up the\nrange of tasks handled by a single CNN: (i) training a deep architecture while\nrelying on diverse training sets and (ii) training many (potentially unlimited)\ntasks with a limited memory budget. Properly addressing these two problems\nallows us to train accurate predictors for a host of tasks, without\ncompromising accuracy.\n  Through these advances we train in an end-to-end manner a CNN that\nsimultaneously addresses (a) boundary detection (b) normal estimation (c)\nsaliency estimation (d) semantic segmentation (e) human part segmentation (f)\nsemantic boundary detection, (g) region proposal generation and object\ndetection. We obtain competitive performance while jointly addressing all of\nthese tasks in 0.7 seconds per frame on a single GPU. A demonstration of this\nsystem can be found at http://cvn.ecp.fr/ubernet/.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 19:35:30 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Kokkinos", "Iasonas", ""]]}, {"id": "1609.02139", "submitter": "Robin Allesiardo", "authors": "Robin Allesiardo, Rapha\\\"el F\\'eraud and Odalric-Ambrym Maillard", "title": "Random Shuffling and Resets for the Non-stationary Stochastic Bandit\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a non-stationary formulation of the stochastic multi-armed bandit\nwhere the rewards are no longer assumed to be identically distributed. For the\nbest-arm identification task, we introduce a version of Successive Elimination\nbased on random shuffling of the $K$ arms. We prove that under a novel and mild\nassumption on the mean gap $\\Delta$, this simple but powerful modification\nachieves the same guarantees in term of sample complexity and cumulative regret\nthan its original version, but in a much wider class of problems, as it is not\nanymore constrained to stationary distributions. We also show that the original\n{\\sc Successive Elimination} fails to have controlled regret in this more\ngeneral scenario, thus showing the benefit of shuffling. We then remove our\nmild assumption and adapt the algorithm to the best-arm identification task\nwith switching arms. We adapt the definition of the sample complexity for that\ncase and prove that, against an optimal policy with $N-1$ switches of the\noptimal arm, this new algorithm achieves an expected sample complexity of\n$O(\\Delta^{-2}\\sqrt{NK\\delta^{-1} \\log(K \\delta^{-1})})$, where $\\delta$ is the\nprobability of failure of the algorithm, and an expected cumulative regret of\n$O(\\Delta^{-1}{\\sqrt{NTK \\log (TK)}})$ after $T$ time steps.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 13:31:21 GMT"}], "update_date": "2016-09-09", "authors_parsed": [["Allesiardo", "Robin", ""], ["F\u00e9raud", "Rapha\u00ebl", ""], ["Maillard", "Odalric-Ambrym", ""]]}, {"id": "1609.02226", "submitter": "Navid Kardan", "authors": "Navid Kardan, Kenneth O. Stanley", "title": "Fitted Learning: Models with Awareness of their Limits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though deep learning has pushed the boundaries of classification forward, in\nrecent years hints of the limits of standard classification have begun to\nemerge. Problems such as fooling, adding new classes over time, and the need to\nretrain learning models only for small changes to the original problem all\npoint to a potential shortcoming in the classic classification regime, where a\ncomprehensive a priori knowledge of the possible classes or concepts is\ncritical. Without such knowledge, classifiers misjudge the limits of their\nknowledge and overgeneralization therefore becomes a serious obstacle to\nconsistent performance. In response to these challenges, this paper extends the\nclassic regime by reframing classification instead with the assumption that\nconcepts present in the training set are only a sample of the hypothetical\nfinal set of concepts. To bring learning models into this new paradigm, a novel\nelaboration of standard architectures called the competitive overcomplete\noutput layer (COOL) neural network is introduced. Experiments demonstrate the\neffectiveness of COOL by applying it to fooling, separable concept learning,\none-class neural networks, and standard classification benchmarks. The results\nsuggest that, unlike conventional classifiers, the amount of generalization in\nCOOL networks can be tuned to match the problem.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 23:59:36 GMT"}, {"version": "v2", "created": "Sun, 11 Sep 2016 06:34:56 GMT"}, {"version": "v3", "created": "Wed, 4 Jan 2017 17:14:41 GMT"}, {"version": "v4", "created": "Mon, 9 Jul 2018 04:21:34 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Kardan", "Navid", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "1609.02228", "submitter": "Thomas Miconi", "authors": "Thomas Miconi", "title": "Learning to learn with backpropagation of Hebbian plasticity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hebbian plasticity is a powerful principle that allows biological brains to\nlearn from their lifetime experience. By contrast, artificial neural networks\ntrained with backpropagation generally have fixed connection weights that do\nnot change once training is complete. While recent methods can endow neural\nnetworks with long-term memories, Hebbian plasticity is currently not amenable\nto gradient descent. Here we derive analytical expressions for activity\ngradients in neural networks with Hebbian plastic connections. Using these\nexpressions, we can use backpropagation to train not just the baseline weights\nof the connections, but also their plasticity. As a result, the networks \"learn\nhow to learn\" in order to solve the problem at hand: the trained networks\nautomatically perform fast learning of unpredictable environmental features\nduring their lifetime, expanding the range of solvable problems. We test the\nalgorithm on various on-line learning tasks, including pattern completion,\none-shot learning, and reversal learning. The algorithm successfully learns how\nto learn the relevant associations from one-shot instruction, and fine-tunes\nthe temporal dynamics of plasticity to allow for continual learning in response\nto changing environmental parameters. We conclude that backpropagation of\nHebbian plasticity offers a powerful model for lifelong learning.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 00:02:20 GMT"}, {"version": "v2", "created": "Wed, 19 Oct 2016 17:51:25 GMT"}], "update_date": "2016-10-20", "authors_parsed": [["Miconi", "Thomas", ""]]}, {"id": "1609.02236", "submitter": "Shanbo Chu", "authors": "Shanbo Chu, Yong Jiang and Kewei Tu", "title": "Latent Dependency Forest Models", "comments": "10 pages, 3 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Probabilistic modeling is one of the foundations of modern machine learning\nand artificial intelligence. In this paper, we propose a novel type of\nprobabilistic models named latent dependency forest models (LDFMs). A LDFM\nmodels the dependencies between random variables with a forest structure that\ncan change dynamically based on the variable values. It is therefore capable of\nmodeling context-specific independence. We parameterize a LDFM using a\nfirst-order non-projective dependency grammar. Learning LDFMs from data can be\nformulated purely as a parameter learning problem, and hence the difficult\nproblem of model structure learning is circumvented. Our experimental results\nshow that LDFMs are competitive with existing probabilistic models.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 00:57:19 GMT"}, {"version": "v2", "created": "Sun, 20 Nov 2016 15:51:35 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Chu", "Shanbo", ""], ["Jiang", "Yong", ""], ["Tu", "Kewei", ""]]}, {"id": "1609.02316", "submitter": "Piers Williams", "authors": "Piers R. Williams, Diego Perez-Liebana and Simon M. Lucas", "title": "Ms. Pac-Man Versus Ghost Team CIG 2016 Competition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the revival of the popular Ms. Pac-Man Versus Ghost\nTeam competition. We present an updated game engine with Partial Observability\nconstraints, a new Multi-Agent Systems approach to developing Ghost agents and\nseveral sample controllers to ease the development of entries. A restricted\ncommunication protocol is provided for the Ghosts, providing a more challenging\nenvironment than before. The competition will debut at the IEEE Computational\nIntelligence and Games Conference 2016. Some preliminary results showing the\neffects of Partial Observability and the benefits of simple communication are\nalso presented.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 08:15:58 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Williams", "Piers R.", ""], ["Perez-Liebana", "Diego", ""], ["Lucas", "Simon M.", ""]]}, {"id": "1609.02531", "submitter": "Yu Sun", "authors": "Matteo Bianchi, Jeannette Bohg, and Yu Sun", "title": "Latest Datasets and Technologies Presented in the Workshop on Grasping\n  and Manipulation Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports the activities and outcomes in the Workshop on Grasping\nand Manipulation Datasets that was organized under the International Conference\non Robotics and Automation (ICRA) 2016. The half day workshop was packed with\nnine invited talks, 12 interactive presentations, and one panel discussion with\nten panelists. This paper summarizes all the talks and presentations and recaps\nwhat has been discussed in the panels session. This summary servers as a review\nof recent developments in data collection in grasping and manipulation. Many of\nthe presentations describe ongoing efforts or explorations that could be\nachieved and fully available in a year or two. The panel discussion not only\ncommented on the current approaches, but also indicates new directions and\nfocuses. The workshop clearly displayed the importance of quality datasets in\nrobotics and robotic grasping and manipulation field. Hopefully the workshop\ncould motivate larger efforts to create big datasets that are comparable with\nbig datasets in other communities such as computer vision.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 19:01:59 GMT"}], "update_date": "2016-09-09", "authors_parsed": [["Bianchi", "Matteo", ""], ["Bohg", "Jeannette", ""], ["Sun", "Yu", ""]]}, {"id": "1609.02584", "submitter": "Patrick Rodler", "authors": "Patrick Rodler", "title": "Towards Better Response Times and Higher-Quality Queries in Interactive\n  Knowledge Base Debugging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many AI applications rely on knowledge encoded in a locigal knowledge base\n(KB). The most essential benefit of such logical KBs is the opportunity to\nperform automatic reasoning which however requires a KB to meet some minimal\nquality criteria such as consistency. Without adequate tool assistance, the\ntask of resolving such violated quality criteria in a KB can be extremely hard,\nespecially when the problematic KB is large and complex. To this end,\ninteractive KB debuggers have been introduced which ask a user queries whether\ncertain statements must or must not hold in the intended domain. The given\nanswers help to gradually restrict the search space for KB repairs.\n  Existing interactive debuggers often rely on a pool-based strategy for query\ncomputation. A pool of query candidates is precomputed, from which the best\ncandidate according to some query quality criterion is selected to be shown to\nthe user. This often leads to the generation of many unnecessary query\ncandidates and thus to a high number of expensive calls to logical reasoning\nservices. We tackle this issue by an in-depth mathematical analysis of diverse\nreal-valued active learning query selection measures in order to determine\nqualitative criteria that make a query favorable. These criteria are the key to\ndevising efficient heuristic query search methods. The proposed methods enable\nfor the first time a completely reasoner-free query generation for interactive\nKB debugging while at the same time guaranteeing optimality conditions, e.g.\nminimal cardinality or best understandability for the user, of the generated\nquery that existing methods cannot realize.\n  Further, we study different relations between active learning measures. The\nobtained picture gives a hint about which measures are more favorable in which\nsituation or which measures always lead to the same outcomes, based on given\ntypes of queries.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 20:48:32 GMT"}, {"version": "v2", "created": "Tue, 30 May 2017 09:57:45 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Rodler", "Patrick", ""]]}, {"id": "1609.02646", "submitter": "Ian Davidson", "authors": "Sean Gilpin, Chia-Tung Kuo, Tina Eliassi-Rad, Ian Davidson", "title": "Some Advances in Role Discovery in Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Role discovery in graphs is an emerging area that allows analysis of complex\ngraphs in an intuitive way. In contrast to other graph prob- lems such as\ncommunity discovery, which finds groups of highly connected nodes, the role\ndiscovery problem finds groups of nodes that share similar graph topological\nstructure. However, existing work so far has two severe limitations that\nprevent its use in some domains. Firstly, it is completely unsupervised which\nis undesirable for a number of reasons. Secondly, most work is limited to a\nsingle relational graph. We address both these lim- itations in an intuitive\nand easy to implement alternating least squares framework. Our framework allows\nconvex constraints to be placed on the role discovery problem which can provide\nuseful supervision. In par- ticular we explore supervision to enforce i)\nsparsity, ii) diversity and iii) alternativeness. We then show how to lift this\nwork for multi-relational graphs. A natural representation of a\nmulti-relational graph is an order 3 tensor (rather than a matrix) and that a\nTucker decomposition allows us to find complex interactions between collections\nof entities (E-groups) and the roles they play for a combination of relations\n(R-groups). Existing Tucker decomposition methods in tensor toolboxes are not\nsuited for our purpose, so we create our own algorithm that we demonstrate is\npragmatically useful.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 03:13:55 GMT"}], "update_date": "2016-09-12", "authors_parsed": [["Gilpin", "Sean", ""], ["Kuo", "Chia-Tung", ""], ["Eliassi-Rad", "Tina", ""], ["Davidson", "Ian", ""]]}, {"id": "1609.02672", "submitter": "Uwe Aickelin", "authors": "Polla Fattah, Uwe Aickelin, Christian Wagner", "title": "Measuring Player's Behaviour Change over Time in Public Goods Game", "comments": "SAI Intelligent Systems Conference 2016 London, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important issue in public goods game is whether player's behaviour changes\nover time, and if so, how significant it is. In this game players can be\nclassified into different groups according to the level of their participation\nin the public good. This problem can be considered as a concept drift problem\nby asking the amount of change that happens to the clusters of players over a\nsequence of game rounds. In this study we present a method for measuring\nchanges in clusters with the same items over discrete time points using\nexternal clustering validation indices and area under the curve. External\nclustering indices were originally used to measure the difference between\nsuggested clusters in terms of clustering algorithms and ground truth labels\nfor items provided by experts. Instead of different cluster label comparison,\nwe use these indices to compare between clusters of any two consecutive time\npoints or between the first time point and the remaining time points to measure\nthe difference between clusters through time points. In theory, any external\nclustering indices can be used to measure changes for any traditional\n(non-temporal) clustering algorithm, due to the fact that any time point alone\nis not carrying any temporal information. For the public goods game, our\nresults indicate that the players are changing over time but the change is\nsmooth and relatively constant between any two time points.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 07:20:01 GMT"}], "update_date": "2016-09-12", "authors_parsed": [["Fattah", "Polla", ""], ["Aickelin", "Uwe", ""], ["Wagner", "Christian", ""]]}, {"id": "1609.02976", "submitter": "Nhien-An Le-Khac", "authors": "Fan Cai, Nhien-An Le-Khac, M-T. Kechadi", "title": "An Integrated Classification Model for Financial Data Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, financial data analysis is becoming increasingly important in the\nbusiness market. As companies collect more and more data from daily operations,\nthey expect to extract useful knowledge from existing collected data to help\nmake reasonable decisions for new customer requests, e.g. user credit category,\nchurn analysis, real estate analysis, etc. Financial institutes have applied\ndifferent data mining techniques to enhance their business performance.\nHowever, simple ap-proach of these techniques could raise a performance issue.\nBesides, there are very few general models for both understanding and\nforecasting different finan-cial fields. We present in this paper a new\nclassification model for analyzing fi-nancial data. We also evaluate this model\nwith different real-world data to show its performance.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 23:45:19 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Cai", "Fan", ""], ["Le-Khac", "Nhien-An", ""], ["Kechadi", "M-T.", ""]]}, {"id": "1609.02993", "submitter": "Gabriel Synnaeve", "authors": "Nicolas Usunier, Gabriel Synnaeve, Zeming Lin, Soumith Chintala", "title": "Episodic Exploration for Deep Deterministic Policies: An Application to\n  StarCraft Micromanagement Tasks", "comments": "18 pages, 1 figure (2 plots), 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider scenarios from the real-time strategy game StarCraft as new\nbenchmarks for reinforcement learning algorithms. We propose micromanagement\ntasks, which present the problem of the short-term, low-level control of army\nmembers during a battle. From a reinforcement learning point of view, these\nscenarios are challenging because the state-action space is very large, and\nbecause there is no obvious feature representation for the state-action\nevaluation function. We describe our approach to tackle the micromanagement\nscenarios with deep neural network controllers from raw state features given by\nthe game engine. In addition, we present a heuristic reinforcement learning\nalgorithm which combines direct exploration in the policy space and\nbackpropagation. This algorithm allows for the collection of traces for\nlearning using deterministic policies, which appears much more efficient than,\nfor example, {\\epsilon}-greedy exploration. Experiments show that with this\nalgorithm, we successfully learn non-trivial strategies for scenarios with\narmies of up to 15 agents, where both Q-learning and REINFORCE struggle.\n", "versions": [{"version": "v1", "created": "Sat, 10 Sep 2016 02:13:02 GMT"}, {"version": "v2", "created": "Tue, 13 Sep 2016 00:18:48 GMT"}, {"version": "v3", "created": "Sat, 26 Nov 2016 19:02:20 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Usunier", "Nicolas", ""], ["Synnaeve", "Gabriel", ""], ["Lin", "Zeming", ""], ["Chintala", "Soumith", ""]]}, {"id": "1609.03058", "submitter": "Weiyao Lin", "authors": "Weiyao Lin, Yang Zhou, Hongteng Xu, Junchi Yan, Mingliang Xu, Jianxin\n  Wu, Zicheng Liu", "title": "A Tube-and-Droplet-based Approach for Representing and Analyzing Motion\n  Trajectories", "comments": "IEEE Transactions on Pattern Analysis and Machine Intelligence, DOI:\n  10.1109/TPAMI.2016.2608884, 2016. Code for our work is available at\n  http://min.sjtu.edu.cn/lwydemo/Trajectory%20analysis.htm", "journal-ref": null, "doi": "10.1109/TPAMI.2016.2608884", "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory analysis is essential in many applications. In this paper, we\naddress the problem of representing motion trajectories in a highly informative\nway, and consequently utilize it for analyzing trajectories. Our approach first\nleverages the complete information from given trajectories to construct a\nthermal transfer field which provides a context-rich way to describe the global\nmotion pattern in a scene. Then, a 3D tube is derived which depicts an input\ntrajectory by integrating its surrounding motion patterns contained in the\nthermal transfer field. The 3D tube effectively: 1) maintains the movement\ninformation of a trajectory, 2) embeds the complete contextual motion pattern\naround a trajectory, 3) visualizes information about a trajectory in a clear\nand unified way. We further introduce a droplet-based process. It derives a\ndroplet vector from a 3D tube, so as to characterize the high-dimensional 3D\ntube information in a simple but effective way. Finally, we apply our\ntube-and-droplet representation to trajectory analysis applications including\ntrajectory clustering, trajectory classification & abnormality detection, and\n3D action recognition. Experimental comparisons with state-of-the-art\nalgorithms demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 10 Sep 2016 14:33:06 GMT"}, {"version": "v2", "created": "Wed, 26 Apr 2017 12:17:26 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Lin", "Weiyao", ""], ["Zhou", "Yang", ""], ["Xu", "Hongteng", ""], ["Yan", "Junchi", ""], ["Xu", "Mingliang", ""], ["Wu", "Jianxin", ""], ["Liu", "Zicheng", ""]]}, {"id": "1609.03145", "submitter": "Volker Tresp", "authors": "Volker Tresp and Maximilian Nickel", "title": "Relational Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a survey on relational models. Relational models describe complete\nnetworked {domains by taking into account global dependencies in the data}.\nRelational models can lead to more accurate predictions if compared to\nnon-relational machine learning approaches. Relational models typically are\nbased on probabilistic graphical models, e.g., Bayesian networks, Markov\nnetworks, or latent variable models. Relational models have applications in\nsocial networks analysis, the modeling of knowledge graphs, bioinformatics,\nrecommendation systems, natural language processing, medical decision support,\nand linked data.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2016 10:14:18 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Tresp", "Volker", ""], ["Nickel", "Maximilian", ""]]}, {"id": "1609.03157", "submitter": "Milad Moradi Vastegani", "authors": "Milad Moradi", "title": "A centralized reinforcement learning method for multi-agent job\n  scheduling in Grid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges in Grid systems is designing an adaptive,\nscalable, and model-independent method for job scheduling to achieve a\ndesirable degree of load balancing and system efficiency. Centralized job\nscheduling methods have some drawbacks, such as single point of failure and\nlack of scalability. Moreover, decentralized methods require a coordination\nmechanism with limited communications. In this paper, we propose a multi-agent\napproach to job scheduling in Grid, named Centralized Learning Distributed\nScheduling (CLDS), by utilizing the reinforcement learning framework. The CLDS\nis a model free approach that uses the information of jobs and their completion\ntime to estimate the efficiency of resources. In this method, there are a\nlearner agent and several scheduler agents that perform the task of learning\nand job scheduling with the use of a coordination strategy that maintains the\ncommunication cost at a limited level. We evaluated the efficiency of the CLDS\nmethod by designing and performing a set of experiments on a simulated Grid\nsystem under different system scales and loads. The results show that the CLDS\ncan effectively balance the load of system even in large scale and heavy loaded\nGrids, while maintains its adaptive performance and scalability.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2016 13:03:21 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Moradi", "Milad", ""]]}, {"id": "1609.03193", "submitter": "Gabriel Synnaeve", "authors": "Ronan Collobert, Christian Puhrsch, Gabriel Synnaeve", "title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "comments": "8 pages, 4 figures (7 plots/schemas), 2 tables (4 tabulars)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a simple end-to-end model for speech recognition,\ncombining a convolutional network based acoustic model and a graph decoding. It\nis trained to output letters, with transcribed speech, without the need for\nforce alignment of phonemes. We introduce an automatic segmentation criterion\nfor training from sequence annotation without alignment that is on par with CTC\nwhile being simpler. We show competitive results in word error rate on the\nLibrispeech corpus with MFCC features, and promising results from raw waveform.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2016 18:56:53 GMT"}, {"version": "v2", "created": "Tue, 13 Sep 2016 02:49:05 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Collobert", "Ronan", ""], ["Puhrsch", "Christian", ""], ["Synnaeve", "Gabriel", ""]]}, {"id": "1609.03234", "submitter": "Noam Brown", "authors": "Noam Brown and Tuomas Sandholm", "title": "Reduced Space and Faster Convergence in Imperfect-Information Games via\n  Regret-Based Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual Regret Minimization (CFR) is the most popular iterative\nalgorithm for solving zero-sum imperfect-information games. Regret-Based\nPruning (RBP) is an improvement that allows poorly-performing actions to be\ntemporarily pruned, thus speeding up CFR. We introduce Total RBP, a new form of\nRBP that reduces the space requirements of CFR as actions are pruned. We prove\nthat in zero-sum games it asymptotically prunes any action that is not part of\na best response to some Nash equilibrium. This leads to provably faster\nconvergence and lower space requirements. Experiments show that Total RBP\nresults in an order of magnitude reduction in space, and the reduction factor\nincreases with game size.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 00:30:54 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Brown", "Noam", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1609.03250", "submitter": "Nan Ye", "authors": "Nan Ye and Adhiraj Somani and David Hsu and Wee Sun Lee", "title": "DESPOT: Online POMDP Planning with Regularization", "comments": "36 pages", "journal-ref": "JAIR 58 (2017) 231-266", "doi": "10.1613/jair.5328", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The partially observable Markov decision process (POMDP) provides a\nprincipled general framework for planning under uncertainty, but solving POMDPs\noptimally is computationally intractable, due to the \"curse of dimensionality\"\nand the \"curse of history\". To overcome these challenges, we introduce the\nDeterminized Sparse Partially Observable Tree (DESPOT), a sparse approximation\nof the standard belief tree, for online planning under uncertainty. A DESPOT\nfocuses online planning on a set of randomly sampled scenarios and compactly\ncaptures the \"execution\" of all policies under these scenarios. We show that\nthe best policy obtained from a DESPOT is near-optimal, with a regret bound\nthat depends on the representation size of the optimal policy. Leveraging this\nresult, we give an anytime online planning algorithm, which searches a DESPOT\nfor a policy that optimizes a regularized objective function. Regularization\nbalances the estimated value of a policy under the sampled scenarios and the\npolicy size, thus avoiding overfitting. The algorithm demonstrates strong\nexperimental results, compared with some of the best online POMDP algorithms\navailable. It has also been incorporated into an autonomous driving system for\nreal-time vehicle control. The source code for the algorithm is available\nonline.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 02:12:13 GMT"}, {"version": "v2", "created": "Wed, 8 Mar 2017 07:28:31 GMT"}, {"version": "v3", "created": "Tue, 19 Sep 2017 03:29:57 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Ye", "Nan", ""], ["Somani", "Adhiraj", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""]]}, {"id": "1609.03286", "submitter": "Yun-Nung Chen", "authors": "Yun-Nung Chen, Dilek Hakkani-Tur, Gokhan Tur, Asli Celikyilmaz,\n  Jianfeng Gao, Li Deng", "title": "Knowledge as a Teacher: Knowledge-Guided Structural Attention Networks", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language understanding (NLU) is a core component of a spoken dialogue\nsystem. Recently recurrent neural networks (RNN) obtained strong results on NLU\ndue to their superior ability of preserving sequential information over time.\nTraditionally, the NLU module tags semantic slots for utterances considering\ntheir flat structures, as the underlying RNN structure is a linear chain.\nHowever, natural language exhibits linguistic properties that provide rich,\nstructured information for better understanding. This paper introduces a novel\nmodel, knowledge-guided structural attention networks (K-SAN), a generalization\nof RNN to additionally incorporate non-flat network topologies guided by prior\nknowledge. There are two characteristics: 1) important substructures can be\ncaptured from small training data, allowing the model to generalize to\npreviously unseen test data; 2) the model automatically figures out the salient\nsubstructures that are essential to predict the semantic tags of the given\nsentences, so that the understanding performance can be improved. The\nexperiments on the benchmark Air Travel Information System (ATIS) data show\nthat the proposed K-SAN architecture can effectively extract salient knowledge\nfrom substructures with an attention mechanism, and outperform the performance\nof the state-of-the-art neural network based frameworks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 07:29:59 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Chen", "Yun-Nung", ""], ["Hakkani-Tur", "Dilek", ""], ["Tur", "Gokhan", ""], ["Celikyilmaz", "Asli", ""], ["Gao", "Jianfeng", ""], ["Deng", "Li", ""]]}, {"id": "1609.03333", "submitter": "Niek Tax", "authors": "Niek Tax, Emin Alasgarov, Natalia Sidorova, Reinder Haakma", "title": "On Generation of Time-based Label Refinements", "comments": "Accepted at CS&P workshop 2016 Overlap in preliminaries with\n  arXiv:1606.07259", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process mining is a research field focused on the analysis of event data with\nthe aim of extracting insights in processes. Applying process mining techniques\non data from smart home environments has the potential to provide valuable\ninsights in (un)healthy habits and to contribute to ambient assisted living\nsolutions. Finding the right event labels to enable application of process\nmining techniques is however far from trivial, as simply using the triggering\nsensor as the label for sensor events results in uninformative models that\nallow for too much behavior (overgeneralizing). Refinements of sensor level\nevent labels suggested by domain experts have shown to enable discovery of more\nprecise and insightful process models. However, there exist no automated\napproach to generate refinements of event labels in the context of process\nmining. In this paper we propose a framework for automated generation of label\nrefinements based on the time attribute of events. We show on a case study with\nreal life smart home event data that behaviorally more specific, and therefore\nmore insightful, process models can be found by using automatically generated\nrefined labels in process discovery.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 10:25:29 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Tax", "Niek", ""], ["Alasgarov", "Emin", ""], ["Sidorova", "Natalia", ""], ["Haakma", "Reinder", ""]]}, {"id": "1609.03357", "submitter": "Anna Jordanous", "authors": "Anna Jordanous and Bill Keller", "title": "Modelling Creativity: Identifying Key Components through a Corpus-Based\n  Approach", "comments": "Submitted to PLOS ONE; currently under review. Figures not included", "journal-ref": null, "doi": "10.1371/journal.pone.0162959", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creativity is a complex, multi-faceted concept encompassing a variety of\nrelated aspects, abilities, properties and behaviours. If we wish to study\ncreativity scientifically, then a tractable and well-articulated model of\ncreativity is required. Such a model would be of great value to researchers\ninvestigating the nature of creativity and in particular, those concerned with\nthe evaluation of creative practice. This paper describes a unique approach to\ndeveloping a suitable model of how creative behaviour emerges that is based on\nthe words people use to describe the concept. Using techniques from the field\nof statistical natural language processing, we identify a collection of\nfourteen key components of creativity through an analysis of a corpus of\nacademic papers on the topic. Words are identified which appear significantly\noften in connection with discussions of the concept. Using a measure of lexical\nsimilarity to help cluster these words, a number of distinct themes emerge,\nwhich collectively contribute to a comprehensive and multi-perspective model of\ncreativity. The components provide an ontology of creativity: a set of building\nblocks which can be used to model creative practice in a variety of domains.\nThe components have been employed in two case studies to evaluate the\ncreativity of computational systems and have proven useful in articulating\nachievements of this work and directions for further research.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 11:58:59 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Jordanous", "Anna", ""], ["Keller", "Bill", ""]]}, {"id": "1609.03437", "submitter": "Fabio Cozman", "authors": "Fabio Gagliardi Cozman", "title": "First-Order Bayesian Network Specifications Capture the Complexity Class\n  PP", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The point of this note is to prove that a language is in the complexity class\nPP if and only if the strings of the language encode valid inferences in a\nBayesian network defined using function-free first-order logic with equality.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 15:11:58 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Cozman", "Fabio Gagliardi", ""]]}, {"id": "1609.03438", "submitter": "Joerg Puehrer", "authors": "Gerhard Brewka, Stefan Ellmauthaler, Ricardo Gon\\c{c}alves, Matthias\n  Knorr, Jo\\~ao Leite, J\\\"org P\\\"uhrer", "title": "Reactive Multi-Context Systems: Heterogeneous Reasoning in Dynamic\n  Environments", "comments": null, "journal-ref": "Artificial Intelligence 256 (2018) 68-104", "doi": "10.1016/j.artint.2017.11.007", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Managed multi-context systems (mMCSs) allow for the integration of\nheterogeneous knowledge sources in a modular and very general way. They were,\nhowever, mainly designed for static scenarios and are therefore not well-suited\nfor dynamic environments in which continuous reasoning over such heterogeneous\nknowledge with constantly arriving streams of data is necessary. In this paper,\nwe introduce reactive multi-context systems (rMCSs), a framework for reactive\nreasoning in the presence of heterogeneous knowledge sources and data streams.\nWe show that rMCSs are indeed well-suited for this purpose by illustrating how\nseveral typical problems arising in the context of stream reasoning can be\nhandled using them, by showing how inconsistencies possibly occurring in the\nintegration of multiple knowledge sources can be handled, and by arguing that\nthe potential non-determinism of rMCSs can be avoided if needed using an\nalternative, more skeptical well-founded semantics instead with beneficial\ncomputational properties. We also investigate the computational complexity of\nvarious reasoning problems related to rMCSs. Finally, we discuss related work,\nand show that rMCSs do not only generalize mMCSs to dynamic settings, but also\ncapture/extend relevant approaches w.r.t. dynamics in knowledge representation\nand stream reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 15:12:00 GMT"}, {"version": "v2", "created": "Fri, 9 Dec 2016 11:20:56 GMT"}, {"version": "v3", "created": "Mon, 11 Dec 2017 08:59:56 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Brewka", "Gerhard", ""], ["Ellmauthaler", "Stefan", ""], ["Gon\u00e7alves", "Ricardo", ""], ["Knorr", "Matthias", ""], ["Leite", "Jo\u00e3o", ""], ["P\u00fchrer", "J\u00f6rg", ""]]}, {"id": "1609.03540", "submitter": "Babak Salimi", "authors": "Babak Salimi, Dan Suciu", "title": "ZaliQL: A SQL-Based Framework for Drawing Causal Inference from Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference from observational data is a subject of active research and\ndevelopment in statistics and computer science. Many toolkits have been\ndeveloped for this purpose that depends on statistical software. However, these\ntoolkits do not scale to large datasets. In this paper we describe a suite of\ntechniques for expressing causal inference tasks from observational data in\nSQL. This suite supports the state-of-the-art methods for causal inference and\nrun at scale within a database engine. In addition, we introduce several\noptimization techniques that significantly speedup causal inference, both in\nthe online and offline setting. We evaluate the quality and performance of our\ntechniques by experiments of real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 19:24:14 GMT"}, {"version": "v2", "created": "Tue, 13 Sep 2016 01:59:05 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Salimi", "Babak", ""], ["Suciu", "Dan", ""]]}, {"id": "1609.03543", "submitter": "Scott Garrabrant", "authors": "Scott Garrabrant, Tsvi Benson-Tilsen, Andrew Critch, Nate Soares,\n  Jessica Taylor", "title": "Logical Induction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO math.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computable algorithm that assigns probabilities to every logical\nstatement in a given formal language, and refines those probabilities over\ntime. For instance, if the language is Peano arithmetic, it assigns\nprobabilities to all arithmetical statements, including claims about the twin\nprime conjecture, the outputs of long-running computations, and its own\nprobabilities. We show that our algorithm, an instance of what we call a\nlogical inductor, satisfies a number of intuitive desiderata, including: (1) it\nlearns to predict patterns of truth and falsehood in logical statements, often\nlong before having the resources to evaluate the statements, so long as the\npatterns can be written down in polynomial time; (2) it learns to use\nappropriate statistical summaries to predict sequences of statements whose\ntruth values appear pseudorandom; and (3) it learns to have accurate beliefs\nabout its own current beliefs, in a manner that avoids the standard paradoxes\nof self-reference. For example, if a given computer program only ever produces\noutputs in a certain range, a logical inductor learns this fact in a timely\nmanner; and if late digits in the decimal expansion of $\\pi$ are difficult to\npredict, then a logical inductor learns to assign $\\approx 10\\%$ probability to\n\"the $n$th digit of $\\pi$ is a 7\" for large $n$. Logical inductors also learn\nto trust their future beliefs more than their current beliefs, and their\nbeliefs are coherent in the limit (whenever $\\phi \\implies \\psi$,\n$\\mathbb{P}_\\infty(\\phi) \\le \\mathbb{P}_\\infty(\\psi)$, and so on); and logical\ninductors strictly dominate the universal semimeasure in the limit.\n  These properties and many others all follow from a single logical induction\ncriterion, which is motivated by a series of stock trading analogies. Roughly\nspeaking, each logical sentence $\\phi$ is associated with a stock that is worth\n\\$1 per share if [...]\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 19:30:56 GMT"}, {"version": "v2", "created": "Mon, 19 Sep 2016 20:32:15 GMT"}, {"version": "v3", "created": "Sun, 2 Oct 2016 14:58:09 GMT"}, {"version": "v4", "created": "Wed, 13 Dec 2017 00:17:09 GMT"}, {"version": "v5", "created": "Mon, 7 Dec 2020 22:26:59 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Garrabrant", "Scott", ""], ["Benson-Tilsen", "Tsvi", ""], ["Critch", "Andrew", ""], ["Soares", "Nate", ""], ["Taylor", "Jessica", ""]]}, {"id": "1609.03632", "submitter": "Bishan Yang", "authors": "Bishan Yang and Tom Mitchell", "title": "Joint Extraction of Events and Entities within a Document Context", "comments": "11 pages, 2 figures, published at NAACL 2016", "journal-ref": "Proceedings of NAACL-HLT 2016, pages 289-299", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Events and entities are closely related; entities are often actors or\nparticipants in events and events without entities are uncommon. The\ninterpretation of events and entities is highly contextually dependent.\nExisting work in information extraction typically models events separately from\nentities, and performs inference at the sentence level, ignoring the rest of\nthe document. In this paper, we propose a novel approach that models the\ndependencies among variables of events, entities, and their relations, and\nperforms joint inference of these variables across a document. The goal is to\nenable access to document-level contextual information and facilitate\ncontext-aware predictions. We demonstrate that our approach substantially\noutperforms the state-of-the-art methods for event extraction as well as a\nstrong baseline for entity extraction.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 23:27:37 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Yang", "Bishan", ""], ["Mitchell", "Tom", ""]]}, {"id": "1609.03765", "submitter": "Umberto Grandi", "authors": "Ulle Endriss and Umberto Grandi", "title": "Graph Aggregation", "comments": null, "journal-ref": "Artificial Intelligence, Volume 245, pages 86-114, 2017", "doi": "10.1016/j.artint.2017.01.001", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph aggregation is the process of computing a single output graph that\nconstitutes a good compromise between several input graphs, each provided by a\ndifferent source. One needs to perform graph aggregation in a wide variety of\nsituations, e.g., when applying a voting rule (graphs as preference orders),\nwhen consolidating conflicting views regarding the relationships between\narguments in a debate (graphs as abstract argumentation frameworks), or when\ncomputing a consensus between several alternative clusterings of a given\ndataset (graphs as equivalence relations). In this paper, we introduce a formal\nframework for graph aggregation grounded in social choice theory. Our focus is\non understanding which properties shared by the individual input graphs will\ntransfer to the output graph returned by a given aggregation rule. We consider\nboth common properties of graphs, such as transitivity and reflexivity, and\narbitrary properties expressible in certain fragments of modal logic. Our\nresults establish several connections between the types of properties preserved\nunder aggregation and the choice-theoretic axioms satisfied by the rules used.\nThe most important of these results is a powerful impossibility theorem that\ngeneralises Arrow's seminal result for the aggregation of preference orders to\na large collection of different types of graphs.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 11:08:23 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Endriss", "Ulle", ""], ["Grandi", "Umberto", ""]]}, {"id": "1609.03847", "submitter": "Daniel Bryce", "authors": "Daniel Bryce, Sergiy Bogomolov, Alexander Heinz, Christian Schilling", "title": "Instrumenting an SMT Solver to Solve Hybrid Network Reachability\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PDDL+ planning has its semantics rooted in hybrid automata (HA) and recent\nwork has shown that it can be modeled as a network of HAs. Addressing the\ncomplexity of nonlinear PDDL+ planning as HAs requires both space and time\nefficient reasoning. Unfortunately, existing solvers either do not address\nnonlinear dynamics or do not natively support networks of automata.\n  We present a new algorithm, called HNSolve, which guides the variable\nselection of the dReal Satisfiability Modulo Theories (SMT) solver while\nreasoning about network encodings of nonlinear PDDL+ planning as HAs. HNSolve\ntightly integrates with dReal by solving a discrete abstraction of the HA\nnetwork. HNSolve finds composite runs on the HA network that ignore continuous\nvariables, but respect mode jumps and synchronization labels. HNSolve\nadmissibly detects dead-ends in the discrete abstraction, and posts conflict\nclauses that prune the SMT solver's search. We evaluate the benefits of our\nHNSolve algorithm on PDDL+ benchmark problems and demonstrate its performance\nwith respect to prior work.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 14:17:32 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Bryce", "Daniel", ""], ["Bogomolov", "Sergiy", ""], ["Heinz", "Alexander", ""], ["Schilling", "Christian", ""]]}, {"id": "1609.03971", "submitter": "Fergal Byrne", "authors": "Eric Laukien, Richard Crowder and Fergal Byrne", "title": "Feynman Machine: The Universal Dynamical Systems Computer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.ET math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efforts at understanding the computational processes in the brain have met\nwith limited success, despite their importance and potential uses in building\nintelligent machines. We propose a simple new model which draws on recent\nfindings in Neuroscience and the Applied Mathematics of interacting Dynamical\nSystems. The Feynman Machine is a Universal Computer for Dynamical Systems,\nanalogous to the Turing Machine for symbolic computing, but with several\nimportant differences. We demonstrate that networks and hierarchies of simple\ninteracting Dynamical Systems, each adaptively learning to forecast its\nevolution, are capable of automatically building sensorimotor models of the\nexternal and internal world. We identify such networks in mammalian neocortex,\nand show how existing theories of cortical computation combine with our model\nto explain the power and flexibility of mammalian intelligence. These findings\nlead directly to new architectures for machine intelligence. A suite of\nsoftware implementations has been built based on these principles, and applied\nto a number of spatiotemporal learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 18:34:59 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Laukien", "Eric", ""], ["Crowder", "Richard", ""], ["Byrne", "Fergal", ""]]}, {"id": "1609.03993", "submitter": "Markus Wagner", "authors": "Tobias Friedrich, Timo K\\\"otzing, Markus Wagner", "title": "A Generic Bet-and-run Strategy for Speeding Up Traveling Salesperson and\n  Minimum Vertex Cover", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common strategy for improving optimization algorithms is to restart the\nalgorithm when it is believed to be trapped in an inferior part of the search\nspace. However, while specific restart strategies have been developed for\nspecific problems (and specific algorithms), restarts are typically not\nregarded as a general tool to speed up an optimization algorithm. In fact, many\noptimization algorithms do not employ restarts at all.\n  Recently, \"bet-and-run\" was introduced in the context of mixed-integer\nprogramming, where first a number of short runs with randomized initial\nconditions is made, and then the most promising run of these is continued. In\nthis article, we consider two classical NP-complete combinatorial optimization\nproblems, traveling salesperson and minimum vertex cover, and study the\neffectiveness of different bet-and-run strategies. In particular, our restart\nstrategies do not take any problem knowledge into account, nor are tailored to\nthe optimization algorithm. Therefore, they can be used off-the-shelf. We\nobserve that state-of-the-art solvers for these problems can benefit\nsignificantly from restarts on standard benchmark instances.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 19:36:45 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Friedrich", "Tobias", ""], ["K\u00f6tzing", "Timo", ""], ["Wagner", "Markus", ""]]}, {"id": "1609.04214", "submitter": "Shujun Li Dr.", "authors": "Aamo Iorliam, Santosh Tirunagari, Anthony T.S. Ho, Shujun Li, Adrian\n  Waller and Norman Poh", "title": "\"Flow Size Difference\" Can Make a Difference: Detecting Malicious TCP\n  Network Flows Based on Benford's Law", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Statistical characteristics of network traffic have attracted a significant\namount of research for automated network intrusion detection, some of which\nlooked at applications of natural statistical laws such as Zipf's law,\nBenford's law and the Pareto distribution. In this paper, we present the\napplication of Benford's law to a new network flow metric \"flow size\ndifference\", which have not been studied before by other researchers, to build\nan unsupervised flow-based intrusion detection system (IDS). The method was\ninspired by our observation on a large number of TCP flow datasets where normal\nflows tend to follow Benford's law closely but malicious flows tend to deviate\nsignificantly from it. The proposed IDS is unsupervised, so it can be easily\ndeployed without any training. It has two simple operational parameters with a\nclear semantic meaning, allowing the IDS operator to set and adapt their values\nintuitively to adjust the overall performance of the IDS. We tested the\nproposed IDS on two (one closed and one public) datasets, and proved its\nefficiency in terms of AUC (area under the ROC curve). Our work showed the\n\"flow size difference\" has a great potential to improve the performance of any\nflow-based network IDSs.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 10:51:00 GMT"}, {"version": "v2", "created": "Fri, 20 Jan 2017 18:22:47 GMT"}], "update_date": "2017-01-23", "authors_parsed": [["Iorliam", "Aamo", ""], ["Tirunagari", "Santosh", ""], ["Ho", "Anthony T. S.", ""], ["Li", "Shujun", ""], ["Waller", "Adrian", ""], ["Poh", "Norman", ""]]}, {"id": "1609.04337", "submitter": "Alexandre Coninx", "authors": "Alexandre Coninx, Pierre Bessi\\`ere and Jacques Droulez", "title": "Quick and energy-efficient Bayesian computing of binocular disparity\n  using stochastic digital signals", "comments": "Preprint of article submitted for publication in International\n  Journal of Approximate Reasoning and accepted pending minor revisions", "journal-ref": null, "doi": "10.1016/j.ijar.2016.11.004", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstruction of the tridimensional geometry of a visual scene using the\nbinocular disparity information is an important issue in computer vision and\nmobile robotics, which can be formulated as a Bayesian inference problem.\nHowever, computation of the full disparity distribution with an advanced\nBayesian model is usually an intractable problem, and proves computationally\nchallenging even with a simple model. In this paper, we show how probabilistic\nhardware using distributed memory and alternate representation of data as\nstochastic bitstreams can solve that problem with high performance and energy\nefficiency. We put forward a way to express discrete probability distributions\nusing stochastic data representations and perform Bayesian fusion using those\nrepresentations, and show how that approach can be applied to diparity\ncomputation. We evaluate the system using a simulated stochastic implementation\nand discuss possible hardware implementations of such architectures and their\npotential for sensorimotor processing and robotics.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 16:41:31 GMT"}, {"version": "v2", "created": "Mon, 31 Oct 2016 15:36:01 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Coninx", "Alexandre", ""], ["Bessi\u00e8re", "Pierre", ""], ["Droulez", "Jacques", ""]]}, {"id": "1609.04371", "submitter": "Alberto Camacho", "authors": "Jorge A. Baier, Alberto Camacho, Christian Muise and Sheila A.\n  McIlraith", "title": "Finite LTL Synthesis is EXPTIME-complete", "comments": "We withdraw this paper because of an error in the proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LTL synthesis -- the construction of a function to satisfy a logical\nspecification formulated in Linear Temporal Logic -- is a 2EXPTIME-complete\nproblem with relevant applications in controller synthesis and a myriad of\nartificial intelligence applications. In this research note we consider De\nGiacomo and Vardi's variant of the synthesis problem for LTL formulas\ninterpreted over finite rather than infinite traces. Rather surprisingly, given\nthe existing claims on complexity, we establish that LTL synthesis is\nEXPTIME-complete for the finite interpretation, and not 2EXPTIME-complete as\npreviously reported. Our result coincides nicely with the planning perspective\nwhere non-deterministic planning with full observability is EXPTIME-complete\nand partial observability increases the complexity to 2EXPTIME-complete; a\nrecent related result for LTL synthesis shows that in the finite case with\npartial observability, the problem is 2EXPTIME-complete.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 18:23:25 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 14:12:45 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Baier", "Jorge A.", ""], ["Camacho", "Alberto", ""], ["Muise", "Christian", ""], ["McIlraith", "Sheila A.", ""]]}, {"id": "1609.04436", "submitter": "Mohammad Ghavamzadeh", "authors": "Mohammad Ghavamzadeh, Shie Mannor, Joelle Pineau, and Aviv Tamar", "title": "Bayesian Reinforcement Learning: A Survey", "comments": null, "journal-ref": "Foundations and Trends in Machine Learning, Vol. 8: No. 5-6, pp\n  359-492, 2015", "doi": "10.1561/2200000049", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian methods for machine learning have been widely investigated, yielding\nprincipled methods for incorporating prior information into inference\nalgorithms. In this survey, we provide an in-depth review of the role of\nBayesian methods for the reinforcement learning (RL) paradigm. The major\nincentives for incorporating Bayesian reasoning in RL are: 1) it provides an\nelegant approach to action-selection (exploration/exploitation) as a function\nof the uncertainty in learning; and 2) it provides a machinery to incorporate\nprior knowledge into the algorithms. We first discuss models and methods for\nBayesian inference in the simple single-step Bandit model. We then review the\nextensive recent literature on Bayesian methods for model-based RL, where prior\ninformation can be expressed on the parameters of the Markov model. We also\npresent Bayesian methods for model-free RL, where priors are expressed over the\nvalue function or policy class. The objective of the paper is to provide a\ncomprehensive survey on Bayesian RL algorithms and their theoretical and\nempirical properties.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 20:34:26 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["Ghavamzadeh", "Mohammad", ""], ["Mannor", "Shie", ""], ["Pineau", "Joelle", ""], ["Tamar", "Aviv", ""]]}, {"id": "1609.04508", "submitter": "Trang Pham", "authors": "Trang Pham, Truyen Tran, Dinh Phung, Svetha Venkatesh", "title": "Column Networks for Collective Classification", "comments": "Accepted at AAAI'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational learning deals with data that are characterized by relational\nstructures. An important task is collective classification, which is to jointly\nclassify networked objects. While it holds a great promise to produce a better\naccuracy than non-collective classifiers, collective classification is\ncomputational challenging and has not leveraged on the recent breakthroughs of\ndeep learning. We present Column Network (CLN), a novel deep learning model for\ncollective classification in multi-relational domains. CLN has many desirable\ntheoretical properties: (i) it encodes multi-relations between any two\ninstances; (ii) it is deep and compact, allowing complex functions to be\napproximated at the network level with a small set of free parameters; (iii)\nlocal and relational features are learned simultaneously; (iv) long-range,\nhigher-order dependencies between instances are supported naturally; and (v)\ncrucially, learning and inference are efficient, linear in the size of the\nnetwork and the number of relations. We evaluate CLN on multiple real-world\napplications: (a) delay prediction in software projects, (b) PubMed Diabetes\npublication classification and (c) film genre classification. In all\napplications, CLN demonstrates a higher accuracy than state-of-the-art rivals.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 04:45:11 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 03:59:26 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Pham", "Trang", ""], ["Tran", "Truyen", ""], ["Phung", "Dinh", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1609.04628", "submitter": "Rocco Tripodi", "authors": "Rocco Tripodi, Sebastiano Vascon, Marcello Pelillo", "title": "Context Aware Nonnegative Matrix Factorization Clustering", "comments": "6 pages, 3 figures. Full paper accepted to International Conference\n  on Pattern Recognition ICPR 2016, Canc\\'un, Mexico", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we propose a method to refine the clustering results obtained\nwith the nonnegative matrix factorization (NMF) technique, imposing consistency\nconstraints on the final labeling of the data. The research community focused\nits effort on the initialization and on the optimization part of this method,\nwithout paying attention to the final cluster assignments. We propose a game\ntheoretic framework in which each object to be clustered is represented as a\nplayer, which has to choose its cluster membership. The information obtained\nwith NMF is used to initialize the strategy space of the players and a weighted\ngraph is used to model the interactions among the players. These interactions\nallow the players to choose a cluster which is coherent with the clusters\nchosen by similar players, a property which is not guaranteed by NMF, since it\nproduces a soft clustering of the data. The results on common benchmarks show\nthat our model is able to improve the performances of many NMF formulations.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 13:23:43 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["Tripodi", "Rocco", ""], ["Vascon", "Sebastiano", ""], ["Pelillo", "Marcello", ""]]}, {"id": "1609.04648", "submitter": "Thomas Voigtmann", "authors": "A. Atashpendar, T. Schilling and Th. Voigtmann", "title": "Sequencing Chess", "comments": null, "journal-ref": null, "doi": "10.1209/0295-5075/116/10009", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the structure of the state space of chess by means of transition\npath sampling Monte Carlo simulation. Based on the typical number of moves\nrequired to transpose a given configuration of chess pieces into another, we\nconclude that the state space consists of several pockets between which\ntransitions are rare. Skilled players explore an even smaller subset of\npositions that populate some of these pockets only very sparsely. These results\nsuggest that the usual measures to estimate both, the size of the state space\nand the size of the tree of legal moves, are not unique indicators of the\ncomplexity of the game, but that topological considerations are equally\nimportant.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 10:13:42 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Atashpendar", "A.", ""], ["Schilling", "T.", ""], ["Voigtmann", "Th.", ""]]}, {"id": "1609.04722", "submitter": "Zhiwei Lin", "authors": "Zhiwei Lin and Hui Wang and Cees H. Elzinga", "title": "Concordance and the Smallest Covering Set of Preference Orderings", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.GT cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preference orderings are orderings of a set of items according to the\npreferences (of judges). Such orderings arise in a variety of domains,\nincluding group decision making, consumer marketing, voting and machine\nlearning. Measuring the mutual information and extracting the common patterns\nin a set of preference orderings are key to these areas. In this paper we deal\nwith the representation of sets of preference orderings, the quantification of\nthe degree to which judges agree on their ordering of the items (i.e. the\nconcordance), and the efficient, meaningful description of such sets.\n  We propose to represent the orderings in a subsequence-based feature space\nand present a new algorithm to calculate the size of the set of all common\nsubsequences - the basis of a quantification of concordance, not only for pairs\nof orderings but also for sets of orderings. The new algorithm is fast and\nstorage efficient with a time complexity of only $O(Nn^2)$ for the orderings of\n$n$ items by $N$ judges and a space complexity of only $O(\\min\\{Nn,n^2\\})$.\n  Also, we propose to represent the set of all $N$ orderings through a smallest\nset of covering preferences and present an algorithm to construct this smallest\ncovering set.\n  The source code for the algorithms is available at\nhttps://github.com/zhiweiuu/secs\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 16:24:45 GMT"}, {"version": "v2", "created": "Wed, 12 Oct 2016 13:37:23 GMT"}, {"version": "v3", "created": "Fri, 14 Oct 2016 07:58:02 GMT"}], "update_date": "2016-10-17", "authors_parsed": [["Lin", "Zhiwei", ""], ["Wang", "Hui", ""], ["Elzinga", "Cees H.", ""]]}, {"id": "1609.04879", "submitter": "Jeffrey Georgeson", "authors": "Jeffrey Georgeson and Christopher Child", "title": "NPCs as People, Too: The Extreme AI Personality Engine", "comments": "9 pages, 3 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PK Dick once asked \"Do Androids Dream of Electric Sheep?\" In video games, a\nsimilar question could be asked of non-player characters: Do NPCs have dreams?\nCan they live and change as humans do? Can NPCs have personalities, and can\nthese develop through interactions with players, other NPCs, and the world\naround them? Despite advances in personality AI for games, most NPCs are still\nundeveloped and undeveloping, reacting with flat affect and predictable\nroutines that make them far less than human--in fact, they become little more\nthan bits of the scenery that give out parcels of information. This need not be\nthe case. Extreme AI, a psychology-based personality engine, creates adaptive\nNPC personalities. Originally developed as part of the thesis \"NPCs as People:\nUsing Databases and Behaviour Trees to Give Non-Player Characters Personality,\"\nExtreme AI is now a fully functioning personality engine using all thirty\nfacets of the Five Factor model of personality and an AI system that is live\nthroughout gameplay. This paper discusses the research leading to Extreme AI;\ndevelops the ideas found in that thesis; discusses the development of other\npersonality engines; and provides examples of Extreme AI's use in two game\ndemos.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 22:40:29 GMT"}], "update_date": "2016-09-19", "authors_parsed": [["Georgeson", "Jeffrey", ""], ["Child", "Christopher", ""]]}, {"id": "1609.04904", "submitter": "Ethan Fast", "authors": "Ethan Fast and Eric Horvitz", "title": "Long-Term Trends in the Public Perception of Artificial Intelligence", "comments": "In AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyses of text corpora over time can reveal trends in beliefs, interest,\nand sentiment about a topic. We focus on views expressed about artificial\nintelligence (AI) in the New York Times over a 30-year period. General\ninterest, awareness, and discussion about AI has waxed and waned since the\nfield was founded in 1956. We present a set of measures that captures levels of\nengagement, measures of pessimism and optimism, the prevalence of specific\nhopes and concerns, and topics that are linked to discussions about AI over\ndecades. We find that discussion of AI has increased sharply since 2009, and\nthat these discussions have been consistently more optimistic than pessimistic.\nHowever, when we examine specific concerns, we find that worries of loss of\ncontrol of AI, ethical concerns for AI, and the negative impact of AI on work\nhave grown in recent years. We also find that hopes for AI in healthcare and\neducation have increased over time.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 03:45:15 GMT"}, {"version": "v2", "created": "Fri, 2 Dec 2016 17:18:42 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Fast", "Ethan", ""], ["Horvitz", "Eric", ""]]}, {"id": "1609.04994", "submitter": "Jan Leike", "authors": "Jan Leike", "title": "Exploration Potential", "comments": "10 pages, including proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce exploration potential, a quantity that measures how much a\nreinforcement learning agent has explored its environment class. In contrast to\ninformation gain, exploration potential takes the problem's reward structure\ninto account. This leads to an exploration criterion that is both necessary and\nsufficient for asymptotic optimality (learning to act optimally across the\nentire environment class). Our experiments in multi-armed bandits use\nexploration potential to illustrate how different algorithms make the tradeoff\nbetween exploration and exploitation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 10:55:27 GMT"}, {"version": "v2", "created": "Wed, 28 Sep 2016 14:22:32 GMT"}, {"version": "v3", "created": "Fri, 18 Nov 2016 11:17:56 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Leike", "Jan", ""]]}, {"id": "1609.05058", "submitter": "Jan Leike", "authors": "Jan Leike, Jessica Taylor, Benya Fallenstein", "title": "A Formal Solution to the Grain of Truth Problem", "comments": "UAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Bayesian agent acting in a multi-agent environment learns to predict the\nother agents' policies if its prior assigns positive probability to them (in\nother words, its prior contains a \\emph{grain of truth}). Finding a reasonably\nlarge class of policies that contains the Bayes-optimal policies with respect\nto this class is known as the \\emph{grain of truth problem}. Only small classes\nare known to have a grain of truth and the literature contains several related\nimpossibility results. In this paper we present a formal and general solution\nto the full grain of truth problem: we construct a class of policies that\ncontains all computable policies as well as Bayes-optimal policies for every\nlower semicomputable prior over the class. When the environment is unknown,\nBayes-optimal agents may fail to act optimally even asymptotically. However,\nagents based on Thompson sampling converge to play {\\epsilon}-Nash equilibria\nin arbitrary unknown computable multi-agent environments. While these results\nare purely theoretical, we show that they can be computationally approximated\narbitrarily closely.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 14:00:51 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Leike", "Jan", ""], ["Taylor", "Jessica", ""], ["Fallenstein", "Benya", ""]]}, {"id": "1609.05140", "submitter": "Pierre-Luc Bacon", "authors": "Pierre-Luc Bacon, Jean Harb and Doina Precup", "title": "The Option-Critic Architecture", "comments": "Accepted to the Thirthy-first AAAI Conference On Artificial\n  Intelligence (AAAI), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal abstraction is key to scaling up learning and planning in\nreinforcement learning. While planning with temporally extended actions is well\nunderstood, creating such abstractions autonomously from data has remained\nchallenging. We tackle this problem in the framework of options [Sutton, Precup\n& Singh, 1999; Precup, 2000]. We derive policy gradient theorems for options\nand propose a new option-critic architecture capable of learning both the\ninternal policies and the termination conditions of options, in tandem with the\npolicy over options, and without the need to provide any additional rewards or\nsubgoals. Experimental results in both discrete and continuous environments\nshowcase the flexibility and efficiency of the framework.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 17:05:55 GMT"}, {"version": "v2", "created": "Sat, 3 Dec 2016 02:47:51 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Bacon", "Pierre-Luc", ""], ["Harb", "Jean", ""], ["Precup", "Doina", ""]]}, {"id": "1609.05152", "submitter": "Gaetan Hadjeres", "authors": "Ga\\\"etan Hadjeres, Jason Sakellariou, Fran\\c{c}ois Pachet", "title": "Style Imitation and Chord Invention in Polyphonic Music with Exponential\n  Families", "comments": "18 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling polyphonic music is a particularly challenging task because of the\nintricate interplay between melody and harmony. A good model should satisfy\nthree requirements: statistical accuracy (capturing faithfully the statistics\nof correlations at various ranges, horizontally and vertically), flexibility\n(coping with arbitrary user constraints), and generalization capacity\n(inventing new material, while staying in the style of the training corpus).\nModels proposed so far fail on at least one of these requirements. We propose a\nstatistical model of polyphonic music, based on the maximum entropy principle.\nThis model is able to learn and reproduce pairwise statistics between\nneighboring note events in a given corpus. The model is also able to invent new\nchords and to harmonize unknown melodies. We evaluate the invention capacity of\nthe model by assessing the amount of cited, re-discovered, and invented chords\non a corpus of Bach chorales. We discuss how the model enables the user to\nspecify and enforce user-defined constraints, which makes it useful for\nstyle-based, interactive music generation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 17:45:39 GMT"}], "update_date": "2016-09-19", "authors_parsed": [["Hadjeres", "Ga\u00ebtan", ""], ["Sakellariou", "Jason", ""], ["Pachet", "Fran\u00e7ois", ""]]}, {"id": "1609.05170", "submitter": "Christophe Roche", "authors": "Christophe Roche", "title": "Should Terminology Principles be re-examined?", "comments": "Proceedings of the 10th Terminology and Knowledge Engineering\n  Conference (TKE 2012), pp.17-32. 19-22 June 2012, Madrid, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operationalization of terminology for IT applications has revived the\nWusterian approach. The conceptual dimension once more prevails after taking\nback seat to specialised lexicography. This is demonstrated by the emergence of\nontology in terminology. While the Terminology Principles as defined in Felber\nmanual and the ISO standards remain at the core of traditional terminology,\ntheir computational implementation raises some issues. In this article, while\nreiterating their importance, we will be re-examining these Principles from a\ndual perspective: that of logic in the mathematical sense of the term and that\nof epistemology as in the theory of knowledge. We will thus be clarifying and\ndescribing some of them so as to take into account advances in knowledge\nengineering (ontology) and formal systems (logic). The notion of\nontoterminology, terminology whose conceptual system is a formal ontology,\nresults from this approach.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 18:33:20 GMT"}], "update_date": "2016-09-19", "authors_parsed": [["Roche", "Christophe", ""]]}, {"id": "1609.05180", "submitter": "Shuhan Wang", "authors": "Shuhan Wang, Erik Andersen", "title": "Grammatical Templates: Improving Text Difficulty Evaluation for Language\n  Learners", "comments": null, "journal-ref": "The 26th International Conference on Computational Linguistics\n  (COLING), 2016", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language students are most engaged while reading texts at an appropriate\ndifficulty level. However, existing methods of evaluating text difficulty focus\nmainly on vocabulary and do not prioritize grammatical features, hence they do\nnot work well for language learners with limited knowledge of grammar. In this\npaper, we introduce grammatical templates, the expert-identified units of\ngrammar that students learn from class, as an important feature of text\ndifficulty evaluation. Experimental classification results show that\ngrammatical template features significantly improve text difficulty prediction\naccuracy over baseline readability features by 7.4%. Moreover, we build a\nsimple and human-understandable text difficulty evaluation approach with 87.7%\naccuracy, using only 5 grammatical template features.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 19:12:30 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2017 22:04:47 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Wang", "Shuhan", ""], ["Andersen", "Erik", ""]]}, {"id": "1609.05224", "submitter": "Anthony Young", "authors": "Anthony P. Young, Sanjay Modgil, Odinaldo Rodrigues", "title": "Prioritised Default Logic as Argumentation with Partial Order Default\n  Priorities", "comments": "50 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We express Brewka's prioritised default logic (PDL) as argumentation using\nASPIC+. By representing PDL as argumentation and designing an argument\npreference relation that takes the argument structure into account, we prove\nthat the conclusions of the justified arguments correspond to the PDL\nextensions. We will first assume that the default priority is total, and then\ngeneralise to the case where it is a partial order. This provides a\ncharacterisation of non-monotonic inference in PDL as an exchange of argument\nand counter-argument, providing a basis for distributed non-monotonic reasoning\nin the form of dialogue.\n", "versions": [{"version": "v1", "created": "Thu, 25 Aug 2016 20:51:07 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Young", "Anthony P.", ""], ["Modgil", "Sanjay", ""], ["Rodrigues", "Odinaldo", ""]]}, {"id": "1609.05228", "submitter": "Abdorrahman Haeri", "authors": "Abdorrahman Haeri", "title": "Continuous occurrence theory", "comments": "This paper is not for public publication in this current form. It\n  needs major revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usually gradual and continuous changes in entities will lead to appear\nevents. But usually it is supposed that an event is occurred at once. In this\nresearch an integrated framework called continuous occurrence theory (COT) is\npresented to investigate respective path leading to occurrence of the events in\nthe real world. For this purpose initially fundamental concepts are defined.\nAfterwards, the appropriate tools such as occurrence variables computations,\noccurrence dependency function and occurrence model are introduced and\nexplained in a systematic manner. Indeed, COT provides the possibility to: (a)\nmonitor occurrence of events during time; (b) study background of the events;\n(c) recognize the relevant issues of each event; and (d) understand how these\nissues affect on the considered event. The developed framework (COT) provides\nthe necessary context to analyze accurately continual changes of the issues and\nthe relevant events in the various branches of science and business. Finally,\ntypical applications of COT and an applied modeling example of it have been\nexplained and a mathematical programming example is modeled in the occurrence\nbased environment.\n", "versions": [{"version": "v1", "created": "Sat, 6 Aug 2016 10:30:09 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 06:43:07 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Haeri", "Abdorrahman", ""]]}, {"id": "1609.05258", "submitter": "J\\\"urgen Leitner", "authors": "J\\\"urgen Leitner, Adam W. Tow, Jake E. Dean, Niko Suenderhauf, Joseph\n  W. Durham, Matthew Cooper, Markus Eich, Christopher Lehnert, Ruben Mangels,\n  Christopher McCool, Peter Kujala, Lachlan Nicholson, Trung Pham, James\n  Sergeant, Liao Wu, Fangyi Zhang, Ben Upcroft, and Peter Corke", "title": "The ACRV Picking Benchmark (APB): A Robotic Shelf Picking Benchmark to\n  Foster Reproducible Research", "comments": "8 pages, submitted to RA:Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic challenges like the Amazon Picking Challenge (APC) or the DARPA\nChallenges are an established and important way to drive scientific progress.\nThey make research comparable on a well-defined benchmark with equal test\nconditions for all participants. However, such challenge events occur only\noccasionally, are limited to a small number of contestants, and the test\nconditions are very difficult to replicate after the main event. We present a\nnew physical benchmark challenge for robotic picking: the ACRV Picking\nBenchmark (APB). Designed to be reproducible, it consists of a set of 42 common\nobjects, a widely available shelf, and exact guidelines for object arrangement\nusing stencils. A well-defined evaluation protocol enables the comparison of\n\\emph{complete} robotic systems -- including perception and manipulation --\ninstead of sub-systems only. Our paper also describes and reports results\nachieved by an open baseline system based on a Baxter robot.\n", "versions": [{"version": "v1", "created": "Sat, 17 Sep 2016 00:07:54 GMT"}, {"version": "v2", "created": "Wed, 14 Dec 2016 09:06:49 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Leitner", "J\u00fcrgen", ""], ["Tow", "Adam W.", ""], ["Dean", "Jake E.", ""], ["Suenderhauf", "Niko", ""], ["Durham", "Joseph W.", ""], ["Cooper", "Matthew", ""], ["Eich", "Markus", ""], ["Lehnert", "Christopher", ""], ["Mangels", "Ruben", ""], ["McCool", "Christopher", ""], ["Kujala", "Peter", ""], ["Nicholson", "Lachlan", ""], ["Pham", "Trung", ""], ["Sergeant", "James", ""], ["Wu", "Liao", ""], ["Zhang", "Fangyi", ""], ["Upcroft", "Ben", ""], ["Corke", "Peter", ""]]}, {"id": "1609.05315", "submitter": "Jeffrey Georgeson", "authors": "Jeffrey Georgeson", "title": "NPCs Vote! Changing Voter Reactions Over Time Using the Extreme AI\n  Personality Engine", "comments": "8 pages, 3 tables, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can non-player characters have human-realistic personalities, changing over\ntime depending on input from those around them? And can they have different\nreactions and thoughts about different people? Using Extreme AI, a\npsychology-based personality engine using the Five Factor model of personality,\nI answer these questions by creating personalities for 100 voters and allowing\nthem to react to two politicians to see if the NPC voters' choice of candidate\ndevelops in a realistic-seeming way, based on initial and changing personality\nfacets and on their differing feelings toward the politicians (in this case,\nacross liking, trusting, and feeling affiliated with the candidates). After 16\ntest runs, the voters did indeed change their attitudes and feelings toward the\ncandidates in different and yet generally realistic ways, and even changed\ntheir attitudes about other issues based on what a candidate extolled.\n", "versions": [{"version": "v1", "created": "Sat, 17 Sep 2016 11:21:17 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Georgeson", "Jeffrey", ""]]}, {"id": "1609.05367", "submitter": "Miquel Bofill", "authors": "Miquel Bofill, V\\'ictor Mu\\~noz, Javier Murillo", "title": "Solving the Wastewater Treatment Plant Problem with SMT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the Wastewater Treatment Plant Problem, a\nreal-world scheduling problem, and compare the performance of several tools on\nit. We show that, for a naive modeling, state-of-the-art SMT solvers outperform\nother tools ranging from mathematical programming to constraint programming. We\nuse both real and randomly generated benchmarks.\n  From this and similar results, we claim for the convenience of developing\ncompiler front-ends being able to translate from constraint programming\nlanguages to the SMT-LIB standard language.\n", "versions": [{"version": "v1", "created": "Sat, 17 Sep 2016 17:17:15 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Bofill", "Miquel", ""], ["Mu\u00f1oz", "V\u00edctor", ""], ["Murillo", "Javier", ""]]}, {"id": "1609.05401", "submitter": "Jose Alberto Garc\\'ia Guti\\'errez Sr.", "authors": "Jose A. Garc\\'ia Guti\\'errez", "title": "Applications of Data Mining (DM) in Science and Engineering: State of\n  the art and perspectives", "comments": "in Spanish", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The continuous increase in the availability of data of any kind, coupled with\nthe development of networks of high-speed communications, the popularization of\ncloud computing and the growth of data centers and the emergence of\nhigh-performance computing does essential the task to develop techniques that\nallow more efficient data processing and analyzing of large volumes datasets\nand extraction of valuable information. In the following pages we will discuss\nabout development of this field in recent decades, and its potential and\napplicability present in the various branches of scientific research. Also, we\ntry to review briefly the different families of algorithms that are included in\ndata mining research area, its scalability with increasing dimensionality of\nthe input data and how they can be addressed and what behavior different\nmethods in a scenario in which the information is distributed or decentralized\nprocessed so as to increment performance optimization in heterogeneous\nenvironments.\n", "versions": [{"version": "v1", "created": "Sat, 17 Sep 2016 22:22:17 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Guti\u00e9rrez", "Jose A. Garc\u00eda", ""]]}, {"id": "1609.05473", "submitter": "Lantao Yu", "authors": "Lantao Yu, Weinan Zhang, Jun Wang, Yong Yu", "title": "SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient", "comments": "The Thirty-First AAAI Conference on Artificial Intelligence (AAAI\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  As a new way of training generative models, Generative Adversarial Nets (GAN)\nthat uses a discriminative model to guide the training of the generative model\nhas enjoyed considerable success in generating real-valued data. However, it\nhas limitations when the goal is for generating sequences of discrete tokens. A\nmajor reason lies in that the discrete outputs from the generative model make\nit difficult to pass the gradient update from the discriminative model to the\ngenerative model. Also, the discriminative model can only assess a complete\nsequence, while for a partially generated sequence, it is non-trivial to\nbalance its current score and the future one once the entire sequence has been\ngenerated. In this paper, we propose a sequence generation framework, called\nSeqGAN, to solve the problems. Modeling the data generator as a stochastic\npolicy in reinforcement learning (RL), SeqGAN bypasses the generator\ndifferentiation problem by directly performing gradient policy update. The RL\nreward signal comes from the GAN discriminator judged on a complete sequence,\nand is passed back to the intermediate state-action steps using Monte Carlo\nsearch. Extensive experiments on synthetic data and real-world tasks\ndemonstrate significant improvements over strong baselines.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2016 11:42:23 GMT"}, {"version": "v2", "created": "Tue, 20 Sep 2016 09:44:18 GMT"}, {"version": "v3", "created": "Sun, 25 Sep 2016 13:06:24 GMT"}, {"version": "v4", "created": "Mon, 24 Oct 2016 13:19:26 GMT"}, {"version": "v5", "created": "Fri, 9 Dec 2016 14:37:13 GMT"}, {"version": "v6", "created": "Fri, 25 Aug 2017 16:22:57 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Yu", "Lantao", ""], ["Zhang", "Weinan", ""], ["Wang", "Jun", ""], ["Yu", "Yong", ""]]}, {"id": "1609.05518", "submitter": "Marta Garnelo", "authors": "Marta Garnelo, Kai Arulkumaran, Murray Shanahan", "title": "Towards Deep Symbolic Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) brings the power of deep neural networks to\nbear on the generic task of trial-and-error learning, and its effectiveness has\nbeen convincingly demonstrated on tasks such as Atari video games and the game\nof Go. However, contemporary DRL systems inherit a number of shortcomings from\nthe current generation of deep learning techniques. For example, they require\nvery large datasets to work effectively, entailing that they are slow to learn\neven when such datasets are available. Moreover, they lack the ability to\nreason on an abstract level, which makes it difficult to implement high-level\ncognitive functions such as transfer learning, analogical reasoning, and\nhypothesis-based reasoning. Finally, their operation is largely opaque to\nhumans, rendering them unsuitable for domains in which verifiability is\nimportant. In this paper, we propose an end-to-end reinforcement learning\narchitecture comprising a neural back end and a symbolic front end with the\npotential to overcome each of these shortcomings. As proof-of-concept, we\npresent a preliminary implementation of the architecture and apply it to\nseveral variants of a simple video game. We show that the resulting system --\nthough just a prototype -- learns effectively, and, by acquiring a set of\nsymbolic rules that are easily comprehensible to humans, dramatically\noutperforms a conventional, fully neural DRL system on a stochastic variant of\nthe game.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2016 17:28:22 GMT"}, {"version": "v2", "created": "Sat, 1 Oct 2016 16:19:56 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Garnelo", "Marta", ""], ["Arulkumaran", "Kai", ""], ["Shanahan", "Murray", ""]]}, {"id": "1609.05521", "submitter": "Devendra Singh Chaplot", "authors": "Guillaume Lample, Devendra Singh Chaplot", "title": "Playing FPS Games with Deep Reinforcement Learning", "comments": "The authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep reinforcement learning have allowed autonomous agents to\nperform well on Atari games, often outperforming humans, using only raw pixels\nto make their decisions. However, most of these games take place in 2D\nenvironments that are fully observable to the agent. In this paper, we present\nthe first architecture to tackle 3D environments in first-person shooter games,\nthat involve partially observable states. Typically, deep reinforcement\nlearning methods only utilize visual input for training. We present a method to\naugment these models to exploit game feature information such as the presence\nof enemies or items, during the training phase. Our model is trained to\nsimultaneously learn these features along with minimizing a Q-learning\nobjective, which is shown to dramatically improve the training speed and\nperformance of our agent. Our architecture is also modularized to allow\ndifferent models to be independently trained for different phases of the game.\nWe show that the proposed architecture substantially outperforms built-in AI\nagents of the game as well as humans in deathmatch scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2016 17:52:28 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 15:13:59 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Lample", "Guillaume", ""], ["Chaplot", "Devendra Singh", ""]]}, {"id": "1609.05566", "submitter": "Russell Stewart", "authors": "Russell Stewart, Stefano Ermon", "title": "Label-Free Supervision of Neural Networks with Physics and Domain\n  Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many machine learning applications, labeled data is scarce and obtaining\nmore labels is expensive. We introduce a new approach to supervising neural\nnetworks by specifying constraints that should hold over the output space,\nrather than direct examples of input-output pairs. These constraints are\nderived from prior domain knowledge, e.g., from known laws of physics. We\ndemonstrate the effectiveness of this approach on real world and simulated\ncomputer vision tasks. We are able to train a convolutional neural network to\ndetect and track objects without any labeled examples. Our approach can\nsignificantly reduce the need for labeled training data, but introduces new\nchallenges for encoding prior knowledge into appropriate loss functions.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2016 23:16:14 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Stewart", "Russell", ""], ["Ermon", "Stefano", ""]]}, {"id": "1609.05600", "submitter": "Damien Teney", "authors": "Damien Teney, Lingqiao Liu, Anton van den Hengel", "title": "Graph-Structured Representations for Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes to improve visual question answering (VQA) with\nstructured representations of both scene contents and questions. A key\nchallenge in VQA is to require joint reasoning over the visual and text\ndomains. The predominant CNN/LSTM-based approach to VQA is limited by\nmonolithic vector representations that largely ignore structure in the scene\nand in the form of the question. CNN feature vectors cannot effectively capture\nsituations as simple as multiple object instances, and LSTMs process questions\nas series of words, which does not reflect the true complexity of language\nstructure. We instead propose to build graphs over the scene objects and over\nthe question words, and we describe a deep neural network that exploits the\nstructure in these representations. This shows significant benefit over the\nsequential processing of LSTMs. The overall efficacy of our approach is\ndemonstrated by significant improvements over the state-of-the-art, from 71.2%\nto 74.4% in accuracy on the \"abstract scenes\" multiple-choice benchmark, and\nfrom 34.7% to 39.1% in accuracy over pairs of \"balanced\" scenes, i.e. images\nwith fine-grained differences and opposite yes/no answers to a same question.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 05:21:36 GMT"}, {"version": "v2", "created": "Thu, 30 Mar 2017 04:26:26 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Teney", "Damien", ""], ["Liu", "Lingqiao", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1609.05616", "submitter": "Kumar Sankar Ray", "authors": "Kumar Sankar Ray, Sandip Paul, Diganta Saha", "title": "Preorder-Based Triangle: A Modified Version of Bilattice-Based Triangle\n  for Belief Revision in Nonmonotonic Reasoning", "comments": null, "journal-ref": "Journal of Experimental & Theoretical Artificial Intelligence\n  Volume 30, 2018 - Issue 5", "doi": "10.1080/0952813X.2018.1467493", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilattice-based triangle provides an elegant algebraic structure for\nreasoning with vague and uncertain information. But the truth and knowledge\nordering of intervals in bilattice-based triangle can not handle repetitive\nbelief revisions which is an essential characteristic of nonmonotonic\nreasoning. Moreover the ordering induced over the intervals by the\nbilattice-based triangle is not sometimes intuitive. In this work, we construct\nan alternative algebraic structure, namely preorder-based triangle and we\nformulate proper logical connectives for this. It is also demonstrated that\nPreorder-based triangle serves to be a better alternative to the\nbilattice-based triangle for reasoning in application areas, that involve\nnonmonotonic fuzzy reasoning with uncertain information.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 07:28:43 GMT"}, {"version": "v2", "created": "Tue, 3 Jan 2017 10:37:58 GMT"}, {"version": "v3", "created": "Fri, 12 May 2017 09:04:31 GMT"}, {"version": "v4", "created": "Tue, 7 Nov 2017 18:26:49 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Ray", "Kumar Sankar", ""], ["Paul", "Sandip", ""], ["Saha", "Diganta", ""]]}, {"id": "1609.05621", "submitter": "J\\\"urgen Koslowski", "authors": "Franz Baader and Stefan Borgwardt and Barbara Morawska (Technische\n  Universit\\\"at Dresden)", "title": "Extending Unification in $\\mathcal{EL}$ to Disunification: The Case of\n  Dismatching and Local Disunification", "comments": "32 pages, extended version of a paper from RTA'15", "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 4 (April 27,\n  2017) lmcs:2063", "doi": "10.2168/LMCS-12(4:1)2016", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unification in Description Logics has been introduced as a means to detect\nredundancies in ontologies. We try to extend the known decidability results for\nunification in the Description Logic $\\mathcal{EL}$ to disunification since\nnegative constraints can be used to avoid unwanted unifiers. While decidability\nof the solvability of general $\\mathcal{EL}$-disunification problems remains an\nopen problem, we obtain NP-completeness results for two interesting special\ncases: dismatching problems, where one side of each negative constraint must be\nground, and local solvability of disunification problems, where we consider\nonly solutions that are constructed from terms occurring in the input problem.\nMore precisely, we first show that dismatching can be reduced to local\ndisunification, and then provide two complementary NP-algorithms for finding\nlocal solutions of disunification problems.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 07:45:50 GMT"}, {"version": "v2", "created": "Wed, 5 Oct 2016 21:44:19 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Baader", "Franz", "", "Technische\n  Universit\u00e4t Dresden"], ["Borgwardt", "Stefan", "", "Technische\n  Universit\u00e4t Dresden"], ["Morawska", "Barbara", "", "Technische\n  Universit\u00e4t Dresden"]]}, {"id": "1609.05632", "submitter": "Tomas Teijeiro", "authors": "Tom\\'as Teijeiro and Paulo F\\'elix", "title": "On the adoption of abductive reasoning for time series interpretation", "comments": "44 pages, 9 figures", "journal-ref": "Artificial Intelligence 262C (2018) pp. 163-188", "doi": "10.1016/j.artint.2018.06.005", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series interpretation aims to provide an explanation of what is observed\nin terms of its underlying processes. The present work is based on the\nassumption that the common classification-based approaches to time series\ninterpretation suffer from a set of inherent weaknesses, whose ultimate cause\nlies in the monotonic nature of the deductive reasoning paradigm. In this\ndocument we propose a new approach to this problem, based on the initial\nhypothesis that abductive reasoning properly accounts for the human ability to\nidentify and characterize the patterns appearing in a time series. The result\nof this interpretation is a set of conjectures in the form of observations,\norganized into an abstraction hierarchy and explaining what has been observed.\nA knowledge-based framework and a set of algorithms for the interpretation task\nare provided, implementing a hypothesize-and-test cycle guided by an\nattentional mechanism. As a representative application domain, interpretation\nof the electrocardiogram allows us to highlight the strengths of the proposed\napproach in comparison with traditional classification-based approaches.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 08:31:18 GMT"}, {"version": "v2", "created": "Wed, 20 Dec 2017 11:15:01 GMT"}, {"version": "v3", "created": "Mon, 25 Jun 2018 07:32:57 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Teijeiro", "Tom\u00e1s", ""], ["F\u00e9lix", "Paulo", ""]]}, {"id": "1609.05705", "submitter": "Renato Krohling", "authors": "R.A. Krohling, Artem dos Santos, A.G.C. Pacheco", "title": "TODIM and TOPSIS with Z-numbers", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an approach that is able to handle with Z-numbers\nin the context of Multi-Criteria Decision Making (MCDM) problems. Z-numbers are\ncomposed of two parts, the first one is a restriction on the values that can be\nassumed, and the second part is the reliability of the information. As human\nbeings we communicate with other people by means of natural language using\nsentences like: the journey time from home to university takes about half hour,\nvery likely. Firstly, Z-numbers are converted to fuzzy numbers using a standard\nprocedure. Next, the Z-TODIM and Z-TOPSIS are presented as a direct extension\nof the fuzzy TODIM and fuzzy TOPSIS, respectively. The proposed methods are\napplied to two case studies and compared with the standard approach using crisp\nvalues. Results obtained show the feasibility of the approach. In addition, a\ngraphical interface was built to handle with both methods Z- TODIM and Z-TOPSIS\nallowing ease of use for user in other areas of knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 13:13:19 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Krohling", "R. A.", ""], ["Santos", "Artem dos", ""], ["Pacheco", "A. G. C.", ""]]}, {"id": "1609.05774", "submitter": "Ashlynn Daughton", "authors": "A.R. Daughton, R. Priedhorsky, G. Fairchild, N. Generous, A.\n  Hengartner, E. Abeyta, N. Velappan, A. Lillo, K. Stark, A. Deshpande", "title": "A globally-applicable disease ontology for biosurveillance; Anthology of\n  Biosurveillance Diseases (ABD)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biosurveillance, a relatively young field, has recently increased in\nimportance because of its relevance to national security and global health.\nDatabases and tools describing particular subsets of disease are becoming\nincreasingly common in the field. However, a common method to describe those\ndiseases is lacking. Here, we present the Anthology of Biosurveillance Diseases\n(ABD), an ontology of infectious diseases of biosurveillance relevance.\n", "versions": [{"version": "v1", "created": "Thu, 25 Aug 2016 19:37:47 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Daughton", "A. R.", ""], ["Priedhorsky", "R.", ""], ["Fairchild", "G.", ""], ["Generous", "N.", ""], ["Hengartner", "A.", ""], ["Abeyta", "E.", ""], ["Velappan", "N.", ""], ["Lillo", "A.", ""], ["Stark", "K.", ""], ["Deshpande", "A.", ""]]}, {"id": "1609.05787", "submitter": "Qiang Liu", "authors": "Qiang Liu, Shu Wu, Diyi Wang, Zhaokang Li, Liang Wang", "title": "Context-aware Sequential Recommendation", "comments": "IEEE International Conference on Data Mining (ICDM) 2016, to apear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since sequential information plays an important role in modeling user\nbehaviors, various sequential recommendation methods have been proposed.\nMethods based on Markov assumption are widely-used, but independently combine\nseveral most recent components. Recently, Recurrent Neural Networks (RNN) based\nmethods have been successfully applied in several sequential modeling tasks.\nHowever, for real-world applications, these methods have difficulty in modeling\nthe contextual information, which has been proved to be very important for\nbehavior modeling. In this paper, we propose a novel model, named Context-Aware\nRecurrent Neural Networks (CA-RNN). Instead of using the constant input matrix\nand transition matrix in conventional RNN models, CA-RNN employs adaptive\ncontext-specific input matrices and adaptive context-specific transition\nmatrices. The adaptive context-specific input matrices capture external\nsituations where user behaviors happen, such as time, location, weather and so\non. And the adaptive context-specific transition matrices capture how lengths\nof time intervals between adjacent behaviors in historical sequences affect the\ntransition of global sequential features. Experimental results show that the\nproposed CA-RNN model yields significant improvements over state-of-the-art\nsequential recommendation methods and context-aware recommendation methods on\ntwo public datasets, i.e., the Taobao dataset and the Movielens-1M dataset.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 15:33:46 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Liu", "Qiang", ""], ["Wu", "Shu", ""], ["Wang", "Diyi", ""], ["Li", "Zhaokang", ""], ["Wang", "Liang", ""]]}, {"id": "1609.05796", "submitter": "Siamak Ravanbakhsh", "authors": "Siamak Ravanbakhsh and Francois Lanusse and Rachel Mandelbaum and Jeff\n  Schneider and Barnabas Poczos", "title": "Enabling Dark Energy Science with Deep Generative Models of Galaxy\n  Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.CO cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the nature of dark energy, the mysterious force driving the\naccelerated expansion of the Universe, is a major challenge of modern\ncosmology. The next generation of cosmological surveys, specifically designed\nto address this issue, rely on accurate measurements of the apparent shapes of\ndistant galaxies. However, shape measurement methods suffer from various\nunavoidable biases and therefore will rely on a precise calibration to meet the\naccuracy requirements of the science analysis. This calibration process remains\nan open challenge as it requires large sets of high quality galaxy images. To\nthis end, we study the application of deep conditional generative models in\ngenerating realistic galaxy images. In particular we consider variations on\nconditional variational autoencoder and introduce a new adversarial objective\nfor training of conditional generative networks. Our results suggest a reliable\nalternative to the acquisition of expensive high quality observations for\ngenerating the calibration data needed by the next generation of cosmological\nsurveys.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 15:48:03 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2016 16:57:52 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Ravanbakhsh", "Siamak", ""], ["Lanusse", "Francois", ""], ["Mandelbaum", "Rachel", ""], ["Schneider", "Jeff", ""], ["Poczos", "Barnabas", ""]]}, {"id": "1609.05811", "submitter": "Pedro Cabalar", "authors": "Felicidad Aguado, Pedro Cabalar, Mart\\'in Di\\'eguez, Gilberto P\\'erez,\n  Concepci\\'on Vidal", "title": "Temporal Logic Programs with Variables", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we consider the problem of introducing variables in temporal\nlogic programs under the formalism of \"Temporal Equilibrium Logic\" (TEL), an\nextension of Answer Set Programming (ASP) for dealing with linear-time modal\noperators. To this aim, we provide a definition of a first-order version of TEL\nthat shares the syntax of first-order Linear-time Temporal Logic (LTL) but has\na different semantics, selecting some LTL models we call \"temporal stable\nmodels\". Then, we consider a subclass of theories (called \"splittable temporal\nlogic programs\") that are close to usual logic programs but allowing a\nrestricted use of temporal operators. In this setting, we provide a syntactic\ndefinition of \"safe variables\" that suffices to show the property of \"domain\nindependence\" -- that is, addition of arbitrary elements in the universe does\nnot vary the set of temporal stable models. Finally, we present a method for\ncomputing the derivable facts by constructing a non-temporal logic program with\nvariables that is fed to a standard ASP grounder. The information provided by\nthe grounder is then used to generate a subset of ground temporal rules which\nis equivalent to (and generally smaller than) the full program instantiation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 16:11:49 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Aguado", "Felicidad", ""], ["Cabalar", "Pedro", ""], ["Di\u00e9guez", "Mart\u00edn", ""], ["P\u00e9rez", "Gilberto", ""], ["Vidal", "Concepci\u00f3n", ""]]}, {"id": "1609.05835", "submitter": "Ender Ozcan", "authors": "Martin Baumers, Ender Ozcan", "title": "Scope for Machine Learning in Digital Manufacturing", "comments": "Royal Society Workshop on Realising the Benefits of Machine Learning\n  in Manufacturing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This provocation paper provides an overview of the underlying optimisation\nproblem in the emerging field of Digital Manufacturing. Initially, this paper\ndiscusses how the notion of Digital Manufacturing is transforming from a term\ndescribing a suite of software tools for the integration of production and\ndesign functions towards a more general concept incorporating computerised\nmanufacturing and supply chain processes, as well as information collection and\nutilisation across the product life cycle. On this basis, we use the example of\none such manufacturing process, Additive Manufacturing, to identify an\nintegrated multi-objective optimisation problem underlying Digital\nManufacturing. Forming an opportunity for a concurrent application of data\nscience and optimisation, a set of challenges arising from this problem is\noutlined.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 17:27:56 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Baumers", "Martin", ""], ["Ozcan", "Ender", ""]]}, {"id": "1609.05876", "submitter": "Roberto Alonso", "authors": "Roberto Alonso, Ra\\'ul Monroy, Eduardo Aguirre", "title": "On the Phase Transition of Finding a Biclique in a larger Bipartite\n  Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on the phase transition of finding a complete subgraph, of\nspecified dimensions, in a bipartite graph. Finding a complete subgraph in a\nbipartite graph is a problem that has growing attention in several domains,\nincluding bioinformatics, social network analysis and domain clustering. A key\nstep for a successful phase transition study is identifying a suitable order\nparameter, when none is known. To this purpose, we have applied a decision tree\nclassifier to real-world instances of this problem, in order to understand what\nproblem features separate an instance that is hard to solve from those that is\nnot. We have successfully identified one such order parameter and with it the\nphase transition of finding a complete bipartite subgraph of specified\ndimensions. Our phase transition study shows an\neasy-to-hard-to-easy-to-hard-to-easy pattern. Further, our results indicate\nthat the hardest instances are in a region where it is more likely that the\ncorresponding bipartite graph will have a complete subgraph of specified\ndimensions, a positive answer. By contrast, instances with a negative answer\nare more likely to appear in a region where the computational cost is\nnegligible. This behaviour is remarkably similar for problems of a number of\ndifferent sizes.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 19:22:08 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Alonso", "Roberto", ""], ["Monroy", "Ra\u00fal", ""], ["Aguirre", "Eduardo", ""]]}, {"id": "1609.05881", "submitter": "Priyank Jaini", "authors": "Priyank Jaini and Pascal Poupart", "title": "Online and Distributed learning of Gaussian mixture models by Bayesian\n  Moment Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gaussian mixture model is a classic technique for clustering and data\nmodeling that is used in numerous applications. With the rise of big data,\nthere is a need for parameter estimation techniques that can handle streaming\ndata and distribute the computation over several processors. While online\nvariants of the Expectation Maximization (EM) algorithm exist, their data\nefficiency is reduced by a stochastic approximation of the E-step and it is not\nclear how to distribute the computation over multiple processors. We propose a\nBayesian learning technique that lends itself naturally to online and\ndistributed computation. Since the Bayesian posterior is not tractable, we\nproject it onto a family of tractable distributions after each observation by\nmatching a set of sufficient moments. This Bayesian moment matching technique\ncompares favorably to online EM in terms of time and accuracy on a set of data\nmodeling benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 19:44:06 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Jaini", "Priyank", ""], ["Poupart", "Pascal", ""]]}, {"id": "1609.05960", "submitter": "Oktay Arslan Oktay Arslan", "authors": "Oktay Arslan and Panagiotis Tsiotras", "title": "Incremental Sampling-based Motion Planners Using Policy Iteration\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in randomized motion planners has led to the development of a\nnew class of sampling-based algorithms that provide asymptotic optimality\nguarantees, notably the RRT* and the PRM* algorithms. Careful analysis reveals\nthat the so-called \"rewiring\" step in these algorithms can be interpreted as a\nlocal policy iteration (PI) step (i.e., a local policy evaluation step followed\nby a local policy improvement step) so that asymptotically, as the number of\nsamples tend to infinity, both algorithms converge to the optimal path almost\nsurely (with probability 1). Policy iteration, along with value iteration (VI)\nare common methods for solving dynamic programming (DP) problems. Based on this\nobservation, recently, the RRT$^{\\#}$ algorithm has been proposed, which\nperforms, during each iteration, Bellman updates (aka \"backups\") on those\nvertices of the graph that have the potential of being part of the optimal path\n(i.e., the \"promising\" vertices). The RRT$^{\\#}$ algorithm thus utilizes\ndynamic programming ideas and implements them incrementally on randomly\ngenerated graphs to obtain high quality solutions. In this work, and based on\nthis key insight, we explore a different class of dynamic programming\nalgorithms for solving shortest-path problems on random graphs generated by\niterative sampling methods. These class of algorithms utilize policy iteration\ninstead of value iteration, and thus are better suited for massive\nparallelization. Contrary to the RRT* algorithm, the policy improvement during\nthe rewiring step is not performed only locally but rather on a set of vertices\nthat are classified as \"promising\" during the current iteration. This tends to\nspeed-up the whole process. The resulting algorithm, aptly named Policy\nIteration-RRT$^{\\#}$ (PI-RRT$^{\\#}$) is the first of a new class of DP-inspired\nalgorithms for randomized motion planning that utilize PI methods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 22:36:03 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Arslan", "Oktay", ""], ["Tsiotras", "Panagiotis", ""]]}, {"id": "1609.05989", "submitter": "Mohammed Korayem", "authors": "Mohammed Korayem, Khalifeh Aljadda, and Trey Grainger", "title": "Macro-optimization of email recommendation response rates harnessing\n  individual activity levels and group affinity trends", "comments": "This version is accepted as regular paper in The 15th IEEE\n  International Conference on Machine Learning and Applications (IEEE ICMLA'16)\n  . pre-camera ready version", "journal-ref": "The 15th IEEE International Conference on Machine Learning and\n  Applications (IEEE ICMLA'16) , 2016", "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation emails are among the best ways to re-engage with customers\nafter they have left a website. While on-site recommendation systems focus on\nfinding the most relevant items for a user at the moment (right item), email\nrecommendations add two critical additional dimensions: who to send\nrecommendations to (right person) and when to send them (right time). It is\ncritical that a recommendation email system not send too many emails to too\nmany users in too short of a time-window, as users may unsubscribe from future\nemails or become desensitized and ignore future emails if they receive too\nmany. Also, email service providers may mark such emails as spam if too many of\ntheir users are contacted in a short time-window. Optimizing email\nrecommendation systems such that they can yield a maximum response rate for a\nminimum number of email sends is thus critical for the long-term performance of\nsuch a system. In this paper, we present a novel recommendation email system\nthat not only generates recommendations, but which also leverages a combination\nof individual user activity data, as well as the behavior of the group to which\nthey belong, in order to determine each user's likelihood to respond to any\ngiven set of recommendations within a given time period. In doing this, we have\neffectively created a meta-recommendation system which recommends sets of\nrecommendations in order to optimize the aggregate response rate of the entire\nsystem. The proposed technique has been applied successfully within\nCareerBuilder's job recommendation email system to generate a 50\\% increase in\ntotal conversions while also decreasing sent emails by 72%\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 01:49:00 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Korayem", "Mohammed", ""], ["Aljadda", "Khalifeh", ""], ["Grainger", "Trey", ""]]}, {"id": "1609.06221", "submitter": "Avnish Chandra Suman", "authors": "Saraswati Mishra, Avnish Chandra Suman", "title": "An Efficient Method of Partitioning High Volumes of Multidimensional\n  Data for Parallel Clustering Algorithms", "comments": "5 pages, 6 figures", "journal-ref": "Int. Journal of Engineering Research and Application ISSN :\n  2248-9622, Vol. 6, Issue 8, August 2016, pp.67-71", "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An optimal data partitioning in parallel & distributed implementation of\nclustering algorithms is a necessary computation as it ensures independent task\ncompletion, fair distribution, less number of affected points and better &\nfaster merging. Though partitioning using Kd Tree is being conventionally used\nin academia, it suffers from performance drenches and bias (non equal\ndistribution) as dimensionality of data increases and hence is not suitable for\npractical use in industry where dimensionality can be of order of 100s to\n1000s. To address these issues we propose two new partitioning techniques using\nexisting mathematical models & study their feasibility, performance (bias and\npartitioning speed) & possible variants in choosing initial seeds. First method\nuses an n dimensional hashed grid based approach which is based on mapping the\npoints in space to a set of cubes which hashes the points. Second method uses a\ntree of voronoi planes where each plane corresponds to a partition. We found\nthat grid based approach was computationally impractical, while using a tree of\nvoronoi planes (using scalable K-Means++ initial seeds) drastically\noutperformed the Kd-tree tree method as dimensionality increased.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 15:26:37 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Mishra", "Saraswati", ""], ["Suman", "Avnish Chandra", ""]]}, {"id": "1609.06265", "submitter": "Faizan Javed", "authors": "Janani Balaji, Faizan Javed, Mayank Kejriwal, Chris Min, Sam Sander\n  and Ozgur Ozturk", "title": "An Ensemble Blocking Scheme for Entity Resolution of Large and Sparse\n  Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity Resolution, also called record linkage or deduplication, refers to the\nprocess of identifying and merging duplicate versions of the same entity into a\nunified representation. The standard practice is to use a Rule based or Machine\nLearning based model that compares entity pairs and assigns a score to\nrepresent the pairs' Match/Non-Match status. However, performing an exhaustive\npair-wise comparison on all pairs of records leads to quadratic matcher\ncomplexity and hence a Blocking step is performed before the Matching to group\nsimilar entities into smaller blocks that the matcher can then examine\nexhaustively. Several blocking schemes have been developed to efficiently and\neffectively block the input dataset into manageable groups. At CareerBuilder\n(CB), we perform deduplication on massive datasets of people profiles collected\nfrom disparate sources with varying informational content. We observed that,\nemploying a single blocking technique did not cover the base for all possible\nscenarios due to the multi-faceted nature of our data sources. In this paper,\nwe describe our ensemble approach to blocking that combines two different\nblocking techniques to leverage their respective strengths.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 17:44:28 GMT"}, {"version": "v2", "created": "Wed, 21 Sep 2016 00:26:17 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Balaji", "Janani", ""], ["Javed", "Faizan", ""], ["Kejriwal", "Mayank", ""], ["Min", "Chris", ""], ["Sander", "Sam", ""], ["Ozturk", "Ozgur", ""]]}, {"id": "1609.06268", "submitter": "Faizan Javed", "authors": "Yun Zhu, Faizan Javed, Ozgur Ozturk", "title": "Semantic Similarity Strategies for Job Title Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic and accurate classification of items enables numerous downstream\napplications in many domains. These applications can range from faceted\nbrowsing of items to product recommendations and big data analytics. In the\nonline recruitment domain, we refer to classifying job ads to pre-defined or\ncustom occupation categories as job title classification. A large-scale job\ntitle classification system can power various downstream applications such as\nsemantic search, job recommendations and labor market analytics. In this paper,\nwe discuss experiments conducted to improve our in-house job title\nclassification system. The classification component of the system is composed\nof a two-stage coarse and fine level classifier cascade that classifies input\ntext such as job title and/or job ads to one of the thousands of job titles in\nour taxonomy. To improve classification accuracy and effectiveness, we\nexperiment with various semantic representation strategies such as average W2V\nvectors and document similarity measures such as Word Movers Distance (WMD).\nOur initial results show an overall improvement in accuracy of Carotene[1].\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 17:54:47 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Zhu", "Yun", ""], ["Javed", "Faizan", ""], ["Ozturk", "Ozgur", ""]]}, {"id": "1609.06354", "submitter": "Yonatan Vaizman", "authors": "Yonatan Vaizman and Katherine Ellis and Gert Lanckriet", "title": "Recognizing Detailed Human Context In-the-Wild from Smartphones and\n  Smartwatches", "comments": "This paper was accepted and is to appear in IEEE Pervasive Computing,\n  vol. 16, no. 4, October-December 2017, pp. 62-74", "journal-ref": "IEEE Pervasive Computing, vol. 16, no. 4, October-December 2017,\n  pp. 62-74", "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to automatically recognize a person's behavioral context can\ncontribute to health monitoring, aging care and many other domains. Validating\ncontext recognition in-the-wild is crucial to promote practical applications\nthat work in real-life settings. We collected over 300k minutes of sensor data\nwith context labels from 60 subjects. Unlike previous studies, our subjects\nused their own personal phone, in any way that was convenient to them, and\nengaged in their routine in their natural environments. Unscripted behavior and\nunconstrained phone usage resulted in situations that are harder to recognize.\nWe demonstrate how fusion of multi-modal sensors is important for resolving\nsuch cases. We present a baseline system, and encourage researchers to use our\npublic dataset to compare methods and improve context recognition in-the-wild.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 20:56:07 GMT"}, {"version": "v2", "created": "Thu, 29 Dec 2016 22:47:22 GMT"}, {"version": "v3", "created": "Wed, 17 May 2017 21:44:18 GMT"}, {"version": "v4", "created": "Sat, 30 Sep 2017 15:25:23 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Vaizman", "Yonatan", ""], ["Ellis", "Katherine", ""], ["Lanckriet", "Gert", ""]]}, {"id": "1609.06374", "submitter": "Dimitrios Adamos Dr", "authors": "Fotis Kalaganis (1), Dimitrios A. Adamos (2 and 3), Nikos Laskaris (1\n  and 3) ((1) AIIA Lab, Department of Informatics, Aristotle University of\n  Thessaloniki, (2) School of Music Studies, Aristotle University of\n  Thessaloniki, (3) Neuroinformatics GRoup, Aristotle University of\n  Thessaloniki)", "title": "A Consumer BCI for Automated Music Evaluation Within a Popular On-Demand\n  Music Streaming Service - Taking Listener's Brainwaves to Extremes", "comments": "12th IFIP WG 12.5 International Conference and Workshops, AIAI 2016,\n  Thessaloniki, Greece, September 16-18, 2016, Proceedings", "journal-ref": "Artificial Intelligence Applications and Innovations, Volume 475\n  of the series IFIP Advances in Information and Communication Technology pp\n  429-440, 2016", "doi": "10.1007/978-3-319-44944-9_37", "report-no": null, "categories": "cs.AI cs.CY cs.HC cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigated the possibility of using a machine-learning scheme in\nconjunction with commercial wearable EEG-devices for translating listener's\nsubjective experience of music into scores that can be used for the automated\nannotation of music in popular on-demand streaming services. Based on the\nestablished -neuroscientifically sound- concepts of brainwave frequency bands,\nactivation asymmetry index and cross-frequency-coupling (CFC), we introduce a\nBrain Computer Interface (BCI) system that automatically assigns a rating score\nto the listened song. Our research operated in two distinct stages: i) a\ngeneric feature engineering stage, in which features from signal-analytics were\nranked and selected based on their ability to associate music induced\nperturbations in brainwaves with listener's appraisal of music. ii) a\npersonalization stage, during which the efficiency of ex- treme learning\nmachines (ELMs) is exploited so as to translate the derived pat- terns into a\nlistener's score. Encouraging experimental results, from a pragmatic use of the\nsystem, are presented.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 22:29:02 GMT"}, {"version": "v2", "created": "Fri, 30 Sep 2016 11:06:37 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Kalaganis", "Fotis", "", "2 and 3"], ["Adamos", "Dimitrios A.", "", "2 and 3"], ["Laskaris", "Nikos", "", "1\n  and 3"]]}, {"id": "1609.06375", "submitter": "Patrick Rodler", "authors": "Patrick Rodler", "title": "A Theory of Interactive Debugging of Knowledge Bases in Monotonic Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A broad variety of knowledge-based applications such as recommender, expert,\nplanning or configuration systems usually operate on the basis of knowledge\nrepresented by means of some logical language. Such a logical knowledge base\n(KB) enables intelligent behavior of such systems by allowing them to\nautomatically reason, answer queries of interest or solve complex real-world\nproblems. Nowadays, where information acquisition comes at low costs and often\nhappens automatically, the applied KBs are continuously growing in terms of\nsize, information content and complexity. These developments foster the\nemergence of errors in these KBs and thus pose a significant challenge on all\npeople and tools involved in KB evolution, maintenance and application.\n  If some minimal quality criteria such as logical consistency are not met by\nsome KB, it becomes useless for knowledge-based applications. To guarantee the\ncompliance of KBs with given requirements, (non-interactive) KB debuggers have\nbeen proposed. These however often cannot localize all potential faults,\nsuggest too large or incorrect modifications of the faulty KB or suffer from\npoor scalability due to the inherent complexity of the KB debugging problem.\n  As a remedy to these issues, based on a well-founded theoretical basis this\nwork proposes complete, sound and optimal methods for the interactive debugging\nof KBs that suggest the one (minimally invasive) error correction of the faulty\nKB that yields a repaired KB with exactly the intended semantics. Users, e.g.\ndomain experts, are involved in the debugging process by answering\nautomatically generated queries whether some given statements must or must not\nhold in the domain that should be modeled by the problematic KB at hand.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 22:31:38 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Rodler", "Patrick", ""]]}, {"id": "1609.06380", "submitter": "Yang Liu", "authors": "Yang Liu and Sujian Li", "title": "Recognizing Implicit Discourse Relations via Repeated Reading: Neural\n  Networks with Multi-Level Attention", "comments": "Accepted as long paper at EMNLP2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing implicit discourse relations is a challenging but important task\nin the field of Natural Language Processing. For such a complex text processing\ntask, different from previous studies, we argue that it is necessary to\nrepeatedly read the arguments and dynamically exploit the efficient features\nuseful for recognizing discourse relations. To mimic the repeated reading\nstrategy, we propose the neural networks with multi-level attention (NNMA),\ncombining the attention mechanism and external memories to gradually fix the\nattention on some specific words helpful to judging the discourse relations.\nExperiments on the PDTB dataset show that our proposed method achieves the\nstate-of-art results. The visualization of the attention weights also\nillustrates the progress that our model observes the arguments on each level\nand progressively locates the important words.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 22:59:19 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Liu", "Yang", ""], ["Li", "Sujian", ""]]}, {"id": "1609.06405", "submitter": "Yanjing Wang", "authors": "Chao Xu, Yanjing Wang, Thomas Studer", "title": "A Logic of Knowing Why", "comments": "34 pages, submitted, a new section added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When we say \"I know why he was late\", we know not only the fact that he was\nlate, but also an explanation of this fact. We propose a logical framework of\n\"knowing why\" inspired by the existing formal studies on why-questions,\nscientific explanation, and justification logic. We introduce the Ky_i operator\ninto the language of epistemic logic to express \"agent i knows why phi\" and\npropose a Kripke-style semantics of such expressions in terms of knowing an\nexplanation of phi. We obtain two sound and complete axiomatizations w.r.t. two\ndifferent model classes depending on different assumptions about introspection.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 02:16:14 GMT"}, {"version": "v2", "created": "Tue, 14 Mar 2017 23:14:28 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Xu", "Chao", ""], ["Wang", "Yanjing", ""], ["Studer", "Thomas", ""]]}, {"id": "1609.06492", "submitter": "Alessia Amelio Dr.", "authors": "Darko Brodic, Alessia Amelio, Zoran N. Milivojevic, Milena Jevtic", "title": "Document Image Coding and Clustering for Script Discrimination", "comments": "8 pages, 4 figures, 2 tables", "journal-ref": "ICIC Express Letters Vol. 10 n. 7 July 2016 pp. 1561-1566", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces a new method for discrimination of documents given in\ndifferent scripts. The document is mapped into a uniformly coded text of\nnumerical values. It is derived from the position of the letters in the text\nline, based on their typographical characteristics. Each code is considered as\na gray level. Accordingly, the coded text determines a 1-D image, on which\ntexture analysis by run-length statistics and local binary pattern is\nperformed. It defines feature vectors representing the script content of the\ndocument. A modified clustering approach employed on document feature vector\ngroups documents written in the same script. Experimentation performed on two\ncustom oriented databases of historical documents in old Cyrillic, angular and\nround Glagolitic as well as Antiqua and Fraktur scripts demonstrates the\nsuperiority of the proposed method with respect to well-known methods in the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 10:52:03 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Brodic", "Darko", ""], ["Amelio", "Alessia", ""], ["Milivojevic", "Zoran N.", ""], ["Jevtic", "Milena", ""]]}, {"id": "1609.06666", "submitter": "Martin Engelcke", "authors": "Martin Engelcke, Dushyant Rao, Dominic Zeng Wang, Chi Hay Tong, Ingmar\n  Posner", "title": "Vote3Deep: Fast Object Detection in 3D Point Clouds Using Efficient\n  Convolutional Neural Networks", "comments": "To be published at the IEEE International Conference on Robotics and\n  Automation 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a computationally efficient approach to detecting objects\nnatively in 3D point clouds using convolutional neural networks (CNNs). In\nparticular, this is achieved by leveraging a feature-centric voting scheme to\nimplement novel convolutional layers which explicitly exploit the sparsity\nencountered in the input. To this end, we examine the trade-off between\naccuracy and speed for different architectures and additionally propose to use\nan L1 penalty on the filter activations to further encourage sparsity in the\nintermediate representations. To the best of our knowledge, this is the first\nwork to propose sparse convolutional layers and L1 regularisation for efficient\nlarge-scale processing of 3D data. We demonstrate the efficacy of our approach\non the KITTI object detection benchmark and show that Vote3Deep models with as\nfew as three layers outperform the previous state of the art in both laser and\nlaser-vision based approaches by margins of up to 40% while remaining highly\ncompetitive in terms of processing time.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 18:32:11 GMT"}, {"version": "v2", "created": "Sun, 5 Mar 2017 15:29:45 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Engelcke", "Martin", ""], ["Rao", "Dushyant", ""], ["Wang", "Dominic Zeng", ""], ["Tong", "Chi Hay", ""], ["Posner", "Ingmar", ""]]}, {"id": "1609.06838", "submitter": "Jia Pan", "authors": "Pinxin Long and Wenxi Liu and Jia Pan", "title": "Deep-Learned Collision Avoidance Policy for Distributed Multi-Agent\n  Navigation", "comments": null, "journal-ref": "IEEE Robotics and Automation Letters 2(2): 656-663 (2017)", "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-speed, low-latency obstacle avoidance that is insensitive to sensor\nnoise is essential for enabling multiple decentralized robots to function\nreliably in cluttered and dynamic environments. While other distributed\nmulti-agent collision avoidance systems exist, these systems require online\ngeometric optimization where tedious parameter tuning and perfect sensing are\nnecessary.\n  We present a novel end-to-end framework to generate reactive collision\navoidance policy for efficient distributed multi-agent navigation. Our method\nformulates an agent's navigation strategy as a deep neural network mapping from\nthe observed noisy sensor measurements to the agent's steering commands in\nterms of movement velocity. We train the network on a large number of frames of\ncollision avoidance data collected by repeatedly running a multi-agent\nsimulator with different parameter settings. We validate the learned deep\nneural network policy in a set of simulated and real scenarios with noisy\nmeasurements and demonstrate that our method is able to generate a robust\nnavigation strategy that is insensitive to imperfect sensing and works reliably\nin all situations. We also show that our method can be well generalized to\nscenarios that do not appear in our training data, including scenes with static\nobstacles and agents with different sizes. Videos are available at\nhttps://sites.google.com/view/deepmaca.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 07:05:56 GMT"}, {"version": "v2", "created": "Thu, 6 Jul 2017 07:41:45 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Long", "Pinxin", ""], ["Liu", "Wenxi", ""], ["Pan", "Jia", ""]]}, {"id": "1609.06953", "submitter": "Azlan Iqbal", "authors": "Azlan Iqbal", "title": "The Digital Synaptic Neural Substrate: Size and Quality Matters", "comments": "7 pages, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the 'Digital Synaptic Neural Substrate' (DSNS) computational\ncreativity approach further with respect to the size and quality of images that\ncan be used to seed the process. In previous work we demonstrated how combining\nphotographs of people and sequences taken from chess games between weak players\ncan be used to generate chess problems or puzzles of higher aesthetic quality,\non average, compared to alternative approaches. In this work we show\nexperimentally that using larger images as opposed to smaller ones improves the\noutput quality even further. The same is also true for using clearer or less\ncorrupted images. The reasons why these things influence the DSNS process is\npresently not well-understood and debatable but the findings are nevertheless\nimmediately applicable for obtaining better results.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 11:26:46 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Iqbal", "Azlan", ""]]}, {"id": "1609.06954", "submitter": "Vaishak Belle", "authors": "Vaishak Belle, Luc De Raedt", "title": "Semiring Programming: A Declarative Framework for Generalized Sum\n  Product Problems", "comments": "In AAAI Workshop: Statistical Relational Artificial Intelligence,\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To solve hard problems, AI relies on a variety of disciplines such as logic,\nprobabilistic reasoning, machine learning and mathematical programming.\nAlthough it is widely accepted that solving real-world problems requires an\nintegration amongst these, contemporary representation methodologies offer\nlittle support for this.\n  In an attempt to alleviate this situation, we introduce a new declarative\nprogramming framework that provides abstractions of well-known problems such as\nSAT, Bayesian inference, generative models, and convex optimization. The\nsemantics of programs is defined in terms of first-order structures with\nsemiring labels, which allows us to freely combine and integrate problems from\ndifferent AI disciplines.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 08:17:40 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 13:55:44 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Belle", "Vaishak", ""], ["De Raedt", "Luc", ""]]}, {"id": "1609.07042", "submitter": "Xiang Xiang", "authors": "Xiang Xiang and Trac D. Tran", "title": "Pose-Selective Max Pooling for Measuring Similarity", "comments": "The tutorial and program associated with this paper are available at\n  https://github.com/eglxiang/ytf yet for non-commercial use", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we deal with two challenges for measuring the similarity of\nthe subject identities in practical video-based face recognition - the\nvariation of the head pose in uncontrolled environments and the computational\nexpense of processing videos. Since the frame-wise feature mean is unable to\ncharacterize the pose diversity among frames, we define and preserve the\noverall pose diversity and closeness in a video. Then, identity will be the\nonly source of variation across videos since the pose varies even within a\nsingle video. Instead of simply using all the frames, we select those faces\nwhose pose point is closest to the centroid of the K-means cluster containing\nthat pose point. Then, we represent a video as a bag of frame-wise deep face\nfeatures while the number of features has been reduced from hundreds to K.\nSince the video representation can well represent the identity, now we measure\nthe subject similarity between two videos as the max correlation among all\npossible pairs in the two bags of features. On the official 5,000 video-pairs\nof the YouTube Face dataset for face verification, our algorithm achieves a\ncomparable performance with VGG-face that averages over deep features of all\nframes. Other vision tasks can also benefit from the generic idea of employing\ngeometric cues to improve the descriptiveness of deep features.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 15:59:38 GMT"}, {"version": "v2", "created": "Mon, 26 Sep 2016 18:21:05 GMT"}, {"version": "v3", "created": "Thu, 10 Nov 2016 04:05:29 GMT"}, {"version": "v4", "created": "Mon, 14 Nov 2016 04:10:09 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Xiang", "Xiang", ""], ["Tran", "Trac D.", ""]]}, {"id": "1609.07102", "submitter": "Jos\\'e M. Gim\\'enez-Garc\\'ia", "authors": "Jos\\'e M. Gim\\'enez-Garc\\'ia, Antoine Zimmermann, Pierre Maret", "title": "NdFluents: A Multi-dimensional Contexts Ontology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Annotating semantic data with metadata is becoming more and more important to\nprovide information about the statements being asserted. While initial\nsolutions proposed a data model to represent a specific dimension of\nmeta-information (such as time or provenance), the need for a general\nannotation framework which allows representing different context dimensions is\nneeded. In this paper, we extend the 4dFluents ontology by Welty and Fikes---on\nassociating temporal validity to statements---to any dimension of context, and\ndiscuss possible issues that multidimensional context representations have to\nface and how we address them.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 18:37:12 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Gim\u00e9nez-Garc\u00eda", "Jos\u00e9 M.", ""], ["Zimmermann", "Antoine", ""], ["Maret", "Pierre", ""]]}, {"id": "1609.07127", "submitter": "Jacques Fleuriot", "authors": "Jacques Fleuriot, Steven Obua, Phil Scott", "title": "Social Network Processes in the Isabelle and Coq Theorem Proving\n  Communities", "comments": "15 pages, 13 figures, Research supported by EPSRC grant EP/L011794/1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LO physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify the main actors in the Isabelle and Coq communities and describe\nhow they affect and influence their peers. This work explores selected\nfoundations of social networking analysis that we expect to be useful in the\ncontext of the ProofPeer project, which is developing a new model for\ninteractive theorem proving based on collaboration and social interactions.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 19:46:08 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Fleuriot", "Jacques", ""], ["Obua", "Steven", ""], ["Scott", "Phil", ""]]}, {"id": "1609.07317", "submitter": "Yishu Miao", "authors": "Yishu Miao and Phil Blunsom", "title": "Language as a Latent Variable: Discrete Generative Models for Sentence\n  Compression", "comments": "EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore deep generative models of text in which the latent\nrepresentation of a document is itself drawn from a discrete language model\ndistribution. We formulate a variational auto-encoder for inference in this\nmodel and apply it to the task of compressing sentences. In this application\nthe generative model first draws a latent summary sentence from a background\nlanguage model, and then subsequently draws the observed sentence conditioned\non this latent summary. In our empirical evaluation we show that generative\nformulations of both abstractive and extractive compression yield\nstate-of-the-art results when trained on a large amount of supervised data.\nFurther, we explore semi-supervised compression scenarios where we show that it\nis possible to achieve performance competitive with previously proposed\nsupervised models while training on a fraction of the supervised data.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 11:25:41 GMT"}, {"version": "v2", "created": "Fri, 14 Oct 2016 00:21:00 GMT"}], "update_date": "2016-10-17", "authors_parsed": [["Miao", "Yishu", ""], ["Blunsom", "Phil", ""]]}, {"id": "1609.07365", "submitter": "Dimitrios Adamos Dr", "authors": "Dimitrios A. Adamos (1 and 3), Stavros I. Dimitriadis (2), Nikolaos A.\n  Laskaris (2 and 3), ((1) School of Music Studies, Faculty of Fine Arts,\n  Aristotle University of Thessaloniki, (2) AIIA Lab, Department of\n  Informatics, Aristotle University of Thessaloniki, (3) Neuroinformatics\n  GRoup, Aristotle University of Thessaloniki)", "title": "Towards the bio-personalization of music recommendation systems: A\n  single-sensor EEG biomarker of subjective music preference", "comments": null, "journal-ref": "Information Sciences, Volumes 343 - 344, 20 May 2016, Pages 94 -\n  108", "doi": "10.1016/j.ins.2016.01.005", "report-no": null, "categories": "q-bio.NC cs.AI cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in biosensors technology and mobile electroencephalographic\n(EEG) interfaces have opened new application fields for cognitive monitoring. A\ncomputable biomarker for the assessment of spontaneous aesthetic brain\nresponses during music listening is introduced here. It derives from\nwell-established measures of cross-frequency coupling (CFC) and quantifies the\nmusic-induced alterations in the dynamic relationships between brain rhythms.\nDuring a stage of exploratory analysis, and using the signals from a suitably\ndesigned experiment, we established the biomarker, which acts on brain\nactivations recorded over the left prefrontal cortex and focuses on the\nfunctional coupling between high-beta and low-gamma oscillations. Based on data\nfrom an additional experimental paradigm, we validated the introduced biomarker\nand showed its relevance for expressing the subjective aesthetic appreciation\nof a piece of music. Our approach resulted in an affordable tool that can\npromote human-machine interaction and, by serving as a personalized music\nannotation strategy, can be potentially integrated into modern flexible music\nrecommendation systems.\n  Keywords: Cross-frequency coupling; Human-computer interaction;\nBrain-computer interface\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 09:24:01 GMT"}], "update_date": "2016-09-26", "authors_parsed": [["Adamos", "Dimitrios A.", "", "1 and 3"], ["Dimitriadis", "Stavros I.", "", "2 and 3"], ["Laskaris", "Nikolaos A.", "", "2 and 3"]]}, {"id": "1609.07384", "submitter": "Anurag Kumar", "authors": "Anurag Kumar, Bhiksha Raj, Ndapandula Nakashole", "title": "Discovering Sound Concepts and Acoustic Relations In Text", "comments": "ICASSP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe approaches for discovering acoustic concepts and\nrelations in text. The first major goal is to be able to identify text phrases\nwhich contain a notion of audibility and can be termed as a sound or an\nacoustic concept. We also propose a method to define an acoustic scene through\na set of sound concepts. We use pattern matching and parts of speech tags to\ngenerate sound concepts from large scale text corpora. We use dependency\nparsing and LSTM recurrent neural network to predict a set of sound concepts\nfor a given acoustic scene. These methods are not only helpful in creating an\nacoustic knowledge base but in the future can also directly help acoustic event\nand scene detection research.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 14:35:17 GMT"}, {"version": "v2", "created": "Mon, 13 Feb 2017 01:09:27 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Kumar", "Anurag", ""], ["Raj", "Bhiksha", ""], ["Nakashole", "Ndapandula", ""]]}, {"id": "1609.07434", "submitter": "Matt Oberdorfer", "authors": "Matt Oberdorfer, Matt Abuzalaf", "title": "Regulating Reward Training by Means of Certainty Prediction in a Neural\n  Network-Implemented Pong Game", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first reinforcement-learning model to self-improve its\nreward-modulated training implemented through a continuously improving\n\"intuition\" neural network. An agent was trained how to play the arcade video\ngame Pong with two reward-based alternatives, one where the paddle was placed\nrandomly during training, and a second where the paddle was simultaneously\ntrained on three additional neural networks such that it could develop a sense\nof \"certainty\" as to how probable its own predicted paddle position will be to\nreturn the ball. If the agent was less than 95% certain to return the ball, the\npolicy used an intuition neural network to place the paddle. We trained both\narchitectures for an equivalent number of epochs and tested learning\nperformance by letting the trained programs play against a near-perfect\nopponent. Through this, we found that the reinforcement learning model that\nuses an intuition neural network for placing the paddle during reward training\nquickly overtakes the simple architecture in its ability to outplay the\nnear-perfect opponent, additionally outscoring that opponent by an increasingly\nwide margin after additional epochs of training.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 17:11:53 GMT"}], "update_date": "2016-09-26", "authors_parsed": [["Oberdorfer", "Matt", ""], ["Abuzalaf", "Matt", ""]]}, {"id": "1609.07460", "submitter": "Alexandros A. Voudouris", "authors": "Ioannis Caragiannis, Xenophon Chatzigeorgiou, George A. Krimpas,\n  Alexandros A. Voudouris", "title": "Optimizing positional scoring rules for rank aggregation", "comments": "Accepted to Artificial Intelligence Journal. A preliminary version\n  appeared in Proceedings of the 31st AAAI Conference on Artificial\n  Intelligence (AAAI), pages 430-436, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, several crowdsourcing projects exploit social choice methods for\ncomputing an aggregate ranking of alternatives given individual rankings\nprovided by workers. Motivated by such systems, we consider a setting where\neach worker is asked to rank a fixed (small) number of alternatives and, then,\na positional scoring rule is used to compute the aggregate ranking. Among the\napparently infinite such rules, what is the best one to use? To answer this\nquestion, we assume that we have partial access to an underlying true ranking.\nThen, the important optimization problem to be solved is to compute the\npositional scoring rule whose outcome, when applied to the profile of\nindividual rankings, is as close as possible to the part of the underlying true\nranking we know. We study this fundamental problem from a theoretical viewpoint\nand present positive and negative complexity results and, furthermore,\ncomplement our theoretical findings with experiments on real-world and\nsynthetic data.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2016 17:18:55 GMT"}, {"version": "v2", "created": "Sat, 24 Nov 2018 15:00:48 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Caragiannis", "Ioannis", ""], ["Chatzigeorgiou", "Xenophon", ""], ["Krimpas", "George A.", ""], ["Voudouris", "Alexandros A.", ""]]}, {"id": "1609.07480", "submitter": "Stylianos Kampakis", "authors": "Stylianos Kampakis", "title": "Predictive modelling of football injuries", "comments": "PhD Thesis submitted and defended successfully at the Department of\n  Computer Science at University College London", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this thesis is to investigate the potential of predictive\nmodelling for football injuries. This work was conducted in close collaboration\nwith Tottenham Hotspurs FC (THFC), the PGA European tour and the participation\nof Wolverhampton Wanderers (WW).\n  Three investigations were conducted:\n  1. Predicting the recovery time of football injuries using the UEFA injury\nrecordings: The UEFA recordings is a common standard for recording injuries in\nprofessional football. For this investigation, three datasets of UEFA injury\nrecordings were available. Different machine learning algorithms were used in\norder to build a predictive model. The performance of the machine learning\nmodels is then improved by using feature selection conducted through\ncorrelation-based subset feature selection and random forests.\n  2. Predicting injuries in professional football using exposure records: The\nrelationship between exposure (in training hours and match hours) in\nprofessional football athletes and injury incidence was studied. A common\nproblem in football is understanding how the training schedule of an athlete\ncan affect the chance of him getting injured. The task was to predict the\nnumber of days a player can train before he gets injured.\n  3. Predicting intrinsic injury incidence using in-training GPS measurements:\nA significant percentage of football injuries can be attributed to overtraining\nand fatigue. GPS data collected during training sessions might provide\nindicators of fatigue, or might be used to detect very intense training\nsessions which can lead to overtraining. This research used GPS data gathered\nduring training sessions of the first team of THFC, in order to predict whether\nan injury would take place during a week.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 11:58:42 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Kampakis", "Stylianos", ""]]}, {"id": "1609.07521", "submitter": "Michael Hughes", "authors": "Michael C. Hughes and Erik B. Sudderth", "title": "Fast Learning of Clusters and Topics via Sparse Posteriors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixture models and topic models generate each observation from a single\ncluster, but standard variational posteriors for each observation assign\npositive probability to all possible clusters. This requires dense storage and\nruntime costs that scale with the total number of clusters, even though\ntypically only a few clusters have significant posterior mass for any data\npoint. We propose a constrained family of sparse variational distributions that\nallow at most $L$ non-zero entries, where the tunable threshold $L$ trades off\nspeed for accuracy. Previous sparse approximations have used hard assignments\n($L=1$), but we find that moderate values of $L>1$ provide superior\nperformance. Our approach easily integrates with stochastic or incremental\noptimization algorithms to scale to millions of examples. Experiments training\nmixture models of image patches and topic models for news articles show that\nour approach produces better-quality models in far less time than baseline\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 21:18:31 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Hughes", "Michael C.", ""], ["Sudderth", "Erik B.", ""]]}, {"id": "1609.07560", "submitter": "Lantao Liu", "authors": "Kai-Chieh Ma, Lantao Liu, Gaurav S. Sukhatme", "title": "Informative Planning and Online Learning with Sparse Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A big challenge in environmental monitoring is the spatiotemporal variation\nof the phenomena to be observed. To enable persistent sensing and estimation in\nsuch a setting, it is beneficial to have a time-varying underlying\nenvironmental model. Here we present a planning and learning method that\nenables an autonomous marine vehicle to perform persistent ocean monitoring\ntasks by learning and refining an environmental model. To alleviate the\ncomputational bottleneck caused by large-scale data accumulated, we propose a\nframework that iterates between a planning component aimed at collecting the\nmost information-rich data, and a sparse Gaussian Process learning component\nwhere the environmental model and hyperparameters are learned online by taking\nadvantage of only a subset of data that provides the greatest contribution. Our\nsimulations with ground-truth ocean data shows that the proposed method is both\naccurate and efficient.\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2016 02:56:25 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Ma", "Kai-Chieh", ""], ["Liu", "Lantao", ""], ["Sukhatme", "Gaurav S.", ""]]}, {"id": "1609.07706", "submitter": "Lana Sinapayen", "authors": "Lana Sinapayen, Atsushi Masumori, Takashi Ikegami", "title": "Learning by Stimulation Avoidance: A Principle to Control Spiking Neural\n  Networks Dynamics", "comments": "17 pages, 11 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0170388", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning based on networks of real neurons, and by extension biologically\ninspired models of neural networks, has yet to find general learning rules\nleading to widespread applications. In this paper, we argue for the existence\nof a principle allowing to steer the dynamics of a biologically inspired neural\nnetwork. Using carefully timed external stimulation, the network can be driven\ntowards a desired dynamical state. We term this principle \"Learning by\nStimulation Avoidance\" (LSA). We demonstrate through simulation that the\nminimal sufficient conditions leading to LSA in artificial networks are also\nsufficient to reproduce learning results similar to those obtained in\nbiological neurons by Shahaf and Marom [1]. We examine the mechanism's basic\ndynamics in a reduced network, and demonstrate how it scales up to a network of\n100 neurons. We show that LSA has a higher explanatory power than existing\nhypotheses about the response of biological neural networks to external\nsimulation, and can be used as a learning rule for an embodied application:\nlearning of wall avoidance by a simulated robot. The surge in popularity of\nartificial neural networks is mostly directed to disembodied models of neurons\nwith biologically irrelevant dynamics: to the authors' knowledge, this is the\nfirst work demonstrating sensory-motor learning with random spiking networks\nthrough pure Hebbian learning.\n", "versions": [{"version": "v1", "created": "Sun, 25 Sep 2016 06:44:42 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 05:38:53 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Sinapayen", "Lana", ""], ["Masumori", "Atsushi", ""], ["Ikegami", "Takashi", ""]]}, {"id": "1609.07721", "submitter": "Diederik Aerts", "authors": "Diederik Aerts, Jonito Aerts Argu\\\"elles, Lester Beltran, Lyneth\n  Beltran, Massimiliano Sassoli de Bianchi, Sandro Sozzo and Tomas Veloz", "title": "Testing Quantum Models of Conjunction Fallacy on the World Wide Web", "comments": "12 pages", "journal-ref": "International Journal of Theoretical Physics, 56, pp. 3744-3756\n  (2017)", "doi": "10.1007/s10773-017-3288-8", "report-no": null, "categories": "cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 'conjunction fallacy' has been extensively debated by scholars in\ncognitive science and, in recent times, the discussion has been enriched by the\nproposal of modeling the fallacy using the quantum formalism. Two major quantum\napproaches have been put forward: the first assumes that respondents use a\ntwo-step sequential reasoning and that the fallacy results from the presence of\n'question order effects'; the second assumes that respondents evaluate the\ncognitive situation as a whole and that the fallacy results from the 'emergence\nof new meanings', as an 'effect of overextension' in the conceptual\nconjunction. Thus, the question arises as to determine whether and to what\nextent conjunction fallacies would result from 'order effects' or, instead,\nfrom 'emergence effects'. To help clarify this situation, we propose to use the\nWorld Wide Web as an 'information space' that can be interrogated both in a\nsequential and non-sequential way, to test these two quantum approaches. We\nfind that 'emergence effects', and not 'order effects', should be considered\nthe main cognitive mechanism producing the observed conjunction fallacies.\n", "versions": [{"version": "v1", "created": "Sun, 25 Sep 2016 09:58:14 GMT"}, {"version": "v2", "created": "Fri, 2 Jun 2017 23:30:10 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Aerts", "Diederik", ""], ["Argu\u00eblles", "Jonito Aerts", ""], ["Beltran", "Lester", ""], ["Beltran", "Lyneth", ""], ["de Bianchi", "Massimiliano Sassoli", ""], ["Sozzo", "Sandro", ""], ["Veloz", "Tomas", ""]]}, {"id": "1609.07772", "submitter": "J. G. Wolff", "authors": "J Gerard Wolff", "title": "Commonsense Reasoning, Commonsense Knowledge, and The SP Theory of\n  Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes how the \"SP Theory of Intelligence\" with the \"SP\nComputer Model\", outlined in an Appendix, may throw light on aspects of\ncommonsense reasoning (CSR) and commonsense knowledge (CSK), as discussed in\nanother paper by Ernest Davis and Gary Marcus (DM). In four main sections, the\npaper describes: 1) The main problems to be solved; 2) Other research on CSR\nand CSK; 3) Why the SP system may prove useful with CSR and CSK 4) How examples\ndescribed by DM may be modelled in the SP system. With regard to successes in\nthe automation of CSR described by DM, the SP system's strengths in\nsimplification and integration may promote seamless integration across these\nareas, and seamless integration of those area with other aspects of\nintelligence. In considering challenges in the automation of CSR described by\nDM, the paper describes in detail, with examples of SP-multiple-alignments. how\nthe SP system may model processes of interpretation and reasoning arising from\nthe horse's head scene in \"The Godfather\" film. A solution is presented to the\n'long tail' problem described by DM. The SP system has some potentially useful\nthings to say about several of DM's objectives for research in CSR and CSK.\n", "versions": [{"version": "v1", "created": "Sun, 25 Sep 2016 16:48:16 GMT"}, {"version": "v2", "created": "Sat, 4 Aug 2018 10:42:51 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Wolff", "J Gerard", ""]]}, {"id": "1609.07843", "submitter": "Richard Socher", "authors": "Stephen Merity and Caiming Xiong and James Bradbury and Richard Socher", "title": "Pointer Sentinel Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural network sequence models with softmax classifiers have achieved\ntheir best language modeling performance only with very large hidden states and\nlarge vocabularies. Even then they struggle to predict rare or unseen words\neven if the context makes the prediction unambiguous. We introduce the pointer\nsentinel mixture architecture for neural sequence models which has the ability\nto either reproduce a word from the recent context or produce a word from a\nstandard softmax classifier. Our pointer sentinel-LSTM model achieves state of\nthe art language modeling performance on the Penn Treebank (70.9 perplexity)\nwhile using far fewer parameters than a standard softmax LSTM. In order to\nevaluate how well language models can exploit longer contexts and deal with\nmore realistic vocabularies and larger corpora we also introduce the freely\navailable WikiText corpus.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 04:06:13 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Merity", "Stephen", ""], ["Xiong", "Caiming", ""], ["Bradbury", "James", ""], ["Socher", "Richard", ""]]}, {"id": "1609.08049", "submitter": "Yueming Sun", "authors": "Yueming Sun, Ye Yang, He Zhang, Wen Zhang, Qing Wang", "title": "Towards Evidence-Based Ontology for Supporting Systematic Literature\n  Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  [Background]: Systematic Literature Review (SLR) has become an important\nsoftware engineering research method but costs tremendous efforts. [Aim]: This\npaper proposes an approach to leverage on empirically evolved ontology to\nsupport automating key SLR activities. [Method]: First, we propose an ontology,\nSLRONT, built on SLR experiences and best practices as a groundwork to capture\ncommon terminologies and their relationships during SLR processes; second, we\npresent an extended version of SLRONT, the COSONT and instantiate it with the\nknowledge and concepts extracted from structured abstracts. Case studies\nillustrate the details of applying it for supporting SLR steps. [Results]:\nResults show that through using COSONT, we acquire the same conclusion compared\nwith sheer manual works, but the efforts involved is significantly reduced.\n[Conclusions]: The approach of using ontology could effectively and efficiently\nsupport the conducting of systematic literature review.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 05:38:50 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Sun", "Yueming", ""], ["Yang", "Ye", ""], ["Zhang", "He", ""], ["Zhang", "Wen", ""], ["Wang", "Qing", ""]]}, {"id": "1609.08082", "submitter": "Longmei Li", "authors": "Longmei Li, Iryna Yevseyeva, Vitor Basto-Fernandes, Heike Trautmann,\n  Ning Jing and Michael Emmerich", "title": "An Ontology of Preference-Based Multiobjective Metaheuristics", "comments": "submitted to European Journal of Operational Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User preference integration is of great importance in multi-objective\noptimization, in particular in many objective optimization. Preferences have\nlong been considered in traditional multicriteria decision making (MCDM) which\nis based on mathematical programming. Recently, it is integrated in\nmulti-objective metaheuristics (MOMH), resulting in focus on preferred parts of\nthe Pareto front instead of the whole Pareto front. The number of publications\non preference-based multi-objective metaheuristics has increased rapidly over\nthe past decades. There already exist various preference handling methods and\nMOMH methods, which have been combined in diverse ways. This article proposes\nto use the Web Ontology Language (OWL) to model and systematize the results\ndeveloped in this field. A review of the existing work is provided, based on\nwhich an ontology is built and instantiated with state-of-the-art results. The\nOWL ontology is made public and open to future extension. Moreover, the usage\nof the ontology is exemplified for different use-cases, including querying for\nmethods that match an engineering application, bibliometric analysis, checking\nexistence of combinations of preference models and MOMH techniques, and\ndiscovering opportunities for new research and open research questions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 17:16:54 GMT"}, {"version": "v2", "created": "Fri, 10 Mar 2017 13:58:27 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Li", "Longmei", ""], ["Yevseyeva", "Iryna", ""], ["Basto-Fernandes", "Vitor", ""], ["Trautmann", "Heike", ""], ["Jing", "Ning", ""], ["Emmerich", "Michael", ""]]}, {"id": "1609.08144", "submitter": "Mike Schuster", "authors": "Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi,\n  Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff\n  Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, {\\L}ukasz Kaiser,\n  Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens,\n  George Kurian, Nishant Patil, Wei Wang, Cliff Young, Jason Smith, Jason\n  Riesa, Alex Rudnick, Oriol Vinyals, Greg Corrado, Macduff Hughes, Jeffrey\n  Dean", "title": "Google's Neural Machine Translation System: Bridging the Gap between\n  Human and Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) is an end-to-end learning approach for\nautomated translation, with the potential to overcome many of the weaknesses of\nconventional phrase-based translation systems. Unfortunately, NMT systems are\nknown to be computationally expensive both in training and in translation\ninference. Also, most NMT systems have difficulty with rare words. These issues\nhave hindered NMT's use in practical deployments and services, where both\naccuracy and speed are essential. In this work, we present GNMT, Google's\nNeural Machine Translation system, which attempts to address many of these\nissues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder\nlayers using attention and residual connections. To improve parallelism and\ntherefore decrease training time, our attention mechanism connects the bottom\nlayer of the decoder to the top layer of the encoder. To accelerate the final\ntranslation speed, we employ low-precision arithmetic during inference\ncomputations. To improve handling of rare words, we divide words into a limited\nset of common sub-word units (\"wordpieces\") for both input and output. This\nmethod provides a good balance between the flexibility of \"character\"-delimited\nmodels and the efficiency of \"word\"-delimited models, naturally handles\ntranslation of rare words, and ultimately improves the overall accuracy of the\nsystem. Our beam search technique employs a length-normalization procedure and\nuses a coverage penalty, which encourages generation of an output sentence that\nis most likely to cover all the words in the source sentence. On the WMT'14\nEnglish-to-French and English-to-German benchmarks, GNMT achieves competitive\nresults to state-of-the-art. Using a human side-by-side evaluation on a set of\nisolated simple sentences, it reduces translation errors by an average of 60%\ncompared to Google's phrase-based production system.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 19:59:55 GMT"}, {"version": "v2", "created": "Sat, 8 Oct 2016 19:10:41 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Wu", "Yonghui", ""], ["Schuster", "Mike", ""], ["Chen", "Zhifeng", ""], ["Le", "Quoc V.", ""], ["Norouzi", "Mohammad", ""], ["Macherey", "Wolfgang", ""], ["Krikun", "Maxim", ""], ["Cao", "Yuan", ""], ["Gao", "Qin", ""], ["Macherey", "Klaus", ""], ["Klingner", "Jeff", ""], ["Shah", "Apurva", ""], ["Johnson", "Melvin", ""], ["Liu", "Xiaobing", ""], ["Kaiser", "\u0141ukasz", ""], ["Gouws", "Stephan", ""], ["Kato", "Yoshikiyo", ""], ["Kudo", "Taku", ""], ["Kazawa", "Hideto", ""], ["Stevens", "Keith", ""], ["Kurian", "George", ""], ["Patil", "Nishant", ""], ["Wang", "Wei", ""], ["Young", "Cliff", ""], ["Smith", "Jason", ""], ["Riesa", "Jason", ""], ["Rudnick", "Alex", ""], ["Vinyals", "Oriol", ""], ["Corrado", "Greg", ""], ["Hughes", "Macduff", ""], ["Dean", "Jeffrey", ""]]}, {"id": "1609.08194", "submitter": "Lei Yu", "authors": "Lei Yu, Jan Buys and Phil Blunsom", "title": "Online Segment to Segment Neural Transduction", "comments": "EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an online neural sequence to sequence model that learns to\nalternate between encoding and decoding segments of the input as it is read. By\nindependently tracking the encoding and decoding representations our algorithm\npermits exact polynomial marginalization of the latent segmentation during\ntraining, and during decoding beam search is employed to find the best\nalignment path together with the predicted output sequence. Our model tackles\nthe bottleneck of vanilla encoder-decoders that have to read and memorize the\nentire input sequence in their fixed-length hidden states before producing any\noutput. It is different from previous attentive models in that, instead of\ntreating the attention weights as output of a deterministic function, our model\nassigns attention weights to a sequential latent variable which can be\nmarginalized out and permits online generation. Experiments on abstractive\nsentence summarization and morphological inflection show significant\nperformance gains over the baseline encoder-decoders.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 21:13:49 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Yu", "Lei", ""], ["Buys", "Jan", ""], ["Blunsom", "Phil", ""]]}, {"id": "1609.08210", "submitter": "Ferhan Ture", "authors": "Ferhan Ture and Elizabeth Boschee", "title": "Learning to Translate for Multilingual Question Answering", "comments": "12 pages. To appear in EMNLP'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multilingual question answering, either the question needs to be\ntranslated into the document language, or vice versa. In addition to direction,\nthere are multiple methods to perform the translation, four of which we explore\nin this paper: word-based, 10-best, context-based, and grammar-based. We build\na feature for each combination of translation direction and method, and train a\nmodel that learns optimal feature weights. On a large forum dataset consisting\nof posts in English, Arabic, and Chinese, our novel learn-to-translate approach\nwas more effective than a strong baseline (p<0.05): translating all text into\nEnglish, then training a classifier based only on English (original or\ntranslated) text.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 22:12:50 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Ture", "Ferhan", ""], ["Boschee", "Elizabeth", ""]]}, {"id": "1609.08264", "submitter": "Zhao Kang", "authors": "Zhao Kang, Chong Peng, Ming Yang, Qiang Cheng", "title": "Top-N Recommendation on Graphs", "comments": "CIKM 2016", "journal-ref": null, "doi": "10.1145/2983323.2983649", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems play an increasingly important role in online\napplications to help users find what they need or prefer. Collaborative\nfiltering algorithms that generate predictions by analyzing the user-item\nrating matrix perform poorly when the matrix is sparse. To alleviate this\nproblem, this paper proposes a simple recommendation algorithm that fully\nexploits the similarity information among users and items and intrinsic\nstructural information of the user-item matrix. The proposed method constructs\na new representation which preserves affinity and structure information in the\nuser-item rating matrix and then performs recommendation task. To capture\nproximity information about users and items, two graphs are constructed.\nManifold learning idea is used to constrain the new representation to be smooth\non these graphs, so as to enforce users and item proximities. Our model is\nformulated as a convex optimization problem, for which we need to solve the\nwell-known Sylvester equation only. We carry out extensive empirical\nevaluations on six benchmark datasets to show the effectiveness of this\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 05:45:03 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Kang", "Zhao", ""], ["Peng", "Chong", ""], ["Yang", "Ming", ""], ["Cheng", "Qiang", ""]]}, {"id": "1609.08419", "submitter": "Lantian Li Mr.", "authors": "Lantian Li, Renyu Wang, Gang Wang, Caixia Wang, Thomas Fang Zheng", "title": "Decision Making Based on Cohort Scores for Speaker Verification", "comments": "APSIPA ASC 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision making is an important component in a speaker verification system.\nFor the conventional GMM-UBM architecture, the decision is usually conducted\nbased on the log likelihood ratio of the test utterance against the GMM of the\nclaimed speaker and the UBM. This single-score decision is simple but tends to\nbe sensitive to the complex variations in speech signals (e.g. text content,\nchannel, speaking style, etc.). In this paper, we propose a decision making\napproach based on multiple scores derived from a set of cohort GMMs (cohort\nscores). Importantly, these cohort scores are not simply averaged as in\nconventional cohort methods; instead, we employ a powerful discriminative model\nas the decision maker. Experimental results show that the proposed method\ndelivers substantial performance improvement over the baseline system,\nespecially when a deep neural network (DNN) is used as the decision maker, and\nthe DNN input involves some statistical features derived from the cohort\nscores.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 13:29:12 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Li", "Lantian", ""], ["Wang", "Renyu", ""], ["Wang", "Gang", ""], ["Wang", "Caixia", ""], ["Zheng", "Thomas Fang", ""]]}, {"id": "1609.08439", "submitter": "Dejanira Araiza-Illan", "authors": "Dejanira Araiza-Illan, Anthony G. Pipe, Kerstin Eder", "title": "Model-based Test Generation for Robotic Software: Automata versus\n  Belief-Desire-Intention Agents", "comments": "arXiv admin note: text overlap with arXiv:1603.00656", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic code needs to be verified to ensure its safety and functional\ncorrectness, especially when the robot is interacting with people. Testing real\ncode in simulation is a viable option. However, generating tests that cover\nrare scenarios, as well as exercising most of the code, is a challenge\namplified by the complexity of the interactions between the environment and the\nsoftware. Model-based test generation methods can automate otherwise manual\nprocesses and facilitate reaching rare scenarios during testing. In this paper,\nwe compare using Belief-Desire-Intention (BDI) agents as models for test\ngeneration with more conventional automata-based techniques that exploit model\nchecking, in terms of practicality, performance, transferability to different\nscenarios, and exploration (`coverage'), through two case studies: a\ncooperative manufacturing task, and a home care scenario. The results highlight\nthe advantages of using BDI agents for test generation. BDI agents naturally\nemulate the agency present in Human-Robot Interactions (HRIs), and are thus\nmore expressive than automata. The performance of the BDI-based test generation\nis at least as high, and the achieved coverage is higher or equivalent,\ncompared to test generation based on model checking automata.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 14:07:28 GMT"}, {"version": "v2", "created": "Mon, 12 Dec 2016 11:23:48 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Araiza-Illan", "Dejanira", ""], ["Pipe", "Anthony G.", ""], ["Eder", "Kerstin", ""]]}, {"id": "1609.08441", "submitter": "Lantian Li Mr.", "authors": "Lantian Li, Yixiang Chen, Dong Wang, Chenghui Zhao", "title": "Weakly Supervised PLDA Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PLDA is a popular normalization approach for the i-vector model, and it has\ndelivered state-of-the-art performance in speaker verification. However, PLDA\ntraining requires a large amount of labelled development data, which is highly\nexpensive in most cases. We present a cheap PLDA training approach, which\nassumes that speakers in the same session can be easily separated, and speakers\nin different sessions are simply different. This results in `weak labels' which\nare not fully accurate but cheap, leading to a weak PLDA training.\n  Our experimental results on real-life large-scale telephony customer service\nachieves demonstrated that the weak training can offer good performance when\nhuman-labelled data are limited. More interestingly, the weak training can be\nemployed as a discriminative adaptation approach, which is more efficient than\nthe prevailing unsupervised method when human-labelled data are insufficient.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 13:46:55 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 10:19:15 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Li", "Lantian", ""], ["Chen", "Yixiang", ""], ["Wang", "Dong", ""], ["Zhao", "Chenghui", ""]]}, {"id": "1609.08445", "submitter": "Lantian Li Mr.", "authors": "Dong Wang, Lantian Li, Difei Tang, Qing Chen", "title": "AP16-OL7: A Multilingual Database for Oriental Languages and A Language\n  Recognition Baseline", "comments": "APSIPA ASC 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the AP16-OL7 database which was released as the training and test\ndata for the oriental language recognition (OLR) challenge on APSIPA 2016.\nBased on the database, a baseline system was constructed on the basis of the\ni-vector model. We report the baseline results evaluated in various metrics\ndefined by the AP16-OLR evaluation plan and demonstrate that AP16-OL7 is a\nreasonable data resource for multilingual research.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 13:50:13 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Wang", "Dong", ""], ["Li", "Lantian", ""], ["Tang", "Difei", ""], ["Chen", "Qing", ""]]}, {"id": "1609.08470", "submitter": "Doron Friedman", "authors": "Doron Friedman", "title": "A computer program for simulating time travel and a possible 'solution'\n  for the grandfather paradox", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the possibility of time travel in physics is still debated, the\nexplosive growth of virtual-reality simulations opens up new possibilities to\nrigorously explore such time travel and its consequences in the digital domain.\nHere we provide a computational model of time travel and a computer program\nthat allows exploring digital time travel. In order to explain our method we\nformalize a simplified version of the famous grandfather paradox, show how the\nsystem can allow the participant to go back in time, try to kill their\nancestors before they were born, and experience the consequences. The system\nhas even come up with scenarios that can be considered consistent \"solutions\"\nof the grandfather paradox. We discuss the conditions for digital time travel,\nwhich indicate that it has a large number of practical applications.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 15:09:29 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Friedman", "Doron", ""]]}, {"id": "1609.08524", "submitter": "Tathagata Chakraborti", "authors": "Tathagata Chakraborti, Kartik Talamadupula, Kshitij P. Fadnis, Murray\n  Campbell, Subbarao Kambhampati", "title": "UbuntuWorld 1.0 LTS - A Platform for Automated Problem Solving &\n  Troubleshooting in the Ubuntu OS", "comments": "Appeared (under the same title) in AAAI/IAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present UbuntuWorld 1.0 LTS - a platform for developing\nautomated technical support agents in the Ubuntu operating system.\nSpecifically, we propose to use the Bash terminal as a simulator of the Ubuntu\nenvironment for a learning-based agent and demonstrate the usefulness of\nadopting reinforcement learning (RL) techniques for basic problem solving and\ntroubleshooting in this environment. We provide a plug-and-play interface to\nthe simulator as a python package where different types of agents can be\nplugged in and evaluated, and provide pathways for integrating data from online\nsupport forums like AskUbuntu into an automated agent's learning process.\nFinally, we show that the use of this data significantly improves the agent's\nlearning efficiency. We believe that this platform can be adopted as a\nreal-world test bed for research on automated technical support.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 16:42:30 GMT"}, {"version": "v2", "created": "Sat, 12 Aug 2017 21:31:02 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Chakraborti", "Tathagata", ""], ["Talamadupula", "Kartik", ""], ["Fadnis", "Kshitij P.", ""], ["Campbell", "Murray", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1609.08677", "submitter": "Zhao Kang", "authors": "Chong Peng, Zhao Kang, Qiang Chen", "title": "A Fast Factorization-based Approach to Robust PCA", "comments": "ICDM 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust principal component analysis (RPCA) has been widely used for\nrecovering low-rank matrices in many data mining and machine learning problems.\nIt separates a data matrix into a low-rank part and a sparse part. The convex\napproach has been well studied in the literature. However, state-of-the-art\nalgorithms for the convex approach usually have relatively high complexity due\nto the need of solving (partial) singular value decompositions of large\nmatrices. A non-convex approach, AltProj, has also been proposed with lighter\ncomplexity and better scalability. Given the true rank $r$ of the underlying\nlow rank matrix, AltProj has a complexity of $O(r^2dn)$, where $d\\times n$ is\nthe size of data matrix. In this paper, we propose a novel factorization-based\nmodel of RPCA, which has a complexity of $O(kdn)$, where $k$ is an upper bound\nof the true rank. Our method does not need the precise value of the true rank.\nFrom extensive experiments, we observe that AltProj can work only when $r$ is\nprecisely known in advance; however, when the needed rank parameter $r$ is\nspecified to a value different from the true rank, AltProj cannot fully\nseparate the two parts while our method succeeds. Even when both work, our\nmethod is about 4 times faster than AltProj. Our method can be used as a\nlight-weight, scalable tool for RPCA in the absence of the precise value of the\ntrue rank.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 21:32:16 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Peng", "Chong", ""], ["Kang", "Zhao", ""], ["Chen", "Qiang", ""]]}, {"id": "1609.08843", "submitter": "Jiaming Xu", "authors": "Jiaming Xu, Jing Shi, Yiqun Yao, Suncong Zheng, Bo Xu, Bo Xu", "title": "Hierarchical Memory Networks for Answer Selection on Unknown Words", "comments": "10 pages, to appear in COLING 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, end-to-end memory networks have shown promising results on Question\nAnswering task, which encode the past facts into an explicit memory and perform\nreasoning ability by making multiple computational steps on the memory.\nHowever, memory networks conduct the reasoning on sentence-level memory to\noutput coarse semantic vectors and do not further take any attention mechanism\nto focus on words, which may lead to the model lose some detail information,\nespecially when the answers are rare or unknown words. In this paper, we\npropose a novel Hierarchical Memory Networks, dubbed HMN. First, we encode the\npast facts into sentence-level memory and word-level memory respectively. Then,\n(k)-max pooling is exploited following reasoning module on the sentence-level\nmemory to sample the (k) most relevant sentences to a question and feed these\nsentences into attention mechanism on the word-level memory to focus the words\nin the selected sentences. Finally, the prediction is jointly learned over the\noutputs of the sentence-level reasoning module and the word-level attention\nmechanism. The experimental results demonstrate that our approach successfully\nconducts answer selection on unknown words and achieves a better performance\nthan memory networks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 10:03:05 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Xu", "Jiaming", ""], ["Shi", "Jing", ""], ["Yao", "Yiqun", ""], ["Zheng", "Suncong", ""], ["Xu", "Bo", ""], ["Xu", "Bo", ""]]}, {"id": "1609.08925", "submitter": "Ekaterina Arafailova", "authors": "Ekaterina Arafailova and Nicolas Beldiceanu and R\\'emi Douence and\n  Mats Carlsson and Pierre Flener and Mar\\'ia Andre\\'ina Francisco Rodr\\'iguez\n  and Justin Pearson and Helmut Simonis", "title": "Global Constraint Catalog, Volume II, Time-Series Constraints", "comments": "3762 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  First this report presents a restricted set of finite transducers used to\nsynthesise structural time-series constraints described by means of a\nmulti-layered function composition scheme. Second it provides the corresponding\nsynthesised catalogue of structural time-series constraints where each\nconstraint is explicitly described in terms of automata with registers.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 19:06:11 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 19:08:03 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Arafailova", "Ekaterina", ""], ["Beldiceanu", "Nicolas", ""], ["Douence", "R\u00e9mi", ""], ["Carlsson", "Mats", ""], ["Flener", "Pierre", ""], ["Rodr\u00edguez", "Mar\u00eda Andre\u00edna Francisco", ""], ["Pearson", "Justin", ""], ["Simonis", "Helmut", ""]]}, {"id": "1609.09001", "submitter": "Aviv Tamar", "authors": "Aviv Tamar, Garrett Thomas, Tianhao Zhang, Sergey Levine, Pieter\n  Abbeel", "title": "Learning from the Hindsight Plan -- Episodic MPC Improvement", "comments": "Additional experiments for neural network generalization and for\n  varying the planning horizon. Paper accepted to ICRA 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model predictive control (MPC) is a popular control method that has proved\neffective for robotics, among other fields. MPC performs re-planning at every\ntime step. Re-planning is done with a limited horizon per computational and\nreal-time constraints and often also for robustness to potential model errors.\nHowever, the limited horizon leads to suboptimal performance. In this work, we\nconsider the iterative learning setting, where the same task can be repeated\nseveral times, and propose a policy improvement scheme for MPC. The main idea\nis that between executions we can, offline, run MPC with a longer horizon,\nresulting in a hindsight plan. To bring the next real-world execution closer to\nthe hindsight plan, our approach learns to re-shape the original cost function\nwith the goal of satisfying the following property: short horizon planning (as\nrealistic during real executions) with respect to the shaped cost should result\nin mimicking the hindsight plan. This effectively consolidates long-term\nreasoning into the short-horizon planning. We empirically evaluate our approach\nin contact-rich manipulation tasks both in simulated and real environments,\nsuch as peg insertion by a real PR2 robot.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 16:43:18 GMT"}, {"version": "v2", "created": "Mon, 20 Mar 2017 22:29:23 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Tamar", "Aviv", ""], ["Thomas", "Garrett", ""], ["Zhang", "Tianhao", ""], ["Levine", "Sergey", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1609.09226", "submitter": "Qiang Liu", "authors": "Qiang Liu, Shu Wu, Feng Yu, Liang Wang, Tieniu Tan", "title": "ICE: Information Credibility Evaluation on Social Media via\n  Representation Learning", "comments": "IEEE Transactions on Information Forensics and Security (TIFS), under\n  review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of social media, rumors are also spreading widely on\nsocial media and bring harm to people's daily life. Nowadays, information\ncredibility evaluation has drawn attention from academic and industrial\ncommunities. Current methods mainly focus on feature engineering and achieve\nsome success. However, feature engineering based methods require a lot of labor\nand cannot fully reveal the underlying relations among data. In our viewpoint,\nthe key elements of user behaviors for evaluating credibility are concluded as\n\"who\", \"what\", \"when\", and \"how\". These existing methods cannot model the\ncorrelation among different key elements during the spreading of microblogs. In\nthis paper, we propose a novel representation learning method, Information\nCredibility Evaluation (ICE), to learn representations of information\ncredibility on social media. In ICE, latent representations are learnt for\nmodeling user credibility, behavior types, temporal properties, and comment\nattitudes. The aggregation of these factors in the microblog spreading process\nyields the representation of a user's behavior, and the aggregation of these\ndynamic representations generates the credibility representation of an event\nspreading on social media. Moreover, a pairwise learning method is applied to\nmaximize the credibility difference between rumors and non-rumors. To evaluate\nthe performance of ICE, we conduct experiments on a Sina Weibo data set, and\nthe experimental results show that our ICE model outperforms the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 07:04:28 GMT"}, {"version": "v2", "created": "Fri, 30 Sep 2016 01:20:32 GMT"}, {"version": "v3", "created": "Mon, 10 Oct 2016 02:06:51 GMT"}, {"version": "v4", "created": "Mon, 24 Oct 2016 07:32:16 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Liu", "Qiang", ""], ["Wu", "Shu", ""], ["Yu", "Feng", ""], ["Wang", "Liang", ""], ["Tan", "Tieniu", ""]]}, {"id": "1609.09253", "submitter": "Ivan Grechikhin", "authors": "Ivan S. Grechikhin", "title": "Heuristic with elements of tabu search for Truck and Trailer Routing\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle Routing Problem is a well-known problem in logistics and\ntransportation, and the variety of such problems is explained by the fact that\nit occurs in many real-life situations. It is an NP-hard combinatorial\noptimization problem and finding an exact optimal solution is practically\nimpossible. In this work, Site-Dependent Truck and Trailer Routing Problem with\nhard and soft Time Windows and Split Deliveries is considered (SDTTRPTWSD). In\nthis article, we develop a heuristic with the elements of Tabu Search for\nsolving SDTTRPTWSD. The heuristic uses the concept of neighborhoods and visits\ninfeasible solutions during the search. A greedy heuristic is applied to\nconstruct an initial solution.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 08:37:48 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Grechikhin", "Ivan S.", ""]]}, {"id": "1609.09315", "submitter": "Tom\\'a\\v{s} Ko\\v{c}isk\\'y", "authors": "Tom\\'a\\v{s} Ko\\v{c}isk\\'y and G\\'abor Melis and Edward Grefenstette\n  and Chris Dyer and Wang Ling and Phil Blunsom and Karl Moritz Hermann", "title": "Semantic Parsing with Semi-Supervised Sequential Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel semi-supervised approach for sequence transduction and\napply it to semantic parsing. The unsupervised component is based on a\ngenerative model in which latent sentences generate the unpaired logical forms.\nWe apply this method to a number of semantic parsing tasks focusing on domains\nwith limited access to labelled training data and extend those datasets with\nsynthetically generated logical forms.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 12:20:13 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Ko\u010disk\u00fd", "Tom\u00e1\u0161", ""], ["Melis", "G\u00e1bor", ""], ["Grefenstette", "Edward", ""], ["Dyer", "Chris", ""], ["Ling", "Wang", ""], ["Blunsom", "Phil", ""], ["Hermann", "Karl Moritz", ""]]}, {"id": "1609.09365", "submitter": "Julie Dequaire", "authors": "Julie Dequaire, Dushyant Rao, Peter Ondruska, Dominic Wang and Ingmar\n  Posner", "title": "Deep Tracking on the Move: Learning to Track the World from a Moving\n  Vehicle using Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an end-to-end approach for tracking static and dynamic\nobjects for an autonomous vehicle driving through crowded urban environments.\nUnlike traditional approaches to tracking, this method is learned end-to-end,\nand is able to directly predict a full unoccluded occupancy grid map from raw\nlaser input data. Inspired by the recently presented DeepTracking approach\n[Ondruska, 2016], we employ a recurrent neural network (RNN) to capture the\ntemporal evolution of the state of the environment, and propose to use Spatial\nTransformer modules to exploit estimates of the egomotion of the vehicle. Our\nresults demonstrate the ability to track a range of objects, including cars,\nbuses, pedestrians, and cyclists through occlusion, from both moving and\nstationary platforms, using a single learned model. Experimental results\ndemonstrate that the model can also predict the future states of objects from\ncurrent inputs, with greater accuracy than previous work.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 14:39:10 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2017 21:35:15 GMT"}, {"version": "v3", "created": "Wed, 19 Apr 2017 14:31:32 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Dequaire", "Julie", ""], ["Rao", "Dushyant", ""], ["Ondruska", "Peter", ""], ["Wang", "Dominic", ""], ["Posner", "Ingmar", ""]]}, {"id": "1609.09405", "submitter": "Siva Reddy", "authors": "Yonatan Bisk, Siva Reddy, John Blitzer, Julia Hockenmaier, Mark\n  Steedman", "title": "Evaluating Induced CCG Parsers on Grounded Semantic Parsing", "comments": "EMNLP 2016, Table 2 erratum, Code and Freebase Semantic Parsing data\n  URL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We compare the effectiveness of four different syntactic CCG parsers for a\nsemantic slot-filling task to explore how much syntactic supervision is\nrequired for downstream semantic analysis. This extrinsic, task-based\nevaluation provides a unique window to explore the strengths and weaknesses of\nsemantics captured by unsupervised grammar induction systems. We release a new\nFreebase semantic parsing dataset called SPADES (Semantic PArsing of\nDEclarative Sentences) containing 93K cloze-style questions paired with\nanswers. We evaluate all our models on this dataset. Our code and data are\navailable at https://github.com/sivareddyg/graph-parser.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 16:09:29 GMT"}, {"version": "v2", "created": "Tue, 31 Jan 2017 16:25:39 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Bisk", "Yonatan", ""], ["Reddy", "Siva", ""], ["Blitzer", "John", ""], ["Hockenmaier", "Julia", ""], ["Steedman", "Mark", ""]]}, {"id": "1609.09444", "submitter": "Arnab Ghosh", "authors": "Arnab Ghosh and Viveka Kulharia and Amitabha Mukerjee and Vinay\n  Namboodiri and Mohit Bansal", "title": "Contextual RNN-GANs for Abstract Reasoning Diagram Generation", "comments": "To Appear in AAAI-17 and NIPS Workshop on Adversarial Training", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding, predicting, and generating object motions and transformations\nis a core problem in artificial intelligence. Modeling sequences of evolving\nimages may provide better representations and models of motion and may\nultimately be used for forecasting, simulation, or video generation.\nDiagrammatic Abstract Reasoning is an avenue in which diagrams evolve in\ncomplex patterns and one needs to infer the underlying pattern sequence and\ngenerate the next image in the sequence. For this, we develop a novel\nContextual Generative Adversarial Network based on Recurrent Neural Networks\n(Context-RNN-GANs), where both the generator and the discriminator modules are\nbased on contextual history (modeled as RNNs) and the adversarial discriminator\nguides the generator to produce realistic images for the particular time step\nin the image sequence. We evaluate the Context-RNN-GAN model (and its variants)\non a novel dataset of Diagrammatic Abstract Reasoning, where it performs\ncompetitively with 10th-grade human performance but there is still scope for\ninteresting improvements as compared to college-grade human performance. We\nalso evaluate our model on a standard video next-frame prediction task,\nachieving improved performance over comparable state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 17:56:32 GMT"}, {"version": "v2", "created": "Tue, 6 Dec 2016 13:14:09 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Ghosh", "Arnab", ""], ["Kulharia", "Viveka", ""], ["Mukerjee", "Amitabha", ""], ["Namboodiri", "Vinay", ""], ["Bansal", "Mohit", ""]]}, {"id": "1609.09748", "submitter": "Arnaud Martin", "authors": "Amal Ben Rjab (LARODEC, DRUID), Mouloud Kharoune (DRUID), Zoltan\n  Miklos (DRUID), Arnaud Martin (DRUID)", "title": "Characterization of experts in crowdsourcing platforms", "comments": "in The 4th International Conference on Belief Functions, Sep 2016,\n  Prague, Czech Republic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing platforms enable to propose simple human intelligence tasks to\na large number of participants who realise these tasks. The workers often\nreceive a small amount of money or the platforms include some other incentive\nmechanisms, for example they can increase the workers reputation score, if they\ncomplete the tasks correctly. We address the problem of identifying experts\namong participants, that is, workers, who tend to answer the questions\ncorrectly. Knowing who are the reliable workers could improve the quality of\nknowledge one can extract from responses. As opposed to other works in the\nliterature, we assume that participants can give partial or incomplete\nresponses, in case they are not sure that their answers are correct. We model\nsuch partial or incomplete responses with the help of belief functions, and we\nderive a measure that characterizes the expertise level of each participant.\nThis measure is based on precise and exactitude degrees that represent two\nparts of the expertise level. The precision degree reflects the reliability\nlevel of the participants and the exactitude degree reflects the knowledge\nlevel of the participants. We also analyze our model through simulation and\ndemonstrate that our richer model can lead to more reliable identification of\nexperts.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 14:23:42 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Rjab", "Amal Ben", "", "LARODEC, DRUID"], ["Kharoune", "Mouloud", "", "DRUID"], ["Miklos", "Zoltan", "", "DRUID"], ["Martin", "Arnaud", "", "DRUID"]]}, {"id": "1609.09864", "submitter": "Baojian Zhou", "authors": "Baojian Zhou, Feng Chen", "title": "Technical Report: Graph-Structured Sparse Optimization for Connected\n  Subgraph Detection", "comments": "11 pages in 2016 IEEE International Conference of Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured sparse optimization is an important and challenging problem for\nanalyzing high-dimensional data in a variety of applications such as\nbioinformatics, medical imaging, social networks, and astronomy. Although a\nnumber of structured sparsity models have been explored, such as trees, groups,\nclusters, and paths, connected subgraphs have been rarely explored in the\ncurrent literature. One of the main technical challenges is that there is no\nstructured sparsity-inducing norm that can directly model the space of\nconnected subgraphs, and there is no exact implementation of a projection\noracle for connected subgraphs due to its NP-hardness. In this paper, we\nexplore efficient approximate projection oracles for connected subgraphs, and\npropose two new efficient algorithms, namely, Graph-IHT and Graph-GHTP, to\noptimize a generic nonlinear objective function subject to connectivity\nconstraint on the support of the variables. Our proposed algorithms enjoy\nstrong guarantees analogous to several current methods for sparsity-constrained\noptimization, such as Projected Gradient Descent (PGD), Approximate Model\nIterative Hard Thresholding (AM-IHT), and Gradient Hard Thresholding Pursuit\n(GHTP) with respect to convergence rate and approximation accuracy. We apply\nour proposed algorithms to optimize several well-known graph scan statistics in\nseveral applications of connected subgraph detection as a case study, and the\nexperimental results demonstrate that our proposed algorithms outperform\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 19:26:26 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Zhou", "Baojian", ""], ["Chen", "Feng", ""]]}, {"id": "1609.09869", "submitter": "Rahul Gopal Krishnan", "authors": "Rahul G. Krishnan, Uri Shalit, David Sontag", "title": "Structured Inference Networks for Nonlinear State Space Models", "comments": "To appear in the Thirty-First AAAI Conference on Artificial\n  Intelligence, February 2017, 13 pages, 11 figures with supplement, changed to\n  AAAI formatting style, added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian state space models have been used for decades as generative models\nof sequential data. They admit an intuitive probabilistic interpretation, have\na simple functional form, and enjoy widespread adoption. We introduce a unified\nalgorithm to efficiently learn a broad class of linear and non-linear state\nspace models, including variants where the emission and transition\ndistributions are modeled by deep neural networks. Our learning algorithm\nsimultaneously learns a compiled inference network and the generative model,\nleveraging a structured variational approximation parameterized by recurrent\nneural networks to mimic the posterior distribution. We apply the learning\nalgorithm to both synthetic and real-world datasets, demonstrating its\nscalability and versatility. We find that using the structured approximation to\nthe posterior results in models with significantly higher held-out likelihood.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 19:53:11 GMT"}, {"version": "v2", "created": "Mon, 5 Dec 2016 19:10:10 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Krishnan", "Rahul G.", ""], ["Shalit", "Uri", ""], ["Sontag", "David", ""]]}]