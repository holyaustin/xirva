[{"id": "1004.1061", "submitter": "Yuexian Hou", "authors": "Yuexian Hou, Tingxu Yan, Peng Zhang, Dawei Song, Wenjie Li", "title": "On Tsallis Entropy Bias and Generalized Maximum Entropy Models", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In density estimation task, maximum entropy model (Maxent) can effectively\nuse reliable prior information via certain constraints, i.e., linear\nconstraints without empirical parameters. However, reliable prior information\nis often insufficient, and the selection of uncertain constraints becomes\nnecessary but poses considerable implementation complexity. Improper setting of\nuncertain constraints can result in overfitting or underfitting. To solve this\nproblem, a generalization of Maxent, under Tsallis entropy framework, is\nproposed. The proposed method introduces a convex quadratic constraint for the\ncorrection of (expected) Tsallis entropy bias (TEB). Specifically, we\ndemonstrate that the expected Tsallis entropy of sampling distributions is\nsmaller than the Tsallis entropy of the underlying real distribution. This\nexpected entropy reduction is exactly the (expected) TEB, which can be\nexpressed by a closed-form formula and act as a consistent and unbiased\ncorrection. TEB indicates that the entropy of a specific sampling distribution\nshould be increased accordingly. This entails a quantitative re-interpretation\nof the Maxent principle. By compensating TEB and meanwhile forcing the\nresulting distribution to be close to the sampling distribution, our\ngeneralized TEBC Maxent can be expected to alleviate the overfitting and\nunderfitting. We also present a connection between TEB and Lidstone estimator.\nAs a result, TEB-Lidstone estimator is developed by analytically identifying\nthe rate of probability correction in Lidstone. Extensive empirical evaluation\nshows promising performance of both TEBC Maxent and TEB-Lidstone in comparison\nwith various state-of-the-art density estimation methods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2010 11:52:25 GMT"}], "update_date": "2010-04-08", "authors_parsed": [["Hou", "Yuexian", ""], ["Yan", "Tingxu", ""], ["Zhang", "Peng", ""], ["Song", "Dawei", ""], ["Li", "Wenjie", ""]]}, {"id": "1004.1230", "submitter": "Rdv Ijcsis", "authors": "Phanu Waraporn, Phayung Meesad, Gareth Clayton", "title": "Ontology-supported processing of clinical text using medical knowledge\n  integration for multi-label classification of diagnosis coding", "comments": "IEEE Publication format, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "IJCSIS, Vol. 7 No. 3, March 2010,", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper discusses the knowledge integration of clinical information\nextracted from distributed medical ontology in order to ameliorate a machine\nlearning-based multi-label coding assignment system. The proposed approach is\nimplemented using a decision tree based cascade hierarchical technique on the\nuniversity hospital data for patients with Coronary Heart Disease (CHD). The\npreliminary results obtained show a satisfactory finding.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2010 03:06:24 GMT"}], "update_date": "2010-04-09", "authors_parsed": [["Waraporn", "Phanu", ""], ["Meesad", "Phayung", ""], ["Clayton", "Gareth", ""]]}, {"id": "1004.1540", "submitter": "Jean Dezert", "authors": "Florentin Smarandache (UNM), Jean Dezert (ONERA)", "title": "Importance of Sources using the Repeated Fusion Method and the\n  Proportional Conflict Redistribution Rules #5 and #6", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper some examples of how to compute by hand the PCR5\nfusion rule for three sources, so the reader will better understand its\nmechanism. We also take into consideration the importance of sources, which is\ndifferent from the classical discounting of sources.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2010 12:38:17 GMT"}], "update_date": "2010-05-02", "authors_parsed": [["Smarandache", "Florentin", "", "UNM"], ["Dezert", "Jean", "", "ONERA"]]}, {"id": "1004.1586", "submitter": "Yehua Wei", "authors": "David Gamarnik, Devavrat Shah, Yehua Wei", "title": "Belief Propagation for Min-cost Network Flow: Convergence and\n  Correctness", "comments": "This paper has been withdrawn as it is not up-to-date. The new\n  version of this paper can be found at\n  http://web.mit.edu/devavrat/www/OR-BP-Preprint.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message passing type algorithms such as the so-called Belief Propagation\nalgorithm have recently gained a lot of attention in the statistics, signal\nprocessing and machine learning communities as attractive algorithms for\nsolving a variety of optimization and inference problems. As a decentralized,\neasy to implement and empirically successful algorithm, BP deserves attention\nfrom the theoretical standpoint, and here not much is known at the present\nstage. In order to fill this gap we consider the performance of the BP\nalgorithm in the context of the capacitated minimum-cost network flow problem -\nthe classical problem in the operations research field. We prove that BP\nconverges to the optimal solution in the pseudo-polynomial time, provided that\nthe optimal solution of the underlying problem is unique and the problem input\nis integral. Moreover, we present a simple modification of the BP algorithm\nwhich gives a fully polynomial-time randomized approximation scheme (FPRAS) for\nthe same problem, which no longer requires the uniqueness of the optimal\nsolution. This is the first instance where BP is proved to have\nfully-polynomial running time. Our results thus provide a theoretical\njustification for the viability of BP as an attractive method to solve an\nimportant class of optimization problems.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2010 16:15:42 GMT"}, {"version": "v2", "created": "Tue, 4 Oct 2011 04:12:51 GMT"}, {"version": "v3", "created": "Wed, 5 Oct 2011 00:12:32 GMT"}, {"version": "v4", "created": "Wed, 11 Jul 2012 23:46:40 GMT"}], "update_date": "2016-03-10", "authors_parsed": [["Gamarnik", "David", ""], ["Shah", "Devavrat", ""], ["Wei", "Yehua", ""]]}, {"id": "1004.1772", "submitter": "Rdv Ijcsis", "authors": "Uraiwan Inyaem, Choochart Haruechaiyasak, Phayung Meesad, Dat Tran", "title": "Terrorism Event Classification Using Fuzzy Inference Systems", "comments": "IEEE Publication format, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "IJCSIS, Vol. 7 No. 3, March 2010, 247-256", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Terrorism has led to many problems in Thai societies, not only property\ndamage but also civilian casualties. Predicting terrorism activities in advance\ncan help prepare and manage risk from sabotage by these activities. This paper\nproposes a framework focusing on event classification in terrorism domain using\nfuzzy inference systems (FISs). Each FIS is a decision-making model combining\nfuzzy logic and approximate reasoning. It is generated in five main parts: the\ninput interface, the fuzzification interface, knowledge base unit, decision\nmaking unit and output defuzzification interface. Adaptive neuro-fuzzy\ninference system (ANFIS) is a FIS model adapted by combining the fuzzy logic\nand neural network. The ANFIS utilizes automatic identification of fuzzy logic\nrules and adjustment of membership function (MF). Moreover, neural network can\ndirectly learn from data set to construct fuzzy logic rules and MF implemented\nin various applications. FIS settings are evaluated based on two comparisons.\nThe first evaluation is the comparison between unstructured and structured\nevents using the same FIS setting. The second comparison is the model settings\nbetween FIS and ANFIS for classifying structured events. The data set consists\nof news articles related to terrorism events in three southern provinces of\nThailand. The experimental results show that the classification performance of\nthe FIS resulting from structured events achieves satisfactory accuracy and is\nbetter than the unstructured events. In addition, the classification of\nstructured events using ANFIS gives higher performance than the events using\nonly FIS in the prediction of terrorism events.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2010 08:12:31 GMT"}], "update_date": "2010-04-13", "authors_parsed": [["Inyaem", "Uraiwan", ""], ["Haruechaiyasak", "Choochart", ""], ["Meesad", "Phayung", ""], ["Tran", "Dat", ""]]}, {"id": "1004.1794", "submitter": "Rdv Ijcsis", "authors": "T.Krishna Kishore, T.Sasi Vardhan, N.Lakshmi Narayana", "title": "Probabilistic Semantic Web Mining Using Artificial Neural Analysis", "comments": "IEEE Publication format, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "IJCSIS, Vol. 7 No. 3, March 2010, 294-304", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Most of the web user's requirements are search or navigation time and getting\ncorrectly matched result. These constrains can be satisfied with some\nadditional modules attached to the existing search engines and web servers.\nThis paper proposes that powerful architecture for search engines with the\ntitle of Probabilistic Semantic Web Mining named from the methods used. With\nthe increase of larger and larger collection of various data resources on the\nWorld Wide Web (WWW), Web Mining has become one of the most important\nrequirements for the web users. Web servers will store various formats of data\nincluding text, image, audio, video etc., but servers can not identify the\ncontents of the data. These search techniques can be improved by adding some\nspecial techniques including semantic web mining and probabilistic analysis to\nget more accurate results. Semantic web mining technique can provide meaningful\nsearch of data resources by eliminating useless information with mining\nprocess. In this technique web servers will maintain Meta information of each\nand every data resources available in that particular web server. This will\nhelp the search engine to retrieve information that is relevant to user given\ninput string. This paper proposing the idea of combing these two techniques\nSemantic web mining and Probabilistic analysis for efficient and accurate\nsearch results of web mining. SPF can be calculated by considering both\nsemantic accuracy and syntactic accuracy of data with the input string. This\nwill be the deciding factor for producing results.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2010 11:19:32 GMT"}], "update_date": "2010-04-13", "authors_parsed": [["Kishore", "T. Krishna", ""], ["Vardhan", "T. Sasi", ""], ["Narayana", "N. Lakshmi", ""]]}, {"id": "1004.2003", "submitter": "Norbert B\\'atfai", "authors": "Norbert B\\'atfai", "title": "The Socceral Force", "comments": "20 pages, 13 figures, added FerSML 0.0.2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have an audacious dream, we would like to develop a simulation and virtual\nreality system to support the decision making in European football (soccer). In\nthis review, we summarize the efforts that we have made to fulfil this dream\nuntil recently. In addition, an introductory version of FerSML (Footballer and\nFootball Simulation Markup Language) is presented in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2010 16:24:54 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2010 11:26:15 GMT"}], "update_date": "2010-04-23", "authors_parsed": [["B\u00e1tfai", "Norbert", ""]]}, {"id": "1004.2008", "submitter": "Ameet Talwalkar", "authors": "Ameet Talwalkar and Afshin Rostamizadeh", "title": "Matrix Coherence and the Nystrom Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Nystrom method is an efficient technique to speed up large-scale learning\napplications by generating low-rank approximations. Crucial to the performance\nof this technique is the assumption that a matrix can be well approximated by\nworking exclusively with a subset of its columns. In this work we relate this\nassumption to the concept of matrix coherence and connect matrix coherence to\nthe performance of the Nystrom method. Making use of related work in the\ncompressed sensing and the matrix completion literature, we derive novel\ncoherence-based bounds for the Nystrom method in the low-rank setting. We then\npresent empirical results that corroborate these theoretical bounds. Finally,\nwe present more general empirical results for the full-rank setting that\nconvincingly demonstrate the ability of matrix coherence to measure the degree\nto which information can be extracted from a subset of columns.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2010 17:09:16 GMT"}], "update_date": "2010-04-13", "authors_parsed": [["Talwalkar", "Ameet", ""], ["Rostamizadeh", "Afshin", ""]]}, {"id": "1004.2027", "submitter": "Mohammad Gheshlaghi Azar", "authors": "Mohammad Gheshlaghi Azar, Vicenc Gomez and Hilbert J. Kappen", "title": "Dynamic Policy Programming", "comments": "Submitted to Journal of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel policy iteration method, called dynamic\npolicy programming (DPP), to estimate the optimal policy in the\ninfinite-horizon Markov decision processes. We prove the finite-iteration and\nasymptotic l\\infty-norm performance-loss bounds for DPP in the presence of\napproximation/estimation error. The bounds are expressed in terms of the\nl\\infty-norm of the average accumulated error as opposed to the l\\infty-norm of\nthe error in the case of the standard approximate value iteration (AVI) and the\napproximate policy iteration (API). This suggests that DPP can achieve a better\nperformance than AVI and API since it averages out the simulation noise caused\nby Monte-Carlo sampling throughout the learning process. We examine this\ntheoretical results numerically by com- paring the performance of the\napproximate variants of DPP with existing reinforcement learning (RL) methods\non different problem domains. Our results show that, in all cases, DPP-based\nalgorithms outperform other RL methods by a wide margin.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2010 19:09:43 GMT"}, {"version": "v2", "created": "Tue, 6 Sep 2011 20:23:59 GMT"}], "update_date": "2011-09-09", "authors_parsed": [["Azar", "Mohammad Gheshlaghi", ""], ["Gomez", "Vicenc", ""], ["Kappen", "Hilbert J.", ""]]}, {"id": "1004.2304", "submitter": "Patrick Harrington Jr.", "authors": "Patrick L. Harrington Jr., Alfred O. Hero III", "title": "Spatio-Temporal Graphical Model Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the topology of spatial interactions in\na discrete state, discrete time spatio-temporal graphical model where the\ninteractions affect the temporal evolution of each agent in a network. Among\nother models, the susceptible, infected, recovered ($SIR$) model for\ninteraction events fall into this framework. We pose the problem as a structure\nlearning problem and solve it using an $\\ell_1$-penalized likelihood convex\nprogram. We evaluate the solution on a simulated spread of infectious over a\ncomplex network. Our topology estimates outperform those of a standard spatial\nMarkov random field graphical model selection using $\\ell_1$-regularized\nlogistic regression.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2010 01:50:42 GMT"}], "update_date": "2010-04-15", "authors_parsed": [["Harrington", "Patrick L.", "Jr."], ["Hero", "Alfred O.", "III"]]}, {"id": "1004.2342", "submitter": "Nicolas Gast", "authors": "Nicolas Gast (INRIA Grenoble Rh\\^one-Alpes / LIG laboratoire\n  d'Informatique de Grenoble, EPFL), Bruno Gaujal (INRIA Grenoble Rh\\^one-Alpes\n  / LIG laboratoire d'Informatique de Grenoble), Jean-Yves Le Boudec (EPFL)", "title": "Mean field for Markov Decision Processes: from Discrete to Continuous\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-7239, RR-7239", "categories": "cs.AI cs.PF cs.SY math.OC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the convergence of Markov Decision Processes made of a large number\nof objects to optimization problems on ordinary differential equations (ODE).\nWe show that the optimal reward of such a Markov Decision Process, satisfying a\nBellman equation, converges to the solution of a continuous\nHamilton-Jacobi-Bellman (HJB) equation based on the mean field approximation of\nthe Markov Decision Process. We give bounds on the difference of the rewards,\nand a constructive algorithm for deriving an approximating solution to the\nMarkov Decision Process from a solution of the HJB equations. We illustrate the\nmethod on three examples pertaining respectively to investment strategies,\npopulation dynamics control and scheduling in queues are developed. They are\nused to illustrate and justify the construction of the controlled ODE and to\nshow the gain obtained by solving a continuous HJB equation rather than a large\ndiscrete Bellman equation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2010 07:56:40 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2010 14:26:32 GMT"}, {"version": "v3", "created": "Thu, 19 May 2011 07:27:54 GMT"}], "update_date": "2011-05-20", "authors_parsed": [["Gast", "Nicolas", "", "INRIA Grenoble Rh\u00f4ne-Alpes / LIG laboratoire\n  d'Informatique de Grenoble, EPFL"], ["Gaujal", "Bruno", "", "INRIA Grenoble Rh\u00f4ne-Alpes\n  / LIG laboratoire d'Informatique de Grenoble"], ["Boudec", "Jean-Yves Le", "", "EPFL"]]}, {"id": "1004.2624", "submitter": "Toby Walsh", "authors": "Marijn Heule and Toby Walsh", "title": "Symmetry within Solutions", "comments": "AAAI 2010, Proceedings of Twenty-Fourth AAAI Conference on Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define the concept of an internal symmetry. This is a symmety within a\nsolution of a constraint satisfaction problem. We compare this to solution\nsymmetry, which is a mapping between different solutions of the same problem.\nWe argue that we may be able to exploit both types of symmetry when finding\nsolutions. We illustrate the potential of exploiting internal symmetries on two\nbenchmark domains: Van der Waerden numbers and graceful graphs. By identifying\ninternal symmetries we are able to extend the state of the art in both cases.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2010 13:15:06 GMT"}], "update_date": "2010-04-16", "authors_parsed": [["Heule", "Marijn", ""], ["Walsh", "Toby", ""]]}, {"id": "1004.2626", "submitter": "Toby Walsh", "authors": "Christian Bessiere and George Katsirelos and Nina Narodytska and\n  Claude-Guy Quimper and Toby Walsh", "title": "Propagating Conjunctions of AllDifferent Constraints", "comments": "AAAI 2010, Proceedings of the Twenty-Fourth AAAI Conference on\n  Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study propagation algorithms for the conjunction of two AllDifferent\nconstraints. Solutions of an AllDifferent constraint can be seen as perfect\nmatchings on the variable/value bipartite graph. Therefore, we investigate the\nproblem of finding simultaneous bipartite matchings. We present an extension of\nthe famous Hall theorem which characterizes when simultaneous bipartite\nmatchings exists. Unfortunately, finding such matchings is NP-hard in general.\nHowever, we prove a surprising result that finding a simultaneous matching on a\nconvex bipartite graph takes just polynomial time. Based on this theoretical\nresult, we provide the first polynomial time bound consistency algorithm for\nthe conjunction of two AllDifferent constraints. We identify a pathological\nproblem on which this propagator is exponentially faster compared to existing\npropagators. Our experiments show that this new propagator can offer\nsignificant benefits over existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2010 13:37:49 GMT"}], "update_date": "2010-04-16", "authors_parsed": [["Bessiere", "Christian", ""], ["Katsirelos", "George", ""], ["Narodytska", "Nina", ""], ["Quimper", "Claude-Guy", ""], ["Walsh", "Toby", ""]]}, {"id": "1004.2854", "submitter": "Uwe Aickelin", "authors": "Jamie Twycross, Uwe Aickelin", "title": "Experimenting with Innate Immunity", "comments": "8 pages, 5 figures, 4 tables, Workshop on Artificial Immune Systems\n  and Immune System Modelling (AISB06)", "journal-ref": "Proceedings of the Workshop on Artificial Immune Systems and\n  Immune System Modelling (AISB06), Bristol, UK, p 18-19, 2006", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a previous paper the authors argued the case for incorporating ideas from\ninnate immunity into artificial immune systems (AISs) and presented an outline\nfor a conceptual framework for such systems. A number of key general properties\nobserved in the biological innate and adaptive immune systems were highlighted,\nand how such properties might be instantiated in artificial systems was\ndiscussed in detail. The next logical step is to take these ideas and build a\nsoftware system with which AISs with these properties can be implemented and\nexperimentally evaluated. This paper reports on the results of that step - the\nlibtissue system.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2010 14:38:20 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Twycross", "Jamie", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1004.2860", "submitter": "Uwe Aickelin", "authors": "Yousof Al-Hammadi, Uwe Aickelin", "title": "Behavioural Correlation for Detecting P2P Bots", "comments": "5 pages, 1 table, 1 algorithm, Second International Conference on\n  Future Networks (ICFN 2010)", "journal-ref": "Proceedings of the Second International Conference on Future\n  Networks (ICFN 2010), Sanya, Hainan, China, p 323-327, 2010", "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, IRC bots, malicious programs which are remotely\ncontrolled by the attacker through IRC servers, have become a major threat to\nthe Internet and users. These bots can be used in different malicious ways such\nas issuing distributed denial of services attacks to shutdown other networks\nand services, keystrokes logging, spamming, traffic sniffing cause serious\ndisruption on networks and users. New bots use peer to peer (P2P) protocols\nstart to appear as the upcoming threat to Internet security due to the fact\nthat P2P bots do not have a centralized point to shutdown or traceback, thus\nmaking the detection of P2P bots is a real challenge. In response to these\nthreats, we present an algorithm to detect an individual P2P bot running on a\nsystem by correlating its activities. Our evaluation shows that correlating\ndifferent activities generated by P2P bots within a specified time period can\ndetect these kind of bots.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2010 15:15:31 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Al-Hammadi", "Yousof", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1004.2870", "submitter": "Uwe Aickelin", "authors": "Uwe Aickelin", "title": "Nurse Rostering with Genetic Algorithms", "comments": "22 pages, Young Operational Research Conference 12", "journal-ref": "Young Operational Research Conference 12, 1998", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years genetic algorithms have emerged as a useful tool for the\nheuristic solution of complex discrete optimisation problems. In particular\nthere has been considerable interest in their use in tackling problems arising\nin the areas of scheduling and timetabling. However, the classical genetic\nalgorithm paradigm is not well equipped to handle constraints and successful\nimplementations usually require some sort of modification to enable the search\nto exploit problem specific knowledge in order to overcome this shortcoming.\nThis paper is concerned with the development of a family of genetic algorithms\nfor the solution of a nurse rostering problem at a major UK hospital. The\nhospital is made up of wards of up to 30 nurses. Each ward has its own group of\nnurses whose shifts have to be scheduled on a weekly basis. In addition to\nfulfilling the minimum demand for staff over three daily shifts, nurses' wishes\nand qualifications have to be taken into account. The schedules must also be\nseen to be fair, in that unpopular shifts have to be spread evenly amongst all\nnurses, and other restrictions, such as team nursing and special conditions for\nsenior staff, have to be satisfied. The basis of the family of genetic\nalgorithms is a classical genetic algorithm consisting of n-point crossover,\nsingle-bit mutation and a rank-based selection. The solution space consists of\nall schedules in which each nurse works the required number of shifts, but the\nremaining constraints, both hard and soft, are relaxed and penalised in the\nfitness function. The talk will start with a detailed description of the\nproblem and the initial implementation and will go on to highlight the\nshortcomings of such an approach, in terms of the key element of balancing\nfeasibility, i.e. covering the demand and work regulations, and quality, as\nmeasured by the nurses' preferences. A series of experiments involving\nparameter adaptation, niching, intelligent weights, delta coding, local hill\nclimbing, migration and special selection rules will then be outlined and it\nwill be shown how a series of these enhancements were able to eradicate these\ndifficulties. Results based on several months' real data will be used to\nmeasure the impact of each modification, and to show that the final algorithm\nis able to compete with a tabu search approach currently employed at the\nhospital. The talk will conclude with some observations as to the overall\nquality of this approach to this and similar problems.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2010 11:27:43 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Aickelin", "Uwe", ""]]}, {"id": "1004.2880", "submitter": "Nicola Di Mauro", "authors": "Nicola Di Mauro, Teresa M.A. Basile, Stefano Ferilli and Floriana\n  Esposito", "title": "GRASP for the Coalition Structure Formation Problem", "comments": "12 pages, Submitted to an International Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coalition structure formation problem represents an active research area\nin multi-agent systems. A coalition structure is defined as a partition of the\nagents involved in a system into disjoint coalitions. The problem of finding\nthe optimal coalition structure is NP-complete. In order to find the optimal\nsolution in a combinatorial optimization problem it is theoretically possible\nto enumerate the solutions and evaluate each. But this approach is infeasible\nsince the number of solutions often grows exponentially with the size of the\nproblem. In this paper we present a greedy adaptive search procedure (GRASP) to\nefficiently search the space of coalition structures in order to find an\noptimal one. Experiments and comparisons to other algorithms prove the validity\nof the proposed method in solving this hard combinatorial problem.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2010 16:43:11 GMT"}], "update_date": "2010-04-19", "authors_parsed": [["Di Mauro", "Nicola", ""], ["Basile", "Teresa M. A.", ""], ["Ferilli", "Stefano", ""], ["Esposito", "Floriana", ""]]}, {"id": "1004.3147", "submitter": "Uwe Aickelin", "authors": "Uwe Aickelin", "title": "Genetic Algorithms for Multiple-Choice Problems", "comments": "258 pages, PhD thesis, University of Wales (Swansea)", "journal-ref": "PhD thesis, University of Wales (Swansea), 1999", "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis investigates the use of problem-specific knowledge to enhance a\ngenetic algorithm approach to multiple-choice optimisation problems.It shows\nthat such information can significantly enhance performance, but that the\nchoice of information and the way it is included are important factors for\nsuccess.Two multiple-choice problems are considered.The first is constructing a\nfeasible nurse roster that considers as many requests as possible.In the second\nproblem, shops are allocated to locations in a mall subject to constraints and\nmaximising the overall income.Genetic algorithms are chosen for their\nwell-known robustness and ability to solve large and complex discrete\noptimisation problems.However, a survey of the literature reveals room for\nfurther research into generic ways to include constraints into a genetic\nalgorithm framework.Hence, the main theme of this work is to balance\nfeasibility and cost of solutions.In particular, co-operative co-evolution with\nhierarchical sub-populations, problem structure exploiting repair schemes and\nindirect genetic algorithms with self-adjusting decoder functions are\nidentified as promising approaches.The research starts by applying standard\ngenetic algorithms to the problems and explaining the failure of such\napproaches due to epistasis.To overcome this, problem-specific information is\nadded in a variety of ways, some of which are designed to increase the number\nof feasible solutions found whilst others are intended to improve the quality\nof such solutions.As well as a theoretical discussion as to the underlying\nreasons for using each operator,extensive computational experiments are carried\nout on a variety of data.These show that the indirect approach relies less on\nproblem structure and hence is easier to implement and superior in solution\nquality.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2010 10:16:18 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Aickelin", "Uwe", ""]]}, {"id": "1004.3196", "submitter": "Uwe Aickelin", "authors": "Julie Greensmith, Uwe Aickelin, Steve Cayzer", "title": "Introducing Dendritic Cells as a Novel Immune-Inspired Algorithm for\n  Anomoly Detection", "comments": "14 pages, 4 figures, 4 tables, 4th International Conference on\n  Artificial Immune Systems (ICARIS2005)", "journal-ref": "Proceedings of the 4th International Conference on Artificial\n  Immune Systems (ICARIS2005), Lecture Notes in Computer Science 3627, Banff,\n  Canada, 2005", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dendritic cells are antigen presenting cells that provide a vital link\nbetween the innate and adaptive immune system. Research into this family of\ncells has revealed that they perform the role of coordinating T-cell based\nimmune responses, both reactive and for generating tolerance. We have derived\nan algorithm based on the functionality of these cells, and have used the\nsignals and differentiation pathways to build a control mechanism for an\nartificial immune system. We present our algorithmic details in addition to\nsome preliminary results, where the algorithm was applied for the purpose of\nanomaly detection. We hope that this algorithm will eventually become the key\ncomponent within a large, distributed immune system, based on sound\nimmunological concepts.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2010 13:52:32 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Greensmith", "Julie", ""], ["Aickelin", "Uwe", ""], ["Cayzer", "Steve", ""]]}, {"id": "1004.3260", "submitter": "Vishal Goyal", "authors": "Rosmayati Mohemad, Abdul Razak Hamdan, Zulaiha Ali Othman, Noor\n  Maizura Mohamad Noor", "title": "Decision Support Systems (DSS) in Construction Tendering Processes", "comments": "International Journal of Computer Science Issues online at\n  http://ijcsi.org/articles/Decision-Support-Systems-DSS-in-Construction-Tendering-Processes.php", "journal-ref": "IJCSI, Volume 7, Issue 2, March 2010", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The successful execution of a construction project is heavily impacted by\nmaking the right decision during tendering processes. Managing tender\nprocedures is very complex and uncertain involving coordination of many tasks\nand individuals with different priorities and objectives. Bias and inconsistent\ndecision are inevitable if the decision-making process is totally depends on\nintuition, subjective judgement or emotion. In making transparent decision and\nhealthy competition tendering, there exists a need for flexible guidance tool\nfor decision support. Aim of this paper is to give a review on current\npractices of Decision Support Systems (DSS) technology in construction\ntendering processes. Current practices of general tendering processes as\napplied to the most countries in different regions such as United States,\nEurope, Middle East and Asia are comprehensively discussed. Applications of\nWeb-based tendering processes is also summarised in terms of its properties.\nBesides that, a summary of Decision Support System (DSS) components is included\nin the next section. Furthermore, prior researches on implementation of DSS\napproaches in tendering processes are discussed in details. Current issues\narise from both of paper-based and Web-based tendering processes are outlined.\nFinally, conclusion is included at the end of this paper.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2010 17:56:06 GMT"}], "update_date": "2010-04-20", "authors_parsed": [["Mohemad", "Rosmayati", ""], ["Hamdan", "Abdul Razak", ""], ["Othman", "Zulaiha Ali", ""], ["Noor", "Noor Maizura Mohamad", ""]]}, {"id": "1004.3390", "submitter": "Christoph Lange", "authors": "Catalin David, Michael Kohlhase, Christoph Lange, Florian Rabe, Nikita\n  Zhiltsov and Vyacheslav Zholudev", "title": "Publishing Math Lecture Notes as Linked Data", "comments": "7th Extended Semantic Web Conference (http://www.eswc2010.org), Demo\n  Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI math.HO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We mark up a corpus of LaTeX lecture notes semantically and expose them as\nLinked Data in XHTML+MathML+RDFa. Our application makes the resulting documents\ninteractively browsable for students. Our ontology helps to answer queries from\nstudents and lecturers, and paves the path towards an integration of our corpus\nwith external sites.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2010 09:32:32 GMT"}], "update_date": "2010-04-21", "authors_parsed": [["David", "Catalin", ""], ["Kohlhase", "Michael", ""], ["Lange", "Christoph", ""], ["Rabe", "Florian", ""], ["Zhiltsov", "Nikita", ""], ["Zholudev", "Vyacheslav", ""]]}, {"id": "1004.3460", "submitter": "Uwe Aickelin", "authors": "Feng Gu, Julie Greensmith, Robert Oates and Uwe Aickelin", "title": "PCA 4 DCA: The Application Of Principal Component Analysis To The\n  Dendritic Cell Algorithm", "comments": "6 pages, 4 figures, 3 tables, (UKCI 2009)", "journal-ref": "Proceedings of the 9th Annual Workshop on Computational\n  Intelligence (UKCI 2009), Nottingham, UK, 2009", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the newest members in the field of artificial immune systems (AIS),\nthe Dendritic Cell Algorithm (DCA) is based on behavioural models of natural\ndendritic cells (DCs). Unlike other AIS, the DCA does not rely on training\ndata, instead domain or expert knowledge is required to predetermine the\nmapping between input signals from a particular instance to the three\ncategories used by the DCA. This data preprocessing phase has received the\ncriticism of having manually over-?tted the data to the algorithm, which is\nundesirable. Therefore, in this paper we have attempted to ascertain if it is\npossible to use principal component analysis (PCA) techniques to automatically\ncategorise input data while still generating useful and accurate classication\nresults. The integrated system is tested with a biometrics dataset for the\nstress recognition of automobile drivers. The experimental results have shown\nthe application of PCA to the DCA for the purpose of automated data\npreprocessing is successful.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2010 14:20:04 GMT"}], "update_date": "2016-11-26", "authors_parsed": [["Gu", "Feng", ""], ["Greensmith", "Julie", ""], ["Oates", "Robert", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1004.3478", "submitter": "Carlos Lorenzetti", "authors": "Carlos M. Lorenzetti and Ana G. Maguitman", "title": "Learning Better Context Characterizations: An Intelligent Information\n  Retrieval Approach", "comments": "10 pages, 3 figures, CLEI 2008", "journal-ref": "XXXIV Conferencia Latinoamericana de Inform\\'{a}tica, pp. 200-209,\n  2008", "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper proposes an incremental method that can be used by an intelligent\nsystem to learn better descriptions of a thematic context. The method starts\nwith a small number of terms selected from a simple description of the topic\nunder analysis and uses this description as the initial search context. Using\nthese terms, a set of queries are built and submitted to a search engine. New\ndocuments and terms are used to refine the learned vocabulary. Evaluations\nperformed on a large number of topics indicate that the learned vocabulary is\nmuch more effective than the original one at the time of constructing queries\nto retrieve relevant material.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2010 15:21:49 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2010 19:29:16 GMT"}], "update_date": "2010-04-28", "authors_parsed": [["Lorenzetti", "Carlos M.", ""], ["Maguitman", "Ana G.", ""]]}, {"id": "1004.3568", "submitter": "Vishal Goyal", "authors": "Vikram Singh, Sapna Nagpal", "title": "Integrating User's Domain Knowledge with Association Rule Mining", "comments": "International Journal of Computer Science Issues online at\n  http://ijcsi.org/articles/Integrating-Users-Domain-Knowledge-with-Association-Rule-Mining.php", "journal-ref": "IJCSI, Volume 7, Issue 2, March 2010", "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a variation of Apriori algorithm that includes the role\nof domain expert to guide and speed up the overall knowledge discovery task.\nUsually, the user is interested in finding relationships between certain\nattributes instead of the whole dataset. Moreover, he can help the mining\nalgorithm to select the target database which in turn takes less time to find\nthe desired association rules. Variants of the standard Apriori and Interactive\nApriori algorithms have been run on artificial datasets. The results show that\nincorporating user's preference in selection of target attribute helps to\nsearch the association rules efficiently both in terms of space and time.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2010 20:37:32 GMT"}], "update_date": "2010-04-22", "authors_parsed": [["Singh", "Vikram", ""], ["Nagpal", "Sapna", ""]]}, {"id": "1004.3708", "submitter": "Uwe Aickelin", "authors": "Yongnan Ji, Pierre-Yves Herve, Uwe Aickelin, Alain Pitiot", "title": "Parcellation of fMRI Datasets with ICA and PLS-A Data Driven Approach", "comments": "8 pages, 5 figures, P12th International Conference of Medical Image\n  Computing and Computer-Assisted Intervention (MICCAI 2009)", "journal-ref": "Proceedings of the 12th International Conference of Medical Image\n  Computing and Computer-Assisted Intervention (MICCAI 2009), Part I, Lecture\n  Notes in Computer Science 5761, London, UK, 2009", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inter-subject parcellation of functional Magnetic Resonance Imaging (fMRI)\ndata based on a standard General Linear Model (GLM)and spectral clustering was\nrecently proposed as a means to alleviate the issues associated with spatial\nnormalization in fMRI. However, for all its appeal, a GLM-based parcellation\napproach introduces its own biases, in the form of a priori knowledge about the\nshape of Hemodynamic Response Function (HRF) and task-related signal changes,\nor about the subject behaviour during the task. In this paper, we introduce a\ndata-driven version of the spectral clustering parcellation, based on\nIndependent Component Analysis (ICA) and Partial Least Squares (PLS) instead of\nthe GLM. First, a number of independent components are automatically selected.\nSeed voxels are then obtained from the associated ICA maps and we compute the\nPLS latent variables between the fMRI signal of the seed voxels (which covers\nregional variations of the HRF) and the principal components of the signal\nacross all voxels. Finally, we parcellate all subjects data with a spectral\nclustering of the PLS latent variables. We present results of the application\nof the proposed method on both single-subject and multi-subject fMRI datasets.\nPreliminary experimental results, evaluated with intra-parcel variance of GLM\nt-values and PLS derived t-values, indicate that this data-driven approach\noffers improvement in terms of parcellation accuracy over GLM based techniques.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2010 13:50:55 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Ji", "Yongnan", ""], ["Herve", "Pierre-Yves", ""], ["Aickelin", "Uwe", ""], ["Pitiot", "Alain", ""]]}, {"id": "1004.3809", "submitter": "Khaled Khalil", "authors": "Khaled M. Khalil, M. Abdel-Aziz, Taymour T. Nazmy, Abdel-Badeeh M.\n  Salem", "title": "Artificial Immune Systems Metaphor for Agent Based Modeling of Crisis\n  Response Operations", "comments": "12 pages, 5 figures, and 5 tables. Submitted to MATES2010: Eighth\n  German Conference on Multi-Agents System Technologies, September 21,\n  2010-September 23, 2010 in Karlsruhe, Germany.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crisis response requires information intensive efforts utilized for reducing\nuncertainty, calculating and comparing costs and benefits, and managing\nresources in a fashion beyond those regularly available to handle routine\nproblems. This paper presents an Artificial Immune Systems (AIS) metaphor for\nagent based modeling of crisis response operations. The presented model\nproposes integration of hybrid set of aspects (multi-agent systems, built-in\ndefensive model of AIS, situation management, and intensity-based learning) for\ncrisis response operations. In addition, the proposed response model is applied\non the spread of pandemic influenza in Egypt as a case study.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2010 21:33:32 GMT"}], "update_date": "2010-04-23", "authors_parsed": [["Khalil", "Khaled M.", ""], ["Abdel-Aziz", "M.", ""], ["Nazmy", "Taymour T.", ""], ["Salem", "Abdel-Badeeh M.", ""]]}, {"id": "1004.3884", "submitter": "Uwe Aickelin", "authors": "WIlliam Wilson, Phil Birkin, Uwe Aickelin", "title": "Oil Price Trackers Inspired by Immune Memory", "comments": "2 pages, Workshop on Artificial Immune Systems and Immune System\n  Modelling (AISB06), Bristol, UK", "journal-ref": "Proceedings of the Workshop on Artificial Immune Systems and\n  Immune System Modelling (AISB06), Bristol, UK, 2006", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline initial concepts for an immune inspired algorithm to evaluate and\npredict oil price time series data. The proposed solution evolves a short term\npool of trackers dynamically, with each member attempting to map trends and\nanticipate future price movements. Successful trackers feed into a long term\nmemory pool that can generalise across repeating trend patterns. The resulting\nsequence of trackers, ordered in time, can be used as a forecasting tool.\nExamination of the pool of evolving trackers also provides valuable insight\ninto the properties of the crude oil market.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2010 10:24:37 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Wilson", "WIlliam", ""], ["Birkin", "Phil", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1004.3887", "submitter": "Uwe Aickelin", "authors": "William Wilson, Phil Birkin, Uwe Aickelin", "title": "Motif Detection Inspired by Immune Memory", "comments": "12 pages, 4 figures, (ICARIS2007),", "journal-ref": "Proceedings of the 6th International Conference on Artificial\n  Immune Systems (ICARIS2007), Lecture Notes in Computer Science 4628, Santos,\n  Brazil, 2007, p 276-287", "doi": null, "report-no": null, "categories": "cs.AI cs.NE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search for patterns or motifs in data represents an area of key interest\nto many researchers. In this paper we present the Motif Tracking Algorithm, a\nnovel immune inspired pattern identification tool that is able to identify\nvariable length unknown motifs which repeat within time series data. The\nalgorithm searches from a completely neutral perspective that is independent of\nthe data being analysed and the underlying motifs. In this paper we test the\nflexibility of the motif tracking algorithm by applying it to the search for\npatterns in two industrial data sets. The algorithm is able to identify a\npopulation of motifs successfully in both cases, and the value of these motifs\nis discussed.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2010 10:55:23 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Wilson", "William", ""], ["Birkin", "Phil", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1004.3919", "submitter": "Uwe Aickelin", "authors": "Yousof Al-Hammadi, Uwe Aickelin, Julie Greensmith", "title": "Performance Evaluation of DCA and SRC on a Single Bot Detection", "comments": "11 pages, 4 figures, 6 tables, Journal of Information Assurance and\n  Security", "journal-ref": "Journal of Information Assurance and Security, 5(1), p265-275,\n  2010", "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious users try to compromise systems using new techniques. One of the\nrecent techniques used by the attacker is to perform complex distributed\nattacks such as denial of service and to obtain sensitive data such as password\ninformation. These compromised machines are said to be infected with malicious\nsoftware termed a \"bot\". In this paper, we investigate the correlation of\nbehavioural attributes such as keylogging and packet flooding behaviour to\ndetect the existence of a single bot on a compromised machine by applying (1)\nSpearman's rank correlation (SRC) algorithm and (2) the Dendritic Cell\nAlgorithm (DCA). We also compare the output results generated from these two\nmethods to the detection of a single bot. The results show that the DCA has a\nbetter performance in detecting malicious activities.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2010 13:41:37 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Al-Hammadi", "Yousof", ""], ["Aickelin", "Uwe", ""], ["Greensmith", "Julie", ""]]}, {"id": "1004.3932", "submitter": "Uwe Aickelin", "authors": "Simon Garret, Martin Robbins, Joanne Walker, William Wilson, Uwe\n  Aickelin", "title": "Modelling Immunological Memory", "comments": "26 pages, In Silico Immunology", "journal-ref": "In Silico Immunology, 83-108, 2006", "doi": null, "report-no": null, "categories": "cs.AI cs.NE q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate immunological models offer the possibility of performing\nhighthroughput experiments in silico that can predict, or at least suggest, in\nvivo phenomena. In this chapter, we compare various models of immunological\nmemory. We first validate an experimental immunological simulator, developed by\nthe authors, by simulating several theories of immunological memory with known\nresults. We then use the same system to evaluate the predicted effects of a\ntheory of immunological memory. The resulting model has not been explored\nbefore in artificial immune systems research, and we compare the simulated in\nsilico output with in vivo measurements. Although the theory appears valid, we\nsuggest that there are a common set of reasons why immunological memory models\nare a useful support tool; not conclusive in themselves.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2010 10:31:21 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Garret", "Simon", ""], ["Robbins", "Martin", ""], ["Walker", "Joanne", ""], ["Wilson", "William", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1004.3939", "submitter": "Uwe Aickelin", "authors": "William Wilson, Phil Birkin, Uwe Aickelin", "title": "Price Trackers Inspired by Immune Memory", "comments": "14 pages, 5 figures, 3 tables, 5th International Conference on\n  Artificial Immune Systems (ICARIS2006)", "journal-ref": "Proceedings of the 5th International Conference on Artificial\n  Immune Systems (ICARIS2006), Lecture Notes in Computer Science 4163,\n  p362-375, 2006", "doi": null, "report-no": null, "categories": "cs.AI cs.NE physics.data-an q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we outline initial concepts for an immune inspired algorithm to\nevaluate price time series data. The proposed solution evolves a short term\npool of trackers dynamically through a process of proliferation and mutation,\nwith each member attempting to map to trends in price movements. Successful\ntrackers feed into a long term memory pool that can generalise across repeating\ntrend patterns. Tests are performed to examine the algorithm's ability to\nsuccessfully identify trends in a small data set. The influence of the long\nterm memory pool is then examined. We find the algorithm is able to identify\nprice trends presented successfully and efficiently.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2010 15:01:02 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Wilson", "William", ""], ["Birkin", "Phil", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1004.4089", "submitter": "Uwe Aickelin", "authors": "Gianni Tedesco, Uwe Aickelin", "title": "Real-Time Alert Correlation with Type Graphs", "comments": "15 pages, 3 tables, (ICISS 2008)", "journal-ref": "Proceedings of the 4th International Conference on Information\n  Systems Security (ICISS 2008), Lecture Notes in Computer Science 5352,\n  Hyderabad, India, 2008, p173-187", "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The premise of automated alert correlation is to accept that false alerts\nfrom a low level intrusion detection system are inevitable and use attack\nmodels to explain the output in an understandable way. Several algorithms exist\nfor this purpose which use attack graphs to model the ways in which attacks can\nbe combined. These algorithms can be classified in to two broad categories\nnamely scenario-graph approaches, which create an attack model starting from a\nvulnerability assessment and type-graph approaches which rely on an abstract\nmodel of the relations between attack types. Some research in to improving the\nefficiency of type-graph correlation has been carried out but this research has\nignored the hypothesizing of missing alerts. Our work is to present a novel\ntype-graph algorithm which unifies correlation and hypothesizing in to a single\noperation. Our experimental results indicate that the approach is extremely\nefficient in the face of intensive alerts and produces compact output graphs\ncomparable to other techniques.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2010 10:23:31 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Tedesco", "Gianni", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1004.4095", "submitter": "Uwe Aickelin", "authors": "Jan Feyereisl, Uwe Aickelin", "title": "STORM - A Novel Information Fusion and Cluster Interpretation Technique", "comments": "11 pages, 2 figures, 10th International Conference on Intelligent\n  Data Engineering and Automated Learning (IDEAL 09)", "journal-ref": "Proceedings of the 10th International Conference on Intelligent\n  Data Engineering and Automated Learning (IDEAL 09), Lecture Notes in Computer\n  Science 5788, Burgos, Spain, 2009, p208-218", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of data without labels is commonly subject to scrutiny by\nunsupervised machine learning techniques. Such techniques provide more\nmeaningful representations, useful for better understanding of a problem at\nhand, than by looking only at the data itself. Although abundant expert\nknowledge exists in many areas where unlabelled data is examined, such\nknowledge is rarely incorporated into automatic analysis. Incorporation of\nexpert knowledge is frequently a matter of combining multiple data sources from\ndisparate hypothetical spaces. In cases where such spaces belong to different\ndata types, this task becomes even more challenging. In this paper we present a\nnovel immune-inspired method that enables the fusion of such disparate types of\ndata for a specific set of problems. We show that our method provides a better\nvisual understanding of one hypothetical space with the help of data from\nanother hypothetical space. We believe that our model has implications for the\nfield of exploratory data analysis and knowledge discovery.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2010 10:54:24 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Feyereisl", "Jan", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1004.4342", "submitter": "Martin Slota", "authors": "Martin Slota and Jo\\~ao Leite", "title": "Towards Closed World Reasoning in Dynamic Open Worlds (Extended Version)", "comments": "40 pages; an extended version of the article published in Theory and\n  Practice of Logic Programming, 10 (4-6): 547 - 564, July. Copyright 2010\n  Cambridge University Press", "journal-ref": "Theory and Practice of Logic Programming, 10(4-6), 547-564, 2010", "doi": "10.1017/S147106841000027X", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for integration of ontologies with nonmonotonic rules has been\ngaining importance in a number of areas, such as the Semantic Web. A number of\nresearchers addressed this problem by proposing a unified semantics for hybrid\nknowledge bases composed of both an ontology (expressed in a fragment of\nfirst-order logic) and nonmonotonic rules. These semantics have matured over\nthe years, but only provide solutions for the static case when knowledge does\nnot need to evolve. In this paper we take a first step towards addressing the\ndynamics of hybrid knowledge bases. We focus on knowledge updates and,\nconsidering the state of the art of belief update, ontology update and rule\nupdate, we show that current solutions are only partial and difficult to\ncombine. Then we extend the existing work on ABox updates with rules, provide a\nsemantics for such evolving hybrid knowledge bases and study its basic\nproperties. To the best of our knowledge, this is the first time that an update\noperator is proposed for hybrid knowledge bases.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2010 10:51:35 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2010 00:31:53 GMT"}], "update_date": "2011-07-27", "authors_parsed": [["Slota", "Martin", ""], ["Leite", "Jo\u00e3o", ""]]}, {"id": "1004.4734", "submitter": "Martin Josef Geiger", "authors": "Martin Josef Geiger", "title": "On the comparison of plans: Proposition of an instability measure for\n  dynamic machine scheduling", "comments": null, "journal-ref": "Proceedings of the 25th Mini EURO Conference on Uncertainty and\n  Robustness in Planning and Decision Making, April 15-17, 2010, Coimbra,\n  Portugal. ISBN 978-989-95055-3-7.", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On the basis of an analysis of previous research, we present a generalized\napproach for measuring the difference of plans with an exemplary application to\nmachine scheduling. Our work is motivated by the need for such measures, which\nare used in dynamic scheduling and planning situations. In this context,\nquantitative approaches are needed for the assessment of the robustness and\nstability of schedules. Obviously, any `robustness' or `stability' of plans has\nto be defined w. r. t. the particular situation and the requirements of the\nhuman decision maker. Besides the proposition of an instability measure, we\ntherefore discuss possibilities of obtaining meaningful information from the\ndecision maker for the implementation of the introduced approach.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2010 08:13:51 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Geiger", "Martin Josef", ""]]}, {"id": "1004.4801", "submitter": "Yves Moinard", "authors": "Philippe Besnard (INRIA - IRISA, IRIT), Marie-Odile Cordier (INRIA -\n  IRISA), Yves Moinard (INRIA - IRISA)", "title": "Ontology-based inference for causal explanation", "comments": null, "journal-ref": "Integrated Computer-Aided Engineering 15, 4 (2008) 351-367", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define an inference system to capture explanations based on causal\nstatements, using an ontology in the form of an IS-A hierarchy. We first\nintroduce a simple logical language which makes it possible to express that a\nfact causes another fact and that a fact explains another fact. We present a\nset of formal inference patterns from causal statements to explanation\nstatements. We introduce an elementary ontology which gives greater\nexpressiveness to the system while staying close to propositional reasoning. We\nprovide an inference system that captures the patterns discussed, firstly in a\npurely propositional framework, then in a datalog (limited predicate)\nframework.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2010 13:42:49 GMT"}], "update_date": "2010-05-02", "authors_parsed": [["Besnard", "Philippe", "", "INRIA - IRISA, IRIT"], ["Cordier", "Marie-Odile", "", "INRIA -\n  IRISA"], ["Moinard", "Yves", "", "INRIA - IRISA"]]}, {"id": "1004.5071", "submitter": "Christoph Lange", "authors": "Andrea Kohlhase and Michael Kohlhase and Christoph Lange", "title": "Dimensions of Formality: A Case Study for MKM in Software Engineering", "comments": "To appear in The 9th International Conference on Mathematical\n  Knowledge Management: MKM 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the formalization of a collection of documents created for a\nSoftware Engineering project from an MKM perspective. We analyze how document\nand collection markup formats can cope with an open-ended, multi-dimensional\nspace of primary and secondary classifications and relationships. We show that\nRDFa-based extensions of MKM formats, employing flexible \"metadata\"\nrelationships referencing specific vocabularies for distinct dimensions, are\nwell-suited to encode this and to put it into service. This formalized\nknowledge can be used for enriching interactive document browsing, for enabling\nmulti-dimensional metadata queries over documents and collections, and for\nexporting Linked Data to the Semantic Web and thus enabling further reuse.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2010 16:00:24 GMT"}], "update_date": "2010-04-29", "authors_parsed": [["Kohlhase", "Andrea", ""], ["Kohlhase", "Michael", ""], ["Lange", "Christoph", ""]]}, {"id": "1004.5215", "submitter": "Uwe Aickelin", "authors": "Grazziela P. Figueredo, Uwe Aickelin, Amanda Whitbrook", "title": "System Dynamics Modelling of the Processes Involving the Maintenance of\n  the Naive T Cell Repertoire", "comments": "6 pages, 2 figures, 1 table, 9th Annual Workshop on Computational\n  Intelligence (UKCI 2009), Nottingham, UK", "journal-ref": "Proceedings of the 9th Annual Workshop on Computational\n  Intelligence (UKCI 2009), Nottingham, UK, p13-18,", "doi": null, "report-no": null, "categories": "cs.AI q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of immune system aging, i.e. immunosenescence, is a relatively new\nresearch topic. It deals with understanding the processes of immunodegradation\nthat indicate signs of functionality loss possibly leading to death. Even\nthough it is not possible to prevent immunosenescence, there is great benefit\nin comprehending its causes, which may help to reverse some of the damage done\nand thus improve life expectancy. One of the main factors influencing the\nprocess of immunosenescence is the number and phenotypical variety of naive T\ncells in an individual. This work presents a review of immunosenescence,\nproposes system dynamics modelling of the processes involving the maintenance\nof the naive T cell repertoire and presents some preliminary results.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2010 08:10:20 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Figueredo", "Grazziela P.", ""], ["Aickelin", "Uwe", ""], ["Whitbrook", "Amanda", ""]]}, {"id": "1004.5222", "submitter": "Uwe Aickelin", "authors": "Robert Oates, Julie Greensmith, Uwe Aickelin, Jonathan M. Garibaldi,\n  Graham Kendall", "title": "The Application of a Dendritic Cell Algorithm to a Robotic Classifier", "comments": "12 pages, 4 figures, Proceedings of the 6th International Conference\n  on Artificial Immune Systems (ICARIS2007)", "journal-ref": "Proceedings of the 6th International Conference on Artificial\n  Immune Systems (ICARIS2007), Lecture Notes in Computer Science 4628, Santos,\n  Brazil, p204-215, 2007", "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dendritic cell algorithm is an immune-inspired technique for processing\ntime-dependant data. Here we propose it as a possible solution for a robotic\nclassification problem. The dendritic cell algorithm is implemented on a real\nrobot and an investigation is performed into the effects of varying the\nmigration threshold median for the cell population. The algorithm performs well\non a classification task with very little tuning. Ways of extending the\nimplementation to allow it to be used as a classifier within the field of\nrobotic security are suggested.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2010 08:51:52 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Oates", "Robert", ""], ["Greensmith", "Julie", ""], ["Aickelin", "Uwe", ""], ["Garibaldi", "Jonathan M.", ""], ["Kendall", "Graham", ""]]}, {"id": "1004.5326", "submitter": "Michael J. Barber", "authors": "Michael J. Barber and John W. Clark", "title": "Designing neural networks that process mean values of random variables", "comments": "13 pages, elsarticle", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a class of neural networks derived from probabilistic models in\nthe form of Bayesian networks. By imposing additional assumptions about the\nnature of the probabilistic models represented in the networks, we derive\nneural networks with standard dynamics that require no training to determine\nthe synaptic weights, that perform accurate calculation of the mean values of\nthe random variables, that can pool multiple sources of evidence, and that deal\ncleanly and consistently with inconsistent or contradictory evidence. The\npresented neural networks capture many properties of Bayesian networks,\nproviding distributed versions of probabilistic models.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2010 15:35:32 GMT"}], "update_date": "2010-04-30", "authors_parsed": [["Barber", "Michael J.", ""], ["Clark", "John W.", ""]]}, {"id": "1004.5339", "submitter": "Kostyantyn Shchekotykhin", "authors": "Kostyantyn Shchekotykhin, Gerhard Friedrich, Philipp Fleiss, Patrick\n  Rodler", "title": "Query strategy for sequential ontology debugging", "comments": "Preprint submitted to Web Semantics: Science, Services and Agents on\n  the World Wide Web", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Debugging of ontologies is an important prerequisite for their wide-spread\napplication, especially in areas that rely upon everyday users to create and\nmaintain knowledge bases, as in the case of the Semantic Web. Recent approaches\nuse diagnosis methods to identify causes of inconsistent or incoherent\nontologies. However, in most debugging scenarios these methods return many\nalternative diagnoses, thus placing the burden of fault localization on the\nuser. This paper demonstrates how the target diagnosis can be identified by\nperforming a sequence of observations, that is, by querying an oracle about\nentailments of the target ontology. We exploit a-priori probabilities of\ntypical user errors to formulate information-theoretic concepts for query\nselection. Our evaluation showed that the proposed method significantly reduces\nthe number of required queries compared to myopic strategies. We experimented\nwith different probability distributions of user errors and different qualities\nof the a-priori probabilities. Our measurements showed the advantageousness of\ninformation-theoretic approach to query selection even in cases where only a\nrough estimate of the priors is available.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2010 16:46:09 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2010 13:00:40 GMT"}, {"version": "v3", "created": "Thu, 21 Jul 2011 08:43:45 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Shchekotykhin", "Kostyantyn", ""], ["Friedrich", "Gerhard", ""], ["Fleiss", "Philipp", ""], ["Rodler", "Patrick", ""]]}, {"id": "1004.5500", "submitter": "Christoph Benzmueller", "authors": "Christoph Benzmueller", "title": "Simple Type Theory as Framework for Combining Logics", "comments": "Contest paper at the World Congress and School on Universal Logic III\n  (UNILOG'2010), Lisbon, Portugal, April 18-25, 2010.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simple type theory is suited as framework for combining classical and\nnon-classical logics. This claim is based on the observation that various\nprominent logics, including (quantified) multimodal logics and intuitionistic\nlogics, can be elegantly embedded in simple type theory. Furthermore, simple\ntype theory is sufficiently expressive to model combinations of embedded logics\nand it has a well understood semantics. Off-the-shelf reasoning systems for\nsimple type theory exist that can be uniformly employed for reasoning within\nand about combinations of logics.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2010 11:20:10 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Benzmueller", "Christoph", ""]]}]